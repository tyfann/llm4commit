{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Build angular format dataset",
   "id": "d5a854cddf0412"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Total_data",
   "id": "e0fc206723bd2ac1"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-02T10:35:25.943522Z",
     "start_time": "2024-07-02T10:33:48.508533Z"
    }
   },
   "source": [
    "import pyarrow.parquet as pq\n",
    "import glob\n",
    "import os\n",
    "from tqdm.auto import tqdm\n",
    "import re\n",
    "\n",
    "def check_angular_convention(msg, has_space=True):\n",
    "    types = '((build)|(ci)|(docs)|(feat)|(fix)|(perf)|(refactor)|(style)|(test)|(chore))'\n",
    "    # types = '((perf))'\n",
    "    if has_space:\n",
    "        pattern = f'{types}\\\\s(\\\\((\\\\s|\\\\S)+\\\\)\\\\s)?:\\\\s(\\\\s|\\\\S)+'\n",
    "    else:\n",
    "        pattern = f'{types}(\\\\((\\\\s|\\\\S)+\\\\))?:\\\\s\\\\S+(\\\\s|\\\\S)+'\n",
    "    # if not strict:\n",
    "    #     pattern = '^((build)|(ci)|(docs)|(feat)|(fix)|(perf)|(refactor)|(style)|(test)|(chore))'\n",
    "    return re.match(pattern, msg) is not None\n",
    "\n",
    "# Define the types for the angular convention\n",
    "angular_types = ['build', 'ci', 'docs', 'feat', 'fix', 'perf', 'refactor', 'style', 'test', 'chore']\n",
    "# angular_types = ['perf']\n",
    "\n",
    "# Create empty dictionaries for each language and type\n",
    "languages = ['JavaScript']\n",
    "dfs = {lang: {atype: [] for atype in angular_types} for lang in languages}\n",
    "\n",
    "# Create a tqdm progress bar for each language\n",
    "bars = {lang: tqdm(total=100000, desc=lang) for lang in languages}  # Total: 10 types * 10000 each\n",
    "\n",
    "folder_path = '../rag/datasets--JetBrains-Research--commit-chronicle/snapshots/5fd076e67b812a9f3d1999e5e40f71715f84bb51/data'  # 文件夹的路径\n",
    "\n",
    "# files = glob.glob(os.path.join(folder_path, 'train*')) + glob.glob(os.path.join(folder_path, 'validation*'))\n",
    "files = glob.glob(os.path.join(folder_path, 'train*')) + glob.glob(os.path.join(folder_path, 'validation*'))\n",
    "\n",
    "for file in files:\n",
    "    df = pq.read_table(file).to_pandas()\n",
    "\n",
    "    # Iterate over each language\n",
    "    for lang in languages[:]:\n",
    "        lang_suffix = '.js'\n",
    "\n",
    "        # Filter rows where language column matches the current language and additional conditions\n",
    "        lang_df = df[(df['language'] == lang) & \n",
    "                     (df['mods'].apply(len) == 1) & \n",
    "                     (df['message'].apply(lambda x: len(x.split())) <= 30) & \n",
    "                     (df['mods'].apply(lambda x: x[0]['change_type']) == 'MODIFY') &\n",
    "                     (df['mods'].apply(lambda x: len(f\"diff --git a/{x[0]['old_path']} b/{x[0]['new_path']} {x[0]['diff']}\") <= 5000))] \n",
    "                    #  (df['mods'].apply(lambda x: ( (x[0]['old_path'].count(lang_suffix) if x[0]['old_path'] else 0) == 1 and (x[0]['new_path'].count(lang_suffix) if x[0]['new_path'] else 0) == 1 and (x[0]['old_path'].count('.json') if x[0]['old_path'] else 0) == 0 and (x[0]['new_path'].count('.json') if x[0]['new_path'] else 0) == 0 )))]\n",
    "\n",
    "        # Iterate over each row in the filtered DataFrame\n",
    "        for index, row in lang_df.iterrows():\n",
    "            msg = row['message']\n",
    "            if check_angular_convention(msg, has_space=True) or check_angular_convention(msg, has_space=False):\n",
    "                diff = row['mods'][0]\n",
    "                old_path = 'a/' + diff['old_path']\n",
    "                new_path = 'b/' + diff['new_path']\n",
    "                diff_content = diff['diff']  # assume diff_content is an empty string\n",
    "                item = {\n",
    "                    'msg': row['message'],\n",
    "                    'diff': f\"diff --git {old_path} {new_path} {diff_content}\",\n",
    "                    'date': row['date'],\n",
    "                    'repo': row['repo']\n",
    "                }\n",
    "\n",
    "                # Find the type in the message\n",
    "                for atype in angular_types:\n",
    "                    if msg.startswith(atype):\n",
    "                        if len(dfs[lang][atype]) < 10000:\n",
    "                            dfs[lang][atype].append(item)\n",
    "                            bars[lang].update(1)\n",
    "                        break\n",
    "\n",
    "            # Check if all types have reached 1000 rows\n",
    "            if all(len(dfs[lang][atype]) >= 10000 for atype in angular_types):\n",
    "                print(f\"Reached 10000 rows for all types in {lang}\")\n",
    "                languages.remove(lang)  # Remove language from list to avoid further processing\n",
    "                break\n",
    "\n",
    "    # Break out of the loop if all languages have reached the required number of rows\n",
    "    if not languages:\n",
    "        break"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "JavaScript:   0%|          | 0/100000 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8a6e87d06f6d4b63a5317a996fa2b0e0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-02T10:39:03.020041Z",
     "start_time": "2024-07-02T10:39:02.215506Z"
    }
   },
   "cell_type": "code",
   "source": [
    "db_data = []\n",
    "\n",
    "for lang, types in dfs.items():\n",
    "    for atype, items in types.items():\n",
    "        if items:  # Ensure there are items to split\n",
    "            for item in items:\n",
    "                item['type'] = atype\n",
    "            db_data.extend(items)\n",
    "\n",
    "import json\n",
    "output_dir = '../data/angular_filtered/subsets'\n",
    "with open(os.path.join(output_dir, f'db_data.json'), 'w') as db_file:\n",
    "    json.dump(db_data, db_file, indent=4)"
   ],
   "id": "f0f9f76a21897770",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-02T10:39:23.544074Z",
     "start_time": "2024-07-02T10:39:22.490514Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "# Split the data and save to files\n",
    "output_dir = '../data/angular_filtered/subsets'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "for lang, types in dfs.items():\n",
    "    for atype, items in types.items():\n",
    "        if items:  # Ensure there are items to split\n",
    "            with open(os.path.join(output_dir, f'type_db/{lang}_{atype}_db.json'), 'w') as db_file:\n",
    "                json.dump(items, db_file, indent=4)\n",
    "\n",
    "print(\"Data splitting and saving completed.\")"
   ],
   "id": "ad06c42fe7a515e9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data splitting and saving completed.\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-02T10:48:37.354490Z",
     "start_time": "2024-07-02T10:48:37.341497Z"
    }
   },
   "cell_type": "code",
   "source": "len(db_data)",
   "id": "e4bdde6bb5af5b91",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53855"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-02T10:37:12.966999Z",
     "start_time": "2024-07-02T10:37:12.949378Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initialize a dictionary to hold counts for each type\n",
    "type_counts = {lang: {atype: 0 for atype in angular_types} for lang in languages}\n",
    "\n",
    "# Iterate over the collected data to count occurrences of each type\n",
    "for lang, types in dfs.items():\n",
    "    for atype, items in types.items():\n",
    "        type_counts[lang][atype] = len(items)\n",
    "\n",
    "# Print the counts\n",
    "for lang, counts in type_counts.items():\n",
    "    print(f\"Language: {lang}\")\n",
    "    for atype, count in counts.items():\n",
    "        print(f\"  Type: {atype}, Count: {count}\")"
   ],
   "id": "982f4caed49cdc78",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Language: JavaScript\n",
      "  Type: build, Count: 1076\n",
      "  Type: ci, Count: 1287\n",
      "  Type: docs, Count: 9672\n",
      "  Type: feat, Count: 10000\n",
      "  Type: fix, Count: 10000\n",
      "  Type: perf, Count: 472\n",
      "  Type: refactor, Count: 6574\n",
      "  Type: style, Count: 883\n",
      "  Type: test, Count: 3891\n",
      "  Type: chore, Count: 10000\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "# import pandas as pd\n",
    "# import json\n",
    "# # Split the data and save to files\n",
    "# output_dir = '../data/angular_filtered/subsets'\n",
    "# os.makedirs(output_dir, exist_ok=True)\n",
    "# \n",
    "# test_data = []\n",
    "# db_data = []\n",
    "# \n",
    "# for lang, types in dfs.items():\n",
    "#     for atype, items in types.items():\n",
    "#         if items:  # Ensure there are items to split\n",
    "#             # Split the data into 1:9 ratio for test and db\n",
    "#             for item in items:\n",
    "#                 item['type'] = atype\n",
    "#             db_items, test_items = train_test_split(items, test_size=0.1, random_state=42)\n",
    "#             test_data.extend(test_items)\n",
    "#             db_data.extend(db_items)\n",
    "#             # Save to files\n",
    "#             # Save to JSON files\n",
    "#             with open(os.path.join(output_dir, f'type_test/{lang}_{atype}_test.json'), 'w') as test_file:\n",
    "#                 json.dump(test_items, test_file, indent=4)\n",
    "#             \n",
    "#             with open(os.path.join(output_dir, f'type_db/{lang}_{atype}_db.json'), 'w') as db_file:\n",
    "#                 json.dump(db_items, db_file, indent=4)\n",
    "# \n",
    "# print(\"Data splitting and saving completed.\")\n",
    "# output_dir = '../data/angular_filtered/subsets'\n",
    "# with open(os.path.join(output_dir, f'db_data.json'), 'w') as db_file:\n",
    "#     json.dump(db_data, db_file, indent=4)\n",
    "#     \n",
    "# with open(os.path.join(output_dir, f'test_data.json'), 'w') as db_file:\n",
    "#     json.dump(test_data, db_file, indent=4)"
   ],
   "id": "7bd5e4cd3c9e837c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## to get final test data(about 2000)",
   "id": "c9b8679106a0ccc9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-02T19:42:43.110720Z",
     "start_time": "2024-07-02T19:42:42.173893Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 读取JSON文件\n",
    "with open('../data/angular_filtered/subsets/test_data.json', 'r', encoding='utf-8') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# 按 type 字段构建字典\n",
    "type_dict = {}\n",
    "for item in data:\n",
    "    item_type = item['type']\n",
    "    if item_type not in type_dict:\n",
    "        type_dict[item_type] = []\n",
    "    type_dict[item_type].append(item)\n",
    "\n",
    "# 按比例切分数据\n",
    "# train_data = []\n",
    "test_data = []\n",
    "\n",
    "for item_type, items in type_dict.items():\n",
    "    train, test = train_test_split(items, test_size=0.25, random_state=42)\n",
    "    # train_data.extend(train)\n",
    "    test_data.extend(test)\n",
    "\n",
    "# # 将训练集和测试集分别保存为JSON文件\n",
    "# with open('train_data.json', 'w', encoding='utf-8') as file:\n",
    "#     json.dump(train_data, file, ensure_ascii=False, indent=4)\n",
    "\n",
    "with open('../data/angular_filtered/subsets/dev_test.json', 'w', encoding='utf-8') as file:\n",
    "    json.dump(test_data, file, ensure_ascii=False, indent=4)"
   ],
   "id": "290f3104c2744e3",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Test_data",
   "id": "5142c34f3a95525a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-02T10:43:08.562535Z",
     "start_time": "2024-07-02T10:42:56.916883Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pyarrow.parquet as pq\n",
    "import glob\n",
    "import os\n",
    "from tqdm.auto import tqdm\n",
    "import re\n",
    "\n",
    "def check_angular_convention(msg, has_space=True, strict=True):\n",
    "    types = '((build)|(ci)|(docs)|(feat)|(fix)|(perf)|(refactor)|(style)|(test)|(chore))'\n",
    "    if has_space:\n",
    "        pattern = f'{types}\\\\s(\\\\((\\\\s|\\\\S)+\\\\)\\\\s)?:\\\\s(\\\\s|\\\\S)+'\n",
    "    else:\n",
    "        pattern = f'{types}(\\\\((\\\\s|\\\\S)+\\\\))?:\\\\s\\\\S+(\\\\s|\\\\S)+'\n",
    "    return re.match(pattern, msg) is not None\n",
    "\n",
    "# Define the types for the angular convention\n",
    "angular_types = ['build', 'ci', 'docs', 'feat', 'fix', 'perf', 'refactor', 'style', 'test', 'chore']\n",
    "\n",
    "# Define the counts from your data\n",
    "counts = {\n",
    "    'build': 1076,\n",
    "    'ci': 1287,\n",
    "    'docs': 9672,\n",
    "    'feat': 10000,\n",
    "    'fix': 10000,\n",
    "    'perf': 472,\n",
    "    'refactor': 6574,\n",
    "    'style': 883,\n",
    "    'test': 3891,\n",
    "    'chore': 10000\n",
    "}\n",
    "\n",
    "# Calculate the total count\n",
    "total_count = sum(counts.values())\n",
    "\n",
    "# Define the total number of samples you want to collect\n",
    "total_samples = 2000\n",
    "\n",
    "# Calculate the target count for each type based on the given counts and total_samples\n",
    "target_counts = {atype: int((count / total_count) * total_samples) for atype, count in counts.items()}\n",
    "\n",
    "# Create empty dictionaries for each language and type\n",
    "languages = ['JavaScript']\n",
    "dfs = {lang: {atype: [] for atype in angular_types} for lang in languages}\n",
    "counters = {lang: {atype: 0 for atype in angular_types} for lang in languages}\n",
    "\n",
    "# Create a tqdm progress bar for each language\n",
    "bars = {lang: tqdm(total=total_samples, desc=lang) for lang in languages}\n",
    "\n",
    "folder_path = '../rag/datasets--JetBrains-Research--commit-chronicle/snapshots/5fd076e67b812a9f3d1999e5e40f71715f84bb51/data'  # 文件夹的路径\n",
    "\n",
    "files = glob.glob(os.path.join(folder_path, 'test*')) \n",
    "\n",
    "for file in files:\n",
    "    df = pq.read_table(file).to_pandas()\n",
    "\n",
    "    # Iterate over each language\n",
    "    for lang in languages[:]:\n",
    "        lang_suffix = '.js'\n",
    "\n",
    "        # Filter rows where language column matches the current language and additional conditions\n",
    "        lang_df = df[(df['language'] == lang) & \n",
    "                     (df['mods'].apply(len) == 1) & \n",
    "                    (df['message'].apply(lambda x: len(x.split())) <= 30) & \n",
    "                     (df['mods'].apply(lambda x: x[0]['change_type']) == 'MODIFY') &\n",
    "                     (df['mods'].apply(lambda x: len(f\"diff --git a/{x[0]['old_path']} b/{x[0]['new_path']} {x[0]['diff']}\") <= 5000))]\n",
    "\n",
    "        # Iterate over each row in the filtered DataFrame\n",
    "        for index, row in lang_df.iterrows():\n",
    "            msg = row['message']\n",
    "            if check_angular_convention(msg, has_space=True) or check_angular_convention(msg, has_space=False):\n",
    "                diff = row['mods'][0]\n",
    "                old_path = 'a/' + diff['old_path']\n",
    "                new_path = 'b/' + diff['new_path']\n",
    "                diff_content = diff['diff']\n",
    "                item = {\n",
    "                    'msg': row['message'],\n",
    "                    'diff': f\"diff --git {old_path} {new_path} {diff_content}\",\n",
    "                    'date': row['date'],\n",
    "                    'repo': row['repo']\n",
    "                }\n",
    "\n",
    "                # Find the type in the message\n",
    "                for atype in angular_types:\n",
    "                    if msg.startswith(atype) and counters[lang][atype] < target_counts[atype]:\n",
    "                        dfs[lang][atype].append(item)\n",
    "                        counters[lang][atype] += 1\n",
    "                        bars[lang].update(1)\n",
    "                        break\n",
    "\n",
    "            # Check if all types have reached their target counts\n",
    "            if all(counters[lang][atype] >= target_counts[atype] for atype in angular_types):\n",
    "                print(f\"Reached target counts for all types in {lang}\")\n",
    "                languages.remove(lang)  # Remove language from list to avoid further processing\n",
    "                break\n",
    "\n",
    "    # Break out of the loop if all languages have reached the required number of rows\n",
    "    if not languages:\n",
    "        break"
   ],
   "id": "b28145576d33acaf",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "JavaScript:   0%|          | 0/2000 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d6e8424e321e4f21ad0d50fac7efc5f6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reached target counts for all types in JavaScript\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-02T10:46:11.088660Z",
     "start_time": "2024-07-02T10:46:11.083659Z"
    }
   },
   "cell_type": "code",
   "source": "target_counts",
   "id": "fccbe62a6b9a7875",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'build': 39,\n",
       " 'ci': 47,\n",
       " 'docs': 359,\n",
       " 'feat': 371,\n",
       " 'fix': 371,\n",
       " 'perf': 17,\n",
       " 'refactor': 244,\n",
       " 'style': 32,\n",
       " 'test': 144,\n",
       " 'chore': 371}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-02T10:46:45.549695Z",
     "start_time": "2024-07-02T10:46:45.537697Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Print the number of items collected for each type\n",
    "for lang in dfs:\n",
    "    for atype in dfs[lang]:\n",
    "        print(f\"Type: {atype}, Count: {len(dfs[lang][atype])}\")"
   ],
   "id": "f702a81ca2d0c597",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: build, Count: 39\n",
      "Type: ci, Count: 47\n",
      "Type: docs, Count: 359\n",
      "Type: feat, Count: 371\n",
      "Type: fix, Count: 371\n",
      "Type: perf, Count: 17\n",
      "Type: refactor, Count: 244\n",
      "Type: style, Count: 32\n",
      "Type: test, Count: 144\n",
      "Type: chore, Count: 371\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-02T10:50:58.719808Z",
     "start_time": "2024-07-02T10:50:58.674297Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test_data = []\n",
    "\n",
    "for lang, types in dfs.items():\n",
    "    for atype, items in types.items():\n",
    "        if items:  # Ensure there are items to split\n",
    "            for item in items:\n",
    "                item['type'] = atype\n",
    "            test_data.extend(items)\n",
    "\n",
    "import json\n",
    "output_dir = '../data/angular_filtered/subsets'\n",
    "with open(os.path.join(output_dir, f'test_data.json'), 'w') as db_file:\n",
    "    json.dump(test_data, db_file, indent=4)"
   ],
   "id": "1463bd988b97e26",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Model generation",
   "id": "2c16235238da2ce5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## RACE",
   "id": "e7ad943801cf9184"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-02T14:27:00.522880Z",
     "start_time": "2024-07-02T14:26:54.927617Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "from tqdm.auto import tqdm\n",
    "with open('../data/angular_filtered/subsets/test_data.json') as f:\n",
    "    prompt_data = json.load(f)\n",
    "    \n",
    "import os\n",
    "os.environ['HF_HOME'] = '../models/'\n",
    "\n",
    "from transformers import pipeline\n",
    "pipe = pipeline(\"text2text-generation\", model=\"JetBrains-Research/cmg-race-without-history\", device=0)"
   ],
   "id": "e4828a38b7e52fd1",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-02T14:32:07.160713Z",
     "start_time": "2024-07-02T14:27:11.918776Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "diffs = []\n",
    "generated_commit_messages = []\n",
    "\n",
    "for commit in prompt_data:\n",
    "    diff = commit['diff']\n",
    "    diffs.append(diff)\n",
    "\n",
    "for diff in tqdm(diffs, total=len(diffs), desc='Generating commit messages'):\n",
    "    prompt = f\"\"\"\n",
    "    The following is a diff which describes the code changes in a commit, Your task is to write a short commit message accordingly.\n",
    "    {diff}\n",
    "    According to the diff, the commit message should be:\n",
    "    \"\"\"\n",
    "    generated_commit_messages.append(pipe(diff)[0]['generated_text'])"
   ],
   "id": "f6267aa94decf7e3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Generating commit messages:   0%|          | 0/1995 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b4f6571134134484949e4f85f3408d14"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tyfann\\anaconda3\\envs\\llm4commit\\lib\\site-packages\\transformers\\generation\\utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1485 > 512). Running this sequence through the model will result in indexing errors\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\tyfann\\anaconda3\\envs\\llm4commit\\lib\\logging\\__init__.py\", line 1100, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"C:\\Users\\tyfann\\anaconda3\\envs\\llm4commit\\lib\\logging\\__init__.py\", line 943, in format\n",
      "    return fmt.format(record)\n",
      "  File \"C:\\Users\\tyfann\\anaconda3\\envs\\llm4commit\\lib\\logging\\__init__.py\", line 678, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"C:\\Users\\tyfann\\anaconda3\\envs\\llm4commit\\lib\\logging\\__init__.py\", line 368, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"C:\\Users\\tyfann\\anaconda3\\envs\\llm4commit\\lib\\runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"C:\\Users\\tyfann\\anaconda3\\envs\\llm4commit\\lib\\runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"C:\\Users\\tyfann\\anaconda3\\envs\\llm4commit\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\Users\\tyfann\\anaconda3\\envs\\llm4commit\\lib\\site-packages\\traitlets\\config\\application.py\", line 992, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\Users\\tyfann\\anaconda3\\envs\\llm4commit\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 701, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\Users\\tyfann\\anaconda3\\envs\\llm4commit\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\tyfann\\anaconda3\\envs\\llm4commit\\lib\\asyncio\\windows_events.py\", line 321, in run_forever\n",
      "    super().run_forever()\n",
      "  File \"C:\\Users\\tyfann\\anaconda3\\envs\\llm4commit\\lib\\asyncio\\base_events.py\", line 603, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\tyfann\\anaconda3\\envs\\llm4commit\\lib\\asyncio\\base_events.py\", line 1909, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\tyfann\\anaconda3\\envs\\llm4commit\\lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\tyfann\\anaconda3\\envs\\llm4commit\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"C:\\Users\\tyfann\\anaconda3\\envs\\llm4commit\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 523, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"C:\\Users\\tyfann\\anaconda3\\envs\\llm4commit\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 429, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\Users\\tyfann\\anaconda3\\envs\\llm4commit\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 767, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\Users\\tyfann\\anaconda3\\envs\\llm4commit\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 429, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"C:\\Users\\tyfann\\anaconda3\\envs\\llm4commit\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\Users\\tyfann\\anaconda3\\envs\\llm4commit\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3051, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\Users\\tyfann\\anaconda3\\envs\\llm4commit\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3106, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"C:\\Users\\tyfann\\anaconda3\\envs\\llm4commit\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\Users\\tyfann\\anaconda3\\envs\\llm4commit\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3311, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\Users\\tyfann\\anaconda3\\envs\\llm4commit\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3493, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"C:\\Users\\tyfann\\anaconda3\\envs\\llm4commit\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3553, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\tyfann\\AppData\\Local\\Temp\\ipykernel_3376\\3104537205.py\", line 14, in <module>\n",
      "    generated_commit_messages.append(pipe(diff)[0]['generated_text'])\n",
      "  File \"C:\\Users\\tyfann\\anaconda3\\envs\\llm4commit\\lib\\site-packages\\transformers\\pipelines\\text2text_generation.py\", line 167, in __call__\n",
      "    result = super().__call__(*args, **kwargs)\n",
      "  File \"C:\\Users\\tyfann\\anaconda3\\envs\\llm4commit\\lib\\site-packages\\transformers\\pipelines\\base.py\", line 1167, in __call__\n",
      "    logger.warning_once(\n",
      "  File \"C:\\Users\\tyfann\\anaconda3\\envs\\llm4commit\\lib\\site-packages\\transformers\\utils\\logging.py\", line 329, in warning_once\n",
      "    self.warning(*args, **kwargs)\n",
      "Message: 'You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset'\n",
      "Arguments: (<class 'UserWarning'>,)\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-02T14:32:56.992624Z",
     "start_time": "2024-07-02T14:32:56.932793Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "for item, msg in zip(prompt_data, generated_commit_messages):\n",
    "    item['race'] = msg\n",
    "\n",
    "output_file = '../data/angular_filtered/subsets/generation/test_race_v1.json'\n",
    "with open(output_file, 'w', encoding='UTF-8') as f:\n",
    "    json.dump(prompt_data, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "# save msg to a file\n",
    "with open(\"../data/angular_filtered/subsets/generation/test_race_v1.txt\", 'w', encoding='UTF-8') as file:\n",
    "    for item in prompt_data:\n",
    "        file.write(item['race'].replace('\\n', '\\\\n').replace('\\r', '\\\\r') + '\\n')"
   ],
   "id": "6b0a35f53ee5f613",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## ChatGPT",
   "id": "8d22ba49c53055c0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-02T13:50:10.605833Z",
     "start_time": "2024-07-02T13:25:16.981079Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain import hub\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "prompt = hub.pull(\"tyfann/llm4commit-zeroshot\")\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=\"\",\n",
    "    base_url=\"https://api.chatanywhere.cn/v1\"\n",
    ")\n",
    "\n",
    "def gpt_35_api(messages: list):\n",
    "\n",
    "    completion = client.chat.completions.create(model=\"gpt-3.5-turbo-0125\", messages=messages, temperature=0)\n",
    "    return completion.choices[0].message.content\n",
    "\n",
    "with open('../data/angular_filtered/subsets/test_data.json', 'r', encoding='UTF-8') as f:\n",
    "    org_data = json.load(f)\n",
    "\n",
    "gpt_msg = []\n",
    "for index, data in tqdm(enumerate(org_data), total=len(org_data), desc=\"Processing documents\"):\n",
    "    # merged_diff = '\\n'.join(diff['diff'] for diff in data['diff'])\n",
    "    messages = prompt.invoke(\n",
    "        {\"DIFF\": data['diff']}\n",
    "    ).to_messages()\n",
    "    example_prompt = [{'role': 'user','content': messages[0].content},]\n",
    "    try:\n",
    "        gpt_msg.append(gpt_35_api(example_prompt))\n",
    "    except:\n",
    "        print(index)\n",
    "        gpt_msg.append(\"\")\n",
    "\n",
    "for item, msg in zip(org_data, gpt_msg):\n",
    "    item['chatgpt_zeroshot'] = msg\n",
    "import os\n",
    "# output_file = '../data/chronicle/rag_baseline/zeroshot/rag_baseline_python_chatgpt.json'\n",
    "output_file = '../data/angular_filtered/subsets/generation/test_gpt35_zeroshot.json'\n",
    "os.makedirs(os.path.dirname(output_file), exist_ok=True)\n",
    "with open(output_file, 'w', encoding='UTF-8') as f:\n",
    "    json.dump(org_data, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "output_file = '../data/angular_filtered/subsets/generation/test_gpt35_zeroshot.txt'\n",
    "with open(output_file, 'w', encoding='UTF-8') as f:\n",
    "    for item in org_data:\n",
    "        f.write(item['chatgpt_zeroshot'].replace('\\n', '\\\\n').replace('\\r', '\\\\r') + '\\n')"
   ],
   "id": "3a7aa3f1bc72788",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing documents: 100%|██████████| 1995/1995 [24:50<00:00,  1.34it/s]\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-02T14:25:12.514265Z",
     "start_time": "2024-07-02T14:25:12.492550Z"
    }
   },
   "cell_type": "code",
   "source": [
    "output_file = '../data/angular_filtered/subsets/generation/test_ref.txt'\n",
    "with open(output_file, 'w', encoding='UTF-8') as f:\n",
    "    for item in org_data:\n",
    "        f.write(item['msg'].replace('\\n', '\\\\n').replace('\\r', '\\\\r') + '\\n')"
   ],
   "id": "b365e13113cdcf9e",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## NNGen",
   "id": "736e514480a8dafa"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-03T14:59:07.231055Z",
     "start_time": "2024-07-03T14:59:07.223545Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import re\n",
    "\n",
    "def convert_diff(diff_output):\n",
    "    # Replace diff --git a/ with mmm a/\n",
    "    diff_output = re.sub(r'diff --git a/(.*) b/(.*)', r'mmm a/\\1\\nppp b/\\1', diff_output)\n",
    "    # Replace newline characters with <nl>\n",
    "    diff_output = diff_output.replace('\\n', '<nl>')\n",
    "    # Split the output into individual words and join them back together with spaces\n",
    "    words = re.split(r'(\\W)', diff_output)\n",
    "    result = ' '.join(words)\n",
    "    # Replace multiple spaces with a single space\n",
    "    result = re.sub(r'\\s+', ' ', result)\n",
    "    result = result.replace('< nl >', '<nl>')\n",
    "    return result"
   ],
   "id": "ffb3da6a8e8ac387",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-02T19:18:56.768405Z",
     "start_time": "2024-07-02T19:18:50.321200Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "with open(f'../data/angular_filtered/subsets/db_data.json') as f:\n",
    "    db_data = json.load(f)\n",
    "\n",
    "for item in db_data:\n",
    "    item['diff'] = convert_diff(item['diff'])\n",
    "\n",
    "# save diff to .diff file\n",
    "with open('../data/angular_filtered/subsets/generation/nngen/train.diff', 'w') as f:\n",
    "    for item in db_data:\n",
    "        f.write(item['diff'] + '\\n')\n",
    "\n",
    "with open('../data/angular_filtered/subsets/generation/nngen/train.msg', 'w') as f:\n",
    "    for item in db_data:\n",
    "        escaped_string = item['msg'].replace(\"\\n\", \"\\\\n\").replace(\"\\r\", \"\\\\r\")\n",
    "        f.write(escaped_string + \"\\n\")\n",
    "\n",
    "with open(f'../data/angular_filtered/subsets/test_data.json') as f:\n",
    "    test_data = json.load(f)\n",
    "\n",
    "for item in test_data:\n",
    "    item['diff'] = convert_diff(item['diff'])\n",
    "\n",
    "# save diff to .diff file\n",
    "with open('../data/angular_filtered/subsets/generation/nngen/test.diff', 'w') as f:\n",
    "    for item in test_data:\n",
    "        f.write(item['diff'] + '\\n')"
   ],
   "id": "1fda55654c1bb0bd",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-02T19:23:42.957007Z",
     "start_time": "2024-07-02T19:23:42.904166Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "with open('../data/angular_filtered/subsets/test_data.json', 'r', encoding='UTF-8') as f:\n",
    "    org_data = json.load(f)\n",
    "\n",
    "output_file = '../data/angular_filtered/subsets/generation/test_nngen.txt'\n",
    "with open(output_file, 'r', encoding='UTF-8') as f:\n",
    "    lines = f.readlines()\n",
    "    for i in range(len(org_data)):\n",
    "        org_data[i]['nngen'] = lines[i].strip()\n",
    "\n",
    "with open('../data/angular_filtered/subsets/generation/test_nngen.json', 'w', encoding='UTF-8') as f:\n",
    "    json.dump(org_data, f, indent=4)"
   ],
   "id": "128319e01ae63c20",
   "outputs": [],
   "execution_count": 3
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
