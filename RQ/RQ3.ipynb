{
 "cells": [
  {
   "cell_type": "code",
   "id": "285c0808879219e5",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-11T09:30:12.484922Z",
     "start_time": "2024-07-11T09:30:12.401592Z"
    }
   },
   "source": [
    "import json\n",
    "import random\n",
    "\n",
    "random.seed(42)\n",
    "# 读取原始JSON文件\n",
    "data = []\n",
    "\n",
    "with open('../data/angular_filtered/subsets/generation/test_race.json', 'r', encoding='utf-8') as f:\n",
    "    race_data = json.load(f)\n",
    "# with open('../data/angular_filtered/subsets/generation/test_gpt35_zeroshot.json', 'r', encoding='utf-8') as f:\n",
    "#     zeroshot_data = json.load(f)\n",
    "# with open('../data/angular_filtered/subsets/generation/test_gpt35_rag.json', 'r', encoding='utf-8') as f:\n",
    "#     rag_data = json.load(f)\n",
    "with open('../data/angular_filtered/subsets/generation/test_gpt35_model_classified_rag.json', 'r', encoding='utf-8') as f:\n",
    "    model_rag_data = json.load(f)\n",
    "# with open('../data/angular_filtered/subsets/generation/test_nngen.json', 'r', encoding='utf-8') as f:\n",
    "#     nngen_data = json.load(f)\n",
    "    "
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-11T09:30:17.637065Z",
     "start_time": "2024-07-11T09:30:17.594739Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for index in range(len(model_rag_data)):\n",
    "    item = {\n",
    "        'diff': race_data[index]['diff'],\n",
    "        # 'human': race_data[index]['msg'],\n",
    "        'race': race_data[index]['race'],\n",
    "        # 'zeroshot': zeroshot_data[index]['chatgpt_zeroshot'],\n",
    "        # 'rag': rag_data[index]['chatgpt_rag'],\n",
    "        'classified_rag': model_rag_data[index]['chatgpt_rag'],\n",
    "        # 'nngen': nngen_data[index]['nngen'],\n",
    "        'type': race_data[index]['type']\n",
    "    }\n",
    "    data.append(item)\n",
    "\n",
    "with open('../data/angular_filtered/subsets/generation/test_all.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(data, f, ensure_ascii=False, indent=4)"
   ],
   "id": "3eb920ce745a60f3",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-11T09:30:39.296402Z",
     "start_time": "2024-07-11T09:30:39.282385Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# 确保JSON数据是一个列表\n",
    "if not isinstance(data, list):\n",
    "    raise ValueError(\"JSON数据不是一个列表\")\n",
    "\n",
    "# 随机选择100个项目\n",
    "sample_size = 50\n",
    "if len(data) < sample_size:\n",
    "    raise ValueError(\"数据量少于50个项目\")\n",
    "\n",
    "initial_sample = random.sample(data, sample_size)\n",
    "\n",
    "# 从剩余的项目中再随机选择100个项目\n",
    "remaining_data = [item for item in data if item not in initial_sample]\n",
    "# second_sample = random.sample(remaining_data, sample_size)\n",
    "\n",
    "# 将选定的项目写入一个新的JSON文件\n",
    "with open('../data/angular_filtered/subsets/human_eval/no_human_ref_test.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(initial_sample, f, ensure_ascii=False, indent=4)\n",
    "    \n",
    "# 将选定的项目写入一个新的JSON文件\n",
    "# with open('../data/angular_filtered/subsets/human_eval/human_ref_test.json', 'w', encoding='utf-8') as f:\n",
    "#     json.dump(second_sample, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(\"随机提取的50个项目已保存到output.json文件中。\")\n"
   ],
   "id": "initial_id",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "随机提取的50个项目已保存到output.json文件中。\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-11T09:30:50.533607Z",
     "start_time": "2024-07-11T09:30:50.520608Z"
    }
   },
   "cell_type": "code",
   "source": [
    "## 统计随机提取的50个项目的类型分布\n",
    "types = {}\n",
    "for item in initial_sample:\n",
    "    if item['type'] not in types:\n",
    "        types[item['type']] = 0\n",
    "    types[item['type']] += 1\n",
    "\n",
    "print(\"类型分布：\")\n",
    "for key, value in types.items():\n",
    "    print(f\"{key}: {value}\")"
   ],
   "id": "600cf96cae0561e8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "类型分布：\n",
      "refactor: 8\n",
      "docs: 10\n",
      "ci: 4\n",
      "test: 5\n",
      "feat: 9\n",
      "chore: 5\n",
      "fix: 7\n",
      "style: 1\n",
      "build: 1\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-11T13:22:20.985718Z",
     "start_time": "2024-07-11T13:22:20.939822Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "import random\n",
    "\n",
    "# 读取原始数据文件\n",
    "with open('../data/angular_filtered/subsets/human_eval/no_human_ref_test.json', 'r', encoding='UTF-8') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "mapping = {}\n",
    "\n",
    "# 遍历每个对象并替换字段名称\n",
    "for i, item in enumerate(data):\n",
    "    item_id = f\"Object-{i+1}\"\n",
    "    mapping[item_id] = {}\n",
    "    \n",
    "    keys = list(item.keys())\n",
    "    keys_to_rename = [key for key in keys if key not in ['diff', 'type']]\n",
    "    \n",
    "    random.shuffle(keys_to_rename)\n",
    "    \n",
    "    # 创建一个新的字典来保存重命名后的字段\n",
    "    new_item = {\"diff\": item[\"diff\"]}\n",
    "    \n",
    "    for idx, key in enumerate(keys_to_rename, 1):\n",
    "        new_key = str(idx)\n",
    "        mapping[item_id][new_key] = key\n",
    "        new_item[new_key] = item[key]\n",
    "    \n",
    "    # 替换原有的item\n",
    "    data[i] = new_item\n",
    "\n",
    "# 将修改后的数据写入新的JSON文件\n",
    "with open('../data/angular_filtered/subsets/human_eval/no_human_ref_test_shuffled.json', 'w', encoding='UTF-8') as file:\n",
    "    json.dump(data, file, ensure_ascii=False, indent=4)\n",
    "\n",
    "# 将映射关系写入映射文件\n",
    "with open('../data/angular_filtered/subsets/human_eval/no_human_ref_test_mapping.json', 'w', encoding='UTF-8') as file:\n",
    "    json.dump(mapping, file, ensure_ascii=False, indent=4)\n",
    "\n"
   ],
   "id": "6578613ccf62ac13",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-08T09:02:16.170990Z",
     "start_time": "2024-07-08T09:02:16.158435Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "\n",
    "# 读取output.json文件\n",
    "with open('../data/angular_filtered/subsets/human_eval/no_human_ref_test_shuffled.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# 打开markdown文件用于写入\n",
    "with open('../data/angular_filtered/subsets/human_eval/no_human_ref_test_shuffled.md', 'w') as md_file:\n",
    "    for i, item in enumerate(data, 1):\n",
    "        md_file.write(f\"## Item {i}\\n\\n\")\n",
    "        \n",
    "        if 'diff' in item:\n",
    "            md_file.write(\"```diff\\n\")\n",
    "            md_file.write(f\"{item['diff']}\\n\")\n",
    "            md_file.write(\"```\\n\\n\")\n",
    "        \n",
    "        for key, value in item.items():\n",
    "            if key != 'diff':\n",
    "                md_file.write(f\"{key}: {value}\\n\\n\")\n",
    "        \n",
    "        md_file.write(\"best description number: \\n\\n\")\n",
    "        md_file.write(\"---\\n\\n\")\n",
    "\n",
    "print(\"处理完成，生成了output.md文件。\")\n"
   ],
   "id": "dc32950341c217eb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "处理完成，生成了output.md文件。\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-12T09:23:41.244299Z",
     "start_time": "2024-07-12T09:23:41.225126Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "\n",
    "# Read the JSON file\n",
    "with open('../data/angular_filtered/subsets/human_eval/no_human_ref_test_shuffled.json', 'r', encoding='UTF-8') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Define evaluation criteria\n",
    "evaluation_criteria = \"\"\"\n",
    "Instruction: Your task is to evaluate the commit messages based on the commit code diffs, so first look at the code diffs and determine what the code changes are, and you will be given 2 commit messages generated by different models for each commit. **You need to score each commit message from the following criteria from the perspectives of Expressiveness, and Informativeness, with a minimum score of 0 and a maximum score of 4. Finally, compare the two commit messages given for each commit and select the Best description number (1 or 2).**\n",
    "\n",
    "Evaluation Criteria:\n",
    "| Expressiveness | Description                              |\n",
    "| -------------- | ---------------------------------------- |\n",
    "| 0              | Cannot read and understand.              |\n",
    "| 1              | The content is difficult to read and understand.          |\n",
    "| 2              | The content is somewhat readable and understandable. |\n",
    "| 3              | The content is mostly readable and understandable.   |\n",
    "| 4              | The content is very easy to read and understand.          |\n",
    "\n",
    "| Informativeness | Description                                                  |\n",
    "| --------------- | ------------------------------------------------------------ |\n",
    "| 0               | No information about the code change is provided.             |\n",
    "| 1               | Some crucial information is missing, making it hard to understand the code changes. |\n",
    "| 2               | Some information is missing, but the missing parts are not essential for understanding the code changes. |\n",
    "| 3               | There is some missing information, but none of it is necessary to understand the code changes. |\n",
    "| 4               | All necessary information about the code change is included.                                 |\n",
    "\"\"\"\n",
    "with open('../data/angular_filtered/subsets/human_eval/no_human_ref_test_shuffled.md', 'w', encoding='UTF-8') as md_file:\n",
    "    # Print evaluation criteria once at the beginning\n",
    "    md_file.write(evaluation_criteria)\n",
    "    \n",
    "    # Parse each item and format the output into markdown\n",
    "    for i, item in enumerate(data, 1):\n",
    "        md_file.write(f\"## Item {i}\\n\\n\")\n",
    "        diff = item['diff']\n",
    "        md_file.write(\"````diff\\n\")\n",
    "        md_file.write(diff)\n",
    "        md_file.write(\"````\\n\\n\")\n",
    "    \n",
    "        for key, value in item.items():\n",
    "            if key != 'diff':\n",
    "                value = value.replace('\\n', ', ')\n",
    "                value = value.replace('\\r', ', ')\n",
    "                md_file.write(f\"{key}: '{value}'\\n\\n\")\n",
    "                # md_file.write(\"Conciseness: \\n\")\n",
    "                md_file.write(\"Expressiveness: \\n\")\n",
    "                md_file.write(\"Informativeness: \\n\\n\")\n",
    "        \n",
    "        md_file.write(\"**Best description number:** \\n\\n\")\n",
    "        md_file.write(\"---\\n\\n\")\n"
   ],
   "id": "db0c29a3e87c49c6",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-12T09:23:44.442477Z",
     "start_time": "2024-07-12T09:23:44.429439Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def generate_file(filename, num_items=50):\n",
    "    with open(filename, 'w') as file:\n",
    "        for i in range(1, num_items + 1):\n",
    "            file.write(f\"item{i}-message1:\\n\")\n",
    "            file.write(\"Expressiveness:\\n\")\n",
    "            file.write(\"Informativeness:\\n\\n\")\n",
    "            file.write(f\"item{i}-message2:\\n\")\n",
    "            file.write(\"Expressiveness:\\n\")\n",
    "            file.write(\"Informativeness:\\n\\n\")\n",
    "            file.write(\"Best description number:\\n\\n\")\n",
    "            file.write(\"---\\n\\n\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    generate_file(\"../data/angular_filtered/subsets/human_eval/no_human_ref_test.txt\")"
   ],
   "id": "4051f6c9af119fc4",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Analyze the result from human evaluation",
   "id": "efe999d58439eb20"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-17T09:04:33.106004Z",
     "start_time": "2024-07-17T09:04:33.074704Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import re\n",
    "import json\n",
    "# 正则表达式匹配模式\n",
    "pattern1 = r'Best description number:\\s*(\\d+)'\n",
    "pattern2 = r'Best description number:\\s*item(\\d+)-message(\\d+)'\n",
    "\n",
    "for file_name in range(1, 6):\n",
    "    # 读取文件内容\n",
    "    file_path = f'../data/angular_filtered/subsets/human_eval/people/no_human_ref_test_{file_name}.txt'\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        content = file.read()\n",
    "    \n",
    "    json_data = []\n",
    "    # 按照item分割文件内容\n",
    "    items = content.strip().split('---\\n')\n",
    "    best_description_counts = {1: 0, 2: 0}\n",
    "    for index, item in enumerate(items):\n",
    "        item = [text for text in item.strip().split('\\n') if text]\n",
    "        ex_1_match = re.match(\"Expressiveness:\\s*(\\d+)\", item[1])\n",
    "        if not ex_1_match:\n",
    "            raise ValueError(f\"无法匹配表达性: {item[1]}\")\n",
    "        ex_1 = ex_1_match.group(1)\n",
    "        in_1_match = re.match(\"Informativeness:\\s*(\\d+)\", item[2])\n",
    "        if not in_1_match:\n",
    "            raise ValueError(f\"无法匹配信息性: {item[2]}\")\n",
    "        in_1 = in_1_match.group(1)\n",
    "        ex_2_match = re.match(\"Expressiveness:\\s*(\\d+)\", item[4])\n",
    "        if not ex_2_match:\n",
    "            raise ValueError(f\"无法匹配表达性: {item[4]}\")\n",
    "        ex_2 = ex_2_match.group(1)\n",
    "        in_2_match = re.match(\"Informativeness:\\s*(\\d+)\", item[5])\n",
    "        if not in_2_match:\n",
    "            raise ValueError(f\"无法匹配信息性: {item[5]}\")\n",
    "        in_2 = in_2_match.group(1)\n",
    "        # use pattern1 and pattern2 to match the best description number\n",
    "        match1 = re.match(pattern1, item[6])\n",
    "        match2 = re.match(pattern2, item[6])\n",
    "        if match1:\n",
    "            best_id = int(match1.group(1))\n",
    "        elif match2:\n",
    "            best_id = int(match2.group(2))\n",
    "        else:\n",
    "            raise ValueError(f\"无法匹配最佳描述号: {item[6]}\")\n",
    "        data = {\"Item_number\": int(index+1), \"Expressiveness1\": int(ex_1), \"Informativeness1\": int(in_1), \"Expressiveness2\": int(ex_2), \"Informativeness2\": int(in_2), \"Best_description_number\": best_id}\n",
    "        json_data.append(data)\n",
    "    \n",
    "    with open(f'../data/angular_filtered/subsets/human_eval/people/no_human_ref_test_{file_name}.json', 'w', encoding='utf-8') as file:\n",
    "        json.dump(json_data, file, ensure_ascii=False, indent=4)"
   ],
   "id": "426b95b5a043abb5",
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "无法匹配表达性: Expressiveness:",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[32], line 21\u001B[0m\n\u001B[0;32m     19\u001B[0m ex_1_match \u001B[38;5;241m=\u001B[39m re\u001B[38;5;241m.\u001B[39mmatch(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mExpressiveness:\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124ms*(\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124md+)\u001B[39m\u001B[38;5;124m\"\u001B[39m, item[\u001B[38;5;241m1\u001B[39m])\n\u001B[0;32m     20\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m ex_1_match:\n\u001B[1;32m---> 21\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m无法匹配表达性: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mitem[\u001B[38;5;241m1\u001B[39m]\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     22\u001B[0m ex_1 \u001B[38;5;241m=\u001B[39m ex_1_match\u001B[38;5;241m.\u001B[39mgroup(\u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m     23\u001B[0m in_1_match \u001B[38;5;241m=\u001B[39m re\u001B[38;5;241m.\u001B[39mmatch(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mInformativeness:\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124ms*(\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124md+)\u001B[39m\u001B[38;5;124m\"\u001B[39m, item[\u001B[38;5;241m2\u001B[39m])\n",
      "\u001B[1;31mValueError\u001B[0m: 无法匹配表达性: Expressiveness:"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-17T08:48:45.971068Z",
     "start_time": "2024-07-17T08:48:45.962605Z"
    }
   },
   "cell_type": "code",
   "source": "items = content.strip().split('---\\n')",
   "id": "484787bb58ca67c0",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-17T08:49:33.911529Z",
     "start_time": "2024-07-17T08:49:33.898503Z"
    }
   },
   "cell_type": "code",
   "source": "item = [text for text in items[0].strip().split('\\n') if text]",
   "id": "2cfceb46eb2aa6d",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-17T08:49:37.297051Z",
     "start_time": "2024-07-17T08:49:37.291533Z"
    }
   },
   "cell_type": "code",
   "source": "item",
   "id": "c4d8041d5e249ca8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['item1-message1:',\n",
       " 'Expressiveness:2',\n",
       " 'Informativeness:1',\n",
       " 'item1-message2:',\n",
       " 'Expressiveness:3',\n",
       " 'Informativeness:3',\n",
       " 'Best description number:item1-message2']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "for item in items:\n",
    "    "
   ],
   "id": "951ba5cef0e64bc7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Items Data:\n",
      "item1:\n",
      "  {'Expressiveness': 3, 'Informativeness': 1}\n",
      "item2:\n",
      "item3:\n",
      "item4:\n",
      "item5:\n",
      "item6:\n",
      "item7:\n",
      "item8:\n",
      "item9:\n",
      "item10:\n",
      "item11:\n",
      "item12:\n",
      "item13:\n",
      "item14:\n",
      "item15:\n",
      "item16:\n",
      "item17:\n",
      "item18:\n",
      "item19:\n",
      "item20:\n",
      "item21:\n",
      "item22:\n",
      "item23:\n",
      "item24:\n",
      "item25:\n",
      "item26:\n",
      "item27:\n",
      "item28:\n",
      "item29:\n",
      "item30:\n",
      "item31:\n",
      "item32:\n",
      "item33:\n",
      "item34:\n",
      "item35:\n",
      "item36:\n",
      "item37:\n",
      "item38:\n",
      "item39:\n",
      "item40:\n",
      "item41:\n",
      "item42:\n",
      "item43:\n",
      "item44:\n",
      "item45:\n",
      "item46:\n",
      "item47:\n",
      "item48:\n",
      "item49:\n",
      "item50:\n",
      "\n",
      "Best Description Counts:\n",
      "  1: 22\n",
      "  2: 26\n"
     ]
    }
   ],
   "execution_count": 2,
   "source": [
    "\n",
    "for item in items:\n",
    "    if item.strip():\n",
    "        # 提取item编号\n",
    "        item_match = re.search(r'item(\\d+)', item)\n",
    "        if item_match:\n",
    "            item_number = item_match.group(1)\n",
    "            messages = re.findall(r'message\\d+:.*?\\nExpressiveness:(\\d+)\\nInformativeness: (\\d+)', item, re.DOTALL)\n",
    "            items_data[f'item{item_number}'] = []\n",
    "            for message in messages:\n",
    "                expressiveness, informativeness = message\n",
    "                items_data[f'item{item_number}'].append({\n",
    "                    'Expressiveness': int(expressiveness),\n",
    "                    'Informativeness': int(informativeness)\n",
    "                })\n",
    "            \n",
    "            # 提取Best description number\n",
    "            best_desc_match = re.search(r'Best description number:(\\d)', item)\n",
    "            if best_desc_match:\n",
    "                best_description_number = int(best_desc_match.group(1))\n",
    "                best_description_counts[best_description_number] += 1\n",
    "\n",
    "# 输出结果\n",
    "print(\"Items Data:\")\n",
    "for item, messages in items_data.items():\n",
    "    print(f\"{item}:\")\n",
    "    for message in messages:\n",
    "        print(f\"  {message}\")\n",
    "\n",
    "print(\"\\nBest Description Counts:\")\n",
    "for number, count in best_description_counts.items():\n",
    "    print(f\"  {number}: {count}\")"
   ],
   "id": "eef811d37edc8a3a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "7ad7f6d36466ca18"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
