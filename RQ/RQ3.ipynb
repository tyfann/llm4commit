{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "285c0808879219e5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-11T09:30:12.484922Z",
     "start_time": "2024-07-11T09:30:12.401592Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "\n",
    "random.seed(42)\n",
    "# 读取原始JSON文件\n",
    "data = []\n",
    "\n",
    "with open('../data/angular_filtered/subsets/generation/test_race.json', 'r', encoding='utf-8') as f:\n",
    "    race_data = json.load(f)\n",
    "# with open('../data/angular_filtered/subsets/generation/test_gpt35_zeroshot.json', 'r', encoding='utf-8') as f:\n",
    "#     zeroshot_data = json.load(f)\n",
    "# with open('../data/angular_filtered/subsets/generation/test_gpt35_rag.json', 'r', encoding='utf-8') as f:\n",
    "#     rag_data = json.load(f)\n",
    "with open('../data/angular_filtered/subsets/generation/test_gpt35_model_classified_rag.json', 'r', encoding='utf-8') as f:\n",
    "    model_rag_data = json.load(f)\n",
    "# with open('../data/angular_filtered/subsets/generation/test_nngen.json', 'r', encoding='utf-8') as f:\n",
    "#     nngen_data = json.load(f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3eb920ce745a60f3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-11T09:30:17.637065Z",
     "start_time": "2024-07-11T09:30:17.594739Z"
    }
   },
   "outputs": [],
   "source": [
    "for index in range(len(model_rag_data)):\n",
    "    item = {\n",
    "        'diff': race_data[index]['diff'],\n",
    "        # 'human': race_data[index]['msg'],\n",
    "        'race': race_data[index]['race'],\n",
    "        # 'zeroshot': zeroshot_data[index]['chatgpt_zeroshot'],\n",
    "        # 'rag': rag_data[index]['chatgpt_rag'],\n",
    "        'classified_rag': model_rag_data[index]['chatgpt_rag'],\n",
    "        # 'nngen': nngen_data[index]['nngen'],\n",
    "        'type': race_data[index]['type']\n",
    "    }\n",
    "    data.append(item)\n",
    "\n",
    "with open('../data/angular_filtered/subsets/generation/test_all.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(data, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-11T09:30:39.296402Z",
     "start_time": "2024-07-11T09:30:39.282385Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "随机提取的50个项目已保存到output.json文件中。\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 确保JSON数据是一个列表\n",
    "if not isinstance(data, list):\n",
    "    raise ValueError(\"JSON数据不是一个列表\")\n",
    "\n",
    "# 随机选择100个项目\n",
    "sample_size = 50\n",
    "if len(data) < sample_size:\n",
    "    raise ValueError(\"数据量少于50个项目\")\n",
    "\n",
    "initial_sample = random.sample(data, sample_size)\n",
    "\n",
    "# 从剩余的项目中再随机选择100个项目\n",
    "remaining_data = [item for item in data if item not in initial_sample]\n",
    "# second_sample = random.sample(remaining_data, sample_size)\n",
    "\n",
    "# 将选定的项目写入一个新的JSON文件\n",
    "with open('../data/angular_filtered/subsets/human_eval/no_human_ref_test.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(initial_sample, f, ensure_ascii=False, indent=4)\n",
    "    \n",
    "# 将选定的项目写入一个新的JSON文件\n",
    "# with open('../data/angular_filtered/subsets/human_eval/human_ref_test.json', 'w', encoding='utf-8') as f:\n",
    "#     json.dump(second_sample, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(\"随机提取的50个项目已保存到output.json文件中。\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "600cf96cae0561e8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-11T09:30:50.533607Z",
     "start_time": "2024-07-11T09:30:50.520608Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "类型分布：\n",
      "refactor: 8\n",
      "docs: 10\n",
      "ci: 4\n",
      "test: 5\n",
      "feat: 9\n",
      "chore: 5\n",
      "fix: 7\n",
      "style: 1\n",
      "build: 1\n"
     ]
    }
   ],
   "source": [
    "## 统计随机提取的50个项目的类型分布\n",
    "types = {}\n",
    "for item in initial_sample:\n",
    "    if item['type'] not in types:\n",
    "        types[item['type']] = 0\n",
    "    types[item['type']] += 1\n",
    "\n",
    "print(\"类型分布：\")\n",
    "for key, value in types.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6578613ccf62ac13",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-11T13:22:20.985718Z",
     "start_time": "2024-07-11T13:22:20.939822Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "\n",
    "# 读取原始数据文件\n",
    "with open('../data/angular_filtered/subsets/human_eval/no_human_ref_test.json', 'r', encoding='UTF-8') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "mapping = {}\n",
    "\n",
    "# 遍历每个对象并替换字段名称\n",
    "for i, item in enumerate(data):\n",
    "    item_id = f\"Object-{i+1}\"\n",
    "    mapping[item_id] = {}\n",
    "    \n",
    "    keys = list(item.keys())\n",
    "    keys_to_rename = [key for key in keys if key not in ['diff', 'type']]\n",
    "    \n",
    "    random.shuffle(keys_to_rename)\n",
    "    \n",
    "    # 创建一个新的字典来保存重命名后的字段\n",
    "    new_item = {\"diff\": item[\"diff\"]}\n",
    "    \n",
    "    for idx, key in enumerate(keys_to_rename, 1):\n",
    "        new_key = str(idx)\n",
    "        mapping[item_id][new_key] = key\n",
    "        new_item[new_key] = item[key]\n",
    "    \n",
    "    # 替换原有的item\n",
    "    data[i] = new_item\n",
    "\n",
    "# 将修改后的数据写入新的JSON文件\n",
    "with open('../data/angular_filtered/subsets/human_eval/no_human_ref_test_shuffled.json', 'w', encoding='UTF-8') as file:\n",
    "    json.dump(data, file, ensure_ascii=False, indent=4)\n",
    "\n",
    "# 将映射关系写入映射文件\n",
    "with open('../data/angular_filtered/subsets/human_eval/no_human_ref_test_mapping.json', 'w', encoding='UTF-8') as file:\n",
    "    json.dump(mapping, file, ensure_ascii=False, indent=4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc32950341c217eb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-08T09:02:16.170990Z",
     "start_time": "2024-07-08T09:02:16.158435Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "处理完成，生成了output.md文件。\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# 读取output.json文件\n",
    "with open('../data/angular_filtered/subsets/human_eval/no_human_ref_test_shuffled.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# 打开markdown文件用于写入\n",
    "with open('../data/angular_filtered/subsets/human_eval/no_human_ref_test_shuffled.md', 'w') as md_file:\n",
    "    for i, item in enumerate(data, 1):\n",
    "        md_file.write(f\"## Item {i}\\n\\n\")\n",
    "        \n",
    "        if 'diff' in item:\n",
    "            md_file.write(\"```diff\\n\")\n",
    "            md_file.write(f\"{item['diff']}\\n\")\n",
    "            md_file.write(\"```\\n\\n\")\n",
    "        \n",
    "        for key, value in item.items():\n",
    "            if key != 'diff':\n",
    "                md_file.write(f\"{key}: {value}\\n\\n\")\n",
    "        \n",
    "        md_file.write(\"best description number: \\n\\n\")\n",
    "        md_file.write(\"---\\n\\n\")\n",
    "\n",
    "print(\"处理完成，生成了output.md文件。\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db0c29a3e87c49c6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-12T09:23:41.244299Z",
     "start_time": "2024-07-12T09:23:41.225126Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Read the JSON file\n",
    "with open('../data/angular_filtered/subsets/human_eval/no_human_ref_test_shuffled.json', 'r', encoding='UTF-8') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Define evaluation criteria\n",
    "evaluation_criteria = \"\"\"\n",
    "Instruction: Your task is to evaluate the commit messages based on the commit code diffs, so first look at the code diffs and determine what the code changes are, and you will be given 2 commit messages generated by different models for each commit. **You need to score each commit message from the following criteria from the perspectives of Expressiveness, and Informativeness, with a minimum score of 0 and a maximum score of 4. Finally, compare the two commit messages given for each commit and select the Best description number (1 or 2).**\n",
    "\n",
    "Evaluation Criteria:\n",
    "| Expressiveness | Description                              |\n",
    "| -------------- | ---------------------------------------- |\n",
    "| 0              | Cannot read and understand.              |\n",
    "| 1              | The content is difficult to read and understand.          |\n",
    "| 2              | The content is somewhat readable and understandable. |\n",
    "| 3              | The content is mostly readable and understandable.   |\n",
    "| 4              | The content is very easy to read and understand.          |\n",
    "\n",
    "| Informativeness | Description                                                  |\n",
    "| --------------- | ------------------------------------------------------------ |\n",
    "| 0               | No information about the code change is provided.             |\n",
    "| 1               | Some crucial information is missing, making it hard to understand the code changes. |\n",
    "| 2               | Some information is missing, but the missing parts are not essential for understanding the code changes. |\n",
    "| 3               | There is some missing information, but none of it is necessary to understand the code changes. |\n",
    "| 4               | All necessary information about the code change is included.                                 |\n",
    "\"\"\"\n",
    "with open('../data/angular_filtered/subsets/human_eval/no_human_ref_test_shuffled.md', 'w', encoding='UTF-8') as md_file:\n",
    "    # Print evaluation criteria once at the beginning\n",
    "    md_file.write(evaluation_criteria)\n",
    "    \n",
    "    # Parse each item and format the output into markdown\n",
    "    for i, item in enumerate(data, 1):\n",
    "        md_file.write(f\"## Item {i}\\n\\n\")\n",
    "        diff = item['diff']\n",
    "        md_file.write(\"````diff\\n\")\n",
    "        md_file.write(diff)\n",
    "        md_file.write(\"````\\n\\n\")\n",
    "    \n",
    "        for key, value in item.items():\n",
    "            if key != 'diff':\n",
    "                value = value.replace('\\n', ', ')\n",
    "                value = value.replace('\\r', ', ')\n",
    "                md_file.write(f\"{key}: '{value}'\\n\\n\")\n",
    "                # md_file.write(\"Conciseness: \\n\")\n",
    "                md_file.write(\"Expressiveness: \\n\")\n",
    "                md_file.write(\"Informativeness: \\n\\n\")\n",
    "        \n",
    "        md_file.write(\"**Best description number:** \\n\\n\")\n",
    "        md_file.write(\"---\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4051f6c9af119fc4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-12T09:23:44.442477Z",
     "start_time": "2024-07-12T09:23:44.429439Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_file(filename, num_items=50):\n",
    "    with open(filename, 'w') as file:\n",
    "        for i in range(1, num_items + 1):\n",
    "            file.write(f\"item{i}-message1:\\n\")\n",
    "            file.write(\"Expressiveness:\\n\")\n",
    "            file.write(\"Informativeness:\\n\\n\")\n",
    "            file.write(f\"item{i}-message2:\\n\")\n",
    "            file.write(\"Expressiveness:\\n\")\n",
    "            file.write(\"Informativeness:\\n\\n\")\n",
    "            file.write(\"Best description number:\\n\\n\")\n",
    "            file.write(\"---\\n\\n\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    generate_file(\"../data/angular_filtered/subsets/human_eval/no_human_ref_test.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe999d58439eb20",
   "metadata": {},
   "source": [
    "## Analyze the result from human evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "426b95b5a043abb5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-17T09:04:33.106004Z",
     "start_time": "2024-07-17T09:04:33.074704Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "# 正则表达式匹配模式\n",
    "pattern1 = r'Best description number:\\s*(\\d+)'\n",
    "pattern2 = r'Best description number:\\s*item(\\d+)-message(\\d+)'\n",
    "\n",
    "for file_name in range(1, 6):\n",
    "    # 读取文件内容\n",
    "    file_path = f'../data/angular_filtered/subsets/human_eval/people/no_human_ref_test_{file_name}.txt'\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        content = file.read()\n",
    "    \n",
    "    json_data = []\n",
    "    # 按照item分割文件内容\n",
    "    items = content.strip().split('---\\n')\n",
    "    best_description_counts = {1: 0, 2: 0}\n",
    "    for index, item in enumerate(items):\n",
    "        item = [text for text in item.strip().split('\\n') if text]\n",
    "        ex_1_match = re.match(\"Expressiveness:\\s*(\\d+)\", item[1])\n",
    "        if not ex_1_match:\n",
    "            raise ValueError(f\"无法匹配表达性: {item[1]}\")\n",
    "        ex_1 = ex_1_match.group(1)\n",
    "        in_1_match = re.match(\"Informativeness:\\s*(\\d+)\", item[2])\n",
    "        if not in_1_match:\n",
    "            raise ValueError(f\"无法匹配信息性: {item[2]}\")\n",
    "        in_1 = in_1_match.group(1)\n",
    "        ex_2_match = re.match(\"Expressiveness:\\s*(\\d+)\", item[4])\n",
    "        if not ex_2_match:\n",
    "            raise ValueError(f\"无法匹配表达性: {item[4]}\")\n",
    "        ex_2 = ex_2_match.group(1)\n",
    "        in_2_match = re.match(\"Informativeness:\\s*(\\d+)\", item[5])\n",
    "        if not in_2_match:\n",
    "            raise ValueError(f\"无法匹配信息性: {item[5]}\")\n",
    "        in_2 = in_2_match.group(1)\n",
    "        # use pattern1 and pattern2 to match the best description number\n",
    "        match1 = re.match(pattern1, item[6])\n",
    "        match2 = re.match(pattern2, item[6])\n",
    "        if match1:\n",
    "            best_id = int(match1.group(1))\n",
    "        elif match2:\n",
    "            best_id = int(match2.group(2))\n",
    "        else:\n",
    "            raise ValueError(f\"无法匹配最佳描述号: {item[6]}\")\n",
    "        data = {\"Item_number\": int(index+1), \"Expressiveness1\": int(ex_1), \"Informativeness1\": int(in_1), \"Expressiveness2\": int(ex_2), \"Informativeness2\": int(in_2), \"Best_description_number\": best_id}\n",
    "        json_data.append(data)\n",
    "    \n",
    "    with open(f'../data/angular_filtered/subsets/human_eval/people/no_human_ref_test_{file_name}.json', 'w', encoding='utf-8') as file:\n",
    "        json.dump(json_data, file, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7ad7f6d36466ca18",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'3'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 22\u001b[0m\n\u001b[1;32m     20\u001b[0m     mapping_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mObject-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mindex\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     21\u001b[0m     item_mapping \u001b[38;5;241m=\u001b[39m mapping[mapping_key]\n\u001b[0;32m---> 22\u001b[0m     count_dict[\u001b[43mitem_mapping\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mBest_description_number\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# 绘制当前文件的条形图\u001b[39;00m\n\u001b[1;32m     25\u001b[0m labels \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrace\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclassified_rag\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mKeyError\u001b[0m: '3'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 假设所有 JSON 文件都在 'json_files' 目录中\n",
    "directory = '../data/angular_filtered/subsets/human_eval/people/'\n",
    "\n",
    "with open('../data/angular_filtered/subsets/human_eval/no_human_ref_test_mapping.json', 'r', encoding='UTF-8') as file:\n",
    "    mapping = json.load(file)\n",
    "\n",
    "# 遍历目录中的所有 JSON 文件\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith('.json'):\n",
    "        with open(os.path.join(directory, filename), 'r', encoding='utf-8') as file:\n",
    "            data = json.load(file)\n",
    "            # 初始化计数器\n",
    "            count_dict = {'race': 0, 'classified_rag': 0}\n",
    "            # 根据 `Best_description_number` 更新计数器\n",
    "            for index, item in enumerate(data):\n",
    "                mapping_key = f\"Object-{index+1}\"\n",
    "                item_mapping = mapping[mapping_key]\n",
    "                if str(item['Best_description_number'])=='3':\n",
    "                    \n",
    "                count_dict[item_mapping[str(item['Best_description_number'])]] += 1\n",
    "            \n",
    "            # 绘制当前文件的条形图\n",
    "            labels = ['race', 'classified_rag']\n",
    "            counts = [count_dict['race'], count_dict['classified_rag']]\n",
    "\n",
    "            plt.figure()\n",
    "            plt.bar(labels, counts, color=['blue', 'green'])\n",
    "            plt.xlabel('Best Description Number')\n",
    "            plt.ylabel('Count')\n",
    "            plt.title(f'Count of Best Description Numbers 1 and 2 in {filename}')\n",
    "            \n",
    "            # 保存图表到文件，也可以使用 plt.show() 直接显示\n",
    "            plt.savefig(f'{directory}{filename}_bar_chart.png')\n",
    "            plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "be086734",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1': 'race', '2': 'classified_rag'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping['Object-1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7898f936",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea86f6d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
