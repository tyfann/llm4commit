[
    {
        "msg": "fix last typos",
        "diff": "diff --git a/sc2/bot_ai.py b/sc2/bot_ai.py @@ -346,7 +346,7 @@ class BotAI:\nif len(worker_pool) > len(deficit_mining_places):\nall_minerals_near_base = [\nmineral\n- for mineral in self.mineral_fields\n+ for mineral in self.state.mineral_field\nif any(mineral.distance_to(base) <= 8 for base in self.townhalls.ready)\n]\n# distribute every worker in the pool\n@@ -376,7 +376,7 @@ class BotAI:\nmineral for mineral in self.state.mineral_field if mineral.distance_to(current_place) <= 8\n]\ntarget_mineral = max(local_minerals, key=lambda mineral: mineral.mineral_contents)\n- self.actions.append(worker.gather(target_mineral))\n+ actions.append(worker.gather(target_mineral))\n# more workers to distribute than free mining spots\n# send to closest if worker is doing nothing\nelif worker.is_idle and all_minerals_near_base:\n",
        "lang": "Python",
        "chatgpt": "Refactor worker mining logic to use state.mineral_field and fix actions.append() bug"
    },
    {
        "msg": "Add null check for compiledConstructor",
        "diff": "diff --git a/src/NLog/Config/ServiceRepositoryInternal.cs b/src/NLog/Config/ServiceRepositoryInternal.cs @@ -142,7 +142,7 @@ private object DefaultResolveInstance(Type itemType, HashSet<Type> seenTypes)\n{\nseenTypes = seenTypes ?? new HashSet<Type>();\nvar parameterValues = CreateCtorParameterValues(constructorParameters, seenTypes);\n- return compiledConstructor.Ctor(parameterValues);\n+ return compiledConstructor?.Ctor(parameterValues);\n}\n}\n",
        "lang": "C#",
        "chatgpt": "Fix null reference exception in DefaultResolveInstance method"
    },
    {
        "msg": "bugfix: fix cmake compile blackwidow can't find \"port\"",
        "diff": "diff --git a/src/blackwidow/CMakeLists.txt b/src/blackwidow/CMakeLists.txt @@ -3,6 +3,8 @@ cmake_minimum_required (VERSION 3.10)\nset (CMAKE_CXX_STANDARD 17)\nproject (blackwidow)\n+add_definitions(-DROCKSDB_PLATFORM_POSIX -DROCKSDB_LIB_IO_POSIX)\n+\naux_source_directory(./src DIR_SRCS)\nadd_library(blackwidow STATIC ${DIR_SRCS} )\n",
        "lang": "C++",
        "chatgpt": "Add ROCKSDB platform and IO definitions to CMakeLists.txt"
    },
    {
        "msg": "Update UnrealEnginePython.Build.cs",
        "diff": "diff --git a/Source/UnrealEnginePython/UnrealEnginePython.Build.cs b/Source/UnrealEnginePython/UnrealEnginePython.Build.cs @@ -21,7 +21,7 @@ public class UnrealEnginePython : ModuleRules\n\"C:/Program Files/Python37\",\n\"C:/Program Files/Python36\",\n\"C:/Program Files/Python35\",\n- \"C:/Python36\",\n+ \"C:/Python27\",\n\"C:/IntelPython35\"\n};\n",
        "lang": "C++",
        "chatgpt": "Update Python paths in Build.cs"
    },
    {
        "msg": "add an example of new query funtion",
        "diff": "diff --git a/api/http/cpp/example/CppAPIExample.cpp b/api/http/cpp/example/CppAPIExample.cpp @@ -38,6 +38,9 @@ int main(int argc, char * argv[])\nstd::string answer = gc.query(\"root\", \"123456\", \"test\", sparql);\nstd::cout << answer << std::endl;\n+ // make a SPARQL query and save the result in ans.txt\n+ gc.query(\"root\", \"123456\", \"test\", sparql, \"ans.txt\");\n+\n// unload this database.\ngc.unload(\"test\", \"root\", \"123456\");\n// also, you can load some exist database directly and then query.\n",
        "lang": "C++",
        "chatgpt": "Add functionality to save SPARQL query result to a file"
    },
    {
        "msg": "Fix tags again.",
        "diff": "diff --git a/nearley/values.ne b/nearley/values.ne @@ -128,7 +128,7 @@ colorCombinationValue ->\n@builtin \"string.ne\"\n-stringSetElementOpValue -> equalityOperator stringValue {% ([, value]) => setElementOperation(value) %}\n+stringSetElementOpValue -> equalityOperator stringValue {% ([op, value]) => setElementOperation(op, value) %}\nstringOpValue -> equalityOperator stringValue {% ([op, value]) => stringOperation(op, value) %}\n",
        "lang": "JavaScript",
        "chatgpt": "Refactor stringSetElementOpValue to include operation parameter"
    },
    {
        "msg": "Fix kubectl not in default location issue",
        "diff": "diff --git a/src/operator-dashboard/agent/ansible/roles/deploy_k8s/pubconn/tasks/apply.yml b/src/operator-dashboard/agent/ansible/roles/deploy_k8s/pubconn/tasks/apply.yml - name: Query service ports\nshell: >-\n- kubectl --kubeconfig kubeconfig get services\n+ ./kubectl --kubeconfig kubeconfig get services\n| grep NodePort | awk '{print $1, $5}'\nregister: ports\nargs:\n",
        "lang": "Python",
        "chatgpt": "Fixing kubectl command in apply.yml to use local executable"
    },
    {
        "msg": "Fix cant full sync bug",
        "diff": "diff --git a/src/pika_repl_server_conn.cc b/src/pika_repl_server_conn.cc @@ -131,6 +131,14 @@ void PikaReplServerConn::HandleTrySyncRequest(void* arg) {\n<< \", pro_offset_: \" << slave_boffset.offset();\npre_success = false;\n}\n+ if (pre_success) {\n+ std::string confile = NewFileName(partition->logger()->filename, slave_boffset.filenum());\n+ if (!slash::FileExists(confile)) {\n+ LOG(INFO) << \"Partition: \" << partition_name << \" binlog has been purged, may need full sync\";\n+ try_sync_response->set_reply_code(InnerMessage::InnerResponse::TrySync::kSyncPointBePurged);\n+ pre_success = false;\n+ }\n+ }\nif (pre_success) {\nPikaBinlogReader reader;\nreader.Seek(partition->logger(), slave_boffset.filenum(), slave_boffset.offset());\n@@ -147,15 +155,6 @@ void PikaReplServerConn::HandleTrySyncRequest(void* arg) {\n}\n}\n- if (pre_success) {\n- std::string confile = NewFileName(partition->logger()->filename, slave_boffset.filenum());\n- if (!slash::FileExists(confile)) {\n- LOG(INFO) << \"Partition: \" << partition_name << \" binlog has been purged, may need full sync\";\n- try_sync_response->set_reply_code(InnerMessage::InnerResponse::TrySync::kSyncPointBePurged);\n- pre_success = false;\n- }\n- }\n-\nif (pre_success) {\nif (!g_pika_rm->CheckPartitionSlaveExist(RmNode(node.ip(), node.port(), table_name, partition_id))) {\nint32_t session_id = g_pika_rm->GenPartitionSessionId(table_name, partition_id);\n",
        "lang": "C++",
        "chatgpt": "Fix issue with handling TrySyncRequest and checking for purged binlog files."
    },
    {
        "msg": "Fix bot_ai.py",
        "diff": "diff --git a/sc2/bot_ai.py b/sc2/bot_ai.py @@ -15,7 +15,6 @@ from .game_state import GameState\nfrom .ids.ability_id import AbilityId\nfrom .ids.unit_typeid import UnitTypeId\nfrom .ids.upgrade_id import UpgradeId\n-from .points import Points\nfrom .position import Point2, Point3\nfrom .unit import Unit\nfrom .units import Units\n",
        "lang": "Python",
        "chatgpt": "Remove Points class from bot_ai.py"
    },
    {
        "msg": "Refactor and add a fix for already existing decks.",
        "diff": "diff --git a/routes/cube_routes.js b/routes/cube_routes.js @@ -1153,6 +1153,34 @@ router.post('/importcubetutor/:id', ensureAuth, body('cubeid').toInt(), flashVal\n}\n});\n+const createDraftForSingleDeck = (deck) => {\n+ let index = 0;\n+ const populatedCards = [];\n+ for (const stack of deck.seats[0].deck) {\n+ for (const card of stack) {\n+ card.index = index;\n+ populatedCards.push(card);\n+ index += 1;\n+ }\n+ }\n+ const draft = new Draft();\n+ draft.initial_state = [[populatedCards]];\n+ const response = await fetch(`${process.env.FLASKROOT}/embeddings/`, {\n+ method: 'post',\n+ headers: { 'Content-Type': 'application/json' },\n+ body: JSON.stringify({\n+ cards: populatedCards.map((card) => carddb.cardFromId(card.cardID).name_lower),\n+ }),\n+ });\n+ if (response.ok) {\n+ draft.synergies = await response.json();\n+ } else {\n+ draft.synergies = null;\n+ }\n+ await draft.save();\n+ return draft._id;\n+};\n+\nrouter.post('/uploaddecklist/:id', ensureAuth, async (req, res) => {\ntry {\nconst cube = await Cube.findOne(buildIdQuery(req.params.id)).lean();\n@@ -1234,31 +1262,7 @@ router.post('/uploaddecklist/:id', ensureAuth, async (req, res) => {\nsideboard: [],\n},\n];\n- let index = 0;\n- const populatedCards = [];\n- for (const stack of deck.seats[0].deck) {\n- for (const card of stack) {\n- card.index = index;\n- populatedCards.push(card);\n- index += 1;\n- }\n- }\n- const draft = new Draft();\n- draft.initial_state = [[populatedCards]];\n- const response = await fetch(`${process.env.FLASKROOT}/embeddings/`, {\n- method: 'post',\n- headers: { 'Content-Type': 'application/json' },\n- body: JSON.stringify({\n- cards: populatedCards.map((card) => carddb.cardFromId(card.cardID).name_lower),\n- }),\n- });\n- if (response.ok) {\n- draft.synergies = await response.json();\n- } else {\n- draft.synergies = null;\n- }\n- await draft.save();\n- deck.draft = draft._id;\n+ deck.draft = createDraftForSingleDeck(deck);\nawait deck.save();\nawait Cube.updateOne(\n@@ -1730,31 +1734,7 @@ router.post('/startsealed/:id', body('packs').toInt({ min: 1, max: 16 }), body('\ndeck: pool,\nsideboard: [],\n});\n- let index = 0;\n- const populatedCards = [];\n- for (const stack of deck.seats[0].deck) {\n- for (const card of stack) {\n- card.index = index;\n- populatedCards.push(card);\n- index += 1;\n- }\n- }\n- const draft = new Draft();\n- draft.initial_state = [[populatedCards]];\n- const response = await fetch(`${process.env.FLASKROOT}/embeddings/`, {\n- method: 'post',\n- headers: { 'Content-Type': 'application/json' },\n- body: JSON.stringify({\n- cards: populatedCards.map((card) => carddb.cardFromId(card.cardID).name_lower),\n- }),\n- });\n- if (response.ok) {\n- draft.synergies = await response.json();\n- } else {\n- draft.synergies = null;\n- }\n- await draft.save();\n- deck.draft = draft._id;\n+ deck.draft = createDraftForSingleDeck(deck);\nawait deck.save();\n@@ -3222,7 +3202,7 @@ router.get('/deckbuilder/:id', async (req, res) => {\nreq.flash('danger', 'Deck not found');\nreturn res.status(404).render('misc/404', {});\n}\n- const draft = await Draft.findById(deck.draft);\n+ const draft = deck.draft ? await Draft.findById(deck.draft) : null;\nconst deckOwner = await User.findById(deck.seats[0].userid).lean();\n@@ -3244,6 +3224,11 @@ router.get('/deckbuilder/:id', async (req, res) => {\ncard.details = carddb.cardFromId(card.cardID);\n}\n}\n+ if (draft) {\n+ for (const card of Object.values(draft.basics)) {\n+ card.details = carddb.cardFromId(card.cardID);\n+ }\n+ }\nconst cube = await Cube.findOne(buildIdQuery(deck.cube), Cube.LAYOUT_FIELDS).lean();\n",
        "lang": "JavaScript",
        "chatgpt": "Refactor deck creation to use a new function for draft creation."
    },
    {
        "msg": "MessageQueueTarget - Removed unnecessary string normalization to check for non-letter '='",
        "diff": "diff --git a/src/NLog.MSMQ/Targets/MessageQueueTarget.cs b/src/NLog.MSMQ/Targets/MessageQueueTarget.cs @@ -218,7 +218,7 @@ protected virtual Message PrepareMessage(LogEventInfo logEvent)\nprivate static bool IsFormatNameSyntax(string queue)\n{\n- return queue.ToLowerInvariant().IndexOf('=') != -1;\n+ return queue.IndexOf('=') >= 0;\n}\n}\n",
        "lang": "C#",
        "chatgpt": "Refactor IsFormatNameSyntax method to improve readability and consistency."
    },
    {
        "msg": "Fix error with null check",
        "diff": "diff --git a/routes/cube_routes.js b/routes/cube_routes.js @@ -820,7 +820,7 @@ router.get('/list/:id', async function(req, res) {\nconst reactProps = {\ncanEdit: req.user ? req.user.id === cube.owner : false,\ncubeID: req.params.id,\n- defaultTagColors: cube.tag_colors,\n+ defaultTagColors: cube.tag_colors ? cube.tag_colors : [],\ndefaultShowTagColors: !req.user || !req.user.hide_tag_colors,\ndefaultSorts: cube.default_sorts,\ncards,\n",
        "lang": "JavaScript",
        "chatgpt": "\"Fix defaultTagColors to handle null values in cube_routes.js\""
    },
    {
        "msg": "node_manager_daemon_fkie: ignore directories on read include files",
        "diff": "diff --git a/node_manager_daemon_fkie/src/node_manager_daemon_fkie/common.py b/node_manager_daemon_fkie/src/node_manager_daemon_fkie/common.py @@ -241,8 +241,11 @@ def included_files(string,\nrecursive_list = res_list\nelse:\nresult += res_list\n+ elif os.path.isdir(file_name):\n+ file_name = ''\nexcept Exception as e:\nrospy.logwarn(utf8(e))\n+ if file_name:\nif not unique:\n# transform found position to line number\nresult.append((content.count(\"\\n\", 0, groups.start()) + 1, file_name, recursive_list))\n",
        "lang": "Python",
        "chatgpt": "Fix issue with handling directories in included_files function"
    },
    {
        "msg": "Only use observerLossEvent if there are observers.\nSummary: As in title. This makes it a noop if the connection has no observers.",
        "diff": "diff --git a/quic/loss/QuicLossFunctions.h b/quic/loss/QuicLossFunctions.h @@ -212,7 +212,10 @@ folly::Optional<CongestionController::LossEvent> detectLossPackets(\n<< \" delayUntilLost=\" << delayUntilLost.count() << \"us\"\n<< \" \" << conn;\nCongestionController::LossEvent lossEvent(lossTime);\n- Observer::LossEvent observerLossEvent(lossTime);\n+ folly::Optional<Observer::LossEvent> observerLossEvent;\n+ if (!conn.observers->empty()) {\n+ observerLossEvent.emplace(lossTime);\n+ }\n// Note that time based loss detection is also within the same PNSpace.\nauto iter = getFirstOutstandingPacket(conn, pnSpace);\nbool shouldSetTimer = false;\n@@ -260,7 +263,9 @@ folly::Optional<CongestionController::LossEvent> detectLossPackets(\n}\ndetectPMTUBlackhole(conn, pkt);\nlossEvent.addLostPacket(pkt);\n- observerLossEvent.addLostPacket(lostByTimeout, lostByReorder, pkt);\n+ if (observerLossEvent) {\n+ observerLossEvent->addLostPacket(lostByTimeout, lostByReorder, pkt);\n+ }\nif (pkt.isDSRPacket) {\nCHECK_GT(conn.outstandings.dsrCount, 0);\n@@ -302,12 +307,12 @@ folly::Optional<CongestionController::LossEvent> detectLossPackets(\n} // while (iter != conn.outstandings.packets.end()) {\n// if there are observers, enqueue a function to call it\n- if (observerLossEvent.hasPackets()) {\n+ if (observerLossEvent && observerLossEvent->hasPackets()) {\nfor (const auto& observer : *(conn.observers)) {\nconn.pendingCallbacks.emplace_back(\n[observer, observerLossEvent](QuicSocket* qSocket) {\nif (observer->getConfig().lossEvents) {\n- observer->packetLossDetected(qSocket, observerLossEvent);\n+ observer->packetLossDetected(qSocket, *observerLossEvent);\n}\n});\n}\n",
        "lang": "C++",
        "chatgpt": "Add optional observerLossEvent in detectLossPackets() to handle observer callbacks."
    },
    {
        "msg": "Add inclusive language statement",
        "diff": "diff --git a/README.md b/README.md @@ -129,4 +129,22 @@ Can you find anyone better at playing chains? :)\n## Incubation Notice\nThis project is a Hyperledger project in _Incubation_. It was proposed to the community and documented [here](https://docs.google.com/document/d/1E2i5GRqWsIag7KTxjQ_jQdDiWcuikv3KqXeuw7NaceM/edit), and was approved by [Hyperledger TSC at 2017-01-07](https://lists.hyperledger.org/pipermail/hyperledger-tsc/2017-January/000535.html). Information on what _Incubation_ entails can be found in the [Hyperledger Project Lifecycle document](https://goo.gl/4edNRc).\n+## Inclusive Language Statement\n+\n+These guiding principles are very important to the maintainers and therefore\n+we respectfully ask all contributors to abide by them as well:\n+\n+- Consider that users who will read the docs are from different backgrounds and\n+cultures and that they have different preferences.\n+- Avoid potential offensive terms and, for instance, prefer \"allow list and\n+deny list\" to \"white list and black list\".\n+- We believe that we all have a role to play to improve our world, and even if\n+writing inclusive documentation might not look like a huge improvement, it's a\n+first step in the right direction.\n+- We suggest to refer to\n+[Microsoft bias free writing guidelines](https://docs.microsoft.com/en-us/style-guide/bias-free-communication)\n+and\n+[Google inclusive doc writing guide](https://developers.google.com/style/inclusive-documentation)\n+as starting points.\n+\n<a rel=\"license\" href=\"http://creativecommons.org/licenses/by/4.0/\"><img alt=\"Creative Commons License\" style=\"border-width:0\" src=\"https://i.creativecommons.org/l/by/4.0/88x31.png\" /></a><br />This work is licensed under a <a rel=\"license\" href=\"http://creativecommons.org/licenses/by/4.0/\">Creative Commons Attribution 4.0 International License</a>.\n",
        "lang": "Python",
        "chatgpt": "Add inclusive language statement to README.md"
    },
    {
        "msg": "speed up mvfst build by not building fizz test target\nSummary:\nWhen consuming fizz as an external target, it's wasteful to build test targets\nof fizz.\nThis should fix the travis build timeout of mvfst in oss:",
        "diff": "diff --git a/cmake/BuildFizz.cmake b/cmake/BuildFizz.cmake @@ -10,6 +10,7 @@ list(APPEND PREFIX_PATH ${CMAKE_PREFIX_PATH} ${CMAKE_INSTALL_PREFIX})\nlist(APPEND CMAKE_ARGS\n-DCMAKE_BUILD_TYPE:STRING=RelWithDebInfo\n-DCMAKE_PREFIX_PATH:STRING=${PREFIX_PATH}\n+ -DBUILD_TESTS:STRING=OFF\n)\nif(UNIX AND APPLE)\nlist(APPEND CMAKE_ARGS\n",
        "lang": "C++",
        "chatgpt": "Disable building tests in BuildFizz.cmake"
    },
    {
        "msg": "[#63]Removed the few extra spaces from the example yaml",
        "diff": "diff --git a/src/agent/fabric-operator/deploy/crds/fabric_v1alpha1_ca_cr.yaml b/src/agent/fabric-operator/deploy/crds/fabric_v1alpha1_ca_cr.yaml @@ -35,14 +35,8 @@ spec:\n# memory: \"1024mi\"\n# cpu: \"250\"\n- # To specify more environment variables for Fabric CA.\n- # following parameters:\n- # FABRIC_CA_SERVER_CSR_HOSTS: \"[]\"\n- # FABRIC_CA_SERVER_CSR_NAMES_0_C: US\n- # FABRIC_CA_SERVER_CSR_NAMES_0_ST: \"North Carolina\"\n- # FABRIC_CA_SERVER_CSR_NAMES_0_L: \"Cary\"\n- # FABRIC_CA_SERVER_CSR_NAMES_0_O: \"Sample Org\"\n- # FABRIC_CA_SERVER_CSR_NAMES_0_OU: \"Sample Org Unit\"\n+ # To specify more environment variables for Fabric CA, use any Fabric CA\n+ # configurable parameters\nconfigParams:\n- name: FABRIC_CA_SERVER_PORT\nvalue: \"7054\"\n",
        "lang": "Python",
        "chatgpt": "Refactor Fabric CA environment variable configuration in CA custom resource definition"
    },
    {
        "msg": "Add debug spawn unit function",
        "diff": "diff --git a/sc2/client.py b/sc2/client.py @@ -8,6 +8,7 @@ from s2clientprotocol import (\nimport logging\nfrom sc2.ids.ability_id import AbilityId\n+from sc2.ids.unit_typeid import UnitTypeId\nlogger = logging.getLogger(__name__)\n@@ -208,3 +209,20 @@ class Client(Protocol):\n))\nelse:\nawait self.debug_text([texts], [positions], color)\n+\n+ async def debug_create_unit(self, unit_type, amount_of_units, position, owner_id):\n+ # example:\n+ # await self._client.debug_create_unit(MARINE, 1, self._game_info.map_center, 1)\n+ assert isinstance(unit_type, UnitTypeId)\n+ assert 0 < amount_of_units # careful, in realtime=True mode, as of now units get created the double amount\n+ assert isinstance(position, (Point2, Point3))\n+ assert 1 <= owner_id <= 2\n+\n+ await self._execute(debug=sc_pb.RequestDebug(\n+ debug=[debug_pb.DebugCommand(create_unit=debug_pb.DebugCreateUnit(\n+ unit_type=unit_type.value,\n+ owner=owner_id,\n+ pos=common_pb.Point2D(x=position.x, y=position.y),\n+ quantity=(amount_of_units)\n+ ))]\n+ ))\n\\ No newline at end of file\n",
        "lang": "Python",
        "chatgpt": "Add debug_create_unit method to Client class"
    },
    {
        "msg": "Fixed the WorkerRushBot example in README\nThe original code that was published as an example for the ```WorkerRushBot``` did not execute properly.",
        "diff": "diff --git a/README.md b/README.md @@ -93,11 +93,13 @@ You can find your Windows IP using `ipconfig /all` from `PowerShell.exe` or `CMD\nAs promised, worker rush in less than twenty lines:\n```python\n-import sc2\n-from sc2 import run_game, maps, Race, Difficulty\n+from sc2 import maps\nfrom sc2.player import Bot, Computer\n+from sc2.main import run_game\n+from sc2.data import Race, Difficulty\n+from sc2.bot_ai import BotAI\n-class WorkerRushBot(sc2.BotAI):\n+class WorkerRushBot(BotAI):\nasync def on_step(self, iteration: int):\nif iteration == 0:\nfor worker in self.workers:\n",
        "lang": "Python",
        "chatgpt": "Refactor worker rush bot class and imports"
    },
    {
        "msg": "Adding missing emails to gfac config",
        "diff": "diff --git a/dev-tools/ansible/roles/gfac/templates/gfac-config.yaml.j2 b/dev-tools/ansible/roles/gfac/templates/gfac-config.yaml.j2 @@ -88,6 +88,7 @@ resources:\n- smic3 <smic@mail.hpc.lsu.edu> # philip.hpc.lsu\n- adm@jetstream-cloud.org\n- adm <adm@smic3.hpc.lsu.edu> #supermic\n+ - root <adm@alamo.uthscsa.edu> #alamo\n- jobManagerType: SLURM\ncommandOutputParser: org.apache.airavata.gfac.impl.job.SlurmOutputParser\n@@ -112,6 +113,8 @@ resources:\n- slurm@sra-master.jetstreamlocal #Searching SRA\n- Slurm Admin <slurmadmin@hpclogin01.rs.gsu.edu> #GSU cluster\n- slurm@head.cluster #USD cluster\n+ - slurm@js-169-158.jetstream-cloud.org\n+ - slurm@joker.nmsu.edu\n- jobManagerType: UGE\ncommandOutputParser: org.apache.airavata.gfac.impl.job.UGEOutputParser\n",
        "lang": "Java",
        "chatgpt": "Add new Slurm resources for cluster at jetstream-cloud.org and joker.nmsu.edu, and root user for alamo.uthscsa.edu cluster."
    },
    {
        "msg": "Adding CILogon to the cyberwater gateway",
        "diff": "diff --git a/dev-tools/ansible/inventories/scigap/develop/host_vars/cyberwater/vars.yml b/dev-tools/ansible/inventories/scigap/develop/host_vars/cyberwater/vars.yml @@ -37,8 +37,8 @@ auth_options:\npassword:\nname: \"CyberWater\"\nexternal:\n-# - name: \"Existing Institute Login\"\n-# idp_alias: \"cilogon\"\n+ - name: \"Existing Institute Login\"\n+ idp_alias: \"cilogon\"\ngateway_id: \"cyberwater\"\nexperiment_data_dir: \"{{ user_data_dir }}/django-cyberwater\"\n",
        "lang": "Java",
        "chatgpt": "Update authentication options for CyberWater host in Ansible inventory"
    },
    {
        "msg": "fixed SHeaderRow width",
        "diff": "diff --git a/Source/UnrealEnginePython/Private/Slate/UEPySHeaderRow.cpp b/Source/UnrealEnginePython/Private/Slate/UEPySHeaderRow.cpp @@ -13,30 +13,29 @@ static PyObject *ue_PySHeaderRow_str(ue_PySHeaderRow *self)\nstatic PyObject *py_ue_sheader_row_add_column(ue_PySHeaderRow *self, PyObject *args, PyObject *kwargs) {\nchar *column_id;\n+ float fixed_width = 0;\nint cell_h_align = 0;\nint cell_v_align = 0;\nchar *default_label = nullptr;\nchar *default_tooltip = nullptr;\n- float fill_width = 0;\n-\nchar *kwlist[] = {\n(char *)\"column_id\",\n+ (char *)\"fixed_width\",\n(char *)\"cell_h_align\",\n(char *)\"cell_v_align\",\n(char *)\"default_label\",\n(char *)\"default_tooltip\",\n- (char *)\"fill_width\",\nnullptr\n};\n- if (!PyArg_ParseTupleAndKeywords(args, kwargs, \"s|iissf:add_column\", kwlist,\n+ if (!PyArg_ParseTupleAndKeywords(args, kwargs, \"sf|iiss:add_column\", kwlist,\n&column_id,\n+ &fixed_width,\n&cell_h_align,\n&cell_v_align,\n&default_label,\n- &default_tooltip,\n- &fill_width)) {\n+ &default_tooltip)) {\nreturn NULL;\n}\n@@ -46,15 +45,15 @@ static PyObject *py_ue_sheader_row_add_column(ue_PySHeaderRow *self, PyObject *\nif (!default_tooltip)\ndefault_tooltip = default_label;\n- auto &column = SHeaderRow::Column(FName(UTF8_TO_TCHAR(column_id)))\n+ SHeaderRow::FColumn column = SHeaderRow::Column(FName(UTF8_TO_TCHAR(column_id)))\n.DefaultLabel(FText::FromString(UTF8_TO_TCHAR(default_label)))\n.DefaultTooltip(FText::FromString(UTF8_TO_TCHAR(default_tooltip)))\n+ .FixedWidth(fixed_width)\n.HAlignCell((EHorizontalAlignment)cell_h_align)\n.VAlignCell((EVerticalAlignment)cell_v_align);\n- if (fill_width)\n- column.FillWidth(fill_width);\n-\n+ //if (width > 0)\n+ // column.Width = width;\nGET_s_header_row;\n",
        "lang": "C++",
        "chatgpt": "\"Add support for fixed width columns in SHeaderRow\""
    },
    {
        "msg": "Slight Readability Improvements\nSummary: - code refactoring",
        "diff": "diff --git a/quic/server/QuicServerWorker.cpp b/quic/server/QuicServerWorker.cpp @@ -682,16 +682,18 @@ void QuicServerWorker::dispatchPacketData(\nif (quicVersion == QuicVersion::MVFST_EXPERIMENTAL) {\ntransportSettings_.initCwndInMss = 30;\n}\n- if (transportSettingsOverrideFn_) {\n- folly::Optional<TransportSettings> overridenTransportSettings =\n- transportSettingsOverrideFn_(\n- transportSettings_, client.getIPAddress());\n+\n+ auto overridenTransportSettings = transportSettingsOverrideFn_\n+ ? transportSettingsOverrideFn_(\n+ transportSettings_, client.getIPAddress())\n+ : folly::none;\n+\nif (overridenTransportSettings) {\nif (overridenTransportSettings->dataPathType !=\ntransportSettings_.dataPathType) {\n// It's too complex to support that.\nLOG(ERROR)\n- << \"Overriding DataPathType isn't supported. Requested daapath=\"\n+ << \"Overriding DataPathType isn't supported. Requested datapath=\"\n<< (overridenTransportSettings->dataPathType ==\nDataPathType::ContinuousMemory\n? \"ContinuousMemory\"\n@@ -701,9 +703,6 @@ void QuicServerWorker::dispatchPacketData(\n} else {\ntrans->setTransportSettings(transportSettings_);\n}\n- } else {\n- trans->setTransportSettings(transportSettings_);\n- }\ntrans->setConnectionIdAlgo(connIdAlgo_.get());\ntrans->setServerConnectionIdRejector(this);\nif (routingData.sourceConnId) {\n",
        "lang": "C++",
        "chatgpt": "Refactor transport settings override logic in QuicServerWorker"
    },
    {
        "msg": "Stream fixed",
        "diff": "diff --git a/src/NUnit.TestAdapter.Tests.Acceptance/DirectoryMutex.cs b/src/NUnit.TestAdapter.Tests.Acceptance/DirectoryMutex.cs @@ -11,7 +11,7 @@ namespace NUnit.VisualStudio.TestAdapter.Tests.Acceptance\n{\nvar mutexFilePath = Path.Combine(directoryPath, \".mutex\");\n- Stream stream;\n+ FileStream stream;\ntry\n{\nstream = new FileStream(mutexFilePath, FileMode.Create, FileAccess.Write, FileShare.None, bufferSize: 1, FileOptions.DeleteOnClose);\n",
        "lang": "C#",
        "chatgpt": "Replace Stream with FileStream in DirectoryMutex.cs"
    },
    {
        "msg": "Enforce verifications on packs and cards for drafts.",
        "diff": "diff --git a/routes/cube_routes.js b/routes/cube_routes.js @@ -1817,8 +1817,8 @@ router.post(\n'/startdraft/:id',\nbody('id').toInt(),\nbody('seats').toInt({ min: 2, max: 16 }),\n- body('packs').toInt(),\n- body('cards').toInt(),\n+ body('packs').toInt({ min: 1, max: 36 }),\n+ body('cards').toInt({ min: 1, max: 90 }),\nasync (req, res) => {\ntry {\nconst cube = await Cube.findOne(\n",
        "lang": "JavaScript",
        "chatgpt": "Update validation for number of packs and cards in draft start endpoint"
    },
    {
        "msg": "SA1009 Closing parenthesis should not be preceded by a space and should be followed by a space",
        "diff": "diff --git a/src/NUnitTestAdapterTests/TestConverterTests.cs b/src/NUnitTestAdapterTests/TestConverterTests.cs @@ -161,8 +161,7 @@ namespace NUnit.VisualStudio.TestAdapter.Tests\n[TestCase(\n\"<test-output stream=\\\"Error\\\" testid=\\\"0-1001\\\" testname=\\\"UnitTests.Test1\\\"><![CDATA[some stdErr]]></test-output>\"\n+ \";<test-output stream=\\\"Progress\\\" testid=\\\"0-1001\\\" testname=\\\"UnitTests.Test1\\\"><![CDATA[some text]]></test-output>\",\n- \"StdErrMsgs:some stdErr\"\n- )]\n+ \"StdErrMsgs:some stdErr\")]\npublic void CanMakeTestResultFromNUnitTestResult2(string output, string expectedMessages)\n{\nvar cachedTestCase = testConverter.ConvertTestCase(fakeTestNode);\n",
        "lang": "C#",
        "chatgpt": "Refactor test case in TestConverterTests to remove unnecessary code changes."
    },
    {
        "msg": "DatabaseTarget - Skip assembly lookup for NetStandard, and ignore case on type lookup",
        "diff": "diff --git a/src/NLog/Targets/DatabaseTarget.cs b/src/NLog/Targets/DatabaseTarget.cs @@ -83,8 +83,6 @@ namespace NLog.Targets\n[Target(\"Database\")]\npublic class DatabaseTarget : Target, IInstallable\n{\n- private static Assembly systemDataAssembly = typeof(IDbConnection).GetAssembly();\n-\nprivate IDbConnection _activeConnection = null;\nprivate string _activeConnectionString;\n@@ -465,23 +463,32 @@ private void SetConnectionType()\ncase \"MSDE\":\n#if NETSTANDARD\ncase \"SYSTEM.DATA.SQLCLIENT\":\n+ {\nvar assembly = Assembly.Load(new AssemblyName(\"System.Data.SqlClient\"));\n#else\n- var assembly = systemDataAssembly;\n+ {\n+ var assembly = typeof(IDbConnection).GetAssembly();\n#endif\nConnectionType = assembly.GetType(\"System.Data.SqlClient.SqlConnection\", true, true);\nbreak;\n+ }\n#if !NETSTANDARD\ncase \"OLEDB\":\n- ConnectionType = systemDataAssembly.GetType(\"System.Data.OleDb.OleDbConnection\", true);\n+ {\n+ var assembly = typeof(IDbConnection).GetAssembly();\n+ ConnectionType = assembly.GetType(\"System.Data.OleDb.OleDbConnection\", true, true);\nbreak;\n+ }\ncase \"ODBC\":\n- ConnectionType = systemDataAssembly.GetType(\"System.Data.Odbc.OdbcConnection\", true);\n+ {\n+ var assembly = typeof(IDbConnection).GetAssembly();\n+ ConnectionType = assembly.GetType(\"System.Data.Odbc.OdbcConnection\", true, true);\nbreak;\n+ }\n#endif\ndefault:\n- ConnectionType = Type.GetType(DBProvider, true);\n+ ConnectionType = Type.GetType(DBProvider, true, true);\nbreak;\n}\n}\n",
        "lang": "C#",
        "chatgpt": "Refactor DatabaseTarget to dynamically load assembly for ConnectionType."
    },
    {
        "msg": "Show process output if result file was not populated",
        "diff": "diff --git a/src/NUnit.TestAdapter.Tests.Acceptance/WorkspaceTools/IsolatedWorkspace.cs b/src/NUnit.TestAdapter.Tests.Acceptance/WorkspaceTools/IsolatedWorkspace.cs @@ -60,12 +60,15 @@ namespace NUnit.VisualStudio.TestAdapter.Tests.Acceptance.WorkspaceTools\n{\nusing var tempTrxFile = new TempFile();\n- ConfigureRun(\"dotnet\")\n+ var result = ConfigureRun(\"dotnet\")\n.Add(\"test\")\n.AddIf(noBuild, \"--no-build\")\n.Add(\"--logger\").Add(\"trx;LogFileName=\" + tempTrxFile)\n.Run(throwOnError: false);\n+ if (new FileInfo(tempTrxFile).Length == 0)\n+ result.ThrowIfError();\n+\nreturn VSTestResult.Load(tempTrxFile);\n}\n@@ -95,16 +98,18 @@ namespace NUnit.VisualStudio.TestAdapter.Tests.Acceptance.WorkspaceTools\npublic VSTestResult VSTest(IEnumerable<string> testAssemblyPaths)\n{\n- using (var tempTrxFile = new TempFile())\n- {\n- ConfigureRun(toolResolver.VSTest)\n+ using var tempTrxFile = new TempFile();\n+\n+ var result = ConfigureRun(toolResolver.VSTest)\n.AddRange(testAssemblyPaths)\n.Add(\"/logger:trx;LogFileName=\" + tempTrxFile)\n.Run(throwOnError: false);\n+ if (new FileInfo(tempTrxFile).Length == 0)\n+ result.ThrowIfError();\n+\nreturn VSTestResult.Load(tempTrxFile);\n}\n- }\nprivate RunSettings ConfigureRun(string filename) => new RunSettings(Directory, filename);\n}\n",
        "lang": "C#",
        "chatgpt": "Refactor VSTest method in IsolatedWorkspace to handle empty trx files and throw errors if necessary."
    },
    {
        "msg": "fix: include local build of Amazon.IonDotnet in unpack library.",
        "diff": "diff --git a/lib/Ephemerality.Unpack/Ephemerality.Unpack.csproj b/lib/Ephemerality.Unpack/Ephemerality.Unpack.csproj @@ -44,4 +44,21 @@ Content can be unpacked in the form of RAWML for Mobi/AZW3 and plain text for KF\n</Otherwise>\n</Choose>\n+ <!--\n+ The following solves the problem that 'dotnet pack' does not include the DLLs from referenced projects.\n+ See https://github.com/NuGet/Home/issues/3891 for a description of the problem\n+ and for newer versions / workarounds / built-in methods.\n+ -->\n+ <PropertyGroup>\n+ <TargetsForTfmSpecificBuildOutput>$(TargetsForTfmSpecificBuildOutput);CopyProjectReferencesToPackage</TargetsForTfmSpecificBuildOutput>\n+ <!-- include PDBs in the NuGet package -->\n+ <!--<AllowedOutputExtensionsInPackageBuildOutputFolder>$(AllowedOutputExtensionsInPackageBuildOutputFolder);.pdb</AllowedOutputExtensionsInPackageBuildOutputFolder>-->\n+ </PropertyGroup>\n+ <Target Name=\"CopyProjectReferencesToPackage\" DependsOnTargets=\"ResolveReferences\">\n+ <ItemGroup>\n+ <!-- Output all references with CopyLocal = true to package directory. E.g. IonDotnet above. -->\n+ <BuildOutputInPackage Include=\"@(ReferenceCopyLocalPaths->WithMetadataValue('CopyLocal', 'true'))\" />\n+ </ItemGroup>\n+ </Target>\n+\n</Project>\n",
        "lang": "C#",
        "chatgpt": "Add solution for 'dotnet pack' not including DLLs from referenced projects"
    },
    {
        "msg": "remove mstch from fbthrift's fbcode_builder spec\nSummary: mstch is no longer required for fbthrift, we can remove it from oss build spec",
        "diff": "diff --git a/build/fbcode_builder/specs/fbthrift.py b/build/fbcode_builder/specs/fbthrift.py @@ -13,21 +13,11 @@ import specs.sodium as sodium\nimport specs.wangle as wangle\nimport specs.zstd as zstd\n-from shell_quoting import ShellQuoted\n-\ndef fbcode_builder_spec(builder):\n- # This API should change rarely, so build the latest tag instead of master.\n- builder.add_option(\n- 'no1msd/mstch:git_hash',\n- ShellQuoted('$(git describe --abbrev=0 --tags)')\n- )\nreturn {\n'depends_on': [folly, fizz, fmt, sodium, rsocket, wangle, zstd],\n'steps': [\n- # This isn't a separete spec, since only fbthrift uses mstch.\n- builder.github_project_workdir('no1msd/mstch', 'build'),\n- builder.cmake_install('no1msd/mstch'),\nbuilder.fb_github_cmake_install('fbthrift/thrift'),\n],\n}\n",
        "lang": "C++",
        "chatgpt": "Remove unnecessary code for fbthrift.py spec and update dependencies."
    },
    {
        "msg": "node_manager_fkie: removed handling for Ctrl+C and Ctrl+X, so this shortcut now works in description dock",
        "diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/master_view_proxy.py b/node_manager_fkie/src/node_manager_fkie/master_view_proxy.py @@ -342,10 +342,10 @@ class MasterViewProxy(QWidget):\nself._shortcut_stop = QShortcut(QKeySequence(self.tr(\"Alt+S\", \"stop selected nodes\")), self)\nself._shortcut_stop.activated.connect(self.on_stop_clicked)\n- self._shortcut_copy = QShortcut(QKeySequence(self.tr(\"Ctrl+C\", \"copy selected values to clipboard\")), self)\n- self._shortcut_copy.activated.connect(self.on_copy_c_pressed)\n- self._shortcut_copy = QShortcut(QKeySequence(self.tr(\"Ctrl+X\", \"copy selected alternative values to clipboard\")), self)\n- self._shortcut_copy.activated.connect(self.on_copy_x_pressed)\n+# self._shortcut_copy = QShortcut(QKeySequence(self.tr(\"Ctrl+C\", \"copy selected values to clipboard\")), self)\n+# self._shortcut_copy.activated.connect(self.on_copy_c_pressed)\n+# self._shortcut_copy = QShortcut(QKeySequence(self.tr(\"Ctrl+X\", \"copy selected alternative values to clipboard\")), self)\n+# self._shortcut_copy.activated.connect(self.on_copy_x_pressed)\n# print \"================ create\", self.objectName()\n#\n",
        "lang": "Python",
        "chatgpt": "Refactor keyboard shortcuts in MasterViewProxy"
    },
    {
        "msg": "preliminary support for new 4.15 properties",
        "diff": "diff --git a/Source/UnrealEnginePython/Private/UEPyModule.cpp b/Source/UnrealEnginePython/Private/UEPyModule.cpp @@ -1342,11 +1342,21 @@ PyObject *ue_py_convert_property(UProperty *prop, uint8 *buffer) {\nreturn PyLong_FromLong(value);\n}\n+ if (auto casted_prop = Cast<UUInt32Property>(prop)) {\n+ uint32 value = casted_prop->GetPropertyValue_InContainer(buffer);\n+ return PyLong_FromUnsignedLong(value);\n+ }\n+\nif (auto casted_prop = Cast<UInt64Property>(prop)) {\nlong long value = casted_prop->GetPropertyValue_InContainer(buffer);\nreturn PyLong_FromLongLong(value);\n}\n+ if (auto casted_prop = Cast<UUInt64Property>(prop)) {\n+ uint64 value = casted_prop->GetPropertyValue_InContainer(buffer);\n+ return PyLong_FromUnsignedLongLong(value);\n+ }\n+\nif (auto casted_prop = Cast<UFloatProperty>(prop)) {\nfloat value = casted_prop->GetPropertyValue_InContainer(buffer);\nreturn PyFloat_FromDouble(value);\n@@ -1357,6 +1367,14 @@ PyObject *ue_py_convert_property(UProperty *prop, uint8 *buffer) {\nreturn PyLong_FromLong(value);\n}\n+#if ENGINE_MINOR_VERSION >= 15\n+ if (auto casted_prop = Cast<UEnumProperty>(prop)) {\n+ UEnum *value = casted_prop->GetEnum();\n+ uint64 enum_index = casted_prop->GetUnderlyingProperty()->GetUnsignedIntPropertyValue(buffer);\n+ return PyLong_FromUnsignedLong(enum_index);\n+ }\n+#endif\n+\nif (auto casted_prop = Cast<UStrProperty>(prop)) {\nFString value = casted_prop->GetPropertyValue_InContainer(buffer);\nreturn PyUnicode_FromString(TCHAR_TO_UTF8(*value));\n@@ -1471,6 +1489,41 @@ PyObject *ue_py_convert_property(UProperty *prop, uint8 *buffer) {\nreturn py_list;\n}\n+#if ENGINE_MINOR_VERSION >= 15\n+ if (auto casted_prop = Cast<UMapProperty>(prop)) {\n+ FScriptMapHelper_InContainer map_helper(casted_prop, buffer);\n+\n+ PyObject *py_dict = PyDict_New();\n+\n+ int32 num = map_helper.Num();\n+ for (int32 i = 0; num; i++) {\n+ if (map_helper.IsValidIndex(i)) {\n+ num--;\n+\n+ uint8 *key = map_helper.GetKeyPtr(i);\n+ PyObject *py_key = ue_py_convert_property(map_helper.KeyProp, key);\n+ if (!py_key) {\n+ Py_DECREF(py_dict);\n+ return NULL;\n+ }\n+\n+ uint8 *value = map_helper.GetValuePtr(i);\n+ PyObject *py_value = ue_py_convert_property(map_helper.ValueProp, value);\n+ if (!py_value) {\n+ Py_DECREF(py_dict);\n+ return NULL;\n+ }\n+\n+ PyDict_SetItem(py_dict, py_key, py_value);\n+ Py_DECREF(py_key);\n+ Py_DECREF(py_value);\n+ }\n+ }\n+\n+ return py_dict;\n+ }\n+#endif\n+\nreturn PyErr_Format(PyExc_Exception, \"unsupported value type %s for property %s\", TCHAR_TO_UTF8(*prop->GetClass()->GetName()), TCHAR_TO_UTF8(*prop->GetName()));\n}\n",
        "lang": "C++",
        "chatgpt": "Add support for converting UMapProperty and UEnumProperty types in ue_py_convert_property."
    },
    {
        "msg": "fix bug\nfix a bug",
        "diff": "diff --git a/Util/VList.h b/Util/VList.h @@ -94,7 +94,7 @@ private:\npublic:\nVList();\nVList(std::string& _filepath, std::string& _mode, unsigned long long _buffer_size);//create a fixed-size file or open an existence\n- bool readValue(unsigned _block_num, char*& _str, unsigned& _len);\n+ bool readValue(unsigned _block_num, char*& _str, unsigned& _len, unsigned _key);\nunsigned writeValue(char* _str, unsigned _len);\nbool removeValue(unsigned _block_num);\n~VList();\n",
        "lang": "C++",
        "chatgpt": "Add parameter for key in readValue method"
    },
    {
        "msg": "simplify bootstrap",
        "diff": "diff --git a/examples/simulate_fight_scenario.py b/examples/simulate_fight_scenario.py @@ -6,56 +6,37 @@ from sc2.main import run_game\nfrom sc2.player import Bot, Computer\nfrom loguru import logger\n+ME = 1\n+PC = 2\n+\nclass FightBot(BotAI):\ndef __init__(self):\nsuper().__init__()\n- self.control_received = False\n+ self.enemy_location = None\nself.fight_started = False\nasync def on_step(self, iteration):\n# retrieve control by enabling enemy control and showing whole map\nif iteration == 0:\n- # we need this one for `self.enemy_units` to \"see\" all units on the map\nawait self._client.debug_show_map()\n- # this one will allow us to do something like: `self.enemy_units.first.attack(self._game_info.map_center)`\nawait self._client.debug_control_enemy()\n- # wait till control retrieved\n- if iteration > 0 and self.enemy_units and not self.control_received:\n- # prepare my side\n- me = 1\n-\n- cc = self.townhalls.first\n- p = cc.position.towards(self.game_info.map_center, 4)\n- # create supply\n- await self._client.debug_create_unit([[UnitTypeId.SUPPLYDEPOT, 1, p, me]])\n- # destroy command center\n- await self._client.debug_kill_unit([cc.tag])\n- # destroy all workers\n- await self._client.debug_kill_unit([w.tag for w in self.workers])\n-\n- # create marines\n- await self._client.debug_create_unit([[UnitTypeId.MARINE, 4, p, me]])\n-\n- # prepare opponent side\n- pc = 2\n- cc = self.enemy_structures.first\n- p = cc.position.towards(self.game_info.map_center, 4)\n- # create supply\n- await self._client.debug_create_unit([[UnitTypeId.SUPPLYDEPOT, 1, p, pc]])\n- # destroy command center\n- await self._client.debug_kill_unit([cc.tag])\n- # destroy all workers\n- await self._client.debug_kill_unit([w.tag for w in self.enemy_units(UnitTypeId.SCV)])\n- # create marines\n- await self._client.debug_create_unit([[UnitTypeId.MARINE, 4, p, pc]])\n- logger.info(\"control received\")\n- # await self.chat_send(\"control received\")\n- self.control_received = True\n+ # wait till control retrieved, destroy all starting units, recreate the world\n+ if iteration > 0 and self.enemy_units and not self.enemy_location:\n+ self.enemy_location = self.enemy_structures(UnitTypeId.COMMANDCENTER).first.position.closest(self.enemy_start_locations)\n+ await self._client.debug_kill_unit([u.tag for u in self.units + self.structures + self.enemy_units + self.enemy_structures])\n+ await self._client.debug_create_unit([\n+ [UnitTypeId.SUPPLYDEPOT, 1, self.enemy_location, PC],\n+ [UnitTypeId.MARINE, 4, self.enemy_location.towards(self.start_location, 8), PC]\n+ ])\n+ await self._client.debug_create_unit([\n+ [UnitTypeId.SUPPLYDEPOT, 1, self.start_location, ME],\n+ [UnitTypeId.MARINE, 4, self.start_location.towards(self.enemy_location, 8), ME]\n+ ])\n# note: we should wait till workers will be destroyed\n- if not self.fight_started and self.control_received and self.enemy_units and not self.enemy_units(UnitTypeId.SCV) and not self.units(UnitTypeId.SCV):\n+ if not self.fight_started and self.enemy_location and not self.enemy_units(UnitTypeId.SCV) and not self.units(UnitTypeId.SCV):\n# start fight\nfor u in self.enemy_units:\nu.attack(self.structures.first.position)\n",
        "lang": "Python",
        "chatgpt": "Refactor fight scenario setup and start conditions in simulate_fight_scenario.py"
    },
    {
        "msg": "Fix version compare in cello ansible for raft\nChanging version compare for raft cluster certs from 2.0.0 to 1.4.1\nin fabric-pod.j2",
        "diff": "diff --git a/src/operator-dashboard/agent/ansible/roles/deploy_k8s/fabricsetup/templates/fabric-pod.j2 b/src/operator-dashboard/agent/ansible/roles/deploy_k8s/fabricsetup/templates/fabric-pod.j2 @@ -354,7 +354,7 @@ spec:\n- { name: \"ORDERER_GENERAL_TLS_CERTIFICATE\", value: \"/etc/hyperledger/fabric/artifacts/keyfiles/{{ orderer.org }}/orderers/{{ orderer.name }}.{{ orderer.org }}/tls/server.crt\" }\n- { name: \"ORDERER_GENERAL_TLS_ROOTCAS\", value: \"[/etc/hyperledger/fabric/artifacts/keyfiles/{{ orderer.org }}/orderers/{{ orderer.name }}.{{ orderer.org }}/tls/ca.crt]\" }\n{% endif %}\n-{% if (project_version is version_compare('2.0.0','>=') or ('stable' in project_version or 'latest' in project_version)) and fabric.consensus_type is defined and fabric.consensus_type == 'etcdraft' %}\n+{% if (project_version is version_compare('1.4.1','>=') or ('stable' in project_version or 'latest' in project_version)) and fabric.consensus_type is defined and fabric.consensus_type == 'etcdraft' %}\n- { name: \"ORDERER_GENERAL_CLUSTER_CLIENTPRIVATEKEY\", value: \"/etc/hyperledger/fabric/artifacts/keyfiles/{{ orderer.org }}/orderers/{{ orderer.name }}.{{ orderer.org }}/tls/server.key\" }\n- { name: \"ORDERER_GENERAL_CLUSTER_CLIENTCERTIFICATE\", value: \"/etc/hyperledger/fabric/artifacts/keyfiles/{{ orderer.org }}/orderers/{{ orderer.name }}.{{ orderer.org }}/tls/server.crt\" }\n- { name: \"ORDERER_GENERAL_CLUSTER_ROOTCAS\", value: \"[/etc/hyperledger/fabric/artifacts/keyfiles/{{ orderer.org }}/orderers/{{ orderer.name }}.{{ orderer.org }}/tls/ca.crt]\" }\n",
        "lang": "Python",
        "chatgpt": "Update fabric-pod.j2 template for compatibility with project version 1.4.1 and etcdraft consensus type."
    },
    {
        "msg": "bugfix user specified the pattern does not take effect when execute the Keys command",
        "diff": "diff --git a/src/pika_kv.cc b/src/pika_kv.cc @@ -425,7 +425,7 @@ void KeysCmd::Do(std::shared_ptr<Partition> partition) {\nstd::vector<std::string> keys;\ndo {\nkeys.clear();\n- cursor = partition->db()->Scan(type_, cursor, \"*\", PIKA_SCAN_STEP_LENGTH, &keys);\n+ cursor = partition->db()->Scan(type_, cursor, pattern_, PIKA_SCAN_STEP_LENGTH, &keys);\nfor (const auto& key : keys) {\nRedisAppendLen(raw, key.size(), \"$\");\nRedisAppendContent(raw, key);\n",
        "lang": "C++",
        "chatgpt": "Fix issue with KeysCmd not using pattern_ parameter in Scan method"
    },
    {
        "msg": "Remove extraneous awaits.",
        "diff": "diff --git a/routes/cube_routes.js b/routes/cube_routes.js @@ -1272,7 +1272,7 @@ async function bulkUpload(req, res, list, cube) {\nif ((cards[0].match(/,/g) || []).length > 3) {\nlet newCards = [];\nlet newMaybe = [];\n- ({ newCards, newMaybe, missing } = await CSVtoCards(list, carddb));\n+ ({ newCards, newMaybe, missing } = CSVtoCards(list, carddb));\nchangelog = newCards.reduce((changes, card) => changes + addCardHtml(carddb.cardFromId(card.cardID)), changelog);\ncube.cards.push(...newCards);\ncube.maybe.push(...newMaybe);\n@@ -1394,7 +1394,7 @@ router.post('/bulkreplacefile/:id', ensureAuth, async (req, res) => {\nlet newCards = [];\nlet newMaybe = [];\nif ((lines[0].match(/,/g) || []).length > 3) {\n- ({ newCards, newMaybe, missing } = await CSVtoCards(items, carddb));\n+ ({ newCards, newMaybe, missing } = CSVtoCards(items, carddb));\ncube.cards = newCards;\ncube.maybe = newMaybe;\nconst pids = new Set();\n",
        "lang": "JavaScript",
        "chatgpt": "Refactor CSVtoCards function call in bulkUpload and bulkreplacefile routes"
    },
    {
        "msg": "NLogTraceListener - DisableFlush should be true by default",
        "diff": "diff --git a/src/NLog/NLogTraceListener.cs b/src/NLog/NLogTraceListener.cs @@ -475,6 +475,14 @@ private void InitAttributes()\nif (!_attributesLoaded)\n{\n_attributesLoaded = true;\n+\n+ if (Trace.AutoFlush)\n+ {\n+ // Avoid a world of hurt, by not constantly spawning new flush threads\n+ // Also timeout exceptions thrown by Flush() will not break diagnostic Trace-logic\n+ _disableFlush = true;\n+ }\n+\nforeach (DictionaryEntry de in Attributes)\n{\nvar key = (string)de.Key;\n",
        "lang": "C#",
        "chatgpt": "\"Disable auto flush to prevent thread spawning and timeout exceptions in NLogTraceListener\""
    },
    {
        "msg": "NdcLayoutRenderer - Defer format to string",
        "diff": "diff --git a/src/NLog/LayoutRenderers/NdcLayoutRenderer.cs b/src/NLog/LayoutRenderers/NdcLayoutRenderer.cs @@ -77,7 +77,8 @@ public NdcLayoutRenderer()\n/// <param name=\"logEvent\">Logging event.</param>\nprotected override void Append(StringBuilder builder, LogEventInfo logEvent)\n{\n- string[] messages = NestedDiagnosticsContext.GetAllMessages(logEvent.FormatProvider);\n+ var messages = NestedDiagnosticsContext.GetAllObjects();\n+\nint startPos = 0;\nint endPos = messages.Length;\n@@ -90,12 +91,13 @@ protected override void Append(StringBuilder builder, LogEventInfo logEvent)\nstartPos = messages.Length - Math.Min(this.BottomFrames, messages.Length);\n}\n- string separator = string.Empty;\n+ string currentSeparator = string.Empty;\nfor (int i = endPos - 1; i >= startPos; --i)\n{\n- builder.Append(separator);\n- builder.Append(messages[i]);\n- separator = this.Separator;\n+ var stringValue = Internal.FormatHelper.ConvertToString(messages[i], logEvent.FormatProvider);\n+ builder.Append(currentSeparator);\n+ builder.Append(stringValue);\n+ currentSeparator = this.Separator;\n}\n}\n}\n",
        "lang": "C#",
        "chatgpt": "Refactor NdcLayoutRenderer to use objects instead of strings for NestedDiagnosticsContext messages."
    },
    {
        "msg": "Update rotate_texture.py",
        "diff": "diff --git a/examples/rotate_texture.py b/examples/rotate_texture.py @@ -5,11 +5,17 @@ from unreal_engine.classes import Texture2D\ndef rotate_selected_assets_data(degrees):\nfor asset in ue.get_selected_assets():\nif asset.is_a(Texture2D):\n- tex = ue.load_object(Texture2D, asset.get_path_name())\n- data = tex.texture_get_data()\n- size = (asset.Blueprint_GetSizeX(), asset.Blueprint_GetSizeY())\n-\n- img = Image.frombytes(\"RGB\", size, data)\n- img.show()\n- out = img.rotate(degrees, expand=1)\n- tex.texture_set_data(out.tobytes())\n+ data = asset.texture_get_source_data()\n+\n+ size = (asset.texture_get_width(), asset.texture_get_height())\n+\n+ img = Image.frombytes('RGBA', size, bytes(data))\n+\n+ out = img.rotate(degrees)\n+\n+ asset.texture_set_source_data(out.tobytes())\n+\n+\n+\n+\n+rotate_selected_assets_data(45)\n",
        "lang": "C++",
        "chatgpt": "\"Refactor rotate_selected_assets_data function to use texture_get_source_data and texture_set_source_data methods\""
    },
    {
        "msg": "node_manager_fkie: Tab and Backtab fixed",
        "diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/editor/text_edit.py b/node_manager_fkie/src/node_manager_fkie/editor/text_edit.py @@ -311,9 +311,10 @@ class TextEdit(QTextEdit):\n# handle the shifting of the block\nif event.modifiers() == Qt.NoModifier and event.key() == Qt.Key_Tab:\nself.shiftText()\n- elif event.modifiers() == Qt.ControlModifier and event.key() == Qt.Key_Tab:\n+ elif event.modifiers() == Qt.ShiftModifier and event.key() == Qt.Key_Backtab:\nself.shiftText(back=True)\nelse:\n+ event.accept()\nQTextEdit.keyPressEvent(self, event)\nelse:\nevent.accept()\n",
        "lang": "Python",
        "chatgpt": "Fix handling of Shift+Tab key combination in TextEdit class"
    },
    {
        "msg": "Add target_in_range test",
        "diff": "diff --git a/test/autotest_bot.py b/test/autotest_bot.py @@ -251,20 +251,22 @@ class TestBot(sc2.BotAI):\n# Test unit.py\nasync def test_unit(self):\n- scv = self.workers.random\n-\n- assert scv.type_id == UnitTypeId.SCV\n- assert scv._type_data == self._game_data.units[UnitTypeId.SCV.value]\n- assert scv.alliance == Alliance.Self.value\n- assert scv.is_mine == True\n- assert isinstance(scv.position, Point2)\n- assert isinstance(scv.position3d, Point3)\n- assert scv.health == 45\n- assert scv.health_max == 45\n- assert scv.health_percentage == 45/45\n- assert scv.energy == 0\n- assert scv.energy_max == 0\n- assert scv.energy_percentage == 0\n+ scv1, scv2, scv3 = self.workers[:3]\n+\n+ assert scv1.type_id == UnitTypeId.SCV\n+ assert scv1._type_data == self._game_data.units[UnitTypeId.SCV.value]\n+ assert scv1.alliance == Alliance.Self.value\n+ assert scv1.is_mine == True\n+ assert isinstance(scv1.position, Point2)\n+ assert isinstance(scv1.position3d, Point3)\n+ assert scv1.health == 45\n+ assert scv1.health_max == 45\n+ assert scv1.health_percentage == 45/45\n+ assert scv1.energy == 0\n+ assert scv1.energy_max == 0\n+ assert scv1.energy_percentage == 0\n+ assert not scv1.target_in_range(self.workers.tags_not_in({scv1.tag}).furthest_to(scv1.position))\n+ assert scv1.target_in_range(scv1)\n# Test units.py\nasync def test_units(self):\n",
        "lang": "Python",
        "chatgpt": "Refactor test_unit method to include additional assertions and target_in_range checks"
    },
    {
        "msg": "Refactoring post workflow manager",
        "diff": "diff --git a/modules/airavata-helix/helix-spectator/src/main/java/org/apache/airavata/helix/impl/workflow/PostWorkflowManager.java b/modules/airavata-helix/helix-spectator/src/main/java/org/apache/airavata/helix/impl/workflow/PostWorkflowManager.java @@ -140,12 +140,37 @@ public class PostWorkflowManager extends WorkflowManager {\nif (jobStatusResult.getState() == JobState.COMPLETE || jobStatusResult.getState() == JobState.FAILED) {\n// if the job is FAILED, still run output staging tasks to debug the reason for failure. And update\n// the experiment status as COMPLETED as this job failure is not related to Airavata scope.\n-\nlogger.info(\"Starting the post workflow for job id : \" + jobStatusResult.getJobId() + \" with process id \"\n+ processId + \", gateway \" + gateway + \" and status \" + jobStatusResult.getState().name());\nlogger.info(\"Job \" + jobStatusResult.getJobId() + \" was completed\");\n+ executePostWorkflow(processId, gateway);\n+\n+ } else if (jobStatusResult.getState() == JobState.CANCELED) {\n+ logger.info(\"Job \" + jobStatusResult.getJobId() + \" was externally cancelled but process is not marked as cancelled yet\");\n+ MonitoringUtil.registerCancelProcess(getCuratorClient(), processId);\n+ publishProcessStatus(processId, experimentId,gateway, ProcessState.CANCELED);\n+ logger.info(\"Marked process \" + processId + \" of experiment \" + experimentId + \" as cancelled as job is already being cancelled\");\n+\n+ } else if (jobStatusResult.getState() == JobState.SUBMITTED) {\n+ logger.info(\"Job \" + jobStatusResult.getJobId() + \" was submitted\");\n+\n+ }\n+ }\n+ return true;\n+ } else {\n+ logger.warn(\"Could not find a monitoring register for job id \" + jobStatusResult.getJobId());\n+ return false;\n+ }\n+ } catch (Exception e) {\n+ logger.error(\"Failed to process job : \" + jobStatusResult.getJobId() + \", with status : \" + jobStatusResult.getState().name(), e);\n+ return false;\n+ }\n+ }\n+\n+ private void executePostWorkflow(String processId, String gateway) throws Exception {\n+\nRegistryService.Client registryClient = getRegistryClientPool().getResource();\nProcessModel processModel;\n@@ -225,26 +250,6 @@ public class PostWorkflowManager extends WorkflowManager {\n\"This will affect cancellation tasks\", e);\n}\n- } else if (jobStatusResult.getState() == JobState.CANCELED) {\n- logger.info(\"Job \" + jobStatusResult.getJobId() + \" was externally cancelled but process is not marked as cancelled yet\");\n- MonitoringUtil.registerCancelProcess(getCuratorClient(), processId);\n- publishProcessStatus(processId, experimentId,gateway, ProcessState.CANCELED);\n- logger.info(\"Marked process \" + processId + \" of experiment \" + experimentId + \" as cancelled as job is already being cancelled\");\n-\n- } else if (jobStatusResult.getState() == JobState.SUBMITTED) {\n- logger.info(\"Job \" + jobStatusResult.getJobId() + \" was submitted\");\n-\n- }\n- }\n- return true;\n- } else {\n- logger.warn(\"Could not find a monitoring register for job id \" + jobStatusResult.getJobId());\n- return false;\n- }\n- } catch (Exception e) {\n- logger.error(\"Failed to process job : \" + jobStatusResult.getJobId() + \", with status : \" + jobStatusResult.getState().name(), e);\n- return false;\n- }\n}\nprivate void runConsumer() throws ApplicationSettingsException {\n",
        "lang": "Java",
        "chatgpt": "Refactor PostWorkflowManager to handle job cancellation and submission states"
    },
    {
        "msg": "Fix up deckbuilder page eslint.",
        "diff": "diff --git a/src/pages/CubeDeckbuilderPage.js b/src/pages/CubeDeckbuilderPage.js @@ -16,7 +16,7 @@ import TextEntry from 'components/TextEntry';\nimport CubeLayout from 'layouts/CubeLayout';\nimport { subtitle } from 'pages/CubeDraftPage';\n-const canDrop = (source, target) => true;\n+const canDrop = () => true;\nconst oppositeLocation = {\n[Location.DECK]: Location.SIDEBOARD,\n@@ -27,12 +27,12 @@ const makeInitialStacks = (playerDeck) => {\nif (playerDeck.length === 2 && Array.isArray(playerDeck[0]) && Array.isArray(playerDeck[0][0])) {\n// Already good.\nreturn playerDeck;\n- } else if (playerDeck.length === 16) {\n+ }\n+ if (playerDeck.length === 16) {\n// Already in stacks. Split into rows.\nreturn [playerDeck.slice(0, 8), playerDeck.slice(8, 16)];\n- } else {\n- return sortDeck(playerDeck);\n}\n+ return sortDeck(playerDeck);\n};\nconst CubeDeckbuilderPage = ({ cube, cubeID, initialDeck, basics }) => {\n@@ -41,9 +41,8 @@ const CubeDeckbuilderPage = ({ cube, cubeID, initialDeck, basics }) => {\nconst initial = initialDeck.playersideboard;\nif (!initial || !Array.isArray(initial) || initial.length === 0) {\nreturn [new Array(8).fill([])];\n- } else {\n- return [initialDeck.playersideboard.slice(0, 8)];\n}\n+ return [initialDeck.playersideboard.slice(0, 8)];\n});\nconst locationMap = {\n@@ -70,7 +69,7 @@ const CubeDeckbuilderPage = ({ cube, cubeID, initialDeck, basics }) => {\nconst handleClickCard = useCallback(\n(event) => {\nevent.preventDefault();\n- /* global */ autocard_hide_card();\n+ /* eslint-disable-line no-undef */ autocard_hide_card();\nconst eventTarget = event.currentTarget;\nconst locationType = eventTarget.getAttribute('data-location-type');\nconst locationData = JSON.parse(eventTarget.getAttribute('data-location-data'));\n@@ -102,7 +101,7 @@ const CubeDeckbuilderPage = ({ cube, cubeID, initialDeck, basics }) => {\nconst currentDeck = { ...initialDeck };\ncurrentDeck.playerdeck = [...deck[0], ...deck[1]];\n- currentDeck.playersideboard = sideboard[0];\n+ [currentDeck.playersideboard] = sideboard;\nconst [name, setName] = useState(initialDeck.name);\nconst [description, setDescription] = useState(initialDeck.description);\n@@ -134,7 +133,7 @@ const CubeDeckbuilderPage = ({ cube, cubeID, initialDeck, basics }) => {\ntype=\"text\"\nvalue={name}\nonChange={(e) => setName(e.target.value)}\n- ></input>\n+ />\n<br />\n<h6>Description</h6>\n@@ -172,8 +171,13 @@ const CubeDeckbuilderPage = ({ cube, cubeID, initialDeck, basics }) => {\n};\nCubeDeckbuilderPage.propTypes = {\n+ basics: PropTypes.objectOf(PropTypes.string).isRequired,\n+ cube: PropTypes.shape({}).isRequired,\n+ cubeID: PropTypes.string.isRequired,\ninitialDeck: PropTypes.shape({\n_id: PropTypes.string.isRequired,\n+ name: PropTypes.string,\n+ description: PropTypes.string,\nplayerdeck: PropTypes.arrayOf(PropTypes.arrayOf(PropTypes.object)).isRequired,\nplayersideboard: PropTypes.arrayOf(PropTypes.arrayOf(PropTypes.object)).isRequired,\n}).isRequired,\n",
        "lang": "JavaScript",
        "chatgpt": "Refactor CubeDeckbuilderPage.js to improve code readability and maintainability."
    },
    {
        "msg": "moved constant definitions outside the function",
        "diff": "diff --git a/src/components/Markdown.js b/src/components/Markdown.js @@ -148,11 +148,22 @@ const renderCardrow = (node) => {\nreturn <Row className=\"cardRow\">{node.children}</Row>;\n};\n-const Markdown = ({ markdown, limited }) => {\n- const validSymbols = 'wubrgcmtsqepxyz/-0123456789';\n- const markdownStr = markdown?.toString() ?? '';\n+const VALID_SYMBOLS = 'wubrgcmtsqepxyz/-0123456789';\n+\n+const BASE_PLUGINS = [\n+ cardrow,\n+ centering,\n+ breaks,\n+ math,\n+ userlink,\n+ cardlink,\n+ [gfm, { singleTilde: false }],\n+ [symbols, { allowed: VALID_SYMBOLS }],\n+];\n+\n+const ALL_PLUGINS = [...BASE_PLUGINS, slug, headings];\n- const renderers = {\n+const RENDERERS = {\n// overridden defaults\nlink: renderLink,\nlinkReference: renderLink,\n@@ -173,23 +184,11 @@ const Markdown = ({ markdown, limited }) => {\ncardrow: renderCardrow,\n};\n- const plugins = [\n- cardrow,\n- centering,\n- breaks,\n- math,\n- userlink,\n- cardlink,\n- [gfm, { singleTilde: false }],\n- [symbols, { allowed: validSymbols }],\n- ];\n-\n- if (!limited) {\n- plugins.push(slug, headings);\n- }\n+const Markdown = ({ markdown, limited }) => {\n+ const markdownStr = markdown?.toString() ?? '';\nreturn (\n- <ReactMarkdown className=\"markdown\" plugins={plugins} renderers={renderers}>\n+ <ReactMarkdown className=\"markdown\" plugins={limited ? BASE_PLUGINS : ALL_PLUGINS} renderers={RENDERERS}>\n{markdownStr}\n</ReactMarkdown>\n);\n",
        "lang": "JavaScript",
        "chatgpt": "Refactor Markdown component to use constant arrays for plugins and renderers. Update ReactMarkdown component to dynamically choose plugins based on 'limited' prop."
    },
    {
        "msg": "Added the new google analytics ID for CSBG LSU",
        "diff": "diff --git a/dev-tools/ansible/inventories/scigap/production/pga_config/csbglsu/vars.yml b/dev-tools/ansible/inventories/scigap/production/pga_config/csbglsu/vars.yml @@ -58,5 +58,5 @@ portal_email_password: \"{{ vault_portal_email_password }}\"\n#portal_theme: \"gsu-gateway-theme\"\n#portal_theme_repo: \"https://github.com/SciGaP/gsu-gateway-theme\"\nportal_title: \"LSU Computational Sys Biology\"\n-pga_google_analytics_id: \"UA-111528347-5\"\n+pga_google_analytics_id: \"UA-117484529-1\"\n...\n",
        "lang": "Java",
        "chatgpt": "Update Google Analytics ID for LSU Computational Sys Biology portal"
    },
    {
        "msg": "Add resource subtraction on action execute attempt",
        "diff": "diff --git a/sc2/bot_ai.py b/sc2/bot_ai.py @@ -328,6 +328,11 @@ class BotAI(object):\nreturn r\nasync def do_actions(self, actions):\n+ for action in actions:\n+ cost = self._game_data.calculate_ability_cost(action.ability)\n+ self.minerals -= cost.minerals\n+ self.vespene -= cost.vespene\n+\nr = await self._client.actions(actions, game_data=self._game_data)\nreturn r\n",
        "lang": "Python",
        "chatgpt": "\"Subtract ability cost from resources in do_actions method\""
    },
    {
        "msg": "Log player scores",
        "diff": "diff --git a/sc2/main.py b/sc2/main.py @@ -97,6 +97,8 @@ async def _play_game_ai(client, player_id, ai, realtime, step_time_limit, game_t\niteration = 0\nwhile True:\nstate = await client.observation()\n+ logger.debug(f\"Score: {state.observation.observation.score.score}\")\n+\nif client._game_result:\nai.on_end(client._game_result[player_id])\nreturn client._game_result[player_id]\n",
        "lang": "Python",
        "chatgpt": "Add debug logging for score in game loop"
    },
    {
        "msg": "LogFactory - Ensure to flush and close on shutdown (Code Layout)",
        "diff": "diff --git a/src/NLog/LogFactory.cs b/src/NLog/LogFactory.cs @@ -886,6 +886,8 @@ internal LoggerConfiguration GetConfigurationForLogger(string name, LoggingConfi\nthis.GetTargetsByLevelForLogger(name, configuration.LoggingRules, targetsByLevel, lastTargetsByLevel, suppressedLevels);\n}\n+ if (InternalLogger.IsDebugEnabled)\n+ {\nInternalLogger.Debug(\"Targets for {0} by level:\", name);\nfor (int i = 0; i <= LogLevel.MaxLevel.Ordinal; ++i)\n{\n@@ -902,6 +904,7 @@ internal LoggerConfiguration GetConfigurationForLogger(string name, LoggingConfi\nInternalLogger.Debug(sb.ToString());\n}\n+ }\n#pragma warning disable 618\nreturn new LoggerConfiguration(targetsByLevel, configuration != null && configuration.ExceptionLoggingOldStyle);\n@@ -988,16 +991,6 @@ private void Close(TimeSpan flushTimeout)\n}\nthis.ConfigurationChanged = null; // Release event listeners\n-\n- var activeAppDomain = currentAppDomain;\n- if (activeAppDomain != null)\n- {\n- // No longer belongs to the AppDomain\n- CurrentAppDomain = null;\n-#if !SILVERLIGHT && !__IOS__ && !__ANDROID__\n- activeAppDomain.DomainUnload -= this.DomainUnload;\n-#endif\n- }\n}\n/// <summary>\n@@ -1020,8 +1013,13 @@ internal void Shutdown()\n{\nvar loadedConfig = Configuration;\nif (loadedConfig != null)\n+ {\n+ ManualResetEvent flushCompleted = new ManualResetEvent(false);\n+ loadedConfig.FlushAllTargets((ex) => flushCompleted.Set());\n+ flushCompleted.WaitOne(DefaultFlushTimeout);\nloadedConfig.Close();\n}\n+ }\nInternalLogger.Info(\"Logger has been closed down.\");\n}\n@@ -1251,23 +1249,6 @@ private void ConfigFileChanged(object sender, EventArgs args)\n}\n}\n}\n-\n- private void DomainUnload(object sender, EventArgs e)\n- {\n- //stop timer on domain unload, otherwise:\n- //Exception: System.AppDomainUnloadedException\n- //Message: Attempted to access an unloaded AppDomain.\n- try\n- {\n- Dispose();\n- }\n- catch (Exception ex)\n- {\n- if (ex.MustBeRethrownImmediately())\n- throw;\n- InternalLogger.Error(ex, \"LogFactory failed to shut down properly.\");\n- }\n- }\n#endif\n/// <summary>\n/// Logger cache key.\n@@ -1435,20 +1416,36 @@ private static void UnregisterEvents(IAppDomain appDomain)\n}\nprivate static void OnLoggerShutdown(object sender, EventArgs args)\n+ {\n+ try\n{\nvar loggerShutdown = LoggerShutdown;\nif (loggerShutdown != null)\nloggerShutdown.Invoke(sender, args);\n+ }\n+ catch (Exception ex)\n+ {\n+ if (ex.MustBeRethrownImmediately())\n+ throw;\n+ InternalLogger.Error(ex, \"LogFactory failed to shut down properly.\");\n+ }\n+ finally\n+ {\n+ LoggerShutdown = null;\nif (currentAppDomain != null)\n{\nCurrentAppDomain = null; // Unregister and disconnect from AppDomain\n}\n}\n+ }\nprivate void OnStopLogging(object sender, EventArgs args)\n{\ntry\n{\n+ //stop timer on domain unload, otherwise:\n+ //Exception: System.AppDomainUnloadedException\n+ //Message: Attempted to access an unloaded AppDomain.\nInternalLogger.Info(\"Shutting down logging...\");\n// Finalizer thread has about 2 secs, before being terminated\nthis.Close(TimeSpan.FromMilliseconds(1500));\n",
        "lang": "C#",
        "chatgpt": "Refactor logging shutdown process and add debug log message for targets by level."
    },
    {
        "msg": "Improve actions and bot_ai",
        "diff": "diff --git a/sc2/client.py b/sc2/client.py @@ -150,11 +150,10 @@ class Client(Protocol):\nres = await self._execute(\naction=sc_pb.RequestAction(actions=(sc_pb.Action(action_raw=a) for a in combine_actions(actions)))\n)\n- result = [ActionResult(r) for r in res.action.result]\nif return_successes:\n- return result\n+ return [ActionResult(r) for r in res.action.result]\nelse:\n- return [r for r in result if r != ActionResult.Success]\n+ return [ActionResult(r) for r in res.action.result if ActionResult(r) != ActionResult.Success]\nasync def query_pathing(\nself, start: Union[Unit, Point2, Point3], end: Union[Point2, Point3]\n",
        "lang": "Python",
        "chatgpt": "Refactor client.py to return only successful ActionResult objects in query_pathing method"
    },
    {
        "msg": "Fix serverjs issue.",
        "diff": "diff --git a/serverjs/cards.js b/serverjs/cards.js @@ -114,15 +114,14 @@ function unloadCardDb() {\n}\n}\n-module.exports = {\n- ...data,\n- cardFromId,\n- getCardDetails,\n- normalizedName: card => card.name.toLowerCase().normalize(\"NFD\").replace(/[\\u0300-\\u036f]/g, \"\").trim(),\n- allIds: card => data.nameToId[data.normalizedName(card)],\n- initializeCardDb,\n- loadJSONFile,\n- getPlaceholderCard,\n- unloadCardDb,\n- allCards: () => Object.values(data._carddict),\n-};\n\\ No newline at end of file\n+data.cardFromId = cardFromId;\n+data.getCardDetails = getCardDetails;\n+data.normalizedName = card => card.name.toLowerCase().normalize(\"NFD\").replace(/[\\u0300-\\u036f]/g, \"\").trim();\n+data.allIds = card => data.nameToId[data.normalizedName(card)];\n+data.allCards = () => Object.values(data._carddict);\n+data.initializeCardDb = initializeCardDb;\n+data.loadJSONFile = loadJSONFile;\n+data.getPlaceholderCard = getPlaceholderCard;\n+data.unloadCardDb = unloadCardDb;\n+\n+module.exports = data;\n\\ No newline at end of file\n",
        "lang": "JavaScript",
        "chatgpt": "Refactor exports in cards.js for better organization and clarity"
    },
    {
        "msg": "fkie_node_manager_daemon: changed absolute path while remote start of nodes",
        "diff": "diff --git a/fkie_node_manager_daemon/src/fkie_node_manager_daemon/launcher.py b/fkie_node_manager_daemon/src/fkie_node_manager_daemon/launcher.py @@ -332,7 +332,7 @@ def _load_parameters(masteruri, params, clear_params):\nfor pkey, pval in params.items():\nvalue = pval\n# resolve path elements\n- if isinstance(value, types.StringTypes) and (value.startswith('$') or value.startswith('pkg://')):\n+ if isinstance(value, types.StringTypes) and (value.startswith('$')):\nvalue = interpret_path(value)\nrospy.logdebug(\"interpret parameter '%s' to '%s'\" % (value, pval))\n# add parameter to the multicall\n@@ -346,6 +346,8 @@ def _load_parameters(masteruri, params, clear_params):\nraise exceptions.StartException(\"Failed to set parameter: %s\" % (msg))\nexcept roslaunch.core.RLException, e:\nraise exceptions.StartException(e)\n+ except rospkg.ResourceNotFound as rnf:\n+ raise exceptions.StartException(\"Failed to set parameter. ResourceNotFound: %s\" % (rnf))\nexcept Exception as e:\nraise exceptions.StartException(\"Failed to set parameter. ROS Parameter Server \"\n\"reports: %s\\n\\n%s\" % (e, '\\n'.join(param_errors)))\n@@ -377,7 +379,7 @@ def _abs_to_package_path(path):\nresult = path\npname, ppath = package_name(path)\nif pname is not None:\n- result = path.replace(ppath, 'pkg://%s' % pname)\n+ result = path.replace(ppath, '$(find %s)' % pname)\nrospy.logdebug(\"replace abs path '%s' by '%s'\" % (path, result))\nreturn result\n",
        "lang": "Python",
        "chatgpt": "Refactor path resolution in launcher.py and handle ResourceNotFound exception"
    },
    {
        "msg": "Kill mongo warnings.",
        "diff": "diff --git a/app.js b/app.js @@ -22,6 +22,7 @@ const carddb = require('./serverjs/cards.js');\nconst errorFile = tmp.fileSync({ prefix: `node-error-${process.pid}-`, postfix: '.log', discardDescriptor: true });\nconst combinedFile = tmp.fileSync({ prefix: `node-combined-${process.pid}-`, postfix: '.log', discardDescriptor: true });\n+console.log(`Logging to ${errorFile.name} and ${combinedFile.name}`);\nconst logger = winston.createLogger({\nlevel: 'info',\n@@ -46,7 +47,11 @@ if (process.env.NODE_ENV !== 'production') {\ncarddb.initializeCardDb();\n// Connect db\n-mongoose.connect(mongosecrets.connectionString);\n+mongoose.connect(mongosecrets.connectionString, {\n+ useCreateIndex: true,\n+ useNewUrlParser: true,\n+ useUnifiedTopology: true,\n+});\nconst db = mongoose.connection;\ndb.once('open', () => {\nlogger.info('Connected to Mongo.');\n",
        "lang": "JavaScript",
        "chatgpt": "Add logging for error and combined files, update mongoose connection options."
    },
    {
        "msg": "htmldecode book title (probably needed lots of other places?)",
        "diff": "diff --git a/src/DataSources/Secondary/Goodreads.cs b/src/DataSources/Secondary/Goodreads.cs using System.Collections.Generic;\nusing System.Globalization;\nusing System.Linq;\n+using System.Net;\nusing System.Text.RegularExpressions;\nusing System.Threading;\nusing System.Threading.Tasks;\n@@ -131,6 +132,7 @@ async Task<BookInfo> ParseSeriesBook(HtmlNode bookNode)\nBookInfo book = new BookInfo(\"\", \"\", \"\");\nvar title = bookNode.SelectSingleNode(\".//div[@class='u-paddingBottomXSmall']/a\");\nbook.Title = Regex.Replace(title.InnerText.Trim(), @\" \\(.*\\)\", \"\", RegexOptions.Compiled);\n+ book.Title = WebUtility.HtmlDecode(book.Title);\nbook.GoodreadsId = ParseBookId(title.GetAttributeValue(\"href\", \"\"));\n// TODO: move this ASIN search somewhere else\nif (!string.IsNullOrEmpty(book.GoodreadsId))\n",
        "lang": "C#",
        "chatgpt": "Decode HTML entities in book title before assigning to BookInfo"
    },
    {
        "msg": "node_manager_fkie: added log for start and wait for ROS master at the beginning",
        "diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/start_handler.py b/node_manager_fkie/src/node_manager_fkie/start_handler.py @@ -593,8 +593,15 @@ class StartHandler(object):\nif ros_hostname:\nnew_env['ROS_HOSTNAME'] = ros_hostname\ncmd_args = '%s roscore --port %d' % (nm.ScreenHandler.getSceenCmd('/roscore--%d' % master_port), master_port)\n+ for n in [1, 2, 3, 4]:\ntry:\n+ if n == 1:\n+ print(\"Launch ROS Master in screen ...\")\nSupervisedPopen(shlex.split(cmd_args), env=new_env, object_id=\"ROSCORE\", description=\"Start roscore\")\n+ elif n == 2:\n+ print(\"ROS Master takes too long for start, wait for next 10 sec ...\")\n+ elif n == 3:\n+ print(\"A really slow start, wait for last 10 sec ...\")\n# wait for roscore to avoid connection problems while init_node\nresult = -1\ncount = 1\n@@ -602,11 +609,12 @@ class StartHandler(object):\ntry:\nmaster = xmlrpclib.ServerProxy(masteruri)\nresult, _, _ = master.getUri(rospy.get_name()) # _:=uri, msg\n- except:\n+ return\n+ except Exception:\ntime.sleep(1)\ncount += 1\n- if count >= 11:\n- raise StartException('Cannot connect to the ROS-Master: ' + utf8(masteruri))\n+ if n == 4 and count >= 11:\n+ raise StartException('Cannot connect to ROS-Master: %s\\n--> please run \"roscore\" manually!' % utf8(masteruri))\nexcept Exception as e:\nraise Exception(\"Error while call '%s': %s\" % (cmd_args, utf8(e)))\nelse:\n",
        "lang": "Python",
        "chatgpt": "Improve handling of ROS Master startup in StartHandler"
    },
    {
        "msg": "node_manager_fkie: changed -T to --title for terminal title",
        "diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/settings.py b/node_manager_fkie/src/node_manager_fkie/settings.py @@ -169,6 +169,7 @@ class Settings(object):\nself._terminal_emulator = None\nself._terminal_command_arg = 'e'\nself._noclose_str = '-hold'\n+ self._terminal_title = '--title'\nself._masteruri = masteruri_from_ros()\nself.CFG_PATH = os.path.join(get_ros_home(), 'node_manager')\n# loads the current configuration path. If the path was changed, a redirection\n@@ -692,12 +693,13 @@ class Settings(object):\n\"be then load by node_manager.\")\nelif os.path.basename(os.path.realpath(t)) in ['xfce4-terminal']:\nself._noclose_str = ''\n+ self._terminal_title = '-T'\nself._terminal_emulator = t\nbreak\nif self._terminal_emulator == \"\":\nraise Exception(\"No Terminal found! Please install one of ['/usr/bin/x-terminal-emulator', '/usr/bin/xterm', '/opt/x11/bin/xterm']\")\nself._noclose_str = self._noclose_str if noclose else \"\"\n- return '%s -T \"%s\" %s -%s %s' % (self._terminal_emulator, title, self._noclose_str, self._terminal_command_arg, ' '.join(cmd))\n+ return '%s %s \"%s\" %s -%s %s' % (self._terminal_emulator, self._terminal_title, title, self._noclose_str, self._terminal_command_arg, ' '.join(cmd))\ndef qsettings(self, settings_file):\nfrom python_qt_binding.QtCore import QSettings\n",
        "lang": "Python",
        "chatgpt": "Add terminal title option to settings for customizing terminal title."
    },
    {
        "msg": "fixed bug which caused infinite load screen",
        "diff": "diff --git a/src/components/FilterCollapse.js b/src/components/FilterCollapse.js @@ -445,6 +445,10 @@ class FilterCollapse extends Component {\n}\nasync updateFilters(overrideFilter) {\n+ if (Query.get('f') === this.state.filterInput) {\n+ return;\n+ }\n+\nconst filterInput = overrideFilter ?? this.state.filterInput;\nif ((filterInput ?? '') === '') {\nthis.props.setFilter(null, '');\n",
        "lang": "JavaScript",
        "chatgpt": "Prevent unnecessary filter updates if filter input has not changed"
    },
    {
        "msg": "remove the judgy comment regarding spin bit\nSummary:\nas title\n(Note: this ignores all push blocking failures!)",
        "diff": "diff --git a/quic/codec/Types.h b/quic/codec/Types.h @@ -691,9 +691,8 @@ struct ShortHeaderInvariant {\nstruct ShortHeader {\npublic:\n+ // There is also a spin bit which is 0x20 that we don't currently implement.\nstatic constexpr uint8_t kFixedBitMask = 0x40;\n- // There is also a spin bit which is 0x20, but as a decent implementation of\n- // course we don't implement that.\nstatic constexpr uint8_t kReservedBitsMask = 0x18;\nstatic constexpr uint8_t kKeyPhaseMask = 0x04;\nstatic constexpr uint8_t kPacketNumLenMask = 0x03;\n",
        "lang": "C++",
        "chatgpt": "Remove unnecessary comment and update ShortHeader class with fixed bit mask."
    },
    {
        "msg": "Squash easy errors in users_routes.",
        "diff": "diff --git a/routes/users_routes.js b/routes/users_routes.js const express = require('express');\n+\nconst router = express.Router();\nconst bcrypt = require('bcryptjs');\nconst passport = require('passport');\n-const emailconfig = require('../../cubecobrasecrets/email');\nconst mailer = require('nodemailer');\nconst fs = require('fs');\n+const emailconfig = require('../../cubecobrasecrets/email');\nconst util = require('../serverjs/util.js');\n// Bring in models\n-let User = require('../models/user');\n-let PasswordReset = require('../models/passwordreset');\n-let Cube = require('../models/cube');\n-let Deck = require('../models/deck');\n+const User = require('../models/user');\n+const PasswordReset = require('../models/passwordreset');\n+const Cube = require('../models/cube');\n+const Deck = require('../models/deck');\nconst { ensureAuth, csrfProtection } = require('./middleware');\n@@ -110,11 +111,11 @@ router.get('/follow/:id', ensureAuth, async (req, res) => {\nuser.followed_users.push(other._id);\n}\n- await util.addNotification(other, user, '/user/view/' + user._id, user.username + ' has followed you!');\n+ await util.addNotification(other, user, `/user/view/${user._id}`, `${user.username} has followed you!`);\nawait Promise.all([user.save(), other.save()]);\n- return res.redirect('/user/view/' + req.params.id);\n+ return res.redirect(`/user/view/${req.params.id}`);\n} catch (err) {\nres.status(500).send({\nsuccess: 'false',\n@@ -149,7 +150,7 @@ router.get('/unfollow/:id', ensureAuth, async (req, res) => {\nawait Promise.all([user.save(), other.save()]);\n- return res.redirect('/user/view/' + req.params.id);\n+ return res.redirect(`/user/view/${req.params.id}`);\n} catch (err) {\nres.status(500).send({\nsuccess: 'false',\n@@ -163,11 +164,11 @@ router.post('/lostpassword', function(req, res) {\nreq.checkBody('email', 'Email is required').notEmpty();\n// handle error checks\n- let errors = req.validationErrors();\n+ const errors = req.validationErrors();\nif (errors) {\nres.render('user/lostpassword', {\n- errors: errors,\n+ errors,\n});\n} else {\nPasswordReset.deleteOne(\n@@ -175,7 +176,7 @@ router.post('/lostpassword', function(req, res) {\nemail: req.body.email.toLowerCase(),\n},\nfunction(err) {\n- let passwordReset = new PasswordReset();\n+ const passwordReset = new PasswordReset();\npasswordReset.expires = addMinutes(Date.now(), 15);\npasswordReset.email = req.body.email;\npasswordReset.code = Math.floor(1000000000 + Math.random() * 9000000000);\n@@ -185,7 +186,7 @@ router.post('/lostpassword', function(req, res) {\nconsole.error(err);\n} else {\n// Use Smtp Protocol to send Email\n- var smtpTransport = mailer.createTransport({\n+ const smtpTransport = mailer.createTransport({\nservice: 'Gmail',\nauth: {\nuser: emailconfig.username,\n@@ -193,27 +194,19 @@ router.post('/lostpassword', function(req, res) {\n},\n});\n- var mail = {\n+ const mail = {\nfrom: 'Cube Cobra Team <support@cubecobra.com>',\nto: passwordReset.email,\nsubject: 'Password Reset',\nhtml:\n- 'A password reset was requested for the account that belongs to this email.<br> To proceed, click <a href=\"https://cubecobra.com/user/passwordreset/' +\n- passwordReset._id +\n- '\">here</a>.<br> Your recovery code is: ' +\n- passwordReset.code +\n- '<br> This link expires in 15 minutes.' +\n- '<br> If you did not request a password reset, ignore this email.',\n+ `A password reset was requested for the account that belongs to this email.<br> To proceed, click <a href=\"https://cubecobra.com/user/passwordreset/${passwordReset._id}\">here</a>.<br> Your recovery code is: ${passwordReset.code}<br> This link expires in 15 minutes.` +\n+ `<br> If you did not request a password reset, ignore this email.`,\ntext:\n- 'A password reset was requested for the account that belongs to this email.\\nTo proceed, go to https://cubecobra.com/user/passwordreset/' +\n- passwordReset._id +\n- '\\nYour recovery code is: ' +\n- passwordReset.code +\n- '\\nThis link expires in 15 minutes.' +\n- '\\nIf you did not request a password reset, ignore this email.',\n+ `A password reset was requested for the account that belongs to this email.\\nTo proceed, go to https://cubecobra.com/user/passwordreset/${passwordReset._id}\\nYour recovery code is: ${passwordReset.code}\\nThis link expires in 15 minutes.` +\n+ `\\nIf you did not request a password reset, ignore this email.`,\n};\n- smtpTransport.sendMail(mail, function(err, response) {\n+ smtpTransport.sendMail(mail, (err, response) => {\nif (err) {\nconsole.error(err);\n}\n@@ -232,7 +225,7 @@ router.post('/lostpassword', function(req, res) {\nrouter.get('/passwordreset/:id', function(req, res) {\n// create a password reset page and return it here\n- PasswordReset.findById(req.params.id, function(err, passwordreset) {\n+ PasswordReset.findById(req.params.id, (err, passwordreset) => {\nif (!passwordreset || Date.now() > passwordreset.expires) {\nreq.flash('danger', 'Password recovery link expired');\nres.redirect('/');\n@@ -247,11 +240,11 @@ router.post('/lostpasswordreset', function(req, res) {\nmin: 8,\nmax: 24,\n});\n- let errors = req.validationErrors();\n+ const errors = req.validationErrors();\nif (errors) {\nres.render('user/passwordreset', {\n- errors: errors,\n+ errors,\n});\n} else {\nPasswordReset.findOne(\n@@ -259,7 +252,7 @@ router.post('/lostpasswordreset', function(req, res) {\ncode: req.body.code,\nemail: req.body.email,\n},\n- function(err, passwordreset) {\n+ (err, passwordreset) => {\nif (!passwordreset) {\nreq.flash('danger', 'Incorrect email and recovery code combination.');\nres.render('user/passwordreset');\n@@ -268,7 +261,7 @@ router.post('/lostpasswordreset', function(req, res) {\n{\nemail: req.body.email,\n},\n- function(err, user) {\n+ (err, user) => {\nif (err) {\nconsole.error('Password reset find user error:', err);\nres.sendStatus(500);\n@@ -284,13 +277,13 @@ router.post('/lostpasswordreset', function(req, res) {\nres.render('user/passwordreset');\nreturn;\n}\n- bcrypt.genSalt(10, function(err, salt) {\n+ bcrypt.genSalt(10, (err, salt) => {\nif (err) {\nconsole.error('Password reset genSalt error:', err);\nres.sendStatus(500);\nreturn;\n}\n- bcrypt.hash(req.body.password2, salt, function(err, hash) {\n+ bcrypt.hash(req.body.password2, salt, (err, hash) => {\nif (err) {\nconsole.error('Password reset hashing error:', err);\nres.sendStatus(500);\n@@ -324,13 +317,13 @@ router.get('/register', function(req, res) {\n// Register process\nrouter.post('/register', function(req, res) {\nconst email = req.body.email.toLowerCase();\n- const username = req.body.username;\n- const password = req.body.password;\n- const password2 = req.body.password2;\n+ const { username } = req.body;\n+ const { password } = req.body;\n+ const { password2 } = req.body;\n- let attempt = {\n- email: email,\n- username: username,\n+ const attempt = {\n+ email,\n+ username,\n};\nreq = checkUsernameValid(req);\n@@ -347,12 +340,12 @@ router.post('/register', function(req, res) {\nmin: 8,\nmax: 24,\n});\n- let errors = req.validationErrors();\n+ const errors = req.validationErrors();\nif (errors) {\nres.render('user/register', {\n- errors: errors,\n- attempt: attempt,\n+ errors,\n+ attempt,\nuser: null,\n});\n} else {\n@@ -360,11 +353,11 @@ router.post('/register', function(req, res) {\n{\nusername_lower: req.body.username.toLowerCase(),\n},\n- function(err, user) {\n+ (err, user) => {\nif (user) {\nreq.flash('danger', 'Username already taken.');\nres.render('user/register', {\n- attempt: attempt,\n+ attempt,\n});\n} else {\n// check if user exists\n@@ -372,23 +365,23 @@ router.post('/register', function(req, res) {\n{\nemail: req.body.email.toLowerCase(),\n},\n- function(err, user) {\n+ (err, user) => {\nif (user) {\nreq.flash('danger', 'Email already associated with an existing account.');\nres.render('user/register', {\n- attempt: attempt,\n+ attempt,\n});\n} else {\n- let newUser = new User({\n- email: email,\n- username: username,\n+ const newUser = new User({\n+ email,\n+ username,\nusername_lower: username.toLowerCase(),\n- password: password,\n+ password,\nconfirm: 'false',\n});\n- bcrypt.genSalt(10, function(err, salt) {\n- bcrypt.hash(newUser.password, salt, function(err, hash) {\n+ bcrypt.genSalt(10, (err, salt) => {\n+ bcrypt.hash(newUser.password, salt, (err, hash) => {\nif (err) {\nconsole.error(err);\n} else {\n@@ -397,10 +390,9 @@ router.post('/register', function(req, res) {\nnewUser.save(function(err) {\nif (err) {\nconsole.error(err);\n- return;\n} else {\n// Use Smtp Protocol to send Email\n- var smtpTransport = mailer.createTransport({\n+ const smtpTransport = mailer.createTransport({\nname: 'CubeCobra.com',\nsecure: true,\nservice: 'Gmail',\n@@ -410,21 +402,12 @@ router.post('/register', function(req, res) {\n},\n});\n- var mail = {\n+ const mail = {\nfrom: 'Cube Cobra Team <support@cubecobra.com>',\nto: email,\nsubject: 'Confirm Account',\n- html:\n- 'Hi ' +\n- newUser.username +\n- ',</br> Thanks for joining! To confirm your email, click <a href=\"https://cubecobra.com/user/register/confirm/' +\n- newUser._id +\n- '\">here</a>.',\n- text:\n- 'Hi ' +\n- newUser.username +\n- ',\\nThanks for joining! To confirm your email, go to https://cubecobra.com/user/register/confirm/' +\n- newUser._id,\n+ html: `Hi ${newUser.username},</br> Thanks for joining! To confirm your email, click <a href=\"https://cubecobra.com/user/register/confirm/${newUser._id}\">here</a>.`,\n+ text: `Hi ${newUser.username},\\nThanks for joining! To confirm your email, go to https://cubecobra.com/user/register/confirm/${newUser._id}`,\n};\nsmtpTransport.sendMail(mail, function(error, response) {\n@@ -454,19 +437,18 @@ router.post('/register', function(req, res) {\n// Register confirm\nrouter.get('/register/confirm/:id', function(req, res) {\n- User.findById(req.params.id, function(err, user) {\n+ User.findById(req.params.id, (err, user) => {\nif (err) {\nreq.flash('danger', 'Invalid confirmation link.');\nres.redirect('/');\n- } else {\n- if (user.confirmed == 'true') {\n+ } else if (user.confirmed == 'true') {\nreq.flash('success', 'User already confirmed.');\nres.redirect('/user/login');\n} else {\n- let user = {\n+ const user = {\nconfirmed: 'true',\n};\n- let query = {\n+ const query = {\n_id: req.params.id,\n};\n@@ -480,7 +462,6 @@ router.get('/register/confirm/:id', function(req, res) {\n}\n});\n}\n- }\n});\n});\n@@ -497,7 +478,7 @@ router.post('/login', function(req, res, next) {\n{\nemail: req.body.username,\n},\n- function(err, user) {\n+ (err, user) => {\nif (!user) {\nreq.flash('danger', 'Incorrect username or email address.');\nres.redirect('/user/login');\n@@ -505,7 +486,7 @@ router.post('/login', function(req, res, next) {\nreq.body.username = user.username;\n// TODO: fix confirmation\nif (true || user.confirmed == 'true') {\n- var redirect = '/';\n+ let redirect = '/';\nif (req.body.loginCallback) {\nredirect = req.body.loginCallback;\n}\n@@ -528,14 +509,14 @@ router.post('/login', function(req, res, next) {\n{\nusername_lower: req.body.username,\n},\n- function(err, user) {\n+ (err, user) => {\nif (!user) {\nreq.flash('danger', 'Incorrect username or email address.');\nres.redirect('/user/login');\n} else {\n// TODO: fix confirmation\nif (true || user.confirmed == 'true') {\n- var redirect = '/';\n+ let redirect = '/';\nif (req.body.loginCallback) {\nredirect = req.body.loginCallback;\n}\n@@ -563,7 +544,7 @@ router.get('/logout', function(req, res) {\nrouter.get('/view/:id', async (req, res) => {\ntry {\n- var user;\n+ let user;\ntry {\nuser = await User.findById(req.params.id);\n} catch (err) {\n@@ -587,8 +568,8 @@ router.get('/view/:id', async (req, res) => {\nabout: user.about,\nid: user._id,\n},\n- cubes: cubes,\n- loginCallback: '/user/view/' + req.params.id,\n+ cubes,\n+ loginCallback: `/user/view/${req.params.id}`,\nfollowers: user.users_following.length,\nfollowing: req.user ? user.users_following.includes(req.user._id) : false,\n});\n@@ -599,7 +580,7 @@ router.get('/view/:id', async (req, res) => {\n});\nrouter.get('/decks/:userid', function(req, res) {\n- res.redirect('/user/decks/' + req.params.userid + '/0');\n+ res.redirect(`/user/decks/${req.params.userid}/0`);\n});\nrouter.get('/notifications', ensureAuth, async (req, res) => {\n@@ -621,8 +602,8 @@ router.get('/notifications', ensureAuth, async (req, res) => {\n2;\nrouter.get('/decks/:userid/:page', async (req, res) => {\ntry {\n- const userid = req.params.userid;\n- const page = req.params.page;\n+ const { userid } = req.params;\n+ const { page } = req.params;\nconst pagesize = 30;\nconst userq = User.findById(userid).exec();\n@@ -647,16 +628,16 @@ router.get('/decks/:userid/:page', async (req, res) => {\n}\nconst pages = [];\n- for (i = 0; i < numDecks / pagesize; i++) {\n+ for (let i = 0; i < numDecks / pagesize; i++) {\nif (page == i) {\npages.push({\n- url: '/user/decks/' + userid + '/' + i,\n+ url: `/user/decks/${userid}/${i}`,\ncontent: i + 1,\nactive: true,\n});\n} else {\npages.push({\n- url: '/user/decks/' + userid + '/' + i,\n+ url: `/user/decks/${userid}/${i}`,\ncontent: i + 1,\n});\n}\n@@ -669,9 +650,9 @@ router.get('/decks/:userid/:page', async (req, res) => {\nabout: user.about,\nid: user._id,\n},\n- loginCallback: '/user/decks/' + userid,\n- decks: decks ? decks : [],\n- pages: pages ? pages : null,\n+ loginCallback: `/user/decks/${userid}`,\n+ decks: decks || [],\n+ pages: pages || null,\n});\n} catch (err) {\nconsole.error(err);\n@@ -681,7 +662,7 @@ router.get('/decks/:userid/:page', async (req, res) => {\n// account page\nrouter.get('/account', ensureAuth, function(req, res) {\n- User.findById(req.user._id, function(err, user) {\n+ User.findById(req.user._id, (err, user) => {\nuser_limited = {\nusername: user.username,\nemail: user.email,\n@@ -698,7 +679,7 @@ router.get('/account', ensureAuth, function(req, res) {\n// account page, password reset\nrouter.get('/account/changepassword', ensureAuth, function(req, res) {\n- User.findById(req.user._id, function(err, user) {\n+ User.findById(req.user._id, (err, user) => {\nuser_limited = {\nusername: user.username,\nemail: user.email,\n@@ -715,7 +696,7 @@ router.get('/account/changepassword', ensureAuth, function(req, res) {\n// account page, password reset\nrouter.get('/account/updateemail', ensureAuth, function(req, res) {\n- User.findById(req.user._id, function(err, user) {\n+ User.findById(req.user._id, (err, user) => {\nuser_limited = {\nusername: user.username,\nemail: user.email,\n@@ -736,10 +717,10 @@ router.post('/resetpassword', ensureAuth, function(req, res, next) {\nmax: 24,\n});\n- let errors = req.validationErrors();\n+ const errors = req.validationErrors();\nif (errors) {\n- User.findById(req.user._id, function(err, user) {\n+ User.findById(req.user._id, (err, user) => {\nuser_limited = {\nusername: user.username,\nemail: user.email,\n@@ -748,24 +729,24 @@ router.post('/resetpassword', ensureAuth, function(req, res, next) {\nres.render('user/user_account', {\nselected: 'changepw',\nuser: user_limited,\n- errors: errors,\n+ errors,\nloginCallback: '/user/account/changepassword',\n});\n});\n} else {\n- User.findById(req.user._id, function(err, user) {\n+ User.findById(req.user._id, (err, user) => {\nif (user) {\n- bcrypt.compare(req.body.password, user.password, function(err, isMatch) {\n+ bcrypt.compare(req.body.password, user.password, (err, isMatch) => {\nif (!isMatch) {\nreq.flash('danger', 'Password is incorrect');\nreturn res.redirect('/user/account/changepassword');\n- } else {\n+ }\nif (req.body.password2 != req.body.password3) {\nreq.flash('danger', \"New passwords don't match\");\nreturn res.redirect('/user/account/changepassword');\n- } else {\n- bcrypt.genSalt(10, function(err, salt) {\n- bcrypt.hash(req.body.password2, salt, function(err, hash) {\n+ }\n+ bcrypt.genSalt(10, (err, salt) => {\n+ bcrypt.hash(req.body.password2, salt, (err, hash) => {\nif (err) {\nconsole.error(err);\n} else {\n@@ -773,7 +754,6 @@ router.post('/resetpassword', ensureAuth, function(req, res, next) {\nuser.save(function(err) {\nif (err) {\nconsole.error(err);\n- return;\n} else {\nreq.flash('success', 'Password updated succesfully');\nreturn res.redirect('/user/account/changepassword');\n@@ -782,8 +762,6 @@ router.post('/resetpassword', ensureAuth, function(req, res, next) {\n}\n});\n});\n- }\n- }\n});\n}\n});\n@@ -791,7 +769,7 @@ router.post('/resetpassword', ensureAuth, function(req, res, next) {\n});\nrouter.post('/updateuserinfo', ensureAuth, function(req, res, next) {\n- User.findById(req.user._id, function(err, user) {\n+ User.findById(req.user._id, (err, user) => {\nif (user) {\nUser.findOne(\n{\n@@ -800,28 +778,28 @@ router.post('/updateuserinfo', ensureAuth, function(req, res, next) {\n$ne: req.user._id,\n},\n},\n- function(err, duplicate_user) {\n+ (err, duplicate_user) => {\nif (user.username !== req.body.username) {\nreq = checkUsernameValid(req);\n- let errors = req.validationErrors();\n+ const errors = req.validationErrors();\nif (errors) {\n- for (i = 0; i < errors.length; i++) {\n+ for (let i = 0; i < errors.length; i++) {\nreq.flash('danger', errors[i].msg);\n}\nreturn res.redirect('/user/account');\n- } else {\n+ }\nif (duplicate_user) {\nreq.flash('danger', 'Username already taken.');\nreturn res.redirect('/user/account');\n- } else {\n+ }\nuser.username = req.body.username;\nuser.username_lower = req.body.username.toLowerCase();\nCube.find(\n{\nowner: req.user._id,\n},\n- function(err, cubes) {\n- cubes.forEach(function(item, index) {\n+ (err, cubes) => {\n+ cubes.forEach((item, index) => {\nitem.owner_name = req.body.username;\nCube.updateOne(\n{\n@@ -834,12 +812,10 @@ router.post('/updateuserinfo', ensureAuth, function(req, res, next) {\n},\n);\n}\n- }\n- }\nuser.about = req.body.body;\n- let query = {\n+ const query = {\n_id: req.user._id,\n};\n@@ -862,16 +838,16 @@ router.post('/updateemail', ensureAuth, function(req, res, next) {\n{\nemail: req.body.email.toLowerCase(),\n},\n- function(err, user) {\n+ (err, user) => {\nif (user) {\nreq.flash('danger', 'Email already associated with an existing account.');\nres.redirect('/user/account/updateemail');\n} else {\n- User.findById(req.user._id, function(err, user) {\n+ User.findById(req.user._id, (err, user) => {\nif (user) {\nuser.email = req.body.email;\n- let query = {\n+ const query = {\n_id: req.user._id,\n};\n",
        "lang": "JavaScript",
        "chatgpt": "Refactor user_routes.js: Update variable declarations to use const, update string interpolation to use template literals, and improve code readability."
    },
    {
        "msg": "Set up logger",
        "diff": "diff --git a/sc2/__init__.py b/sc2/__init__.py @@ -9,6 +9,11 @@ def is_submodule(path):\n__all__ = [p.stem for p in Path(__file__).parent.iterdir() if is_submodule(p)]\n+import sys, logging\n+logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n+logger = logging.getLogger(__name__)\n+logger.setLevel(logging.INFO)\n+\nfrom . import maps\nfrom .data import *\nfrom .bot_ai import BotAI\n",
        "lang": "Python",
        "chatgpt": "Add logging configuration and logger initialization in __init__.py"
    },
    {
        "msg": "redraft hotfix",
        "diff": "diff --git a/routes/cube_routes.js b/routes/cube_routes.js @@ -2872,7 +2872,7 @@ router.get('/redraft/:id', async (req, res) => {\nif (!srcDraft) {\nreq.flash('danger', 'This deck is not able to be redrafted.');\n- res.redirect(`/cube/deck/${req.params.id}`);\n+ return res.redirect(`/cube/deck/${req.params.id}`);\n}\nconst draft = new Draft();\n",
        "lang": "JavaScript",
        "chatgpt": "Fix redirect issue in redraft route"
    },
    {
        "msg": "node_manager_fkie: fixed open parameter dialog",
        "diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/parameter_dialog.py b/node_manager_fkie/src/node_manager_fkie/parameter_dialog.py @@ -1015,21 +1015,21 @@ class MasterParameterDialog(ParameterDialog):\ngiven namespace.\n'''\n- def __init__(self, masteruri, ns='/', parent=None):\n+ def __init__(self, masteruri, ns='/', parent=None, store_geometry=''):\n'''\n@param masteruri: if the master uri is not None, the parameter are retrieved from ROS parameter server.\n@type masteruri: C{str}\n@param ns: namespace of the parameter retrieved from the ROS parameter server.\n@type ns: C{str}\n'''\n- ParameterDialog.__init__(self, dict(), parent=parent)\n+ ParameterDialog.__init__(self, dict(), parent=parent, store_geometry=store_geometry)\nself.masteruri = masteruri\nself.ns = ns\nself.is_delivered = False\nself.is_send = False\nself.mIcon = QIcon(\":/icons/default_cfg.png\")\nself.setWindowIcon(self.mIcon)\n- self.resize(450, 300)\n+ # self.resize(450, 300)\nself.add_new_button = QPushButton()\nself.add_new_button.setIcon(QIcon(':/icons/crystal_clear_add.png'))\nself.add_new_button.clicked.connect(self._on_add_parameter)\n",
        "lang": "Python",
        "chatgpt": "Add store_geometry parameter to MasterParameterDialog constructor"
    },
    {
        "msg": "Fix: a bug caused by preloading a value bigger than 2G",
        "diff": "diff --git a/Database/Database.cpp b/Database/Database.cpp @@ -843,7 +843,7 @@ Database::get_candidate_preID()\n_size = this->kvstore->getPreListSize(i);\n- if (!VList::isLongList(_size)) continue; // only long list need to be stored in cache\n+ if (!VList::isLongList(_size) || _size >= max_total_size) continue; // only long list need to be stored in cache\n_value = pre2num[i];\nif (_value == 0) continue;\n@@ -934,7 +934,7 @@ Database::get_important_subID()\nunsigned _size = 0;\nif (this->kvstore->getEntityByID(i) == invalid) continue;\n_size = this->kvstore->getSubListSize(i);\n- if (!VList::isLongList(_size)) continue; // only long list need to be stored in cache\n+ if (!VList::isLongList(_size) || _size >= max_total_size) continue; // only long list need to be stored in cache\nfor(unsigned j = 0; j < important_preID.size(); ++j)\n{\n@@ -997,7 +997,7 @@ Database::get_important_objID()\nif (_tmp == invalid) continue;\n_size = this->kvstore->getObjListSize(i);\n- if (!VList::isLongList(_size)) continue; // only long list need to be stored in cache\n+ if (!VList::isLongList(_size) || _size >= max_total_size) continue; // only long list need to be stored in cache\nfor(unsigned j = 0; j < important_preID.size(); ++j)\n{\n",
        "lang": "C++",
        "chatgpt": "Refactor caching logic to include size check for long lists."
    },
    {
        "msg": "Add placeholders to self.all_units to enable distance calculation",
        "diff": "diff --git a/sc2/bot_ai.py b/sc2/bot_ai.py @@ -1700,10 +1700,10 @@ class BotAI(DistanceCalculation):\ncontinue\nunit_obj = Unit(unit, self, distance_calculation_index=index)\nindex += 1\n+ self.all_units.append(unit_obj)\nif unit.display_type == IS_PLACEHOLDER:\nself.placeholders.append(unit_obj)\ncontinue\n- self.all_units.append(unit_obj)\nalliance = unit.alliance\n# Alliance.Neutral.value = 3\nif alliance == 3:\n",
        "lang": "Python",
        "chatgpt": "Add unit_obj to all_units list in BotAI class"
    },
    {
        "msg": "QuicVersion::MVFST client default.\nSummary: Move the default forward.",
        "diff": "diff --git a/quic/client/state/ClientStateMachine.h b/quic/client/state/ClientStateMachine.h @@ -63,7 +63,7 @@ struct QuicClientConnectionState : public QuicConnectionStateBase {\n// TODO: this is wrong, it should be the handshake finish time. But i need\n// a relatively sane time now to make the timestamps all sane.\nconnectionTime = Clock::now();\n- originalVersion = QuicVersion::MVFST_D24;\n+ originalVersion = QuicVersion::MVFST;\nDCHECK(handshakeFactory);\nauto tmpClientHandshake = handshakeFactory->makeClientHandshake(this);\nclientHandshakeLayer = tmpClientHandshake.get();\n",
        "lang": "C++",
        "chatgpt": "Fix originalVersion value in ClientStateMachine to use correct QuicVersion"
    },
    {
        "msg": "Shortex never used anywhere else",
        "diff": "diff --git a/src/XRay.cs b/src/XRay.cs @@ -50,7 +50,6 @@ public class XRay\nprivate List<Excerpt> excerpts = new List<Excerpt>();\nprivate long _srl;\nprivate long _erl;\n- private bool _shortEx = true;\nprivate bool unattended;\nprivate bool skipShelfari;\nprivate int locOffset;\n@@ -339,7 +338,6 @@ public int ExpandFromRawMl(string rawMl, IProgress<Tuple<int, int>> progress, Ca\nstring punctuationMarks = String.Format(@\"({0}s|{0})?{1}?[!\\.?,\"\"\\);:]*{0}*{1}*{2}*\", apostrophes, quotes, dashesEllipsis);\nint excerptId = 0;\n- this._shortEx = shortEx;\nHtmlAgilityPack.HtmlDocument web = new HtmlAgilityPack.HtmlDocument();\nstring readContents;\nusing (StreamReader streamReader = new StreamReader(rawMl, Encoding.Default))\n",
        "lang": "C#",
        "chatgpt": "Remove unnecessary assignment of _shortEx variable"
    },
    {
        "msg": "convert chapter to properties",
        "diff": "diff --git a/src/XRay.cs b/src/XRay.cs namespace XRayBuilderGUI\n{\n+ // TODO: Anywhere JSON is used, serialization should be done rather than text formatting...\npublic class XRay\n{\nprivate string dataUrl = \"\";\n@@ -353,7 +354,12 @@ public void HandleChapters(long mlLen, HtmlDocument doc, string rawMl, SafeShowD\n//Define srl and erl so \"progress bar\" shows up correctly\nif (_chapters.Count == 0)\n{\n- _chapters.Add(new Chapter(\"\", 1, mlLen));\n+ _chapters.Add(new Chapter\n+ {\n+ Name = \"\",\n+ Start = 1,\n+ End = mlLen\n+ });\n_srl = 1;\n_erl = mlLen;\n}\n@@ -361,12 +367,12 @@ public void HandleChapters(long mlLen, HtmlDocument doc, string rawMl, SafeShowD\n{\n//Run through all chapters and take the highest value, in case some chapters can be defined in individual chapters and parts.\n//EG. Part 1 includes chapters 1-6, Part 2 includes chapters 7-12.\n- _srl = _chapters[0].start;\n+ _srl = _chapters[0].Start;\nLogger.Log(\"Found chapters:\");\nforeach (Chapter c in _chapters)\n{\nif (c.End > _erl) _erl = c.End;\n- Logger.Log($\"{c.name} | start: {c.start} | end: {c.End}\");\n+ Logger.Log($\"{c.Name} | start: {c.Start} | end: {c.End}\");\n}\n}\n}\n@@ -661,10 +667,15 @@ private void SearchChapters(HtmlDocument bookDoc, string rawML)\nif (_chapters.Count > 0)\n{\n_chapters[_chapters.Count - 1].End = filepos;\n- if (_chapters[_chapters.Count - 1].start > filepos)\n+ if (_chapters[_chapters.Count - 1].Start > filepos)\n_chapters.RemoveAt(_chapters.Count - 1); //remove broken chapters\n}\n- _chapters.Add(new Chapter(chapter.InnerText, filepos, rawML.Length));\n+ _chapters.Add(new Chapter\n+ {\n+ Name = chapter.InnerText,\n+ Start = filepos,\n+ End = rawML.Length\n+ });\n}\n}\n@@ -689,7 +700,12 @@ private void SearchChapters(HtmlDocument bookDoc, string rawML)\n{\nif (_chapters.Count > 0)\n_chapters[_chapters.Count - 1].End = index;\n- _chapters.Add(new Chapter(chap.InnerText, index, rawML.Length));\n+ _chapters.Add(new Chapter\n+ {\n+ Name = chap.InnerText,\n+ Start = index,\n+ End = rawML.Length\n+ });\n}\n}\n}\n@@ -719,7 +735,12 @@ private void SearchChapters(HtmlDocument bookDoc, string rawML)\n{\nif (_chapters.Count > 0)\n_chapters[_chapters.Count - 1].End = index;\n- _chapters.Add(new Chapter(chap.InnerText, index, rawML.Length));\n+ _chapters.Add(new Chapter\n+ {\n+ Name = chap.InnerText,\n+ Start = index,\n+ End = rawML.Length\n+ });\n}\n}\n}\n@@ -918,28 +939,15 @@ public class Excerpt\npublic class Chapter\n{\n- public string name;\n- public long start;\n- public long End;\n-\n- public Chapter()\n- {\n- name = \"\";\n- start = 1;\n- End = 9999999;\n- }\n-\n- public Chapter(string name, long start, long end)\n- {\n- this.name = name;\n- this.start = start;\n- End = end;\n- }\n+ public string Name { get; set; }\n+ public long Start { get; set; }\n+ public long End { get; set; }\n+ // TODO: Replace w/ serialization\npublic override string ToString()\n{\nreturn string.Format(@\"{{\"\"name\"\":{0},\"\"start\"\":{1},\"\"end\"\":{2}}}\",\n- (name == \"\" ? \"null\" : \"\\\"\" + name + \"\\\"\"), start, End);\n+ (Name == \"\" ? \"null\" : \"\\\"\" + Name + \"\\\"\"), Start, End);\n}\n}\n@@ -1013,7 +1021,7 @@ public void SaveChapters()\nEncoding.UTF8))\n{\nforeach (Chapter c in _chapters)\n- streamWriter.WriteLine(c.name + \"|\" + c.start + \"|\" + c.End);\n+ streamWriter.WriteLine(c.Name + \"|\" + c.Start + \"|\" + c.End);\n}\n}\n@@ -1030,7 +1038,12 @@ public bool LoadChapters()\nstring[] tmp = streamReader.ReadLine()?.Split('|');\nif (tmp?.Length != 3) return false; //Malformed chapters file\nif (tmp[0] == \"\" || tmp[0].Substring(0, 1) == \"#\") continue;\n- _chapters.Add(new Chapter(tmp[0], Convert.ToInt32(tmp[1]), Convert.ToInt64(tmp[2])));\n+ _chapters.Add(new Chapter\n+ {\n+ Name = tmp[0],\n+ Start = Convert.ToInt32(tmp[1]),\n+ End = Convert.ToInt64(tmp[2])\n+ });\n}\n}\nreturn true;\n",
        "lang": "C#",
        "chatgpt": "Refactor XRay class to use serialization for JSON data handling"
    },
    {
        "msg": "ConfigApiTests - Fixed xunit warning in ConfigLogRuleWithName about using Assert.Same for null-check",
        "diff": "diff --git a/tests/NLog.UnitTests/Config/ConfigApiTests.cs b/tests/NLog.UnitTests/Config/ConfigApiTests.cs @@ -301,7 +301,7 @@ public void ConfigLogRuleWithName()\nAssert.Same(rule, ruleLookup);\nAssert.True(config.RemoveRuleByName(\"hello\"));\nruleLookup = config.FindRuleByName(\"hello\");\n- Assert.Same(null, ruleLookup);\n+ Assert.Null(ruleLookup);\nAssert.False(config.RemoveRuleByName(\"hello\"));\n}\n}\n",
        "lang": "C#",
        "chatgpt": "Refactor ConfigApiTests.cs to use Assert.Null instead of Assert.Same(null, ...) for better readability."
    },
    {
        "msg": "Fix BUILD_ARGS",
        "diff": "diff --git a/dockerfiles/test_docker_image.sh b/dockerfiles/test_docker_image.sh @@ -9,7 +9,7 @@ export SC2_VERSION=${SC2_VERSION:-4.10}\n# For better readability, set local variables\nIMAGE_NAME=burnysc2/python-sc2-docker:local\n-BUILD_ARGS=--build-arg PYTHON_VERSION=$PYTHON_VERSION --build-arg SC2_VERSION=$SC2_VERSION\n+BUILD_ARGS=\"--build-arg PYTHON_VERSION=$PYTHON_VERSION --build-arg SC2_VERSION=$SC2_VERSION\"\n# Allow image squashing by enabling experimental docker features\n# https://stackoverflow.com/a/21164441/10882657\n",
        "lang": "Python",
        "chatgpt": "Fix quoting issue in BUILD_ARGS in test_docker_image.sh"
    },
    {
        "msg": "added dash to allowed cube url characters",
        "diff": "diff --git a/routes/cube_routes.js b/routes/cube_routes.js @@ -2448,7 +2448,9 @@ router.post(\nmax: 100,\n}),\nbody('name', 'Cube name may not use profanity.').custom((value) => !util.hasProfanity(value)),\n- body('urlAlias', 'Custom URL must contain only alphanumeric characters or underscores.').matches(/^[A-Za-z0-9_]*$/),\n+ body('urlAlias', 'Custom URL must contain only alphanumeric characters, dashes, or underscores.').matches(\n+ /^[A-Za-z0-9_-]*$/,\n+ ),\nbody('urlAlias', `Custom URL may not be longer than 100 characters.`).isLength({\nmax: 100,\n}),\n",
        "lang": "JavaScript",
        "chatgpt": "Update custom URL validation to allow dashes in addition to alphanumeric characters and underscores."
    },
    {
        "msg": "Fix global navbar spacing.",
        "diff": "diff --git a/views/layout.pug b/views/layout.pug @@ -33,7 +33,7 @@ html\nimg(src=\"/content/banner.png\" style='height: 45px; margin: 0 0' alt=\"Cube Cobra: a site for Magic: the Gathering Cubing\")\nbutton.navbar-toggler(type='button', data-toggle='collapse', data-target='#navbar', aria-controls='navbar', aria-expanded='false', aria-label='Toggle navigation')\nspan.navbar-toggler-icon\n- #navbar.collapse.navbar-collapse\n+ #navbar.collapse.navbar-collapse(style='flex: 10000 1 auto')\nul.navbar-nav.mr-auto\nform(method='POST', action='/search').form-inline\n.input-group.mt-2.mb-sm-2\n@@ -55,7 +55,9 @@ html\nli.nav-item\na.nav-link.d-none.d-lg-block(href=\"#\", data-toggle='modal', data-target='#cubeModal') New Cube\nli.nav-item\n- a.nav-link(href=\"/user/view/\"+user.id) Your Profile\n+ a.nav-link(href=\"/user/view/\"+user.id)\n+ span.d-none.d-lg-inline Your\n+ | Profile\nli.nav-item.dropdown\na#navbarDropdownMenuLink.nav-link.dropdown-toggle(href='#', role='button', data-toggle='dropdown', aria-haspopup='true', aria-expanded='false')\n| #{user.username}\n",
        "lang": "JavaScript",
        "chatgpt": "Update layout.pug to adjust navbar styling and improve user profile link readability."
    },
    {
        "msg": "fix(cycle): return empty if not exist cyclePath",
        "diff": "diff --git a/Query/PathQueryHandler.cpp b/Query/PathQueryHandler.cpp @@ -571,6 +571,8 @@ std::vector<int> PathQueryHandler::cycle(int uid, int vid, bool directed,\n// }\nans = shortestPath0(uid, vid, false, pred_set);\nint lens = ans.size();\n+ if (lens == 0)\n+ return ans;\nfor(int i = lens - 2; i > 0; --i)\nans.push_back(ans[i]);\nans.push_back(uid);\n",
        "lang": "C++",
        "chatgpt": "Fix issue with cycle method in PathQueryHandler"
    },
    {
        "msg": "Fix computation of cubedWith array.\nIt should use oracle IDs as well.",
        "diff": "diff --git a/jobs/populate_analytics.js b/jobs/populate_analytics.js @@ -210,13 +210,10 @@ async function processCard(card) {\n// cubed with\n// create correl dict\n- const cubedWith = [];\n- for (const otherCard of carddb.allCards()) {\n- cubedWith.push({\n- other: otherCard.oracle_id,\n- count: correlations[correlationIndex[oracle_id]][correlationIndex[otherCard.oracle_id]],\n- });\n- }\n+ const cubedWith = carddb.allOracleIds().map((otherOracleId) => ({\n+ other: otherOracleId,\n+ count: correlations[correlationIndex[oracle_id]][correlationIndex[otherOracleId]],\n+ }));\n// quickselect isn't sorting correctly for some reason\ncubedWith.sort((first, second) => {\n",
        "lang": "JavaScript",
        "chatgpt": "Refactor cubedWith creation to use map function for improved readability"
    },
    {
        "msg": "read missing mobi header fields",
        "diff": "diff --git a/XRayBuilder.Core/src/Unpack/Mobi/MobiHead.cs b/XRayBuilder.Core/src/Unpack/Mobi/MobiHead.cs using System.Text;\nusing MiscUtil.Conversion;\nusing MiscUtil.IO;\n-using XRayBuilder.Core.Libraries.Primitives.Extensions;\nnamespace XRayBuilder.Core.Unpack.Mobi\n{\npublic sealed class MobiHead\n{\n- private readonly byte[] _identifier = new byte[4];\n- private readonly byte[] _headerLength = new byte[4];\n- private readonly byte[] _mobiType = new byte[4];\n- private readonly byte[] _textEncoding = new byte[4];\n- private readonly byte[] _uniqueId = new byte[4];\n- private readonly byte[] _fileVersion = new byte[4];\n- private readonly byte[] _orthographicIndex = new byte[4];\n- private readonly byte[] _inflectionIndex = new byte[4];\n- private readonly byte[] _indexNames = new byte[4];\n- private readonly byte[] _indexKeys = new byte[4];\n- private readonly byte[] _extraIndex0 = new byte[4];\n- private readonly byte[] _extraIndex1 = new byte[4];\n- private readonly byte[] _extraIndex2 = new byte[4];\n- private readonly byte[] _extraIndex3 = new byte[4];\n- private readonly byte[] _extraIndex4 = new byte[4];\n- private readonly byte[] _extraIndex5 = new byte[4];\n- private readonly byte[] _firstNonBookIndex = new byte[4];\n- private readonly byte[] _fullNameOffset = new byte[4];\n- private readonly byte[] _fullNameLength = new byte[4];\n- private readonly byte[] _locale = new byte[4];\n- private readonly byte[] _inputLanguage = new byte[4];\n- private readonly byte[] _outputLanguage = new byte[4];\n- private readonly byte[] _minVersion = new byte[4];\n- private readonly byte[] _firstImageIndex = new byte[4];\n- private readonly byte[] _huffmanRecordOffset = new byte[4];\n- private readonly byte[] _huffmanRecordCount = new byte[4];\n- private readonly byte[] _huffmanTableOffset = new byte[4];\n- private readonly byte[] _huffmanTableLength = new byte[4];\n- private readonly byte[] _exthFlags = new byte[4];\n+ public string Identifier { get; set; }\n+ public int HeaderLength { get; set; }\n+ public int MobiType { get; set; }\n+ public short CryptoType { get; set; }\n+ public ushort TextEncoding { get; set; }\n+ public uint UniqueId { get; set; }\n+ public int Version { get; set; }\n+ public int OrthographicIndex { get; set; }\n+ public int InflectionIndex { get; set; }\n+ public int IndexNames { get; set; }\n+ public int IndexKeys { get; set; }\n+ public int ExtraIndex0 { get; set; }\n+ public int ExtraIndex1 { get; set; }\n+ public int ExtraIndex2 { get; set; }\n+ public int ExtraIndex3 { get; set; }\n+ public int ExtraIndex4 { get; set; }\n+ public int ExtraIndex5 { get; set; }\n+ public int FirstNonBookIndex { get; set; }\n+ public int FullNameOffset { get; set; }\n+ public int FullNameLength { get; set; }\n+ /// <summary>\n+ /// Book locale code.\n+ /// Low byte is main language 09 = English, next byte is dialect, 08 = British, 04 = US.\n+ /// Thus US English is 1033, UK English is 2057.\n+ /// </summary>\n+ public int Locale { get; set; }\n+ public int InputLanguage { get; set; }\n+ public int OutputLanguage { get; set; }\n+ public int MinVersion { get; set; }\n+ public int FirstImageIndex { get; set; }\n+ public int HuffmanRecordOffset { get; set; }\n+ public int HuffmanRecordCount { get; set; }\n+ public int HuffmanTableOffset { get; set; }\n+ public int HuffmanTableLength { get; set; }\n+ public int ExtHFlags { get; set; }\n+ public byte[] Unknown1 { get; set; }\n+ public int DrmOffset { get; set; }\n+ public int DrmCount { get; set; }\n+ public int DrmSize { get; set; }\n+ public int DrmFlags { get; set; }\n+ public byte[] Unknown2 { get; set; }\n+ public short FirstContentRecordNumber { get; set; }\n+ public short LastContentRecordNumber { get; set; }\n+ public int Unknown3 { get; set; }\n+ public int FcisRecordNumber { get; set; }\n+ public int Unknown4 { get; set; }\n+ public int FlisRecordNumber { get; set; }\n+ public int Unknown5 { get; set; }\n+ public long Unknown6 { get; set; }\n+ public int Unknown7 { get; set; }\n+ public int Unknown8 { get; set; }\n+ public int Unknown9 { get; set; }\n+ public int Unknown10 { get; set; }\n+ /// <summary>\n+ /// A set of binary flags, some of which indicate extra data at the end of each text block.\n+ /// This only seems to be valid for Mobipocket format version 5 and 6 (and higher?), when the header length is 228 (0xE4) or 232 (0xE8).\n+ /// bit 1 (0x1): extra multibyte bytes - size\n+ /// bit 2 (0x2): TBS indexing description of this HTML record - size\n+ /// bit 3 (0x4): uncrossable breaks - size\n+ /// Setting bit 2 (0x2) disables [guide][reference type = \"start\"] functionality.\n+ /// </summary>\n+ public int MbhFlags { get; set; }\n+ /// <summary>\n+ /// If not 0xFFFFFFFF, the record number of the first INDX record created from an ncx file.\n+ /// </summary>\n+ public int IndxRecordOffset { get; set; }\n+ public string FullName { get; set; }\n+\nprivate readonly byte[] _restOfMobiHeader;\npublic readonly ExtHeader ExtHeader;\nprivate readonly byte[] _remainder;\n- private readonly byte[] _fullName;\n- public bool Multibyte;\n- public int Trailers;\n+ public bool Multibyte { get; }\n+ public int Trailers { get; }\npublic MobiHead(FileStream fs, uint mobiHeaderSize)\n{\n- fs.Read(_identifier, 0, _identifier.Length);\n- if (IdentifierAsString != \"MOBI\")\n+ var reader = new EndianBinaryReader(EndianBitConverter.Big, fs);\n+ Identifier = Encoding.UTF8.GetString(reader.ReadBytes(4)).Trim('\\0');\n+ if (Identifier != \"MOBI\")\nthrow new UnpackException(\"Did not get expected MOBI identifier\");\n- fs.Read(_headerLength, 0, _headerLength.Length);\n- _restOfMobiHeader = new byte[HeaderLength + 16 - 132];\n-\n- fs.Read(_mobiType, 0, _mobiType.Length);\n- fs.Read(_textEncoding, 0, _textEncoding.Length);\n- fs.Read(_uniqueId, 0, _uniqueId.Length);\n- Array.Reverse(_uniqueId);\n- fs.Read(_fileVersion, 0, _fileVersion.Length);\n- fs.Read(_orthographicIndex, 0, _orthographicIndex.Length);\n- fs.Read(_inflectionIndex, 0, _inflectionIndex.Length);\n- fs.Read(_indexNames, 0, _indexNames.Length);\n- fs.Read(_indexKeys, 0, _indexKeys.Length);\n- fs.Read(_extraIndex0, 0, _extraIndex0.Length);\n- fs.Read(_extraIndex1, 0, _extraIndex1.Length);\n- fs.Read(_extraIndex2, 0, _extraIndex2.Length);\n- fs.Read(_extraIndex3, 0, _extraIndex3.Length);\n- fs.Read(_extraIndex4, 0, _extraIndex4.Length);\n- fs.Read(_extraIndex5, 0, _extraIndex5.Length);\n- fs.Read(_firstNonBookIndex, 0, _firstNonBookIndex.Length);\n- fs.Read(_fullNameOffset, 0, _fullNameOffset.Length);\n- fs.Read(_fullNameLength, 0, _fullNameLength.Length);\n- fs.Read(_locale, 0, _locale.Length);\n- fs.Read(_inputLanguage, 0, _inputLanguage.Length);\n- fs.Read(_outputLanguage, 0, _outputLanguage.Length);\n- fs.Read(_minVersion, 0, _minVersion.Length);\n- fs.Read(_firstImageIndex, 0, _firstImageIndex.Length);\n- fs.Read(_huffmanRecordOffset, 0, _huffmanRecordOffset.Length);\n- fs.Read(_huffmanRecordCount, 0, _huffmanRecordCount.Length);\n- fs.Read(_huffmanTableOffset, 0, _huffmanTableOffset.Length);\n- fs.Read(_huffmanTableLength, 0, _huffmanTableLength.Length);\n- fs.Read(_exthFlags, 0, _exthFlags.Length);\n+ HeaderLength = reader.ReadInt32();\n+ MobiType = reader.ReadInt32();\n+ CryptoType = reader.ReadInt16();\n+ TextEncoding = reader.ReadUInt16();\n+ UniqueId = reader.ReadUInt32();\n+ Version = reader.ReadInt32();\n+ OrthographicIndex = reader.ReadInt32();\n+ InflectionIndex = reader.ReadInt32();\n+ IndexNames = reader.ReadInt32();\n+ IndexKeys = reader.ReadInt32();\n+ ExtraIndex0 = reader.ReadInt32();\n+ ExtraIndex1 = reader.ReadInt32();\n+ ExtraIndex2 = reader.ReadInt32();\n+ ExtraIndex3 = reader.ReadInt32();\n+ ExtraIndex4 = reader.ReadInt32();\n+ ExtraIndex5 = reader.ReadInt32();\n+ FirstNonBookIndex = reader.ReadInt32();\n+ FullNameOffset = reader.ReadInt32();\n+ FullNameLength = reader.ReadInt32();\n+ Locale = reader.ReadInt32();\n+ InputLanguage = reader.ReadInt32();\n+ OutputLanguage = reader.ReadInt32();\n+ MinVersion = reader.ReadInt32();\n+ FirstImageIndex = reader.ReadInt32();\n+ HuffmanRecordOffset = reader.ReadInt32();\n+ HuffmanRecordCount = reader.ReadInt32();\n+ HuffmanTableOffset = reader.ReadInt32();\n+ HuffmanTableLength = reader.ReadInt32();\n+ ExtHFlags = reader.ReadInt32();\n+ Unknown1 = reader.ReadBytesOrThrow(32);\n+ DrmOffset = reader.ReadInt32();\n+ DrmCount = reader.ReadInt32();\n+ DrmSize = reader.ReadInt32();\n+ DrmFlags = reader.ReadInt32();\n+ Unknown2 = reader.ReadBytes(12);\n+ FirstContentRecordNumber = reader.ReadInt16();\n+ LastContentRecordNumber = reader.ReadInt16();\n+ Unknown3 = reader.ReadInt32();\n+ FcisRecordNumber = reader.ReadInt32();\n+ Unknown4 = reader.ReadInt32();\n+ FlisRecordNumber = reader.ReadInt32();\n+ Unknown5 = reader.ReadInt32();\n+ Unknown6 = reader.ReadInt64();\n+ Unknown7 = reader.ReadInt32();\n+ Unknown8 = reader.ReadInt32();\n+ Unknown9 = reader.ReadInt32();\n+ Unknown10 = reader.ReadInt32();\n+ MbhFlags = reader.ReadInt32();\n+ IndxRecordOffset = reader.ReadInt32();\n+\n+ // If anything is left, read it and save it\n+ // (length + 16 extra that are usually at the end and unknown (in newer mobi versions) - the 248 we've read in already)\n+ var bytesLeftInHeader = HeaderLength + 16 - 248;\n+ _restOfMobiHeader = bytesLeftInHeader > 0\n+ ? reader.ReadBytes(bytesLeftInHeader)\n+ : new byte[0];\n//If bit 6 (0x40) is set, then there's an EXTH record\n- var exthExists = (BitConverter.ToUInt32(_exthFlags.BigEndian(), 0) & 0x40) != 0;\n-\n- fs.Read(_restOfMobiHeader, 0, _restOfMobiHeader.Length);\n-\n- if (exthExists)\n- {\n- var reader = new EndianBinaryReader(EndianBitConverter.Big, fs);\n+ if ((ExtHFlags & 0x40) != 0)\nExtHeader = new ExtHeader(reader);\n- }\nelse\nthrow new UnpackException(\"No EXT Header found. Ensure this book was processed with Calibre then try again.\");\n// If applicable, read mbh flags regarding trailing bytes in record data\nif (MinVersion >= 5 && HeaderLength >= 228)\n{\n- var tempFlags = new byte[2];\n- Array.Copy(_restOfMobiHeader, 110, tempFlags, 0, 2);\n- var mbhFlags = BitConverter.ToUInt16(tempFlags.BigEndian(), 0);\n+ var mbhFlags = MbhFlags;\nMultibyte = Convert.ToBoolean(mbhFlags & 1);\nwhile (mbhFlags > 1)\n{\n@@ -115,32 +169,22 @@ public MobiHead(FileStream fs, uint mobiHeaderSize)\n}\n}\n- var currentOffset = 132 + _restOfMobiHeader.Length + ExthHeaderSize;\n- _remainder = new byte[(int)(mobiHeaderSize - currentOffset)];\n- fs.Read(_remainder, 0, _remainder.Length);\n-\n- var fullNameIndexInRemainder = BitConverter.ToInt32(_fullNameOffset.BigEndian(), 0) - currentOffset;\n- var fullNameLen = BitConverter.ToInt32(_fullNameLength.BigEndian(), 0);\n- _fullName = new byte[fullNameLen];\n+ var currentOffset = 248 + _restOfMobiHeader.Length + ExthHeaderSize;\n+ _remainder = reader.ReadBytes((int) (mobiHeaderSize - currentOffset));\n+ var fullNameIndexInRemainder = FullNameOffset - currentOffset;\nif (fullNameIndexInRemainder >= 0 &&\nfullNameIndexInRemainder < _remainder.Length &&\n- fullNameIndexInRemainder + fullNameLen <= _remainder.Length && fullNameLen > 0)\n+ fullNameIndexInRemainder + FullNameLength <= _remainder.Length && FullNameLength > 0)\n{\n- Array.Copy(_remainder, fullNameIndexInRemainder, _fullName, 0, fullNameLen);\n+ var buffer = new byte[FullNameLength];\n+ Array.Copy(_remainder, fullNameIndexInRemainder, buffer, 0, FullNameLength);\n+ FullName = Encoding.ASCII.GetString(buffer).Trim('\\0');\n}\n}\npublic int ExthHeaderSize => ExtHeader?.Size ?? 0;\n- public string FullName => Encoding.UTF8.GetString(_fullName).Trim('\\0');\n-\n- public string IdentifierAsString => Encoding.ASCII.GetString(_identifier).Trim('\\0');\n-\n- public uint HeaderLength => BitConverter.ToUInt32(_headerLength.BigEndian(), 0);\n-\n- public uint MobiType => BitConverter.ToUInt32(_mobiType.BigEndian(), 0);\n-\npublic string MobiTypeAsString\n{\nget\n@@ -163,27 +207,5 @@ public string MobiTypeAsString\n};\n}\n}\n-\n- public uint UniqueId => BitConverter.ToUInt32(_uniqueId, 0);\n-\n- public uint FileVersion => BitConverter.ToUInt32(_fileVersion, 0);\n-\n- public uint IndexKeys => BitConverter.ToUInt32(_indexKeys, 0);\n-\n- public uint FirstNonBookIndex => BitConverter.ToUInt32(_firstNonBookIndex.BigEndian(), 0);\n-\n- public uint FullNameOffset => BitConverter.ToUInt32(_fullNameOffset.BigEndian(), 0);\n-\n- public uint FullNameLength => BitConverter.ToUInt32(_fullNameLength.BigEndian(), 0);\n-\n- public uint MinVersion => BitConverter.ToUInt32(_minVersion.BigEndian(), 0);\n-\n- public uint HuffmanRecordOffset => BitConverter.ToUInt32(_huffmanRecordOffset.BigEndian(), 0);\n-\n- public uint HuffmanRecordCount => BitConverter.ToUInt32(_huffmanRecordCount.BigEndian(), 0);\n-\n- public uint HuffmanTableOffset => BitConverter.ToUInt32(_huffmanTableOffset.BigEndian(), 0);\n-\n- public uint HuffmanTableLength => BitConverter.ToUInt32(_huffmanTableLength.BigEndian(), 0);\n}\n}\n",
        "lang": "C#",
        "chatgpt": "Refactor MobiHead class properties to use more descriptive names and appropriate data types."
    },
    {
        "msg": "Added both r-hpc and rutgersgemr gateways to the list",
        "diff": "diff --git a/dev-tools/ansible/pga-scigap-prod.yml b/dev-tools/ansible/pga-scigap-prod.yml - include: pga-single-vhost.yml vars_dir=\"{{ inventory_dir }}/pga_config/testdrive\"\n- include: pga-single-vhost.yml vars_dir=\"{{ inventory_dir }}/pga_config/uab\"\n- include: pga-single-vhost.yml vars_dir=\"{{ inventory_dir }}/pga_config/ultrascan\"\n-- include: pga-single-vhost.yml vars_dir=\"{{ inventory_dir }}/pga_config/utah\"\n+#- include: pga-single-vhost.yml vars_dir=\"{{ inventory_dir }}/pga_config/utah\"\n- include: pga-single-vhost.yml vars_dir=\"{{ inventory_dir }}/pga_config/wvsu\"\n- include: pga-single-vhost.yml vars_dir=\"{{ inventory_dir }}/pga_config/iugeosurvey\"\n- include: pga-single-vhost.yml vars_dir=\"{{ inventory_dir }}/pga_config/csbglsu\"\n- include: pga-single-vhost.yml vars_dir=\"{{ inventory_dir }}/pga_config/NCSAIndustry\"\n- include: pga-single-vhost.yml vars_dir=\"{{ inventory_dir }}/pga_config/Kentucky\"\n- include: pga-single-vhost.yml vars_dir=\"{{ inventory_dir }}/pga_config/searchingSRA\"\n+- include: pga-single-vhost.yml vars_dir=\"{{ inventory_dir }}/pga_config/r-hpc\"\n+- include: pga-single-vhost.yml vars_dir=\"{{ inventory_dir }}/pga_config/rutgersgemr\"\n...\n",
        "lang": "Java",
        "chatgpt": "Update vars_dir for utah and add new configurations for r-hpc and rutgersgemr."
    },
    {
        "msg": "Eliminate the \"game already ended\" error",
        "diff": "diff --git a/sc2/main.py b/sc2/main.py @@ -3,23 +3,37 @@ import asyncio\nfrom .sc2process import SC2Process\nfrom .portconfig import Portconfig\nfrom .client import Client\n-from .player import Human, Bot, Observer\n+from .player import Human, Bot\nfrom .data import Race, Difficulty, Result, ActionResult\nfrom .game_state import GameState\nfrom .protocol import ProtocolError\n-async def _play_game_human(client, realtime):\n+def __get_result(state, player_id):\n+ assert len(state.observation.player_result) > 0\n+ for pr in state.observation.player_result:\n+ if pr.player_id == player_id:\n+ return Result(pr.result)\n+\n+ raise RuntimeError(\"No result found for player\")\n+\n+\n+async def _play_game_human(client, player_id, realtime):\nwhile True:\nstate = await client.observation()\nif len(state.observation.player_result) > 0:\n- result = Result([pr.result for pr in state.observation.player_result if pr.player_id == player_id][0])\nawait client.leave()\nawait client.quit()\n- return result\n+ return _get_result(state, player_id)\n+ try:\nif not realtime:\nawait client.step()\n+ except ProtocolError:\n+ state = await client.observation()\n+ await client.leave()\n+ await client.quit()\n+ return _get_result(state, player_id)\nasync def _play_game_ai(client, player_id, ai, realtime):\ngame_data = await client.get_game_data()\n@@ -32,34 +46,28 @@ async def _play_game_ai(client, player_id, ai, realtime):\nwhile True:\nstate = await client.observation()\nif len(state.observation.player_result) > 0:\n- result = Result([pr.result for pr in state.observation.player_result if pr.player_id == player_id][0])\nawait client.leave()\nawait client.quit()\n- return result\n+ return _get_result(state, player_id)\ngs = GameState(state.observation, game_data)\nai._prepare_step(gs)\ntry:\nawait ai.on_step(gs, iteration)\n+ if not realtime:\n+ await client.step()\nexcept ProtocolError:\nstate = await client.observation()\n- assert len(state.observation.player_result) > 0\n- result = Result([pr.result for pr in state.observation.player_result if pr.player_id == player_id][0])\nawait client.leave()\nawait client.quit()\n- return result\n+ return _get_result(state, player_id)\n- if not realtime:\n- await client.step()\niteration += 1\n-async def _host_game(map_settings, players, realtime=False, observer=False, portconfig=None):\n+async def _host_game(map_settings, players, realtime=False, portconfig=None):\nassert len(players) > 0, \"Can't create a game without players\"\n- if observer:\n- players.append(Observer())\n- else:\nassert any(isinstance(p, (Human, Bot)) for p in players)\nasync with SC2Process() as server:\n@@ -69,15 +77,10 @@ async def _host_game(map_settings, players, realtime=False, observer=False, port\nclient = Client(server._ws)\n- if observer:\n- await client.join_game(observed_player_id=1, portconfig=portconfig)\n- return await _play_game_human(client, realtime)\n-\n-\nplayer_id = await client.join_game(players[0].race, portconfig=portconfig)\nif isinstance(players[0], Human):\n- return await _play_game_human(client, realtime)\n+ return await _play_game_human(client, player_id, realtime)\nelse:\nreturn await _play_game_ai(client, player_id, players[0].ai, realtime)\n@@ -88,7 +91,7 @@ async def _join_game(map_settings, players, realtime, portconfig):\nplayer_id = await client.join_game(players[1].race, portconfig=portconfig)\nif isinstance(player_id, Human):\n- return await _play_game_human(client, realtime)\n+ return await _play_game_human(client, player_id, realtime)\nelse:\nreturn await _play_game_ai(client, player_id, players[1].ai, realtime)\n",
        "lang": "Python",
        "chatgpt": "Refactor player result retrieval and fix ProtocolError handling in game functions"
    },
    {
        "msg": "All tokens are displayed in a row now with generating cards below.",
        "diff": "diff --git a/src/components/GeneratedTokensAnalysis.js b/src/components/GeneratedTokensAnalysis.js import React from 'react';\n-\n+import { Row, Col } from 'reactstrap';\nconst GeneratedTokensAnalysis = ( GeneratedTokensCounts) => (\n<div>\n<h4>GeneratedTokensAnalysis</h4>\n- {console.log(GeneratedTokensCounts)}\n- <div>\n+ <div className='row'>\n{GeneratedTokensCounts.GeneratedTokensCounts.map(token =>\n- <div style={{width: 150, margin:10}}>\n- <img src={token[0].image_small}></img>\n+ <Col xs={12} sm={6} md={4} lg={2}>\n+ <div class=\"card\">\n+ <img src={token[0].image_small} className='card-img-top'></img>\n+ <div class=\"card-body\">\n+ <p class=\"card-text\">\n{token[1].map( sourceCard =>\n<div>\n+ <a>\n{sourceCard.name}\n+ </a><br></br>\n</div>\n)}\n+ </p>\n</div>\n-\n+ </div>\n+ </Col>\n)}\n</div>\n</div>\n",
        "lang": "JavaScript",
        "chatgpt": "Refactor GeneratedTokensAnalysis component to use Row and Col from 'reactstrap' instead of divs"
    },
    {
        "msg": "Make  fixing agnostic from rating",
        "diff": "diff --git a/src/utils/draftbots.js b/src/utils/draftbots.js @@ -160,7 +160,7 @@ export const getFixing = (combination, _, card) => {\nconst isLand = typeLine.indexOf('Land') > -1;\nconst isFetch = !!fetchLands[cardName(card)];\nconst hasBasicTypes = basics.filter((basic) => typeLine.toLowerCase().includes(basic.toLowerCase())).length > 1;\n- let score = card.rating;\n+ let score = 1;\n// Guaranteed contains by botRatingAndCombination\nif (isLand || isFetch) {\nscore /= COLOR_SCALING_FACTOR[combination.length];\n@@ -187,7 +187,7 @@ export const getFixing = (combination, _, card) => {\n} else {\nscore *= 0.5 * COLOR_SCALING_FACTOR[combination.length];\n}\n- return Math.min(10, score / 1000);\n+ return Math.min(10, score);\n};\nexport const getRatingWeight = (pack, pick, initialState) => {\n",
        "lang": "JavaScript",
        "chatgpt": "Update scoring logic in getFixing function"
    },
    {
        "msg": "fkie_node_manager: store all loggers states in logscreen while runtime",
        "diff": "diff --git a/fkie_node_manager/src/fkie_node_manager/logscreen/logger_handler.py b/fkie_node_manager/src/fkie_node_manager/logscreen/logger_handler.py @@ -80,6 +80,7 @@ class LoggerHandler(QObject):\nself._logger_items = {} # logger name: LoggerItem\nself.layout = layout\nself._change_all_cancel = False\n+ self._stored_values = {}\nself.loggers_signal.connect(self._handle_loggers)\nself._thread_update = None\nself._thread_set_all = None\n@@ -105,12 +106,11 @@ class LoggerHandler(QObject):\nself._thread_update = None\ndef _handle_loggers(self, loggers):\n- stored_values = {}\nwhile self.layout.count() > 1:\nitem = self.layout.takeAt(0)\nwd = item.widget()\nif wd.current_level is not None:\n- stored_values[wd.loggername] = wd.current_level\n+ self._stored_values[wd.loggername] = wd.current_level\nwd.setParent(None)\nself._logger_items.clear()\nall_item = LoggerItem(self.nodename, self.masteruri, 'all', '')\n@@ -121,8 +121,8 @@ class LoggerHandler(QObject):\nitem = LoggerItem(self.nodename, self.masteruri, logger.name, logger.level)\nself._logger_items[logger.name] = item\nself.layout.insertWidget(index, item)\n- if logger.name in stored_values and stored_values[logger.name] != logger.level:\n- item.set_level(stored_values[logger.name])\n+ if logger.name in self._stored_values and self._stored_values[logger.name] != logger.level:\n+ item.set_level(self._stored_values[logger.name])\nindex += 1\ndef change_all(self, loglevel, ignore=['ros.roscpp.roscpp_internal',\n",
        "lang": "Python",
        "chatgpt": "Add stored_values dictionary to LoggerHandler class and update references to use self._stored_values."
    },
    {
        "msg": "Fluent LogBuilder  - Remove Sonar warning about empty namespace",
        "diff": "diff --git a/src/NLog/Fluent/Log.cs b/src/NLog/Fluent/Log.cs // THE POSSIBILITY OF SUCH DAMAGE.\n//\n+#if !NET35 && !NET40\n+\nnamespace NLog.Fluent\n{\n-#if !NET35 && !NET40\nusing System;\nusing System.IO;\nusing System.Runtime.CompilerServices;\n@@ -148,5 +149,6 @@ private static ILogger GetLogger(string callerFilePath)\n}\n}\n}\n-#endif\n}\n+\n+#endif\n",
        "lang": "C#",
        "chatgpt": "Fix conditional compilation issue in Log.cs file"
    },
    {
        "msg": "fix(Query): fix ORDER BY DESC (only single var)",
        "diff": "diff --git a/Query/GeneralEvaluation.cpp b/Query/GeneralEvaluation.cpp @@ -2522,7 +2522,8 @@ void GeneralEvaluation::getFinalResult(ResultSet &ret_result)\nvector <bool> desc;\nfor (int i = 0; i < (int)this->query_tree.getOrderVarVector().size(); i++)\n{\n- int var_id = Varset(this->query_tree.getOrderVarVector()[i].var).mapTo(ret_result_varset)[0];\n+ // int var_id = Varset(this->query_tree.getOrderVarVector()[i].var).mapTo(ret_result_varset)[0];\n+ int var_id = this->query_tree.getOrderVarVector()[i].comp_tree_root.getVarset().mapTo(ret_result_varset)[0];\nif (var_id != -1)\n{\nkeys.push_back(var_id);\n",
        "lang": "C++",
        "chatgpt": "Refactor getOrderVarVector to use comp_tree_root.getVarset() instead of creating a new Varset object."
    },
    {
        "msg": "Fixing case sensitive issues in database initialization script.",
        "diff": "diff --git a/modules/ide-integration/src/main/resources/database_scripts/init/01-databases.sql b/modules/ide-integration/src/main/resources/database_scripts/init/01-databases.sql @@ -3530,7 +3530,7 @@ USE `experiment_catalog`;\n/*!50001 SET collation_connection = utf8mb4_unicode_ci */;\n/*!50001 CREATE ALGORITHM=UNDEFINED */\n/*!50013 DEFINER=`root`@`%` SQL SECURITY DEFINER */\n-/*!50001 VIEW `experiment_summary` AS select `E`.`EXPERIMENT_ID` AS `EXPERIMENT_ID`,`E`.`PROJECT_ID` AS `PROJECT_ID`,`E`.`GATEWAY_ID` AS `GATEWAY_ID`,`E`.`USER_NAME` AS `USER_NAME`,`E`.`EXECUTION_ID` AS `EXECUTION_ID`,`E`.`EXPERIMENT_NAME` AS `EXPERIMENT_NAME`,`E`.`CREATION_TIME` AS `CREATION_TIME`,`E`.`DESCRIPTION` AS `DESCRIPTION`,`es`.`STATE` AS `STATE`,`UD`.`RESOURCE_HOST_ID` AS `RESOURCE_HOST_ID`,`es`.`TIME_OF_STATE_CHANGE` AS `TIME_OF_STATE_CHANGE` from ((`experiment` `E` left join `latest_experiment_status` `ES` on((`E`.`EXPERIMENT_ID` = `es`.`EXPERIMENT_ID`))) left join `user_configuration_data` `UD` on((`E`.`EXPERIMENT_ID` = `UD`.`EXPERIMENT_ID`))) where 1 */;\n+/*!50001 VIEW `experiment_summary` AS select `E`.`EXPERIMENT_ID` AS `EXPERIMENT_ID`,`E`.`PROJECT_ID` AS `PROJECT_ID`,`E`.`GATEWAY_ID` AS `GATEWAY_ID`,`E`.`USER_NAME` AS `USER_NAME`,`E`.`EXECUTION_ID` AS `EXECUTION_ID`,`E`.`EXPERIMENT_NAME` AS `EXPERIMENT_NAME`,`E`.`CREATION_TIME` AS `CREATION_TIME`,`E`.`DESCRIPTION` AS `DESCRIPTION`,`es`.`STATE` AS `STATE`,`UD`.`RESOURCE_HOST_ID` AS `RESOURCE_HOST_ID`,`es`.`TIME_OF_STATE_CHANGE` AS `TIME_OF_STATE_CHANGE` from ((`EXPERIMENT` `E` left join `latest_experiment_status` `es` on((`E`.`EXPERIMENT_ID` = `es`.`EXPERIMENT_ID`))) left join `USER_CONFIGURATION_DATA` `UD` on((`E`.`EXPERIMENT_ID` = `UD`.`EXPERIMENT_ID`))) where 1 */;\n/*!50001 SET character_set_client = @saved_cs_client */;\n/*!50001 SET character_set_results = @saved_cs_results */;\n/*!50001 SET collation_connection = @saved_col_connection */;\n@@ -3548,7 +3548,7 @@ USE `experiment_catalog`;\n/*!50001 SET collation_connection = utf8mb4_unicode_ci */;\n/*!50001 CREATE ALGORITHM=UNDEFINED */\n/*!50013 DEFINER=`root`@`%` SQL SECURITY DEFINER */\n-/*!50001 VIEW `latest_experiment_status` AS select `ES1`.`EXPERIMENT_ID` AS `EXPERIMENT_ID`,`ES1`.`STATE` AS `STATE`,`ES1`.`TIME_OF_STATE_CHANGE` AS `TIME_OF_STATE_CHANGE` from (`experiment_status` `ES1` left join `experiment_status` `ES2` on(((`ES1`.`EXPERIMENT_ID` = `ES2`.`EXPERIMENT_ID`) and (`ES1`.`TIME_OF_STATE_CHANGE` < `ES2`.`TIME_OF_STATE_CHANGE`)))) where isnull(`ES2`.`TIME_OF_STATE_CHANGE`) */;\n+/*!50001 VIEW `latest_experiment_status` AS select `ES1`.`EXPERIMENT_ID` AS `EXPERIMENT_ID`,`ES1`.`STATE` AS `STATE`,`ES1`.`TIME_OF_STATE_CHANGE` AS `TIME_OF_STATE_CHANGE` from (`EXPERIMENT_STATUS` `ES1` left join `EXPERIMENT_STATUS` `ES2` on(((`ES1`.`EXPERIMENT_ID` = `ES2`.`EXPERIMENT_ID`) and (`ES1`.`TIME_OF_STATE_CHANGE` < `ES2`.`TIME_OF_STATE_CHANGE`)))) where isnull(`ES2`.`TIME_OF_STATE_CHANGE`) */;\n/*!50001 SET character_set_client = @saved_cs_client */;\n/*!50001 SET character_set_results = @saved_cs_results */;\n/*!50001 SET collation_connection = @saved_col_connection */;\n",
        "lang": "Java",
        "chatgpt": "Refactor database view names to use consistent casing."
    },
    {
        "msg": "fix goodreads & lt tests",
        "diff": "diff --git a/XRayBuilder.Test/src/DataSources/LibraryThingTests.cs b/XRayBuilder.Test/src/DataSources/LibraryThingTests.cs @@ -59,7 +59,7 @@ public async Task SearchBookTest()\ntestMetadata.Title.Returns(\"The Fellowship of the Ring\");\nvar results = (await _libraryThing.SearchBookAsync(testMetadata, CancellationToken.None)).ToArray();\n- Assert.AreEqual(11, results.Length);\n+ Assert.AreEqual(12, results.Length);\nAssert.AreEqual(\"https://www.librarything.com/work/3203347\", results[0].DataUrl);\nAssert.AreEqual(\"J. R. R. Tolkien\", results[0].Author);\nAssert.AreEqual(\"The Fellowship of the Ring\", results[0].Title);\n",
        "lang": "C#",
        "chatgpt": "Update search book test to expect 12 results instead of 11"
    },
    {
        "msg": "Switched the abstract NUnitTestAdapter ctor to protected based on code review",
        "diff": "diff --git a/src/NUnitTestAdapter/NUnitTestAdapter.cs b/src/NUnitTestAdapter/NUnitTestAdapter.cs @@ -63,7 +63,7 @@ namespace NUnit.VisualStudio.TestAdapter\n#region Constructor\n- public NUnitTestAdapter()\n+ protected NUnitTestAdapter()\n{\n#if NETCOREAPP1_0\nAdapterVersion = typeof(NUnitTestAdapter).GetTypeInfo().Assembly.GetName().Version.ToString();\n",
        "lang": "C#",
        "chatgpt": "Change constructor access modifier to protected in NUnitTestAdapter"
    },
    {
        "msg": "Fix memory leak.\nNot shutting down the thread pool was preventing the\nRoboPlatform from being GC'ed when not in use anymore.",
        "diff": "diff --git a/robovm/src/playn/robovm/RoboPlatform.java b/robovm/src/playn/robovm/RoboPlatform.java @@ -187,6 +187,7 @@ public class RoboPlatform extends Platform {\n}\nvoid willTerminate () {\n+ pool.shutdown();\n// let the app know that we're terminating\ndispatchEvent(lifecycle, Lifecycle.EXIT);\n}\n",
        "lang": "Java",
        "chatgpt": "Shutdown thread pool on app termination"
    },
    {
        "msg": "making trivial change to test ansible",
        "diff": "diff --git a/dev-tools/ansible/inventories/scigap/production/pga_config/oscer/vars.yml b/dev-tools/ansible/inventories/scigap/production/pga_config/oscer/vars.yml @@ -51,5 +51,5 @@ portal_email_username: \"pga.airavata@gmail.com\"\nportal_email_password: \"{{ vault_portal_email_password }}\"\nportal_theme: \"oscer\"\nportal_theme_repo: \"https://github.com/SciGaP/ou-gateway-theme\"\n-portal_title: \"OU CyberGateway\"\n+portal_title: \"OU Science Gateway\"\n...\n",
        "lang": "Java",
        "chatgpt": "Update portal title from \"OU CyberGateway\" to \"OU Science Gateway\" in OSCER theme configuration."
    },
    {
        "msg": "node_manager_fkie: editor: fixed un/comment function",
        "diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/editor/text_edit.py b/node_manager_fkie/src/node_manager_fkie/editor/text_edit.py from python_qt_binding.QtCore import QFile, QFileInfo, QIODevice, QRegExp, Qt, Signal\nfrom python_qt_binding.QtGui import QFont, QTextCursor\nimport os\n+import re\nfrom node_manager_fkie.common import package_name, utf8\nfrom node_manager_fkie.detailed_msg_box import MessageBox\n@@ -333,7 +334,47 @@ class TextEdit(QTextEdit):\nevent.accept()\nQTextEdit.keyReleaseEvent(self, event)\n+ def _has_uncommented(self):\n+ cursor = QTextCursor(self.textCursor())\n+ if not cursor.isNull():\n+# cursor.beginEditBlock()\n+ start = cursor.selectionStart()\n+ end = cursor.selectionEnd()\n+ cursor.setPosition(start)\n+ block_start = cursor.blockNumber()\n+ cursor.setPosition(end)\n+ block_end = cursor.blockNumber()\n+ if block_end - block_start > 0 and end - cursor.block().position() <= 0:\n+ # skip the last block, if no characters are selected\n+ block_end -= 1\n+ cursor.setPosition(start, QTextCursor.MoveAnchor)\n+ cursor.movePosition(QTextCursor.StartOfLine)\n+ start = cursor.position()\n+ xmlre = re.compile(r\"\\A\\s*<!--\")\n+ otherre = re.compile(r\"\\A\\s*#\")\n+ ext = os.path.splitext(self.filename)\n+ # XML comment\n+ xml_file = ext[1] in self.CONTEXT_FILE_EXT\n+ while (cursor.block().blockNumber() < block_end + 1):\n+ cursor.movePosition(QTextCursor.StartOfLine)\n+ cursor.movePosition(QTextCursor.EndOfLine, QTextCursor.KeepAnchor)\n+ if xml_file:\n+ if not xmlre.match(cursor.selectedText()):\n+# cursor.endEditBlock()\n+# self.undo()\n+ return True\n+ else:\n+ if not otherre.match(cursor.selectedText()):\n+# cursor.endEditBlock()\n+# self.undo()\n+ return True\n+ cursor.movePosition(QTextCursor.NextBlock)\n+# self.undo()\n+# cursor.endEditBlock()\n+ return False\n+\ndef commentText(self):\n+ do_comment = self._has_uncommented()\ncursor = self.textCursor()\nif not cursor.isNull():\ncursor.beginEditBlock()\n@@ -349,61 +390,42 @@ class TextEdit(QTextEdit):\ncursor.setPosition(start, QTextCursor.MoveAnchor)\ncursor.movePosition(QTextCursor.StartOfLine)\nstart = cursor.position()\n+ ext = os.path.splitext(self.filename)\n+ # XML comment\n+ xml_file = ext[1] in self.CONTEXT_FILE_EXT\nwhile (cursor.block().blockNumber() < block_end + 1):\ncursor.movePosition(QTextCursor.StartOfLine)\n- ext = os.path.splitext(self.filename)\n# XML comment\n- if ext[1] in self.CONTEXT_FILE_EXT:\n- # skipt the existing spaces at the start of the line\n- cursor.movePosition(QTextCursor.NextCharacter, QTextCursor.KeepAnchor, 1)\n- while cursor.selectedText() in [' ', '\\t']:\n- cursor.setPosition(cursor.position(), QTextCursor.MoveAnchor)\n- cursor.movePosition(QTextCursor.NextCharacter, QTextCursor.KeepAnchor, 1)\n- cursor.movePosition(QTextCursor.PreviousCharacter, 1)\n- cursor.movePosition(QTextCursor.NextCharacter, QTextCursor.KeepAnchor, 4)\n- # only comments breakers at the start of the line are removed\n- if cursor.selectedText() == '<!--':\n- cursor.insertText('')\n- # remove spaces between comment and text\n- cursor.movePosition(QTextCursor.NextCharacter, QTextCursor.KeepAnchor, 1)\n- while cursor.selectedText() in [' ', '\\t']:\n- cursor.insertText('')\n- cursor.movePosition(QTextCursor.NextCharacter, QTextCursor.KeepAnchor, 1)\n- cursor.movePosition(QTextCursor.EndOfLine)\n- cursor.movePosition(QTextCursor.PreviousCharacter, QTextCursor.KeepAnchor, 3)\n- if cursor.selectedText() == '-->':\n- cursor.insertText('')\n- # remove spaces between comment and text\n- cursor.movePosition(QTextCursor.PreviousCharacter, QTextCursor.KeepAnchor, 1)\n- while cursor.selectedText() in [' ', '\\t']:\n- cursor.insertText('')\n- cursor.movePosition(QTextCursor.PreviousCharacter, QTextCursor.KeepAnchor, 1)\n- else:\n- cursor.setPosition(cursor.anchor())\n+ if xml_file:\n+ xmlre_start = re.compile(r\"<!-- ?\")\n+ xmlre_end = re.compile(r\" ?-->\")\ncursor.movePosition(QTextCursor.EndOfLine, QTextCursor.KeepAnchor)\n- # only comment out, if no comments are found\n- if cursor.selectedText().find('<!--') < 0 and cursor.selectedText().find('-->') < 0:\n- cursor.movePosition(QTextCursor.StartOfLine)\n- # skipt the current existing spaces\n- cursor.movePosition(QTextCursor.NextCharacter, QTextCursor.KeepAnchor, 1)\n- while cursor.selectedText() in [' ', '\\t']:\n- cursor.setPosition(cursor.position(), QTextCursor.MoveAnchor)\n- cursor.movePosition(QTextCursor.NextCharacter, QTextCursor.KeepAnchor, 1)\n- cursor.movePosition(QTextCursor.PreviousCharacter, 1)\n- cursor.insertText('<!-- ')\n- cursor.movePosition(QTextCursor.EndOfLine)\n- cursor.insertText(' -->')\n- else: # other comments\n- if cursor.block().length() < 2:\n- cursor.movePosition(QTextCursor.NextBlock)\n- continue\n- cursor.movePosition(QTextCursor.NextCharacter, QTextCursor.KeepAnchor, 2)\n- # only comments breakers at the start of the line are removed\n- if cursor.selectedText() == '# ':\n- cursor.insertText('')\n+ if do_comment:\n+ cursor.insertText(\"<!-- %s -->\" % cursor.selectedText().replace(\"--\", \"- -\"))\nelse:\n- cursor.movePosition(QTextCursor.StartOfLine)\n+ res = cursor.selectedText()\n+ mstart = xmlre_start.search(res)\n+ if mstart:\n+ res = res.replace(mstart.group(), \"\", 1)\n+ res = res.replace(\"<!- -\", \"<!--\", 1)\n+ mend = xmlre_end.search(res)\n+ if mend:\n+ res = res.replace(mend.group(), \"\", 1)\n+ last_pos = res.rfind(\"- ->\")\n+ if last_pos > -1:\n+ res = \"%s-->\" % res[0:last_pos]\n+ cursor.insertText(res)\n+ else: # other comments\n+ hash_re = re.compile(r\"# ?\")\n+ if do_comment:\ncursor.insertText('# ')\n+ else:\n+ cursor.movePosition(QTextCursor.EndOfLine, QTextCursor.KeepAnchor)\n+ res = cursor.selectedText()\n+ hres = hash_re.search(res)\n+ if hres:\n+ res = res.replace(hres.group(), \"\", 1)\n+ cursor.insertText(res)\ncursor.movePosition(QTextCursor.NextBlock)\n# Set our cursor's selection to span all of the involved lines.\ncursor.endEditBlock()\n",
        "lang": "Python",
        "chatgpt": "Add functionality to check for uncommented lines before commenting in TextEdit"
    },
    {
        "msg": "Adding SSL certificates to SDState gateway",
        "diff": "diff --git a/dev-tools/ansible/inventories/scigap/production/pga_config/sdstate/vars.yml b/dev-tools/ansible/inventories/scigap/production/pga_config/sdstate/vars.yml @@ -26,11 +26,11 @@ group: \"pga\"\ndoc_root_dir: \"/var/www/portals/{{ gateway_id }}\"\nvhost_servername: \"sciencegateway.sdstate.edu\"\n#vhost_serveralias: \"www.mines.scigap.org\"\n-#vhost_ssl: true\n+vhost_ssl: true\n# TODO: have Ansible manage these files as well\n-#ssl_certificate_file: \"/etc/letsencrypt/live/mines.scigap.org/cert.pem\"\n-#ssl_certificate_chain_file: \"/etc/letsencrypt/live/mines.scigap.org/fullchain.pem\"\n-#ssl_certificate_key_file: \"/etc/letsencrypt/live/mines.scigap.org/privkey.pem\"\n+ssl_certificate_file: \"/etc/letsencrypt/live/sciencegateway.sdstate.edu/cert.pem\"\n+ssl_certificate_chain_file: \"/etc/letsencrypt/live/sciencegateway.sdstate.edu/fullchain.pem\"\n+ssl_certificate_key_file: \"/etc/letsencrypt/live/sciencegateway.sdstate.edu/privkey.pem\"\n## Keycloak related variables\ntenant_domain: \"{{ gateway_id }}\"\n",
        "lang": "Java",
        "chatgpt": "Enable SSL configuration for sciencegateway.sdstate.edu domain"
    },
    {
        "msg": "LogFactory Setup LoadConfiguration should skip refresh Loggers when config unchanged",
        "diff": "diff --git a/src/NLog/SetupBuilderExtensions.cs b/src/NLog/SetupBuilderExtensions.cs @@ -109,9 +109,13 @@ public static ISetupBuilder LoadConfiguration(this ISetupBuilder setupBuilder, A\nbool configHasChanged = !ReferenceEquals(config, setupBuilder.LogFactory._config);\nif (ReferenceEquals(newConfig, setupBuilder.LogFactory._config))\n+ {\n+ // New config has already been assigned or unchanged, check if refresh is needed\n+ if (!ReferenceEquals(config, newConfig) || !ReferenceEquals(newConfig, null))\n{\nsetupBuilder.LogFactory.ReconfigExistingLoggers();\n}\n+ }\nelse if (!configHasChanged || !ReferenceEquals(config, newConfig))\n{\nsetupBuilder.LogFactory.Configuration = newConfig;\n",
        "lang": "C#",
        "chatgpt": "\"Fix issue with refreshing configuration in SetupBuilderExtensions.cs\""
    },
    {
        "msg": "node_manager_fkie: changed xmlformatter",
        "diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/editor/xmlformatter.py b/node_manager_fkie/src/node_manager_fkie/editor/xmlformatter.py @@ -39,15 +39,22 @@ DEFAULT_INDENT_CHAR = \" \"\nDEFAULT_INLINE = True\nDEFAULT_ENCODING_INPUT = None\nDEFAULT_ENCODING_OUTPUT = None\n+DEFAULT_NOEMPTYTAG = False\n+DEFAULT_EMPTYATTR = True\n+DEFAULT_INDENT_DATA = True\nclass Formatter():\n# Use internal encoding:\nencoding_internal = None\n- def __init__(self, indent = DEFAULT_INDENT, preserve = [], compress = DEFAULT_COMPRESS, indent_char = DEFAULT_INDENT_CHAR, encoding_input = DEFAULT_ENCODING_INPUT, encoding_output = DEFAULT_ENCODING_OUTPUT, inline = DEFAULT_INLINE, correct = DEFAULT_CORRECT):\n+ def __init__(self, indent = DEFAULT_INDENT, preserve = [], compress = DEFAULT_COMPRESS, indent_char = DEFAULT_INDENT_CHAR, encoding_input = DEFAULT_ENCODING_INPUT, encoding_output = DEFAULT_ENCODING_OUTPUT, inline = DEFAULT_INLINE, correct = DEFAULT_CORRECT, noemptytag = DEFAULT_NOEMPTYTAG, emptyattr = DEFAULT_EMPTYATTR, indent_data = DEFAULT_INDENT_DATA):\n# Minify the XML document:\nself.compress = compress\n+ # Allow self closing tag also it not compress\n+ self.noemptytag = noemptytag\n+ # Allow attributes with empty value\n+ self.emptyattr = emptyattr\n# Correct text nodes\nself.correct = correct\n# Decode the XML document:\n@@ -58,6 +65,8 @@ class Formatter():\nself.indent = int(indent)\n# Indent by char:\nself.indent_char = indent_char\n+ # Indent also data\n+ self.indent_data = indent_data\n# Format inline objects:\nself.inline = inline\n# Don't compress this elements and their descendants:\n@@ -417,7 +426,7 @@ class Formatter():\nreturn self.formatter.correct\ndef attribute(self, key, value):\n- if (key and value):\n+ if ((key and value) or self.formatter.emptyattr):\nreturn \" %s=\\\"%s\\\"\" % (key, value)\nreturn \"\"\n@@ -494,6 +503,8 @@ class Formatter():\nif not self.cdata_section:\nstr = re.sub(r'&', '&amp;', str)\nstr = re.sub(r'<', '&lt;', str)\n+ if str and self.formatter.indent_data:\n+ str = \"%s%s\" % (self.indent_create(self.level + 1), str)\nreturn str\ndef pre_operate(self):\n@@ -580,8 +591,8 @@ class Formatter():\ndef __unicode__(self):\nstr = \"\"\n# Don't close empty nodes on compression mode:\n- if (not self.formatter.compress or self.list[self.pos-1].name != \"StartElement\"):\n- if (self.preserve in [0] and self.indent):\n+ if (self.formatter.noemptytag or self.list[self.pos - 1].name != \"StartElement\"):\n+ if (not self.formatter.compress or self.preserve in [0] and self.indent):\nstr += self.indent_insert()\nstr += \"</%s>\" % self.arg[0]\nreturn str\n@@ -653,7 +664,7 @@ class Formatter():\nstr += \"<%s\" %self.arg[0]\nfor attr in sorted(self.arg[1].keys()):\nstr += self.attribute(attr, self.arg[1][attr])\n- if (self.list[self.pos+1].end and self.formatter.compress):\n+ if (self.list[self.pos + 1].end and not self.formatter.noemptytag):\nstr += \"/>\"\nelse:\nstr += \">\"\n",
        "lang": "Python",
        "chatgpt": "Add new options for XML formatting in Formatter class"
    },
    {
        "msg": "added xterm path for macOS",
        "diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/settings.py b/node_manager_fkie/src/node_manager_fkie/settings.py @@ -476,7 +476,7 @@ class Settings(object):\nnoclose_str = '-hold'\nif self._terminal_emulator is None:\nself._terminal_emulator = \"\"\n- for t in ['/usr/bin/x-terminal-emulator', '/usr/bin/xterm']:\n+ for t in ['/usr/bin/x-terminal-emulator', '/usr/bin/xterm', '/opt/x11/bin/xterm']:\nif os.path.isfile(t) and os.access(t, os.X_OK):\n# workaround to support the command parameter in different terminal\nif os.path.basename(os.path.realpath(t)) in ['terminator', 'gnome-terminal', 'xfce4-terminal']:\n",
        "lang": "Python",
        "chatgpt": "Add /opt/x11/bin/xterm to terminal emulator search list"
    },
    {
        "msg": "Treat preflipped cards as only one face",
        "diff": "diff --git a/serverjs/updatecards.js b/serverjs/updatecards.js @@ -466,7 +466,7 @@ function convertParsedCost(card, isExtra = false) {\n.split('}{')\n.reverse();\n} else {\n- winston.error(`Error converting parsed colors: (isExtra:${isExtra}) card.name`);\n+ winston.error(`Error converting parsed colors: (isExtra:${isExtra}) ${card.name}`);\n}\nif (parsedCost) {\n@@ -480,7 +480,6 @@ function convertParsedCost(card, isExtra = false) {\nfunction convertColors(card, isExtra = false) {\nif (isExtra) {\nif (typeof card.card_faces === 'undefined' || card.card_faces.length < 2) {\n- winston.error(`Error converting colors: (isExtra:${isExtra}) card.name`);\nreturn [];\n}\n// special case: Adventure faces currently do not have colors on Scryfall (but probably should)\n@@ -552,6 +551,8 @@ function convertCard(card, isExtra) {\nconst newcard = {};\nif (isExtra) {\n[, faceAttributeSource] = card.card_faces;\n+ card = { ...card };\n+ card.card_faces = [faceAttributeSource];\n} else if (card.card_faces) {\n[faceAttributeSource] = card.card_faces;\n} else {\n",
        "lang": "JavaScript",
        "chatgpt": "Fix error in converting parsed colors and colors for extra cards"
    },
    {
        "msg": "Removed unused libs.",
        "diff": "diff --git a/src/api-engine/api/routes/channel/serializers.py b/src/api-engine/api/routes/channel/serializers.py @@ -3,7 +3,6 @@ from rest_framework import serializers\nfrom api.models import Channel\nfrom api.common.serializers import ListResponseSerializer\n-from api.routes.organization.serializers import OrganizationResponse\nclass ChannelCreateBody(serializers.Serializer):\n",
        "lang": "Python",
        "chatgpt": "Remove import statement for OrganizationResponse serializer in channel serializers."
    },
    {
        "msg": "add tests for getCardImageUrl",
        "diff": "diff --git a/__tests__/serverjs/util.js b/__tests__/serverjs/util.js @@ -112,3 +112,24 @@ test(\"addCardToCube allows card id to be overridden\", () => {\nconst result = testCube.cards[0];\nexpect(result.cardID).toBe(idOverride);\n});\n+\n+test(\"getCardImageURL returns imgUrl when defined\", () => {\n+ const testCard = {\n+ details: {\n+ image_normal: \"normal ol image\"\n+ },\n+ imgUrl: \"an image url\"\n+ };\n+ const result = util.getCardImageURL(testCard);\n+ expect(result).toBe(testCard.imgUrl);\n+});\n+\n+test(\"getCardImageURL falls back to image_normal\", () => {\n+ const testCard = {\n+ details: {\n+ image_normal: \"normal ol image\"\n+ }\n+ };\n+ const result = util.getCardImageURL(testCard);\n+ expect(result).toBe(testCard.details.image_normal);\n+});\n\\ No newline at end of file\n",
        "lang": "JavaScript",
        "chatgpt": "Add tests for getCardImageURL function in util.js"
    },
    {
        "msg": "Create output staging tasks for URI_COLLECTION",
        "diff": "diff --git a/modules/orchestrator/orchestrator-core/src/main/java/org/apache/airavata/orchestrator/cpi/impl/SimpleOrchestratorImpl.java b/modules/orchestrator/orchestrator-core/src/main/java/org/apache/airavata/orchestrator/cpi/impl/SimpleOrchestratorImpl.java @@ -470,6 +470,7 @@ public class SimpleOrchestratorImpl extends AbstractOrchestrator{\ncreateOutputDataSatagingTasks(registryClient, processModel, gatewayId, dataStagingTaskIds, processOutput);\nbreak;\ncase URI:\n+ case URI_COLLECTION:\ncreateOutputDataSatagingTasks(registryClient, processModel, gatewayId, dataStagingTaskIds, processOutput);\nbreak;\ndefault:\n",
        "lang": "Java",
        "chatgpt": "Add support for URI_COLLECTION type in output data staging tasks"
    },
    {
        "msg": "No pacing during initCwnd\nSummary: as title",
        "diff": "diff --git a/quic/congestion_control/Bbr.cpp b/quic/congestion_control/Bbr.cpp @@ -264,6 +264,9 @@ void BbrCongestionController::updatePacing() noexcept {\nif (!conn_.pacer) {\nreturn;\n}\n+ if (conn_.lossState.totalBytesSent < initialCwnd_) {\n+ return;\n+ }\nauto bandwidthEstimate = bandwidth();\nif (!bandwidthEstimate) {\nreturn;\n",
        "lang": "C++",
        "chatgpt": "\"Add check to skip pacing update until initial congestion window is reached\""
    },
    {
        "msg": "Version 2.0.24",
        "diff": "diff --git a/Properties/AssemblyInfo.cs b/Properties/AssemblyInfo.cs // You can specify all the values or you can default the Build and Revision Numbers\n// by using the '*' as shown below:\n// [assembly: AssemblyVersion(\"1.0.*\")]\n-[assembly: AssemblyVersion(\"2.0.22.0\")]\n-[assembly: AssemblyFileVersion(\"2.0.22.0\")]\n+[assembly: AssemblyVersion(\"2.0.24.0\")]\n+[assembly: AssemblyFileVersion(\"2.0.24.0\")]\n",
        "lang": "C#",
        "chatgpt": "Update version numbers to 2.0.24.0."
    },
    {
        "msg": "add kubernetes 1.8.x support\nCurrently the ansible agent only supports k8s 1.7.x releases\nthis patch set will add the support for releases 1.8.3 which\nis the latest k8s release up to date.",
        "diff": "diff --git a/src/agent/ansible/roles/env_k8s/worker/tasks/apply.yml b/src/agent/ansible/roles/env_k8s/worker/tasks/apply.yml dest: \"~/.kube/config\"\nmode: 0600\n+- name: Setup kubeconfig for each node\n+ template:\n+ src: \"{{ playbook_dir }}/../env_k8s/worker/templates/kubeconfig.j2\"\n+ dest: \"/etc/kubernetes/kubeconfig\"\n+ mode: 0600\n+\n+- name: Check kubelet version\n+ command: \"{{ fabricroot }}/bin/kubelet --version\"\n+ register: kubeversion\n+\n- name: Setup worker node service variables\nset_fact:\nkubelet_params: >-\n- --api-servers={{ private_ip }}:8080\n+ --cloud-provider=''\n+ --kubeconfig=/etc/kubernetes/kubeconfig\n+ --require-kubeconfig\n--container-runtime=docker\n--cluster-dns={{ cluster.dns_service_ip }}\n--cluster-domain={{ cluster.domain }}\n--master={{ private_ip }}:8080\n--cluster-cidr={{ cluster.container_network.Network }}\n+- name: Setup worker node service variables\n+ set_fact:\n+ kubelet_params: \"{{ kubelet_params }} --fail-swap-on=false\"\n+ when: kubeversion.stdout | search('v1.8.')\n+\n- name: Configure the worker node services\ntemplate:\nsrc: \"{{ playbook_dir }}/../env_k8s/worker/templates/k8s.conf.j2\"\n",
        "lang": "Python",
        "chatgpt": "Refactor kubeconfig setup and worker node service variables"
    },
    {
        "msg": "255 Beautify",
        "diff": "diff --git a/routes/root.js b/routes/root.js @@ -326,7 +326,7 @@ router.get('/search/:id', (req, res) => {\nconst terms = [];\nfunction regexEscape(input) {\n- return input.replace(/[-[\\]/{}()*+?.\\\\^$|]/g, \"\\\\$&\");\n+ return input.replace(/[-[\\]/{}()*+?.\\\\^$|]/g, '\\\\$&');\n}\nrawQueries.forEach((searchExpression) => {\nlet field;\n",
        "lang": "JavaScript",
        "chatgpt": "Fix regex escape function to use single quotes for escaping characters."
    },
    {
        "msg": "fix character search for mobi/azw3",
        "diff": "diff --git a/XRayBuilder.Core/src/XRay/Logic/XRayService.cs b/XRayBuilder.Core/src/XRay/Logic/XRayService.cs @@ -136,6 +136,12 @@ public void ExportAndDisplayTerms(XRay xray, string path, bool overwriteAliases,\nutf8Doc.LoadHtml(readContents);\n_chaptersService.HandleChapters(xray, xray.Asin, rawMlStream.Length, utf8Doc, readContents, overwriteChapters, safeShow, xray.Unattended, enableEdit);\n}\n+ else\n+ {\n+ // set default ERL to prevent filtering\n+ xray.Srl = 1;\n+ xray.Erl = rawMlStream.Length;\n+ }\n_logger.Log(\"Scanning book content...\");\nvar timer = new System.Diagnostics.Stopwatch();\n",
        "lang": "C#",
        "chatgpt": "Set default ERL to prevent filtering and log book content scanning."
    }
]