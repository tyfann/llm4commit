[
    {
        "org_diff": "diff --git a/fkie_node_manager/src/fkie_node_manager/editor/editor.py b/fkie_node_manager/src/fkie_node_manager/editor/editor.py @@ -168,6 +168,7 @@ class Editor(QMainWindow):\nfor f in filenames:\nif f:\nself.on_load_request(f, search_text, only_launch=True)\n+ self.log_dock.setVisible(False)\n# def __del__(self):\n# print \"******** destroy\", self.objectName()\n",
        "org_msg": "fkie_node_manager: editor hide log bar on open dialog",
        "sim_msg": "add Duplicate menu item for toplevel windows",
        "sim_diff": "diff --git a/edit_windows.py b/edit_windows.py @@ -244,6 +244,10 @@ class EditBase(EventsMixin, np.PropertyOwner):\nself._dont_destroy = False # always destroy when explicitly asked\ncommon.app_tree.remove(self.node)\n+ def duplicate(self, *args):\n+ clipboard.copy(self)\n+ clipboard.paste(common.app_tree.root.widget)\n+\ndef on_set_focus(self, event):\n\"\"\"Event handler called when a window receives the focus: this in fact is\nconnected to a EVT_LEFT_DOWN and not to an EVT_FOCUS, but the effect is the same\"\"\"\n@@ -746,6 +750,9 @@ class TopLevelBase(WindowBase, PreviewMixin):\ni = misc.append_menu_item(menu, -1, _('Remove %s\\tDel')%widgetclass, wx.ART_DELETE)\nmisc.bind_menu_item_after(widget, i, self.remove)\n+ i = misc.append_menu_item(menu, -1, _('Duplicate %s')%widgetclass, wx.ART_COPY)\n+ misc.bind_menu_item_after(widget, i, self.duplicate)\n+\n# paste\ni = misc.append_menu_item(menu, -1, _('Paste Sizer\\tCtrl+V'), wx.ART_PASTE)\nmisc.bind_menu_item_after(widget, i, self.clipboard_paste)\n",
        "chatgpt_cot": "Hide log dock on file load in Editor class."
    },
    {
        "org_diff": "diff --git a/src/dashboard/src/pages/Operator/Node/index.js b/src/dashboard/src/pages/Operator/Node/index.js @@ -14,7 +14,8 @@ import {\nForm,\nInput,\nSelect,\n- InputNumber\n+ InputNumber,\n+ Badge\n} from 'antd';\nimport { DownOutlined, PlusOutlined } from '@ant-design/icons';\nimport moment from 'moment';\n@@ -546,9 +547,6 @@ class Index extends PureComponent {\ncase 'stopped':\nstatusOfBadge = 'warning';\nbreak;\n- case 'error':\n- statusOfBadge = 'error';\n- break;\ndefault:\nbreak;\n}\n@@ -568,6 +566,8 @@ class Index extends PureComponent {\n</a>\n</Menu.Item>\n)}\n+ {\n+ record.status === 'stopped' &&\n<Menu.Item>\n<a onClick={() => this.operationForNode('start', record)}>\n{intl.formatMessage({\n@@ -576,6 +576,9 @@ class Index extends PureComponent {\n})}\n</a>\n</Menu.Item>\n+ }\n+ {\n+ record.status === 'running' &&\n<Menu.Item>\n<a onClick={() => this.operationForNode('stop', record)}>\n{intl.formatMessage({\n@@ -584,6 +587,9 @@ class Index extends PureComponent {\n})}\n</a>\n</Menu.Item>\n+ }\n+ {\n+ record.status === 'stopped' &&\n<Menu.Item>\n<a onClick={() => this.operationForNode('restart', record)}>\n{intl.formatMessage({\n@@ -592,6 +598,7 @@ class Index extends PureComponent {\n})}\n</a>\n</Menu.Item>\n+ }\n</Menu>\n);\n@@ -630,6 +637,14 @@ class Index extends PureComponent {\ndataIndex: 'created_at',\nrender: text => <span>{moment(text).format('YYYY-MM-DD HH:mm:ss')}</span>,\n},\n+ {\n+ title: intl.formatMessage({\n+ id: 'app.operator.node.table.header.status',\n+ defaultMessage: 'Status',\n+ }),\n+ dataIndex: 'status',\n+ render: text => <Badge status={badgeStatus(text)} text={text} />,\n+ },\n{\ntitle: intl.formatMessage({\nid: 'form.table.header.operation',\n",
        "org_msg": "[#issue-436]Add display node status\nAdd display node status in node list page",
        "sim_msg": "Style the error message",
        "sim_diff": "diff --git a/openprescribing/media/js/src/chart.js b/openprescribing/media/js/src/chart.js @@ -67,10 +67,10 @@ var analyseChart = {\nshowErrorMessage: function(status, error) {\nvar errorHtml;\nif (error !== null) {\n- errorHtml += '<p>Sorry, something went wrong.</br>';\n- errorHtml += 'This is what we know: ' + status + ': ' + error + '</p>';\n+ errorHtml += '<p class=\"alert alert-danger\">Sorry, something went wrong.</p>';\n+ errorHtml += '<p>This is what we know: ' + status + ': ' + error + '</p>';\n} else {\n- errorHtml = \"<p>\" + status + \"</p>\";\n+ errorHtml = \"<p class='alert alert-danger'>\" + status + \"</p>\";\n}\nthis.el.errorMessage.html(errorHtml);\nthis.el.errorContainer.show();\n",
        "chatgpt_cot": "\"Add Badge component to display status in Node index file\""
    },
    {
        "org_diff": "diff --git a/fkie_node_manager_daemon/src/fkie_node_manager_daemon/launcher.py b/fkie_node_manager_daemon/src/fkie_node_manager_daemon/launcher.py @@ -332,7 +332,7 @@ def _load_parameters(masteruri, params, clear_params):\nfor pkey, pval in params.items():\nvalue = pval\n# resolve path elements\n- if isinstance(value, types.StringTypes) and (value.startswith('$') or value.startswith('pkg://') or value.startswith('package://')):\n+ if isinstance(value, types.StringTypes) and (value.startswith('$') or value.startswith('pkg://')):\nvalue = interpret_path(value)\nrospy.logdebug(\"interpret parameter '%s' to '%s'\" % (value, pval))\n# add parameter to the multicall\n",
        "org_msg": "fkie_node_manager_daemon: remove \"package://\" resolve while set parameter",
        "sim_msg": "fix filename extraction",
        "sim_diff": "diff --git a/pybamm/parameters/parameter_values.py b/pybamm/parameters/parameter_values.py @@ -331,11 +331,11 @@ class ParameterValues:\ndata_path = os.path.join(\npybamm.root_dir(), \"pybamm\", \"input\", \"drive_cycles\"\n)\n- filename = os.path.join(data_path, value[14:] + \".pkl\")\n- function_name = value[14:]\n+ filename = os.path.join(data_path, value[17:] + \".pkl\")\n+ function_name = value[17:]\nelse:\n- filename = os.path.join(path, value[6:] + \".pkl\")\n- function_name = value[6:]\n+ filename = os.path.join(path, value[9:] + \".pkl\")\n+ function_name = value[9:]\nfilename = pybamm.get_parameters_filepath(filename)\nmy_pspc = PybammStandardParameterClass(pkl_filename=filename)\ndata = my_pspc.get_interpolation_parameters()\n",
        "chatgpt_cot": "Refactor path resolution logic in launcher.py to handle only '$' and 'pkg://' prefixes, improving parameter interpretation and logging clarity."
    },
    {
        "org_diff": "diff --git a/test/test_bot.py b/test/test_bot.py @@ -20,7 +20,7 @@ class TestBot(sc2.BotAI):\ndef __init__(self):\n# Tests related\nself.game_time_timeout_limit = 2*60\n- self.tests_target = 7\n+ self.tests_target = 8\nself.tests_done_by_name = set()\n# Variables handled by tests\n@@ -64,6 +64,11 @@ class TestBot(sc2.BotAI):\nawait self.test_botai_actions4()\nawait self.test_botai_actions4_successful()\n+ elif \"test_botai_actions5_successful\" not in self.tests_done_by_name:\n+ if iteration >= 6:\n+ await self.test_botai_actions5()\n+ await self.test_botai_actions5_successful()\n+\n# End when all tests successful\n@@ -123,8 +128,22 @@ class TestBot(sc2.BotAI):\ncombined_actions.append(scv.move(center))\nawait self.do_actions(combined_actions)\n- # Test BotAI action: move all SCVs to mine minerals near townhall\n+ # Test BotAI action: move some scvs to the center, some to minerals\nasync def test_botai_actions3(self):\n+ combined_actions = []\n+ center = self._game_info.map_center\n+ scvs = self.workers\n+ scvs1 = scvs[:6]\n+ scvs2 = scvs[6:]\n+ for scv in scvs1:\n+ combined_actions.append(scv.move(center))\n+ mf = self.state.mineral_field.closest_to(self.townhalls.random)\n+ for scv in scvs2:\n+ combined_actions.append(scv.gather(mf))\n+ await self.do_actions(combined_actions)\n+\n+ # Test BotAI action: move all SCVs to mine minerals near townhall\n+ async def test_botai_actions4(self):\ncombined_actions = []\nmf = self.state.mineral_field.closest_to(self.townhalls.random)\nfor scv in self.units(UnitTypeId.SCV):\n@@ -132,7 +151,7 @@ class TestBot(sc2.BotAI):\nawait self.do_actions(combined_actions)\n# Test BotAI action: self.expand_now()\n- async def test_botai_actions4(self):\n+ async def test_botai_actions5(self):\nif self.can_afford(UnitTypeId.COMMANDCENTER) and not self.already_pending(UnitTypeId.COMMANDCENTER, all_units=True):\nawait self.expand_now()\n@@ -147,13 +166,18 @@ class TestBot(sc2.BotAI):\nself.tests_done_by_name.add(\"test_botai_actions2_successful\")\nasync def test_botai_actions3_successful(self):\n- if self.units.gathering.amount >= 12:\n+ if self.units.filter(lambda x: x.is_moving).amount >= 6:\n+ if self.units.gathering.amount >= 6:\nself.tests_done_by_name.add(\"test_botai_actions3_successful\")\nasync def test_botai_actions4_successful(self):\n- if self.units(UnitTypeId.COMMANDCENTER).amount >= 2:\n+ if self.units.gathering.amount >= 12:\nself.tests_done_by_name.add(\"test_botai_actions4_successful\")\n+ async def test_botai_actions5_successful(self):\n+ if self.units(UnitTypeId.COMMANDCENTER).amount >= 2:\n+ self.tests_done_by_name.add(\"test_botai_actions5_successful\")\n+\n# Test self.state variables\n",
        "org_msg": "Add important test for do_actions()",
        "sim_msg": "Added tests to check the count_completed fields",
        "sim_diff": "diff --git a/scale/batch/test/test_models.py b/scale/batch/test/test_models.py @@ -138,6 +138,32 @@ class TestBatchManager(TransactionTestCase):\n'workspace_id': self.workspace.id,\n}\n+ def test_count_completed_job(self):\n+ \"\"\"Tests calling BatchManger.count_completed_job()\"\"\"\n+\n+ batch = batch_test_utils.create_batch(self.recipe_type)\n+ batch_job = batch_test_utils.create_batch_job(batch=batch)\n+\n+ Batch.objects.count_completed_job(batch.id)\n+ count = Batch.objects.get(id=batch.id).completed_job_count\n+\n+ Batch.objects.count_completed_job(batch_job.batch.id)\n+ next_count = Batch.objects.get(id=batch.id).completed_job_count\n+ self.assertEqual(count + 1, next_count)\n+\n+ def test_count_completed_recipe(self):\n+ \"\"\"Tests calling BatchManger.count_completed_recipe()\"\"\"\n+\n+ batch = batch_test_utils.create_batch(self.recipe_type)\n+ batch_recipe = batch_test_utils.create_batch_recipe(batch=batch)\n+\n+ Batch.objects.count_completed_recipe(batch.id)\n+ count = Batch.objects.get(id=batch.id).completed_recipe_count\n+\n+ Batch.objects.count_completed_recipe(batch_recipe.batch.id)\n+ next_count = Batch.objects.get(id=batch.id).completed_recipe_count\n+ self.assertEqual(count + 1, next_count)\n+\ndef test_create_successful(self):\n\"\"\"Tests calling BatchManager.create_batch() successfully\"\"\"\n",
        "chatgpt_cot": "\"Update test_bot.py to increase test target, add new test method, and adjust successful test conditions for BotAI actions.\""
    },
    {
        "org_diff": "diff --git a/fkie_node_manager_daemon/src/fkie_node_manager_daemon/screen.py b/fkie_node_manager_daemon/src/fkie_node_manager_daemon/screen.py @@ -197,6 +197,10 @@ def get_ros_logfile(node):\nelse:\n# search in latest subfolder\nlogpath = os.path.join(LOG_PATH, \"latest\")\n+ if not os.path.exists(logpath):\n+ logpath = LOG_PATH\n+ if not os.path.exists(logpath):\n+ return ''\np = re.compile(r\"%s-\\d*.log\" % (node.strip('/').replace('/', '-')))\nfiles = os.listdir(logpath)\nfor fn in files:\n",
        "org_msg": "fkie_node_manager_daemon: fixed delete node's log file if no latest folder exists",
        "sim_msg": "base: Rework logging location\nSo the order is script location, inkscape_extensions_path, cwd\nFixes issues with non-writable log location",
        "sim_diff": "diff --git a/textext/base.py b/textext/base.py @@ -33,10 +33,6 @@ EXIT_CODE_OK = 0\nEXIT_CODE_EXPECTED_ERROR = 1\nEXIT_CODE_UNEXPECTED_ERROR = 60\n-LOG_LOCATION = os.path.join(os.path.dirname(__file__))\n-if not os.path.isdir(LOG_LOCATION):\n- os.makedirs(LOG_LOCATION)\n-LOG_FILENAME = os.path.join(LOG_LOCATION, \"textext.log\") # todo: check destination is writeable\n# There are two channels `file_log_channel` and `user_log_channel`\n# `file_log_channel` dumps detailed log to a file\n@@ -50,6 +46,27 @@ __logger.setLevel(logging.DEBUG)\nlog_formatter = logging.Formatter('[%(asctime)s][%(levelname)8s]: %(message)s // %(filename)s:%(lineno)-5d')\n+user_formatter = logging.Formatter('[%(name)s][%(levelname)6s]: %(message)s')\n+user_log_channel = CycleBufferHandler(capacity=1024) # store up to 1024 messages\n+user_log_channel.setLevel(logging.DEBUG)\n+user_log_channel.setFormatter(user_formatter)\n+\n+__logger.addHandler(user_log_channel)\n+\n+SCRIPT_LOCATION=os.path.dirname(__file__)\n+LOG_LOCATION=None\n+if os.access(SCRIPT_LOCATION, os.W_OK):\n+ LOG_LOCATION=SCRIPT_LOCATION\n+elif os.access(defaults.inkscape_extensions_path, os.W_OK):\n+ LOG_LOCATION=defaults.inkscape_extensions_path\n+else:\n+ LOG_LOCATION=os.getcwd()\n+\n+if not os.path.isdir(LOG_LOCATION):\n+ os.makedirs(LOG_LOCATION)\n+\n+LOG_FILENAME = os.path.join(LOG_LOCATION, \"textext.log\")\n+\nfile_log_channel = logging.handlers.RotatingFileHandler(LOG_FILENAME,\nmaxBytes=500 * 1024, # up to 500 kB\nbackupCount=2, # up to two log files\n@@ -58,13 +75,7 @@ file_log_channel = logging.handlers.RotatingFileHandler(LOG_FILENAME,\nfile_log_channel.setLevel(logging.NOTSET)\nfile_log_channel.setFormatter(log_formatter)\n-user_formatter = logging.Formatter('[%(name)s][%(levelname)6s]: %(message)s')\n-user_log_channel = CycleBufferHandler(capacity=1024) # store up to 1024 messages\n-user_log_channel.setLevel(logging.DEBUG)\n-user_log_channel.setFormatter(user_formatter)\n-\n__logger.addHandler(file_log_channel)\n-__logger.addHandler(user_log_channel)\nimport inkex\nfrom lxml import etree\n",
        "chatgpt_cot": "\"Add condition to check for logpath existence and return empty string if not found\""
    },
    {
        "org_diff": "diff --git a/fkie_node_manager/src/fkie_node_manager/main_window.py b/fkie_node_manager/src/fkie_node_manager/main_window.py @@ -2090,7 +2090,11 @@ class MainWindow(QMainWindow):\nnm.nmd().settings.get_config_threaded(nmd_uri)\ndef _nmd_yaml_cfg(self, data, nmdurl):\n+ params = {}\n+ try:\nparams = ruamel.yaml.load(data, Loader=ruamel.yaml.Loader)\n+ except Exception as err:\n+ rospy.logwarn(\"Error while parse daemon configuration: %s\" % utf8(err))\ndia = ParameterDialog(params, store_geometry=\"nmd_cfg_dialog\")\ndia.setWindowTitle('Daemon Configuration')\ndia.setFocusField('load_warn_level')\n",
        "org_msg": "catch exception for daemon configuration\nthis error occurs on requests from Ubuntu 16 to Ubuntu 18",
        "sim_msg": "Add fNIRS support to coregistration gui",
        "sim_diff": "diff --git a/mne/gui/_coreg.py b/mne/gui/_coreg.py @@ -772,23 +772,24 @@ class CoregistrationUI(HasTraits):\ndef _add_eeg_channels(self):\nif self._eeg_channels:\neeg = [\"original\"]\n- picks = pick_types(self._info, eeg=(len(eeg) > 0))\n+ picks = pick_types(self._info, eeg=(len(eeg) > 0), fnirs=True)\nif len(picks) > 0:\n- eeg_actors = _plot_sensors(\n+ actors = _plot_sensors(\nself._renderer, self._info, self._to_cf_t, picks,\n- meg=False, eeg=eeg, fnirs=False, warn_meg=False,\n- head_surf=self._head_geo, units='m',\n+ meg=False, eeg=eeg, fnirs=[\"sources\", \"detectors\"],\n+ warn_meg=False, head_surf=self._head_geo, units='m',\nsensor_opacity=self._defaults[\"sensor_opacity\"],\norient_glyphs=self._orient_glyphs,\nscale_by_distance=self._scale_by_distance,\nproject_points=self._project_eeg,\nsurf=self._head_geo)\n- eeg_actors = eeg_actors[\"eeg\"]\n+ sens_actors = actors[\"eeg\"]\n+ sens_actors.extend(actors[\"fnirs\"])\nelse:\n- eeg_actors = None\n+ sens_actors = None\nelse:\n- eeg_actors = None\n- self._update_actor(\"eeg_channels\", eeg_actors)\n+ sens_actors = None\n+ self._update_actor(\"eeg_channels\", sens_actors)\ndef _add_head_surface(self):\nbem = None\n",
        "chatgpt_cot": "Add error handling for parsing daemon configuration in MainWindow class. Fixes potential issue with loading daemon configuration."
    },
    {
        "org_diff": "diff --git a/rasa_core_sdk/forms.py b/rasa_core_sdk/forms.py @@ -40,14 +40,26 @@ class FormAction(Action):\n@staticmethod\ndef from_entity(entity, intent=None):\n+ # type: (Text, Optional[Text]) -> Dict[Text: Any]\n+ \"\"\"A dictionary to map required slots to\n+ - an extracted entity\n+ \"\"\"\nreturn {\"type\": \"from_entity\", \"intent\": intent, \"entity\": entity}\n@staticmethod\ndef from_intent(intent, value):\n+ # type: (Optional[Text], Any) -> Dict[Text: Any]\n+ \"\"\"A dictionary to map required slots to\n+ - intent: value pair\n+ \"\"\"\nreturn {\"type\": \"from_intent\", \"intent\": intent, \"value\": value}\n@staticmethod\ndef from_text(intent=None):\n+ # type: (Optional[Text]) -> Dict[Text: Any]\n+ \"\"\"A dictionary to map required slots to\n+ - a whole message\n+ \"\"\"\nreturn {\"type\": \"from_text\", \"intent\": intent}\n# noinspection PyMethodMayBeStatic\n",
        "org_msg": "add types and descriptions to from_... helper methods RasaHQ/roadmap#280",
        "sim_msg": "ADD Pydantic Payload, RequestPayload and Response payload",
        "sim_diff": "diff --git a/packages/syft/src/syft/core/node/common/node_service/generic_payload/syft_message.py b/packages/syft/src/syft/core/node/common/node_service/generic_payload/syft_message.py @@ -3,10 +3,12 @@ from typing import Any\nfrom typing import Dict\nfrom typing import List\nfrom typing import Optional\n+from typing import Type\nfrom typing import Union\n# third party\nfrom nacl.signing import VerifyKey\n+from pydantic import BaseModel\n# relative\nfrom .....common.message import ImmediateSyftMessage\n@@ -16,10 +18,26 @@ from .....io.address import Address\nfrom ....abstract.node_service_interface import NodeServiceInterface\n+# Inner Payload message using Pydantic.\n+class Payload(BaseModel):\n+ class Config:\n+ orm_mode = True\n+\n+\n+class RequestPayload(Payload):\n+ pass\n+\n+\n+class ReplyPayload(Payload):\n+ pass\n+\n+\nclass SyftMessage(ImmediateSyftMessage):\n- __attr_allowlist__ = [\"id\", \"payload\", \"address\", \"reply_to\", \"msg_id\", \"kwargs\"]\n+ __attr_allowlist__ = [\"id\", \"address\", \"reply_to\", \"reply\", \"msg_id\", \"kwargs\"]\nsigned_type = SignedMessage\n+ request_payload_type = RequestPayload\n+ reply_payload_type = ReplyPayload\ndef __init__(\nself,\n@@ -27,12 +45,30 @@ class SyftMessage(ImmediateSyftMessage):\nkwargs: Union[List, Dict[str, Any]] = {},\nmsg_id: Optional[UID] = None,\nreply_to: Optional[Address] = None,\n+ reply: bool = False,\n) -> None:\nsuper().__init__(address=address, msg_id=msg_id)\nself.reply_to = reply_to\n+ self.reply = reply\nself.kwargs = kwargs\n+ @property\n+ def payload(self) -> Payload:\n+ kwargs_dict = {}\n+\n+ if hasattr(self.kwargs, \"upcast\"):\n+ kwargs_dict = self.kwargs.upcast() # type: ignore\n+ else:\n+ kwargs_dict = self.kwargs # type: ignore\n+\n+ # If it's not a reply message then load kwargs as a proper request payload.\n+ if not self.reply:\n+ return self.request_payload_type(**kwargs_dict)\n+ # If it's a reply message, then load kwargs as a proper reply payload.\n+ else:\n+ return self.reply_payload_type(**kwargs_dict)\n+\ndef run(\nself, node: NodeServiceInterface, verify_key: Optional[VerifyKey] = None\n- ) -> Union[List, Dict[str, Any]]:\n+ ) -> Union[None, Payload]:\nraise NotImplementedError\n",
        "chatgpt_cot": "Add new methods to FormAction for mapping required slots to an entity, intent, or whole message, improving flexibility and functionality of the class."
    },
    {
        "org_diff": "diff --git a/fkie_node_manager/src/fkie_node_manager/master_view_proxy.py b/fkie_node_manager/src/fkie_node_manager/master_view_proxy.py @@ -1523,6 +1523,8 @@ class MasterViewProxy(QWidget):\nadded_diags = []\nfor diag_status in reversed(node.diagnostic_array):\nif node.diagnostic_array:\n+ level_str = 'Unknown'\n+ if diag_status.level in self.DIAGNOSTIC_LEVELS:\nlevel_str = self.DIAGNOSTIC_LEVELS[diag_status.level]\ndiag_color = '#FF6600'\nif diag_status.level == 2:\n",
        "org_msg": "fkie_node_manager: fix crash on unknown diagnostic level",
        "sim_msg": "Tree: display title for e.g. Frame, allow editing of this and class name",
        "sim_diff": "diff --git a/tree.py b/tree.py @@ -484,7 +484,15 @@ class WidgetTree(wx.TreeCtrl, Tree):\nnew_value = evt.Label\nif new_value==self._build_label(node): return\n- new_name = new_label = new_title = new_tab = None\n+ new_name = new_label = new_title = new_tab = new_class = None\n+\n+ if node.widget.klass != node.widget.base and node.widget.klass != 'wxScrolledWindow':\n+ if new_value.count(\"(\")==1 and new_value.count(\")\")==1:\n+ pre, new_class = new_value.split(\"(\")\n+ new_class, post = new_class.split(\")\")\n+ if pre.endswith(\" \"): pre = pre[:-1]\n+ new_value = pre+post\n+\nif \"label\" in widget.properties and self._label_editable(widget):\nnew_name, new_label = self._split_name_label(new_value)\nelif \"label\" in widget.properties:\n@@ -507,14 +515,23 @@ class WidgetTree(wx.TreeCtrl, Tree):\nif new_name==name_p.get(): new_name = None\nif new_name:\n# check\n- name_OK = name_p.check(new_name)\n- if not name_OK: new_name = None\n+ OK = name_p.check(new_name)\n+ if not OK: new_name = None\n+\n+ # check class/klass\n+ if new_class:\n+ class_p = widget.properties[\"klass\"]\n+ if new_class==class_p.get(): new_class = None\n+ if new_class:\n+ # check\n+ OK = class_p.check(new_class)\n+ if not OK: new_class = None\n# check label\nif new_label is not None:\nlabel_p = widget.properties[\"label\"]\nif new_label==label_p.get(): new_label = None\n- if not new_name and new_label is None and new_title is None and new_tab is None:\n+ if not new_name and new_label is None and new_title is None and new_tab is None and new_class is None:\n# no change or an error\nwx.Bell()\nevt.Veto()\n@@ -543,6 +560,10 @@ class WidgetTree(wx.TreeCtrl, Tree):\nname_p.previous_value = name_p.value\nname_p.set(new_name, notify=False)\nmodified.add(\"name\")\n+ if new_class:\n+ class_p.previous_value = class_p.value\n+ class_p.set(new_class, notify=False)\n+ modified.add(\"class\")\nif new_label:\nlabel_p.previous_value = label_p.value\nlabel_p.set(new_label, notify=False)\n@@ -577,6 +598,9 @@ class WidgetTree(wx.TreeCtrl, Tree):\nif node.widget.klass != node.widget.base and node.widget.klass != 'wxScrolledWindow':\n# special case...\ns += ' (%s)' % node.widget.klass\n+ if getattr(node.widget, \"has_title\", None):\n+ # include title\n+ s += ': \"%s\"'%node.widget.title\nelif \"label\" in node.widget.properties and node.widget.properties[\"label\"].is_active():\n# include label of control\nlabel = node.widget.label\n",
        "chatgpt_cot": "Add handling for unknown diagnostic level in MasterViewProxy to prevent errors and improve functionality."
    },
    {
        "org_diff": "diff --git a/fkie_node_manager/src/fkie_node_manager/parameter_dialog.py b/fkie_node_manager/src/fkie_node_manager/parameter_dialog.py @@ -1400,7 +1400,7 @@ class MasterParameterDialog(ParameterDialog):\ntype_str = 'float'\nelif isinstance(val, list) or isinstance(val, dict):\n# handle representation of `rosparam`\n- type_str = '[]'\n+ type_str = 'list'\nvalue = ''\nfor v in val:\nif len(value) > 0:\n@@ -1417,14 +1417,14 @@ class MasterParameterDialog(ParameterDialog):\nfor n in names_sep:\ngroup_name = n\nif group_name in group:\n- group = group[group_name][1]\n+ group = group[group_name]\nelse:\ntmp_dict = dict()\n- group[group_name] = {':type': 'list', ':value': tmp_dict}\n+ group[group_name] = tmp_dict\ngroup = tmp_dict\n- group[param_name] = {':type': type_str, ':value': [value]}\n+ group[param_name] = {':type': type_str, ':value': value}\nelse:\n- dia_params[param_name] = {':type': type_str, ':value': [value]}\n+ dia_params[param_name] = {':type': type_str, ':value': value}\ntry:\nself.content.createFieldFromValue(dia_params, clear_origin_value=new_param)\nself.setInfoActive(False)\n",
        "org_msg": "fix crash while read config parameter from parameter server",
        "sim_msg": "change variable name to avoid conflicts",
        "sim_diff": "diff --git a/src/genie/libs/parser/junos/show_ospf3.py b/src/genie/libs/parser/junos/show_ospf3.py @@ -84,8 +84,8 @@ class ShowOspf3Interface(ShowOspf3InterfaceSchema):\ngroup = m.groupdict()\nentry = {}\nfor group_key, group_value in group.items():\n- entry_key = group_key.replace('_','-')\n- entry[entry_key] = group_value\n+ entry_key_ = group_key.replace('_','-')\n+ entry[entry_key_] = group_value\nentry_list.append(entry)\ncontinue\n@@ -219,8 +219,8 @@ class ShowOspf3Database(ShowOspf3DatabaseSchema):\ngroup = m.groupdict()\nentry = {}\nfor group_key, group_value in group.items():\n- entry_key = group_key.replace('_','-')\n- entry[entry_key] = group_value\n+ entry_key_ = group_key.replace('_','-')\n+ entry[entry_key_] = group_value\nlsa_id = entry['lsa-id']\nif lsa_id[0] == '*':\n@@ -239,8 +239,8 @@ class ShowOspf3Database(ShowOspf3DatabaseSchema):\ngroup = m.groupdict()\nentry = {}\nfor group_key, group_value in group.items():\n- entry_key = group_key.replace('_','-')\n- entry[entry_key] = group_value\n+ entry_key_ = group_key.replace('_','-')\n+ entry[entry_key_] = group_value\nentry_list.append(entry)\ncontinue\n",
        "chatgpt_cot": "Refactor data structure representation in MasterParameterDialog to use Python list instead of string. Fix issue with nested dictionary assignment."
    },
    {
        "org_diff": "diff --git a/scripts/worker_node/setup_docker_worker_node.sh b/scripts/worker_node/setup_docker_worker_node.sh @@ -24,12 +24,13 @@ bash ./download_images.sh\necho_b \"Copy required fabric 1.0 artifacts\"\nARTIFACTS_DIR=/opt/cello\nUSER=`whoami`\n+USERGROUP=`id -gn`\necho_b \"Checking local artifacts path ${ARTIFACTS_DIR}...\"\n[ ! -d ${ARTIFACTS_DIR} ] \\\n&& echo_r \"Local artifacts path ${ARTIFACTS_DIR} not existed, creating one\" \\\n&& sudo mkdir -p ${ARTIFACTS_DIR} \\\n&& sudo cp -r ../../src/agent/docker/_compose_files/fabric-1.0 ${ARTIFACTS_DIR} \\\n- && sudo chown -R ${USER}:${USER} ${ARTIFACTS_DIR}\n+ && sudo chown -R ${USER}:${USERGROUP} ${ARTIFACTS_DIR}\necho_b \"Setup ip forward rules\"\nsudo sysctl -w net.ipv4.ip_forward=1\n",
        "org_msg": "Fix work-node setup script\nModify user and usergroup when change the authority of /opt/cello",
        "sim_msg": "docker confirmed working now",
        "sim_diff": "diff --git a/docker/backend/Dockerfile b/docker/backend/Dockerfile @@ -36,7 +36,7 @@ RUN set -x \\\nRUN ./scripts/docker/install-go.sh\n# RUN ./scripts/install/workers.sh\n-RUN mkdir -p repos/ logs/ facade/\n+RUN mkdir -p repos/ logs/ /augur/facade/\nCOPY ./docker/backend/entrypoint.sh /\nRUN chmod +x /entrypoint.sh\n",
        "chatgpt_cot": "Fix ownership issue in setup_docker_worker_node.sh script to resolve permission problem and enable proper execution of the script."
    },
    {
        "org_diff": "diff --git a/examples/competitive/__init__.py b/examples/competitive/__init__.py @@ -27,7 +27,7 @@ def run_ladder_game(bot):\nparser.add_argument(\"--ComputerRace\", type=str, nargs=\"?\", help=\"Computer race\")\nparser.add_argument(\"--ComputerDifficulty\", type=str, nargs=\"?\", help=\"Computer difficulty\")\nparser.add_argument(\"--OpponentId\", type=str, nargs=\"?\", help=\"Opponent ID\")\n- parser.add_argument(\"--RealTime\", type=bool, nargs=\"?\", const=True, default=False, help=\"Real Time\")\n+ parser.add_argument(\"--RealTime\", action=\"store_true\", help=\"Real time flag\")\nargs, unknown = parser.parse_known_args()\nif args.LadderServer == None:\n",
        "org_msg": "Use sharpy's --RealTime argparse argument",
        "sim_msg": "Forgot to update iNumPlayers",
        "sim_diff": "diff --git a/v3/runner.py b/v3/runner.py @@ -63,6 +63,8 @@ if __name__ == '__main__':\ncallbacks = []\nname_dict = dict()\n+ gameInputPacket.iNumPlayers = num_bots\n+\n# Set configuration values for bots and store name and team\nfor i in range(num_bots):\nbot_config = configparser.RawConfigParser()\n",
        "chatgpt_cot": "Refactor RealTime argument in ladder game to use action \"store_true\" for clarity and consistency with other arguments."
    },
    {
        "org_diff": "diff --git a/examples/threebase_voidray.py b/examples/threebase_voidray.py @@ -26,12 +26,8 @@ class ThreebaseVoidrayBot(sc2.BotAI):\nif not nexus.has_buff(BuffId.CHRONOBOOSTENERGYCOST):\nabilities = await self.get_available_abilities(nexus)\n- if AbilityId.CHRONOBOOSTENERGYCOST in abilities:\n- await self.do(nexus(AbilityId.CHRONOBOOSTENERGYCOST, nexus))\n- else:\n- await self.chat_send(\"Can't cast chrono boost\")\n- else:\n- await self.chat_send(\"Nexus is already boosted\")\n+ if AbilityId.EFFECT_CHRONOBOOSTENERGYCOST in abilities:\n+ await self.do(nexus(AbilityId.EFFECT_CHRONOBOOSTENERGYCOST, nexus))\nfor idle_worker in self.workers.idle:\nmf = self.state.mineral_field.closest_to(idle_worker)\n",
        "org_msg": "Fix voidray example",
        "sim_msg": "fixed typo in combined equipment energy input item report in api",
        "sim_diff": "diff --git a/myems-aggregation/combined_equipment_energy_input_item.py b/myems-aggregation/combined_equipment_energy_input_item.py @@ -411,7 +411,7 @@ def worker(combined_equipment):\ntry:\nfor equipment in equipment_list:\nequipment_id = str(equipment['id'])\n- query = (\" SELECT start_datetime_utc, energy_category_id, actual_value \"\n+ query = (\" SELECT start_datetime_utc, energy_item_id, actual_value \"\n\" FROM tbl_equipment_input_item_hourly \"\n\" WHERE equipment_id = %s \"\n\" AND start_datetime_utc >= %s \"\n@@ -427,9 +427,9 @@ def worker(combined_equipment):\ncurrent_datetime_utc = row_value[0]\nif current_datetime_utc not in energy_equipment_hourly[equipment_id]:\nenergy_equipment_hourly[equipment_id][current_datetime_utc] = dict()\n- energy_category_id = row_value[1]\n+ energy_item_id = row_value[1]\nactual_value = row_value[2]\n- energy_equipment_hourly[equipment_id][current_datetime_utc][energy_category_id] = \\\n+ energy_equipment_hourly[equipment_id][current_datetime_utc][energy_item_id] = \\\nactual_value\nexcept Exception as e:\nerror_string = \"Error in step 9 of combined_equipment_energy_input_item.worker \" + str(e)\n@@ -563,9 +563,9 @@ def worker(combined_equipment):\nequipment_id = str(equipment['id'])\nmeta_data_dict = energy_equipment_hourly[equipment_id].get(current_datetime_utc, None)\nif meta_data_dict is not None and len(meta_data_dict) > 0:\n- for energy_category_id, actual_value in meta_data_dict.items():\n- aggregated_value['meta_data'][energy_category_id] = \\\n- aggregated_value['meta_data'].get(energy_category_id, Decimal(0.0)) + actual_value\n+ for energy_item_id, actual_value in meta_data_dict.items():\n+ aggregated_value['meta_data'][energy_item_id] = \\\n+ aggregated_value['meta_data'].get(energy_item_id, Decimal(0.0)) + actual_value\naggregated_values.append(aggregated_value)\n",
        "chatgpt_cot": "\"Replace deprecated AbilityId.CHRONOBOOSTENERGYCOST with AbilityId.EFFECT_CHRONOBOOSTENERGYCOST to resolve compilation issue in ThreebaseVoidrayBot.\""
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/network_discovery_dialog.py b/node_manager_fkie/src/node_manager_fkie/network_discovery_dialog.py @@ -87,6 +87,7 @@ class NetworkDiscoveryDialog(QDialog, threading.Thread):\nself.status_label = QLabel('0 messages', self)\nself.verticalLayout.addWidget(self.status_label)\nself.status_text_signal.connect(self.status_label.setText)\n+ self._msg_counts = dict()\nself._networks_count = networks_count\nself._running = True\n@@ -118,6 +119,9 @@ class NetworkDiscoveryDialog(QDialog, threading.Thread):\nif index not in self._discovered:\nself._discovered[index] = dict()\nself._discovered[index][address] = (hostname, time.time())\n+ if hostname not in self._msg_counts:\n+ self._msg_counts[hostname] = 0\n+ self._msg_counts[hostname] += 1\nself._received_msgs += 1\nforce_update = True\nexcept:\n@@ -130,12 +134,14 @@ class NetworkDiscoveryDialog(QDialog, threading.Thread):\nwhile (not rospy.is_shutdown()) and self._running:\nwith self.mutex:\nfor msock in self.sockets:\n+ received = True\n+ while received:\ntry:\nrecv_item = msock.receive_queue.get(False)\nself._received_msgs += 1\nself.on_heartbeat_received(recv_item.msg, recv_item.sender_addr, (recv_item.via == QueueReceiveItem.MULTICAST))\nexcept Queue.Empty:\n- pass\n+ received = False\nstatus_text = 'received messages: %d' % (self._received_msgs)\nself.status_text_signal.emit(status_text)\n# self.parent().masterlist_service.refresh(self.parent().getMasteruri(), False)\n@@ -160,7 +166,7 @@ class NetworkDiscoveryDialog(QDialog, threading.Thread):\nfor index, addr_dict in self._discovered.items():\ntext = ''.join([text, 'Network <b>', str(index), '</b>: <a href=\"', str(index), '\">join</a><dl>'])\nfor addr, (hostname, ts) in addr_dict.items():\n- text = ''.join([text, '<dt>', self._getTsStr(ts), ' <b><u>', str(hostname), '</u></b> ', str(addr), '</dt>\\n'])\n+ text = ''.join([text, '<dt>', self._getTsStr(ts), ' <b><u>', str(hostname), '</u></b> ', str(addr), ', received messages: ', str(self._msg_counts[hostname]), '</dt>\\n'])\ntext = ''.join([text, '</dl><br>'])\ntext = ''.join([text, '</div>'])\nself.display_append_signal.emit(text)\n",
        "org_msg": "node_manager_fkie: improved network discovering",
        "sim_msg": "modified some of the methods",
        "sim_diff": "diff --git a/syft/core/workers/websocket.py b/syft/core/workers/websocket.py import websockets\nimport asyncio\nimport json\n+from .. import utils\nfrom .base import BaseWorker\n@@ -38,8 +39,8 @@ class WebSocketWorker(BaseWorker):\nif(self.verbose):\nprint(\"Starting Socket Worker...\")\n- self.serversocket = websockets.serve(self._server_socket_run, self.hostname, self.port)\n+ self._run_server_socket()\n# if it's a client worker, then we don't want it waiting for commands\n# because it's going to be issuing commands.\n@@ -49,17 +50,27 @@ class WebSocketWorker(BaseWorker):\nelse:\nprint(\"Ready!\")\n+ async def _run_server_socket(self):\n+ self.serversocket = websockets.serve(self._server_socket_run, self.hostname, self.port)\n+ asyncio.get_event_loop().run_until_complete(self.serversocket)\n+ asyncio.get_event_loop().run_forever()\n+\nasync def _client_socket_connect(self, json_request):\nasync with websockets.connect(self.uri) as client_socket:\nawait client_socket.send(json_request)\n+ return await client_socket.recv()\n+\n+\n+ async def _server_socket_run(self, websocket, path):\n+ message_wrapper_json = await websocket.recv()\n+ decoder = utils.PythonJSONDecoder(self)\n+ message_wrapper = decoder.decode(message_wrapper_json)\n+ await websocket.send(self.process_message_type(message_wrapper))\n- async def _server_socket_run(self):\n- asyncio.get_event_loop().run_until_complete(self._start_server)\n- asyncio.get_event_loop().run_forever()\nasync def _client_socket_run(self, json_request):\n- asyncio.get_event_loop().run_until_complete(_client_socket_connect(json_request))\n+ return asyncio.get_event_loop().run_until_complete(self._client_socket_connect(json_request))\ndef whoami(self):\nreturn json.dumps({\"hostname\": self.hostname, \"port\": self.port, \"id\": self.id})\n@@ -106,28 +117,30 @@ class WebSocketWorker(BaseWorker):\nreturn buffer\n- def listen(self, num_messages=-1):\n+ async def listen(self, num_messages=-1):\n\"\"\"\nStarts SocketWorker server on the correct port and handles message as they\nare received.\n\"\"\"\nwhile num_messages != 0:\n-\n+ connection = self.serversocket()\n+ address, port = connection.remote_address()\ntry:\nwhile num_messages != 0:\n# collapse buffer of messages into a string\nmessage = self._process_buffer(self.serversocket)\n# process message and generate response\n- response = self.receive_msg(message, False)\n+ response = self._client_socket_run(message)\nif(response[-1] != \"\\n\"):\nresponse += \"\\n\"\n# send response back\n- connection.send(response.encode())\n+\n+ await connection.send(response.encode())\nif(self.verbose):\n- print(\"Received Command From:\", address)\n+ print(\"Received Command From:\", self.uri)\nnum_messages -= 1\nfinally:\n",
        "chatgpt_cot": "\"Add the count of received messages for each unique hostname to the NetworkDiscoveryDialog class, to display the count of received messages for each hostname.\""
    },
    {
        "org_diff": "diff --git a/sc2/unit.py b/sc2/unit.py @@ -282,7 +282,8 @@ class Unit(object):\n\"\"\" Does not include upgrades \"\"\"\nif hasattr(self._type_data._proto, \"weapons\"):\nweapons = self._type_data._proto.weapons\n- weapon = next((weapon for weapon in weapons if weapon.type in {TargetType.Ground.value, TargetType.Any.value}), None) if weapon:\n+ weapon = next((weapon for weapon in weapons if weapon.type in {TargetType.Ground.value, TargetType.Any.value}), None)\n+ if weapon:\nreturn (weapon.damage * weapon.attacks) / weapon.speed\nreturn 0\n@@ -291,7 +292,7 @@ class Unit(object):\n\"\"\" Does not include upgrades \"\"\"\nif hasattr(self._type_data._proto, \"weapons\"):\nweapons = self._type_data._proto.weapons\n- weapon = next((weapon for weapon in weapons if weapon.type in [TargetType.Ground.value, TargetType.Any.value]), None)\n+ weapon = next((weapon for weapon in weapons if weapon.type in {TargetType.Ground.value, TargetType.Any.value}), None)\nif weapon:\nreturn weapon.range\nreturn 0\n@@ -301,7 +302,7 @@ class Unit(object):\n\"\"\" Does not include upgrades \"\"\"\nif hasattr(self._type_data._proto, \"weapons\"):\nweapons = self._type_data._proto.weapons\n- weapon = next((weapon for weapon in weapons if weapon.type in [TargetType.Air.value, TargetType.Any.value]), None)\n+ weapon = next((weapon for weapon in weapons if weapon.type in {TargetType.Air.value, TargetType.Any.value}), None)\nreturn weapon is not None\nreturn False\n@@ -310,7 +311,7 @@ class Unit(object):\n\"\"\" Does not include upgrades \"\"\"\nif hasattr(self._type_data._proto, \"weapons\"):\nweapons = self._type_data._proto.weapons\n- weapon = next((weapon for weapon in weapons if weapon.type in [TargetType.Air.value, TargetType.Any.value]), None)\n+ weapon = next((weapon for weapon in weapons if weapon.type in {TargetType.Air.value, TargetType.Any.value}), None)\nif weapon:\nreturn (weapon.damage * weapon.attacks) / weapon.speed\nreturn 0\n@@ -320,7 +321,7 @@ class Unit(object):\n\"\"\" Does not include upgrades \"\"\"\nif hasattr(self._type_data._proto, \"weapons\"):\nweapons = self._type_data._proto.weapons\n- weapon = next((weapon for weapon in weapons if weapon.type in [TargetType.Air.value, TargetType.Any.value]), None)\n+ weapon = next((weapon for weapon in weapons if weapon.type in {TargetType.Air.value, TargetType.Any.value}), None)\nif weapon:\nreturn weapon.range\nreturn 0\n",
        "org_msg": "Change list to set",
        "sim_msg": "real acc calc",
        "sim_diff": "diff --git a/objects/player.py b/objects/player.py @@ -799,8 +799,17 @@ class Player:\n# increment playcount\nstats.plays += 1\n- # calculate avg acc based on top 50 scores\n- stats.acc = sum([row['acc'] for row in res[:50]]) / min(50, len(res))\n+ # calculate avg acc based on top 100 scores\n+ tot = div = 0\n+ for i, acc in enumerate(res):\n+ add = int((0.95 ** i) * 100)\n+ tot += row['acc'] * add\n+ div += add\n+\n+ stats.acc = tot / div\n+\n+ # old acc calc\n+ # stats.acc = sum([row['acc'] for row in res[:50]]) / min(50, len(res))\n# calculate weighted pp based on top 100 scores\nstats.pp = round(sum([row['pp'] * 0.95 ** i\n",
        "chatgpt_cot": "Refactor weapon selection logic in Unit class to use set instead of list for TargetType values to improve efficiency and readability."
    },
    {
        "org_diff": "diff --git a/fkie_node_manager/src/fkie_node_manager/editor/text_edit.py b/fkie_node_manager/src/fkie_node_manager/editor/text_edit.py @@ -378,7 +378,8 @@ class TextEdit(QTextEdit):\n# create a new file, if it does not exists\nresult = MessageBox.question(self, \"File not exists\", '\\n\\n'.join([\"Create a new file?\", path]), buttons=MessageBox.Yes | MessageBox.No)\nif result == MessageBox.Yes:\n- nm.nmd().file.save_file(path, '<launch>\\n\\n</launch>', 0)\n+ content = '<launch>\\n\\n</launch>' if path.endswith('.launch') else ''\n+ nm.nmd().file.save_file(path, content.encode(), 0)\nevent.setAccepted(True)\nself.load_request_signal.emit(path)\nexcept Exception as e:\n",
        "org_msg": "fkie_node_manager: editor: fix create new file",
        "sim_msg": "fix settings error with create file dialog",
        "sim_diff": "diff --git a/qualcoder/manage_files.py b/qualcoder/manage_files.py @@ -585,7 +585,7 @@ class DialogManageFiles(QtWidgets.QDialog):\n_(\"Filename in use\"), QtWidgets.QMessageBox.Ok)\nreturn\n- ui = DialogMemo(self.app.settings, _(\"Creating a new file: \") + name)\n+ ui = DialogMemo(self.app, _(\"Creating a new file: \") + name)\nui.exec_()\nfiletext = ui.memo\n# update database\n",
        "chatgpt_cot": "\"Fix issue in creating new file in TextEdit\""
    },
    {
        "org_diff": "diff --git a/fkie_node_manager/src/fkie_node_manager/logscreen/screen_widget.py b/fkie_node_manager/src/fkie_node_manager/logscreen/screen_widget.py @@ -297,6 +297,8 @@ class ScreenWidget(QWidget):\nchars_count = self._seek_count_lines(lines)\nself._seek_start = self.qfile.pos()\ndata = self.qfile.read(chars_count)\n+ if sys.version_info > (3, 0):\n+ data = data.decode('utf-8')\nself.output.emit(data)\nself._seek_end = self.qfile.pos()\nself._first_fill = False\n@@ -306,6 +308,8 @@ class ScreenWidget(QWidget):\nif (not self._pause_read_end and self.qfile.bytesAvailable()):\nstart = self.qfile.pos()\ndata = self.qfile.readAll().data()\n+ if sys.version_info > (3, 0):\n+ data = data.decode('utf-8')\nself.output.emit(data)\nself._seek_end = self.qfile.pos()\nself._info = \"NEW: %d\" % (self._seek_end - start)\n@@ -322,6 +326,8 @@ class ScreenWidget(QWidget):\nchars_count = self._seek_count_lines(lines)\nself._seek_start = self.qfile.pos()\ndata = self.qfile.read(chars_count)\n+ if sys.version_info > (3, 0):\n+ data = data.decode('utf-8')\nself.output_prefix.emit(data)\ndef _seek_count_lines(self, lines=20):\n",
        "org_msg": "fkie_node_manager: python3 compatibility fix",
        "sim_msg": "Added utf-8 encoding to fix html encoding error\nTrial this on Windows 10 to see if it fixes the error: 'charmap' codec can't decode byte 0x9d",
        "sim_diff": "diff --git a/QualCoder/information.py b/QualCoder/information.py @@ -68,7 +68,7 @@ class DialogInformation(QtWidgets.QDialog):\nscriptdir = os.path.dirname(os.path.abspath(__file__))\nhtmlFile = os.path.join(scriptdir, filename)\ntry:\n- with open(htmlFile, 'r') as f:\n+ with open(htmlFile, 'r', encoding='utf8') as f:\nself.text = f.read()\nself.ui.textEdit.setHtml(self.text)\nexcept Exception as e:\n",
        "chatgpt_cot": "Fix data decoding for Python 3 compatibility in ScreenWidget class. Added data.decode('utf-8') to handle data decoding in Python 3."
    },
    {
        "org_diff": "diff --git a/node_manager_daemon_fkie/src/node_manager_daemon_fkie/startcfg.py b/node_manager_daemon_fkie/src/node_manager_daemon_fkie/startcfg.py @@ -111,14 +111,8 @@ class StartConfig():\nif value_type == BOOL:\nreturn value.lower() in (\"yes\", \"true\", \"t\", \"1\")\nif value_type == LIST:\n- lstr = value\ntry:\n- lstr = lstr.strip('[]')\n- lstr = lstr.replace('u\"', '')\n- lstr = lstr.replace('\"', '')\n- lstr = lstr.replace(\"'\", '')\n- lstr = lstr.replace(\",\", ' ')\n- return [utf8(i).strip() for i in lstr.split(' ') if i]\n+ return eval(value)\nexcept Exception:\nreturn []\nreturn value\n",
        "org_msg": "node_manager_daemon_fkie: fix list parameter while start on remote hosts",
        "sim_msg": "make use of start and end inputs in string->bytes/locale",
        "sim_diff": "diff --git a/pycket/prims/string.py b/pycket/prims/string.py @@ -152,13 +152,20 @@ def string_to_symbol(v):\ndefault(values.W_Object, values.w_false),\ndefault(values.W_Fixnum, values.W_Fixnum.ZERO),\ndefault(values.W_Fixnum, None)])\n-def string_to_bytes_locale(str, errbyte, start, end):\n+def string_to_bytes_locale(w_str, errbyte, w_start, w_end):\n# assert errbyte is values.w_false\n# ignore for now\n- assert start.value == 0\n- assert end is None\n+\n+ if w_start.value == 0 and w_end is None:\n+ w_sub_str = w_str\n+ else:\n+ s_val = w_start.value\n+ e_val = w_end.value if w_end else w_str.length()\n+ # FIXME: check the bounds\n+ w_sub_str = w_str.getslice(s_val, e_val)\n+\n# FIXME: This ignores the locale\n- return values.W_Bytes.from_charlist(str.as_charlist_utf8())\n+ return values.W_Bytes.from_charlist(w_sub_str.as_charlist_utf8())\n@expose(\"bytes->string/latin-1\",\n[values.W_Bytes,\n",
        "chatgpt_cot": "Refactor StartConfig class in startcfg.py by simplifying list parsing logic and using eval() for evaluation, improving readability and maintainability of the code."
    },
    {
        "org_diff": "diff --git a/README.md b/README.md ![Cello](docs/imgs/logo.png)\n+Blockchain as a Service!\n+\n**Note:** This is a **read-only mirror** of the formal [Gerrit](https://gerrit.hyperledger.org/r/#/admin/projects/cello) repository,\n-where active development is ongoing. Issue tracking is handled in [Jira](https://jira.hyperledger.org/secure/RapidBoard.jspa?rapidView=111)\n+where active development is ongoing. Issue tracking is handled in [Jira](https://jira.hyperledger.org/projects/CE/issues/).\n## Incubation Notice\nThis project is a Hyperledger project in _Incubation_. It was proposed to the community and documented [here](https://docs.google.com/document/d/1E2i5GRqWsIag7KTxjQ_jQdDiWcuikv3KqXeuw7NaceM/edit), and was approved by [Hyperledger TSC at 2017-01-07](https://lists.hyperledger.org/pipermail/hyperledger-tsc/2017-January/000535.html). Information on what _Incubation_ entails can be found in the [Hyperledger Project Lifecycle document](https://goo.gl/4edNRc).\n-Platform to provide Blockchain as a Service!\nUsing Cello, we can\n-* Provision customizable Blockchains instantly, e.g., a 6-node chain using PBFT consensus.\n+* Provision customizable Blockchains instantly, e.g., a 6-node fabric chain using PBFT consensus.\n* Maintain a pool of running blockchains healthy with no manual operations.\n* Check the system status, scale the chain numbers, change resources... through a dashboard.\n@@ -28,13 +29,11 @@ You can also find more [scenarios](docs/scenario.md).\n* Support heterogeneous architecture, e.g., Z, Power and X86, from bare-metal servers to virtual machines.\n* Extend with monitor/log/health features by employing additional components.\n-## Docs\n-\n-### User Docs\n-* [Dashboard](docs/dashboard.md)\n+## Documentation\n-### Operator Docs\n+### Operational Docs\n* [Installation & Deployment](docs/deployment.md)\n+* [Dashboard](docs/dashboard.md)\n* [Scenarios](docs/scenario.md)\n* [Production Configuration](docs/production_config.md)\n",
        "org_msg": "Update the documentation\nMinor change the description and links.",
        "sim_msg": "Nice README.",
        "sim_diff": "diff --git a/README.md b/README.md @@ -362,7 +362,7 @@ Currently alive channels\n| [/r/trippinthroughtime](https://www.reddit.com/r/trippinthroughtime/) | [@medieval_memes](https://t.me/medieval_memes) | 1 hour |\n| [/r/onepunchman](https://www.reddit.com/r/onepunchman/) | [@r_opm](https://t.me/r_opm) | 1 hour |\n| [/r/preppers](https://www.reddit.com/r/preppers/) | [@r_preppers](https://t.me/r_preppers) | 1 hour |\n-| [/r/Chainlink+Vechain+FetchAI_Community+perlin+Qtum+NEO+hashgraph+IoTeX+elrondnetwork+Aeternity+loopringorg+waltonchain+nebulas+IOStoken+NavCoin+viacoin+skycoin+MoedaBanking+WabiToken+EnjinCoin+OntologyNetwork+PolymathNetwork+insolar+nexusearth+zcoin+zilliqa+quarkchainio+tezos+Neblio+helloicon+ArkEcosystem+kybernetwork+0xProject+BATProject+SysCoin+omise_go+pivx+civicplatform+factom+nem+Stellar+Ripple+Wavesplatform+statusim+Ardor+stratisplatform+GolemProject+komodoplatform+storj+vergecurrency+eos+siacoin](https://www.reddit.com/r/Chainlink+Vechain+FetchAI_Community+perlin+Qtum+NEO+hashgraph+IoTeX+elrondnetwork+Aeternity+loopringorg+waltonchain+nebulas+IOStoken+NavCoin+viacoin+skycoin+MoedaBanking+WabiToken+EnjinCoin+OntologyNetwork+PolymathNetwork+insolar+nexusearth+zcoin+zilliqa+quarkchainio+tezos+Neblio+helloicon+ArkEcosystem+kybernetwork+0xProject+BATProject+SysCoin+omise_go+pivx+civicplatform+factom+nem+Stellar+Ripple+Wavesplatform+statusim+Ardor+stratisplatform+GolemProject+komodoplatform+storj+vergecurrency+eos+siacoin/) | [@cryptoinstantnews2](https://t.me/cryptoinstantnews2) | 1 hour |\n+| [/r/%A_LOT_OF_CRYPTO_RELATED%](https://www.reddit.com/r/Chainlink+Vechain+FetchAI_Community+perlin+Qtum+NEO+hashgraph+IoTeX+elrondnetwork+Aeternity+loopringorg+waltonchain+nebulas+IOStoken+NavCoin+viacoin+skycoin+MoedaBanking+WabiToken+EnjinCoin+OntologyNetwork+PolymathNetwork+insolar+nexusearth+zcoin+zilliqa+quarkchainio+tezos+Neblio+helloicon+ArkEcosystem+kybernetwork+0xProject+BATProject+SysCoin+omise_go+pivx+civicplatform+factom+nem+Stellar+Ripple+Wavesplatform+statusim+Ardor+stratisplatform+GolemProject+komodoplatform+storj+vergecurrency+eos+siacoin/) | [@cryptoinstantnews2](https://t.me/cryptoinstantnews2) | 1 hour |\n| [/r/LeagueOfMemes](https://www.reddit.com/r/LeagueOfMemes/) | [@r_league_of_memes](https://t.me/r_league_of_memes) | 1 hour |\n| [/r/VirtualYoutubers](https://www.reddit.com/r/VirtualYoutubers/) | [@vtuber_en](https://t.me/vtuber_en) | 1 hour |\n| | ... be the next one ... | |@\n",
        "chatgpt_cot": "Update README.md with new information about Blockchain as a Service, update links, and reorganize documentation section for clarity and completeness."
    },
    {
        "org_diff": "diff --git a/fkie_node_manager_daemon/src/fkie_node_manager_daemon/common.py b/fkie_node_manager_daemon/src/fkie_node_manager_daemon/common.py @@ -250,6 +250,8 @@ def interpret_path(path, pwd='.'):\nif len(paths) > 0:\n# if more then one launch file is found, take the first one\nreturn paths[0]\n+ else:\n+ return path\nif path_suffix:\nreturn os.path.normpath(os.path.join(pkg, path_suffix))\nelse:\n",
        "org_msg": "fkie_node_manager_daemon: fixed interpret_path for script_runner",
        "sim_msg": "adding primitive path->directory-path",
        "sim_diff": "diff --git a/pycket/prims/input_output.py b/pycket/prims/input_output.py @@ -882,6 +882,13 @@ def path_to_path_complete_path(path, _base):\nreturn values.W_Path(p)\nreturn values.W_Path(base + os.path.sep + p)\n+@expose(\"path->directory-path\", [values.W_Object])\n+def path_to_path_complete_path(path):\n+ p = extract_path(path)\n+ if p and p[-1] == os.path.sep:\n+ return values.W_Path(p)\n+ return values.W_Path(p + os.path.sep)\n+\n@expose(\"path-convention-type\", [values.W_Path])\ndef path_convention_type(path):\nfrom pycket.prims.general import detect_platform, w_macosx_sym, w_unix_sym\n",
        "chatgpt_cot": "Add a new condition to return the original path if no launch file is found."
    },
    {
        "org_diff": "diff --git a/fkie_node_manager/src/fkie_node_manager/editor/editor.py b/fkie_node_manager/src/fkie_node_manager/editor/editor.py @@ -941,7 +941,7 @@ class Editor(QMainWindow):\nname = \"\"\nif len(lines) == 1:\nname = lines[0]\n- self._insert_text('<param name=\"%s\" value=\"value\" />' % name, 13, len(name))\n+ self._insert_text('<param name=\"%s\" value=\"value\" />' % name, 22 + len(name), 5)\ndef _on_add_param_tag(self):\nself._insert_text('<param name=\"name\" value=\"value\" />', 13, 4)\n",
        "org_msg": "node_manager: editor: select value after add parameter",
        "sim_msg": "Added confirmation request to close TT window when text has been changed (GTK)\nRelates to issue",
        "sim_diff": "diff --git a/extension/textext/asktext.py b/extension/textext/asktext.py @@ -196,7 +196,8 @@ class AskText(object):\nDEFAULT_INSERTSPACES = True\nDEFAULT_TABWIDTH = 4\nDEFAULT_NEW_NODE_CONTENT = \"Empty\"\n- DEFAULT_CLOSE_SHORTCUT = \"None\"\n+ DEFAULT_CLOSE_SHORTCUT = \"Escape\"\n+ DEFAULT_CONFIRM_CLOSE = True\nNEW_NODE_CONTENT = [\"Empty\", \"InlineMath\", \"DisplayMath\"]\nCLOSE_SHORTCUT = [\"Escape\", \"CtrlQ\", \"None\"]\n@@ -242,7 +243,7 @@ class AskText(object):\n@staticmethod\ndef cb_cancel(widget=None, data=None):\n\"\"\"Callback for Cancel button\"\"\"\n- raise SystemExit(1)\n+ pass\ndef cb_ok(self, widget=None, data=None):\n\"\"\"Callback for OK / Save button\"\"\"\n@@ -275,6 +276,11 @@ if TOOLKIT == TK:\nself._frame = None\nself._scale = None\n+ @staticmethod\n+ def cb_cancel(widget=None, data=None):\n+ \"\"\"Callback for Cancel button\"\"\"\n+ raise SystemExit(1)\n+\n@staticmethod\ndef validate_spinbox_input(d, i, P, s, S, v, V, W):\n\"\"\" Ensure that only floating point numbers are accepted as input of a Tk widget\n@@ -748,14 +754,28 @@ if TOOLKIT in (GTK, GTKSOURCEVIEW):\ngtk.main_quit()\nreturn False\n+ def cb_cancel(self, widget=None, data=None):\n+ \"\"\"Callback for Cancel button\"\"\"\n+ self.window_deleted_cb(widget, None, None)\n+\ndef move_cursor_cb(self, text_buffer, cursoriter, mark, view):\nself.update_position_label(text_buffer, view)\n- @staticmethod\n- def window_deleted_cb(widget, event, view):\n- gtk.main_quit()\n+ def window_deleted_cb(self, widget, event, view):\n+ if self._gui_config.get(\"confirm_close\", self.DEFAULT_CONFIRM_CLOSE) and \\\n+ self._source_buffer.get_text(self._source_buffer.get_start_iter(), self._source_buffer.get_end_iter()) \\\n+ != self.text:\n+ dlg = gtk.MessageDialog(self._window, gtk.DIALOG_MODAL, gtk.MESSAGE_QUESTION, gtk.BUTTONS_YES_NO,\n+ \"You made text changes, do you really want to close TexText?\")\n+ res = dlg.run()\n+ dlg.destroy()\n+ if res == gtk.RESPONSE_NO:\nreturn True\n+ gtk.main_quit()\n+ return False\n+\n+\ndef update_preview(self, widget):\n\"\"\"Update the preview image of the GUI using the callback it gave \"\"\"\nif self._preview_callback:\n@@ -1160,11 +1180,13 @@ if TOOLKIT in (GTK, GTKSOURCEVIEW):\nif self.text==\"\":\nif new_node_content_value=='InlineMath':\n- self._source_buffer.set_text(\"$$\")\n+ self.text=\"$$\"\n+ self._source_buffer.set_text(self.text)\niter = self._source_buffer.get_iter_at_offset(1)\nself._source_buffer.place_cursor(iter)\nif new_node_content_value=='DisplayMath':\n- self._source_buffer.set_text(\"$$$$\")\n+ self.text = \"$$$$\"\n+ self._source_buffer.set_text(self.text)\niter = self._source_buffer.get_iter_at_offset(2)\nself._source_buffer.place_cursor(iter)\n",
        "chatgpt_cot": "Update text insertion position in Editor class to fix incorrect offset calculation."
    },
    {
        "org_diff": "diff --git a/sc2/client.py b/sc2/client.py @@ -150,11 +150,10 @@ class Client(Protocol):\nres = await self._execute(\naction=sc_pb.RequestAction(actions=(sc_pb.Action(action_raw=a) for a in combine_actions(actions)))\n)\n- result = [ActionResult(r) for r in res.action.result]\nif return_successes:\n- return result\n+ return [ActionResult(r) for r in res.action.result]\nelse:\n- return [r for r in result if r != ActionResult.Success]\n+ return [ActionResult(r) for r in res.action.result if ActionResult(r) != ActionResult.Success]\nasync def query_pathing(\nself, start: Union[Unit, Point2, Point3], end: Union[Point2, Point3]\n",
        "org_msg": "Improve actions and bot_ai",
        "sim_msg": "add assets, activate, download to client",
        "sim_diff": "diff --git a/planet/api/client.py b/planet/api/client.py @@ -296,3 +296,15 @@ class ClientV1(_Base):\nreturn self.dispatcher.response(models.Request(\nself._url('data/v1/stats'), self.auth,\nbody_type=models.JSON, data=body, method='POST')).get_body()\n+\n+ def get_assets(self, item):\n+ assets_url = item['_links']['assets']\n+ return self._get(assets_url).get_body()\n+\n+ def activate(self, asset):\n+ activate_url = asset['_links']['activate']\n+ return self._get(activate_url).get_body()\n+\n+ def download(self, asset, callback=None):\n+ download_url = asset['location']\n+ return self._get(download_url, models.Image, callback=callback)\n",
        "chatgpt_cot": "\"Refactor return statement in query_pathing method in Client class to handle ActionResult.Success and non-Success cases.\""
    },
    {
        "org_diff": "diff --git a/setup.py b/setup.py @@ -10,7 +10,7 @@ test_requirements = convert_deps_to_pip(pfile[\"dev-packages\"], r=False)\nsetup(\nname=\"burnysc2\",\npackages=find_packages(exclude=[\"examples*\", \"examples\"]),\n- version=\"0.12.9\",\n+ version=\"0.12.10\",\ndescription=\"A StarCraft II API Client for Python 3\",\nlicense=\"MIT\",\nauthor=\"BurnySc2\",\n",
        "org_msg": "Bump version and push to pypi",
        "sim_msg": "Bump {install,extra}_requires versions in setup.py",
        "sim_diff": "diff --git a/setup.py b/setup.py @@ -30,9 +30,9 @@ setup(\npackages=find_packages(exclude=[\"docs*\", \"tests*\"]),\npython_requires=\">=2.7\",\ninstall_requires=[\n- \"requests>=2.21.0\",\n+ \"requests>=2.25.1\",\n],\ninclude_package_data=True,\npackage_data={\"hvac\": [\"version\"]},\n- extras_require={\"parser\": [\"pyhcl>=0.3.10\"]},\n+ extras_require={\"parser\": [\"pyhcl>=0.4.4\"]},\n)\n",
        "chatgpt_cot": "Update version to 0.12.10 in setup.py to reflect the latest changes and improvements in the BurnySc2 package."
    },
    {
        "org_diff": "diff --git a/sc2/paths.py b/sc2/paths.py @@ -25,10 +25,6 @@ CWD = {\nPF = platform.system()\n-if PF not in BASEDIR:\n- logger.critical(f\"Unsupported platform '{PF}'\")\n- exit(1)\n-\ndef get_env():\n# TODO: Linux env conf from: https://github.com/deepmind/pysc2/blob/master/pysc2/run_configs/platforms.py\nreturn None\n@@ -41,14 +37,28 @@ def latest_executeble(versions_dir):\nexit(1)\nreturn path / BINPATH[PF]\n-class Paths(object):\n+\n+class _MetaPaths(type):\n+ \"\"\"\"Lazily loads paths to allow importing the library even if SC2 isn't installed.\"\"\"\n+ def __setup(self):\n+ if PF not in BASEDIR:\n+ logger.critical(f\"Unsupported platform '{PF}'\")\n+ exit(1)\n+\ntry:\n- BASE = Path(os.environ.get(\"SC2PATH\", BASEDIR[PF])).expanduser()\n- EXECUTABLE = latest_executeble(BASE / \"Versions\")\n- CWD = base_dir / CWD[PF] if CWD[PF] else None\n+ self.BASE = Path(os.environ.get(\"SC2PATH\", BASEDIR[PF])).expanduser()\n+ self.EXECUTABLE = latest_executeble(self.BASE / \"Versions\")\n+ self.CWD = base_dir / CWD[PF] if CWD[PF] else None\n- REPLAYS = BASE / \"Replays\"\n- MAPS = BASE / \"Maps\"\n+ self.REPLAYS = self.BASE / \"Replays\"\n+ self.MAPS = self.BASE / \"Maps\"\nexcept FileNotFoundError as e:\nlogger.critical(f\"SC2 installation not found: File '{e.filename}' does not exist.\")\nexit(1)\n+\n+ def __getattr__(self, attr):\n+ self.__setup()\n+ return getattr(self, attr)\n+\n+class Paths(metaclass=_MetaPaths):\n+ \"\"\"Paths for SC2 folders, lazily loaded using the above metaclass.\"\"\"\n",
        "org_msg": "Lazily loads paths to allow importing the library even if SC2 isn't installed",
        "sim_msg": "fixed replay bugs in golang migrator",
        "sim_diff": "diff --git a/tools/migrate_v420/main.go b/tools/migrate_v420/main.go @@ -113,7 +113,7 @@ INSERT INTO scores VALUES (\n:online_checksum\n)`\n-var replays_moved int32\n+var replaysMoved int32\nfunc recalculate_chunk(chunk []Score, table string, increase int) {\ntx := DB.MustBegin()\n@@ -142,13 +142,13 @@ func recalculate_chunk(chunk []Score, table string, increase int) {\ncontinue\n}\n- replay_path := fmt.Sprintf(\"%s/.data/osr/%d.osr\", GulagPath, score.ID)\n- if _, err := os.Stat(replay_path); os.IsNotExist(err) {\n+ oldReplayPath := fmt.Sprintf(\"/tmp/gulag_replays/%d.osr\", score.ID)\n+ if _, err := os.Stat(oldReplayPath); os.IsNotExist(err) {\nfmt.Printf(\"Warning: replay file for old ID %d could not be found\\n\", score.ID)\n} else {\n- new_replay_path := fmt.Sprintf(\"%s/.data/osr/%d.osr\", GulagPath, new_id)\n- os.Rename(replay_path, new_replay_path)\n- atomic.AddInt32(&replays_moved, 1)\n+ newReplayPath := fmt.Sprintf(\"%s/.data/osr/%d.osr\", GulagPath, new_id)\n+ os.Rename(oldReplayPath, newReplayPath)\n+ atomic.AddInt32(&replaysMoved, 1)\n}\nif batch == 3000 {\n@@ -194,6 +194,16 @@ func main() {\npanic(err)\n}\n+ err = os.Rename(fmt.Sprintf(\"%s/.data/osr\", GulagPath), \"/tmp/gulag_replays\")\n+ if err != nil {\n+ panic(err)\n+ }\n+\n+ err = os.Mkdir(fmt.Sprintf(\"%s/.data/osr\", GulagPath), 0755)\n+ if err != nil {\n+ panic(err)\n+ }\n+\nDB = db\nvar wg sync.WaitGroup\n@@ -283,9 +293,14 @@ func main() {\nwg.Wait()\n+ err = os.Remove(\"/tmp/gulag_replays\")\n+ if err != nil {\n+ fmt.Println(\"There are some replays files for which scores could not be found in the database. They have been left at /tmp/gulag_replays.\")\n+ }\n+\nelapsed := time.Since(start)\nfmt.Printf(\"Score migrator took %s\\n\", elapsed)\n- fmt.Printf(\"Moved %d replays\\n\", replays_moved)\n+ fmt.Printf(\"Moved %d replays\\n\", replaysMoved)\nfmt.Printf(\"Do you wish to drop the old tables? (y/n)\\n>> \")\nvar res string\n@@ -293,8 +308,11 @@ func main() {\nres = strings.ToLower(res)\nif res == \"y\" {\n+ fmt.Println(\"Dropping old tables\")\nDB.MustExec(\"drop table scores_vn\")\nDB.MustExec(\"drop table scores_rx\")\nDB.MustExec(\"drop table scores_ap\")\n+ } else {\n+ fmt.Println(\"Not dropping old tables\")\n}\n}\n",
        "chatgpt_cot": "Refactor Paths class to lazily load paths, allowing import even without SC2 installed, improving flexibility and error handling."
    },
    {
        "org_diff": "diff --git a/sc2/sc2process.py b/sc2/sc2process.py @@ -193,7 +193,8 @@ class SC2Process:\n)\nasync def _connect(self):\n- for i in range(60):\n+ # How long it waits for SC2 to start (in seconds)\n+ for i in range(180):\nif self._process is None:\n# The ._clean() was called, clearing the process\nlogger.debug(\"Process cleanup complete, exit\")\n",
        "org_msg": "Increase SC2 start-timeout limit from 1 to 3 minutes",
        "sim_msg": "[NotSoBot] Maybe fix transport error and other minor fixes",
        "sim_diff": "diff --git a/notsobot/notsobot.py b/notsobot/notsobot.py @@ -229,6 +229,7 @@ class NotSoBot(commands.Cog):\nasync def run_process(self, code, response=False):\ntry:\n+ transport = None\nloop = self.bot.loop\nexit_future = asyncio.Future(loop=loop)\ncreate = loop.subprocess_exec(\n@@ -246,6 +247,7 @@ class NotSoBot(commands.Cog):\nprint(e)\nreturn False\nfinally:\n+ if transport:\ntransport.close()\nasync def gist(self, ctx, idk, content: str):\n@@ -626,8 +628,8 @@ class NotSoBot(commands.Cog):\nawait ctx.send(file=file)\nos.remove(path)\nos.remove(path2)\n- except Exception as e:\n- await ctx.send(e)\n+ except Exception:\n+ log.error(\"Error triggering image\", exc_info=True)\ntry:\nos.remove(path)\nos.remove(path2)\n@@ -1603,6 +1605,8 @@ class NotSoBot(commands.Cog):\nurls = await ImageFinder().search_for_images(ctx)\nurl = urls[0]\nb = await self.bytes_download(url)\n+ if not b:\n+ return await ctx.send(\"That's not a valid image to rotate.\")\ndef rotate_img(b, degrees):\nimg = PIL.Image.open(b).convert(\"RGBA\")\n",
        "chatgpt_cot": "Increase waiting time for SC2 to start from 60 seconds to 180 seconds to ensure proper initialization of the process."
    },
    {
        "org_diff": "diff --git a/README.md b/README.md **Note:** This is a **read-only mirror** of the formal [Gerrit](https://gerrit.hyperledger.org/r/#/admin/projects/cello) repository. Find more details at [Cello Wiki](https://wiki.hyperledger.org/projects/cello).\n-![Cello](docs/imgs/logo.png)\n+![Cello](docs/images/logo.png)\nHyperledger Cello is a blockchain provision and operation system, which helps manage blockchain networks in an efficient way.\n@@ -21,7 +21,7 @@ Using Cello, everyone can easily:\nA typical usage scenario is illustrated as:\n-![Typical Scenario](docs/imgs/scenario.png)\n+![Typical Scenario](docs/images/scenario.png)\n## Quick Start\n",
        "org_msg": "Fix the image path\nAlso to test the new github-based process",
        "sim_msg": "add integrity checks after s3 download as well",
        "sim_diff": "diff --git a/lbrynet/core/Wallet.py b/lbrynet/core/Wallet.py @@ -113,7 +113,8 @@ class Wallet(object):\nelse:\nwith open(os.path.join(self.config.path, \"blockchain_headers\"), \"wb\") as headers_file:\nyield treq.collect(response, headers_file.write)\n- log.info(\"fetched headers from s3 (s3 height: %i)\", s3_height)\n+ log.info(\"fetched headers from s3 (s3 height: %i), now verifying integrity after download.\", s3_height)\n+ self._check_header_file_integrity()\nelse:\nlog.warning(\"s3 is more out of date than we are\")\nelse:\n@@ -143,7 +144,7 @@ class Wallet(object):\nfrom lbrynet import conf\nif conf.settings['blockchain_name'] != \"lbrycrd_main\":\ndefer.returnValue(False)\n- self._check_header_file_integrity(conf)\n+ self._check_header_file_integrity()\ns3_headers_depth = conf.settings['s3_headers_depth']\nif not s3_headers_depth:\ndefer.returnValue(False)\n@@ -159,8 +160,11 @@ class Wallet(object):\nlog.warning(\"error requesting remote height from %s:%i - %s\", server_url, port, err)\ndefer.returnValue(False)\n- def _check_header_file_integrity(self, conf):\n+ def _check_header_file_integrity(self):\n# TODO: temporary workaround for usability. move to txlbryum and check headers instead of file integrity\n+ from lbrynet import conf\n+ if conf.settings['blockchain_name'] != \"lbrycrd_main\":\n+ return\nhashsum = sha256()\nchecksum_height, checksum = conf.settings['HEADERS_FILE_SHA256_CHECKSUM']\nchecksum_length_in_bytes = checksum_height * HEADER_SIZE\n",
        "chatgpt_cot": "Update README.md to fix image paths and provide information about Hyperledger Cello."
    },
    {
        "org_diff": "diff --git a/sc2/proxy.py b/sc2/proxy.py @@ -170,7 +170,7 @@ class Proxy:\nwhile self.result is None:\nbot_alive = bot_process and bot_process.poll() is None\n- sc2_alive = self.controller.running and self.controller._process._process.poll() is None\n+ sc2_alive = self.controller.running\nif self.done or not (bot_alive and sc2_alive):\nlogger.info(\nf\"Proxy({self.port}): {self.player.name} died, \"\n",
        "org_msg": "Fix crashes on linux",
        "sim_msg": "remove old timeout things",
        "sim_diff": "diff --git a/pajbot/bot.py b/pajbot/bot.py @@ -864,45 +864,6 @@ class Bot:\nself._timeout(username, 3600)\nreturn True\n- raw_m = event.arguments[0]\n- m = \"\".join(sorted(set(raw_m), key=raw_m.index))\n- m = \"\".join(ch for ch in m if ch.isalnum())\n- if \"niqers\" in m:\n- self.timeout(username, 600)\n- return True\n-\n- if \"niqe3rs\" in m:\n- self.timeout(username, 600)\n- return True\n-\n- if \"niq3ers\" in m:\n- self.timeout(username, 600)\n- return True\n-\n- if \"niqurs\" in m:\n- self.timeout(username, 600)\n- return True\n-\n- if \"nigurs\" in m:\n- self.timeout(username, 600)\n- return True\n-\n- if \"nige3rs\" in m:\n- self.timeout(username, 600)\n- return True\n-\n- if \"nig3ers\" in m:\n- self.timeout(username, 600)\n- return True\n-\n- if \"nig3ers\" in m:\n- self.timeout(username, 600)\n- return True\n-\n- if \"nigger\" in m:\n- self.timeout(username, 600)\n- return True\n-\n# We use .lower() in case twitch ever starts sending non-lowercased usernames\nwith self.users.get_user_context(username) as source:\nres = HandlerManager.trigger(\"on_pubmsg\", source=source, message=event.arguments[0])\n",
        "chatgpt_cot": "Fix sc2_alive condition in Proxy class to prevent incorrect logic."
    },
    {
        "org_diff": "diff --git a/sc2/unit.py b/sc2/unit.py @@ -397,6 +397,15 @@ class Unit:\n<= (self.radius + target.radius + unit_attack_range + bonus_distance) ** 2\n)\n+ def target_melee_in_range(self, target: \"Unit\", bonus_distance: Union[int, float] = 0) -> bool:\n+ \"\"\" Checks if the target is in melee range.\n+ Includes the target's radius when calculating distance to target.\n+ This function is ideal for checking if an scv is in range to repair a target. \"\"\"\n+ return (\n+ self._bot_object._distance_squared_unit_to_unit(self, target)\n+ <= (self.radius + target.radius + bonus_distance) ** 2\n+ )\n+\ndef in_ability_cast_range(\nself, ability_id: AbilityId, target: Union[\"Unit\", Point2], bonus_distance: float = 0\n) -> bool:\n",
        "org_msg": "Add target_melee_in_range for scv repair",
        "sim_msg": "eccentric coordinates",
        "sim_diff": "diff --git a/auto_lens/profile.py b/auto_lens/profile.py @@ -46,7 +46,7 @@ class EllipticalProfile(object):\ndef coordinates_to_centre(self, coordinates):\n\"\"\"\n- Converts image coordinates to mass profile's centre\n+ Converts image coordinates to profile's centre\nParameters\n----------\n@@ -61,12 +61,12 @@ class EllipticalProfile(object):\ndef coordinates_to_radius(self, coordinates):\n\"\"\"\n- Compute the distance of image coordinates from (0.0). which should be the mass profile centre\n+ Convert the coordinates to a radius\nParameters\n----------\ncoordinates : (float, float)\n- The image coordinates shifted to the mass profile centre (x, y)\n+ The image coordinates (x, y)\nReturns\n-------\n@@ -76,6 +76,28 @@ class EllipticalProfile(object):\nreturn math.sqrt(shifted_coordinates[0] ** 2 + shifted_coordinates[1] ** 2)\n+ def coordinates_to_eccentric_radius(self, coordinates, is_elliptical_effective_radius=False):\n+ \"\"\"\n+ Convert the coordinates to a radius in elliptical space.\n+\n+ Parameters\n+ ----------\n+ coordinates : (float, float)\n+ The image coordinates (x, y)\n+ is_elliptical_effective_radius: Boolean\n+ False -> effective radius for a circular aperture\n+ True -> effective radius for an elliptical aperture\n+ Returns\n+ -------\n+ The radius at those coordinates\n+ \"\"\"\n+ shifted_coordinates = self.coordinates_to_centre(coordinates)\n+\n+ if is_elliptical_effective_radius:\n+ return math.sqrt(shifted_coordinates[0] ** 2 + (shifted_coordinates[1] / self.axis_ratio) ** 2)\n+ return math.sqrt(\n+ self.axis_ratio * shifted_coordinates[0] ** 2 + (shifted_coordinates[1] / self.axis_ratio) ** 2)\n+\n# TODO: This isn't using any variable from the class. Should it be?\n@staticmethod\ndef coordinates_angle_from_x(coordinates):\n@@ -224,7 +246,7 @@ class SersicLightProfile(EllipticalProfile):\n-self.sersic_constant * (((radius / self.effective_radius) ** (1. / self.sersic_index)) - 1))\ndef flux_at_coordinates(self, coordinates):\n- radius = self.coordinates_to_radius(coordinates)\n+ radius = self.coordinates_to_eccentric_radius(coordinates)\nreturn self.flux_at_radius(radius)\ndef as_array(self, x_min=0, y_min=0, x_max=100, y_max=100):\n",
        "chatgpt_cot": "Add method to check if target is in melee range, including target's radius. Ideal for checking if SCV is in range to repair target."
    },
    {
        "org_diff": "diff --git a/.github/workflows/docker-ci.yml b/.github/workflows/docker-ci.yml @@ -29,6 +29,12 @@ jobs:\nsteps:\n- uses: actions/checkout@v1\n+ - name: Enable experimental docker features\n+ run: |\n+ sudo cat /etc/docker/daemon.json\n+ echo $'{\\n \"experimental\": true\\n}' | sudo tee /etc/docker/daemon.json\n+ sudo systemctl restart docker.service\n+\n- name: Run shell script\nrun: |\nexport VERSION_NUMBER=${{ env.VERSION_NUMBER }}\n",
        "org_msg": "Enable docker experimental features before running shell script",
        "sim_msg": "Split build and run of Docker container.\nSplit commands to get separate logs in CI.",
        "sim_diff": "diff --git a/.github/workflows/test.yml b/.github/workflows/test.yml @@ -22,6 +22,9 @@ jobs:\nsteps:\n- uses: actions/checkout@v2\n+ - name: Build Docker\n+ run: |\n+ make docker-qa-build PYTHON_VERSION=${{matrix.python-version}}\n- name: Run Docker\nrun: |\n.github/bump_version ./ minor > atlassian/VERSION\n",
        "chatgpt_cot": "Enable experimental docker features in docker-ci.yml workflow file. This modification adds a step to enable experimental docker features in the workflow."
    },
    {
        "org_diff": "diff --git a/node_manager_daemon_fkie/src/node_manager_daemon_fkie/settings.py b/node_manager_daemon_fkie/src/node_manager_daemon_fkie/settings.py @@ -125,9 +125,8 @@ class Settings:\nresult = value\nelse:\nresult = value\n- except Exception as _exc:\n- pass\n- # print exc\n+ except Exception as exc:\n+ rospy.logdebug(\"Cant't get parameter '%s', full parameter path: '%s'\" % (utf8(exc), param_name))\nreturn result\ndef set_param(self, param_name, value, tag=':value'):\n@@ -155,8 +154,8 @@ class Settings:\n# create new parameter entry\ncfg_item[pname] = {val_tag: value}\nself.save()\n- except Exception as _exc:\n- pass\n+ except Exception as exc:\n+ rospy.logdebug(\"Cant't set parameter '%s', full parameter path: '%s'\" % (utf8(exc), param_name))\ndef reload(self):\n'''\n",
        "org_msg": "node_manager_daemon_fkie: added some debug outputs",
        "sim_msg": "raise exceptions, dont yield them",
        "sim_diff": "diff --git a/lbrynet/lbrynet_daemon/Daemon.py b/lbrynet/lbrynet_daemon/Daemon.py @@ -1350,10 +1350,9 @@ class Daemon(AuthJSONRPCServer):\nfn = self.callable_methods.get(command)\nif fn is None:\n- yield Exception(\n+ raise Exception(\n\"No help available for '{}'. It is not a valid command.\".format(command)\n)\n- return\nyield {\n'help': fn.__doc__\n",
        "chatgpt_cot": "Add logging for exception handling in parameter get and set methods in Settings class to improve error visibility and debugging."
    },
    {
        "org_diff": "diff --git a/sc2/unit.py b/sc2/unit.py @@ -1191,7 +1191,7 @@ class Unit:\n@property\ndef weapon_ready(self) -> bool:\n\"\"\" Checks if the weapon is ready to be fired. \"\"\"\n- return self.weapon_cooldown < self._bot_object.client.game_step\n+ return self.weapon_cooldown == 0\n@property\ndef engaged_target_tag(self) -> int:\n",
        "org_msg": "Change weapon_ready property to weapon_cooldown ==0",
        "sim_msg": "fixed refactor bug",
        "sim_diff": "diff --git a/saltie.py b/saltie.py @@ -134,7 +134,7 @@ class Agent:\nframe_time = time.time() - self.last_frame_time\nself.last_frame_time = time.time()\ninput_state = self.model.create_input_array(game_tick_packet, frame_time)\n- if self.state_dim != len(input_state):\n+ if self.model.state_dim != len(input_state):\nprint('wrong input size', self.index, len(input_state))\nreturn self.actions_handler.create_controller_from_selection(\nself.actions_handler.get_random_option()) # do not return anything\n",
        "chatgpt_cot": "\"Change weapon_ready method to check if weapon cooldown is 0. Improve accuracy of weapon readiness check.\""
    },
    {
        "org_diff": "diff --git a/rasa_core_sdk/endpoint.py b/rasa_core_sdk/endpoint.py @@ -11,7 +11,7 @@ from flask_cors import CORS, cross_origin\nfrom gevent.pywsgi import WSGIServer\nfrom rasa_core_sdk.executor import ActionExecutor\n-from rasa_core.utils import ActionExecutionError\n+from rasa_core.actions.action import ActionExecutionError\nDEFAULT_SERVER_PORT = 5055\n",
        "org_msg": "move actionexecution error",
        "sim_msg": "Take into account the blobstore service port",
        "sim_diff": "diff --git a/djangae/sandbox.py b/djangae/sandbox.py @@ -230,7 +230,7 @@ def _local(devappserver2=None, configuration=None, options=None, wsgi_request_in\n# We set the API and Admin ports so that they are beyond any modules (if you\n# have 10 modules then these values will shift, but it's better that they are predictable\n# in the common case)\n- options.api_port = get_next_available_port(url, DEFAULT_API_PORT)\n+ options.api_port = get_next_available_port(url, max(DEFAULT_API_PORT, port + 1))\noptions.admin_port = get_next_available_port(url, max(DEFAULT_ADMIN_PORT, options.api_port + 1))\nif hasattr(api_server, \"create_api_server\"):\n",
        "chatgpt_cot": "Fix import error in endpoint.py due to changes in ActionExecutionError import statement."
    },
    {
        "org_diff": "diff --git a/docs/setup_worker_docker.md b/docs/setup_worker_docker.md @@ -79,4 +79,10 @@ $ docker run -d -v /var/run/docker.sock:/var/run/docker.sock -p 127.0.0.1:2375:2\n$ docker -H 127.0.0.1:2375 info\n```\n+And users can use `0.0.0.0` to replace `127.0.0.1` to make sure Master can reach Worker Node through this port, as Ubuntu.\n+\n+```bash\n+$ docker run -d -v /var/run/docker.sock:/var/run/docker.sock -p 0.0.0.0:2375:2375 bobrik/socat TCP-LISTEN:2375,fork UNIX-CONNECT:/var/run/docker.sock\n+```\n+\n<a rel=\"license\" href=\"http://creativecommons.org/licenses/by/4.0/\"><img alt=\"Creative Commons License\" style=\"border-width:0\" src=\"https://i.creativecommons.org/l/by/4.0/88x31.png\" /></a><br />This work is licensed under a <a rel=\"license\" href=\"http://creativecommons.org/licenses/by/4.0/\">Creative Commons Attribution 4.0 International License</a>.\n",
        "org_msg": "[CE-490]Add a new command to start worker with mac os\nmake it more friendly for users to start a docker worker node with mac os\n#done",
        "sim_msg": "updated top-level README",
        "sim_diff": "diff --git a/README.md b/README.md # ACL Anthology\n-(This repo was originally wing-nus/acl and has been transferred over to acl-org\n-as of 5 Jun 2017. Please update accordingly.)\n-\n-These are basic instructions on generating the ACL Anthology website as seen on\n-<https://aclweb.org/anthology/>.\n-\n+These are basic instructions on generating the ACL Anthology website as seen on <https://aclweb.org/anthology/>.\n+The offical home of this repository is <https://github.com/acl-org/acl-anthology>.\n## Generating the Anthology\n@@ -64,21 +60,18 @@ about a minute to start.\n## Contributing\n-If you'd like to contribute to the ACL Anthology, please take a look at our\n-[information on volunteering](https://aclanthology.info/volunteer) and the\n-[detailed README](README_detailed.md) containing more in-depth information about\n-generating and modifying the website.\n+If you'd like to contribute to the ACL Anthology, please take a look at:\n+- our [Github issues page](https://github.com/acl-org/acl-anthology/issues)\n+- our [call for volunteers](https://aclanthology.info/volunteer)\n+- the [detailed README](README_detailed.md) which contains more in-depth information about generating and modifying the website.\n-## License\n+## History\n-Materials prior to 2016 here are licensed under the [Creative Commons\n-Attribution-NonCommercial-ShareAlike 3.0 International\n-License](https://creativecommons.org/licenses/by-nc-sa/3.0/). Permission is\n-granted to make copies for the purposes of teaching and research. Materials\n-published in or after 2016 are licensed on a [Creative Commons Attribution 4.0\n-License](https://creativecommons.org/licenses/by/4.0/).\n+This repo was originally wing-nus/acl and has been transferred over to acl-org as of 5 June 2017.\n-Matt Post (Editor, 2019-) / Min-Yen Kan (Editor, 2008-2018) / Steven Bird (Editor, 2001-2007)\n+## License\n-Developer team: Linh Hien Ng (linhhienng at gmail dot com), Duong Ho Tuan zamakkat at gmail dot com)\n+Materials prior to 2016 here are licensed under the [Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License](https://creativecommons.org/licenses/by-nc-sa/3.0/).\n+Permission is granted to make copies for the purposes of teaching and research.\n+Materials published in or after 2016 are licensed on a [Creative Commons Attribution 4.0 License](https://creativecommons.org/licenses/by/4.0/).\n",
        "chatgpt_cot": "Update setup_worker_docker.md to include instructions for using '0.0.0.0' as a replacement for '127.0.0.1' to ensure Master can reach Worker Node."
    },
    {
        "org_diff": "diff --git a/sc2/unit.py b/sc2/unit.py @@ -357,6 +357,14 @@ class Unit:\nspeed *= SPEED_ALTERING_BUFFS.get(buff, 1)\nreturn speed\n+ @property\n+ def distance_per_step(self) -> float:\n+ return (self.real_speed/22.4) * self._bot_object.client.game_step\n+\n+ @property\n+ def distance_to_weapon_ready(self) -> float:\n+ return (self.real_speed / 22.4) * self.weapon_cooldown\n+\n@property\ndef is_mineral_field(self) -> bool:\n\"\"\" Checks if the unit is a mineral field. \"\"\"\n@@ -1177,6 +1185,10 @@ class Unit:\nreturn self._proto.weapon_cooldown\nreturn -1\n+ @property\n+ def weapon_ready(self) -> bool:\n+ return self.weapon_cooldown < self._bot_object.client.game_step\n+\n@property\ndef engaged_target_tag(self) -> int:\n# TODO What does this do?\n",
        "org_msg": "unit.py changes",
        "sim_msg": "cleaner handle calc_df_row warning",
        "sim_diff": "diff --git a/slm_lab/agent/__init__.py b/slm_lab/agent/__init__.py @@ -129,6 +129,8 @@ class Body:\nframe = self.env.clock.get('frame')\nwall_t = env.clock.get_elapsed_wall_t()\nfps = 0 if wall_t == 0 else frame / wall_t\n+ with np.errstate(all='ignore'):\n+ total_reward = np.nanmean(env.total_reward) # guard for vec env\n# update debugging variables\nif net_util.to_check_train_step():\n@@ -144,7 +146,7 @@ class Body:\n'opt_step': self.env.clock.get('opt_step'),\n'frame': frame,\n'fps': fps,\n- 'total_reward': np.nanmean(env.total_reward), # guard for vec env\n+ 'total_reward': total_reward,\n'total_reward_ma': np.nan, # update outside\n'loss': self.loss,\n'lr': self.get_mean_lr(),\n",
        "chatgpt_cot": "Add properties for distance calculation and weapon readiness. Improve unit functionality for game simulation in sc2/unit.py."
    },
    {
        "org_diff": "diff --git a/src/agent/ansible/README.md b/src/agent/ansible/README.md @@ -33,12 +33,13 @@ need to do should be identical.\nsudo apt-get update\nsudo apt-get install python-dev python-pip libssl-dev libffi-dev -y\nsudo pip install --upgrade pip\n- sudo pip install six==1.10.0\n- sudo pip install ansible==2.3.0.0\n+ sudo pip install 'ansible>=2.3.0.0'\ngit clone https://gerrit.hyperledger.org/r/cello\nAll the following work assumed that you are in cello/src/agent/ansible directory\n+Supported ansible versions are 2.3.0.0 or greater.\n+\n## Deploy hyperledger fabric onto different environment\n### On VirtualBox::\n",
        "org_msg": "Add supported ansible versions",
        "sim_msg": "Try pinning pip to compatible version",
        "sim_diff": "diff --git a/ansible/test_playbook.sh b/ansible/test_playbook.sh @@ -5,7 +5,7 @@ set -e -o pipefail\n# Install ansible dependencies\ncd /openprescribing/ansible\napt-get update && apt-get -qq -y install locales curl python3\n-curl https://bootstrap.pypa.io/get-pip.py | python3\n+curl https://bootstrap.pypa.io/3.5/get-pip.py | python3\necho \"Downgrading setuptools to <50 for Debian/Ubuntu compatibility\"\npip install setuptools==49.6.0\n/usr/local/bin/pip install -r vagrant_requirements.txt\n",
        "chatgpt_cot": "Update ansible installation instructions to support versions 2.3.0.0 or greater, ensuring compatibility with Hyperledger Fabric deployment in the README.md file."
    },
    {
        "org_diff": "diff --git a/fkie_node_manager/src/fkie_node_manager/editor/text_search_thread.py b/fkie_node_manager/src/fkie_node_manager/editor/text_search_thread.py @@ -140,7 +140,7 @@ class TextSearchThread(QObject, threading.Thread):\nnew_dict = dict(args)\nnew_dict.update(include_args)\n# test search string for 'name=' and skip search in not launch files\n- if self._only_launch or inc_path.endswith('.launch') or path.find('.launch.') > 0:\n+ if not self._only_launch or inc_path.endswith('.launch') or path.find('.launch.') > 0:\nself.search(search_text, inc_path, recursive, new_dict, count + 1)\nif self._path == path and self._found == 0:\nself.warning_signal.emit(\"not found '%s' in %s (%srecursive)\" % (search_text, path, '' if recursive else 'not '))\n",
        "org_msg": "fkie_node_manager: editor: fixed recursive search",
        "sim_msg": "Avoid loop in doctest\nThis makes it fail on Travis-CI",
        "sim_diff": "diff --git a/gaphor/misc/gidlethread.py b/gaphor/misc/gidlethread.py @@ -44,8 +44,9 @@ class GIdleThread(object):\n>>> t = GIdleThread(counter(123))\n>>> id = t.start()\n>>> main = GLib.main_context_default()\n- >>> while t.is_alive():\n- ... main.iteration(False) # doctest: +ELLIPSIS\n+ >>> t.is_alive()\n+ True\n+ >>> main.iteration(False) # doctest: +ELLIPSIS\nTrue\n\"\"\"\n",
        "chatgpt_cot": "Update text search condition to include all files, not just launch files, in the TextSearchThread class."
    },
    {
        "org_diff": "diff --git a/fkie_node_manager_daemon/src/fkie_node_manager_daemon/version.py b/fkie_node_manager_daemon/src/fkie_node_manager_daemon/version.py @@ -61,23 +61,23 @@ def detect_version(package):\ntry:\nwith open(\"%s/VERSION\" % pkg_path) as f:\nversion = f.read()\n- version = version.strip()\n+ version = version.strip().decode('utf-8')\nwith open(\"%s/DATE\" % pkg_path) as f:\ndatetag = f.read().split()\nif datetag:\n- date = datetag[0]\n+ date = datetag[0].decode('utf-8')\nexcept Exception as err:\nsys.stderr.write(\"version detection error: %s\" % utf8(err))\nelif os.path.isdir(\"%s/../.git\" % pkg_path):\ntry:\nos.chdir(pkg_path)\nps = SupervisedPopen(['git', 'describe', '--tags', '--dirty', '--always', '--abbrev=8'], stdout=subprocess.PIPE, object_id='get git version')\n- output = ps.stdout.read()\n+ output = ps.stdout.read().decode('utf-8')\nversion = output.strip()\nps = SupervisedPopen(['git', 'show', '-s', '--format=%ci'], stdout=subprocess.PIPE, object_id='get git date')\noutput = ps.stdout.read().split()\nif output:\n- date = output[0]\n+ date = output[0].decode('utf-8')\nexcept Exception as err:\nsys.stderr.write(\"version detection error: %s\" % utf8(err))\nelse:\n",
        "org_msg": "fkie_node_manager_daemon: fixed read version with python 3",
        "sim_msg": "fix: updated setversion.py to not clobber",
        "sim_diff": "diff --git a/setversion.py b/setversion.py @@ -27,7 +27,8 @@ message = sys.argv[2]\nmaterialize_version(version)\nprint(\"Updated __init__.py with version \" + version)\n-subprocess.check_output(\"git reset && git add cloudvolume/__init__.py && git commit --amend --no-edit\", shell=True)\n+assert len(version) < 9\n+subprocess.check_output(\"git reset && git add cloudvolume/__init__.py && git commit -m 'Version {}'\".format(version), shell=True)\ntry:\nsubprocess.check_output(['git', 'tag', '-a', version, '-m', message])\n",
        "chatgpt_cot": "Fix encoding issue in version detection for UTF-8 in version.py file. Added decoding for version and date strings to prevent errors."
    },
    {
        "org_diff": "diff --git a/sc2/bot_ai.py b/sc2/bot_ai.py @@ -78,8 +78,9 @@ class BotAI(DistanceCalculation):\nself.larva_count: int = None\nself.actions: List[UnitCommand] = []\nself.blips: Set[Blip] = set()\n- self._units_previous_map: dict = dict()\n- self._structures_previous_map: dict = dict()\n+ self._unit_tags_seen_this_game: Set[int] = set()\n+ self._units_previous_map: Dict[int, Unit] = dict()\n+ self._structures_previous_map: Dict[int, Unit] = dict()\nself._previous_upgrades: Set[UpgradeId] = set()\n# Internally used to keep track which units received an action in this frame, so that self.train() function does not give the same larva two orders - cleared every frame\nself._unit_tags_received_action: Set[int] = set()\n@@ -1326,7 +1327,8 @@ class BotAI(DistanceCalculation):\nasync def _issue_unit_added_events(self):\nfor unit in self.units:\n- if unit.tag not in self._units_previous_map:\n+ if unit.tag not in self._units_previous_map and unit.tag not in self._unit_tags_seen_this_game:\n+ self._unit_tags_seen_this_game.add(unit.tag)\nawait self.on_unit_created(unit)\nasync def _issue_upgrade_events(self):\n",
        "org_msg": "Fix \"on_unit_created\" event when workers are leaving the gas structure",
        "sim_msg": "Forgot to update iNumPlayers",
        "sim_diff": "diff --git a/v3/runner.py b/v3/runner.py @@ -63,6 +63,8 @@ if __name__ == '__main__':\ncallbacks = []\nname_dict = dict()\n+ gameInputPacket.iNumPlayers = num_bots\n+\n# Set configuration values for bots and store name and team\nfor i in range(num_bots):\nbot_config = configparser.RawConfigParser()\n",
        "chatgpt_cot": "Add unit tag tracking and change map data types to Dict to improve performance and solve unit duplication issue in BotAI."
    },
    {
        "org_diff": "diff --git a/sc2/unit.py b/sc2/unit.py @@ -178,6 +178,19 @@ class Unit(object):\n\"\"\" Checks if a geyser has gas remaining (cant build extractors on empty geysers), useful for lategame \"\"\"\nreturn self._proto.vespene_contents > 0\n+ @property\n+ def weapon_cooldown(self):\n+ \"\"\" Returns time in game loops (self.state.game_loop) until the unit can fire again\n+ Usage:\n+ if unit.weapon_cooldown == 0:\n+ await self.do(unit.attack(target))\n+ else:\n+ await self.do(unit.move(retreatPosition))\n+ \"\"\"\n+ if self.can_attack_ground or self.can_attack_air:\n+ return self._proto.weapon_cooldown\n+ return 1000\n+\n@property\ndef can_attack_ground(self):\n# See data_pb2.py line 141 for info on weapon data\n",
        "org_msg": "Add weapon_cooldown to Unit attributes",
        "sim_msg": "queen_attack: replace assertFalse with assertIs",
        "sim_diff": "diff --git a/exercises/queen-attack/queen_attack_test.py b/exercises/queen-attack/queen_attack_test.py @@ -27,28 +27,28 @@ class QueenAttackTest(unittest.TestCase):\nself.assertEqual(board((0, 6), (1, 7)), ans)\ndef test_attack_true1(self):\n- self.assertTrue(can_attack((2, 3), (5, 6)))\n+ self.assertIs(can_attack((2, 3), (5, 6)), True)\ndef test_attack_true2(self):\n- self.assertTrue(can_attack((2, 6), (5, 3)))\n+ self.assertIs(can_attack((2, 6), (5, 3)), True)\ndef test_attack_true3(self):\n- self.assertTrue(can_attack((2, 4), (2, 7)))\n+ self.assertIs(can_attack((2, 4), (2, 7)), True)\ndef test_attack_true4(self):\n- self.assertTrue(can_attack((5, 4), (2, 4)))\n+ self.assertIs(can_attack((5, 4), (2, 4)), True)\ndef test_attack_true5(self):\n- self.assertTrue(can_attack((1, 1), (6, 6)))\n+ self.assertIs(can_attack((1, 1), (6, 6)), True)\ndef test_attack_true6(self):\n- self.assertTrue(can_attack((0, 6), (1, 7)))\n+ self.assertIs(can_attack((0, 6), (1, 7)), True)\ndef test_attack_false1(self):\n- self.assertFalse(can_attack((4, 2), (0, 5)))\n+ self.assertIs(can_attack((4, 2), (0, 5)), False)\ndef test_attack_false2(self):\n- self.assertFalse(can_attack((2, 3), (4, 7)))\n+ self.assertIs(can_attack((2, 3), (4, 7)), False)\n# If either board or can_attack are called with an invalid board position\n# they should raise a ValueError with a meaningful error message.\n",
        "chatgpt_cot": "Add property weapon_cooldown to Unit class for checking time until unit can fire again, improving unit behavior in game scenarios."
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/launch_list_model.py b/node_manager_fkie/src/node_manager_fkie/launch_list_model.py @@ -253,7 +253,7 @@ class LaunchListModel(QStandardItemModel):\nitem = self.itemFromIndex(index)\nprev = '%s\\n' % text if text else ''\ntext = '%sfile://%s' % (prev, item.path)\n- mimeData.setData('text/plain', utf8(text))\n+ mimeData.setData('text/plain', text)\nreturn mimeData\n# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
        "org_msg": "node_manager_fkie: fixed crash while navigation in launch editor",
        "sim_msg": "Removed redundant internalPointer query",
        "sim_diff": "diff --git a/avalon/tools/cbsceneinventory/model.py b/avalon/tools/cbsceneinventory/model.py @@ -50,7 +50,6 @@ class InventoryModel(TreeModel):\nif role == QtCore.Qt.DecorationRole:\nif index.column() == 0:\n# Override color\n- node = index.internalPointer()\ncolor = node.get(\"color\", style.colors.default)\nif not index.parent().isValid(): # group-item\nreturn qta.icon(\"fa.folder\", color=color)\n@@ -62,7 +61,6 @@ class InventoryModel(TreeModel):\nreturn node.get(\"familyIcon\", None)\nif role == self.UniqueRole:\n- node = index.internalPointer()\nreturn node['representation'] + node.get(\"objectName\", \"<none>\")\nreturn super(InventoryModel, self).data(index, role)\n",
        "chatgpt_cot": "Fix mimeData setData method in LaunchListModel to properly handle text data in the launch list model."
    },
    {
        "org_diff": "diff --git a/sc2/units.py b/sc2/units.py @@ -103,6 +103,13 @@ class Units(list):\nposition = position.position\nreturn min({unit.position.to2.distance_to(position.to2) for unit in self})\n+ def furthest_distance_to(self, position: Union[Unit, Point2, Point3]) -> Union[int, float]:\n+ \"\"\" Returns the distance between the furthest unit from this group to the target unit \"\"\"\n+ assert self.exists\n+ if isinstance(position, Unit):\n+ position = position.position\n+ return max({unit.position.to2.distance_to(position.to2) for unit in self})\n+\ndef closest_to(self, position: Union[Unit, Point2, Point3]) -> Unit:\nassert self.exists\nif isinstance(position, Unit):\n@@ -110,7 +117,6 @@ class Units(list):\nreturn min(self, key=lambda unit: unit.position.to2.distance_to(position.to2))\ndef furthest_to(self, position: Union[Unit, Point2, Point3]) -> Unit:\n- \"\"\" Returns the distance between the furthest unit from this group to the target unit \"\"\"\nassert self.exists\nif isinstance(position, Unit):\nposition = position.position\n",
        "org_msg": "Add furthest_distance_to",
        "sim_msg": "pushing where i am",
        "sim_diff": "diff --git a/syft/syft.py b/syft/syft.py @@ -131,6 +131,9 @@ class FloatTensor():\nreturn list(map(lambda x:int(x),res.split(\",\")[0:-1]))\nreturn []\n+ def dataOnGpu(self):\n+ return self.get(\"dataOnGpu\")\n+\ndef __truediv__(self, x):\nreturn self.arithmetic_operation(x, \"div\", False)\n",
        "chatgpt_cot": "Add new method furthest_distance_to in Units class to calculate the distance to the furthest unit from the group."
    },
    {
        "org_diff": "diff --git a/sc2/game_state.py b/sc2/game_state.py @@ -40,7 +40,7 @@ class GameState(object):\nself.creep = PixelMap(observation.observation.raw_data.map_state.creep)\nself.dead_units = {dead_unit_tag for dead_unit_tag in observation.observation.raw_data.event.dead_units} # set of unit tags that died this step - sometimes has multiple entries\n- self.effects = {EffectId(effect) for effect in observation.observation.raw_data.effects} # effects like ravager bile shot, lurker attack, everything in effect_id.py # usage: if RAVAGERCORROSIVEBILECP in self.state.effects: do stuff\n+ self.effects = {effect for effect in observation.observation.raw_data.effects} # effects like ravager bile shot, lurker attack, everything in effect_id.py # usage: if RAVAGERCORROSIVEBILECP.value in self.state.effects: do stuff\nself.upgrades = {UpgradeId(upgrade) for upgrade in observation.observation.raw_data.player.upgrade_ids} # usage: if TERRANINFANTRYWEAPONSLEVEL1 in self.state.upgrades: do stuff\n@property\n",
        "org_msg": "Manually change effects because effect_id.py doesnt seem to be complete",
        "sim_msg": "Use `mode.value` instead enumerate.",
        "sim_diff": "diff --git a/app/objects/player.py b/app/objects/player.py @@ -536,14 +536,14 @@ class Player:\nasync with app.state.services.database.connection() as db_conn:\nawait self.stats_from_sql_full(db_conn)\n- for idx, mode_stat in enumerate(self.stats.values()):\n+ for mode, stats in self.stats.items():\nawait app.state.services.redis.zadd(\n- f\"gulag:leaderboard:{idx}\",\n- {self.id: mode_stat.pp},\n+ f\"gulag:leaderboard:{mode.value}\",\n+ {self.id: stats.pp},\n)\nawait app.state.services.redis.zadd(\n- f\"gulag:leaderboard:{idx}:{self.geoloc['country']['acronym']}\",\n- {self.id: mode_stat.pp},\n+ f\"gulag:leaderboard:{mode.value}:{self.geoloc['country']['acronym']}\",\n+ {self.id: stats.pp},\n)\nif \"restricted\" in self.__dict__:\n",
        "chatgpt_cot": "\"Refactor effects handling in GameState to use effect values instead of EffectId objects for better readability and consistency.\""
    },
    {
        "org_diff": "diff --git a/node_manager_daemon_fkie/src/node_manager_daemon_fkie/monitor/hdd_usage.py b/node_manager_daemon_fkie/src/node_manager_daemon_fkie/monitor/hdd_usage.py @@ -53,6 +53,9 @@ class HddUsage(SensorInterface):\nself._path = settings.param('sysmon/Disk/path', self._path)\ndef check_sensor(self):\n+ diag_level = 0\n+ diag_vals = []\n+ diag_msg = ''\ntry:\nhdd = psutil.disk_usage(self._path)\ndiag_level = 0\n",
        "org_msg": "node_manager_daemon_fkie: fix hdd_usage monitor if not path available",
        "sim_msg": "Fix typo for additional device support in intel node manger",
        "sim_diff": "diff --git a/ceilometer/ipmi/platform/intel_node_manager.py b/ceilometer/ipmi/platform/intel_node_manager.py @@ -95,7 +95,7 @@ NM_GET_DEVICE_ID_TEMPLATE['Device_revision'] = 1\nNM_GET_DEVICE_ID_TEMPLATE['Firmware_revision_1'] = 1\nNM_GET_DEVICE_ID_TEMPLATE['Firmware_Revision_2'] = 1\nNM_GET_DEVICE_ID_TEMPLATE['IPMI_Version'] = 1\n-NM_GET_DEVICE_ID_TEMPLATE['Additinal_Device_support'] = 1\n+NM_GET_DEVICE_ID_TEMPLATE['Additional_Device_support'] = 1\nNM_GET_DEVICE_ID_TEMPLATE['Manufacturer_ID'] = 3\nNM_GET_DEVICE_ID_TEMPLATE['Product_ID_min_version'] = 1\nNM_GET_DEVICE_ID_TEMPLATE['Product_ID_major_version'] = 1\n",
        "chatgpt_cot": "\"Add diagnostic variables and message in check_sensor method for HddUsage class\""
    },
    {
        "org_diff": "diff --git a/rasa_core_sdk/__init__.py b/rasa_core_sdk/__init__.py @@ -154,16 +154,19 @@ class Action(object):\n\"\"\"\nExecute the side effects of this action.\nArgs:\n- dispatcher (CollectingDispatcher): the dispatcher which is used to send\n- messages back to the user. Use ``dipatcher.utter_message()``\n- or any other :class:`rasa_core_sdk.executor.CollectingDispatcher` method.\n+ dispatcher (CollectingDispatcher): the dispatcher which is used to\n+ send messages back to the user. Use ``dipatcher.utter_message()``\n+ or any other :class:`rasa_core_sdk.executor.CollectingDispatcher`\n+ method.\ntracker (Tracker): the state tracker for the current\nuser. You can access slot values using\n- ``tracker.get_slot(slot_name)``, the most recent user\n- message is ``tracker.latest_message.text`` and any other :class:`rasa_core_sdk.Tracker` property.\n+ ``tracker.get_slot(slot_name)``, the most recent user message\n+ is ``tracker.latest_message.text`` and any other\n+ :class:`rasa_core_sdk.Tracker` property.\ndomain (Dict[Text, Any]): the bot's domain\nReturns:\n- List[Event]: A list of :class:`rasa_core_sdk.events.Event` instances that is returned through the endpoint\n+ Dict[Event]: A list of :class:`rasa_core_sdk.events.Event` instances\n+ that is returned through the endpoint\n\"\"\"\nraise NotImplementedError\n",
        "org_msg": "Cut long method description lines",
        "sim_msg": "fix slot machine module (user != source)",
        "sim_diff": "diff --git a/pajbot/modules/slotmachine.py b/pajbot/modules/slotmachine.py @@ -215,9 +215,9 @@ class SlotMachineModule(BaseModule):\n)\nself.commands[\"smp\"] = self.commands[\"slotmachine\"]\n- def pull(self, bot, user, message, **rest):\n+ def pull(self, bot, source, message, **rest):\nif message is None:\n- bot.whisper(user.username, \"I didn't recognize your bet! Usage: !slotmachine 150 to bet 150 points\")\n+ bot.whisper(source.username, \"I didn't recognize your bet! Usage: !slotmachine 150 to bet 150 points\")\nreturn False\nlow_tier_emotes = self.settings[\"low_tier_emotes\"].split()\n@@ -228,19 +228,19 @@ class SlotMachineModule(BaseModule):\nmsg_split = message.split(\" \")\ntry:\n- bet = pajbot.utils.parse_points_amount(user, msg_split[0])\n+ bet = pajbot.utils.parse_points_amount(source, msg_split[0])\nexcept pajbot.exc.InvalidPointAmount as e:\n- bot.whisper(user.username, str(e))\n+ bot.whisper(source.username, str(e))\nreturn False\n- if not user.can_afford(bet):\n+ if not source.can_afford(bet):\nbot.whisper(\n- user.username, \"You don't have enough points to do a slot machine pull for {} points :(\".format(bet)\n+ source.username, \"You don't have enough points to do a slot machine pull for {} points :(\".format(bet)\n)\nreturn False\nif bet < self.settings[\"min_bet\"]:\n- bot.whisper(user.username, \"You have to bet at least {} point! :(\".format(self.settings[\"min_bet\"]))\n+ bot.whisper(source.username, \"You have to bet at least {} point! :(\".format(self.settings[\"min_bet\"]))\nreturn False\n# how much of the users point they're expected to get back (basically how much the house yoinks)\n@@ -261,13 +261,13 @@ class SlotMachineModule(BaseModule):\nelse:\npoints = bet * bet_return\n- user.points += points\n+ source.points += points\narguments = {\n\"bet\": bet,\n\"result\": points,\n- \"user\": user.username_raw,\n- \"points\": user.points_available(),\n+ \"user\": source.username_raw,\n+ \"points\": source.points_available(),\n\"win\": points > 0,\n\"emotes\": \" \".join(randomized_emotes),\n}\n@@ -285,7 +285,7 @@ class SlotMachineModule(BaseModule):\nif self.settings[\"options_output\"] == \"1. Show results in chat\":\nbot.me(out_message)\nif self.settings[\"options_output\"] == \"2. Show results in whispers\":\n- bot.whisper(user.username, out_message)\n+ bot.whisper(source.username, out_message)\nif (\nself.settings[\"options_output\"]\n== \"3. Show results in chat if it's over X points else it will be whispered.\"\n@@ -293,9 +293,9 @@ class SlotMachineModule(BaseModule):\nif abs(points) >= self.settings[\"min_show_points\"]:\nbot.me(out_message)\nelse:\n- bot.whisper(user.username, out_message)\n+ bot.whisper(source.username, out_message)\n- HandlerManager.trigger(\"on_slot_machine_finish\", user=user, points=points)\n+ HandlerManager.trigger(\"on_slot_machine_finish\", user=source, points=points)\ndef on_tick(self, **rest):\nif self.output_buffer == \"\":\n",
        "chatgpt_cot": "Refactor Action class method signatures in __init__.py for better clarity and consistency with the rasa_core_sdk module."
    },
    {
        "org_diff": "diff --git a/fkie_node_manager_daemon/tests/test_common.py b/fkie_node_manager_daemon/tests/test_common.py @@ -100,7 +100,7 @@ class TestCommonLib(unittest.TestCase):\ndef test_get_packages(self):\npath = os.path.dirname(self.nm_path.rstrip(os.path.sep))\npkg_res = get_packages(path)\n- self.assertEqual(6, len(pkg_res), \"wrong count of get_packages(%s), expected: %d, got: %d\" % (path, 6, len(pkg_res)))\n+ self.assertEqual(6, len(pkg_res), \"wrong count of get_packages(%s), expected: %d, got: %d -> packages: %s\" % (path, 6, len(pkg_res), pkg_res))\ndef test_get_cwd(self):\ntest_path = '/this/is/path/to'\n",
        "org_msg": "test for packages",
        "sim_msg": "issue Python 2.4 lacked Thread.name.",
        "sim_diff": "diff --git a/tests/testlib.py b/tests/testlib.py @@ -301,9 +301,10 @@ class TestCase(unittest2.TestCase):\ndef _teardown_check_threads(self):\ncounts = {}\nfor thread in threading.enumerate():\n- assert thread.name in self.ALLOWED_THREADS, \\\n- 'Found thread %r still running after tests.' % (thread.name,)\n- counts[thread.name] = counts.get(thread.name, 0) + 1\n+ name = thread.getName()\n+ assert name in self.ALLOWED_THREADS, \\\n+ 'Found thread %r still running after tests.' % (name,)\n+ counts[name] = counts.get(name, 0) + 1\nfor name in counts:\nassert counts[name] == 1, \\\n",
        "chatgpt_cot": "\"Modify test_get_packages method to include packages in the assertion message for better debugging and error identification.\""
    },
    {
        "org_diff": "diff --git a/sc2/bot_ai.py b/sc2/bot_ai.py @@ -557,6 +557,7 @@ class BotAI:\nself.player_id: int = player_id\nself.race: Race = Race(self._game_info.player_races[self.player_id])\n+ if len(self._game_info.player_races) == 2:\nself.enemy_race = Race(self._game_info.player_races[3 - self.player_id])\nself._units_previous_map: dict = dict()\nself._previous_upgrades: Set[UpgradeId] = set()\n",
        "org_msg": "Don't include enemy_race when running on a single player map",
        "sim_msg": "Forgot to update iNumPlayers",
        "sim_diff": "diff --git a/v3/runner.py b/v3/runner.py @@ -63,6 +63,8 @@ if __name__ == '__main__':\ncallbacks = []\nname_dict = dict()\n+ gameInputPacket.iNumPlayers = num_bots\n+\n# Set configuration values for bots and store name and team\nfor i in range(num_bots):\nbot_config = configparser.RawConfigParser()\n",
        "chatgpt_cot": "Add condition to set enemy_race based on number of player races."
    },
    {
        "org_diff": "diff --git a/fkie_master_sync/src/fkie_master_sync/sync_thread.py b/fkie_master_sync/src/fkie_master_sync/sync_thread.py @@ -116,8 +116,8 @@ class SyncThread(object):\nself._filter = FilterInterface()\nself._filter.load(self.name,\n['/rosout', self.discoverer_name, '/master_discovery', '/master_sync', '/node_manager', '/node_manager_daemon', '/zeroconf', '/param_sync'], [],\n- ['/rosout', '/rosout_agg', '/diagnostics', '/diagnostics_agg'], ['/'] if sync_on_demand else [],\n- ['/*get_loggers', '/*set_logger_level'], [],\n+ ['/rosout', '/rosout_agg', '/master_discovery/*', '/master_sync/*', '/zeroconf/*'], ['/'] if sync_on_demand else [],\n+ ['/*get_loggers', '/*set_logger_level', '/master_discovery/*', '/master_sync/*', '/node_manager_daemon/*', '/zeroconf/*'], [],\n# do not sync the bond message of the nodelets!!\n['bond/Status', 'fkie_multimaster_msgs/SyncTopicInfo', 'fkie_multimaster_msgs/SyncServiceInfo', 'fkie_multimaster_msgs/SyncMasterInfo', 'fkie_multimaster_msgs/MasterState'],\n[], [],\n",
        "org_msg": "fkie_master_sync: added names and topics of multimaster nodes to default ignore lists",
        "sim_msg": "Reset Block height sync bad targets on cleanUp",
        "sim_diff": "diff --git a/loopchain/peer/block_sync.py b/loopchain/peer/block_sync.py @@ -699,6 +699,7 @@ class BlockSync:\nself._sync_done_event = None\nself._retry_queue = None\nself._retry_task = None\n+ self._block_height_sync_bad_targets.clear()\ndef stop(self):\nself._cleanup()\n",
        "chatgpt_cot": "Update SyncThread filter to include additional topics and services for synchronization based on demand. Fixing sync_on_demand condition for better topic and service synchronization."
    },
    {
        "org_diff": "diff --git a/test/autotest_bot.py b/test/autotest_bot.py @@ -27,9 +27,9 @@ class TestBot(sc2.BotAI):\nasync def on_step(self, iteration):\nif iteration == 0:\nawait self.chat_send(\"(glhf)\")\n- if iteration == 1:\n+ #if iteration == 1:\n# Test if chat message was sent correctly\n- assert len(self.state.chat) >= 1, self.state.chat\n+ # assert len(self.state.chat) >= 1, self.state.chat\n# Tests at start:\nif iteration == 5:\n",
        "org_msg": "Test if test completes without chat",
        "sim_msg": "try to debug \"FAIL: test_30_full (test_message_queue.TestPikaRabbitMQ)\"",
        "sim_diff": "diff --git a/tests/test_message_queue.py b/tests/test_message_queue.py @@ -97,6 +97,24 @@ class TestPikaRabbitMQ(TestMessageQueue, unittest.TestCase):\ndel self.q2\ndel self.q3\n+ def test_30_full(self):\n+ self.assertEqual(self.q1.qsize(), 0)\n+ self.assertEqual(self.q2.qsize(), 0)\n+ for i in range(2):\n+ self.q1.put_nowait('TEST_DATA%d' % i)\n+ for i in range(3):\n+ self.q2.put('TEST_DATA%d' % i)\n+\n+ print(self.q1.__dict__)\n+ print(self.q1.qsize())\n+ with self.assertRaises(Queue.Full):\n+ self.q1.put_nowait('TEST_DATA6')\n+ print(self.q1.__dict__)\n+ print(self.q1.qsize())\n+ with self.assertRaises(Queue.Full):\n+ self.q1.put('TEST_DATA6', timeout=0.01)\n+\n+\n@unittest.skipIf(os.environ.get('IGNORE_RABBITMQ') or os.environ.get('IGNORE_ALL'), 'no rabbitmq server for test.')\nclass TestAmqpRabbitMQ(TestMessageQueue, unittest.TestCase):\n",
        "chatgpt_cot": "Comment out assertion for chat message in TestBot to avoid failing test due to chat message check."
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/editor/xml_highlighter.py b/node_manager_fkie/src/node_manager_fkie/editor/xml_highlighter.py @@ -72,7 +72,8 @@ class XmlHighlighter(QSyntaxHighlighter):\nLAUNCH_INCLUDE_CHILDS = ['env', 'arg']\nLAUNCH_INCLUDE_ATTR = {'file=': '\"$(find pkg-name)/path/filename.xml\"',\n'ns=': '\"foo\"',\n- 'clear_params=': '\"true|false\"'\n+ 'clear_params=': '\"true|false\"',\n+ 'pass_all_args=': '\"true|false\"'\n}\nLAUNCH_REMAP_ATTR = {'from=': '\"originalname\"',\n",
        "org_msg": "added \"pass_all_args\" for highlighter",
        "sim_msg": "set app and class defaults on loading",
        "sim_diff": "diff --git a/xml_parse.py b/xml_parse.py @@ -178,8 +178,8 @@ class XmlWidgetBuilder(XmlParser):\np[\"encoding\"].set( attrs['encoding'] )\np[\"output_path\"].set( attrs['path'] or \"\" )\n- p[\"class\"].set( attrs['class'] or \"\", activate=bool(attrs.get(\"class\")) )\n- p[\"name\"].set( attrs['name'] or \"\", activate=bool(attrs.get(\"name\")) )\n+ p[\"class\"].set( attrs['class'] or \"MyApp\", activate=bool(attrs.get(\"class\")) )\n+ p[\"name\"].set( attrs['name'] or \"app\", activate=bool(attrs.get(\"name\")) )\np[\"multiple_files\"].set( attrs['option'] )\np[\"language\"].set( attrs['language'] )\np[\"top_window\"].set( attrs['top_window'] or \"\" )\n",
        "chatgpt_cot": "Add new attribute in XmlHighlighter for launch configuration to handle passing all arguments."
    },
    {
        "org_diff": "diff --git a/sc2/position.py b/sc2/position.py @@ -2,7 +2,7 @@ from __future__ import annotations\nimport itertools\nimport math\nimport random\n-from typing import Any, Dict, List, Optional, Set, Tuple, Union, TYPE_CHECKING\n+from typing import Any, Dict, List, Optional, Set, Tuple, Union, Iterable, TYPE_CHECKING\nif TYPE_CHECKING:\nfrom .unit import Unit\n@@ -57,7 +57,7 @@ class Pointlike(tuple):\np = p.position\nreturn self.distance_to_point2(p) > distance\n- def sort_by_distance(self, ps: Union[Units, List[Point2]]) -> List[Point2]:\n+ def sort_by_distance(self, ps: Union[Units, Iterable[Point2]]) -> List[Point2]:\n\"\"\" This returns the target points sorted as list.\nYou should not pass a set or dict since those are not sortable.\nIf you want to sort your units towards a point, use 'units.sorted_by_distance_to(point)' instead.\n@@ -65,14 +65,14 @@ class Pointlike(tuple):\n:param ps: \"\"\"\nreturn sorted(ps, key=lambda p: self.distance_to_point2(p.position))\n- def closest(self, ps: Union[Units, List[Point2], Set[Point2]]) -> Union[Unit, Point2]:\n+ def closest(self, ps: Union[Units, Iterable[Point2]]) -> Union[Unit, Point2]:\n\"\"\" This function assumes the 2d distance is meant\n:param ps: \"\"\"\nassert ps, f\"ps is empty\"\nreturn min(ps, key=lambda p: self.distance_to(p))\n- def distance_to_closest(self, ps: Union[Units, List[Point2], Set[Point2]]) -> Union[int, float]:\n+ def distance_to_closest(self, ps: Union[Units, Iterable[Point2]]) -> Union[int, float]:\n\"\"\" This function assumes the 2d distance is meant\n:param ps: \"\"\"\nassert ps, f\"ps is empty\"\n@@ -84,14 +84,14 @@ class Pointlike(tuple):\nclosest_distance = distance\nreturn closest_distance\n- def furthest(self, ps: Union[Units, List[Point2], Set[Point2]]) -> Union[Unit, Pointlike]:\n+ def furthest(self, ps: Union[Units, Iterable[Point2]]) -> Union[Unit, Pointlike]:\n\"\"\" This function assumes the 2d distance is meant\n:param ps: Units object, or iterable of Unit or Point2 \"\"\"\nassert ps, f\"ps is empty\"\nreturn max(ps, key=lambda p: self.distance_to(p))\n- def distance_to_furthest(self, ps: Union[Units, List[Point2], Set[Point2]]) -> Union[int, float]:\n+ def distance_to_furthest(self, ps: Union[Units, Iterable[Point2]]) -> Union[int, float]:\n\"\"\" This function assumes the 2d distance is meant\n:param ps: \"\"\"\n@@ -291,7 +291,7 @@ class Point2(Pointlike):\nreturn abs(other.x - self.x) + abs(other.y - self.y)\n@staticmethod\n- def center(units_or_points: Union[Set[Point2], List[Point2]]) -> Point2:\n+ def center(units_or_points: Iterable[Point2]) -> Point2:\n\"\"\" Returns the central point for points in list\n:param units_or_points:\"\"\"\n",
        "org_msg": "Change argument type hints from list or set to iterable",
        "sim_msg": "Added tests for distances and distances_indices_sorted functions.",
        "sim_diff": "diff --git a/pymatgen/analysis/chemenv/utils/tests/test_coordination_geometry_utils.py b/pymatgen/analysis/chemenv/utils/tests/test_coordination_geometry_utils.py @@ -214,6 +214,40 @@ class PlanesUtilsTest(PymatgenTest):\nself.assertEqual(sep[1], [3, 5])\nself.assertEqual(sep[2], [4, 7])\n+ def test_distances(self):\n+ # Test with the common test plane\n+ point_1 = np.array([0.0, 0.0, 0.0], np.float)\n+ point_2 = np.array([0.0, 0.0, 0.75], np.float)\n+ point_3 = np.array([-0.75, 0.0, 0.0], np.float)\n+ point_4 = np.array([1.0, 0.0, 0.0], np.float)\n+ point_5 = np.array([0.0, -1.5, 0.0], np.float)\n+ point_6 = np.array([10.0, 2.0, -20.0], np.float)\n+ point_7 = np.array([10.0, 10.0, 10.0], np.float)\n+ point_8 = np.array([100.0, 0.0, 0.0], np.float)\n+ plist = [point_1, point_2, point_4, point_6, point_7, point_8]\n+ distances, indices_sorted = self.plane.distances_indices_sorted(plist)\n+ self.assertArrayAlmostEqual(distances, [0.5, 0.0, 1.16666666666666,\n+ 21.1666666666666, 3.8333333333333, 67.1666666666666])\n+ self.assertArrayEqual(indices_sorted, [1, 0, 2, 4, 3, 5])\n+ # Plane 2y+1=0 (perpendicular to y)\n+ plane = Plane.from_coefficients(0, 2, 0, 1)\n+ plist = [point_1, point_5, point_6, point_7]\n+ distances, indices_sorted = plane.distances_indices_sorted(plist)\n+ self.assertArrayAlmostEqual(distances, [0.5, -1.0, 2.5, 10.5])\n+ self.assertArrayEqual(indices_sorted, [0, 1, 2, 3])\n+ plist = [point_1, point_5, point_6, point_7]\n+ distances, indices_sorted = plane.distances_indices_sorted(plist)\n+ self.assertArrayAlmostEqual(distances, [0.5, -1.0, 2.5, 10.5])\n+ self.assertArrayEqual(indices_sorted, [0, 1, 2, 3])\n+ plist = [point_5, point_1, point_6, point_7]\n+ distances, indices_sorted = plane.distances_indices_sorted(plist)\n+ self.assertArrayAlmostEqual(distances, [-1.0, 0.5, 2.5, 10.5])\n+ self.assertArrayEqual(indices_sorted, [1, 0, 2, 3])\n+ plist = [point_1, point_2, point_3, point_4, point_5, point_6, point_7, point_8]\n+ distances, indices_sorted = plane.distances_indices_sorted(plist)\n+ self.assertArrayAlmostEqual(distances, [0.5, 0.5, 0.5, 0.5, -1.0, 2.5, 10.5, 0.5])\n+ self.assertEqual(set(indices_sorted[:5]), {0, 1, 2, 3, 7})\n+\ndef test_projections(self):\n#Projections of points that are already on the plane\nexpected_projected_points = [self.p1, self.p2, self.p3, self.plane.p1, self.plane.p2, self.plane.p3]\n@@ -262,4 +296,13 @@ class PlanesUtilsTest(PymatgenTest):\nif __name__ == \"__main__\":\n+ # p1 = np.array([0.0, 0.0, 0.0])\n+ # p2 = np.array([-0.75, 3.0, 2.0])\n+ # p3 = np.array([1.0, -1.5, 2.0])\n+ # plane = Plane.from_3points(p1, p2, p3)\n+ # print(plane.distances([[0.0, 0.0, 0.0], [0.0, 0.0, 0.75], [0.0, 0.0, -0.75], [0.2, -0.3, 0.75], [-0.2, 0.3, -0.75]]))\n+ # print(plane.distances_indices_sorted([[0.0, 0.0, 0.0], [0.0, 0.0, 0.75], [0.0, 0.0, -0.75], [0.2, -0.3, 0.75], [-0.2, 0.3, -0.75]]))\n+ # print(plane.normal_vector)\n+ # print(plane.d)\n+ # exit()\nunittest.main()\n",
        "chatgpt_cot": "Modify the `position.py` file to change the type of a parameter to Iterable instead of List, Set, or Units to make it more flexible."
    },
    {
        "org_diff": "diff --git a/Makefile b/Makefile @@ -293,6 +293,8 @@ api-engine: # for debug only now\ndocker-rest-agent: # for debug only now\ndocker build -t hyperledger/cello-agent-docker:latest -f build_image/docker/agent/docker-rest-agent/Dockerfile.in ./ --build-arg pip=$(PIP)\n+start-dashboard:\n+ make -C src/dashboard start;\n.PHONY: \\\nall \\\n",
        "org_msg": "Update quick start part of README",
        "sim_msg": "Turn cluster debugging back off.",
        "sim_diff": "diff --git a/Makefile b/Makefile # See the License for the specific language governing permissions and\n# limitations under the License\n-CI_DEBUG_KAT_BRANCH=flynn/dev/1467\n+CI_DEBUG_KAT_BRANCH=\nSHELL = bash\n@@ -307,11 +307,11 @@ ifneq ($(DOCKER_REGISTRY), -)\ndocker push $(AMBASSADOR_DOCKER_IMAGE) | python releng/linify.py push.log; \\\nif [ \\( \"$(COMMIT_TYPE)\" = \"RC\" \\) -o \\( \"$(COMMIT_TYPE)\" = \"EA\" \\) ]; then \\\nmake docker-login || exit 1; \\\n- if [ \"$(COMMIT_TYPE)\" = \"EA\" ]; then \\\n+ \\\necho \"PUSH $(AMBASSADOR_EXTERNAL_DOCKER_REPO):$(GIT_TAG_SANITIZED)\"; \\\ndocker tag $(AMBASSADOR_DOCKER_IMAGE) $(AMBASSADOR_EXTERNAL_DOCKER_REPO):$(GIT_TAG_SANITIZED); \\\ndocker push $(AMBASSADOR_EXTERNAL_DOCKER_REPO):$(GIT_TAG_SANITIZED) | python releng/linify.py push.log; \\\n- fi; \\\n+ \\\necho \"PUSH $(AMBASSADOR_EXTERNAL_DOCKER_REPO):$(LATEST_RC)\"; \\\ndocker tag $(AMBASSADOR_DOCKER_IMAGE) $(AMBASSADOR_EXTERNAL_DOCKER_REPO):$(LATEST_RC); \\\ndocker push $(AMBASSADOR_EXTERNAL_DOCKER_REPO):$(LATEST_RC) | python releng/linify.py push.log; \\\n",
        "chatgpt_cot": "Add start-dashboard target to Makefile for starting dashboard in src/dashboard. Fix compilation issue."
    },
    {
        "org_diff": "diff --git a/src/agent/ansible/roles/deploy_compose/certsetup/templates/configtx.j2 b/src/agent/ansible/roles/deploy_compose/certsetup/templates/configtx.j2 @@ -51,13 +51,19 @@ Organizations:\n{% if project_version is version_compare('1.1.0','>=') or 'stable' in project_version or project_version == 'latest' %}\nCapabilities:\nGlobal: &ChannelCapabilities\n+{% if project_version is version_compare('1.3.0','>=') or 'stable' in project_version or project_version == 'latest' %}\n+ V1_3: true\n+{% elif project_version is version_compare('1.1.0','>=') and project_version is version_compare('1.3.0','<') %}\nV1_1: true\n+{% endif %}\nOrderer: &OrdererCapabilities\nV1_1: true\nApplication: &ApplicationCapabilities\n-{% if project_version is version_compare('1.2.0','>=') or 'stable' in project_version or project_version == 'latest' %}\n+{% if project_version is version_compare('1.3.0','>=') or 'stable' in project_version or project_version == 'latest' %}\n+ V1_3: true\n+{% elif project_version is version_compare('1.2.0','>=') and project_version is version_compare('1.3.0','<') %}\nV1_2: true\n{% elif project_version is version_compare('1.1.0','>=') and project_version is version_compare('1.2.0','<') %}\nV1_1: true\n@@ -123,6 +129,10 @@ Application: &ApplicationDefaults\nType: ImplicitMeta\nRule: \"MAJORITY Admins\"\n{% endif %}\n+{% if project_version is version_compare('1.1.0','>=') or 'stable' in project_version or project_version == 'latest' %}\n+ Capabilities:\n+ <<: *ApplicationCapabilities\n+{% endif %}\n{% if project_version is version_compare('1.2.0','>=') or 'stable' in project_version or project_version == 'latest' %}\nChannel: &ChannelDefaults\n@@ -143,10 +153,6 @@ Profiles:\nConsortium: FabricConsortium\nApplication:\n<<: *ApplicationDefaults\n-{% if project_version is version_compare('1.1.0','>=') or 'stable' in project_version or project_version == 'latest' %}\n- Capabilities:\n- <<: *ApplicationCapabilities\n-{% endif %}\nOrdererGenesis:\n{% if project_version is version_compare('1.2.0','>=') or 'stable' in project_version or project_version == 'latest' %}\n<<: *ChannelDefaults\n",
        "org_msg": "adding V1_3 capabilities to ansible agent\nAdding V1_3 capabilities to ansible agent to configtx.j2",
        "sim_msg": "router update fixes with comparison logic",
        "sim_diff": "diff --git a/frontend/src/Augur.ts b/frontend/src/Augur.ts @@ -57,29 +57,69 @@ export default function Augur() {\nif (!to.params.compares) {\nstore.commit('compare/resetCompared')\n}\n- store.dispatch('compare/setBaseRepo').then((data: any) => {\n- return store.dispatch('compare/setBaseGroup')\n+ store.dispatch('compare/setBaseRepo', {\n+ rg_name: to.params.group,\n+ repo_name: to.params.repo,\n+ repo_group_id: to.params.repo_group_id,\n+ repo_id: to.params.repo_id,\n+ gitURL: to.params.url\n+ }).then((data: any) => {\n+ return store.dispatch('compare/setBaseGroup', {\n+ rg_name: to.params.group,\n+ repo_name: to.params.repo,\n+ repo_group_id: to.params.repo_group_id,\n+ repo_id: to.params.repo_id,\n+ gitURL: to.params.url\n+ })\n}).finally(() => {\nnext()\n})\n} else if (to.params.group && to.params.repo) {\n- console.log(\"bout to\")\n+ console.log(\"bout to\", to.params, !to.params.repo_group_id || !to.params.repo_id)\nNProgress.set(0.6);\n+ let repo_group_id = null\n+ let repo_id = null\n+ if (!to.params.repo_group_id || !to.params.repo_id) {\n+ store.dispatch('common/retrieveRepoIds', {\n+ repo: to.params.repo,\n+ rg_name: to.params.group\n+ }).then((ids: any) => {\n+ repo_group_id = ids['repo_group_id']\n+ repo_id = ids['repo_id']\nstore.dispatch('compare/setBaseRepo', {\nrg_name: to.params.group,\n- repo_name: to.params.repo,\n+ repo: to.params.repo,\n+ repo_group_id: repo_group_id,\n+ repo_id: repo_id\n+ }).then(() => {\n+ NProgress.set(0.8);\n+ if(to.params.compares) {\n+ let compares = to.params.compares === '' ? [] : to.params.compares.split(',');\n+ let ids = to.params.comparedRepoIds === '' ? [] : to.params.comparedRepoIds.split(',');\n+ return store.dispatch('compare/setComparedRepos', { 'names': compares, 'ids': ids })\n+ }\n+ }).finally(()=>{\n+ next()\n+ })\n+ })\n+ } else {\n+ store.dispatch('compare/setBaseRepo', {\n+ rg_name: to.params.group,\n+ repo: to.params.repo,\nrepo_group_id: to.params.repo_group_id,\n- repo_id: to.params.repo_id,\n- gitURL: to.params.url\n+ repo_id: to.params.repo_id\n}).then(() => {\nNProgress.set(0.8);\nif(to.params.compares) {\nlet compares = to.params.compares === '' ? [] : to.params.compares.split(',');\n- return store.dispatch('compare/setComparedRepos', compares)\n+ let ids = to.params.comparedRepoIds === '' ? [] : to.params.comparedRepoIds.split(',');\n+ return store.dispatch('compare/setComparedRepos', { 'names': compares, 'ids': ids })\n}\n}).finally(()=>{\nnext()\n})\n+ }\n+\n} else if (to.params.group && !to.params.repo) {\nNProgress.set(0.6)\nstore.dispatch('compare/setBaseGroup', {\n",
        "chatgpt_cot": "Update configtx.j2 to include version-specific capabilities for different project versions, addressing compatibility issues and ensuring proper functionality across different versions."
    },
    {
        "org_diff": "diff --git a/sc2/client.py b/sc2/client.py @@ -8,6 +8,7 @@ from s2clientprotocol import (\nimport logging\nfrom sc2.ids.ability_id import AbilityId\n+from sc2.ids.unit_typeid import UnitTypeId\nlogger = logging.getLogger(__name__)\n@@ -208,3 +209,20 @@ class Client(Protocol):\n))\nelse:\nawait self.debug_text([texts], [positions], color)\n+\n+ async def debug_create_unit(self, unit_type, amount_of_units, position, owner_id):\n+ # example:\n+ # await self._client.debug_create_unit(MARINE, 1, self._game_info.map_center, 1)\n+ assert isinstance(unit_type, UnitTypeId)\n+ assert 0 < amount_of_units # careful, in realtime=True mode, as of now units get created the double amount\n+ assert isinstance(position, (Point2, Point3))\n+ assert 1 <= owner_id <= 2\n+\n+ await self._execute(debug=sc_pb.RequestDebug(\n+ debug=[debug_pb.DebugCommand(create_unit=debug_pb.DebugCreateUnit(\n+ unit_type=unit_type.value,\n+ owner=owner_id,\n+ pos=common_pb.Point2D(x=position.x, y=position.y),\n+ quantity=(amount_of_units)\n+ ))]\n+ ))\n\\ No newline at end of file\n",
        "org_msg": "Add debug spawn unit function",
        "sim_msg": "Calculate total allocation data per-row",
        "sim_diff": "diff --git a/InvenTree/static/script/inventree/build.js b/InvenTree/static/script/inventree/build.js @@ -103,4 +103,15 @@ function fillAllocationTable(table, parent_row, options) {\n],\nurl: \"/api/build/item?build=\" + options.build + \"&part=\" + parent_row.sub_part,\n});\n+\n+ table.on('load-success.bs.table', function(data) {\n+ var allocated = 0;\n+\n+ var allocationData = table.bootstrapTable('getData');\n+\n+ // Calculate total allocation\n+ for (var i = 0; i < allocationData.length; i++) {\n+ allocated += allocationData[i].quantity;\n+ }\n+ });\n}\n\\ No newline at end of file\n",
        "chatgpt_cot": "Add debug_create_unit method to Client class for creating units with specific parameters, ensuring correct unit type, amount, position, and owner ID."
    },
    {
        "org_diff": "diff --git a/scripts/check_license.sh b/scripts/check_license.sh # SPDX-License-Identifier: Apache-2.0\n#\n-CHECK=$(git diff --name-only HEAD * | grep -v .json$ | grep -v .jpg$ | grep -v .JPG$ | grep -v .png$ | grep -v .ico$ \\\n+CHECK=$(git diff --name-only HEAD * | grep -v check_license.sh | grep -v .json$ | grep -v .jpg$ | grep -v .JPG$ | grep -v .png$ | grep -v .ico$ \\\n| grep -v .graffle$ | grep -v .svg$ | grep -v .pug$ | grep -v .rst$ | grep -v .git \\\n| grep -v .pem$ | grep -v .crt$ | grep -v .key$ | grep -v lib/ | grep -v fonts/ | grep -v .min.css$ \\\n| grep -v .block$ | grep -v .less$ | grep -v crypto-config/ | grep -v .min.js$ \\\n| grep -v .md$ | grep -v ^vendor/ | grep -v ^build/ | grep -v .pb.go$ | grep -v .txt | grep -v .env | sort -u)\n+\nif [[ -z \"$CHECK\" ]]; then\nCHECK=$(git diff-tree --no-commit-id --name-only -r $(git log -2 \\\n- --pretty=format:\"%h\") | grep -v .json$ | grep -v .jpg$ | grep -v .JPG$ | grep -v .png$ | grep -v .ico$ \\\n+ --pretty=format:\"%h\") | grep -v check_license.sh | grep -v .json$ | grep -v .jpg$ | grep -v .JPG$ | grep -v .png$ | grep -v .ico$ \\\n| grep -v .graffle$ | grep -v .svg$ | grep -v .pug$ | grep -v .rst$ | grep -v .git \\\n| grep -v .pem$ | grep -v .crt$ | grep -v .key$ | grep -v lib/ | grep -v fonts/ | grep -v .min.css$ \\\n| grep -v .block$ | grep -v .less$ | grep -v crypto-config/ | grep -v .min.js$ \\\n| grep -v .md$ | grep -v ^vendor/ | grep -v ^build/ | grep -v .pb.go$ | grep -v .txt | grep -v .env | sort -u)\nfi\n+\necho \"Checking committed files for SPDX-License-Identifier headers ...\"\n+if [ -z \"$CHECK\" ]; then\n+ echo \"All files have SPDX-License-Identifier headers\"\n+ exit 0\n+fi\nmissing=`echo $CHECK | xargs grep -L \"SPDX-License-Identifier\"`\nif [ -z \"$missing\" ]; then\necho \"All files have SPDX-License-Identifier headers\"\n",
        "org_msg": "Test build error of license check",
        "sim_msg": "Remove nix overlay for `gh` tool\nNixpkgs has a newer version now",
        "sim_diff": "diff --git a/scripts/shell.nix b/scripts/shell.nix #\n# SPDX-License-Identifier: LicenseRef-MIT-TQ\n-let\n- overlays =\n- [\n- (self: super: {\n- gh = (super.callPackage \"${super.path}/pkgs/applications/version-management/git-and-tools/gh\" {\n- buildGoModule = args: super.buildGoModule (args // rec {\n- version = \"1.2.0\";\n- vendorSha256 = \"0ybbwbw4vdsxdq4w75s1i0dqad844sfgs69b3vlscwfm6g3i9h51\";\n- src = self.fetchFromGitHub {\n- owner = \"cli\";\n- repo = \"cli\";\n- rev = \"v${version}\";\n- sha256 = \"17hbgi1jh4p07r4p5mr7w7p01i6zzr28mn5i4jaki7p0jwfqbvvi\";\n- };\n- });\n- });\n- })\n- ];\n-in\n-\n-{ pkgs ? import (import ../nix/nix/sources.nix {}).nixpkgs { inherit overlays; } }:\n+{ pkgs ? import (import ../nix/nix/sources.nix {}).nixpkgs { } }:\nwith pkgs;\nmkShell {\nbuildInputs = [ gh git rename gnupg ];\n",
        "chatgpt_cot": "Add SPDX-License-Identifier header check in the script to ensure all files have the SPDX-License-Identifier headers."
    },
    {
        "org_diff": "diff --git a/sc2/game_state.py b/sc2/game_state.py @@ -3,6 +3,7 @@ from .power_source import PsionicMatrix\nfrom .pixel_map import PixelMap\nfrom .ids.upgrade_id import UpgradeId\nfrom .ids.effect_id import EffectId\n+from .position import Point2\nclass Common(object):\nATTRIBUTES = [\n@@ -20,6 +21,18 @@ class Common(object):\nassert attr in self.ATTRIBUTES, f\"'{attr}' is not a valid attribute\"\nreturn int(getattr(self._proto, attr))\n+class EffectData(object):\n+ def __init__(self, proto):\n+ self._proto = proto\n+\n+ @property\n+ def id(self):\n+ return EffectId(self._proto.effect_id)\n+\n+ @property\n+ def positions(self):\n+ return [Point2.from_proto(p) for p in self._proto.pos]\n+\nclass GameState(object):\ndef __init__(self, observation, game_data):\nself.common = Common(observation.observation.player_common)\n@@ -40,7 +53,14 @@ class GameState(object):\nself.creep = PixelMap(observation.observation.raw_data.map_state.creep)\nself.dead_units = {dead_unit_tag for dead_unit_tag in observation.observation.raw_data.event.dead_units} # set of unit tags that died this step - sometimes has multiple entries\n- self.effects = {effect for effect in observation.observation.raw_data.effects} # effects like ravager bile shot, lurker attack, everything in effect_id.py # usage: if RAVAGERCORROSIVEBILECP.value in self.state.effects: do stuff\n+ self.effects = {EffectData(effect) for effect in observation.observation.raw_data.effects} # effects like ravager bile shot, lurker attack, everything in effect_id.py\n+ \"\"\" Usage:\n+ for effect in self.state.effects:\n+ if effect.id == EffectId.RAVAGERCORROSIVEBILECP:\n+ positions = effect.positions\n+ # dodge the ravager biles\n+ \"\"\"\n+\nself.upgrades = {UpgradeId(upgrade) for upgrade in observation.observation.raw_data.player.upgrade_ids} # usage: if TERRANINFANTRYWEAPONSLEVEL1 in self.state.upgrades: do stuff\n@property\n",
        "org_msg": "Fix and polish to effect data",
        "sim_msg": "Fix title string",
        "sim_diff": "diff --git a/pysteps/visualization/animations.py b/pysteps/visualization/animations.py @@ -5,7 +5,7 @@ import numpy as np\nimport pysteps as st\ndef animate(R_obs, nloops=2, timestamps=None,\n- R_for=None, timestep_min=5,\n+ R_fct=None, timestep_min=5,\nUV=None, motion_plot=\"quiver\",\ngeodata=None,\ncolorscale=\"MeteoSwiss\", units=\"mm/h\", colorbar=True,\n@@ -21,7 +21,7 @@ def animate(R_obs, nloops=2, timestamps=None,\nnloops : int\nOptional, the number of loops in the animation.\n- R_for : array-like\n+ R_fct : array-like\nOptional, the three or four-dimensional (for ensembles) array containing\nthe time series of forecasted precipitation field.\ntimestep_min : float\n@@ -71,18 +71,17 @@ def animate(R_obs, nloops=2, timestamps=None,\nelse:\nstartdate_str = None\n- if R_for is not None:\n- if len(R_for.shape) == 3:\n- R_for = R_for[None, :, :, :]\n+ if R_fct is not None:\n+ if len(R_fct.shape) == 3:\n+ R_fct = R_fct[None, :, :, :]\n- if R_for is not None:\n- n_lead_times = R_for.shape[1]\n- n_members = R_for.shape[0]\n+ if R_fct is not None:\n+ n_lead_times = R_fct.shape[1]\n+ n_members = R_fct.shape[0]\nelse:\nn_lead_times = 0\nn_members = 1\n-\nloop = 0\nwhile loop < nloops:\n@@ -114,19 +113,19 @@ def animate(R_obs, nloops=2, timestamps=None,\nprint(figname, 'saved.')\n# Forecasts\n- elif i >= R_obs.shape[0] and R_for is not None:\n+ elif i >= R_obs.shape[0] and R_fct is not None:\nif timestamps is not None:\ntitle = \"%s +%02d min\" % (timestamps[-1].strftime(\"%Y-%m-%d %H:%M\"),\n(1 + i - R_obs.shape[0])*timestep_min)\nelse:\n- title = \"+%02d min\" % (1 + i - R_obs.shape[0])*timestep_min\n+ title = \"+%02d min\" % ((1 + i - R_obs.shape[0])*timestep_min)\nif n_members > 1:\ntitle = \"%s (member %02d)\" % (title, n)\n- st.plt.plot_precip_field(R_for[n, i - R_obs.shape[0],:,:],\n+ st.plt.plot_precip_field(R_fct[n, i - R_obs.shape[0],:,:],\nFalse, geodata, units=units,\ntitle=title,\ncolorscale=colorscale, colorbar=colorbar)\n",
        "chatgpt_cot": "Add EffectData class and its properties in game_state.py to handle game effects and their positions. Fixes a compilation issue and improves game effect handling."
    },
    {
        "org_diff": "diff --git a/fkie_node_manager/nodes/dynamic_reconfigure b/fkie_node_manager/nodes/dynamic_reconfigure from __future__ import division, absolute_import, print_function, unicode_literals\nimport sys\n+try:\n+ # renamed in commit #973d0d8 -> https://github.com/ros-visualization/rqt_reconfigure/commit/973d0d8bf614e27fdb6ce12aaaf8e65dce348ff1#diff-3809107d101d214d37251fe0bff88d74\n+ from rqt_reconfigure.param_client_widget import ParamClientWidget as DynreconfClientWidget\n+except ImportError:\nfrom rqt_reconfigure.dynreconf_client_widget import DynreconfClientWidget\nimport dynamic_reconfigure.client\nimport rospy\n@@ -72,7 +76,7 @@ def main(argv=sys.argv):\n_scroll_area = QScrollArea()\n_dynreconf_client = DynreconfClientWidget(dynreconf_client, node)\n- _scroll_area.resize(_dynreconf_client.width() + 20, 480 if _dynreconf_client.height() > 480 else _dynreconf_client.height())\n+ _scroll_area.resize(_dynreconf_client.width() + 30, 480 if _dynreconf_client.height() > 480 else _dynreconf_client.height())\n_scroll_area.setWidget(_dynreconf_client)\n_scroll_area.show()\nexit_code = -1\n",
        "org_msg": "fix start dynamic reconfigure\nit was broken by renaming DynreconfClientWidget to ParamClientWidget",
        "sim_msg": "Grid Client Small changes\nRemove proxy/unproxy methods\nADD load method\nAdd user_key optional parameter",
        "sim_diff": "diff --git a/src/syft/grid/client/client.py b/src/syft/grid/client/client.py from typing import Any\nfrom typing import Dict\nfrom typing import Optional\n+from typing import Type\nfrom typing import Union\n# third party\n@@ -24,8 +25,10 @@ from ...core.node.device.client import DeviceClient\nfrom ...core.node.domain.client import DomainClient\nfrom ...core.node.network.client import NetworkClient\nfrom ...core.node.vm.client import VirtualMachineClient\n+from ...core.pointer.pointer import Pointer\nfrom ..messages.setup_messages import CreateInitialSetUpMessage\nfrom ..messages.setup_messages import GetSetUpMessage\n+from ..messages.transfer_messages import LoadObjectMessage\nfrom .request_api.association_api import AssociationRequestAPI\nfrom .request_api.group_api import GroupRequestAPI\nfrom .request_api.role_api import RoleRequestAPI\n@@ -38,6 +41,7 @@ def connect(\nconn_type: ClientConnection,\nclient_type: Client,\ncredentials: Dict = {},\n+ user_key: Optional[SigningKey] = None,\n) -> Any:\nclass GridClient(client_type): # type: ignore\ndef __init__(\n@@ -52,11 +56,14 @@ def connect(\nconn = conn_type(url=url) # type: ignore\nif credentials:\n- metadata, user_key = conn.login(credentials=credentials)\n- user_key = SigningKey(user_key.encode(\"utf-8\"), encoder=HexEncoder)\n+ metadata, _user_key = conn.login(credentials=credentials)\n+ _user_key = SigningKey(_user_key.encode(\"utf-8\"), encoder=HexEncoder)\nelse:\nmetadata = conn._get_metadata()\n- user_key = SigningKey.generate()\n+ if not user_key:\n+ _user_key = SigningKey.generate()\n+ else:\n+ _user_key = user_key\n(\nspec_location,\n@@ -81,22 +88,28 @@ def connect(\nvm=location_args[VirtualMachineClient],\nname=name,\nroutes=[route],\n- signing_key=user_key,\n+ signing_key=_user_key,\n)\nself.groups = GroupRequestAPI(send=self.__perform_grid_request)\nself.users = UserRequestAPI(send=self.__perform_grid_request)\nself.roles = RoleRequestAPI(send=self.__perform_grid_request)\n- self.workers = WorkerRequestAPI(send=self.__perform_grid_request)\n+ self.workers = WorkerRequestAPI(\n+ send=self.__perform_grid_request, client=self\n+ )\nself.association_requests = AssociationRequestAPI(\nsend=self.__perform_grid_request\n)\n- def proxy(self, vm_address: Address) -> None:\n- self.proxy_address = vm_address\n-\n- def unproxy(self) -> None:\n- self.proxy_address = None\n+ def load(\n+ self, obj_ptr: Type[Pointer], address: Address, searchable: bool = False\n+ ) -> None:\n+ content = {\n+ \"address\": address.serialize().SerializeToString().decode(\"ISO-8859-1\"), # type: ignore\n+ \"uid\": str(obj_ptr.id_at_location.value),\n+ \"searchable\": searchable,\n+ }\n+ self.__perform_grid_request(grid_msg=LoadObjectMessage, content=content)\ndef initial_setup(self, **kwargs: Any) -> Any:\nreturn self.__perform_grid_request(\n@@ -113,7 +126,6 @@ def connect(\n],\nroute_index: int = 0,\n) -> SyftMessage:\n-\nif self.proxy_address:\nmsg.address = self.proxy_address\n",
        "chatgpt_cot": "Update import statement for ParamClientWidget in dynamic_reconfigure file to fix ImportError, and adjust widget resizing in main function for better display."
    },
    {
        "org_diff": "diff --git a/.travis.yml b/.travis.yml @@ -5,6 +5,7 @@ env:\nmatrix:\n- ROS_DISTRO=\"indigo\" ROS_REPO=\"ros\"\n- ROS_DISTRO=\"jade\" ROS_REPO=\"ros\"\n+ - ROS_DISTRO=\"kinetic\" ROS_REPO=\"ros-shadow-fixed\"\n- ROS_DISTRO=\"kinetic\" ROS_REPO=\"ros\"\n- ROS_DISTRO=\"lunar\" ROS_REPO=\"ros\"\nbefore_config:\n",
        "org_msg": "CI: test against ros-shadow-fixed for kinetic",
        "sim_msg": "issue enable a 2->3 Mitogen job.",
        "sim_diff": "diff --git a/.travis.yml b/.travis.yml @@ -32,6 +32,9 @@ matrix:\n# 2.6 -> 2.7\n- python: \"2.6\"\nenv: MODE=mitogen DISTRO=centos7\n+ # 2.6 -> 3.5\n+ - python: \"2.6\"\n+ env: MODE=mitogen DISTRO=debian-py3\n# 3.6 -> 2.6\n- python: \"3.6\"\nenv: MODE=mitogen DISTRO=centos6\n",
        "chatgpt_cot": "Add ROS Kinetic with ros-shadow-fixed for Travis CI build."
    },
    {
        "org_diff": "diff --git a/build_image/dockerhub/latest/agent/ansible/Dockerfile b/build_image/dockerhub/latest/agent/ansible/Dockerfile @@ -19,7 +19,7 @@ ARG uid=1000\nARG gid=1000\nRUN apt-get update && \\\n- apt-get install -y bash python-pip sudo && \\\n+ apt-get install -y bash python-pip sudo curl && \\\npip install --upgrade pip ansible pyyaml && \\\ngroupadd -g ${gid} ${user} && \\\nuseradd -d /opt/agent -u ${uid} -g ${user} ${user} && \\\n",
        "org_msg": "[Fix Add curl install for ansible agent\nIn ansible agent dockerhub file, add curl installation.",
        "sim_msg": "tests: Throttle docker pulls for Ansible tests\nI hope this will prevent AWS Elastic Container Registry returning 429:\nToo Many Requests error, due to the burst of activity from multiple VMs,\nwhen a CI build begins.",
        "sim_diff": "diff --git a/.ci/ansible_install.py b/.ci/ansible_install.py @@ -17,7 +17,7 @@ batches = [\n]\nbatches.extend(\n- ['docker pull %s' % (ci_lib.image_for_distro(distro),)]\n+ ['docker pull %s' % (ci_lib.image_for_distro(distro),), 'sleep 1']\nfor distro in ci_lib.DISTROS\n)\n",
        "chatgpt_cot": "Add curl to Dockerfile dependencies for Ansible agent image. Update pip and install dependencies to ensure proper functionality and compatibility with Ansible."
    },
    {
        "org_diff": "diff --git a/node_manager_daemon_fkie/src/node_manager_daemon_fkie/screen.py b/node_manager_daemon_fkie/src/node_manager_daemon_fkie/screen.py @@ -262,6 +262,7 @@ def rosclean():\nto get log again.\n'''\nd = rospkg.get_log_dir()\n+ if d and d != os.path.sep:\nps = SupervisedPopen(['rm -fr %s/*' % d], stdout=subprocess.PIPE, shell=True)\noutput_err = ps.stderr.read()\nif output_err:\n",
        "org_msg": "node_manager_daemon_fkie: check for log dir",
        "sim_msg": "make git log call simpler",
        "sim_diff": "diff --git a/InvenTree/plugin/helpers.py b/InvenTree/plugin/helpers.py @@ -98,14 +98,16 @@ def get_git_log(path):\n\"\"\"\npath = path.replace(os.path.dirname(settings.BASE_DIR), '')[1:]\ncommand = ['git', 'log', '-n', '1', \"--pretty=format:'%H%n%aN%n%aE%n%aI%n%f%n%G?%n%GK'\", '--follow', '--', path]\n+ output = None\ntry:\noutput = str(subprocess.check_output(command, cwd=os.path.dirname(settings.BASE_DIR)), 'utf-8')[1:-1]\nif output:\noutput = output.split('\\n')\n- else:\n- output = 7 * ['']\n- except subprocess.CalledProcessError:\n- output = 7 * ['']\n+ except subprocess.CalledProcessError: # pragma: no cover\n+ pass\n+\n+ if not output:\n+ output = 7 * [''] # pragma: no cover\nreturn {'hash': output[0], 'author': output[1], 'mail': output[2], 'date': output[3], 'message': output[4], 'verified': output[5], 'key': output[6]}\n",
        "chatgpt_cot": "Fix issue with rosclean function in screen.py to properly handle the log directory path, preventing errors and improving functionality."
    },
    {
        "org_diff": "diff --git a/fkie_node_manager_daemon/src/fkie_node_manager_daemon/launcher.py b/fkie_node_manager_daemon/src/fkie_node_manager_daemon/launcher.py @@ -224,8 +224,8 @@ def run_node(startcfg):\n_load_parameters(masteruri, startcfg.params, startcfg.clear_params)\n# start\ncmd_str = utf8('%s %s %s' % (screen.get_cmd(startcfg.fullname, new_env, startcfg.env.keys()), cmd_type, ' '.join(args)))\n- rospy.loginfo(\"run node '%s' with masteruri: %s, launch_file: '%s'\" % (nodename, masteruri, startcfg.config_path))\n- rospy.logdebug(\"run node: %s (env: %s)\", cmd_str, new_env)\n+ rospy.loginfo(\"%s (launch_file: '%s', masteruri: %s)\" % (cmd_str, startcfg.config_path, masteruri))\n+ rospy.logdebug(\"environment while run node '%s': '%s'\" % (cmd_str, new_env))\nSupervisedPopen(shlex.split(cmd_str), cwd=cwd, env=new_env, object_id=\"run_node_%s\" % startcfg.fullname, description=\"Run [%s]%s\" % (utf8(startcfg.package), utf8(startcfg.binary)))\nelse:\nrospy.loginfo(\"remote run node '%s' at '%s'\" % (nodename, startcfg.nmduri))\n",
        "org_msg": "fkie_node_manager_daemon: changed log info on node start",
        "sim_msg": "retry startup",
        "sim_diff": "diff --git a/lbrynet/lbrynet_daemon/DaemonControl.py b/lbrynet/lbrynet_daemon/DaemonControl.py @@ -114,7 +114,7 @@ def update_settings_from_args(args):\n@defer.inlineCallbacks\n-def start_server_and_listen(launchui, use_auth, analytics_manager):\n+def start_server_and_listen(launchui, use_auth, analytics_manager, max_tries=5):\n\"\"\"The primary entry point for launching the daemon.\nArgs:\n@@ -124,13 +124,19 @@ def start_server_and_listen(launchui, use_auth, analytics_manager):\n\"\"\"\nanalytics_manager.send_server_startup()\nlog_support.configure_analytics_handler(analytics_manager)\n+ tries = 1\n+ while tries < max_tries:\n+ log.info('Making attempt %s / %s to startup', tries, max_tries)\ntry:\ndaemon_server = DaemonServer(analytics_manager)\nyield daemon_server.start(use_auth, launchui)\nanalytics_manager.send_server_startup_success()\n+ break\nexcept Exception as e:\nlog.exception('Failed to startup')\nanalytics_manager.send_server_startup_error(str(e))\n+ tries += 1\n+ else:\nreactor.callFromThread(reactor.stop)\n",
        "chatgpt_cot": "Refactor run_node to log environment and launch file. This improves the information logged for debugging and helps with remote node execution."
    },
    {
        "org_diff": "diff --git a/fkie_node_manager/src/fkie_node_manager/editor/editor.py b/fkie_node_manager/src/fkie_node_manager/editor/editor.py @@ -935,7 +935,7 @@ class Editor(QMainWindow):\nself._insert_text('<env name=\"variable\" value=\"value\"/>', 11, 8)\ndef _on_add_param_clipboard_tag(self):\n- self._insert_text('<param name=\"name\" value=\"%s\" />' % QApplication.clipboard().mimeData().text(), 13, 4)\n+ self._insert_text('<param name=\"%s\" value=\"value\" />' % QApplication.clipboard().mimeData().text(), 13, 4)\ndef _on_add_param_tag(self):\nself._insert_text('<param name=\"name\" value=\"value\" />', 13, 4)\n",
        "org_msg": "fkie_node_manager: editor: add name from clipboard on add new parameter",
        "sim_msg": "Tidy microdata code",
        "sim_diff": "diff --git a/v7/microdata/microdata.py b/v7/microdata/microdata.py @@ -50,10 +50,13 @@ class ItemProp(nodes.Inline, nodes.TextElement):\npass\n-def itemprop_role(role, rawtext, text, lineno, inliner, options={}, content=[]):\n+def itemprop_role(\n+ role, rawtext, text, lineno, inliner, options={}, content=[]):\nmatch = RE_ROLE.match(text)\nif not match or not match.group('name'):\n- raise ValueError('%s does not match expected itemprop format: :itemprop:`value <name>`')\n+ raise ValueError(\n+ '%s does not match expected itemprop format: :itemprop:`'\n+ 'value <name>`')\nvalue = ''\nif match.group('value'):\nvalue = match.group('value')\n@@ -105,7 +108,9 @@ class ItemPropDirective(Directive):\nclass ItemScope(nodes.Element):\n- def __init__(self, tagname, itemtype, itemprop=None, compact=False, classes=None):\n+ def __init__(\n+ self, tagname, itemtype,\n+ itemprop=None, compact=False, classes=None):\nkwargs = {\n'itemscope': None,\n'itemtype': \"http://data-vocabulary.org/%s\" % itemtype,\n@@ -149,17 +154,31 @@ def visit_ItemProp(self, node):\nif node['name'] == 'url':\nnode['tag'] = 'a'\n- self.body.append(self.starttag(node, node['tag'], '', itemprop=node['name'], href=node['info']))\n+ self.body.append(\n+ self.starttag(\n+ node, node['tag'], '',\n+ itemprop=node['name'], href=node['info']))\nelif node['tag'] == 'img':\n- self.body.append(self.emptytag(node, node['tag'], '', itemprop=node['name'], src=node['info']))\n+ self.body.append(\n+ self.emptytag(\n+ node, node['tag'], '',\n+ itemprop=node['name'], src=node['info']))\nelif node['tag'] == 'time':\n# TODO: auto convert the time\n- self.body.append(self.starttag(node, node['tag'], '', itemprop=node['name'], datetime=node['info']))\n+ self.body.append(\n+ self.starttag(\n+ node, node['tag'], '',\n+ itemprop=node['name'], datetime=node['info']))\nelif node['tag'] == 'meta':\n# TODO: auto convert the time\n- self.body.append(self.emptytag(node, node['tag'], '', itemprop=node['name'], content=node['info']))\n+ self.body.append(\n+ self.emptytag(\n+ node, node['tag'], '',\n+ itemprop=node['name'], content=node['info']))\nelse:\n- self.body.append(self.starttag(node, node['tag'], '', itemprop=node['name']))\n+ self.body.append(\n+ self.starttag(\n+ node, node['tag'], '', itemprop=node['name']))\ndef depart_ItemProp(self, node):\n",
        "chatgpt_cot": "Update _on_add_param_clipboard_tag method to use variable value from clipboard for param name instead of hard-coded value."
    },
    {
        "org_diff": "diff --git a/.travis.yml b/.travis.yml @@ -33,10 +33,10 @@ jobs:\n- docker exec -i app bash -c \"cd /root/template && pipenv install --dev --python 3.7\"\n# Run tests\n- docker exec -i app bash -c \"cd /root/template && pipenv run pytest test/\"\n- - docker exec -i app bash -c \"cd /root/template && pipenv run pytest test/test_benchmark_distance_two_points.py --benchmark-compare\"\n- - docker exec -i app bash -c \"cd /root/template && pipenv run pytest test/test_benchmark_distances_units.py --benchmark-compare\"\n- - docker exec -i app bash -c \"cd /root/template && pipenv run pytest test/test_benchmark_array_creation.py --benchmark-compare\"\n- - docker exec -i app bash -c \"cd /root/template && pipenv run pytest test/test_benchmark_distances_points_to_point.py --benchmark-compare\"\n+ - docker exec -i app bash -c \"cd /root/template && pipenv run pytest test/test_benchmark_distance_two_points.py\"\n+ - docker exec -i app bash -c \"cd /root/template && pipenv run pytest test/test_benchmark_distances_units.py\"\n+ - docker exec -i app bash -c \"cd /root/template && pipenv run pytest test/test_benchmark_array_creation.py\"\n+ - docker exec -i app bash -c \"cd /root/template && pipenv run pytest test/test_benchmark_distances_points_to_point.py\"\n# Shut down and remove container\n- docker rm -f app\n",
        "org_msg": "Remove --benchmark-compare",
        "sim_msg": "ch-3986: update tox config for course notebook test",
        "sim_diff": "diff --git a/tox.ini b/tox.ini @@ -10,6 +10,7 @@ envlist =\nstack.test.integration.windows\nstack.test.integration.k8s\nstack.test.integration.smpc\n+ stack.test.integration.course\ngrid.test.backend\nrequires =\ntox-run-command\n@@ -325,23 +326,6 @@ commands =\npytest tests/integration -m k8s -p no:randomly --co\nbash -c 'TEST_DOMAIN_IP=`minikube ip` TEST_DOMAIN_PORT=80 pytest tests/integration -m k8s -vvvv -p no:randomly -p no:benchmark -o log_cli=True --capture=no'\n-[testenv:grid.test.backend]\n-description = Tests for Grid Backend\n-deps =\n- {[testenv:syft]deps}\n- pytest\n- pytest-xdist[psutil]\n- poetry\n- importlib-metadata\n-changedir = {toxinidir}/packages/grid/backend\n-allowlist_externals =\n- bash\n-commands =\n- python --version\n- pip install -r requirements.txt\n- pip install importlib-metadata colorama # poetry is messing this up?\n- bash -c 'SQLALCHEMY_DATABASE_URI=\"sqlite:///file:test_db?mode=memory&cache=shared&uri=true\" LOGURU_SINK=\"./grid.log\" pytest grid/tests'\n-\n[testenv:stack.test.integration.course]\ndescription = Integration Tests for Course Notebooks\ndeps =\n@@ -354,6 +338,7 @@ allowlist_externals =\nbash\ncommands =\npip install -e packages/hagrid\n+ pip install testbook\ndocker --version\ndocker compose version\nbash -c \"docker volume rm test_domain_1_app-db-data --force || true\"\n@@ -365,17 +350,31 @@ commands =\ndocker ps\nbash -c '(docker logs test_domain_1-backend_stream-1 -f &) | grep -q \"Application startup complete\" || true'\nbash -c 'cd tests/integration/course/courses && git checkout introduction-to-remote-data-science && git pull'\n- bash -c 'pytest tests'\nsleep 5\n- ; perform spmc test\n-\n- pytest tests/integration -m smpc -p no:randomly --co\n- pytest tests/integration -m smpc -vvvv -p no:randomly -p no:benchmark -o log_cli=True --capture=no\n+ ; perform course notebook test\n+ bash -c 'pytest tests'\nbash -c 'HAGRID_ART=false hagrid land test_domain_1'\nbash -c 'cd.. && rm -rf courses'\n+[testenv:grid.test.backend]\n+description = Tests for Grid Backend\n+deps =\n+ {[testenv:syft]deps}\n+ pytest\n+ pytest-xdist[psutil]\n+ poetry\n+ importlib-metadata\n+changedir = {toxinidir}/packages/grid/backend\n+allowlist_externals =\n+ bash\n+commands =\n+ python --version\n+ pip install -r requirements.txt\n+ pip install importlib-metadata colorama # poetry is messing this up?\n+ bash -c 'SQLALCHEMY_DATABASE_URI=\"sqlite:///file:test_db?mode=memory&cache=shared&uri=true\" LOGURU_SINK=\"./grid.log\" pytest grid/tests'\n+\n[flake8]\nignore =\nW503\n",
        "chatgpt_cot": "\"Refactor test commands in .travis.yml to remove unnecessary benchmark comparison and improve test execution efficiency.\""
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/main_window.py b/node_manager_fkie/src/node_manager_fkie/main_window.py @@ -1624,7 +1624,7 @@ class MainWindow(QMainWindow):\nmastername = ''\nif nm.is_local(addr):\nsmuri = smuri.replace(get_hostname(smuri), '%LOCAL%')\n- addr = 'localhost'\n+ addr = '%LOCAL%'\nelse:\nmastername = nm.nameres().mastername(smuri, nm.nameres().address(smuri))\nfor node_name in running_nodes.keys():\n@@ -1641,7 +1641,6 @@ class MainWindow(QMainWindow):\nif cfg not in configs:\nconfigs[cfg] = {'nodes': []}\nconfigs[cfg]['nodes'].append(node_name)\n-# nodes.append(node_name)\nelif node_name.endswith('master_discovery'):\nmd_param = self.get_param('master_discovery', muri)\nelif node_name.endswith('master_sync'):\n@@ -1715,7 +1714,8 @@ class MainWindow(QMainWindow):\nif not isinstance(content, dict):\nraise Exception(\"Mailformed profile: %s\" % os.path.basename(path))\nfor muri, master_dict in content.items():\n- rmuri = muri.replace('%LOCAL%', get_hostname(self.getMasteruri()))\n+ local_hostname = get_hostname(self.getMasteruri())\n+ rmuri = muri.replace('%LOCAL%', local_hostname)\nmaster = self.getMaster(rmuri)\nrunning_nodes = master.getRunningNodesIfLocal()\nusr = None\n@@ -1723,7 +1723,7 @@ class MainWindow(QMainWindow):\nusr = master_dict['user']\nif master_dict['mastername'] and master_dict['mastername']:\nnm.nameres().add_master_entry(master.masteruri, master_dict['mastername'], master_dict['address'])\n- hostname = master_dict['address']\n+ hostname = master_dict['address'].replace('%LOCAL%', local_hostname)\nif 'master_discovery' in master_dict:\nself._start_node_from_profile(master, hostname, 'master_discovery_fkie', 'master_discovery', usr, cfg=master_dict['master_discovery'])\nif 'master_sync' in master_dict:\n@@ -1747,6 +1747,7 @@ class MainWindow(QMainWindow):\nif not reload_launch:\nforce_start = False\ndo_not_stop.update(set(cmdict['nodes']))\n+ do_start.append((reload_launch, cfg_name, cmdict['nodes'], force_start))\nelse:\ndo_start.append((reload_launch, cfg_name, cmdict['nodes'], force_start))\n# close unused configurations\n",
        "org_msg": "node_manager_fkie: fixed satrt nodes by load new profile with same launch files",
        "sim_msg": "a bunch of improvements on ui",
        "sim_diff": "diff --git a/quarkchain/cluster/master.py b/quarkchain/cluster/master.py @@ -736,6 +736,8 @@ class MasterServer():\n\"txCount60s\": txCount60s,\n\"pendingTxCount\": pendingTxCount,\n\"syncing\": self.synchronizer.running,\n+ \"numTxPerBlock\": self.artificialTxConfig.numTxPerBlock,\n+ \"xShardTxPercent\": self.artificialTxConfig.xShardTxPercent,\n\"shards\": shards,\n}\n",
        "chatgpt_cot": "\"Update local address to '%LOCAL%' for local nodes and replace '%LOCAL%' with actual local hostname for remote nodes.\""
    },
    {
        "org_diff": "diff --git a/rasa_core_sdk/forms.py b/rasa_core_sdk/forms.py @@ -6,7 +6,7 @@ from __future__ import unicode_literals\nimport logging\nimport typing\n-from typing import Dict, Text, Any, List, Union\n+from typing import Dict, Text, Any, List, Union, Optional\nfrom rasa_core_sdk import Action, ActionExecutionError\nfrom rasa_core_sdk.events import SlotSet, Form\n@@ -23,6 +23,8 @@ REQUESTED_SLOT = \"requested_slot\"\nclass FormAction(Action):\n+ FREETEXT = 'FREETEXT'\n+\ndef name(self):\n# type: () -> Text\n\"\"\"Unique identifier of the form\"\"\"\n@@ -38,31 +40,54 @@ class FormAction(Action):\n\"that it has to fill\")\ndef slot_mapping(self):\n- # type: () -> Dict[Text: Union[Text, List[Text]]]\n- \"\"\"A dictionary to map required slots to extracted entities\"\"\"\n+ # type: () -> Dict[Text: Union[Text, List[Text], Dict[Text: Any]]]\n+ \"\"\"A dictionary to map required slots to extracted entities or\n+ to intent:value pairs or free text\"\"\"\nreturn dict(zip(self.required_slots(), self.required_slots()))\n# noinspection PyUnusedLocal\n- def validate(self, dispatcher, tracker, domain):\n- # type: (CollectingDispatcher, Tracker, Dict[Text, Any]) -> List[Dict]\n- \"\"\"\"Validate the user input else return an error\"\"\"\n+ def extract(self, dispatcher, tracker, domain):\n+ # type: (CollectingDispatcher, Tracker, Dict[Text, Any]) -> Optional[List[Dict]]\n+ \"\"\"\"Extract the user input else return an error\"\"\"\nslot_to_fill = tracker.slots[REQUESTED_SLOT]\n# map requested_slot to entity\n- required_entities = self.slot_mapping().get(slot_to_fill)\n-\n- if required_entities:\n- if isinstance(required_entities, str):\n+ slot_mapping = self.slot_mapping().get(slot_to_fill)\n+\n+ if slot_mapping:\n+ if slot_mapping == self.FREETEXT:\n+ return [SlotSet(slot_to_fill,\n+ tracker.latest_message.get(\"text\"))]\n+ elif isinstance(slot_mapping, dict):\n+ intent = tracker.latest_message.get(\"intent\", {}).get(\"name\")\n+ if intent in slot_mapping.keys():\n+ return [SlotSet(slot_to_fill, slot_mapping[intent])]\n+ else:\n+ required_entities = slot_mapping\n+ if not isinstance(required_entities, list):\nrequired_entities = [required_entities]\nfor e in tracker.latest_message[\"entities\"]:\nif e.get(\"entity\") in required_entities:\nreturn [SlotSet(slot_to_fill, e['value'])]\n+ return None\n+\n+ # noinspection PyUnusedLocal\n+ def validate(self, dispatcher, tracker, domain):\n+ # type: (CollectingDispatcher, Tracker, Dict[Text, Any]) -> List[Dict]\n+ \"\"\"\"Extract the user input else return an error\"\"\"\n+\n+ events = self.extract(dispatcher, tracker, domain)\n+\n+ if events is not None:\n+ return events\n+ else:\nraise ActionExecutionError(\"Failed to validate slot {0} \"\n\"with action {1}\"\n- \"\".format(slot_to_fill, self.name()),\n+ \"\".format(tracker.slots[REQUESTED_SLOT],\n+ self.name()),\nself.name())\ndef submit(self, dispatcher, tracker, domain):\n",
        "org_msg": "add freetext key and {intent:value} pairs RasaHQ/roadmap#280",
        "sim_msg": "Custom DRF serializers for receiving line items against a purchase order",
        "sim_diff": "diff --git a/InvenTree/order/serializers.py b/InvenTree/order/serializers.py @@ -11,6 +11,8 @@ from django.db.models import Case, When, Value\nfrom django.db.models import BooleanField\nfrom rest_framework import serializers\n+from rest_framework.serializers import ValidationError\n+\nfrom sql_util.utils import SubqueryCount\nfrom InvenTree.serializers import InvenTreeModelSerializer\n@@ -18,8 +20,12 @@ from InvenTree.serializers import InvenTreeAttachmentSerializer\nfrom InvenTree.serializers import InvenTreeMoneySerializer\nfrom InvenTree.serializers import InvenTreeAttachmentSerializerField\n+import company.models\nfrom company.serializers import CompanyBriefSerializer, SupplierPartSerializer\n+\nfrom part.serializers import PartBriefSerializer\n+\n+import stock.models\nfrom stock.serializers import LocationBriefSerializer, StockItemSerializer, LocationSerializer\nfrom .models import PurchaseOrder, PurchaseOrderLineItem\n@@ -161,6 +167,72 @@ class POLineItemSerializer(InvenTreeModelSerializer):\n]\n+class POLineItemReceiveSerializer(serializers.Serializer):\n+ \"\"\"\n+ A serializer for receiving a single purchase order line item against a purchase order\n+ \"\"\"\n+\n+ supplier_part = serializers.PrimaryKeyRelatedField(\n+ queryset=company.models.SupplierPart.objects.all(),\n+ many=False,\n+ label=_('Supplier Part'),\n+ )\n+\n+ location = serializers.PrimaryKeyRelatedField(\n+ queryset=stock.models.StockLocation.objects.all(),\n+ many=False,\n+ allow_null=True,\n+ label=_('Location'),\n+ help_text=_('Select destination location for received items'),\n+ )\n+\n+ class Meta:\n+ fields = [\n+ 'supplier_part',\n+ 'location',\n+ ]\n+\n+\n+class POReceiveSerializer(serializers.Serializer):\n+ \"\"\"\n+ Serializer for receiving items against a purchase order\n+ \"\"\"\n+\n+ items = serializers.StringRelatedField(\n+ many=True\n+ )\n+\n+ location = serializers.PrimaryKeyRelatedField(\n+ queryset=stock.models.StockLocation.objects.all(),\n+ many=False,\n+ allow_null=True,\n+ label=_('Location'),\n+ help_text=_('Select destination location for received items'),\n+ )\n+\n+ def is_valid(self, raise_exception=False):\n+\n+ super().is_valid(raise_exception)\n+\n+ # Custom validation\n+ data = self.validated_data\n+\n+ items = data.get('items', [])\n+\n+ if len(items) == 0:\n+ raise ValidationError({\n+ 'items': _('Line items must be provided'),\n+ })\n+\n+ return not bool(self._errors)\n+\n+ class Meta:\n+ fields = [\n+ 'items',\n+ 'location',\n+ ]\n+\n+\nclass POAttachmentSerializer(InvenTreeAttachmentSerializer):\n\"\"\"\nSerializers for the PurchaseOrderAttachment model\n",
        "chatgpt_cot": "Add FREETEXT slot mapping to extract free text from user input in FormAction. Update validate method to use extract method for slot validation."
    },
    {
        "org_diff": "diff --git a/sc2/bot_ai.py b/sc2/bot_ai.py @@ -157,8 +157,7 @@ class BotAI(object):\nif random_alternative:\nreturn random.choice(possible)\nelse:\n- m = min(possible, key=lambda p: p.distance_to(near))\n- return m\n+ return min(possible, key=lambda p: p.distance_to(near))\nreturn None\ndef already_pending(self, unit_type):\n",
        "org_msg": "Directly return value instead of assigning to an unused variable",
        "sim_msg": "added time to the saved files",
        "sim_diff": "diff --git a/bot_manager.py b/bot_manager.py @@ -178,7 +178,7 @@ class BotManager:\ncurrent_time = game_tick_packet.gameInfo.TimeSeconds\nif self.save_data and game_tick_packet.gameInfo.bRoundActive and not old_time == current_time and not current_time == -10:\n- np_input = self.input_converter.create_input_array(game_tick_packet)\n+ np_input = self.input_converter.create_input_array(game_tick_packet, passed_time=time.time() - before2)\nnp_output = np.array(controller_input, dtype=np.float32)\nself.input_array = np.append(self.input_array, np_input)\nself.output_array = np.append(self.output_array, np_output)\n",
        "chatgpt_cot": "Refactor distance calculation in BotAI to improve readability."
    },
    {
        "org_diff": "diff --git a/sc2/bot_ai.py b/sc2/bot_ai.py @@ -1918,18 +1918,18 @@ class BotAI(DistanceCalculation):\nawait self.on_enemy_unit_left_vision(enemy_structure_tag)\nasync def _issue_unit_dead_events(self):\n- for unit_tag in self.state.dead_units:\n- dead_unit: Optional[Unit] = self._all_units_previous_map.get(unit_tag, None)\n- if dead_unit:\n- await self.on_unit_destroyed(dead_unit)\n+ for unit_tag in self.state.dead_units & set(self._all_units_previous_map.keys()):\n+ await self.on_unit_destroyed(unit_tag)\n- async def on_unit_destroyed(self, unit: Unit):\n+ async def on_unit_destroyed(self, unit_tag: int):\n\"\"\"\nOverride this in your bot class.\n+ Note that this function uses unit tags and not the unit objects\n+ because the unit does not exist any more.\nThis will event will be called when a unit (or structure, friendly or enemy) dies.\nFor enemy units, this only works if the enemy unit was in vision on death.\n- :param unit:\n+ :param unit_tag:\n\"\"\"\nasync def on_unit_created(self, unit: Unit):\n",
        "org_msg": "Restore unit_tag function signature",
        "sim_msg": "added time to the saved files",
        "sim_diff": "diff --git a/bot_manager.py b/bot_manager.py @@ -178,7 +178,7 @@ class BotManager:\ncurrent_time = game_tick_packet.gameInfo.TimeSeconds\nif self.save_data and game_tick_packet.gameInfo.bRoundActive and not old_time == current_time and not current_time == -10:\n- np_input = self.input_converter.create_input_array(game_tick_packet)\n+ np_input = self.input_converter.create_input_array(game_tick_packet, passed_time=time.time() - before2)\nnp_output = np.array(controller_input, dtype=np.float32)\nself.input_array = np.append(self.input_array, np_input)\nself.output_array = np.append(self.output_array, np_output)\n",
        "chatgpt_cot": "Refactor on_unit_destroyed method to use unit tags, improving efficiency and functionality. Also, change parameter type to int for consistency."
    },
    {
        "org_diff": "diff --git a/examples/simulate_fight_scenario.py b/examples/simulate_fight_scenario.py @@ -10,23 +10,20 @@ from loguru import logger\nclass FightBot(BotAI):\ndef __init__(self):\nsuper().__init__()\n- self.control_requested = False\nself.control_received = False\nself.fight_started = False\nself.supplies_been_damaged = False\nasync def on_step(self, iteration):\n- # prepare the level\n- if not self.control_requested:\n- # we need this one for `self.enemy_units` to \"see\" all units\n+ # before everything else - retrieve control\n+ if iteration == 0:\n+ # we need this one for `self.enemy_units` to \"see\" all units on the map\nawait self._client.debug_show_map()\n- # this one will allow us to do something like: `self.enemy_units.first.attack(self.townhalls.first)`\n+ # this one will allow us to do something like: `self.enemy_units.first.attack(self._game_info.map_center)`\nawait self._client.debug_control_enemy()\n- logger.info(\"control requested\")\n- # await self.chat_send(\"control requested\")\n- self.control_requested = True\n- if self.control_requested and self.enemy_units and not self.control_received:\n+ # wait till control retrieved\n+ if iteration > 0 and self.enemy_units and not self.control_received:\n# prepare my side\nme = 1\ncc = self.townhalls.first\n@@ -60,9 +57,9 @@ class FightBot(BotAI):\n# to speedup, we are going damage both supplies\nif not self.supplies_been_damaged and self.structures(UnitTypeId.SUPPLYDEPOT) and self.enemy_structures(UnitTypeId.SUPPLYDEPOT):\n- for s in self.structures:\n+ for s in self.structures(UnitTypeId.SUPPLYDEPOT):\nawait self._client.debug_set_unit_value([s.tag], 2, 100)\n- for s in self.enemy_structures:\n+ for s in self.enemy_structures(UnitTypeId.SUPPLYDEPOT):\nawait self._client.debug_set_unit_value([s.tag], 2, 100)\nlogger.info(\"supplies damaged\")\n# await self.chat_send(\"supplies damaged\")\n",
        "org_msg": "damage only supply depots",
        "sim_msg": "feat(logging): included optional default message to every log (e.g., can be used to inform thread id)",
        "sim_diff": "diff --git a/rlberry/utils/logging.py b/rlberry/utils/logging.py @@ -5,7 +5,8 @@ import gym\ndef configure_logging(level: str = \"INFO\",\nfile_path: Path = None,\n- file_level: str = \"DEBUG\") -> None:\n+ file_level: str = \"DEBUG\",\n+ default_msg: str = \"\") -> None:\n\"\"\"\nSet the logging configuration\n@@ -20,16 +21,18 @@ def configure_logging(level: str = \"INFO\",\nPath to a log file\nfile_level\nLevel of verbosity for the file handler\n+ default_msg\n+ Message to append to the beginning all logs (e.g. thread id).\n\"\"\"\nconfig = {\n\"version\": 1,\n\"disable_existing_loggers\": False,\n\"formatters\": {\n\"standard\": {\n- \"format\": \"[%(levelname)s] %(message)s \"\n+ \"format\": default_msg+\"[%(levelname)s] %(message)s \"\n},\n\"detailed\": {\n- \"format\": \"[%(name)s:%(levelname)s] %(message)s \"\n+ \"format\": default_msg+\"[%(name)s:%(levelname)s] %(message)s \"\n}\n},\n\"handlers\": {\n",
        "chatgpt_cot": "Refactor control logic in FightBot, retrieve control on iteration 0, and damage supplies properly. Improve code readability and functionality."
    },
    {
        "org_diff": "diff --git a/node_manager_daemon_fkie/src/node_manager_daemon_fkie/settings.py b/node_manager_daemon_fkie/src/node_manager_daemon_fkie/settings.py @@ -125,8 +125,9 @@ class Settings:\nresult = value\nelse:\nresult = value\n- except Exception as exc:\n- print exc\n+ except Exception as _exc:\n+ pass\n+ # print exc\nreturn result\ndef set_param(self, param_name, value, tag=':value'):\n@@ -154,8 +155,8 @@ class Settings:\n# create new parameter entry\ncfg_item[pname] = {val_tag: value}\nself.save()\n- except Exception as exc:\n- print exc\n+ except Exception as _exc:\n+ pass\ndef reload(self):\n'''\n",
        "org_msg": "node_manager_daemon_fkie: removed print statements",
        "sim_msg": "badrequest  fix",
        "sim_diff": "diff --git a/modules/config.py b/modules/config.py @@ -1124,7 +1124,12 @@ class Config:\nitems = library.Plex.all()\nfor i, item in enumerate(items, 1):\nlength = util.print_return(length, \"Processing: {}/{} {}\".format(i, len(items), item.title))\n+ try:\nid_type, main_id = self.get_id(item, library, length)\n+ except BadRequest:\n+ util.print_stacktrace()\n+ util.print_end(length, \"{} {:<46} | {} for {}\".format(\"Cache | ! |\" if self.Cache else \"Mapping Error:\", item.guid, error_message, item.title))\n+ continue\nif isinstance(main_id, list):\nif id_type == \"movie\":\nfor m in main_id: movie_map[m] = item.ratingKey\n",
        "chatgpt_cot": "\"Refactor exception handling in settings.py to use pass instead of print to improve code readability and maintainability.\""
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/scripts/remote_nm.py b/node_manager_fkie/scripts/remote_nm.py @@ -9,6 +9,7 @@ import time\nimport roslib\nimport rospy\n+from master_discovery_fkie.common import masteruri_from_ros\nfrom node_manager_daemon_fkie import screen\nfrom node_manager_daemon_fkie.settings import RESPAWN_SCRIPT\ntry:\n@@ -149,7 +150,7 @@ def runNode(package, executable, name, args, prefix='', repawn=False, masteruri=\nRuns a ROS node. Starts a roscore if needed.\n'''\nif not masteruri:\n- masteruri = nm.masteruri_from_ros()\n+ masteruri = masteruri_from_ros()\n# start roscore, if needed\nnm.StartHandler._prepareROSMaster(masteruri)\n# start node\n",
        "org_msg": "node_manager_fkie: fix remote start",
        "sim_msg": "add option to set bootstrap_node",
        "sim_diff": "diff --git a/scripts/dht_node.py b/scripts/dht_node.py import asyncio\nimport argparse\nimport logging\n+from typing import Optional\nfrom lbry.dht.constants import generate_id\nfrom lbry.dht.node import Node\n@@ -12,16 +13,21 @@ logging.basicConfig(level=logging.INFO, format=\"%(asctime)s %(levelname)-4s %(na\nlog = logging.getLogger(__name__)\n-async def main(host: str, port: int, db_file_path):\n+async def main(host: str, port: int, db_file_path: str, bootstrap_node: Optional[str]):\nloop = asyncio.get_event_loop()\nconf = Config()\nstorage = SQLiteStorage(conf, db_file_path, loop, loop.time)\n+ if bootstrap_node:\n+ nodes = bootstrap_node.split(':')\n+ nodes = [(nodes[0], int(nodes[1]))]\n+ else:\n+ nodes = conf.known_dht_nodes\nawait storage.open()\nnode = Node(\nloop, PeerManager(loop), generate_id(), port, port, 3333, None,\nstorage=storage\n)\n- node.start(host, conf.known_dht_nodes)\n+ node.start(host, nodes)\nwhile True:\nawait asyncio.sleep(10)\nlog.info(\"Known peers: %d. Storing contact information for %d blobs from %d peers.\",\n@@ -35,5 +41,8 @@ if __name__ == '__main__':\nparser.add_argument(\"--host\", default='0.0.0.0', type=str, help=\"Host to listen for requests. Default: 0.0.0.0\")\nparser.add_argument(\"--port\", default=4444, type=int, help=\"Port to listen for requests. Default: 4444\")\nparser.add_argument(\"--db_file\", default='/tmp/dht.db', type=str, help=\"DB file to save peers. Default: /tmp/dht.db\")\n+ parser.add_argument(\"--bootstrap_node\", default=None, type=str,\n+ help=\"Node to connect for bootstraping this node. Leave unset to use the default ones. \"\n+ \"Format: host:port Example: lbrynet1.lbry.com:4444\")\nargs = parser.parse_args()\n- asyncio.run(main(args.host, args.port, args.db_file))\n+ asyncio.run(main(args.host, args.port, args.db_file, args.bootstrap_node))\n",
        "chatgpt_cot": "Fix import issue in remote_nm.py by using masteruri_from_ros directly. This modification helps resolve import conflicts and improves code readability."
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/__init__.py b/node_manager_fkie/src/node_manager_fkie/__init__.py @@ -186,7 +186,7 @@ def is_local(hostname, wait=False):\n# fix to handle the local names with domains\nif hostname == get_hostname(socket.gethostname()):\nwith _LOCK:\n- HOSTS_CACHE[hostname] = result\n+ HOSTS_CACHE[hostname] = hostname\nreturn True\nexcept:\npass\n",
        "org_msg": "fix copy&paste error",
        "sim_msg": "Added Cleanup for Localhost guest IPs",
        "sim_diff": "diff --git a/functions/database.py b/functions/database.py @@ -197,6 +197,12 @@ def dbFixes():\nchannel.xmppToken = str(os.urandom(32).hex())\ndb.session.commit()\n+ # Clear Any Localhost Guest UUIDs from the DB due to coding pre 0.8.6\n+ guestQuery = Sec.Guest.query.filter_by(last_active_ip=\"127.0.0.1\").all()\n+ for guest in guestQuery:\n+ db.session.delete(guest)\n+ db.session.commit()\n+\nreturn True\ndef init(app, user_datastore):\n",
        "chatgpt_cot": "Fix issue with handling local names with domains in the __init__.py file by updating the HOSTS_CACHE dictionary with the correct hostname value."
    },
    {
        "org_diff": "diff --git a/test/test_examples.py b/test/test_examples.py @@ -11,7 +11,7 @@ from examples.zerg_rush import ZergRushBot\ndef run_example(race, bot):\nresult = sc2.run_game(sc2.maps.get(\"Sequencer LE\"), [\nBot(race, bot),\n- Computer(Race.Zerg, Difficulty.Easy)\n+ Computer(Race.Terran, Difficulty.Easy)\n], realtime=False)\nassert result in [sc2.Result.Victory, sc2.Result.Defeat, sc2.Result.Tie]\n",
        "org_msg": "Play against Terran instead of Zerg in examples",
        "sim_msg": "Forgot to update iNumPlayers",
        "sim_diff": "diff --git a/v3/runner.py b/v3/runner.py @@ -63,6 +63,8 @@ if __name__ == '__main__':\ncallbacks = []\nname_dict = dict()\n+ gameInputPacket.iNumPlayers = num_bots\n+\n# Set configuration values for bots and store name and team\nfor i in range(num_bots):\nbot_config = configparser.RawConfigParser()\n",
        "chatgpt_cot": "Change the race of the computer opponent in the run_example function from Zerg to Terran in test_examples.py."
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/echo_dialog.py b/node_manager_fkie/src/node_manager_fkie/echo_dialog.py @@ -129,6 +129,7 @@ class EchoDialog(QDialog):\nself.line_limit = self.MESSAGE_LINE_LIMIT\nself.field_filter_fn = None\n+ self._latched = False\noptions = QWidget(self)\nif not show_only_rate:\n@@ -233,6 +234,7 @@ class EchoDialog(QDialog):\nself.print_hz_timer = QTimer()\nself.print_hz_timer.timeout.connect(self._on_calc_hz)\nself.print_hz_timer.start(1000)\n+ self._start_time = time.time()\n# print \"======== create\", self.objectName()\n#\n@@ -318,6 +320,7 @@ class EchoDialog(QDialog):\nif self.sub is None and self.ssh_output_file is None:\nif self.__msg_class:\nself.sub = rospy.Subscriber(self.topic, self.__msg_class, self._msg_handle)\n+ self._start_time = time.time()\nelse:\nself._on_display_anchorClicked(QUrl(self._masteruri))\nself.topic_control_button.setText('stop')\n@@ -346,11 +349,12 @@ class EchoDialog(QDialog):\n@param msg: the text to add to the dialog\n@type msg: message object\n'''\n+ self._latched = latched\ncurrent_time = time.time()\nself._count_messages(current_time)\n# skip messages, if they are received often then MESSAGE_HZ_LIMIT\nif self._last_received_ts != 0 and self.receiving_hz != 0:\n- if not latched and current_time - self._last_received_ts < 1.0 / self.receiving_hz:\n+ if (latched and current_time - self._start_time > 3.0) and current_time - self._last_received_ts < 1.0 / self.receiving_hz:\nself._scrapped_msgs += 1\nself._scrapped_msgs_sl += 1\nreturn\n@@ -451,7 +455,10 @@ class EchoDialog(QDialog):\nself.display.append(self._rate_message)\ndef _print_status(self):\n- self.status_label.setText('%s messages %s' % (self.message_count, self._rate_message))\n+ text = '%s messages %s' % (self.message_count, self._rate_message)\n+ if self._latched:\n+ text = \"[latched] %s\" % text\n+ self.status_label.setText(text)\ndef _append_text(self, text):\n'''\n",
        "org_msg": "node_manager_fkie: changed filter handling for latched topics\nAdded info in status bar for latched topic",
        "sim_msg": "Fix possible exception in task.check_status",
        "sim_diff": "diff --git a/pymatgen/io/abinit/tasks.py b/pymatgen/io/abinit/tasks.py @@ -1677,7 +1677,7 @@ class Task(six.with_metaclass(abc.ABCMeta, Node)):\n# Can only reset tasks that are done.\n# One should be able to reset 'Submitted' tasks (sometimes, they are not in the queue\n# and we want to restart them)\n- if self.status != self.S_SUB and self.status < self.S_DONE: return 1\n+ #if self.status != self.S_SUB and self.status < self.S_DONE: return 1\n# Remove output files otherwise the EventParser will think the job is still running\nself.output_file.remove()\n@@ -1951,31 +1951,29 @@ class Task(six.with_metaclass(abc.ABCMeta, Node)):\nscheduler_parser.parse()\nif scheduler_parser.errors:\n+ # Store the queue errors in the task\nself.queue_errors = scheduler_parser.errors\n- # the queue errors in the task\n+ # The job is killed or crashed and we know what happened\nmsg = \"scheduler errors found:\\n%s\" % str(scheduler_parser.errors)\n- # self.history.critical(msg)\nreturn self.set_status(self.S_QCRITICAL, msg=msg)\n- # The job is killed or crashed and we know what happened\n+\nelif lennone(qerr_info) > 0:\n# if only qout_info, we are not necessarily in QCRITICAL state,\n# since there will always be info in the qout file\n- msg = 'found unknown messages in the queue error: %s' % str(qerr_info)\n- logger.history.info(msg)\n- print(msg)\n- # self.num_waiting += 1\n- # if self.num_waiting > 1000:\n- rt = self.datetimes.get_runtime().seconds\n- tl = self.manager.qadapter.timelimit\n- if rt > tl:\n- msg += 'set to error : runtime (%s) exceded walltime (%s)' % (rt, tl)\n- print(msg)\n- return self.set_status(self.S_ERROR, msg=msg)\n+ self.history.info('found unknown messages in the queue error: %s' % str(qerr_info))\n+ #try:\n+ # rt = self.datetimes.get_runtime().seconds\n+ #except:\n+ # rt = -1.0\n+ #tl = self.manager.qadapter.timelimit\n+ #if rt > tl:\n+ # msg += 'set to error : runtime (%s) exceded walltime (%s)' % (rt, tl)\n+ # print(msg)\n+ # return self.set_status(self.S_ERROR, msg=msg)\n# The job may be killed or crashed but we don't know what happened\n# It may also be that an innocent message was written to qerr, so we wait for a while\n# it is set to QCritical, we will attempt to fix it by running on more resources\n-\n# 8) analizing the err files and abinit output did not identify a problem\n# but if the files are not empty we do have a problem but no way of solving it:\nif lennone(err_msg) > 0:\n",
        "chatgpt_cot": "add latched attribute to EchoDialog class to handle latched messages and update status label accordingly."
    },
    {
        "org_diff": "diff --git a/fkie_node_manager/src/fkie_node_manager/ssh_handler.py b/fkie_node_manager/src/fkie_node_manager/ssh_handler.py @@ -227,7 +227,7 @@ class SSHhandler(object):\nsession.connect(host, username=user, password=pw, timeout=3, compress=True)\nself.SSH_AUTH[host] = user\nexcept Exception as e:\n- if utf8(e) in ['Authentication failed.', 'No authentication methods available', 'Private key file is encrypted']:\n+ if utf8(e) in ['Authentication failed.', 'No authentication methods available', 'Private key file is encrypted', 'No existing session']:\nif auto_pw_request:\nres, user, pw = self._requestPW(user, host)\nif not res:\n",
        "org_msg": "fkie_node_manager: fixed ssh behaviour with 'No existing session'",
        "sim_msg": "On second thought, cache using fingerprints, so that we don't fill the disk.",
        "sim_diff": "diff --git a/ambassador/ambassador/utils.py b/ambassador/ambassador/utils.py @@ -379,7 +379,16 @@ class SecretHandler:\nkey_path = None\ncert_data = None\n+ h = hashlib.new('sha1')\n+\nif cert:\n+ h.update(cert.encode('utf-8'))\n+\n+ if key:\n+ h.update(key.encode('utf-8'))\n+\n+ hd = h.hexdigest().upper()\n+\nsecret_dir = os.path.join(self.cache_dir, namespace, \"secrets-decoded\", name)\ntry:\n@@ -387,11 +396,11 @@ class SecretHandler:\nexcept FileExistsError:\npass\n- cert_path = os.path.join(secret_dir, f'tls-{self.version}.crt')\n+ cert_path = os.path.join(secret_dir, f'{hd}.crt')\nopen(cert_path, \"w\").write(cert)\nif key:\n- key_path = os.path.join(secret_dir, f'tls-{self.version}.key')\n+ key_path = os.path.join(secret_dir, f'{hd}.key')\nopen(key_path, \"w\").write(key)\ncert_data = {\n",
        "chatgpt_cot": "Fix authentication error handling in SSHhandler. Added 'No existing session' to the list of authentication failure messages to trigger password request."
    },
    {
        "org_diff": "diff --git a/sc2/position.py b/sc2/position.py @@ -3,6 +3,8 @@ import math\nimport random\nfrom typing import Any, Dict, List, Optional, Set, Tuple, Union # for mypy type checking\n+EPSILON = 10 ** -8\n+\ndef _sign(num):\nreturn math.copysign(1, num)\n@@ -136,7 +138,7 @@ class Pointlike(tuple):\ndef __eq__(self, other):\ntry:\n- return all(a == b for a, b in itertools.zip_longest(self, other, fillvalue=0))\n+ return all(abs(a - b) <= EPSILON for a, b in itertools.zip_longest(self, other, fillvalue=0))\nexcept:\nreturn False\n",
        "org_msg": "Roll back to epsilon difference on position __eq__",
        "sim_msg": "feat: add coloring by connected component to skeleton viz",
        "sim_diff": "diff --git a/cloudvolume/skeleton.py b/cloudvolume/skeleton.py @@ -1055,7 +1055,11 @@ class Skeleton(object):\nreturn swc\n- def viewer(self, units='nm', draw_edges=True, draw_vertices=True):\n+ def viewer(\n+ self, units='nm',\n+ draw_edges=True, draw_vertices=True,\n+ color_by='radius'\n+ ):\n\"\"\"\nView the skeleton with a radius heatmap.\n@@ -1065,6 +1069,12 @@ class Skeleton(object):\nunits: label axes with these units\ndraw_edges: draw lines between vertices (more useful when skeleton is sparse)\ndraw_vertices: draw each vertex colored by its radius.\n+ color_by:\n+ 'radius': color each vertex according to its radius attribute\n+ aliases: 'r', 'radius', 'radii'\n+ 'component': color connected components seperately\n+ aliases: 'c', 'component', 'components'\n+ anything else: draw everything black\n\"\"\"\ntry:\nimport matplotlib.pyplot as plt\n@@ -1074,36 +1084,55 @@ class Skeleton(object):\nprint(\"Skeleton.viewer requires matplotlib. Try: pip install matplotlib --upgrade\")\nreturn\n+ RADII_KEYWORDS = ('radius', 'radii', 'r')\n+ COMPONENT_KEYWORDS = ('component', 'components', 'c')\n+\nfig = plt.figure(figsize=(10,10))\nax = Axes3D(fig)\nax.set_xlabel(units)\nax.set_ylabel(units)\nax.set_zlabel(units)\n+ component_colors = ['k', 'deeppink', 'dodgerblue', 'mediumaquamarine', 'gold' ]\n+\n+ def draw_component(i, skel):\n+ component_color = component_colors[ i % len(component_colors) ]\n+\nif draw_vertices:\n- xs = self.vertices[:,0]\n- ys = self.vertices[:,1]\n- zs = self.vertices[:,2]\n+ xs = skel.vertices[:,0]\n+ ys = skel.vertices[:,1]\n+ zs = skel.vertices[:,2]\n+ if color_by in RADII_KEYWORDS:\ncolmap = cm.ScalarMappable(cmap=cm.get_cmap('rainbow'))\n- colmap.set_array(self.radii)\n+ colmap.set_array(skel.radii)\n- normed_radii = self.radii / np.max(self.radii)\n+ normed_radii = skel.radii / np.max(skel.radii)\nyg = ax.scatter(xs, ys, zs, c=cm.rainbow(normed_radii), marker='o')\ncbar = fig.colorbar(colmap)\ncbar.set_label('radius (' + units + ')', rotation=270)\n+ elif color_by in COMPONENT_KEYWORDS:\n+ yg = ax.scatter(xs, ys, zs, color=component_color, marker='.')\n+ else:\n+ yg = ax.scatter(xs, ys, zs, color='k', marker='.')\nif draw_edges:\n- for e1, e2 in self.edges:\n- pt1, pt2 = self.vertices[e1], self.vertices[e2]\n+ for e1, e2 in skel.edges:\n+ pt1, pt2 = skel.vertices[e1], skel.vertices[e2]\nax.plot(\n[ pt1[0], pt2[0] ],\n[ pt1[1], pt2[1] ],\nzs=[ pt1[2], pt2[2] ],\n- color=('mediumseagreen' if not draw_vertices else 'silver'),\n+ color=(component_color if not draw_vertices else 'silver'),\nlinewidth=1,\n)\n+ if color_by in COMPONENT_KEYWORDS:\n+ for i, skel in enumerate(self.components()):\n+ draw_component(i, skel)\n+ else:\n+ draw_component(0, self)\n+\nplt.show()\ndef __eq__(self, other):\n",
        "chatgpt_cot": "Add EPSILON constant and modify equality comparison to use EPSILON for floating point comparison in position.py."
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/main_window.py b/node_manager_fkie/src/node_manager_fkie/main_window.py @@ -1619,6 +1619,14 @@ class MainWindow(QMainWindow):\nmd_param = {}\nms_param = {}\nzc_param = {}\n+ smuri = muri\n+ addr = nm.nameres().address(smuri)\n+ mastername = ''\n+ if nm.is_local(addr):\n+ smuri = smuri.replace(get_hostname(smuri), '%LOCAL%')\n+ addr = 'localhost'\n+ else:\n+ mastername = nm.nameres().mastername(smuri, nm.nameres().address(smuri))\nfor node_name in running_nodes.keys():\nnode_items = master.getNode(node_name)\nfor node in node_items:\n@@ -1646,15 +1654,15 @@ class MainWindow(QMainWindow):\nconfigs[a] = {}\nconfigs[a]['argv'] = b.argv\n# fill the configuration content for yaml as dictionary\n- content[muri] = {'mastername': nm.nameres().mastername(master.masteruri, nm.nameres().address(master.masteruri)),\n- 'address': nm.nameres().address(master.masteruri),\n+ content[smuri] = {'mastername': mastername,\n+ 'address': addr,\n'configs': configs}\nif md_param:\n- content[muri]['master_discovery'] = md_param\n+ content[smuri]['master_discovery'] = md_param\nif ms_param:\n- content[muri]['master_sync'] = ms_param\n+ content[smuri]['master_sync'] = ms_param\nif zc_param:\n- content[muri]['zeroconf'] = zc_param\n+ content[smuri]['zeroconf'] = zc_param\ntext = yaml.dump(content, default_flow_style=False)\nwith open(path, 'w+') as f:\nf.write(text)\n@@ -1707,11 +1715,13 @@ class MainWindow(QMainWindow):\nif not isinstance(content, dict):\nraise Exception(\"Mailformed profile: %s\" % os.path.basename(path))\nfor muri, master_dict in content.items():\n- master = self.getMaster(muri)\n+ rmuri = muri.replace('%LOCAL%', get_hostname(self.getMasteruri()))\n+ master = self.getMaster(rmuri)\nrunning_nodes = master.getRunningNodesIfLocal()\nusr = None\nif 'user' in master_dict:\nusr = master_dict['user']\n+ if master_dict['mastername'] and master_dict['mastername']:\nnm.nameres().add_master_entry(master.masteruri, master_dict['mastername'], master_dict['address'])\nhostname = master_dict['address']\nif 'master_discovery' in master_dict:\n",
        "org_msg": "node_manager_fkie: save profile for local master as generic",
        "sim_msg": "update for bright talk show",
        "sim_diff": "diff --git a/src/genie/libs/parser/dnac/interface.py b/src/genie/libs/parser/dnac/interface.py @@ -77,9 +77,14 @@ class InterfaceSchema(MetaParser):\n# Parser for '/dna/intent/api/v1/interface'\n# ============================================\nclass Interface(InterfaceSchema):\n- \"\"\"parser for /dna/intent/api/v1/interface, /dna/intent/api/v1/interface/{interface}\"\"\"\n+ \"\"\"\n+ parser for\n+ /dna/intent/api/v1/interface,\n+ /dna/intent/api/v1/interface/{interface}\n+ \"\"\"\n- cli_command = ['/dna/intent/api/v1/interface', '/dna/intent/api/v1/interface/{interface}']\n+ cli_command = ['/dna/intent/api/v1/interface',\n+ '/dna/intent/api/v1/interface/{interface}']\ndef cli(self,interface=\"\", output=None):\nif output is None:\n@@ -101,15 +106,17 @@ class Interface(InterfaceSchema):\ndevice_id = intf_dict['deviceId']\nif device_id not in id_to_hostname:\ndevice_id_cmd = cmd.format(device_id=device_id)\n- device_id_response = self.device.get(device_id_cmd).json()['response']\n- hostname = device_id_response['hostname']\n+ device_info = self.device.get(device_id_cmd).json()['response']\n+ hostname = device_info['hostname']\nid_to_hostname[device_id] = hostname\nelse:\nhostname = id_to_hostname[device_id]\n- result_dict.setdefault(device_id, {})\n+ host_info = result_dict.setdefault(hostname, {})\n# remove None values\n- result_dict[device_id][intf_dict['portName']] = {k: v for k, v in intf_dict.items() if v is not None}\n- result_dict[device_id][intf_dict['portName']]['hostname'] = hostname\n+ host_info[intf_dict['portName']] = {k: v\n+ for k, v in intf_dict.items()\n+ if v is not None}\n+ host_info[intf_dict['portName']]['hostname'] = hostname\nreturn result_dict\n",
        "chatgpt_cot": "Add new method, fix compilation issue because of new method in Alert."
    },
    {
        "org_diff": "diff --git a/examples/competitive/__init__.py b/examples/competitive/__init__.py @@ -47,10 +47,12 @@ def run_ladder_game(bot):\ncomputer_difficulty = args.ComputerDifficulty\n# Port config\n+ if lan_port is None:\n+ portconfig = None\n+ else:\nports = [lan_port + p for p in range(1, 6)]\nportconfig = sc2.portconfig.Portconfig()\n- portconfig.shared = ports[0] # Not used\nportconfig.server = [ports[1], ports[2]]\nportconfig.players = [[ports[3], ports[4]]]\n",
        "org_msg": "Update competitive example for vsComputer",
        "sim_msg": "Forgot to update iNumPlayers",
        "sim_diff": "diff --git a/v3/runner.py b/v3/runner.py @@ -63,6 +63,8 @@ if __name__ == '__main__':\ncallbacks = []\nname_dict = dict()\n+ gameInputPacket.iNumPlayers = num_bots\n+\n# Set configuration values for bots and store name and team\nfor i in range(num_bots):\nbot_config = configparser.RawConfigParser()\n",
        "chatgpt_cot": "Add condition to handle None value for lan_port in run_ladder_game function in __init__.py to prevent potential errors."
    },
    {
        "org_diff": "diff --git a/README.md b/README.md @@ -14,6 +14,12 @@ To install the SDK run\npip install rasa_core_sdk\n```\n+## Compatibility\n+\n+| SDK version | compatible Rasa Core version |\n+|---------------|----------------------------------------|\n+| `0.11.x` | `>=0.11.x` |\n+\n## Usage\nDetailed instructions can be found in the Rasa Core Documentation about\n",
        "org_msg": "added compatibility information",
        "sim_msg": "Improve grammar readme",
        "sim_diff": "diff --git a/README.md b/README.md @@ -208,7 +208,7 @@ In order to install all libraries used by this repository, you must run\n```\npip install -r requirements.txt\n```\n-Note: The libraries specified in the [requirements.txt](/requirements.txt) file have been tested and work for the purpose of this project, however, these may be older versions. Hence, it is recommended for the user to set up a virtual python environment previous to install these. This allows to keep dependencies required by different projects in separate places.\n+Note: The libraries specified in the [requirements.txt](/requirements.txt) file have been tested and work for the purpose of this project, however, these may be older versions. Hence, it is recommended for the user to set up a virtual python environment prior to installing these. This allows to keep dependencies required by different projects in separate places.\n## API Keys <a name=\"API_Keys\"></a>\n",
        "chatgpt_cot": "Add compatibility table for SDK and Rasa Core versions."
    },
    {
        "org_diff": "diff --git a/README.md b/README.md @@ -93,11 +93,13 @@ You can find your Windows IP using `ipconfig /all` from `PowerShell.exe` or `CMD\nAs promised, worker rush in less than twenty lines:\n```python\n-import sc2\n-from sc2 import run_game, maps, Race, Difficulty\n+from sc2 import maps\nfrom sc2.player import Bot, Computer\n+from sc2.main import run_game\n+from sc2.data import Race, Difficulty\n+from sc2.bot_ai import BotAI\n-class WorkerRushBot(sc2.BotAI):\n+class WorkerRushBot(BotAI):\nasync def on_step(self, iteration: int):\nif iteration == 0:\nfor worker in self.workers:\n",
        "org_msg": "Fixed the WorkerRushBot example in README\nThe original code that was published as an example for the ```WorkerRushBot``` did not execute properly.",
        "sim_msg": "Forgot to update iNumPlayers",
        "sim_diff": "diff --git a/v3/runner.py b/v3/runner.py @@ -63,6 +63,8 @@ if __name__ == '__main__':\ncallbacks = []\nname_dict = dict()\n+ gameInputPacket.iNumPlayers = num_bots\n+\n# Set configuration values for bots and store name and team\nfor i in range(num_bots):\nbot_config = configparser.RawConfigParser()\n",
        "chatgpt_cot": "\"Fix compilation issue in README.md by importing necessary modules and correcting class name to BotAI.\""
    },
    {
        "org_diff": "diff --git a/sc2/bot_ai.py b/sc2/bot_ai.py @@ -7,7 +7,15 @@ from collections import Counter\nfrom typing import Any, Dict, List, Optional, Set, Tuple, Union, TYPE_CHECKING\nfrom .cache import property_cache_forever, property_cache_once_per_frame\n-from .constants import FakeEffectID, abilityid_to_unittypeid, geyser_ids, mineral_ids\n+from .constants import (\n+ FakeEffectID,\n+ abilityid_to_unittypeid,\n+ geyser_ids,\n+ mineral_ids,\n+ TERRAN_TECH_REQUIREMENT,\n+ PROTOSS_TECH_REQUIREMENT,\n+ ZERG_TECH_REQUIREMENT,\n+)\nfrom .data import ActionResult, Alert, Race, Result, Target, race_gas, race_townhalls, race_worker\nfrom .distances import DistanceCalculation\nfrom .game_data import AbilityData, GameData\n@@ -869,10 +877,14 @@ class BotAI(DistanceCalculation):\n:param structure_type:\n\"\"\"\n+ assert isinstance(\n+ structure_type, (int, UnitTypeId)\n+ ), f\"Needs to be int or UnitTypeId, but was: {type(structure_type)}\"\nif isinstance(structure_type, int):\nstructure_type_value = structure_type\nelse:\nstructure_type_value = structure_type.value\n+ assert structure_type_value, f\"structure_type can not be 0 or NOTAUNIT, but was: {structure_type_value}\"\nreturn_value = 0\nfor structure in self.structures:\n@@ -901,8 +913,15 @@ class BotAI(DistanceCalculation):\nprint(tech_requirement) # Prints 1 because even though the type id of the flying factory is different, it still has build progress of 1 and thus tech requirement is completed\n:param structure_type: \"\"\"\n- unit_info_id_value = self._game_data.units[structure_type.value]._proto.tech_requirement\n- if not unit_info_id_value:\n+ race_dict = {\n+ Race.Protoss: PROTOSS_TECH_REQUIREMENT,\n+ Race.Terran: TERRAN_TECH_REQUIREMENT,\n+ Race.Zerg: ZERG_TECH_REQUIREMENT,\n+ }\n+ unit_info_id_value = race_dict[self.race][structure_type].value\n+ # The following line is unrelaible for ghost / thor as they return 0 which is incorrect\n+ # unit_info_id_value = self._game_data.units[structure_type.value]._proto.tech_requirement\n+ if not unit_info_id_value: # Equivalent to \"if unit_info_id_value == 0:\"\nreturn 1\nreturn self.structure_type_build_progress(unit_info_id_value)\n@@ -934,7 +953,6 @@ class BotAI(DistanceCalculation):\nreturn False\nresearch_structure_types: UnitTypeId = UPGRADE_RESEARCHED_FROM[upgrade_type]\n- # Convert to a set\n# research_ability: AbilityId = RESEARCH_INFO[research_structure_types][upgrade_type][\"ability\"]\nrequired_tech_building: Optional[UnitTypeId] = RESEARCH_INFO[research_structure_types][upgrade_type].get(\n\"required_building\", None\n@@ -953,6 +971,8 @@ class BotAI(DistanceCalculation):\nUnitTypeId.GREATERSPIRE: {UnitTypeId.SPIRE, UnitTypeId.GREATERSPIRE},\nUnitTypeId.HIVE: {UnitTypeId.HATCHERY, UnitTypeId.LAIR, UnitTypeId.HIVE},\n}\n+ # Convert to a set, or equivalent structures are chosen\n+ # Overlord speed upgrade can be researched from hatchery, lair or hive\nresearch_structure_types: Set[UnitTypeId] = equiv_structures.get(\nresearch_structure_types, {research_structure_types}\n)\n",
        "org_msg": "Make use of tech requirement from constants.py in bot_ai train function",
        "sim_msg": "[Hockey] Fix issue where sometimes a game will show incorrect standings data on previews",
        "sim_diff": "diff --git a/hockey/game.py b/hockey/game.py from __future__ import annotations\n+\nimport logging\nfrom datetime import datetime\n-from typing import Literal, Optional, List, Dict, Union, Tuple\n+from typing import Dict, List, Literal, Optional, Tuple, Union\nimport aiohttp\nimport discord\n@@ -12,7 +13,13 @@ from redbot.core.utils import AsyncIter, bounded_gather\nfrom .constants import BASE_URL, CONTENT_URL, TEAMS\nfrom .goal import Goal\n-from .helper import check_to_post, get_channel_obj, get_team, get_team_role, utc_to_local\n+from .helper import (\n+ check_to_post,\n+ get_channel_obj,\n+ get_team,\n+ get_team_role,\n+ utc_to_local,\n+)\nfrom .standings import Standings\n_ = Translator(\"Hockey\", __file__)\n@@ -423,7 +430,10 @@ class Game:\nstats, home_i = await Standings.get_team_standings(self.home_team)\nfor team in stats:\nif team.name == self.away_team:\n+ try:\nstreak = \"{} {}\".format(team.streak, streak_types[team.streak_type])\n+ except KeyError:\n+ streak = \"**0**\"\naway_str = msg.format(\nwins=team.wins,\nlosses=team.losses,\n@@ -433,7 +443,10 @@ class Game:\nstreak=streak,\n)\nif team.name == self.home_team:\n+ try:\nstreak = \"{} {}\".format(team.streak, streak_types[team.streak_type])\n+ except KeyError:\n+ streak = \"**0**\"\nhome_str = msg.format(\nwins=team.wins,\nlosses=team.losses,\n@@ -443,6 +456,7 @@ class Game:\nstreak=streak,\n)\nexcept Exception:\n+ log.exception(\"Error pulling stats\")\npass\nreturn home_str, away_str\n",
        "chatgpt_cot": "\"Add assertions for structure_type and race_dict, and fix tech_requirement bug in BotAI file.\""
    },
    {
        "org_diff": "diff --git a/sc2/bot_ai.py b/sc2/bot_ai.py @@ -1584,7 +1584,7 @@ class BotAI(DistanceCalculation):\npos = pos.position.rounded\nreturn self._game_info.terrain_height[pos]\n- def get_terrain_z_height(self, pos: Union[Point2, Unit]) -> int:\n+ def get_terrain_z_height(self, pos: Union[Point2, Unit]) -> float:\n\"\"\"Returns terrain z-height at a position.\n:param pos:\"\"\"\n",
        "org_msg": "Fix type hint for 'get_terrain_z_height'",
        "sim_msg": "Changed applicable types to float and str",
        "sim_diff": "diff --git a/src/astral/__init__.py b/src/astral/__init__.py @@ -70,7 +70,7 @@ import re\nfrom dataclasses import dataclass\nfrom enum import Enum\nfrom math import fabs\n-from typing import Any\n+from typing import Any, Union\ntry:\nimport pytz\n@@ -167,11 +167,11 @@ class Observer:\nlongitude: float = -0.00088\nelevation: float = 24.0\n- def __setattr__(self, name: str, value: Any):\n+ def __setattr__(self, name: str, value: Union[float, str]):\nif name == \"latitude\":\n- value = latlng_to_float(value, 90)\n+ value = latlng_to_float(value, 90.0)\nelif name == \"longitude\":\n- value = latlng_to_float(value, 180)\n+ value = latlng_to_float(value, 180.0)\nelif name == \"elevation\":\nvalue = float(value)\nsuper(Observer, self).__setattr__(name, value)\n@@ -209,11 +209,11 @@ class LocationInfo:\nlongitude: float = -0.00088\nelevation: float = 24.0\n- def __setattr__(self, name: str, value: Any):\n+ def __setattr__(self, name: str, value: Union[float, str]):\nif name == \"latitude\":\n- value = latlng_to_float(value, 90)\n+ value = latlng_to_float(value, 90.0)\nelif name == \"longitude\":\n- value = latlng_to_float(value, 180)\n+ value = latlng_to_float(value, 180.0)\nelif name == \"elevation\":\nvalue = float(value)\nsuper(LocationInfo, self).__setattr__(name, value)\n",
        "chatgpt_cot": "Update return type of get_terrain_z_height method to float for more accurate terrain z-height calculation."
    },
    {
        "org_diff": "diff --git a/src/agent/ansible/roles/env_flanneld/networksetup/tasks/apply.yml b/src/agent/ansible/roles/env_flanneld/networksetup/tasks/apply.yml dest: \"/lib/systemd/system/flanneld.service\"\nmode: 0644\n+- name: Change IP Forwarding\n+ command: iptables -P FORWARD ACCEPT\n+\n- name: Reload services\ncommand: systemctl daemon-reload\n",
        "org_msg": "Fix the ip forwarding issue\nnewer docker version stops iptable forwarding so that\ntraffic from outside the host machine can not pass through\nthis creates problems when we need to allow the traffic.\nthis patch set will fix that problem.",
        "sim_msg": "Use state \"present\" instead of \"installed\"\nThe latter is deprecated and due to be removed in Ansible v2.9.",
        "sim_diff": "diff --git a/ansible/roles/setup/tasks/main.yml b/ansible/roles/setup/tasks/main.yml become: yes\napt:\npkg: apt-transport-https\n- state: installed\n+ state: present\n- name: Add NodeSource apt signing key\nbecome: yes\nbecome: yes\napt:\npkg: \"{{ item }}\"\n- state: installed\n+ state: present\nwith_items:\n- apt-transport-https\n- ca-certificates\nbecome: yes\napt:\npkg: \"{{item}}\"\n- state: installed\n+ state: present\nwith_items:\n- nodejs\nbecome: yes\napt:\npkg: \"{{ item }}\"\n- state: installed\n+ state: present\nwith_items:\n- postgresql-9.5-postgis-2.2\n- postgresql-server-dev-9.5 # required for building pyscopg against correct postgres\n",
        "chatgpt_cot": "Add IP forwarding configuration and reload services in flanneld network setup."
    },
    {
        "org_diff": "diff --git a/examples/protoss/cannon_rush.py b/examples/protoss/cannon_rush.py @@ -20,7 +20,7 @@ class CannonRushBot(sc2.BotAI):\nnexus = self.townhalls.random\n# Make probes until we have 16 total\n- if self.workers.amount < 16 and nexus.is_idle:\n+ if self.supply_workers < 16 and nexus.is_idle:\nif self.can_afford(PROBE):\nself.do(nexus.train(PROBE), subtract_cost=True, subtract_supply=True)\n",
        "org_msg": "use precalculated number",
        "sim_msg": "increase jumbo limit temp",
        "sim_diff": "diff --git a/GearBot/Util/JumboGenerator.py b/GearBot/Util/JumboGenerator.py import asyncio\n-import math\nimport os\nimport re\nimport aiohttp\nimport discord\n+import math\nfrom PIL import Image\nfrom Util import MessageUtils\n@@ -192,8 +192,8 @@ class JumboGenerator:\nasync def generate(self):\ntry:\n- await asyncio.wait_for(self.prep(), timeout=20)\n- await asyncio.wait_for(self.build(), timeout=60)\n+ await asyncio.wait_for(self.prep(), timeout=200)\n+ await asyncio.wait_for(self.build(), timeout=600)\nexcept asyncio.TimeoutError:\nawait MessageUtils.send_to(self.ctx, \"WHAT\", 'jumbo_timeout')\nelse:\n",
        "chatgpt_cot": "Update condition to check supply_workers instead of workers amount in CannonRushBot for probe training."
    },
    {
        "org_diff": "diff --git a/src/api-engine/api/lib/agent/docker/handler.py b/src/api-engine/api/lib/agent/docker/handler.py @@ -42,7 +42,7 @@ class DockerAgent(AgentBase):\n'img': 'yeasy/hyperledger-fabric:2.2.0',\n'cmd': 'bash /tmp/init.sh \"peer node start\"' if info.get(\"type\") == \"peer\" else 'bash /tmp/init.sh \"orderer\"',\n'name': 'cello-hlf-{}-{}'.format(info.get(\"type\"), info.get(\"name\")),\n- 'port_map': str(info.get(\"ports\").__repr__()),\n+ 'port_map': info.get(\"ports\").__repr__(),\n'action': 'create'\n}\n",
        "org_msg": "Removed unnecessary type converting for port mapping data.",
        "sim_msg": "Use GENESIS_FILE when running the agent locally",
        "sim_diff": "diff --git a/demo/runners/support/agent.py b/demo/runners/support/agent.py @@ -33,6 +33,7 @@ RUN_MODE = os.getenv(\"RUNMODE\")\nGENESIS_URL = os.getenv(\"GENESIS_URL\")\nLEDGER_URL = os.getenv(\"LEDGER_URL\")\n+GENESIS_FILE = os.getenv(\"GENESIS_FILE\")\nif RUN_MODE == \"docker\":\nDEFAULT_INTERNAL_HOST = os.getenv(\"DOCKERHOST\") or \"host.docker.internal\"\n@@ -59,6 +60,9 @@ async def default_genesis_txns():\nf\"http://{DEFAULT_EXTERNAL_HOST}:9000/genesis\"\n) as resp:\ngenesis = await resp.text()\n+ elif GENESIS_FILE:\n+ with open(GENESIS_FILE, \"r\") as genesis_file:\n+ genesis = genesis_file.read()\nelse:\nwith open(\"local-genesis.txt\", \"r\") as genesis_file:\ngenesis = genesis_file.read()\n",
        "chatgpt_cot": "\"Refactor port_map attribute to remove unnecessary string conversion in DockerAgent class\""
    },
    {
        "org_diff": "diff --git a/fkie_multimaster/package.xml b/fkie_multimaster/package.xml -<package>\n+<package format=\"2\">\n<name>fkie_multimaster</name>\n+ <replace>multimaster_fkie</replace>\n<description>\nThe metapackage to combine the nodes required to establish and manage a multimaster network.\nThis requires no or minimal configuration. The changes are automatically detected and synchronized.\n<buildtool_depend>catkin</buildtool_depend>\n- <run_depend>fkie_multimaster_msgs</run_depend>\n- <run_depend>fkie_master_discovery</run_depend>\n- <run_depend>fkie_master_sync</run_depend>\n- <run_depend>fkie_node_manager</run_depend>\n- <run_depend>fkie_node_manager_daemon</run_depend>\n+ <exec_depend>fkie_multimaster_msgs</exec_depend>\n+ <exec_depend>fkie_master_discovery</exec_depend>\n+ <exec_depend>fkie_master_sync</exec_depend>\n+ <exec_depend>fkie_node_manager</exec_depend>\n+ <exec_depend>fkie_node_manager_daemon</exec_depend>\n<export>\n<metapackage/>\n",
        "org_msg": "Migrate package to format 2",
        "sim_msg": "Update README\nProblem: After recent update README has some amount on nonsense.\nSolution: Rereade it and update.",
        "sim_diff": "diff --git a/README.md b/README.md @@ -40,13 +40,12 @@ see [PPA](#ppa) and [Copr](#copr) for more information about remote package repo\nContents of release:\n* `tezos-*-005-PsBabyM1` static binaries for 005 protocol.\n* `tezos-*-006-PsCARTHA` static binaries for 006 protocol.\n-* `packages-deb.tar.gz` `.deb` packages for both mainnet and babylonnet versions,\n+* `packages-deb.tar.gz` `.deb` packages with binaries built from master branch sources,\nit is recommended to use `apt` to install packages directly from remote repository.\n-* `packages-rpm.tar.gz` `.rpm` packages for both mainnet and babylonnet versions,\n+* `packages-rpm.tar.gz` `.rpm` packages with binaries built from master branch sources,\nit is recommended to use `dnf` to install packages directly from remote repository.\n* `binaries-<revision>.tar.gz` archive with all binaries made from\nparticular master branch revision.\n-binaries made from particular branch revision.\n* License file from [tezos repository](https://gitlab.com/tezos/tezos/).\n## Ubuntu (Debian based distros) usage\n@@ -55,11 +54,13 @@ binaries made from particular branch revision.\n### Use PPA with `tezos-*` binaries\nIf you are using Ubuntu you can use PPA in order to install `tezos-*` executables.\n-E.g, in order to do install `tezos-client` run the following commands:\n+E.g, in order to do install `tezos-client` or `tezos-baker` run the following commands:\n```\nsudo add-apt-repository ppa:serokell/tezos && sudo apt-get update\nsudo apt-get install tezos-client\n-sudo apt-get install tezos-baker-005-PsBabyM1\n+# dpkg-source prohibits uppercase in the packages names so the protocol\n+# name is in lowercase\n+sudo apt-get install tezos-baker-005-psbabym1\n```\nOnce you install such packages the commands `tezos-*` will be available.\n@@ -78,7 +79,7 @@ sudo apt install <path to deb file>\nIf you are using Fedora you can use Copr in order to install `tezos-*`\nexecutables.\n-E.g. in order to install `tezos-client` run the following commands:\n+E.g. in order to install `tezos-client` or `tezos-baker` run the following commands:\n```\n# use dnf\nsudo dnf copr enable @Serokell/Tezos\n",
        "chatgpt_cot": "Update package.xml format and dependencies to use exec_depend instead of run_depend for fkie_multimaster package."
    },
    {
        "org_diff": "diff --git a/sc2/game_info.py b/sc2/game_info.py @@ -35,11 +35,21 @@ class Ramp:\ndef points(self) -> Set[Point2]:\nreturn self._points.copy()\n- @property\n+ @property_mutable_cache\ndef upper(self) -> Set[Point2]:\n\"\"\" Returns the upper points of a ramp. \"\"\"\n- max_height = max(self.height_at(p) for p in self._points)\n- return {p for p in self._points if self.height_at(p) == max_height}\n+ current_max = -10000\n+ result = set()\n+ for p in self._points:\n+ height = self.height_at(p)\n+ if height < current_max:\n+ continue\n+ elif height == current_max:\n+ result.add(p)\n+ else:\n+ current_max = height\n+ result = {p}\n+ return result\n@property_mutable_cache\ndef upper2_for_ramp_wall(self) -> Set[Point2]:\n@@ -61,8 +71,18 @@ class Ramp:\n@property_mutable_cache\ndef lower(self) -> Set[Point2]:\n- min_height = min(self.height_at(p) for p in self._points)\n- return {p for p in self._points if self.height_at(p) == min_height}\n+ current_min = 10000\n+ result = set()\n+ for p in self._points:\n+ height = self.height_at(p)\n+ if height > current_min:\n+ continue\n+ elif height == current_min:\n+ result.add(p)\n+ else:\n+ current_min = height\n+ result = {p}\n+ return result\n@property_immutable_cache\ndef bottom_center(self) -> Point2:\n",
        "org_msg": "Improve upper and lower in Ramp",
        "sim_msg": "Fixed an oopsie I made",
        "sim_diff": "diff --git a/game_data_struct.py b/game_data_struct.py @@ -227,10 +227,10 @@ def rotate_game_tick_packet_boost_omitted(game_tick_packet):\ngame_tick_packet.gameball.Acceleration.Y = -1 * game_tick_packet.gameball.Acceleration.Y\n# ball touch data\n- game_tick_packet.gameball.Touch.sHitLocation.X = -1 * game_tick_packet.gameball.Touch.sHitLocation.X\n- game_tick_packet.gameball.Touch.sHitLocation.Y = -1 * game_tick_packet.gameball.Touch.sHitLocation.Y\n- game_tick_packet.gameball.Touch.sHitNormal.X = -1 * game_tick_packet.gameball.Touch.sHitNormal.X\n- game_tick_packet.gameball.Touch.sHitNormal.Y = -1 * game_tick_packet.gameball.Touch.sHitNormal.Y\n+ game_tick_packet.gameball.LatestTouch.sHitLocation.X = -1 * game_tick_packet.gameball.LatestTouch.sHitLocation.X\n+ game_tick_packet.gameball.LatestTouch.sHitLocation.Y = -1 * game_tick_packet.gameball.LatestTouch.sHitLocation.Y\n+ game_tick_packet.gameball.LatestTouch.sHitNormal.X = -1 * game_tick_packet.gameball.LatestTouch.sHitNormal.X\n+ game_tick_packet.gameball.LatestTouch.sHitNormal.Y = -1 * game_tick_packet.gameball.LatestTouch.sHitNormal.Y\n# Rotate Yaw 180 degrees is all that is necessary.\nball_yaw = game_tick_packet.gameball.Rotation.Yaw\n",
        "chatgpt_cot": "\"Fix compilation issue due to modified method in game_info.py\""
    },
    {
        "org_diff": "diff --git a/node_manager_daemon_fkie/src/node_manager_daemon_fkie/common.py b/node_manager_daemon_fkie/src/node_manager_daemon_fkie/common.py @@ -242,7 +242,16 @@ def replace_internal_args(content, resolve_args={}, path=None):\nreturn replaced, new_content, resolve_args_intern\n-def __get_include_args(content):\n+def replace_arg(self, value, resolve_args):\n+ # test for if statement\n+ re_if = re.compile(r\"\\$\\(arg.(?P<name>.*?)\\)\")\n+ for arg in re_if.findall(value):\n+ if arg in resolve_args:\n+ return value.replace('$(arg %s)' % arg, resolve_args[arg])\n+ return value\n+\n+\n+def __get_include_args(content, resolve_args):\nincluded_files = []\ntry:\nxml_nodes = minidom.parseString(content).getElementsByTagName('include')\n@@ -259,13 +268,20 @@ def __get_include_args(content):\nif inc_arg.nodeType == node.ELEMENT_NODE and inc_arg.hasAttributes():\naname = ''\naval = ''\n+ skip = False\nfor argi in range(inc_arg.attributes.length):\narg_attr = inc_arg.attributes.item(argi)\nif arg_attr.localName == 'name':\naname = arg_attr.value\nelif arg_attr.localName in ['value', 'default']:\naval = arg_attr.value\n- if aname:\n+ elif arg_attr.localName == 'if':\n+ val = replace_arg(arg_attr.value, resolve_args)\n+ skip = val in ['false', '0']\n+ elif arg_attr.localName == 'unless':\n+ val = replace_arg(arg_attr.value, resolve_args)\n+ skip = val in ['true', '1']\n+ if aname and not skip:\nresolved_inc_args[aname] = aval\nif filename:\nincluded_files.append((filename, resolved_inc_args))\n@@ -318,7 +334,7 @@ def included_files(string,\n# replace the arguments and detect arguments for include-statements\nif (string.endswith(\".launch\")):\n_replaced, content, _resolve_args_intern = replace_internal_args(content, path=string)\n- inc_files_forward_args = __get_include_args(content)\n+ inc_files_forward_args = __get_include_args(content, resolve_args)\nmy_unique_files = unique_files\nif not unique_files:\nmy_unique_files = list()\n",
        "org_msg": "node_manager_daemon_fkie: check for if, unless for include arguments",
        "sim_msg": "Add -imacros files to forcedInclude field in VSCode template",
        "sim_diff": "diff --git a/platformio/ide/tpls/vscode/.vscode/c_cpp_properties.json.tpl b/platformio/ide/tpls/vscode/.vscode/c_cpp_properties.json.tpl %\n% def _find_forced_includes(flags, inc_paths):\n% result = []\n+% include_args = (\"-include\", \"-imacros\")\n% for f in flags:\n+% if not f.startswith(include_args):\n+% continue\n+% end\n+% for arg in include_args:\n% inc = \"\"\n-% if f.startswith(\"-include\") and f.split(\"-include\")[1].strip():\n-% inc = f.split(\"-include\")[1].strip()\n+% if f.startswith(arg) and f.split(arg)[1].strip():\n+% inc = f.split(arg)[1].strip()\n% elif not f.startswith(\"-\"):\n% inc = f\n% end\n% result.append(_find_abs_path(inc, inc_paths))\n% end\n% end\n+% end\n% return result\n% end\n%\n% cxx_stds = STD_RE.findall(cxx_flags)\n% cc_m_flags = split_args(cc_flags)\n% forced_includes = _find_forced_includes(\n-% filter_args(cc_m_flags, [\"-include\"]), cleaned_includes)\n+% filter_args(cc_m_flags, [\"-include\", \"-imacros\"]), cleaned_includes)\n%\n{\n\"configurations\": [\n\"compilerArgs\": [\n% for flag in [\n% '\"%s\"' % _escape(f) if _escape_required(f) else f\n-% for f in filter_args(cc_m_flags, [\"-m\", \"-i\", \"@\"], [\"-include\"])\n+% for f in filter_args(cc_m_flags, [\"-m\", \"-i\", \"@\"], [\"-include\", \"-imacros\"])\n% ]:\n\"{{ flag }}\",\n% end\n",
        "chatgpt_cot": "Add method to replace arguments in include statements, handle conditional logic for include attributes, and improve argument resolution in the file \"common.py\"."
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/CMakeLists.txt b/node_manager_fkie/CMakeLists.txt @@ -33,6 +33,7 @@ install(\ninstall(\nFILES\n+ ./src/node_manager_fkie/EchoDialog.ui\n./src/node_manager_fkie/MasterTab.ui\n./src/node_manager_fkie/LaunchFilesDockWidget.ui\n./src/node_manager_fkie/LogDockWidget.ui\n@@ -40,6 +41,7 @@ install(\n./src/node_manager_fkie/ProfileWidget.ui\n./src/node_manager_fkie/MainWindow.ui\n./src/node_manager_fkie/SettingsDockWidget.ui\n+ ./src/node_manager_fkie/TimeInput.ui\n./src/node_manager_fkie/GUI.qrc\nDESTINATION ${CATKIN_PACKAGE_PYTHON_DESTINATION}\n)\n",
        "org_msg": "fixed install, see issue",
        "sim_msg": "Change variables so PyInstaller finds GLib schemas",
        "sim_diff": "diff --git a/_packaging/appimage/Dockerfile b/_packaging/appimage/Dockerfile @@ -127,8 +127,7 @@ ENV CHECKOUT=/root/jhbuild/checkout \\\nLD_LIBRARY_PATH=\"/root/jhbuild/install/lib\" \\\nPKG_CONFIG_PATH=\"/root/jhbuild/install/lib/pkgconfig\" \\\nPATH=\"/root/jhbuild/install/bin:/root/.local/bin:/root/.cargo/bin:$PATH\" \\\n- JHBUILD_RUN_AS_ROOT=\"\" \\\n- GSETTINGS_SCHEMA_DIR=\"/root/jhbuild/install/share/glib-2.0/schemas\"\n+ JHBUILD_RUN_AS_ROOT=\"\"\n# Install jhbuild\nRUN mkdir -p $CHECKOUT \\\n@@ -149,3 +148,5 @@ RUN jhbuild build \\\n&& rm -r /root/.config \\\n&& rm -r /root/.cache\n+# Environmental variable needed to run GTK for gsettings schema\n+ENV XDG_DATA_DIRS=\"/root/jhbuild/install/share\"\n",
        "chatgpt_cot": "Add TimeInput.ui to the installation in CMakeLists.txt. This modification includes adding the TimeInput.ui file to the installation, expanding the functionality of the node manager."
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/editor/text_search_thread.py b/node_manager_fkie/src/node_manager_fkie/editor/text_search_thread.py @@ -255,7 +255,7 @@ class TextSearchThread(QObject, threading.Thread):\nrname = aname\nfor arg_key, args_val in resolve_args.items():\nrname = rname.replace('$(arg %s)' % arg_key, args_val)\n- if aname == node_name:\n+ if rname == node_name:\nyield aname, rname, groups.span(\"name\")\ndef _check_node_conditions(self, launch_node, node_name, node_idx, resolve_args, path):\n",
        "org_msg": "node_manager_fkie: fixed search for node with arg in name",
        "sim_msg": "Avoid loop in doctest\nThis makes it fail on Travis-CI",
        "sim_diff": "diff --git a/gaphor/misc/gidlethread.py b/gaphor/misc/gidlethread.py @@ -44,8 +44,9 @@ class GIdleThread(object):\n>>> t = GIdleThread(counter(123))\n>>> id = t.start()\n>>> main = GLib.main_context_default()\n- >>> while t.is_alive():\n- ... main.iteration(False) # doctest: +ELLIPSIS\n+ >>> t.is_alive()\n+ True\n+ >>> main.iteration(False) # doctest: +ELLIPSIS\nTrue\n\"\"\"\n",
        "chatgpt_cot": "Fix variable name in TextSearchThread to properly compare with node_name."
    },
    {
        "org_diff": "diff --git a/user-dashboard/package.json b/user-dashboard/package.json \"babel-preset-stage-0\": \"^6.5.0\",\n\"babel-plugin-transform-runtime\": \"^6.0.0\",\n\"eslint\": \"^3.1.1\",\n+ \"pm2\": \"^2.9.1\",\n\"nodemon\": \"^1.12.1\"\n},\n\"scripts\": {\n- \"start\": \"node dist\",\n+ \"start\": \"pm2 start dist/index.js -i max\",\n\"build\": \"babel src -s --ignore src/public -D -d dist && cp -r src/public dist/\",\n- \"dev\": \"nodemon src/index.js --exec \\\"babel-node src\\\"\",\n+ \"dev\": \"pm2 --interpreter babel-node start src/index.js --no-daemon --watch\",\n\"test\": \"echo \\\"Error: no test specified\\\" && exit 1\"\n},\n\"author\": \"hightall\",\n",
        "org_msg": "Change to pm2 for start express service",
        "sim_msg": "Removed old build steps and replaced with new ones",
        "sim_diff": "diff --git a/package.json b/package.json },\n\"main\": \"src/index.js\",\n\"scripts\": {\n- \"build-dev\": \"builder run clean-lib && builder run extract-metadata && builder run generate-python-classes && webpack -w --config=./config/webpack/webpack.config.dev.js\",\n- \"build-dist\": \"builder run clean-lib && builder run extract-metadata && builder run generate-python-classes && cross-env NODE_ENV=production webpack --config=./config/webpack/webpack.config.dist.js\",\n- \"copy-lib\": \"cp -f lib/* dash_core_components\",\n\"generate-python-classes\": \"python -c \\\"import dash; dash.development.component_loader.generate_classes('dash_core_components', 'dash_core_components/metadata.json');\\\"\",\n\"install-local\": \"npm run copy-lib && python setup.py install\",\n- \"prepublish\": \"npm test && builder run build-dist && npm run copy-lib\",\n+ \"prepublish\": \"npm test && npm run build:js && npm run build:py\",\n\"publish-all\": \"npm publish && python setup.py sdist upload\",\n\"publish-pypi\": \"npm run prepublish && python setup.py sdist && twine upload --sign --skip-existing\",\n\"start\": \"./node_modules/.bin/builder run build-dev\",\n- \"test\": \"eslint src\",\n+ \"lint\": \"eslint src\",\n\"test-watch\": \"./node_modules/.bin/builder run test-frontend-watch\",\n\"test-debug\": \"./node_modules/.bin/builder run test-frontend-debug\",\n\"uninstall-local\": \"pip uninstall dash-core-components -y\",\n",
        "chatgpt_cot": "\"Add pm2 for process management and update start and dev scripts to use pm2 for user-dashboard\""
    },
    {
        "org_diff": "diff --git a/fkie_node_manager/src/fkie_node_manager/node_tree_model.py b/fkie_node_manager/src/fkie_node_manager/node_tree_model.py @@ -682,8 +682,6 @@ class GroupItem(QStandardItem):\nhas_off = True\nelif item.state == NodeItem.STATE_RUN:\nhas_running = True\n- if item.diagnostic_level > self.diagnostic_level:\n- self.diagnostic_level = item.diagnostic_level\nelif item.state == NodeItem.STATE_GHOST:\nhas_ghosts = True\nelif item.state == NodeItem.STATE_DUPLICATE:\n@@ -691,6 +689,9 @@ class GroupItem(QStandardItem):\nelif item.state == NodeItem.STATE_PARTS:\nhas_running = True\nhas_off = True\n+ if item.state == NodeItem.STATE_RUN or isinstance(item, GroupItem):\n+ if item.diagnostic_level > self.diagnostic_level:\n+ self.diagnostic_level = item.diagnostic_level\ndiag_icon = None\nif self.diagnostic_level > 0:\ndiag_icon = NodeItem._diagnostic_level2icon(self.diagnostic_level)\n",
        "org_msg": "fkie_node_manager: fixed propagation of node states to parent groups",
        "sim_msg": "Dimming item node name's color",
        "sim_diff": "diff --git a/avalon/tools/cbsceneinventory/model.py b/avalon/tools/cbsceneinventory/model.py @@ -73,6 +73,9 @@ class InventoryModel(TreeModel):\nreturn self.GRAYOUT_COLOR\n+ if key == \"name\" and not node.get(\"isGroupNode\"):\n+ return self.GRAYOUT_COLOR\n+\n# Add icons\nif role == QtCore.Qt.DecorationRole:\nif index.column() == 0:\n",
        "chatgpt_cot": "\"Refactor diagnostic level comparison in GroupItem class to handle different node states and group items.\""
    },
    {
        "org_diff": "diff --git a/src/api-engine/api/lib/peer/chaincode.py b/src/api-engine/api/lib/peer/chaincode.py @@ -334,3 +334,34 @@ class ChainCode(BasicEnv):\nexcept Exception as e:\nerr_msg = \"invoke failed for {}!\".format(e)\nraise Exception(err_msg)\n+\n+ def query(self, orderer_url, orderer_tls_rootcert, channel_name, cc_name, args):\n+ try:\n+ if os.getenv(\"CORE_PEER_TLS_ENABLED\") == \"false\" or os.getenv(\"CORE_PEER_TLS_ENABLED\") is None:\n+ res = subprocess.Popen(\"./../bin/{}/bin/peer chaincode query -o {} --channelID {} --name {} -c '{}'\"\n+ .format(self.version, orderer_url, channel_name, cc_name, args),\n+ shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n+ stdout, stderr = res.communicate()\n+ return_code = res.returncode\n+ if return_code == 0:\n+ return return_code, ''\n+ else:\n+ stderr = str(stderr, encoding=\"utf-8\")\n+ return return_code, stderr\n+ else:\n+ res = subprocess.Popen(\"./../bin/{}/bin/peer chaincode query -o {} --tls --cafile {} --channelID {}\"\n+ \" --name {} -c '{}'\".format(self.version, orderer_url, orderer_tls_rootcert,\n+ channel_name, cc_name, args),\n+ shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n+ stdout, stderr = res.communicate()\n+ return_code = res.returncode\n+ if return_code == 0:\n+ content = str(stdout, encoding=\"utf-8\")\n+ query_result = json.loads(content)\n+ return return_code, query_result\n+ else:\n+ stderr = str(stderr, encoding=\"utf-8\")\n+ return return_code, stderr\n+ except Exception as e:\n+ err_msg = \"query failed for {}!\".format(e)\n+ raise Exception(err_msg)\n",
        "org_msg": "[#issue-332] add query function\nimplement of lifecycle_query_committed && invoke function\nClose #issue-332",
        "sim_msg": "add error output message and fix nnp-scaling/nnp-train",
        "sim_diff": "diff --git a/maml/apps/pes/_nnp.py b/maml/apps/pes/_nnp.py @@ -642,22 +642,33 @@ class NNPotential(Potential):\noutput = 'training_output'\ninput_filename = self.write_input(**kwargs)\n- p_scaling = subprocess.Popen(['nnp-scaling', input_filename])\n- stdout = p_scaling.communicate()[0]\n-\n- p_train = subprocess.Popen(['nnp-train', input_filename],\n- stdout=open(output, 'w'))\n- stdout = p_train.communicate()[0]\n+ p_scaling = subprocess.Popen(['nnp-scaling', '100'],\n+ stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n+ stdout, stderr = p_scaling.communicate()\n+ rc = p_scaling.returncode\n+ if rc != 0:\n+ error_msg = 'n2p2 exited with return code %d' % rc\n+ msg = stderr.decode(\"utf-8\").split('\\n')[:-1]\n+ try:\n+ error_line = [i for i, m in enumerate(msg) if m.startswith('ERROR')][0]\n+ error_msg += ', '.join(msg[error_line:])\n+ except Exception:\n+ error_msg += ', '\n+ error_msg += msg[-1]\n+ raise RuntimeError(error_msg)\n+ p_train = subprocess.Popen(['nnp-train'],\n+ stdout=open(output, 'w'), stderr=subprocess.PIPE)\n+ stdout, stderr = p_train.communicate()\nrc = p_train.returncode\nif rc != 0:\nerror_msg = 'n2p2 exited with return code %d' % rc\n- msg = stdout.decode(\"utf-8\").split('\\n')[:-1]\n+ msg = stderr.decode(\"utf-8\").split('\\n')[:-1]\ntry:\n- error_line = [i for i, m in enumerate(msg)\n- if m.startswith('ERROR')][0]\n+ error_line = [i for i, m in enumerate(msg) if m.startswith('ERROR')][0]\nerror_msg += ', '.join(msg[error_line:])\nexcept Exception:\n+ error_msg += ', '\nerror_msg += msg[-1]\nraise RuntimeError(error_msg)\n@@ -719,18 +730,19 @@ class NNPotential(Potential):\ndfs = []\nfor data in predict_pool:\n_ = self.write_cfgs(original_file, cfg_pool=[data])\n- p = subprocess.Popen(['nnp-predict', input_filename], stdout=subprocess.PIPE)\n- stdout = p.communicate()[0]\n+ p_evaluation = subprocess.Popen(['nnp-predict', input_filename],\n+ stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n+ stdout, stderr = p_evaluation.communicate()\n- rc = p.returncode\n+ rc = p_evaluation.returncode\nif rc != 0:\nerror_msg = 'n2p2 exited with return code %d' % rc\n- msg = stdout.decode(\"utf-8\").split('\\n')[:-1]\n+ msg = stderr.decode(\"utf-8\").split('\\n')[:-1]\ntry:\n- error_line = [i for i, m in enumerate(msg)\n- if m.startswith('ERROR')][0]\n+ error_line = [i for i, m in enumerate(msg) if m.startswith('ERROR')][0]\nerror_msg += ', '.join(msg[error_line:])\nexcept Exception:\n+ error_msg += ', '\nerror_msg += msg[-1]\nraise RuntimeError(error_msg)\n",
        "chatgpt_cot": "Add query method to ChainCode class for chaincode querying, handling TLS settings and returning query results or error messages. Fixes potential query failures."
    },
    {
        "org_diff": "diff --git a/sc2/paths.py b/sc2/paths.py import os\nfrom pathlib import Path\nimport platform\n-\n+import re\nimport logging\nlogger = logging.getLogger(__name__)\n@@ -11,6 +11,12 @@ BASEDIR = {\n\"Linux\": \"~/StarCraftII\"\n}\n+USERPATH = {\n+ \"Windows\": \"\\Documents\\StarCraft II\\ExecuteInfo.txt\",\n+ \"Darwin\": \"/Library/Application Support/Blizzard/StarCraft II/ExecuteInfo.txt\",\n+ \"Linux\": None\n+}\n+\nBINPATH = {\n\"Windows\": \"SC2_x64.exe\",\n\"Darwin\": \"SC2.app/Contents/MacOS/SC2\",\n@@ -46,7 +52,19 @@ class _MetaPaths(type):\nexit(1)\ntry:\n- self.BASE = Path(os.environ.get(\"SC2PATH\", BASEDIR[PF])).expanduser()\n+ base = os.environ.get(\"SC2PATH\")\n+ if base is None and USERPATH[PF] is not None:\n+ einfo = str(Path.home().expanduser()) + USERPATH[PF]\n+ if os.path.isfile(einfo):\n+ with open(einfo) as f:\n+ content = f.read()\n+ if content:\n+ base = re.search(r\" = (.*)Versions\", content).group(1)\n+ if not os.path.exists(base):\n+ base = None\n+ if base is None:\n+ base = BASEDIR[PF]\n+ self.BASE = Path(base).expanduser()\nself.EXECUTABLE = latest_executeble(self.BASE / \"Versions\")\nself.CWD = self.BASE / CWD[PF] if CWD[PF] else None\n",
        "org_msg": "ExecuteInfo.txt parsing",
        "sim_msg": "simplified conf loading",
        "sim_diff": "diff --git a/quebap/sisyphos/util.py b/quebap/sisyphos/util.py @@ -68,54 +68,34 @@ def get_timestamped_dir(path, name=None, link_to_latest=False):\nos.symlink(current_time, path + \"/latest\", target_is_directory=True)\nreturn dir\n-\n-def load_conf(path, experiment_dir=None, default=\"default.conf\"):\n+def save_conf(path, conf):\n+ with open(path, \"w\") as f_out:\nsplits = path.split(\"/\")\n- file_name = splits[-1]\ndir = \"/\".join(splits[:-1]) + \"/\"\n- default_path = dir + default\n- default_exists = os.path.isfile(default_path) and not file_name == default\n+ conf[\"meta\"][\"experiment_dir\"] = dir\n+ json.dump(conf, f_out, indent=4, sort_keys=True)\n+ f_out.close()\n- return_conf = None\n- if default_exists:\n- with open(default_path, 'r') as f_default:\n- default_conf = eval(f_default.read())\n- with open(path, 'r') as f:\n- conf = eval(f.read())\n- for key in conf:\n- val = conf[key]\n- if isinstance(val, dict):\n- for inner_key in val:\n- default_conf[key][inner_key] = conf[key][inner_key]\n- else:\n- default_conf[key] = conf[key]\n- return_conf = default_conf\n- f.close()\n- f_default.close()\n+def load_conf(path, experiment_dir=None):\n+ file_name = path.split(\"/\")[-1]\n- else:\nwith open(path, 'r') as f:\nconf = eval(f.read())\n- return_conf = conf\n- f.close()\n- return_conf[\"meta\"] = {\n- \"conf\": path,\n- \"name\": file_name.split(\".\")[0],\n- \"file_name\": file_name,\n- \"default\": default_path,\n- }\n+ if \"meta\" not in conf:\n+ conf[\"meta\"] = {}\n- if experiment_dir is not None:\n- save_conf(experiment_dir+file_name, return_conf)\n+ conf[\"meta\"][\"conf\"] = path\n+ conf[\"meta\"][\"name\"] = file_name.split(\".\")[0]\n+ conf[\"meta\"][\"file_name\"] = file_name\n- return return_conf\n+ if \"parent\" in conf[\"meta\"]:\n+ parent = load_conf_new(conf[\"meta\"][\"parent\"])\n+ conf = {**parent, **conf}\n+ if experiment_dir is not None:\n+ save_conf(experiment_dir+file_name, conf)\n-def save_conf(path, conf):\n- with open(path, \"w\") as f_out:\n- splits = path.split(\"/\")\n- dir = \"/\".join(splits[:-1]) + \"/\"\n- conf[\"meta\"][\"experiment_dir\"] = dir\n- json.dump(conf, f_out, indent=4, sort_keys=True)\n- f_out.close()\n+ f.close()\n+\n+ return conf\n",
        "chatgpt_cot": "\"Add USERPATH for Windows, Darwin, and Linux, to set game file paths based on the platform, and fix compilation issue due to new path setting.\""
    },
    {
        "org_diff": "diff --git a/node_manager_daemon_fkie/src/node_manager_daemon_fkie/monitor/hdd_usage.py b/node_manager_daemon_fkie/src/node_manager_daemon_fkie/monitor/hdd_usage.py @@ -53,6 +53,7 @@ class HddUsage(SensorInterface):\nself._path = settings.param('sysmon/Disk/path', self._path)\ndef check_sensor(self):\n+ try:\nhdd = psutil.disk_usage(self._path)\ndiag_level = 0\ndiag_vals = []\n@@ -68,6 +69,12 @@ class HddUsage(SensorInterface):\ndiag_vals.append(KeyValue(key='Free', value=hdd.free))\ndiag_vals.append(KeyValue(key='Free [%]', value='%.2f' % (100.0 - hdd.percent)))\ndiag_vals.append(KeyValue(key='Path', value=self._path))\n+ except Exception as err:\n+ warn_level = DiagnosticStatus.WARN\n+ diag_msg = '%s' % err\n+ diag_vals.append(KeyValue(key='Free', value=\"---\"))\n+ diag_vals.append(KeyValue(key='Free [%]', value=\"---\"))\n+ diag_vals.append(KeyValue(key='Path', value=self._path))\n# Update status\nwith self.mutex:\n",
        "org_msg": "node_manager_daemon_fkie: catch exception to pass the test on travis",
        "sim_msg": "\"==\" instead of \"is\" operator",
        "sim_diff": "diff --git a/xcube/core/dsio.py b/xcube/core/dsio.py @@ -329,7 +329,7 @@ class Netcdf4DatasetIO(DatasetIO):\next = _get_ext(path)\next_value = ext in {'.nc', '.hdf', '.h5'}\ntype_value = 0.0\n- if path_type is \"file\":\n+ if path_type == \"file\":\ntype_value = 1.0\nelif path_type is None:\ntype_value = 0.5\n@@ -380,7 +380,7 @@ class ZarrDatasetIO(DatasetIO):\ntype_value = 0.0\nif ext == \".zarr\":\next_value = 1.0\n- if path_type is \"dir\":\n+ if path_type == \"dir\":\ntype_value = 1.0\nelif path_type == \"url\" or path_type is None:\ntype_value = 0.5\n@@ -397,7 +397,7 @@ class ZarrDatasetIO(DatasetIO):\nelse:\next_value = 0.0\nelse:\n- if path_type is \"dir\":\n+ if path_type == \"dir\":\ntype_value = 1.0\nelif path_type == \"url\":\ntype_value = 0.5\n",
        "chatgpt_cot": "Add exception handling in check_sensor method to handle any exceptions thrown by psutil.disk_usage, update status and diagnostic message accordingly."
    },
    {
        "org_diff": "diff --git a/fkie_node_manager/src/fkie_node_manager/echo_dialog.py b/fkie_node_manager/src/fkie_node_manager/echo_dialog.py @@ -691,12 +691,18 @@ class EchoDialog(QDialog):\n:returns: string (YAML) representation of message, ``str``\n\"\"\"\ntype_ = type(val)\n- if type_ in (int, long, float) and fixed_numeric_width is not None:\n+ if sys.version_info[0] <= 2:\n+ types = (int, long, float)\n+ types_wb = (int, long, float, bool)\n+ else:\n+ types = (int, float)\n+ types_wb = (int, float, bool)\n+ if type_ in types and fixed_numeric_width is not None:\nif type_ is float:\nreturn ('%.' + str(fixed_numeric_width) + 'f') % val\nelse:\nreturn ('%d') % val\n- elif type_ in (int, long, float, bool):\n+ elif type_ in types_wb:\nreturn utf8(val)\nelif isstring(val):\n# TODO: need to escape strings correctly\n",
        "org_msg": "fkie_node_manager: fixed compatibility of echo dialog to python 3",
        "sim_msg": "adds extract_request_param to safely extract a typed value from URL parameters in the request",
        "sim_diff": "diff --git a/utils/request.py b/utils/request.py @@ -4,6 +4,7 @@ import re\n# HTK Imports\nfrom htk.utils import htk_setting\nfrom htk.utils.constants import *\n+from htk.utils.general import strtobool_safe\ndef get_current_request():\n@@ -26,6 +27,38 @@ def extract_request_ip(request):\nreturn request.environ['REMOTE_ADDR']\n+def extract_request_param(request, param, as_type=str, allow_none=True):\n+ \"\"\"Extracts a URL parameter from the request (i.e. request.GET.get)\n+\n+ - Performs basic input validation and allows typed retrieval via `as_type`\n+ - Can designate whether `None` is allowed via `allow_none`\n+ \"\"\"\n+ default_value_map = {\n+ str: '',\n+ bool: False,\n+ int: 0,\n+ float: 0,\n+ }\n+ default_value = None if allow_none else default_value_map.get(as_type, '')\n+\n+ raw_value = request.GET.get(param, default_value)\n+\n+ if as_type == str:\n+ value = raw_value\n+ elif as_type == bool:\n+ value = strtobool_safe(raw_value)\n+ elif as_type == int:\n+ m = re.match(r'^(?:\\+|\\-)?(?P<value>\\d+)\\.?$', raw_value) if raw_value else None\n+ value = int(m.group('value')) if m else default_value\n+ elif as_type == float:\n+ m = re.match(r'^(?:\\+|\\-)?(?P<value>\\d*\\.?\\d*)$', raw_value) if raw_value else None\n+ value = float(m.group('value')) if m else default_value\n+ else:\n+ value = raw_value\n+\n+ return value\n+\n+\ndef get_request_metadata(request):\npath = request.path\nurl_name = request.resolver_match.url_name\n",
        "chatgpt_cot": "\"Fix the compilation issue by adding or removing the methods in the EchoDialog file, to resolve the compilation problem related to the EchoDialog file.\""
    },
    {
        "org_diff": "diff --git a/Makefile b/Makefile @@ -6,6 +6,12 @@ RESET := $(shell tput -Txterm sgr0)\nTHEME?=basic\nSTATIC_FOLDER?=themes\\/${THEME}\\/static\nTEMPLATE_FOLDER?=themes\\/${THEME}\\/templates\n+SYSTEM=$(shell uname)\n+ifeq ($(SYSTEM), Darwin)\n+ SED = sed -ix\n+else\n+ SED = sed -i\n+endif\n.PHONY: \\\nall \\\n@@ -40,8 +46,8 @@ redeploy: ##@Service Redeploy single service, Use like \"make redeploy service=da\nbash scripts/redeploy.sh ${service}\ninitial-env: ##@Configuration Initial Configuration for dashboard\n- sed -i 's/\\(STATIC_FOLDER=\\).*/\\1${STATIC_FOLDER}/' .env\n- sed -i 's/\\(TEMPLATE_FOLDER=\\).*/\\1${TEMPLATE_FOLDER}/' .env\n+ $(SED) 's/\\(STATIC_FOLDER=\\).*/\\1${STATIC_FOLDER}/' .env\n+ $(SED) 's/\\(TEMPLATE_FOLDER=\\).*/\\1${TEMPLATE_FOLDER}/' .env\nstart: ##@Service Start service\n@$(MAKE) initial-env\n",
        "org_msg": "Fix sed command error in Mac OS\nFix issue #CE-23",
        "sim_msg": "site: delete/create instead of apply",
        "sim_diff": "diff --git a/site/Makefile b/site/Makefile @@ -32,4 +32,6 @@ deploy-site:\nsed -e \"s,@sha@,$(shell git rev-parse --short=12 HEAD),\" \\\n-e \"s,@image@,$(shell cat site-image),\" \\\n< site-deployment.yaml.in > site-deployment.yaml\n- kubectl apply -f site-deployment.yaml\n+ kubectl delete -f site-deployment.yaml\n+ sleep 5\n+ kubectl create -f site-deployment.yaml\n",
        "chatgpt_cot": "\"Add system dependent code for SED assignment, and fix the compilation issue for initial-env target.\""
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/master_view_proxy.py b/node_manager_fkie/src/node_manager_fkie/master_view_proxy.py @@ -2339,16 +2339,17 @@ class MasterViewProxy(QWidget):\nfinally:\nself.setCursor(cursor)\n- def _on_no_screen_error(self, node, host):\n- msg = nm.NoScreenOpenLogRequest(node, host).msg()\n+ def _on_no_screen_error(self, nodename, host):\n+ msg = nm.NoScreenOpenLogRequest(nodename, host).msg()\nrospy.logwarn(\"%s\" % msg)\n- muri = nm.nameres().masterurisbyaddr(host)\n- if muri:\n- nodes = self.node_tree_model.get_tree_node(node, muri[0])\n+ muris = nm.nameres().masterurisbyaddr(host)\n+ for muri in muris:\n+ if muri == self.masteruri:\n+ nodes = self.node_tree_model.get_tree_node(nodename, muri)\nfor node in nodes:\nnode.has_screen = False\nif nm.settings().show_noscreen_error:\n- self.info_frame.show_info(MessageFrame.TYPE_NOSCREEN, 'No screens found! See log for details!<br>The following nodes are affected:', MessageData('', [node.name]))\n+ self.info_frame.show_info(MessageFrame.TYPE_NOSCREEN, 'No screens found! See log for details!<br>The following nodes are affected:', MessageData('', [nodename]))\ndef on_kill_screens(self):\n'''\n",
        "org_msg": "node_manager_fkie: fixed crash on multiple screen detection\nThis error occurs if multiple roscore instances run on one machine.",
        "sim_msg": "fix preview issue on gtk",
        "sim_diff": "diff --git a/edit_windows.py b/edit_windows.py @@ -763,6 +763,9 @@ class PreviewMixin(object):\nself.preview_widget = common.root.preview(self, self._preview_position)\nif self.preview_widget:\nnew_label = _('Close Preview')\n+ if wx.Platform == '__WXGTK__': # otherwise e.g. preview of Test_Editing2 fails sometimes\n+ wx.SafeYield()\n+ compat.wxWindow_SendSizeEventToParent(self.preview_widget)\nelse:\nself._preview_position = self.preview_widget.GetPosition() # remember position\nself.preview_widget.Close()\n",
        "chatgpt_cot": "\"Fix display issue in MasterViewProxy by updating method parameters and iterating through masteruris to find matching node and update display.\""
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/editor/text_edit.py b/node_manager_fkie/src/node_manager_fkie/editor/text_edit.py @@ -174,7 +174,7 @@ class TextEdit(QTextEdit):\ndef toprettyxml(self):\ntry:\nimport xmlformatter\n- formatter = xmlformatter.Formatter(indent=\"4\", indent_char=\" \", encoding_output='utf-8', preserve=[\"literal\"])\n+ formatter = xmlformatter.Formatter(indent=\"2\", indent_char=\" \", encoding_output='utf-8', preserve=[\"literal\"])\nxml_pretty_str = formatter.format_string(self.toPlainText().encode('utf-8'))\ncursor = self.textCursor()\nif not cursor.isNull():\n",
        "org_msg": "node_manager_fkie: set indent to 2 in xmlformater",
        "sim_msg": "Fixed: Missing/ doubled accelerators in settings menu",
        "sim_diff": "diff --git a/extension/textext/asktext.py b/extension/textext/asktext.py @@ -505,7 +505,7 @@ if TOOLKIT in (GTK, GTKSOURCEVIEW):\n('ViewMenu', None, '_View'),\n('SettingsMenu', None, '_Settings'),\n('NewNodeContent', None, '_New Node Content'),\n- ('CloseShortcut', None, '_Close TexText Shortcut'),\n+ ('CloseShortcut', None, 'Close TexText _Shortcut'),\n('TabsWidth', None, '_Tabs Width'),\n]\nelse:\n@@ -551,17 +551,17 @@ if TOOLKIT in (GTK, GTKSOURCEVIEW):\nself._new_node_content_actions = [\n# name of action , stock id, label, accelerator, tooltip, callback/value\n- ('NewNodeContentEmpty', None, 'Empty', None, 'New node will be initialized with empty content', 0),\n- ('NewNodeContentInlineMath', None, 'Inline math', None, 'New node will be initialized with $ $', 1),\n- ('NewNodeContentDisplayMath', None, 'Display math', None, 'New node will be initialized with $$ $$', 2)\n+ ('NewNodeContentEmpty', None, '_Empty', None, 'New node will be initialized with empty content', 0),\n+ ('NewNodeContentInlineMath', None, '_Inline math', None, 'New node will be initialized with $ $', 1),\n+ ('NewNodeContentDisplayMath', None, '_Display math', None, 'New node will be initialized with $$ $$', 2)\n]\nnew_node_content = \"\\n\".join(\n['<menuitem action=\\'%s\\'/>' % action for (action, _, _, _, _, _) in self._new_node_content_actions])\nself._close_shortcut_actions = [\n- ('CloseShortcutEscape', None, 'ESC', None, 'TexText window closes when pressing ESC', 0),\n- ('CloseShortcutCtrlQ', None, 'CTRL + Q', None, 'TexText window closes when pressing CTRL + Q', 1),\n- ('CloseShortcutNone', None, 'None', None, 'No shortcut for closing TexText window', 2)\n+ ('CloseShortcutEscape', None, '_ESC', None, 'TexText window closes when pressing ESC', 0),\n+ ('CloseShortcutCtrlQ', None, 'CTRL + _Q', None, 'TexText window closes when pressing CTRL + Q', 1),\n+ ('CloseShortcutNone', None, '_None', None, 'No shortcut for closing TexText window', 2)\n]\nclose_shortcut = \"\\n\".join(\n['<menuitem action=\\'%s\\'/>' % action for (action, _, _, _, _, _) in self._close_shortcut_actions])\n",
        "chatgpt_cot": "Update XML formatter indent to 2 spaces to improve readability in TextEdit class."
    },
    {
        "org_diff": "diff --git a/src/agent/ansible/roles/deploy_compose/fabricsetup/templates/fabric-ca-server-config.j2 b/src/agent/ansible/roles/deploy_compose/fabricsetup/templates/fabric-ca-server-config.j2 +registry:\n+ # Maximum number of times a password/secret can be reused for enrollment\n+ # (default: -1, which means there is no limit)\n+ maxenrollments: -1\n+\n+ # Contains identity information which is used when LDAP is disabled\n+ identities:\n+ - name: {{ fabric.ca.admin }}\n+ pass: {{ fabric.ca.adminpw }}\n+ type: client\n+ affiliation: \"\"\n+ maxenrollments: -1\n+ attrs:\n+ hf.Registrar.Roles: \"client,user,peer,validator,auditor\"\n+ hf.Registrar.DelegateRoles: \"client,user,validator,auditor\"\n+ hf.Revoker: true\n+ hf.IntermediateCA: true\n+\nldap:\nenabled: false\n+\naffiliations:\n+ {{ item.org }}:\n+ - department1\n+ - department2\n",
        "org_msg": "Fix ca configuration issue\nCurrently the ca containers are not configured with role and\naffiliations, this made the ca container not being able to\nenroll and register new users, peers, orderers. This patch set\nwill fix that problem.",
        "sim_msg": "Sets env var for custom secret\nAn environment variable needs to be set for the custom secret name to be\nread. This resolves a bug where the licenseKey.secretName, while\nproperly mounted, would not be used as the license key secret which\ndefault to ambassador-edge-stack",
        "sim_diff": "diff --git a/templates/deployment.yaml b/templates/deployment.yaml @@ -154,6 +154,10 @@ spec:\nvalue: {{ include \"ambassador.fullname\" . }}-redis:6379\n{{- end }}\n{{- end }}\n+ {{- if and .Values.licenseKey.secretName .Values.enableAES}}\n+ - name: AMBASSADOR_AES_SECRET_NAME\n+ value: {{ .Values.licenseKey.secretName }}\n+ {{- end }}\n{{- if .Values.prometheusExporter.enabled }}\n- name: STATSD_ENABLED\nvalue: \"true\"\n",
        "chatgpt_cot": "\"Add registry and LDAP configurations to fabric-ca-server-config.j2 template\""
    },
    {
        "org_diff": "diff --git a/examples/cannon_rush.py b/examples/cannon_rush.py @@ -12,7 +12,7 @@ class CannonRushBot(sc2.BotAI):\nif not self.units(NEXUS).exists:\nfor worker in self.workers:\n- worker.attack(self.enemy_start_locations[0])\n+ await self.do(worker.attack(self.enemy_start_locations[0]))\nreturn\nelse:\nnexus = self.units(NEXUS).first\n",
        "org_msg": "Fix unawaited call in the cannon rush example",
        "sim_msg": "[batch] Dont blow up the killing task when killing a container",
        "sim_diff": "diff --git a/batch/batch/worker/worker.py b/batch/batch/worker/worker.py @@ -750,6 +750,8 @@ class Container:\ntry:\nif self._run_fut is not None:\nawait self._run_fut\n+ except ContainerDeletedError:\n+ pass\nfinally:\ntry:\nif self.container_is_running():\n",
        "chatgpt_cot": "\"Fix asynchronous issue in CannonRushBot by using 'await' keyword for worker attack method.\""
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/LaunchFilesDockWidget.ui b/node_manager_fkie/src/node_manager_fkie/LaunchFilesDockWidget.ui <widget class=\"QWidget\" name=\"ui_dock_widget_contents\">\n<layout class=\"QVBoxLayout\" name=\"verticalLayout\">\n<property name=\"spacing\">\n- <number>2</number>\n- </property>\n- <property name=\"leftMargin\">\n- <number>0</number>\n- </property>\n- <property name=\"topMargin\">\n- <number>2</number>\n- </property>\n- <property name=\"rightMargin\">\n- <number>0</number>\n+ <number>1</number>\n</property>\n- <property name=\"bottomMargin\">\n- <number>0</number>\n+ <property name=\"margin\">\n+ <number>3</number>\n</property>\n<item>\n<widget class=\"QFrame\" name=\"ui_launch_filter_frame\">\n",
        "org_msg": "node_manager_fkie: changed layout space in launch dock widget",
        "sim_msg": "add functionality in gui report codings\nadd functionality for whole sentence coding by found text\nadd functionality to add context to code snippets",
        "sim_diff": "diff --git a/GUI_UIs/ui_dialog_report_codings.ui b/GUI_UIs/ui_dialog_report_codings.ui <widget class=\"QPushButton\" name=\"pushButton_caseselect\">\n<property name=\"geometry\">\n<rect>\n- <x>390</x>\n+ <x>420</x>\n<y>50</y>\n<width>191</width>\n<height>27</height>\n<widget class=\"QPushButton\" name=\"pushButton_fileselect\">\n<property name=\"geometry\">\n<rect>\n- <x>390</x>\n+ <x>420</x>\n<y>20</y>\n<width>191</width>\n<height>27</height>\n<widget class=\"QPushButton\" name=\"pushButton_search\">\n<property name=\"geometry\">\n<rect>\n- <x>610</x>\n+ <x>630</x>\n<y>30</y>\n<width>121</width>\n<height>61</height>\n<widget class=\"QLabel\" name=\"label_2\">\n<property name=\"geometry\">\n<rect>\n- <x>10</x>\n- <y>30</y>\n+ <x>20</x>\n+ <y>0</y>\n<width>61</width>\n<height>22</height>\n</rect>\n<widget class=\"QComboBox\" name=\"comboBox_coders\">\n<property name=\"geometry\">\n<rect>\n- <x>90</x>\n+ <x>10</x>\n<y>20</y>\n- <width>221</width>\n- <height>34</height>\n+ <width>211</width>\n+ <height>30</height>\n</rect>\n</property>\n</widget>\n<widget class=\"QPushButton\" name=\"pushButton_attributeselect\">\n<property name=\"geometry\">\n<rect>\n- <x>390</x>\n+ <x>420</x>\n<y>80</y>\n<width>191</width>\n<height>27</height>\n<string>Export csv file</string>\n</property>\n</widget>\n+ <widget class=\"QCheckBox\" name=\"checkBox_by_sentence\">\n+ <property name=\"geometry\">\n+ <rect>\n+ <x>230</x>\n+ <y>80</y>\n+ <width>171</width>\n+ <height>23</height>\n+ </rect>\n+ </property>\n+ <property name=\"text\">\n+ <string>by sentence</string>\n+ </property>\n+ </widget>\n+ <widget class=\"QCheckBox\" name=\"checkBox_text_context\">\n+ <property name=\"geometry\">\n+ <rect>\n+ <x>230</x>\n+ <y>20</y>\n+ <width>181</width>\n+ <height>23</height>\n+ </rect>\n+ </property>\n+ <property name=\"text\">\n+ <string>text context</string>\n+ </property>\n+ </widget>\n</widget>\n</item>\n<item>\n<property name=\"text\">\n<string>Search selections:</string>\n</property>\n+ <property name=\"scaledContents\">\n+ <bool>true</bool>\n+ </property>\n<property name=\"wordWrap\">\n<bool>true</bool>\n</property>\n",
        "chatgpt_cot": "\"Adjust margin property in LaunchFilesDockWidget.ui for better layout spacing and appearance.\""
    },
    {
        "org_diff": "diff --git a/node_manager_daemon_fkie/tests/test_grpc_server.py b/node_manager_daemon_fkie/tests/test_grpc_server.py @@ -149,7 +149,7 @@ class TestGrpcServer(unittest.TestCase):\nlaunch_file, _argv = self.ls.load_launch(package, launch, path=path, args=args, request_args=request_args)\nself.fail(\"`load_launch` did not raises `exceptions.LaunchSelectionRequest` on multiple launch files\")\nexcept exceptions.LaunchSelectionRequest as lsr:\n- path = lsr.choices[-1]\n+ path = interpret_path(\"$(find node_manager_daemon_fkie)/tests/resources/description_example.launch\")\nexcept Exception as err:\nself.fail(\"`load_launch` raises wrong Exception on multiple launch files, got: %s, expected: `exceptions.LaunchSelectionRequest`: %s\" % (type(err), err))\ntry:\n",
        "org_msg": "fixed grpc server test",
        "sim_msg": "Another bad test name fixed.",
        "sim_diff": "diff --git a/tests/test_cli/test_registry/test_utils.py b/tests/test_cli/test_registry/test_utils.py @@ -161,7 +161,7 @@ class DownloadFileTestCase(TestCase):\nself.assertEqual(result, expected_result)\nget_mock.assert_called_once_with(url, stream=True)\n- def testdownload_file_wrong_response(self, get_mock):\n+ def test_download_file_wrong_response(self, get_mock):\n\"\"\"Test for download_file method wrong response from file server.\"\"\"\nresp_mock = mock.Mock()\nresp_mock.status_code = 404\n",
        "chatgpt_cot": "Fix path assignment in TestGrpcServer for multiple launch files to use interpret_path function for better resource handling."
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/master_view_proxy.py b/node_manager_fkie/src/node_manager_fkie/master_view_proxy.py @@ -915,10 +915,9 @@ class MasterViewProxy(QWidget):\nfor ld in launch_descriptions:\n# TODO: check masteruri and host\nif ld.masteruri != masteruri:\n- print \"skip MASTER\", ld.masteruri, masteruri, ld.path, self.__configs\n+ rospy.logdebug(\"skip apply config %s from %s to %s with configs %s \", ld.path, ld.masteruri, masteruri, self.__configs)\ncontinue\n# add the new config\n- print \"add MASTER\", ld.masteruri, masteruri, ld.path, self.__configs\nif ld.path not in self.__configs:\nargs = {}\nif ld.path in self._loaded_args:\n",
        "org_msg": "node_manager_fkie: removed some debug output",
        "sim_msg": "use masterframe",
        "sim_diff": "diff --git a/pypeit/scripts/ql.py b/pypeit/scripts/ql.py @@ -30,7 +30,7 @@ import numpy as np\nimport configobj\nfrom pypeit import utils\n-from pypeit.scripts import run_pypeit\n+from pypeit import masterframe\nfrom pypeit import msgs\nfrom pypeit import pypeitsetup\nfrom pypeit import io\n@@ -90,6 +90,7 @@ def generate_sci_pypeitfile(redux_path:str,\nmaster_calib_dir (str): Path to the master calib folder\nmaster_setup_and_bit (list):\nName of the master setup and bit (list of str)\n+ The latter is used to tie the science frames to the Masters\nps_sci (:class:`pypeit.pypeitsetup.PypeItSetup`):\nSetup object for the science frame(s)\ninput_cfg_dict (dict, optional):\n@@ -144,14 +145,23 @@ def generate_sci_pypeitfile(redux_path:str,\nslitTrace = SlitTraceSet.from_file(sliittrace_file)\nif maskID in slitTrace.maskdef_id:\ndetname = slitTrace.detname\n- mosaic_id = np.where(ps_sci.spectrograph.list_detectors(mosaic=True) == detname)[0][0]\n- det_tuple = ps_sci.spectrograph.allowed_mosaics[mosaic_id]\n+ # Mosaic?\n+ mosaic = True if detname[0:3] == 'MSC' else False\n+ det_id = np.where(\n+ ps_sci.spectrograph.list_detectors(\n+ mosaic=mosaic) == detname)[0][0]\n+ # Set det\n+ if mosaic:\n+ detnum = [ps_sci.spectrograph.allowed_mosaics[det_id]]\n+ else:\n+ detnum = det_id+1 # 1-based indexing\n+ # Break\nbreak\nif detname is None:\nmsgs.error('Could not find a SlitTrace file with maskID={}'.format(maskID))\n# Add to config\n- maskID_dict = dict(rdx=dict(detnum=[det_tuple],\n+ maskID_dict = dict(rdx=dict(detnum=detnum,\nmaskIDs=maskID))\nfull_cfg.merge(configobj.ConfigObj(maskID_dict))\n@@ -362,8 +372,9 @@ class QL(scriptbase.ScriptBase):\nmasters_dir, 'Master*'))\nif len(master_files) == 0:\nmsgs.error('No Master files found in {:s}'.format(masters_dir))\n- masters_setup_and_bit = os.path.basename(\n- master_files[0]).split('_')[1:3]\n+ master_key, _ = masterframe.grab_key_mdir(\n+ master_files[0], from_filename=True)\n+ masters_setup_and_bit = master_key.split(masterframe.sep1)[0:2]\n# Build the PypeIt file and link to Masters\nsci_pypeit_file, _ = \\\n",
        "chatgpt_cot": "\"Replace print statements with rospy.logdebug for better debugging and add comments for clarity in MasterViewProxy.py\""
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/editor/text_edit.py b/node_manager_fkie/src/node_manager_fkie/editor/text_edit.py @@ -40,7 +40,7 @@ import rospy\nimport traceback\nfrom node_manager_daemon_fkie import exceptions, file_item\n-from node_manager_daemon_fkie.common import get_arg_names, get_internal_args, replace_arg, utf8\n+from node_manager_daemon_fkie.common import find_included_files, get_arg_names, get_internal_args, replace_arg, utf8\nfrom node_manager_fkie.common import package_name\nfrom node_manager_fkie.detailed_msg_box import MessageBox\nfrom node_manager_fkie.parameter_dialog import ParameterDialog\n@@ -280,9 +280,8 @@ class TextEdit(QTextEdit):\nif event.modifiers() == Qt.ControlModifier or event.modifiers() == Qt.ShiftModifier:\ncursor = self.cursorForPosition(event.pos())\ntry:\n- value_pattern = re.compile(r\"\\\"(?P<value>.*?)\\\"\")\n- for groups in value_pattern.finditer(cursor.block().text()):\n- aval = groups.group(\"value\")\n+ for inc_file in find_included_files(cursor.block().text(), False, False, search_in_ext=[]):\n+ aval = inc_file.raw_inc_path\naitems = aval.split(\"'\")\nfor search_for in aitems:\nif not search_for:\n@@ -720,7 +719,6 @@ class TextEdit(QTextEdit):\nmenu.addMenu(menu_tags)\nreturn menu\nexcept Exception:\n- import traceback\nprint(traceback.format_exc(1))\nreturn None\nreturn None\n",
        "org_msg": "node_manager_fkie: fixed load launch file on Ctrl+Click",
        "sim_msg": "[MRG] Change multiprocessing import to a try statement\n* Try import multiprocessing\nTo run mne in the browser using Pyodide (cPython + WebAssembly), we need to replace the multiprocessing import in config.py with a try statement within the sys_config function\n* Update config.py",
        "sim_diff": "diff --git a/mne/utils/config.py b/mne/utils/config.py @@ -9,7 +9,6 @@ from functools import partial\nimport inspect\nfrom io import StringIO\nimport json\n-import multiprocessing\nimport os\nimport os.path as op\nimport platform\n@@ -456,9 +455,14 @@ def sys_info(fid=None, show_paths=False):\nout = 'Platform:'.ljust(ljust) + platform.platform() + '\\n'\nout += 'Python:'.ljust(ljust) + str(sys.version).replace('\\n', ' ') + '\\n'\nout += 'Executable:'.ljust(ljust) + sys.executable + '\\n'\n- out += 'CPU:'.ljust(ljust) + ('%s: %s cores\\n' %\n- (platform.processor(),\n- multiprocessing.cpu_count()))\n+ out += 'CPU:'.ljust(ljust) + ('%s: ' % platform.processor())\n+ try:\n+ import multiprocessing\n+ except ImportError:\n+ out += ('number of processors unavailable ' +\n+ '(requires \"multiprocessing\" package)\\n')\n+ else:\n+ out += '%s cores\\n' % multiprocessing.cpu_count()\nout += 'Memory:'.ljust(ljust)\ntry:\nimport psutil\n",
        "chatgpt_cot": "Refactor import statements in TextEdit.py, add find_included_files function, and update event handling."
    },
    {
        "org_diff": "diff --git a/examples/zerg/hydralisk_push.py b/examples/zerg/hydralisk_push.py @@ -8,6 +8,7 @@ import sc2\nfrom sc2 import Race, Difficulty\nfrom sc2.ids.unit_typeid import UnitTypeId\nfrom sc2.ids.ability_id import AbilityId\n+from sc2.ids.upgrade_id import UpgradeId\nfrom sc2.unit import Unit\nfrom sc2.units import Units\nfrom sc2.position import Point2\n@@ -35,6 +36,19 @@ class Hydralisk(sc2.BotAI):\nlarvae.random.train(UnitTypeId.OVERLORD)\nreturn\n+ # If hydra den is ready and idle, research upgrades\n+ hydra_dens = self.structures(UnitTypeId.HYDRALISKDEN)\n+ if hydra_dens:\n+ for hydra_den in hydra_dens.ready.idle:\n+ if self.already_pending_upgrade(UpgradeId.EVOLVEGROOVEDSPINES) < 1 and self.can_afford(\n+ UpgradeId.EVOLVEGROOVEDSPINES\n+ ):\n+ hydra_den.research(UpgradeId.EVOLVEGROOVEDSPINES)\n+ elif self.already_pending_upgrade(UpgradeId.EVOLVEMUSCULARAUGMENTS) < 1 and self.can_afford(\n+ UpgradeId.EVOLVEMUSCULARAUGMENTS\n+ ):\n+ hydra_den.research(UpgradeId.EVOLVEMUSCULARAUGMENTS)\n+\n# If hydra den is ready, train hydra\nif larvae and self.can_afford(UnitTypeId.HYDRALISK) and self.structures(UnitTypeId.HYDRALISKDEN).ready:\nlarvae.random.train(UnitTypeId.HYDRALISK)\n",
        "org_msg": "Add hydralisk upgrade research for hydralisk_push.py",
        "sim_msg": "allow for template paths",
        "sim_diff": "diff --git a/xcube/server/impl/framework/tornado.py b/xcube/server/impl/framework/tornado.py @@ -29,6 +29,7 @@ import tornado.ioloop\nimport tornado.web\nfrom xcube.constants import LOG\n+from xcube.constants import LOG_LEVEL_DETAIL\nfrom xcube.server.api import ApiHandler\nfrom xcube.server.api import ApiRequest\nfrom xcube.server.api import ApiResponse\n@@ -61,13 +62,17 @@ class TornadoFramework(ServerFramework):\npass\nhandlers.append((\n- api_route.path,\n+ self._convert_path_to_pattern(api_route.path),\nTornadoHandler,\n{\n\"api_route\": api_route\n}\n))\n+ LOG.log(LOG_LEVEL_DETAIL, f'Added route'\n+ f' {api_route.path!r}'\n+ f' from API {api_route.api_name!r}')\n+\nself._application.add_handlers(\".*$\", handlers)\ndef update(self, ctx: Context):\n@@ -81,9 +86,10 @@ class TornadoFramework(ServerFramework):\nself._application.listen(port, address=address)\n- address = \"127.0.0.1\" if address == \"0.0.0.0\" else address\n- test_url = f\"http://{address}:{port}/openapi\"\n- LOG.info(f\"Service running, listening on {address}:{port}, try {test_url}\")\n+ address_ = \"127.0.0.1\" if address == \"0.0.0.0\" else address\n+ test_url = f\"http://{address_}:{port}/openapi\"\n+ LOG.info(f\"Service running, listening on {address}:{port}\")\n+ LOG.info(f\"Try {test_url}\")\nLOG.info(f\"Press CTRL+C to stop service\")\nself._io_loop.start()\n@@ -111,6 +117,44 @@ class TornadoFramework(ServerFramework):\ntornado_logger.addHandler(h)\ntornado_logger.setLevel(logging.root.level)\n+ @staticmethod\n+ def _convert_path_to_pattern(path: str):\n+ \"\"\"\n+ Convert a string *pattern* where any occurrences of ``{NAME}``\n+ are replaced by an equivalent regex expression which will\n+ assign matching character groups to NAME. Characters match until\n+ one of the RFC 2396 reserved characters is found or the end of\n+ the *pattern* is reached.\n+\n+ :param path: URL path\n+ :return: equivalent regex pattern\n+ :raise ValueError: if *pattern* is invalid\n+ \"\"\"\n+ if '{' not in path:\n+ return path\n+ name_pattern = r'(?P<%s>[^\\;\\/\\?\\:\\@\\&\\=\\+\\$\\,]+)'\n+ reg_expr = ''\n+ pos = 0\n+ while True:\n+ pos1 = path.find('{', pos)\n+ if pos1 >= 0:\n+ pos2 = path.find('}', pos1 + 2)\n+ if pos2 > pos1:\n+ name = path[pos1 + 2:pos2]\n+ if not name.isidentifier():\n+ raise ValueError(\n+ '\"{name}\" in path must be a valid identifier,'\n+ ' but got \"%s\"' % name)\n+ reg_expr += path[pos:pos1] + (name_pattern % name)\n+ pos = pos2 + 2\n+ else:\n+ raise ValueError('no matching \"}\"'\n+ ' after \"{\" in \"%s\"' % path)\n+ else:\n+ reg_expr += path[pos:]\n+ break\n+ return reg_expr\n+\nclass TornadoBaseHandler(tornado.web.RequestHandler, ABC):\n",
        "chatgpt_cot": "\"Add upgrade research logic for hydra den and train hydra if den is ready.\""
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/editor/line_number_widget.py b/node_manager_fkie/src/node_manager_fkie/editor/line_number_widget.py @@ -75,7 +75,8 @@ class LineNumberWidget(QFrame):\npainter.setPen(Qt.black)\n# Draw the line number right justified at the y position of the\n# line. 3 is the magic padding number. drawText(x, y, text)\n- painter.drawText(self.width() - font_metrics.width(str(line_count)) - 3, round(position.y()) - contents_y + font_metrics.ascent() + self.edit.document().documentMargin(), str(line_count))\n+ midh = abs(font_metrics.height() - font_metrics.ascent()) / 2\n+ painter.drawText(self.width() - font_metrics.width(str(line_count)) - 3, round(position.y()) - contents_y + font_metrics.ascent() - midh + self.edit.document().documentMargin(), str(line_count))\nif bold:\nfont = painter.font()\nfont.setBold(False)\n@@ -99,6 +100,7 @@ class LineNumberWidget(QFrame):\nhbox = QHBoxLayout(self)\nhbox.setSpacing(0)\n+ hbox.setContentsMargins(0, 0, 0, 0)\n# hbox.setMargin(0) # removed: it is not supported by Qt5\nhbox.addWidget(self.number_bar)\nhbox.addWidget(self.edit)\n",
        "org_msg": "node_manager_fkie: editor adjust the line numbers",
        "sim_msg": "Fixed dark text on dark. Fixed context menu None type error.",
        "sim_diff": "diff --git a/qualcoder/view_graph.py b/qualcoder/view_graph.py @@ -100,6 +100,11 @@ class ViewGraph(QDialog):\npm = QtGui.QPixmap()\npm.loadFromData(QtCore.QByteArray.fromBase64(zoom_icon), \"png\")\nself.ui.label_zoom.setPixmap(pm.scaled(26, 26))\n+ pm = QtGui.QPixmap()\n+ pm.loadFromData(QtCore.QByteArray.fromBase64(eye_icon), \"png\")\n+ self.ui.pushButton_reveal.setIcon(QtGui.QIcon(pm))\n+ self.ui.pushButton_reveal.pressed.connect(self.reveal_hidden_items)\n+ self.ui.pushButton_reveal.hide() # TODO TMP\n# Set the scene\nself.scene = GraphicsScene()\n@@ -415,6 +420,11 @@ class ViewGraph(QDialog):\ni += 1\nreturn new_model\n+ def reveal_hidden_items(self):\n+ \"\"\" Show list of hidden items to be revealed on selection \"\"\"\n+\n+ pass\n+\ndef keyPressEvent(self, event):\n\"\"\" Plus to zoom in and Minus to zoom out. Needs focus on the QGraphicsView widget. \"\"\"\n@@ -647,6 +657,8 @@ class FreeTextGraphicsItem(QtWidgets.QGraphicsTextItem):\nmenu = QtWidgets.QMenu()\nmenu.addAction(_('Remove'))\naction = menu.exec(QtGui.QCursor.pos())\n+ if action is None:\n+ return\nif action.text() == \"Remove\":\nself.remove = True\n@@ -663,9 +675,9 @@ class FreeTextGraphicsItem(QtWidgets.QGraphicsTextItem):\npainter.drawRect(self.boundingRect())\npainter.setFont(self.font)\nfm = painter.fontMetrics()\n+ painter.setPen(QtGui.QColor(QtCore.Qt.GlobalColor.black))\nif self.app.settings['stylesheet'] == 'dark':\npainter.setPen(QtGui.QColor(QtCore.Qt.GlobalColor.white))\n- painter.setPen(QtGui.QColor(QtCore.Qt.GlobalColor.black))\nlines = self.text.split('\\\\n')\nfor row in range(0, len(lines)):\npainter.drawText(5, fm.height() * (row + 1), lines[row])\n@@ -716,6 +728,8 @@ class FreeLineGraphicsItem(QtWidgets.QGraphicsLineItem):\nmenu.addAction(_('Blue'))\nmenu.addAction(_('Remove'))\naction = menu.exec(QtGui.QCursor.pos())\n+ if action is None:\n+ return\nif action.text() == 'Thicker':\nself.line_width = self.line_width + 0.5\nif self.line_width > 5:\n@@ -957,6 +971,8 @@ class LinkGraphicsItem(QtWidgets.QGraphicsLineItem):\nmenu.addAction(_(\"Hide\"))\naction = menu.exec(QtGui.QCursor.pos())\n+ if action is None:\n+ return\nif action.text() == 'Thicker':\nself.line_width = self.line_width + 0.5\nif self.line_width > 5:\n",
        "chatgpt_cot": "\"Adjust LineNumberWidget layout and text positioning for better display and alignment, and remove unsupported margin setting.\""
    },
    {
        "org_diff": "diff --git a/sc2/protocol.py b/sc2/protocol.py @@ -46,6 +46,9 @@ class Protocol(object):\nresult = await self._execute(ping=sc_pb.RequestPing())\nreturn result\n+ async def leave(self):\n+ await self._execute(leave_game=sc_pb.RequestLeaveGame())\n+\nasync def quit(self):\ntry:\nawait self._execute(quit=sc_pb.RequestQuit())\n",
        "org_msg": "Add leave command to cleanly exit games",
        "sim_msg": "[ServerStats] Fix error when no invite link or message is provided on pruneroles kick",
        "sim_diff": "diff --git a/serverstats/serverstats.py b/serverstats/serverstats.py @@ -501,7 +501,7 @@ class ServerStats(commands.Cog):\n\"message\", check=lambda m: m.author == ctx.message.author, timeout=30\n)\nexcept asyncio.TimeoutError:\n- await msg.edit(content=_(\"I Guess not.\"))\n+ await ctx.send(_(\"I Guess not.\"))\nreturn None\nif \"exit\" in msg.content:\nreturn None\n",
        "chatgpt_cot": "Add async leave method in Protocol class to handle leaving game requests efficiently."
    },
    {
        "org_diff": "diff --git a/src/api-engine/api/routes/general/views.py b/src/api-engine/api/routes/general/views.py @@ -5,7 +5,7 @@ import logging\nimport base64\nfrom rest_framework import viewsets, status\n-from django.core.exceptions import ObjectDoesNotExist\n+from django.core.exceptions import ObjectDoesNotExist, MultipleObjectsReturned\nfrom rest_framework.response import Response\nfrom rest_framework_jwt.views import ObtainJSONWebToken\nfrom api.models import UserProfile, Organization\n@@ -33,24 +33,39 @@ class RegisterViewSet(viewsets.ViewSet):\ntry:\nserializer = RegisterBody(data=request.data)\nif serializer.is_valid(raise_exception=True):\n- username = serializer.validated_data.get(\"username\")\n+ #username = serializer.validated_data.get(\"username\")\nemail = serializer.validated_data.get(\"email\")\norgname = serializer.validated_data.get(\"orgName\")\npassword = serializer.validated_data.get(\"password\")\n+\ntry:\n- Organization.objects.get(name=orgname)\nUserProfile.objects.get(email=email)\nexcept ObjectDoesNotExist:\npass\n- except Exception as e:\n+ except MultipleObjectsReturned:\nreturn Response(\n- err(e), status=status.HTTP_409_CONFLICT\n+ err(\"Email Aleady exists!\"), status=status.HTTP_409_CONFLICT\n)\nelse:\nreturn Response(\n- err(\"orgnization exists!\"), status=status.HTTP_409_CONFLICT\n+ err(\"Email Aleady exists!\"), status=status.HTTP_409_CONFLICT\n)\n+ try:\n+ Organization.objects.get(name=orgname)\n+ except ObjectDoesNotExist:\n+ pass\n+ except MultipleObjectsReturned:\n+ return Response(\n+ err(\"Orgnization already exists!\"), status=status.HTTP_409_CONFLICT\n+ )\n+ else:\n+ return Response(\n+ err(\"Orgnization already exists!\"), status=status.HTTP_409_CONFLICT\n+ )\n+\n+\n+\nCryptoConfig(orgname).create(0, 0)\nCryptoGen(orgname).generate()\n",
        "org_msg": "[#issue-439]Debug Info in 500 HTTP Response Body\n[#issue-439] Fix the issue of long debug info in http response body.\nCause of issue:\nLine 48: err(e), status=status.HTTP_409_CONFLICT\nerr(e) contains all the debug information, and should be replaced with a better error message.",
        "sim_msg": "Adds API filtering for the \"user\" list",
        "sim_diff": "diff --git a/InvenTree/users/api.py b/InvenTree/users/api.py @@ -7,15 +7,16 @@ from django.core.exceptions import ObjectDoesNotExist\nfrom django.conf.urls import url, include\n-from rest_framework import generics, permissions\n+from django_filters.rest_framework import DjangoFilterBackend\n+\n+from rest_framework import filters, generics, permissions\nfrom rest_framework.views import APIView\nfrom rest_framework.authtoken.models import Token\nfrom rest_framework.response import Response\nfrom rest_framework import status\n-from .serializers import UserSerializer, OwnerSerializer\n-\n-from .models import RuleSet, Owner, check_user_role\n+from users.models import RuleSet, Owner, check_user_role\n+from users.serializers import UserSerializer, OwnerSerializer\nclass OwnerList(generics.ListAPIView):\n@@ -127,6 +128,18 @@ class UserList(generics.ListAPIView):\nserializer_class = UserSerializer\npermission_classes = (permissions.IsAuthenticated,)\n+ filter_backends = [\n+ DjangoFilterBackend,\n+ filters.SearchFilter,\n+ ]\n+\n+ search_fields = [\n+ 'first_name',\n+ 'last_name',\n+ 'username',\n+ ]\n+\n+\nclass GetAuthToken(APIView):\n\"\"\" Return authentication token for an authenticated user. \"\"\"\n",
        "chatgpt_cot": "Fix compilation issue due to addition of MultipleObjectsReturned exception in views.py for RegisterViewSet class. Added handling for multiple objects returned in organization and email check."
    },
    {
        "org_diff": "diff --git a/sc2/bot_ai.py b/sc2/bot_ai.py @@ -75,11 +75,13 @@ class BotAI(DistanceCalculation):\nself.realtime: bool = False\nself.all_units: Units = Units([], self)\nself.units: Units = Units([], self)\n+ self.all_own_units: Units = Units([], self)\nself.workers: Units = Units([], self)\nself.townhalls: Units = Units([], self)\nself.structures: Units = Units([], self)\nself.gas_buildings: Units = Units([], self)\nself.enemy_units: Units = Units([], self)\n+ self.all_enemy_units: Units = Units([], self)\nself.enemy_structures: Units = Units([], self)\nself.resources: Units = Units([], self)\nself.destructables: Units = Units([], self)\n@@ -1674,8 +1676,10 @@ class BotAI(DistanceCalculation):\nself.placeholders: Units = Units([], self)\nself.units: Units = Units([], self)\nself.structures: Units = Units([], self)\n+ self.all_own_units: Units = Units([], self)\nself.enemy_units: Units = Units([], self)\nself.enemy_structures: Units = Units([], self)\n+ self.all_enemy_units: Units = Units([], self)\nself.mineral_field: Units = Units([], self)\nself.vespene_geyser: Units = Units([], self)\nself.resources: Units = Units([], self)\n@@ -1726,6 +1730,7 @@ class BotAI(DistanceCalculation):\nself.destructables.append(unit_obj)\n# Alliance.Self.value = 1\nelif alliance == 1:\n+ self.all_own_units.append(unit_obj)\nunit_id = unit_obj.type_id\nif unit_obj.is_structure:\nself.structures.append(unit_obj)\n@@ -1756,6 +1761,7 @@ class BotAI(DistanceCalculation):\nself.larva.append(unit_obj)\n# Alliance.Enemy.value = 4\nelif alliance == 4:\n+ self.all_enemy_units.append(unit_obj)\nif unit_obj.is_structure:\nself.enemy_structures.append(unit_obj)\nelse:\n",
        "org_msg": "bot_ai.py changes",
        "sim_msg": "initial pass at creation of conversion from export to a labelbox format",
        "sim_diff": "diff --git a/labelbox/data/serialization/labelbox_v1/objects.py b/labelbox/data/serialization/labelbox_v1/objects.py @@ -259,17 +259,22 @@ class LBV1TextEntity(LBV1ObjectBase):\n**extra)\n+class LBV1DocumentRectangle(LBV1Rectangle):\n+ unit: str\n+ page: int\n+\n+\nclass LBV1Objects(BaseModel):\n- objects: List[Union[LBV1Line, LBV1Point, LBV1Polygon, LBV1Rectangle,\n- LBV1TextEntity, LBV1Mask, LBV1TIPoint, LBV1TILine,\n- LBV1TIPolygon, LBV1TIRectangle]]\n+ objects: List[Union[LBV1DocumentRectangle, LBV1Line, LBV1Point, LBV1Polygon,\n+ LBV1Rectangle, LBV1TextEntity, LBV1Mask, LBV1TIPoint,\n+ LBV1TILine, LBV1TIPolygon, LBV1TIRectangle,]]\ndef to_common(self) -> List[ObjectAnnotation]:\nobjects = [\n- ObjectAnnotation(value=obj.to_common(),\n+ ObjectAnnotation(\n+ value=obj.to_common(),\nclassifications=[\n- ClassificationAnnotation(\n- value=cls.to_common(),\n+ ClassificationAnnotation(value=cls.to_common(),\nfeature_schema_id=cls.schema_id,\nname=cls.title,\nextra={\n@@ -285,6 +290,8 @@ class LBV1Objects(BaseModel):\n'color': obj.color,\n'feature_id': obj.feature_id,\n'value': obj.value,\n+ 'page': obj.page if hasattr(obj, 'page') else None,\n+ 'unit': obj.unit if hasattr(obj, 'unit') else None,\n}) for obj in self.objects\n]\nreturn objects\n",
        "chatgpt_cot": "Add all_own_units and all_enemy_units attributes to BotAI class. Improve organization and management of own and enemy units."
    },
    {
        "org_diff": "diff --git a/rasa_core_sdk/forms.py b/rasa_core_sdk/forms.py @@ -71,8 +71,10 @@ class FormAction(Action):\ntracker, # type: Tracker\ndomain # type: Dict[Text, Any]\n):\n- # type: (...) -> Optional[List[Dict]]\n- \"\"\"\"Extract requested slot from a user input else return None\"\"\"\n+ # type: (...) -> Optional[Any]\n+ \"\"\"Extract the value of requested slot from a user input\n+ else return None\n+ \"\"\"\nslot_to_fill = tracker.get_slot(REQUESTED_SLOT)\nlogger.debug(\"Trying to extract requested slot '{}' ...\"\n\"\".format(slot_to_fill))\n@@ -114,7 +116,7 @@ class FormAction(Action):\nif value is not None:\nlogger.debug(\"Successfully extracted '{}'\"\n\"\".format(value))\n- return [SlotSet(slot_to_fill, value)]\n+ return value\nlogger.debug(\"Failed to extract\")\nreturn None\n@@ -125,10 +127,10 @@ class FormAction(Action):\n\"\"\"\"Validate extracted requested slot else raise an error\"\"\"\nslot_to_fill = tracker.get_slot(REQUESTED_SLOT)\n- events = self.extract(dispatcher, tracker, domain)\n+ extracted_value = self.extract(dispatcher, tracker, domain)\n- if events is not None:\n- return events\n+ if extracted_value is not None:\n+ return [SlotSet(slot_to_fill, extracted_value)]\nelse:\nraise ActionExecutionRejection(self.name(),\n\"Failed to validate slot {0} \"\n",
        "org_msg": "'extract()' returns the value of theslot and not event RasaHQ/roadmap#280",
        "sim_msg": "add online/inperson question to inquiry form",
        "sim_diff": "diff --git a/amy/extrequests/forms.py b/amy/extrequests/forms.py @@ -649,6 +649,7 @@ class WorkshopInquiryRequestBaseForm(forms.ModelForm):\n\"institution_department\",\n\"location\",\n\"country\",\n+ \"online_inperson\",\n# \"your audience\" section starts now\n\"routine_data\",\n\"routine_data_other\",\n@@ -685,6 +686,7 @@ class WorkshopInquiryRequestBaseForm(forms.ModelForm):\n'class': 'nopastdates'}),\n'institution_other_URL': forms.TextInput(),\n'country': Select2Widget,\n+ 'online_inperson':forms.RadioSelect(),\n'language': Select2Widget,\n'number_attendees': forms.RadioSelect(),\n'computing_levels': forms.CheckboxSelectMultiple(),\n",
        "chatgpt_cot": "Add new method and modify return type for existing methods in FormAction class. Fix method comments and adjust method to return the value."
    },
    {
        "org_diff": "diff --git a/src/modules/cluster.py b/src/modules/cluster.py @@ -484,11 +484,11 @@ class ClusterHandler(object):\nelse:\nreturn False\n- result = self.cluster_agents[h.get('type')].start(\n- name=cluster_id, worker_api=h.get('worker_api'),\n+ result = self.cluster_agents[h.type].start(\n+ name=cluster_id, worker_api=h.worker_api,\nmapped_ports=c.get('mapped_ports', PEER_SERVICE_PORTS),\n- log_type=h.get('log_type'),\n- log_level=h.get('log_level'),\n+ log_type=h.log_type,\n+ log_level=h.log_level,\nlog_server='',\nconfig=config,\n)\n@@ -528,11 +528,11 @@ class ClusterHandler(object):\nelse:\nreturn False\n- result = self.cluster_agents[h.get('type')].restart(\n- name=cluster_id, worker_api=h.get('worker_api'),\n+ result = self.cluster_agents[h.type].restart(\n+ name=cluster_id, worker_api=h.worker_api,\nmapped_ports=c.get('mapped_ports', PEER_SERVICE_PORTS),\n- log_type=h.get('log_type'),\n- log_level=h.get('log_level'),\n+ log_type=h.log_type,\n+ log_level=h.log_level,\nlog_server='',\nconfig=config,\n)\n@@ -570,11 +570,11 @@ class ClusterHandler(object):\nsize=c.get('size'))\nelse:\nreturn False\n- result = self.cluster_agents[h.get('type')].stop(\n- name=cluster_id, worker_api=h.get('worker_api'),\n+ result = self.cluster_agents[h.type].stop(\n+ name=cluster_id, worker_api=h.worker_api,\nmapped_ports=c.get('mapped_ports', PEER_SERVICE_PORTS),\n- log_type=h.get('log_type'),\n- log_level=h.get('log_level'),\n+ log_type=h.log_type,\n+ log_level=h.log_level,\nlog_server='',\nconfig=config,\n)\n",
        "org_msg": "Fix chain operation in admin dashboard\nCan restart/stop/start chains in admin dashboard",
        "sim_msg": "Updated version and added augur metadata",
        "sim_diff": "diff --git a/workers/clustering_worker/clustering_worker.py b/workers/clustering_worker/clustering_worker.py @@ -48,8 +48,8 @@ class ClusteringWorker(Worker):\n# Define data collection info\nself.tool_source = 'Clustering Worker'\n- self.tool_version = '0.0.0'\n- self.data_source = 'Non-existent API'\n+ self.tool_version = '0.1.0'\n+ self.data_source = 'Augur Collected Messages'\n#define clustering specific parameters\n# self.max_df = 0.9 #get from configuration file\n@@ -166,7 +166,10 @@ class ClusteringWorker(Worker):\nrecord = {\n'repo_id': int(repo_id),\n'cluster_content': int(prediction[0]),\n- 'cluster_mechanism' : -1\n+ 'cluster_mechanism' : -1,\n+ 'tool_source' : self.tool_source,\n+ 'tool_version' : self.tool_version,\n+ 'data_source' : self.data_source\n}\nresult = self.db.execute(self.repo_cluster_messages_table.insert().values(record))\nlogging.info(\"Primary key inserted into the repo_cluster_messages table: {}\".format(result.inserted_primary_key))\n@@ -187,7 +190,10 @@ class ClusteringWorker(Worker):\nrecord = {\n'repo_id': int(repo_id),\n'topic_id': i+1,\n- 'topic_prob' : prob\n+ 'topic_prob' : prob,\n+ 'tool_source' : self.tool_source,\n+ 'tool_version' : self.tool_version,\n+ 'data_source' : self.data_source\n}\nresult = self.db.execute(self.repo_topic_table.insert().values(record))\n@@ -290,7 +296,10 @@ class ClusteringWorker(Worker):\n#'topic_words_id': twid,\n#'word_prob': word_prob[i],\n'topic_id': int(topic_id),\n- 'word': feature_names[i]\n+ 'word': feature_names[i],\n+ 'tool_source' : self.tool_source,\n+ 'tool_version' : self.tool_version,\n+ 'data_source' : self.data_source\n}\nresult = self.db.execute(self.topic_words_table.insert().values(record))\nself.logger.info(\"Primary key inserted into the topic_words table: {}\".format(result.inserted_primary_key))\n",
        "chatgpt_cot": "Refactor ClusterHandler methods to use attributes directly instead of using get() method. This simplifies the code and improves readability."
    },
    {
        "org_diff": "diff --git a/fkie_node_manager/doc/index.rst b/fkie_node_manager/doc/index.rst @@ -21,3 +21,25 @@ changelog_\n.. _shortcuts: manuals/shortcuts.rst\n.. _changelog: ../CHANGELOG.rst\n+\n+````\n+\n+**Troubleshooting**\n+\n+- Error while launch a node on remote host: ``bash: rosrun: command not found``\n+\n+ To run a node on remote host, an SSH connection will be established without setting any enviroment variables.\n+\n+ Add ``source /opt/ros/xxx/setup.bash`` to **.bashrc** before ``[ -z \"$PS1\" ] && return``\n+\n+- The Node Manager crashes on load a launch file with error: *QSpiAccessible::accessibleEvent not handled: \"8008\"*\n+\n+ This \"bug\" seems to be resolved by removing the **qt-at-spi** package.\n+\n+- You don't see the correct output of your nodes. Try to change your default terminal:\n+\n+ ``sudo update-alternatives --config x-terminal-emulator``\n+\n+- You get an exception on access remote host: *Exception: ssh connection to REMOTE_HOST failed: not a valid RSA private key file*\n+\n+ Generate an SSH key file with e.g. ``ssh-keygen -p -m PEM -f ~/.ssh/id_rsa``\n\\ No newline at end of file\n",
        "org_msg": "fkie_node_manager: added troubleshooting to internal help",
        "sim_msg": "Update p2p config script\nsupports updating bootnodes as well. also supports deleting them.",
        "sim_diff": "diff --git a/quarkchain/tools/config_p2p.py b/quarkchain/tools/config_p2p.py \"\"\"\n- python config_p2p.py <64 character hex>\n+ python config_p2p.py \\\n+ --privkey <64 character hex> \\\n+ --bootnodes enode://xxx@yyy:zzz,...\n-will update PRIV_KEY field in P2P section.\n+will update PRIV_KEY and BOOT_NODES fields in P2P section.\n\"\"\"\nimport argparse\nimport json\nimport os\n+import re\n+import socket\nFILE = \"../../testnet/2/cluster_config_template.json\"\nif \"QKC_CONFIG\" in os.environ:\nFILE = os.environ[\"QKC_CONFIG\"]\n+def validate_bootnodes(bootnodes_str):\n+ \"\"\"Expect comma-separated string like 'enode://<128 char pub key>@<ip>:<port>'.\"\"\"\n+ if not bootnodes_str:\n+ return\n+ p = re.compile(\"^enode://([a-z0-9]+)@(.+):([0-9]+)$\")\n+ for bootnode in bootnodes_str.split(\",\"):\n+ res = p.match(bootnode)\n+ if not res:\n+ raise ValueError(\"Invalid boot nodes\")\n+ pubkey, ip, port = res.group(1, 2, 3)\n+ if len(pubkey) != 128:\n+ raise ValueError(\"Invalid public key in boot nodes\")\n+ try:\n+ socket.inet_aton(ip)\n+ except socket.error:\n+ raise ValueError(\"Invalid IP in boot nodes\")\n+ if not port.isnumeric():\n+ raise ValueError(\"Invalid port in boot nodes\")\n+\n+\ndef main():\nparser = argparse.ArgumentParser()\n- parser.add_argument(\"privkey\", metavar=\"privkey\", help=\"Private key for P2P config\")\n+ parser.add_argument(\"--privkey\", help=\"Private key for P2P config\")\n+ parser.add_argument(\"--bootnodes\", help=\"List of bootnodes\")\nargs = parser.parse_args()\nprivkey = args.privkey\n- if not privkey or not privkey.isalnum() or len(privkey) != 64:\n+ if privkey and (not privkey.isalnum() or len(privkey) != 64):\nraise ValueError(\"Invalid private key\")\n+ validate_bootnodes(args.bootnodes)\n+\nabspath = os.path.abspath(__file__)\ndname = os.path.dirname(abspath)\nos.chdir(dname)\n@@ -29,7 +56,9 @@ def main():\nparsed_config = json.load(f)\nif \"P2P\" not in parsed_config:\nraise ValueError(\"P2P not found in config\")\n- parsed_config[\"P2P\"][\"PRIV_KEY\"] = privkey\n+ p2p = parsed_config[\"P2P\"]\n+ p2p[\"PRIV_KEY\"] = privkey or \"\"\n+ p2p[\"BOOT_NODES\"] = args.bootnodes or \"\"\nf.seek(0)\nf.truncate()\nf.write(json.dumps(parsed_config, indent=4))\n",
        "chatgpt_cot": "\"Add troubleshooting section to index.rst for common issues and their solutions related to launching nodes on remote hosts and accessing remote hosts.\""
    },
    {
        "org_diff": "diff --git a/.github/workflows/pythonactions.yml b/.github/workflows/pythonactions.yml @@ -180,7 +180,7 @@ jobs:\ncd ..\n- name: Publish to Github Pages\n- if: github.ref == 'refs/heads/develop' || github.ref == 'refs/heads/convert-to-github-actions'\n+ if: github.ref == 'refs/heads/develop' && github.event_name == 'push'\nuses: JamesIves/github-pages-deploy-action@releases/v3\nwith:\nACCESS_TOKEN: ${{ secrets.ACCESS_TOKEN }}\n@@ -223,7 +223,7 @@ jobs:\n- name: Publish package\n# continue-on-error: true\n# Upload files in dist/* directory\n- if: github.ref == 'refs/heads/develop' || github.ref == 'refs/heads/convert-to-github-actions'\n+ if: github.ref == 'refs/heads/develop' && github.event_name == 'push'\nenv:\n# Set env variables, 'twine' then uses these to upload to pypi\nTWINE_PASSWORD: ${{ secrets.pypi_password }}\n",
        "org_msg": "Limit pypi and github pages release to push",
        "sim_msg": "fix pypi username",
        "sim_diff": "diff --git a/.github/workflows/ci_deploy_pypi.yml b/.github/workflows/ci_deploy_pypi.yml @@ -24,5 +24,5 @@ jobs:\nif: github.event_name == 'push' && startsWith(github.event.ref, 'refs/tags')\nuses: pypa/gh-action-pypi-publish@master\nwith:\n- user: ${{ secrets.PYPI_USER }}\n+ user: __token__\npassword: ${{ secrets.PYPI_PASSWORD }}\n",
        "chatgpt_cot": "Update Github Pages and package publishing conditions based on branch and event to ensure correct deployment triggers."
    },
    {
        "org_diff": "diff --git a/fkie_node_manager/src/fkie_node_manager/master_view_proxy.py b/fkie_node_manager/src/fkie_node_manager/master_view_proxy.py @@ -223,7 +223,7 @@ class MasterViewProxy(QWidget):\nself.masterTab.nodeTreeView.setItemDelegateForColumn(0, self.nodeNameDelegate)\nself.node_delegate = NodeInfoIconsDelegate()\nself.masterTab.nodeTreeView.setItemDelegateForColumn(1, self.node_delegate)\n- self.masterTab.nodeTreeView.collapsed.connect(self.on_node_collapsed)\n+ # self.masterTab.nodeTreeView.collapsed.connect(self.on_node_collapsed)\nself.masterTab.nodeTreeView.expanded.connect(self.on_node_expanded)\nsm = self.masterTab.nodeTreeView.selectionModel()\nsm.selectionChanged.connect(self.on_node_selection_changed)\n@@ -2949,8 +2949,6 @@ class MasterViewProxy(QWidget):\nindex = selected\nwhile index is not None and index.isValid():\nitem = proxy_model.sourceModel().itemFromIndex(index)\n- if type(item) in [TopicGroupItem, ServiceGroupItem, GroupItem] and not tree_view.isExpanded(index):\n- tree_view.setExpanded(index, True)\ntree_view.setExpanded(index, True)\nindex = index.parent()\n# expand the root item. NodesView has on sync also other hosts. In this case only local host will expanded.\n",
        "org_msg": "fkie_node_manager: fix: show selected node on clear filter",
        "sim_msg": "implemented search in loader",
        "sim_diff": "diff --git a/avalon/tools/cbloader/widgets.py b/avalon/tools/cbloader/widgets.py @@ -32,6 +32,8 @@ class SubsetWidget(QtWidgets.QWidget):\nmodel = SubsetsModel()\nproxy = FilterProxyModel()\n+ filter = QtGui.QLineEdit()\n+\nview = QtWidgets.QTreeView()\nview.setIndentation(5)\nview.setStyleSheet(\"\"\"\n@@ -52,6 +54,7 @@ class SubsetWidget(QtWidgets.QWidget):\nlayout = QtWidgets.QVBoxLayout(self)\nlayout.setContentsMargins(0, 0, 0, 0)\n+ layout.addWidget(filter)\nlayout.addWidget(view)\nview.setContextMenuPolicy(QtCore.Qt.CustomContextMenu)\n@@ -68,10 +71,12 @@ class SubsetWidget(QtWidgets.QWidget):\nself.proxy = proxy\nself.model = model\nself.view = view\n+ self.filter = filter\n# settings and connections\nself.proxy.setSourceModel(self.model)\nself.proxy.setDynamicSortFilter(True)\n+ self.proxy.setFilterCaseSensitivity(QtCore.Qt.CaseInsensitive)\nself.view.setModel(self.proxy)\nself.view.customContextMenuRequested.connect(self.on_context_menu)\n@@ -79,6 +84,8 @@ class SubsetWidget(QtWidgets.QWidget):\nselection = view.selectionModel()\nselection.selectionChanged.connect(self.active_changed)\n+ self.filter.textChanged.connect(self.proxy.setFilterRegExp)\n+\nself.model.refresh()\ndef on_context_menu(self, point):\n",
        "chatgpt_cot": "\"Remove unnecessary code for nodeTreeView and fix the collapsed method in MasterViewProxy\""
    },
    {
        "org_diff": "diff --git a/rasa_core_sdk/forms.py b/rasa_core_sdk/forms.py @@ -23,7 +23,6 @@ REQUESTED_SLOT = \"requested_slot\"\nclass FormAction(Action):\n- FREETEXT = '__FREETEXT__'\ndef name(self):\n# type: () -> Text\n@@ -39,16 +38,27 @@ class FormAction(Action):\nraise NotImplementedError(\"A form must implement required slots \"\n\"that it has to fill\")\n+ @staticmethod\n+ def from_entity(entity, intent=None):\n+ return {\"type\": \"from_entity\", \"intent\": intent, \"entity\": entity}\n+\n+ @staticmethod\n+ def from_intent(intent, value):\n+ return {\"type\": \"from_intent\", \"intent\": intent, \"value\": value}\n+\n+ @staticmethod\n+ def from_text(intent=None):\n+ return {\"type\": \"from_text\", \"intent\": intent}\n+\ndef slot_mapping(self):\n# type: () -> Dict[Text: Union[Text, Dict, List[Text, Dict]]]\n\"\"\"A dictionary to map required slots to\n- - an extracted entity;\n- - a dictionary of intent: value pairs,\n- if value is FREETEXT, use a whole message as value;\n- - a whole message;\n+ - an extracted entity\n+ - intent: value pairs\n+ - a whole message\nor a list of all of them, where a first match will be picked\"\"\"\n- return dict(zip(self.required_slots(), self.required_slots()))\n+ return {slot: self.from_entity(slot) for slot in self.required_slots()}\n# noinspection PyUnusedLocal\ndef extract(self,\n@@ -68,28 +78,33 @@ class FormAction(Action):\nslot_mappings = [slot_mappings]\nfor slot_mapping in slot_mappings:\n- if isinstance(slot_mapping, dict):\n+ if (not isinstance(slot_mapping, dict) or\n+ slot_mapping.get(\"type\") is None):\n+ raise ValueError(\"Provided incompatible slot_mapping\")\n+\n+ mapping_intent = slot_mapping.get(\"intent\")\nintent = tracker.latest_message.get(\"intent\",\n{}).get(\"name\")\n- if intent in slot_mapping.keys():\n- if slot_mapping[intent] == self.FREETEXT:\n- return [SlotSet(slot_to_fill,\n- tracker.latest_message.get(\n- \"text\"))]\n- else:\n- return [SlotSet(slot_to_fill,\n- slot_mapping[intent])]\n- else:\n+ if mapping_intent is None or mapping_intent == intent:\n+ mapping_type = slot_mapping[\"type\"]\n+\n+ if mapping_type == \"from_entity\":\nentity_value = next(tracker.get_latest_entity_values(\n- slot_mapping), None)\n+ slot_mapping.get(\"entity\")), None)\nif entity_value is not None:\nreturn [SlotSet(slot_to_fill, entity_value)]\n- # the whole text can be always extracted, so it is done in the end\n- if self.FREETEXT in slot_mappings:\n+ elif mapping_type == \"from_intent\":\n+ return [SlotSet(slot_to_fill,\n+ slot_mapping.get(\"value\"))]\n+\n+ elif mapping_type == \"from_text\":\nreturn [SlotSet(slot_to_fill,\ntracker.latest_message.get(\"text\"))]\n+ else:\n+ raise TypeError(\"slot_mapping type is not supported\")\n+\nreturn None\n# noinspection PyUnusedLocal\n",
        "org_msg": "add helper methods to construct slot_mapping RasaHQ/roadmap#280",
        "sim_msg": "In Fluent strings, only machine translate part that follows the ID",
        "sim_diff": "diff --git a/pontoon/pretranslation/pretranslate.py b/pontoon/pretranslation/pretranslate.py @@ -18,6 +18,7 @@ from pontoon.base.templatetags.helpers import (\nget_reconstructed_message,\n)\n+UNTRANSLATABLE_KEY = \"AIzaSyDX3R5Y1kxh_8lJ4OAO\"\nserializer = FluentSerializer()\n@@ -40,7 +41,7 @@ def get_translations(entity, locale):\nstrings = []\nplural_forms = range(0, locale.nplurals or 1)\n- entity_string = (\n+ tm_input = (\nas_simple_translation(entity.string)\nif is_single_input_ftl_string(entity.string)\nelse entity.string\n@@ -48,7 +49,7 @@ def get_translations(entity, locale):\n# Try to get matches from translation_memory\ntm_response = get_translation_memory_data(\n- text=entity_string,\n+ text=tm_input,\nlocale=locale,\n)\n@@ -58,7 +59,7 @@ def get_translations(entity, locale):\nif entity.string_plural == \"\":\ntranslation = tm_response[0][\"target\"]\n- if entity.string != entity_string:\n+ if entity.string != tm_input:\ntranslation = serializer.serialize_entry(\nget_reconstructed_message(entity.string, translation)\n)\n@@ -70,12 +71,23 @@ def get_translations(entity, locale):\n# Else fetch from google translate\nelif locale.google_translate_code:\n+ gt_input = (\n+ entity.string.replace(entity.key, UNTRANSLATABLE_KEY, 1)\n+ if entity.resource.format == \"ftl\"\n+ else entity.string\n+ )\n+\ngt_response = get_google_translate_data(\n- text=entity.string,\n+ text=gt_input,\nlocale=locale,\n)\nif gt_response[\"status\"]:\n+ if entity.string != gt_input:\n+ gt_response[\"translation\"] = gt_response[\"translation\"].replace(\n+ UNTRANSLATABLE_KEY, entity.key\n+ )\n+\nif entity.string_plural == \"\":\nstrings = [(gt_response[\"translation\"], None, gt_user)]\nelse:\n",
        "chatgpt_cot": "Refactor FormAction class in forms.py by adding new static methods for slot mapping and handling slot mappings based on intent and entity."
    },
    {
        "org_diff": "diff --git a/examples/simulate_fight_scenario.py b/examples/simulate_fight_scenario.py @@ -36,7 +36,7 @@ class FightBot(BotAI):\n# destroy command center\nawait self._client.debug_kill_unit([cc.tag])\n# destroy all workers\n- for w in self.units(UnitTypeId.SCV):\n+ for w in self.workers:\nawait self._client.debug_kill_unit([w.tag])\n# create marines\nawait self._client.debug_create_unit([[UnitTypeId.MARINE, 4, p, me]])\n",
        "org_msg": "use shorthand method",
        "sim_msg": "tutor does just the normal control scheme",
        "sim_diff": "diff --git a/tutor_bot.cfg b/tutor_bot.cfg @@ -23,8 +23,8 @@ goal_explosion_id = 1905\n[Model Configuration]\nmodel_package = models.fake_model\nmodel_name = FakeModel\n-control_scheme = regression_controls\n-#teacher_package = TutorialBot.tutorial_bot_output\n-teacher_package = TutorialBot.atba2_demo_output\n+control_scheme = regression_everything\n+teacher_package = TutorialBot.tutorial_bot_output\n+#teacher_package = TutorialBot.atba2_demo_output\nbatch_size = 1\nmini_batch_size = 1\n",
        "chatgpt_cot": "\"Refactor destroy workers logic in FightBot class to use self.workers for consistency and readability\""
    },
    {
        "org_diff": "diff --git a/fkie_node_manager_daemon/src/fkie_node_manager_daemon/launcher.py b/fkie_node_manager_daemon/src/fkie_node_manager_daemon/launcher.py @@ -154,7 +154,7 @@ def run_node(startcfg):\nargs = []\nfor arg in startcfg.args:\nnew_arg = arg\n- if arg.startswith('pkg://'):\n+ if arg.startswith('$(find'):\nnew_arg = interpret_path(arg)\nrospy.logdebug(\"interpret arg '%s' to '%s'\" % (arg, new_arg))\nargs.append(new_arg)\n",
        "org_msg": "fkie_node_manager_daemon: fixed resolve find in args",
        "sim_msg": "define arg types",
        "sim_diff": "diff --git a/scripts/dht_node.py b/scripts/dht_node.py @@ -32,7 +32,7 @@ async def main(host: str, port: int):\nif __name__ == '__main__':\nparser = argparse.ArgumentParser(\ndescription=\"Starts a single DHT node, which then can be used as a seed node or just a contributing node.\")\n- parser.add_argument(\"--host\", default='0.0.0.0', help=\"Host to listen for requests. Default: 0.0.0.0\")\n- parser.add_argument(\"--port\", default=4444, help=\"Port to listen for requests. Default: 4444\")\n+ parser.add_argument(\"--host\", default='0.0.0.0', type=str, help=\"Host to listen for requests. Default: 0.0.0.0\")\n+ parser.add_argument(\"--port\", default=4444, type=int, help=\"Port to listen for requests. Default: 4444\")\nargs = parser.parse_args()\nasyncio.run(main(args.host, args.port))\n",
        "chatgpt_cot": "\"Fix interpretation of package path in launcher.py\""
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/editor/text_search_thread.py b/node_manager_fkie/src/node_manager_fkie/editor/text_search_thread.py @@ -110,7 +110,7 @@ class TextSearchThread(QObject, threading.Thread):\nif not self._isrunning:\nbreak\nif recursive:\n- self.search(search_text, incf)\n+ self.search(search_text, incf, recursive)\ndef _get_text(self, path):\nif path in self._path_text:\n",
        "org_msg": "node_manager_fkie: editor: fix recursive search",
        "sim_msg": "#update thread_name",
        "sim_diff": "diff --git a/QUANTAXIS/QAEngine/QAThreadEngine.py b/QUANTAXIS/QAEngine/QAThreadEngine.py @@ -56,7 +56,7 @@ class QA_Thread(threading.Thread):\nself.daemon=daemon\ndef __repr__(self):\n- return '<QA_Thread{} id={} ident {}>'.format(self.name, id(self), self.ident)\n+ return '<QA_Thread: {} id={} ident {}>'.format(self.name, id(self), self.ident)\ndef run(self):\nwhile self.__running.isSet():\n",
        "chatgpt_cot": "Add recursive parameter to search method in TextSearchThread. Fix the recursion issue in the file."
    },
    {
        "org_diff": "diff --git a/examples/terran/ramp_wall.py b/examples/terran/ramp_wall.py @@ -29,7 +29,7 @@ class RampWallBot(sc2.BotAI):\n# Raise depos when enemies are nearby\nfor depo in self.structures(SUPPLYDEPOT).ready:\nfor unit in self.enemy_units:\n- if unit.position.distance_to(depo) < 15:\n+ if unit.distance_to(depo) < 15:\nbreak\nelse:\nself.do(depo(MORPH_SUPPLYDEPOT_LOWER))\n@@ -37,7 +37,7 @@ class RampWallBot(sc2.BotAI):\n# Lower depos when no enemies are nearby\nfor depo in self.structures(SUPPLYDEPOTLOWERED).ready:\nfor unit in self.enemy_units:\n- if unit.position.distance_to(depo) < 10:\n+ if unit.distance_to(depo) < 10:\nself.do(depo(MORPH_SUPPLYDEPOT_RAISE))\nbreak\n@@ -66,6 +66,9 @@ class RampWallBot(sc2.BotAI):\n# Draw some example boxes around units, lines towards command center, text on the screen and barracks\n# self.draw_example()\n+ # Draw if two selected units are facing each other - green if this guy is facing the other, red if he is not\n+ # self.draw_facing_units()\n+\n# Filter locations close to finished supply depots\nif depots:\ndepot_placement_positions = {d for d in depot_placement_positions if depots.closest_distance_to(d) > 1}\n@@ -198,6 +201,21 @@ class RampWallBot(sc2.BotAI):\nself._client.debug_text_screen(text=\"Hello world!\", pos=Point2((0, 0)), color=None, size=16)\nself._client.debug_text_simple(text=\"Hello world2!\")\n+ def draw_facing_units(self):\n+ \"\"\" Draws green box on top of selected_unit2, if selected_unit2 is facing selected_unit1 \"\"\"\n+ selected_unit1: Unit\n+ selected_unit2: Unit\n+ red = Point3((255, 0, 0))\n+ green = Point3((0, 255, 0))\n+ for selected_unit1 in (self.units | self.structures).selected:\n+ for selected_unit2 in self.units.selected:\n+ if selected_unit1 == selected_unit2:\n+ continue\n+ if selected_unit2.is_facing_unit(selected_unit1):\n+ self._client.debug_box2_out(selected_unit2, half_vertex_length=0.25, color=green)\n+ else:\n+ self._client.debug_box2_out(selected_unit2, half_vertex_length=0.25, color=red)\n+\ndef main():\nmap = random.choice(\n@@ -217,7 +235,7 @@ def main():\n]\n)\nsc2.run_game(\n- sc2.maps.get(map), [Bot(Race.Terran, RampWallBot()), Computer(Race.Zerg, Difficulty.Hard)], realtime=False\n+ sc2.maps.get(map), [Bot(Race.Terran, RampWallBot()), Computer(Race.Zerg, Difficulty.Hard)], realtime=True\n)\n",
        "org_msg": "Add is_facing function",
        "sim_msg": "Fixing wrong documentation.",
        "sim_diff": "diff --git a/v7/latex_formula_renderer/latex_formula_renderer.py b/v7/latex_formula_renderer/latex_formula_renderer.py @@ -592,10 +592,10 @@ class LaTeXFormulaRendererPlugin(Task):\n* ``\"inline\"`` (standard inline formula);\n* ``\"display\"`` (standard display-style formula);\n* ``\"align\"`` (formula in an ``align*`` environment);\n- * ``(\"pstricks\", xx)`` (for content in a ``tikzpicture`` environment),\n+ * ``(\"tikzpicture\", xx)`` (for content in a ``tikzpicture`` environment),\nwith ``xx`` either being ``None`` or the content of the argument to\nthe ``tikzpicture`` environment;\n- * ``(\"tikzpicure\", { \"left\": xx, \"right\": xx, \"top\": xx, \"bottom\": xx, \"unit\": yy })``\n+ * ``(\"pstricks\", { \"left\": xx, \"right\": xx, \"top\": xx, \"bottom\": xx, \"unit\": yy })``\nwhere ``xx`` are numbers and yy is a string (content in an\n``pstricks`` environment).\n",
        "chatgpt_cot": "Refactor facing_units visualization, fix distance comparison in structure placement, and update game settings to run in real-time mode."
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/main_window.py b/node_manager_fkie/src/node_manager_fkie/main_window.py @@ -1910,13 +1910,13 @@ class MainWindow(QMainWindow):\ndef on_description_anchorClicked(self, url):\nself._accept_next_update = True\nif url.toString().startswith('open-sync-dialog://'):\n- self.on_sync_dialog_released(False, self._url_path(url).replace('open-sync-dialog', 'http'), True)\n+ self.on_sync_dialog_released(False, url.toString().replace('open-sync-dialog', 'http'), True)\nelif url.toString().startswith('show-all-screens://'):\n- master = self.getMaster(self._url_path(url).replace('show-all-screens', 'http'), False)\n+ master = self.getMaster(url.toString().replace('show-all-screens', 'http'), False)\nif master is not None:\nmaster.on_show_all_screens()\nelif url.toString().startswith('remove-all-launch-server://'):\n- master = self.getMaster(self._url_path(url).replace('remove-all-launch-server', 'http'), False)\n+ master = self.getMaster(url.toString().replace('remove-all-launch-server', 'http'), False)\nif master is not None:\nmaster.on_remove_all_launch_server()\nelif url.toString().startswith('node://'):\n",
        "org_msg": "node_manager_fkie: fixed call of host url options",
        "sim_msg": "fixed undefined variable problem",
        "sim_diff": "diff --git a/pacu.py b/pacu.py @@ -558,7 +558,7 @@ class Main:\nexcept botocore.exceptions.ProfileNotFound as error:\nself.print('\\n Did not find the AWS CLI profile: {}\\n'.format(profile_name))\nboto3_session = boto3.session.Session()\n- print(' Profiles that are available:\\n {}\\n'.format('\\n '.join(session.available_profiles)))\n+ print(' Profiles that are available:\\n {}\\n'.format('\\n '.join(boto3_session.available_profiles)))\ndef run_aws_cli_command(self, command):\ntry:\n@@ -687,14 +687,15 @@ class Main:\nprint('No listeners are running.')\nelse:\nif not proxy_target_agent == []:\n+ for i, conn in enumerate(self.server.all_connections):\n+ if self.server.all_addresses[i][0] == proxy_target_agent[0]:\nif proxy_target_agent[-1].startswith('Windows'):\npass\n- # for i, conn in enumerate(self.server.all_connections):\n- # if self.server.all_addresses[i][0] == proxy_target_agent[0]:\n# self.server.run_cmd(proxy_target_agent[0], self.server.all_connections[i], 'Stop-PortForwardJobs')\n# break\nelse:\nself.server.run_cmd(proxy_target_agent[0], self.server.all_connections[i], 'kill -9 $! && rm /dev/shm/{}'.format(shm_name))\n+ break\nself.server.quit_gracefully()\nself.queue.put(5)\nself.server = None\n@@ -719,14 +720,15 @@ class Main:\ntry:\nif command[2] == 'none':\nself.print('** No longer using a remote PacuProxy agent to route commands. **')\n+ for i, conn in enumerate(self.server.all_connections):\n+ if self.server.all_addresses[i][0] == proxy_target_agent[0]:\nif proxy_target_agent[-1].startswith('Windows'):\npass\n- # for i, conn in enumerate(self.server.all_connections):\n- # if self.server.all_addresses[i][0] == proxy_target_agent[0]:\n- # self.server.run_cmd(proxy_target_agent[0], self.server.all_connections[i], 'powershell Stop-PortForwardJobs')\n+ # self.server.run_cmd(proxy_target_agent[0], self.server.all_connections[i], 'Stop-PortForwardJobs')\n# break\nelse:\nself.server.run_cmd(proxy_target_agent[0], self.server.all_connections[i], 'kill -9 $! && rm /dev/shm/{}'.format(shm_name))\n+ break\nproxy_target_agent = []\nelse:\nproxy_target_agent = self.server.all_addresses[int(command[2])]\n",
        "chatgpt_cot": "\"Fix URL path replacement in MainWindow.py\""
    },
    {
        "org_diff": "diff --git a/fkie_node_manager/src/fkie_node_manager/settings.py b/fkie_node_manager/src/fkie_node_manager/settings.py @@ -626,33 +626,36 @@ class Settings(object):\n:return: command with a terminal prefix\n:rtype: str\n'''\n- if self._terminal_emulator is None:\n- self._terminal_emulator = ''\n+ terminal_emulator = ''\n+ terminal_title = self._terminal_title\n+ noclose_str = self._noclose_str\n+ terminal_command_arg = self._terminal_command_arg\nfor t in ['/usr/bin/x-terminal-emulator', '/usr/bin/xterm', '/opt/x11/bin/xterm']:\nif os.path.isfile(t) and os.access(t, os.X_OK):\n+ print(os.path.basename(os.path.realpath(t)))\n# workaround to support the command parameter in different terminal\nif os.path.basename(os.path.realpath(t)) in ['terminator', 'gnome-terminal', 'xfce4-terminal']:\n- self._terminal_command_arg = 'x'\n+ terminal_command_arg = 'x'\nelse:\n- self._terminal_command_arg = 'e'\n+ terminal_command_arg = 'e'\nif os.path.basename(os.path.realpath(t)) in ['terminator', 'gnome-terminal', 'gnome-terminal.wrapper']:\n- self._noclose_str = '--profile hold'\n+ noclose_str = '--profile hold'\nif noclose:\nrospy.loginfo(\"If your terminal close after the execution, you can change this behavior in \"\n\"profiles. You can also create a profile with name 'hold'. This profile will \"\n\"be then load by node_manager.\")\n- elif os.path.basename(os.path.realpath(t)) in ['xfce4-terminal']:\n- self._noclose_str = ''\n- self._terminal_title = '-T'\n- self._terminal_emulator = t\n+ elif os.path.basename(os.path.realpath(t)) in ['xfce4-terminal', 'xterm', 'lxterm', 'uxterm']:\n+ noclose_str = ''\n+ terminal_title = '-T'\n+ terminal_emulator = t\nbreak\n- if self._terminal_emulator == '':\n+ if terminal_emulator == '':\nraise Exception(\"No Terminal found! Please install one of ['/usr/bin/x-terminal-emulator', '/usr/bin/xterm', '/opt/x11/bin/xterm']\")\n- self._noclose_str = self._noclose_str if noclose else ''\n+ noclose_str = noclose_str if noclose else ''\ntitle_opt = ''\nif title:\n- title_opt = '%s \"%s\"' % (self._terminal_title, title)\n- return '%s %s %s -%s %s' % (self._terminal_emulator, title_opt, self._noclose_str, self._terminal_command_arg, ' '.join(cmd))\n+ title_opt = '%s \"%s\"' % (terminal_title, title)\n+ return '%s %s %s -%s %s' % (terminal_emulator, title_opt, noclose_str, terminal_command_arg, ' '.join(cmd))\ndef qsettings(self, settings_file):\npath = settings_file\n",
        "org_msg": "fkie_node_manager: changed terminal detection",
        "sim_msg": "reinstate hacky code",
        "sim_diff": "diff --git a/shutit_pexpect.py b/shutit_pexpect.py @@ -490,27 +490,27 @@ class ShutItPexpectSession(object):\n# Don't use send here (will mess up last_output)!\n# Space before \"echo\" here is sic - we don't need this to show up in bash history\nself.sendline(' echo EXIT_CODE:$?')\n- #while True:\n- # Sometimes pexpect gets confused at this point (TODO why?), so we expect again until all appears ok.\n+ while True:\n+ # Sometimes pexpect gets confused at this point (TODO why? - repro'd in shutitfiles test, stalls after a login), so we expect again until all appears ok.\nshutit.log('Expecting: ' + str(expect),level=logging.DEBUG)\nself.expect(expect,timeout=60)\nres = shutit_util.match_string(str(self.pexpect_child.before), '^EXIT_CODE:([0-9][0-9]?[0-9]?)$')\n- #if res is None and (isinstance(self.pexpect_child.before, pexpect.exceptions.EOF) or isinstance(self.pexpect_child.after, pexpect.exceptions.EOF)):\n- # shutit_util.handle_exit(1)\n- #if res is None:\n- # # Try before without anchor - sometimes needed when logging into obscure shells\n- # shutit.log('Un-clean login (1), trying: ' + str(self.pexpect_child.before), level=logging.DEBUG)\n- # res = shutit_util.match_string(str(self.pexpect_child.before), '.*EXIT_CODE:([0-9][0-9]?[0-9]?)$')\n- #if res is None:\n- # # Try after - for some reason needed after login\n- # shutit.log('Un-clean login (2), trying: ' + str(self.pexpect_child.after), level=logging.DEBUG)\n- # res = shutit_util.match_string(str(self.pexpect_child.after), '^EXIT_CODE:([0-9][0-9]?[0-9]?)$')\n- #if res is None:\n- # # Try after without anchor - sometimes needed when logging into obscure\n- # shutit.log('Un-clean login (3), trying: ' + str(self.pexpect_child.after), level=logging.DEBUG)\n- # res = shutit_util.match_string(str(self.pexpect_child.after), '^.*EXIT_CODE:([0-9][0-9]?[0-9]?)$')\n- #if res != None:\n- # break\n+ if res is None and (isinstance(self.pexpect_child.before, pexpect.exceptions.EOF) or isinstance(self.pexpect_child.after, pexpect.exceptions.EOF)):\n+ shutit_util.handle_exit(1)\n+ if res is None:\n+ # Try before without anchor - sometimes needed when logging into obscure shells\n+ shutit.log('Un-clean login (1), trying: ' + str(self.pexpect_child.before), level=logging.DEBUG)\n+ res = shutit_util.match_string(str(self.pexpect_child.before), '.*EXIT_CODE:([0-9][0-9]?[0-9]?)$')\n+ if res is None:\n+ # Try after - for some reason needed after login\n+ shutit.log('Un-clean login (2), trying: ' + str(self.pexpect_child.after), level=logging.DEBUG)\n+ res = shutit_util.match_string(str(self.pexpect_child.after), '^EXIT_CODE:([0-9][0-9]?[0-9]?)$')\n+ if res is None:\n+ # Try after without anchor - sometimes needed when logging into obscure\n+ shutit.log('Un-clean login (3), trying: ' + str(self.pexpect_child.after), level=logging.DEBUG)\n+ res = shutit_util.match_string(str(self.pexpect_child.after), '^.*EXIT_CODE:([0-9][0-9]?[0-9]?)$')\n+ if res != None:\n+ break\nif res not in exit_values or res is None:\nif res is None:\nres_str = str(res)\n",
        "chatgpt_cot": "Refactor terminal settings in Settings.py for better readability and maintainability by using local variables instead of class attributes."
    },
    {
        "org_diff": "diff --git a/sc2/client.py b/sc2/client.py @@ -169,15 +169,16 @@ class Client(Protocol):\n))\nreturn [ActionResult(p.result) for p in result.query.placements]\n- async def query_available_abilities(self, unit):\n- assert isinstance(unit, Unit)\n+ async def query_available_abilities(self, units):\n+ if not isinstance(units, list):\n+ assert isinstance(units, Unit)\n+ units = [units]\n+ assert len(units) > 0\nresult = await self._execute(query=query_pb.RequestQuery(\nabilities=[query_pb.RequestQueryAvailableAbilities(\n- unit_tag=unit.tag\n- )]\n+ unit_tag=unit.tag) for unit in units]\n))\n- return [AbilityId(a.ability_id) for a in result.query.abilities[0].abilities]\n-\n+ return [[AbilityId(a.ability_id) for a in b.abilities] for b in result.query.abilities]\nasync def chat_send(self, message, team_only):\nch = ChatChannel.Team if team_only else ChatChannel.Broadcast\n",
        "org_msg": "Change query_available_abilities to allow multiple per call requests",
        "sim_msg": "add assets, activate, download to client",
        "sim_diff": "diff --git a/planet/api/client.py b/planet/api/client.py @@ -296,3 +296,15 @@ class ClientV1(_Base):\nreturn self.dispatcher.response(models.Request(\nself._url('data/v1/stats'), self.auth,\nbody_type=models.JSON, data=body, method='POST')).get_body()\n+\n+ def get_assets(self, item):\n+ assets_url = item['_links']['assets']\n+ return self._get(assets_url).get_body()\n+\n+ def activate(self, asset):\n+ activate_url = asset['_links']['activate']\n+ return self._get(activate_url).get_body()\n+\n+ def download(self, asset, callback=None):\n+ download_url = asset['location']\n+ return self._get(download_url, models.Image, callback=callback)\n",
        "chatgpt_cot": "Fix compilation issue with query_available_abilities method in Client class. Changed parameter name and added input validation to handle single unit input."
    },
    {
        "org_diff": "diff --git a/fkie_node_manager_daemon/src/fkie_node_manager_daemon/screen.py b/fkie_node_manager_daemon/src/fkie_node_manager_daemon/screen.py @@ -161,7 +161,7 @@ def test_screen():\nraise ScreenException(SCREEN, \"%s is missing\" % SCREEN)\n-def get_logfile(session=None, node=None):\n+def get_logfile(session=None, node=None, for_new_screen=False):\n'''\nGenerates a log file name of the ROS log.\n@@ -177,7 +177,7 @@ def get_logfile(session=None, node=None):\nreturn path\nif node is not None:\npath = \"%s%s.log\" % (LOG_PATH, create_session_name(node))\n- if os.path.exists(path):\n+ print('RETURN PATH', path)\nreturn path\nreturn get_ros_logfile(node)\n@@ -240,7 +240,7 @@ def get_cmd(node, env=[], keys=[]):\nshell = '-/bin/bash'\nif 'SHELL' in os.environ:\nshell = '-%s' % os.environ['SHELL']\n- return '%s -O -L -Logfile %s -s %s -dmS %s' % (SCREEN, get_logfile(node=node), shell, create_session_name(node=node))\n+ return '%s -O -L -Logfile %s -s %s -dmS %s' % (SCREEN, get_logfile(node=node, for_new_screen=True), shell, create_session_name(node=node))\ndef rosclean():\n",
        "org_msg": "fkie_node_manager: fixed open echo dialog",
        "sim_msg": "Fixing monitor attribute name",
        "sim_diff": "diff --git a/src/app/beer_garden/monitor.py b/src/app/beer_garden/monitor.py @@ -87,7 +87,7 @@ class MonitorFile:\nif path:\nself.path = os.path.split(path)[0]\nself.create_event = create_event\n- self.modified = modified_event\n+ self.modified_event = modified_event\nself.moved_event = moved_event\nself.deleted_event = deleted_event\n",
        "chatgpt_cot": "Add optional parameter to get_logfile function and update function calls to include new parameter for_new_screen."
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/master_view_proxy.py b/node_manager_fkie/src/node_manager_fkie/master_view_proxy.py @@ -2740,15 +2740,27 @@ class MasterViewProxy(QWidget):\ncalls a service.\n'''\nselectedServices = self.servicesFromIndexes(self.masterTab.servicesView.selectionModel().selectedIndexes())\n+ try:\nfor service in selectedServices:\nparam = ServiceDialog(service, self)\nparam.show()\n+ except Exception, e:\n+ rospy.logwarn(\"Call service '%s' failed: %s\" % (service.name, utf8(e)))\n+ MessageBox.warning(self, \"Call service error\",\n+ 'Call service %s failed!' % service.name,\n+ '%s' % utf8(e))\ndef service_call(self, service_name):\nservice = self.master_info.getService(utf8(service_name))\nif service is not None:\n+ try:\nparam = ServiceDialog(service, self)\nparam.show()\n+ except Exception, e:\n+ rospy.logwarn(\"Call service '%s' failed: %s\" % (service.name, utf8(e)))\n+ MessageBox.warning(self, \"Call service error\",\n+ 'Call service %s failed!' % service.name,\n+ '%s' % utf8(e))\ndef on_node_filter_changed(self, text):\n'''\n",
        "org_msg": "node_manager_fkie: fixed crash on call of an unknown service",
        "sim_msg": "feat(service): Dynamic port allocation",
        "sim_diff": "diff --git a/service.py b/service.py import threading\nimport SocketServer\nimport xbmc\n+import xbmcaddon\n+import socket\nfrom resources.lib.common import log\nfrom resources.lib.MSLHttpRequestHandler import MSLHttpRequestHandler\n-PORT = 8000\n+def select_unused_port():\n+ s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n+ s.bind(('localhost', 0))\n+ addr, port = s.getsockname()\n+ s.close()\n+ return port\n+\n+addon = xbmcaddon.Addon()\n+PORT = select_unused_port()\n+addon.setSetting('msl_service_port', str(PORT))\n+log(\"Picked Port: \" + str(PORT))\nHandler = MSLHttpRequestHandler\nSocketServer.TCPServer.allow_reuse_address = True\nserver = SocketServer.TCPServer(('127.0.0.1', PORT), Handler)\n",
        "chatgpt_cot": "Fix exception handling in service calls in MasterViewProxy to display error message and log warning when service call fails."
    },
    {
        "org_diff": "diff --git a/fkie_node_manager/src/fkie_node_manager/message_frame.py b/fkie_node_manager/src/fkie_node_manager/message_frame.py @@ -246,7 +246,7 @@ class MessageFrame(QFrame):\nself.frameui.setVisible(False)\ntry:\n# set action for do not ask again\n- if self._do_not_ask[self.questionid] == 2:\n+ if self.frameui.checkBox_dnaa.isChecked():\nself._do_not_ask[self.questionid] = 1\nexcept Exception:\npass\n@@ -261,7 +261,7 @@ class MessageFrame(QFrame):\nself.frameui.setVisible(False)\ntry:\n# set action for do not ask again\n- if self._do_not_ask[self.questionid] == 2:\n+ if self.frameui.checkBox_dnaa.isChecked():\nself._do_not_ask[self.questionid] = 0\nexcept Exception:\npass\n@@ -307,8 +307,6 @@ class MessageFrame(QFrame):\nelif self.questionid == self.TYPE_NOSCREEN:\nself.frameui.questionCancelButton.setVisible(not state)\nnm.settings().show_noscreen_error = not state\n- else:\n- self._do_not_ask[self.questionid] = 2\ndef _clear_scroll_area(self):\nchild = self.frameui.scrollAreaLayout.takeAt(0)\n",
        "org_msg": "fkie_node_manager: fixed no ask field in restart/reload dialog",
        "sim_msg": "Update forcemention.py\ndecrease sleep cause more better",
        "sim_diff": "diff --git a/forcemention/forcemention.py b/forcemention/forcemention.py @@ -50,7 +50,7 @@ class ForceMention(commands.Cog):\nelif channel.permissions_for(channel.guild.me).manage_roles:\nawait role.edit(mentionable=True)\nawait channel.send(message, allowed_mentions=mentionPerms, **kwargs)\n- await asyncio.sleep(5)\n+ await asyncio.sleep(1.5)\nawait role.edit(mentionable=False)\nelse:\nawait channel.send(message, allowed_mentions=mentionPerms, **kwargs)\n",
        "chatgpt_cot": "Update action for \"do not ask again\" based on checkbox state in MessageFrame to ensure correct behavior and improve user experience."
    },
    {
        "org_diff": "diff --git a/fkie_node_manager/src/fkie_node_manager/MainWindow.ui b/fkie_node_manager/src/fkie_node_manager/MainWindow.ui <property name=\"windowTitle\">\n<string>ROS Node Manager</string>\n</property>\n+ <property name=\"toolTip\">\n+ <string>Go to the root of the help</string>\n+ </property>\n<property name=\"locale\">\n<locale language=\"English\" country=\"UnitedStates\"/>\n</property>\n@@ -792,7 +795,7 @@ p, li { white-space: pre-wrap; }\n<number>0</number>\n</property>\n<item>\n- <widget class=\"QPushButton\" name=\"ui_help_back\">\n+ <widget class=\"QPushButton\" name=\"ui_help_home\">\n<property name=\"sizePolicy\">\n<sizepolicy hsizetype=\"Minimum\" vsizetype=\"Minimum\">\n<horstretch>0</horstretch>\n@@ -805,8 +808,8 @@ p, li { white-space: pre-wrap; }\n<height>26</height>\n</size>\n</property>\n- <property name=\"text\">\n- <string>back</string>\n+ <property name=\"icon\">\n+ <iconset theme=\"go-home\"/>\n</property>\n<property name=\"flat\">\n<bool>true</bool>\n@@ -814,7 +817,7 @@ p, li { white-space: pre-wrap; }\n</widget>\n</item>\n<item>\n- <widget class=\"QPushButton\" name=\"ui_help_home\">\n+ <widget class=\"QPushButton\" name=\"ui_help_back\">\n<property name=\"sizePolicy\">\n<sizepolicy hsizetype=\"Minimum\" vsizetype=\"Minimum\">\n<horstretch>0</horstretch>\n@@ -827,8 +830,11 @@ p, li { white-space: pre-wrap; }\n<height>26</height>\n</size>\n</property>\n- <property name=\"text\">\n- <string>home</string>\n+ <property name=\"toolTip\">\n+ <string>Go back in history</string>\n+ </property>\n+ <property name=\"icon\">\n+ <iconset theme=\"go-previous\"/>\n</property>\n<property name=\"flat\">\n<bool>true</bool>\n@@ -849,8 +855,11 @@ p, li { white-space: pre-wrap; }\n<height>26</height>\n</size>\n</property>\n- <property name=\"text\">\n- <string>forward</string>\n+ <property name=\"statusTip\">\n+ <string>Go forward in history</string>\n+ </property>\n+ <property name=\"icon\">\n+ <iconset theme=\"go-next\"/>\n</property>\n<property name=\"flat\">\n<bool>true</bool>\n",
        "org_msg": "added theme icons to the help view",
        "sim_msg": "buttons to enter and exit edit mode",
        "sim_diff": "diff --git a/GUI_UIs/ui_dialog_code_text.ui b/GUI_UIs/ui_dialog_code_text.ui <rect>\n<x>0</x>\n<y>0</y>\n- <width>1024</width>\n+ <width>1054</width>\n<height>695</height>\n</rect>\n</property>\n<string>Code Text</string>\n</property>\n<layout class=\"QGridLayout\" name=\"gridLayout_2\">\n+ <item row=\"1\" column=\"0\">\n+ <widget class=\"QGroupBox\" name=\"groupBox_edit_mode\">\n+ <property name=\"minimumSize\">\n+ <size>\n+ <width>0</width>\n+ <height>80</height>\n+ </size>\n+ </property>\n+ <property name=\"maximumSize\">\n+ <size>\n+ <width>16777215</width>\n+ <height>80</height>\n+ </size>\n+ </property>\n+ <property name=\"title\">\n+ <string/>\n+ </property>\n+ <layout class=\"QGridLayout\" name=\"gridLayout_3\">\n+ <item row=\"1\" column=\"1\">\n+ <widget class=\"QPushButton\" name=\"pushButton_exit_edit\">\n+ <property name=\"minimumSize\">\n+ <size>\n+ <width>28</width>\n+ <height>28</height>\n+ </size>\n+ </property>\n+ <property name=\"maximumSize\">\n+ <size>\n+ <width>28</width>\n+ <height>28</height>\n+ </size>\n+ </property>\n+ <property name=\"toolTip\">\n+ <string>Exit Edit text </string>\n+ </property>\n+ <property name=\"text\">\n+ <string/>\n+ </property>\n+ </widget>\n+ </item>\n+ <item row=\"0\" column=\"0\" rowspan=\"2\">\n+ <widget class=\"QLabel\" name=\"label_editing\">\n+ <property name=\"enabled\">\n+ <bool>true</bool>\n+ </property>\n+ <property name=\"maximumSize\">\n+ <size>\n+ <width>16777215</width>\n+ <height>76</height>\n+ </size>\n+ </property>\n+ <property name=\"text\">\n+ <string/>\n+ </property>\n+ <property name=\"wordWrap\">\n+ <bool>true</bool>\n+ </property>\n+ </widget>\n+ </item>\n+ </layout>\n+ </widget>\n+ </item>\n<item row=\"0\" column=\"0\">\n<widget class=\"QGroupBox\" name=\"groupBox\">\n<property name=\"minimumSize\">\n</rect>\n</property>\n<property name=\"toolTip\">\n- <string>Edit text mode.\n-You can click on a position, without selecting text, to type, delete, or paste text.\n-You can select text that is not underlined and delete or paste over.\n+ <string>Edit text\n+Click on a position, without selecting text, to type, delete, or paste text.\n+Select text that is not underlined and delete or paste over.\nAvoid selecting text to delete or paste over if the selected text is underlined:\n(coded - red, annotated - yellow, case-assigned - green)\n-As all assigned positions may be wrong. </string>\n+As all assigned positions may be incorrect. </string>\n</property>\n<property name=\"text\">\n<string/>\n@@ -487,25 +549,6 @@ As all assigned positions may be wrong. </string>\n</widget>\n</widget>\n</item>\n- <item row=\"1\" column=\"0\">\n- <widget class=\"QLabel\" name=\"label_editing\">\n- <property name=\"enabled\">\n- <bool>true</bool>\n- </property>\n- <property name=\"maximumSize\">\n- <size>\n- <width>16777215</width>\n- <height>80</height>\n- </size>\n- </property>\n- <property name=\"text\">\n- <string/>\n- </property>\n- <property name=\"wordWrap\">\n- <bool>true</bool>\n- </property>\n- </widget>\n- </item>\n<item row=\"2\" column=\"0\">\n<widget class=\"QSplitter\" name=\"splitter\">\n<property name=\"orientation\">\n",
        "chatgpt_cot": "Add tooltips and icons to help buttons for navigation in MainWindow.ui to improve user experience and clarify functionality."
    },
    {
        "org_diff": "diff --git a/sc2/bot_ai.py b/sc2/bot_ai.py @@ -27,6 +27,11 @@ class BotAI(object):\nEXPANSION_GAP_THRESHOLD = 15\n+ def __init__(self):\n+ # Specific opponent bot ID used in sc2ai ladder games http://sc2ai.net/\n+ # The bot ID will stay the same each game so your bot can \"adapt\" to the opponent\n+ self.opponent_id: int = None\n+\n@property\ndef enemy_race(self) -> Race:\nself.enemy_id = 3 - self.player_id\n",
        "org_msg": "Add opponent_id to bot class for sc2ai ladder",
        "sim_msg": "Forgot to update iNumPlayers",
        "sim_diff": "diff --git a/v3/runner.py b/v3/runner.py @@ -63,6 +63,8 @@ if __name__ == '__main__':\ncallbacks = []\nname_dict = dict()\n+ gameInputPacket.iNumPlayers = num_bots\n+\n# Set configuration values for bots and store name and team\nfor i in range(num_bots):\nbot_config = configparser.RawConfigParser()\n",
        "chatgpt_cot": "Add initialization method with opponent_id attribute to adapt to specific opponent bot ID in sc2ai ladder games, enhancing bot adaptability and performance."
    },
    {
        "org_diff": "diff --git a/sc2/main.py b/sc2/main.py @@ -126,6 +126,9 @@ async def _play_game_ai(client, player_id, ai, realtime, step_time_limit, game_t\nout_of_budget = False\nbudget = time_limit - time_window.available\n+ # Tell the bot how much time it has left attribute\n+ ai.time_budget_available = budget\n+\nif budget < 0:\nlogger.warning(f\"Running AI step: out of budget before step\")\nstep_time = 0.0\n",
        "org_msg": "Inform bot about it's time budget with it's limited",
        "sim_msg": "Adds the ability to save to input data to file\nThis saves real same input as the skeleton tf model to a file.",
        "sim_diff": "diff --git a/bot_manager.py b/bot_manager.py @@ -90,6 +90,10 @@ class BotManager:\nplayer_input.bBoost = controller_input[6]\nplayer_input.bHandbrake = controller_input[7]\n+ if self.save_data and game_tick_packet.gameInfo.bRoundActive and old_time is not 0 and not old_time == current_time:\n+ self.game_file.writelines(str(self.create_input_array(game_tick_packet)) + '\\n')\n+ self.game_file.writelines(str(controller_input) + '\\n')\n+\n# Ratelimit here\nafter = datetime.now()\n# print('Latency of ' + self.name + ': ' + str(after - before))\n@@ -99,5 +103,16 @@ class BotManager:\n# If terminated, send callback\nself.callbackEvent.set()\n-\n-\n+ def create_input_array(self, gameTickPacket):\n+ return [\n+ gameTickPacket.gameball.Location.X,\n+ gameTickPacket.gameball.Location.Y,\n+ gameTickPacket.gamecars[self.index].Location.X,\n+ gameTickPacket.gamecars[self.index].Location.Y,\n+ float(gameTickPacket.gamecars[self.index].Rotation.Pitch),\n+ float(gameTickPacket.gamecars[self.index].Rotation.Yaw),\n+ gameTickPacket.gamecars[enemy_index].Location.X,\n+ gameTickPacket.gamecars[enemy_index].Location.Y,\n+ float(gameTickPacket.gamecars[enemy_index].Rotation.Pitch),\n+ float(gameTickPacket.gamecars[enemy_index].Rotation.Yaw),\n+ ]\n",
        "chatgpt_cot": "Add attribute to inform bot of time budget available to solve out of budget issue in SC2 main.py."
    },
    {
        "org_diff": "diff --git a/build_image/docker/common/nginx/nginx.conf.default b/build_image/docker/common/nginx/nginx.conf.default @@ -45,7 +45,7 @@ http {\n#access_log logs/host.access.log main;\nlocation $URL_PREFIX/static {\n- alias /var/www/server/static;\n+ alias /var/www/static;\n}\nlocation $URL_PREFIX {\n",
        "org_msg": "[Fix Rename static directory mapping\nChange from /var/www/server/static to /var/www/static.",
        "sim_msg": "Fixed 404 error on refresh of augur docker frontend.",
        "sim_diff": "diff --git a/util/docker/frontend/nginx.conf b/util/docker/frontend/nginx.conf @@ -25,6 +25,7 @@ http {\nlocation / {\nroot /usr/share/nginx/core/;\nindex index.html;\n+ try_files $uri $uri/ /index.html;\n}\nlocation /augurface/ {\nroot /usr/share/nginx/;\n",
        "chatgpt_cot": "Update nginx.conf.default to change the alias for static files from /var/www/server/static to /var/www/static."
    },
    {
        "org_diff": "diff --git a/src/agent/ansible/roles/deploy_compose/certsetup/templates/configtx.j2 b/src/agent/ansible/roles/deploy_compose/certsetup/templates/configtx.j2 @@ -12,6 +12,7 @@ Organizations:\nName: {{ org }}\nID: {{ org }}\nMSPDir: {{ fabricworkdir }}/keyfiles/{{ org }}/msp\n+{% if org in peerorgs %}\n{% if project_version | version_compare('1.2.0','>=') or 'stable' in project_version or project_version == 'latest' %}\nPolicies:\nReaders:\n@@ -29,7 +30,7 @@ Organizations:\n- Host: {{ org_anchor[org].name }}\nPort: 7051\n{% endif %}\n-{% else %}\n+{% elif org in ordererorgs %}\n{% if project_version | version_compare('1.2.0','>=') or 'stable' in project_version or project_version == 'latest' %}\nPolicies:\nReaders:\n@@ -42,6 +43,7 @@ Organizations:\nType: Signature\nRule: \"OR('{{ org }}.admin')\"\n{% endif %}\n+{% endif %}\n{% endfor %}\n{% endif %}\n",
        "org_msg": "Fixing configtx.j2 in cello/ansible k8s\nFixing configtx.j2 to include correct orderer organization policies\nfor v1.2",
        "sim_msg": "Use state \"present\" instead of \"installed\"\nThe latter is deprecated and due to be removed in Ansible v2.9.",
        "sim_diff": "diff --git a/ansible/roles/setup/tasks/main.yml b/ansible/roles/setup/tasks/main.yml become: yes\napt:\npkg: apt-transport-https\n- state: installed\n+ state: present\n- name: Add NodeSource apt signing key\nbecome: yes\nbecome: yes\napt:\npkg: \"{{ item }}\"\n- state: installed\n+ state: present\nwith_items:\n- apt-transport-https\n- ca-certificates\nbecome: yes\napt:\npkg: \"{{item}}\"\n- state: installed\n+ state: present\nwith_items:\n- nodejs\nbecome: yes\napt:\npkg: \"{{ item }}\"\n- state: installed\n+ state: present\nwith_items:\n- postgresql-9.5-postgis-2.2\n- postgresql-server-dev-9.5 # required for building pyscopg against correct postgres\n",
        "chatgpt_cot": "Add condition for different org types in configtx.j2 template to handle peer and orderer organizations separately. Fixing logic for organization type check."
    },
    {
        "org_diff": "diff --git a/src/agent/k8s/templates/orderer0.ordererorg-kafka.tpl b/src/agent/k8s/templates/orderer0.ordererorg-kafka.tpl @@ -106,6 +106,8 @@ spec:\nvalue: \"3\"\n- name: KAFKA_ZOOKEEPER_CONNECT\nvalue: \"zookeeper0:2181,zookeeper1:2181,zookeeper2:2181\"\n+ - name: KAFKA_ZOOKEEPER_CONNECTION_TIMEOUT_MS\n+ value: \"36000\"\n- name: KAFKA_ADVERTISED_HOST_NAME\nvalue: \"kafka0\"\nports:\n@@ -146,6 +148,8 @@ spec:\nvalue: \"3\"\n- name: KAFKA_ZOOKEEPER_CONNECT\nvalue: \"zookeeper0:2181,zookeeper1:2181,zookeeper2:2181\"\n+ - name: KAFKA_ZOOKEEPER_CONNECTION_TIMEOUT_MS\n+ value: \"36000\"\n- name: KAFKA_ADVERTISED_HOST_NAME\nvalue: \"kafka1\"\nports:\n@@ -186,6 +190,8 @@ spec:\nvalue: \"3\"\n- name: KAFKA_ZOOKEEPER_CONNECT\nvalue: \"zookeeper0:2181,zookeeper1:2181,zookeeper2:2181\"\n+ - name: KAFKA_ZOOKEEPER_CONNECTION_TIMEOUT_MS\n+ value: \"36000\"\n- name: KAFKA_ADVERTISED_HOST_NAME\nvalue: \"kafka2\"\nports:\n",
        "org_msg": "Kafka pods cannot be started successfully\nKafka pods cannot be started successfully(sometimes).\nThe kafka pods cannot connect to zookeepers  with timeout of\n6000 ms, therefore, set zookeeper.connection.timeout.ms = 36000.",
        "sim_msg": "Add metrics to read by wrapper",
        "sim_diff": "diff --git a/workloads/rpc-perf/rpc-perf.aurora b/workloads/rpc-perf/rpc-perf.aurora @@ -135,7 +135,7 @@ jobs = [\n'--log_level {log_level} --stderr 0 --prometheus_port {prom_port} '\n'--prometheus_ip {prom_ip} --labels \"{labels}\" '\n'--metric_name_prefix \"{application}_\" '\n- '--regexp \"(?P<name>p\\d*): (?P<value>\\d+)\" '\n+ '--regexp \"(?P<name>Success|Hit Rate|Rate|min|max|p\\d*): (?P<value>\\d+.\\d+)\" '\n'--kafka_topic {kafka_topic} '\n'--kafka_brokers {kafka_brokers}'.format(\nprotocol=rpcperf_protocol, ip=application_host_ip,\n",
        "chatgpt_cot": "Add KAFKA_ZOOKEEPER_CONNECTION_TIMEOUT_MS to orderer0.ordererorg-kafka.tpl for all Kafka instances to set the Zookeeper connection timeout to 36000 ms."
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/topic_list_model.py b/node_manager_fkie/src/node_manager_fkie/topic_list_model.py @@ -371,7 +371,7 @@ class TopicGroupItem(QStandardItem):\nitem = self.child(i)\nif isinstance(item, TopicGroupItem):\nif recursive:\n- result[len(result):] = item.get_node_items()\n+ result[len(result):] = item.get_topic_items()\nelif isinstance(item, TopicItem):\nresult.append(item)\nreturn result\n",
        "org_msg": "node_manager_fkie: fix crash on click on topics",
        "sim_msg": "Functions now work properly",
        "sim_diff": "diff --git a/Vyxal.py b/Vyxal.py @@ -131,6 +131,17 @@ class Stack(list):\ndef __getitem__(self, n):\nreturn self.contents[n]\n+ def __iadd__(self, rhs):\n+ if type(rhs) == type(self):\n+ self.contents += rhs.contents\n+ else:\n+ self.contents += rhs\n+ return self\n+\n+ def __add__(self, rhs):\n+ return self.contents + rhs\n+\n+\ndef pop(self, n=1):\nif n == 1:\nif len(self.contents):\n@@ -282,6 +293,7 @@ if __name__ == \"__main__\":\nfile_location = \"\"\nflags = \"\"\ninputs = []\n+ header = \"stack = Stack()\\nVY_reg_reps = 1\\nVY_reg = 0\\nprinted = False\\n\"\nif len(sys.argv) > 1:\nfile_location = sys.argv[1]\n@@ -290,10 +302,17 @@ if __name__ == \"__main__\":\nflags = sys.argv[2]\ninputs = list(map(eval,sys.argv[3:]))\n+\n+ if not file_location: #repl mode\n+ while 1:\n+ line = input(\">>> \")\n+ line = VyCompile(line)\n+ exec(header + line)\n+ print(stack)\n+ else:\nfile = open(file_location, \"r\", encoding=\"utf-8\")\ncode = file.read()\n- header = \"stack = Stack()\\nVY_reg_reps = 1\\nVY_reg = 0\\nprinted = False\\n\"\ncode = VyCompile(code)\nexec(header + code)\n",
        "chatgpt_cot": "\"Refactor get_node_items to get_topic_items in TopicGroupItem class for better clarity and consistency in topic_list_model.py\""
    },
    {
        "org_diff": "diff --git a/docs/setup/setup_master.md b/docs/setup/setup_master.md @@ -50,11 +50,11 @@ To start the whole services, please run\n$ SERVER_PUBLIC_IP=x.x.x.x make start\n```\n-This may take 1+ min till all services are up.\n+This may take 1+ min till all services are up. After all services containers are up, you can access the operator dashboard at x.x.x.x:8080, and user dashboard at x.x.x.x:8081.\nEnvironment variables which you can use in the command:\n-* `SERVER_PUBLIC_IP`(required): Master node's public IP address\n+* `SERVER_PUBLIC_IP`(required): Master node's public IP address, do not use `127.0.0.1`\n* `THEME`(optional): Theme name for operator dashboard basic/vue/react, default is basic\n* `NPM_REGISTRY`(optional):: npm registry for install node packages\n* `DEV`(optional):: Start service in dev/product mode, options is True/False, default is False\n@@ -109,7 +109,7 @@ To check the logs for one specific service, please run\n$ make log service=watchdog\n```\n-Now you can access the `MASTER_NODE_IP:8080` to open the Web-based [operation dashboard](../dashboard_operator.md).\n+Now you can access the `x.x.x.x:8080` to open the Web-based [operation dashboard](../dashboard_operator.md).\n### Configuration\nThe application configuration can be imported from file named `CELLO_CONFIG_FILE`.\n",
        "org_msg": "Add doc on dashboard URL\nThe dashboard needs to be accessed via the public IP, instead of\nlocal host.",
        "sim_msg": "chore: Add PR Links",
        "sim_diff": "diff --git a/frappe/change_log/v13/v13_0_0_beta_1.md b/frappe/change_log/v13/v13_0_0_beta_1.md ## Major Features\n-- New Desk (#9617)\n-- Child table pagination (#8786)\n-- Offsite backup (#8241)\n-- Events Streaming (#8567)\n-- Mandatory Depends On & Read Only Depends On for Document Fields (#8820)\n+- New Desk ([#9617](https://github.com/frappe/frappe/pull/9617))\n+- Child table pagination ([#8786](https://github.com/frappe/frappe/pull/8786))\n+- Events Streaming ([#8567](https://github.com/frappe/frappe/pull/8567))\n+\n### Dashboard Enhancements\n-- Onboarding Wizard with configurable slides (#8880)\n-- Save Dashboard Chart config per user (#9830)\n-- Dashboard permissions (#9789)\n-- Create Dashboard Charts from Reports (#9518)\n-- Web Page tracking (#9959)\n+- Onboarding Wizard with configurable slides ([#8880](https://github.com/frappe/frappe/pull/8880))\n+- Save Dashboard Chart config per user ([#9830](https://github.com/frappe/frappe/pull/9830))\n+- Dashboard permissions ([#9789](https://github.com/frappe/frappe/pull/9789))\n+- Create Dashboard Charts from Reports ([#9518](https://github.com/frappe/frappe/pull/9518))\n+- Web Page tracking ([#9959](https://github.com/frappe/frappe/pull/9959))\n-### Other Minor Features\n+### Other Features\n-- Ability to cancel all linked document with a single click (#8905)\n-- Custom JS & CSS support in Web Form (#9121) (#9610)\n-- System Setting to remove seconds from datetime field (#8531)\n-- Added empty list graphics for list view (#8863)\n-- Validation for Data options and Data values (#9784)\n-- Introduced tnum font feature for reports (#9430)\n-- Allow list structure to be changed for the web view (#9431)\n-- Added Google API Indexing (#9411)\n+- Ability to cancel all linked document with a single click ([#8905](https://github.com/frappe/frappe/pull/8905))\n+- Custom JS & CSS support in Web Form ([#9121](https://github.com/frappe/frappe/pull/9121)) ([#9610](https://github.com/frappe/frappe/pull/9610))\n+- System Setting to remove seconds from datetime field ([#8531](https://github.com/frappe/frappe/pull/8531))\n+- Added empty list graphics for list view ([#8863](https://github.com/frappe/frappe/pull/8863))\n+- Validation for Data options and Data values ([#9784](https://github.com/frappe/frappe/pull/9784))\n+- Introduced tnum font feature for reports ([#9430](https://github.com/frappe/frappe/pull/9430))\n+- Allow list structure to be changed for the web view ([#9431](https://github.com/frappe/frappe/pull/9431))\n+- Offsite backup ([#8241](https://github.com/frappe/frappe/pull/8241))\n+- Mandatory Depends On & Read Only Depends On for Document Fields ([#8820](https://github.com/frappe/frappe/pull/8820))\n+- Added Google API Indexing ([#9411](https://github.com/frappe/frappe/pull/9411))\n",
        "chatgpt_cot": "Update setup_master.md to include the correct IP address for accessing the operator dashboard and user dashboard after all services are up."
    },
    {
        "org_diff": "diff --git a/fkie_node_manager/src/fkie_node_manager/logscreen/screen_highlighter.py b/fkie_node_manager/src/fkie_node_manager/logscreen/screen_highlighter.py @@ -46,12 +46,12 @@ class ScreenHighlighter(QSyntaxHighlighter):\nself._grep_format = QTextCharFormat()\nself._grep_rule = None\nself.rules = []\n- self.rules.append((self._create_regexp(r'.*\\[DEBUG\\].*', syntax=QRegExp.RegExp), self._create_format(QColor(57, 181, 74))))\n- self.rules.append((self._create_regexp(r'.*\\[INFO\\].*', syntax=QRegExp.RegExp), self._create_format(QColor('#FFFAFA'))))\n- self.rules.append((self._create_regexp(r'.*\\[WARN\\].*', syntax=QRegExp.RegExp), self._create_format(QColor(255, 199, 6))))\n- self.rules.append((self._create_regexp(r'.*WARNING.*', syntax=QRegExp.RegExp), self._create_format(QColor(255, 199, 6))))\n- self.rules.append((self._create_regexp(r'.*\\[ERROR\\].*', syntax=QRegExp.RegExp), self._create_format(QColor(222, 56, 43))))\n- self.rules.append((self._create_regexp(r'.*\\[FATAL\\].*', syntax=QRegExp.RegExp), self._create_format(QColor(255, 0, 0)))) #red\n+ self.rules.append((self._create_regexp(r'.*\\[DEBUG\\].', syntax=QRegExp.RegExp), self._create_format(QColor(57, 181, 74))))\n+ self.rules.append((self._create_regexp(r'.*\\[INFO\\].', syntax=QRegExp.RegExp), self._create_format(QColor('#FFFAFA'))))\n+ self.rules.append((self._create_regexp(r'.*\\[WARN\\].', syntax=QRegExp.RegExp), self._create_format(QColor(255, 199, 6))))\n+ self.rules.append((self._create_regexp(r'.*WARNING.', syntax=QRegExp.RegExp), self._create_format(QColor(255, 199, 6))))\n+ self.rules.append((self._create_regexp(r'.*\\[ERROR\\].', syntax=QRegExp.RegExp), self._create_format(QColor(222, 56, 43))))\n+ self.rules.append((self._create_regexp(r'.*\\[FATAL\\].', syntax=QRegExp.RegExp), self._create_format(QColor(255, 0, 0)))) #red\ndef _create_format(self, color, style=''):\n_format = QTextCharFormat()\n@@ -66,11 +66,10 @@ class ScreenHighlighter(QSyntaxHighlighter):\ndef highlightBlock(self, text):\nfor pattern, frmt in self.rules:\n- index = pattern.indexIn(text)\n- while index >= 0:\n- length = pattern.matchedLength()\n- self.setFormat(index, length, frmt)\n- index = pattern.indexIn(text, index + length)\n+ index = pattern.indexIn(text[:80])\n+ if index >= 0:\n+ self.setFormat(0, len(text), frmt)\n+ break\nif self._grep_rule is not None:\nindex = self._grep_rule.indexIn(text)\nwhile index >= 0:\n",
        "org_msg": "fkie_node_manager: logscreen: improved highlighting speed",
        "sim_msg": "Some markdown formatting\n# H1, ## H2, ### H3, **text** bold, *text* italic",
        "sim_diff": "diff --git a/qualcoder/journals.py b/qualcoder/journals.py @@ -26,6 +26,8 @@ https://github.com/ccbogel/QualCoder\nhttps://qualcoder.wordpress.com/\n\"\"\"\n+'''from PyQt6.QtGui import QSyntaxHighlighter, QTextCharFormat, QBrush, QFont, QColor\n+from PyQt6.QtCore import *'''\nfrom PyQt6 import QtCore, QtWidgets, QtGui\nimport datetime\nimport os\n@@ -160,8 +162,9 @@ class DialogJournals(QtWidgets.QDialog):\nself.ui.checkBox_search_all_journals.stateChanged.connect(self.search_for_text)\nself.ui.textEdit.textChanged.connect(self.text_changed)\nself.ui.textEdit.installEventFilter(self)\n- self.ui.tableWidget.installEventFilter(self)\n+ highlighter = Highlighter(self.ui.textEdit, self.app)\n+ self.ui.tableWidget.installEventFilter(self)\n@staticmethod\ndef help():\n@@ -511,3 +514,55 @@ class DialogJournals(QtWidgets.QDialog):\ncursor.setPosition(cursor.position() + next_result[2], QtGui.QTextCursor.MoveMode.KeepAnchor)\nself.ui.textEdit.setTextCursor(cursor)\nself.ui.label_search_totals.setText(str(self.search_index + 1) + \" / \" + str(len(self.search_indices)))\n+\n+\n+class Highlighter(QtGui.QSyntaxHighlighter):\n+ \"\"\" Journal text mardown highlighter. \"\"\"\n+\n+ highlighting_rules = []\n+ app = None\n+\n+ def __init__(self, parent, app):\n+ QtGui.QSyntaxHighlighter.__init__(self, parent)\n+ self.parent = parent\n+ self.app = app\n+ self.highlighting_rules = []\n+ self.rules()\n+\n+ def rules(self):\n+ \"\"\" Sets formatting rules for markdown text.\n+ H1 H2 H3 and bold\n+ \"\"\"\n+\n+ # Heading 1\n+ h1_format = QtGui.QTextCharFormat()\n+ h1_format.setFontPointSize(self.app.settings['docfontsize'] + 6)\n+ h1_format.setFontWeight(QtGui.QFont.Weight.Bold)\n+ self.highlighting_rules += [(QtCore.QRegularExpression(\"# [^\\n]*\"), h1_format)]\n+ # Heading 2\n+ h2_format = QtGui.QTextCharFormat()\n+ h2_format.setFontPointSize(self.app.settings['docfontsize'] + 4)\n+ h2_format.setFontWeight(QtGui.QFont.Weight.Bold)\n+ self.highlighting_rules += [(QtCore.QRegularExpression(\"## [^\\n]*\"), h2_format)]\n+ # Heading 3\n+ h3_format = QtGui.QTextCharFormat()\n+ h3_format.setFontPointSize(self.app.settings['docfontsize'] + 2)\n+ h3_format.setFontWeight(QtGui.QFont.Weight.Bold)\n+ self.highlighting_rules += [(QtCore.QRegularExpression(\"### [^\\n]*\"), h3_format)]\n+ # Italic\n+ italic_format = QtGui.QTextCharFormat()\n+ italic_format.setFontItalic(True)\n+ self.highlighting_rules += [(QtCore.QRegularExpression(\"\\*.*\\*\"), italic_format)]\n+ # Bold\n+ bold_format = QtGui.QTextCharFormat()\n+ bold_format.setFontWeight(QtGui.QFont.Weight.Bold)\n+ self.highlighting_rules += [(QtCore.QRegularExpression(\"\\*\\*.*\\*\\*\"), bold_format)]\n+\n+ def highlightBlock(self, text):\n+ for pattern, format_ in self.highlighting_rules:\n+ reg_exp = QtCore.QRegularExpression(pattern)\n+ i = reg_exp.globalMatch(text)\n+ while i.hasNext():\n+ match = i.next()\n+ self.setFormat(match.capturedStart(), match.capturedLength(), format_)\n+\n",
        "chatgpt_cot": "fix the pattern in ScreenHighlighter to highlight the warning and error."
    },
    {
        "org_diff": "diff --git a/sc2/bot_ai.py b/sc2/bot_ai.py @@ -20,7 +20,7 @@ from .ids.upgrade_id import UpgradeId\nclass BotAI(object):\n\"\"\"Base class for bots.\"\"\"\n- EXPANSION_GAP_THRESHOLD = 15\n+ EXPANSION_GAP_THRESHOLD = 12\ndef _prepare_start(self, client, player_id, game_info, game_data):\n\"\"\"Ran until game start to set game and player data.\"\"\"\n",
        "org_msg": "Tweak EXPANSION_GAP_THRESHOLD",
        "sim_msg": "Forgot to update iNumPlayers",
        "sim_diff": "diff --git a/v3/runner.py b/v3/runner.py @@ -63,6 +63,8 @@ if __name__ == '__main__':\ncallbacks = []\nname_dict = dict()\n+ gameInputPacket.iNumPlayers = num_bots\n+\n# Set configuration values for bots and store name and team\nfor i in range(num_bots):\nbot_config = configparser.RawConfigParser()\n",
        "chatgpt_cot": "Adjust EXPANSION_GAP_THRESHOLD to 12 to improve bot performance. Update in bot_ai.py file reflects the change in the base class for bots."
    },
    {
        "org_diff": "diff --git a/sc2/bot_ai.py b/sc2/bot_ai.py @@ -105,11 +105,16 @@ class BotAI(object):\n# right know only checks cooldown, energy cost, and whether the ability has been researched\nreturn await self._client.query_available_abilities(units, ignore_resource_requirements)\n- async def expand_now(self, building: Optional[UnitTypeId]=None, max_distance: Union[int, float]=10, location: Optional[Point2]=None):\n+ async def expand_now(self, building: UnitTypeId=None, max_distance: Union[int, float]=10, location: Optional[Point2]=None):\n\"\"\"Takes new expansion.\"\"\"\nif not building:\n- building = self.townhalls.first.type_id\n+ if self.race == Race.Protoss:\n+ building = UnitTypeId.NEXUS\n+ elif self.race == Race.Terran:\n+ building = UnitTypeId.COMMANDCENTER\n+ elif self.race == Race.Zerg:\n+ building = UnitTypeId.HATCHERY\nassert isinstance(building, UnitTypeId)\n@@ -288,7 +293,6 @@ class BotAI(object):\n\"\"\"Finds a placement location for building.\"\"\"\nassert isinstance(building, (AbilityId, UnitTypeId))\n- assert self.can_afford(building)\nassert isinstance(near, Point2)\nif isinstance(building, UnitTypeId):\n@@ -377,7 +381,7 @@ class BotAI(object):\nreturn ActionResult.CantFindPlacementLocation\nunit = unit or self.select_build_worker(p)\n- if unit is None:\n+ if unit is None or self.can_afford(building):\nreturn ActionResult.Error\nreturn await self.do(unit.build(building, p))\n",
        "org_msg": "Fix expand_now()",
        "sim_msg": "codebuild__enumm/main.py(fix): added error handling to ensure that if AccessDeniedException occurs, the script does not stop and continues to run other modules (if called via load_commands_file option) OR when enumerating other regions",
        "sim_diff": "diff --git a/modules/codebuild__enum/main.py b/modules/codebuild__enum/main.py #!/usr/bin/env python3\nimport argparse\nfrom copy import deepcopy\n+from botocore.exceptions import ClientError\nmodule_info = {\n@@ -52,6 +53,8 @@ def main(args, pacu_main):\n# Projects\nif enum_all is True or args.projects is True:\nproject_names = []\n+ response = {}\n+ try:\nresponse = client.list_projects()\nproject_names.extend(response['projects'])\nwhile 'nextToken' in response:\n@@ -67,25 +70,51 @@ def main(args, pacu_main):\nprint('Found {} projects'.format(len(region_projects)))\nsummary_data[region]['Projects'] = len(region_projects)\nall_projects.extend(region_projects)\n+ except ClientError as error:\n+ if error.response['Error']['Code'] == 'AccessDeniedException':\n+ print('No projects got for region: {} - AccessDeniedException'.format(region))\n+ print('ClientError getting projects: {}'.format(error))\n+\n# Builds\nif enum_all is True or args.builds is True:\nbuild_ids = []\n+ response = {}\n+ try:\nresponse = client.list_builds()\nbuild_ids.extend(response['ids'])\n+ except ClientError as error:\n+ if error.response['Error']['Code'] == 'AccessDeniedException':\n+ print('No code-builds builds got for region: {} - AccessDeniedException'.format(region))\n+ print('ClientError getting builds: {}'.format(error))\n+\n+\nwhile 'nextToken' in response:\n+ response = {}\n+ try:\nresponse = client.list_builds(\nnextToken=response['nextToken']\n)\nbuild_ids.extend(response['ids'])\n+ except ClientError as error:\n+ if error.response['Error']['Code'] == 'AccessDeniedException':\n+ print('No further code-builds builds for region: {} - AccessDeniedException'.format(region))\n+ print('ClientError getting further builds: {}'.format(error))\nif len(build_ids) > 0:\n+ region_builds = {}\n+ try:\nregion_builds = client.batch_get_builds(\nids=build_ids\n)['builds']\nprint(' Found {} builds'.format(len(region_builds)))\nsummary_data[region]['Builds'] = len(region_builds)\nall_builds.extend(region_builds)\n+ except ClientError as error:\n+ if error.response['Error']['Code'] == 'AccessDeniedException':\n+ print('No info retrieved about code-builds for region: {} - AccessDeniedException'.format(region))\n+ print('ClientError getting info about builds: {}'.format(error))\n+\nif not summary_data[region]:\ndel summary_data[region]\n@@ -118,7 +147,6 @@ def main(args, pacu_main):\nreturn summary_data\n-\ndef summary(data, pacu_main):\nout = ''\nfor region in sorted(data):\n",
        "chatgpt_cot": "Add race-specific expansion buildings, fix can_afford assert, and improve build placement logic in BotAI class."
    },
    {
        "org_diff": "diff --git a/sc2/sc2process.py b/sc2/sc2process.py +import sys\n+import signal\nimport time\nimport os.path\nimport shutil\n@@ -19,6 +21,12 @@ class SC2Process(object):\nself._ws = None\nasync def __aenter__(self):\n+ def signal_handler(signal, frame):\n+ self._clean()\n+ sys.exit(0)\n+\n+ signal.signal(signal.SIGINT, signal_handler)\n+\ntry:\nself._process = self._launch()\nself._ws = await self._connect()\n@@ -30,6 +38,7 @@ class SC2Process(object):\nasync def __aexit__(self, *args):\nself._clean()\n+ signal.signal(signal.SIGINT, signal.SIG_DFL)\n@property\ndef ws_url(self):\n",
        "org_msg": "Add signal handler to always clean up after the game ends",
        "sim_msg": "remove hash_func from dataset object",
        "sim_diff": "diff --git a/python/dgl/data/dgl_dataset.py b/python/dgl/data/dgl_dataset.py @@ -77,7 +77,6 @@ class DGLDataset(object):\nself._force_reload = force_reload\nself._verbose = verbose\nself._hash_key = hash_key\n- self._hash_func = hashlib.sha1()\nself._hash = self._get_hash()\n# if no dir is provided, the default dgl download dir is used.\n@@ -192,8 +191,9 @@ class DGLDataset(object):\n>>> hash_value\n'a770b222'\n\"\"\"\n- self._hash_func.update(str(self._hash_key).encode('utf-8'))\n- return self._hash_func.hexdigest()[:8]\n+ hash_func = hashlib.sha1()\n+ hash_func.update(str(self._hash_key).encode('utf-8'))\n+ return hash_func.hexdigest()[:8]\n@property\ndef url(self):\n",
        "chatgpt_cot": "Add signal handler to clean up process and exit gracefully. Fixes issue with SIGINT interrupt not properly cleaning up resources."
    },
    {
        "org_diff": "diff --git a/src/agent/kubernetes-agent/src/operations/create_node.py b/src/agent/kubernetes-agent/src/operations/create_node.py @@ -137,7 +137,7 @@ def _create_fabric_node():\nnode_status = NodeStatus.Error.value\nfor i in range(1, MAX_QUERY_RETRY):\npod = k8s_client.get_pod(AGENT_ID, deploy_name)\n- if pod.status.phase == \"Running\":\n+ if pod and pod.status.phase == \"Running\":\nnode_status = NodeStatus.Running.value\nbreak\nsleep(5)\n",
        "org_msg": "[Fix Fix node status check crash for k8s agent\nFor k8s agent node creation, node status check need\ncheck whether pod is not None at first.",
        "sim_msg": "Add error massages from requests",
        "sim_diff": "diff --git a/wca/kubernetes.py b/wca/kubernetes.py @@ -123,6 +123,8 @@ class KubernetesNode(Node):\nverify=SERVICE_CERT_FILENAME\n)\n+ if not r.ok():\n+ log.error('%i %s - %s', r.status_code, r.reason, r.raw)\nr.raise_for_status()\nreturn r.json()\n@@ -144,6 +146,8 @@ class KubernetesNode(Node):\njson=dict(type='GET_STATE'),\ntimeout=self.timeout)\n+ if not r.ok():\n+ log.error('%i %s - %s', r.status_code, r.reason, r.raw)\nr.raise_for_status()\nreturn r.json()\n",
        "chatgpt_cot": "\"Fix issue with pod status check in create_node.py\""
    },
    {
        "org_diff": "diff --git a/sc2/unit.py b/sc2/unit.py @@ -479,11 +479,10 @@ class Unit:\n\"\"\"\nif not self.can_attack:\nreturn 0\n- # Early return recommended?\n- # if not self.can_attack_ground and not target.is_flying:\n- # return 0\n- # if not self.can_attack_air and target.is_flying:\n- # return 0\n+ if not self.can_attack_ground and not target.is_flying:\n+ return 0\n+ if not self.can_attack_air and target.is_flying:\n+ return 0\n# Inaccurate for enemy ultralisks with armor upgrade:\nenemy_armor: float = target.armor + target.armor_upgrade_level\nenemy_shield_armor: float = target.shield_upgrade_level\n@@ -501,7 +500,7 @@ class Unit:\nenemy_shield: float = target.shield\ntotal_attacks: int = weapon.attacks\n# TODO: if unit has weapon upgrades, add to damage per attack\n- damage_per_attack: float = weapon.damage\n+ damage_per_attack: float = weapon.damage + self.attack_upgrade_level\n# Remaining damage after all damage is dealt to shield\nremaining_damage: float = 0\n",
        "org_msg": "Add 'self.attack_upgrade_level' to damage per attack",
        "sim_msg": "Removed cantAngleRad != 0 check on rollParameters",
        "sim_diff": "diff --git a/rocketpy/Rocket.py b/rocketpy/Rocket.py @@ -773,11 +773,7 @@ class Rocket:\n/ (Aref * d ** 2)\n)\n# Function of mach number\n- rollParameters = (\n- [clfDelta, cldOmega, cantAngleRad]\n- if cantAngleRad != 0\n- else [Function(0), Function(0), 0]\n- )\n+ rollParameters = [clfDelta, cldOmega, cantAngleRad]\n# Store values\nfin = {\n",
        "chatgpt_cot": "\"Add conditional checks for attacking ground and air units, and include attack upgrade level in damage calculation for Unit class.\""
    },
    {
        "org_diff": "diff --git a/sc2/action.py b/sc2/action.py @@ -32,12 +32,12 @@ def combine_actions(action_iter):\nability, target, queue, combineable = key\nif combineable:\n- # Combine actions with no target, e.g. train and research commands\n+ # Combine actions with no target, e.g. lift, burrowup, burrowdown, siege, unsiege, uproot spines\nif target is None:\ncmd = raw_pb.ActionRawUnitCommand(\nability_id=ability.value, unit_tags={u.unit.tag for u in items}, queue_command=queue\n)\n- # Combine actions with target point\n+ # Combine actions with target point, e.g. attack_move or move commands on a position\nelif isinstance(target, Point2):\ncmd = raw_pb.ActionRawUnitCommand(\nability_id=ability.value,\n@@ -45,7 +45,7 @@ def combine_actions(action_iter):\nqueue_command=queue,\ntarget_world_space_pos=common_pb.Point2D(x=target.x, y=target.y),\n)\n- # Combine actions with target unit\n+ # Combine actions with target unit, e.g. attack commands directly on a unit\nelif isinstance(target, Unit):\ncmd = raw_pb.ActionRawUnitCommand(\nability_id=ability.value,\n@@ -63,7 +63,7 @@ def combine_actions(action_iter):\nReturn one action for each unit; this is required for certain commands that would otherwise be grouped, and only executed once\nExamples:\nSelect 3 hatcheries, build a queen with each hatch - the grouping function would group these unit tags and only issue one train command once to all 3 unit tags - resulting in one total train command\n- I imagine the same thing would happen to certain other abilities: Battlecruiser yamato on same target, queen transfuse on same time, ghost snipe on same target, all build commands with the same unit type and also all morphs (zergling to banelings)\n+ I imagine the same thing would happen to certain other abilities: Battlecruiser yamato on same target, queen transfuse on same target, ghost snipe on same target, all build commands with the same unit type and also all morphs (zergling to banelings)\nHowever, other abilities can and should be grouped, see constants.py 'COMBINEABLE_ABILITIES'\n\"\"\"\nu: UnitCommand\n",
        "org_msg": "Fix typo, improve comment description",
        "sim_msg": "fixed bug with combo always being created",
        "sim_diff": "diff --git a/modelHelpers/actions/dynamic_action_handler.py b/modelHelpers/actions/dynamic_action_handler.py @@ -62,29 +62,7 @@ class DynamicActionHandler(SplitActionHandler):\naction_data = np.arange(*item[1])\nreturn action_data\n- def create_actions(self):\n- self.reset()\n-\n- for i, item in enumerate(self.control_names):\n- self.control_names_index_map[item] = i\n-\n- ranges = self.control_scheme[0]\n- combo_scheme = self.control_scheme[1]\n- copies = self.control_scheme[2]\n-\n- for item in ranges:\n- action = self.create_range_action(item)\n- self.action_sizes.append(len(action))\n- self.action_name_index_map[item[0]] = len(self.action_list_names)\n- if len(item) > 2:\n- self.action_loss_type_map[len(self.action_list_names)] = item[2]\n- else:\n- self.action_loss_type_map[len(self.action_list_names)] = LOSS_SPARSE_CROSS\n- self.action_list_names.append(item[0])\n- self.actions.append(action)\n-\n- self.ranged_actions = list(self.actions)\n-\n+ def create_combo_actions(self, combo_scheme):\nfor item in combo_scheme:\naction = self.create_range_action(item)\nself.combo_name_list.append(item[0])\n@@ -101,6 +79,36 @@ class DynamicActionHandler(SplitActionHandler):\nself.action_list_names.append(COMBO)\nself.actions.append(self.button_combo)\n+ def create_ranged_actions(self, ranges):\n+ for item in ranges:\n+ action = self.create_range_action(item)\n+ self.action_sizes.append(len(action))\n+ self.action_name_index_map[item[0]] = len(self.action_list_names)\n+ if len(item) > 2:\n+ self.action_loss_type_map[len(self.action_list_names)] = item[2]\n+ else:\n+ self.action_loss_type_map[len(self.action_list_names)] = LOSS_SPARSE_CROSS\n+ self.action_list_names.append(item[0])\n+ self.actions.append(action)\n+\n+ self.ranged_actions = list(self.actions)\n+\n+ def create_actions(self):\n+ self.reset()\n+\n+ for i, item in enumerate(self.control_names):\n+ self.control_names_index_map[item] = i\n+\n+ ranges = self.control_scheme[0]\n+ combo_scheme = self.control_scheme[1]\n+ copies = self.control_scheme[2]\n+\n+ if len(ranges) > 0:\n+ self.create_ranged_actions(ranges)\n+\n+ if len(combo_scheme) > 0:\n+ self.create_combo_actions(combo_scheme)\n+\nfor item in copies:\nself.action_name_index_map[item[0]] = self.action_name_index_map[item[1]]\nreturn self.actions\n",
        "chatgpt_cot": "Refactor code to combine actions with no target and actions with a target point or unit. Update comments to reflect the types of actions combined."
    },
    {
        "org_diff": "diff --git a/.travis.yml b/.travis.yml @@ -3,12 +3,10 @@ services:\nlanguage: generic\nenv:\nmatrix:\n- - ROS_DISTRO=\"kinetic\" ROS_REPO=\"ros-shadow-fixed\"\n- - ROS_DISTRO=\"kinetic\" ROS_REPO=\"ros\"\n- - ROS_DISTRO=\"melodic\" ROS_REPO=\"ros-shadow-fixed\"\n- - ROS_DISTRO=\"melodic\" ROS_REPO=\"ros\"\n+ - ROS_DISTRO=\"kinetic\"\n+ - ROS_DISTRO=\"melodic\"\ninstall:\n- - git clone https://github.com/ros-industrial/industrial_ci.git .ci_config\n+ - git clone --quiet --depth 1 https://github.com/ros-industrial/industrial_ci.git .industrial_ci -b master\nscript:\n- - .ci_config/travis.sh\n+ - .industrial_ci/travis.sh\n",
        "org_msg": "updated travis script with new refactored industrial_ci",
        "sim_msg": "issue enable a 2->3 Mitogen job.",
        "sim_diff": "diff --git a/.travis.yml b/.travis.yml @@ -32,6 +32,9 @@ matrix:\n# 2.6 -> 2.7\n- python: \"2.6\"\nenv: MODE=mitogen DISTRO=centos7\n+ # 2.6 -> 3.5\n+ - python: \"2.6\"\n+ env: MODE=mitogen DISTRO=debian-py3\n# 3.6 -> 2.6\n- python: \"3.6\"\nenv: MODE=mitogen DISTRO=centos6\n",
        "chatgpt_cot": "Update ROS configuration in .travis.yml for kinetic and melodic distributions to use different ROS repositories and clone industrial_ci with quiet option."
    },
    {
        "org_diff": "diff --git a/src/agent/ansible/roles/deploy_k8s/pubconn/templates/connection.j2 b/src/agent/ansible/roles/deploy_k8s/pubconn/templates/connection.j2 \"entityMatchers\": {\n\"orderer\": [\n{% for orderer in allorderers %}\n- { mappedHost: \"{{ orderer.name }}\",\n- pattern: (\\w*){{ orderer.name }}(\\w*),\n- sslTargetOverrideUrlSubstitutionExp: {{ orderer.name }},\n- urlSubstitutionExp: \"{{ tls|ternary('grpcs','grpc') }}://{{ allips|random }}:{{ k8sports[orderer.name+':7050'] }}\"\n+ { \"mappedHost\": \"{{ orderer.name }}\",\n+ \"pattern\": \"(\\\\w*){{ orderer.name }}(\\\\w*)\",\n+ \"sslTargetOverrideUrlSubstitutionExp\": \"{{ orderer.name }}\",\n+ \"urlSubstitutionExp\": \"{{ tls|ternary('grpcs','grpc') }}://{{ allips|random }}:{{ k8sports[orderer.name+':7050'] }}\"\n}{{ '' if loop.last else ',' }}\n{% endfor %}\n],\n\"peer\": [\n{% for peer in allpeers|selectattr('org', 'equalto', item)|list %}\n- { mappedHost: \"{{ peer.name }}\"\n- pattern: (\\w*){{ peer.name }}(\\w*),\n- sslTargetOverrideUrlSubstitutionExp: {{ peer.name }},\n- urlSubstitutionExp: \"{{ tls|ternary('grpcs','grpc') }}://{{ allips|random }}:{{ k8sports[peer.name+':7051'] }}\",\n- eventUrlSubstitutionExp: \"{{ tls|ternary('grpcs','grpc') }}://{{ allips|random }}:{{ k8sports[peer.name+':7053'] }}\"\n+ { \"mappedHost\": \"{{ peer.name }}\",\n+ \"pattern\": \"(\\\\w*){{ peer.name }}(\\\\w*)\",\n+ \"sslTargetOverrideUrlSubstitutionExp\": \"{{ peer.name }}\",\n+ \"urlSubstitutionExp\": \"{{ tls|ternary('grpcs','grpc') }}://{{ allips|random }}:{{ k8sports[peer.name+':7051'] }}\",\n+ \"eventUrlSubstitutionExp\": \"{{ tls|ternary('grpcs','grpc') }}://{{ allips|random }}:{{ k8sports[peer.name+':7053'] }}\"\n}{{ '' if loop.last else ',' }}\n{% endfor %}\n]\n",
        "org_msg": "[CE-498]JSON connection profile misses few quotes\nAnsible agent created json connection profiles missed\nfew double quotes and also missing escape slash. This\npatch fixes the problem.",
        "sim_msg": "address customer issue",
        "sim_diff": "diff --git a/src/genie/libs/parser/iosxe/tests/test_show_acl.py b/src/genie/libs/parser/iosxe/tests/test_show_acl.py #!/bin/env python\nimport unittest\n+\nfrom unittest.mock import Mock\nfrom ats.topology import Device\n@@ -1860,6 +1861,96 @@ IPv6 access list OutFilter_IPv6\n}\n}\n+ golden_output_customer = {'execute.return_value': '''\n+ Standard IP access list 43\n+ 10 permit 10.1.0.2 (1168716 matches)\n+ 20 permit 11.1.0.9\n+ 30 permit 12.28.10.0, wildcard bits 0.0.10.255\n+ 40 permit 13.1.0.0, wildcard bits 0.0.255.255 (8353358 matches)\n+ '''\n+ }\n+\n+ golden_parsed_output_customer = {\n+ '43': {\n+ 'aces': {\n+ '10': {\n+ 'actions': {\n+ 'forwarding': 'permit'\n+ },\n+ 'matches': {\n+ 'l3': {\n+ 'ipv4': {\n+ 'protocol': 'ipv4',\n+ 'source_network': {\n+ '10.1.0.2 0.0.0.0': {\n+ 'source_network': '10.1.0.2 0.0.0.0'\n+ }\n+ }\n+ }\n+ }\n+ },\n+ 'name': '10'\n+ },\n+ '20': {\n+ 'actions': {\n+ 'forwarding': 'permit'\n+ },\n+ 'matches': {\n+ 'l3': {\n+ 'ipv4': {\n+ 'protocol': 'ipv4',\n+ 'source_network': {\n+ '11.1.0.9 0.0.0.0': {\n+ 'source_network': '11.1.0.9 0.0.0.0'\n+ }\n+ }\n+ }\n+ }\n+ },\n+ 'name': '20'\n+ },\n+ '30': {\n+ 'actions': {\n+ 'forwarding': 'permit'\n+ },\n+ 'matches': {\n+ 'l3': {\n+ 'ipv4': {\n+ 'protocol': 'ipv4',\n+ 'source_network': {\n+ '12.28.10.0 0.0.10.255': {\n+ 'source_network': '12.28.10.0 0.0.10.255'\n+ }\n+ }\n+ }\n+ }\n+ },\n+ 'name': '30'\n+ },\n+ '40': {\n+ 'actions': {\n+ 'forwarding': 'permit'\n+ },\n+ 'matches': {\n+ 'l3': {\n+ 'ipv4': {\n+ 'protocol': 'ipv4',\n+ 'source_network': {\n+ '13.1.0.0 0.0.255.255': {\n+ 'source_network': '13.1.0.0 0.0.255.255'\n+ }\n+ }\n+ }\n+ }\n+ },\n+ 'name': '40'\n+ }\n+ },\n+ 'name': '43',\n+ 'type': 'ipv4-acl-type'\n+ }\n+ }\n+\ndef test_empty(self):\nself.dev1 = Mock(**self.empty_output)\nobj = ShowAccessLists(device=self.dev1)\n@@ -1901,6 +1992,13 @@ IPv6 access list OutFilter_IPv6\nparsed_output = obj.parse()\nself.assertEqual(parsed_output, self.golden_parsed_output_1)\n+ def test_golden_customer(self):\n+ self.maxDiff = None\n+ self.dev_c3850 = Mock(**self.golden_output_customer)\n+ obj = ShowIpAccessLists(device=self.dev_c3850)\n+ parsed_output = obj.parse(acl='43')\n+ self.assertEqual(parsed_output, self.golden_parsed_output_customer)\n+\nif __name__ == '__main__':\nunittest.main()\n",
        "chatgpt_cot": "\"Update connection.j2 for better readability and maintainability with consistent JSON syntax and formatting for orderer and peer entities.\""
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/echo_dialog.py b/node_manager_fkie/src/node_manager_fkie/echo_dialog.py @@ -136,6 +136,7 @@ class EchoDialog(QDialog):\nself.field_filter_fn = None\nself._latched = False\n+ self._msgs = []\noptions = QWidget(self)\nif not show_only_rate:\n@@ -312,6 +313,9 @@ class EchoDialog(QDialog):\nself.line_limit = float(ch_txt)\nexcept ValueError:\nself.combobox_reduce_ch.setEditText(str(self.line_limit))\n+ self.display.clear()\n+ for msg, current_time in self._msgs:\n+ self._append_message(msg, self._latched, current_time, False)\ndef on_combobox_chars_activated(self, chars_txt):\ntry:\n@@ -321,6 +325,9 @@ class EchoDialog(QDialog):\nself.chars_limit = float(chars_txt)\nexcept ValueError:\nself.combobox_displ_chars.setEditText(str(self.chars_limit))\n+ self.display.clear()\n+ for msg, current_time in self._msgs:\n+ self._append_message(msg, self._latched, current_time, False)\ndef on_combobox_hz_activated(self, hz_txt):\ntry:\n@@ -374,14 +381,19 @@ class EchoDialog(QDialog):\ndef _msg_handle(self, data):\nself.msg_signal.emit(data, (data._connection_header['latching'] != '0'))\n- def _append_message(self, msg, latched):\n+ def _append_message(self, msg, latched, current_time=None, store=True):\n'''\nAdds a label to the dialog's layout and shows the given text.\n@param msg: the text to add to the dialog\n@type msg: message object\n'''\n- self._latched = latched\n+ if current_time is None:\ncurrent_time = time.time()\n+ self._latched = latched\n+ if store:\n+ self._msgs.append((msg, current_time))\n+ if len(self._msgs) > 25:\n+ self._msgs.pop()\nmsg_len = -1\nif (self.SHOW_BYTES or self.show_only_rate):\nbuff = None\n@@ -397,6 +409,7 @@ class EchoDialog(QDialog):\nbuff = BytesIO()\nmsg.serialize(buff)\nmsg_len = buff.getbuffer().nbytes\n+ if store:\nself._count_messages(current_time, msg_len)\n# skip messages, if they are received often then MESSAGE_HZ_LIMIT\nif self._last_received_ts != 0 and self.receiving_hz != 0:\n@@ -501,6 +514,8 @@ class EchoDialog(QDialog):\nmessage_std_dev = ''\nmessage_scrapped = ''\nsum_times = sum(self.times)\n+ if sum_times == 0:\n+ sum_times = 1\nif (self.SHOW_BYTES or self.show_only_rate) and self.bytes:\nsum_bytes = sum(self.bytes)\navg = sum_bytes / len(self.bytes)\n",
        "org_msg": "node_manager_fkie: store last messages in echo dialog to show them after some filter was chagned",
        "sim_msg": "fixed 'case' key bug in new file creation",
        "sim_diff": "diff --git a/qualcoder/manage_files.py b/qualcoder/manage_files.py @@ -682,8 +682,10 @@ class DialogManageFiles(QtWidgets.QDialog):\ndef get_cases_by_filename(self, name):\n\"\"\" Called by get_icon_and_metadata, get_file_data\n- \"\"\"\n+ param: name String of filename \"\"\"\n+\ncur = self.app.conn.cursor()\n+ # Case_text is the table, but this also links av and images\nsql = \"select distinct cases.name from cases join case_text on case_text.caseid=cases.caseid \"\nsql += \"join source on source.id=case_text.fid where source.name=? \"\ntext = \"\"\n@@ -1211,7 +1213,7 @@ class DialogManageFiles(QtWidgets.QDialog):\nicon, metadata = self.get_icon_and_metadata(name, filetext, None)\nentry = {'name': name, 'id': -1, 'fulltext': filetext, 'memo': \"\",\n'owner': self.app.settings['codername'], 'date': datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n- 'mediapath': None, 'icon': icon, 'metadata': metadata}\n+ 'mediapath': None, 'icon': icon, 'metadata': metadata, 'case': \"\"}\n# Update database\ncur = self.app.conn.cursor()\n",
        "chatgpt_cot": "Add message storage and display functionality in EchoDialog to show messages in the dialog. Fix compilation issue related to message display."
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/launch_list_model.py b/node_manager_fkie/src/node_manager_fkie/launch_list_model.py @@ -374,7 +374,7 @@ class LaunchListModel(QStandardItemModel):\nitem = self.itemFromIndex(index)\nprev = '%s\\n' % text if text else ''\ntext = '%sfile://%s' % (prev, item.path)\n- mimeData.setData('text/plain', utf8(text))\n+ mimeData.setData('text/plain', text)\nQApplication.clipboard().setMimeData(mimeData)\n# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
        "org_msg": "node_manager_fkie: fixed file name copy crash",
        "sim_msg": "fix code generation for list controls",
        "sim_diff": "diff --git a/widgets/list_ctrl/codegen.py b/widgets/list_ctrl/codegen.py @@ -25,13 +25,15 @@ class ListCtrlPropertyGeneratorMixin(object):\ncols_p = obj.properties[\"columns\"]\ncolumns = cols_p.value\n+ tmpl_append_column, tmpl_append_row = self._get_row_col_templates()\n+\nfor i, (heading,width) in enumerate(columns):\nvalues = {\"name\":name, \"heading\":self.codegen.quote_str(heading), \"width\":width, \"col\":i}\n- out.append( self.tmpl_append_column % values )\n+ out.append( tmpl_append_column % values )\nif self.codegen.preview:\nfor r in range(rows_number):\n- out.append( self.tmpl_append_row % (name, r) )\n+ out.append( tmpl_append_row % (name, r) )\nreturn out\n@@ -39,19 +41,23 @@ class ListCtrlPropertyGeneratorMixin(object):\nclass PythonListCtrlGenerator(ListCtrlPropertyGeneratorMixin, wcodegen.PythonWidgetCodeWriter):\ntmpl = '%(name)s = %(klass)s(%(parent)s, %(id)s%(style)s)\\n'\n+ def _get_row_col_templates(self):\n# templates for adding columns and rows (rows are for preview only)\n- if compat.IS_PHOENIX:\n+ if self.codegen.for_version >= (3,0):\ntmpl_append_column = '%(name)s.AppendColumn(%(heading)s, format=wx.LIST_FORMAT_LEFT, width=%(width)d)\\n'\ntmpl_append_row = '%s.InsertItem(%d, \"\")\\n'\nelse:\ntmpl_append_column ='%(name)s.InsertColumn(%(col)d, %(heading)s, format=wx.LIST_FORMAT_LEFT, width=%(width)d)\\n'\ntmpl_append_row = '%s.InsertStringItem(%d, \"\")\\n'\n+ return (tmpl_append_column, tmpl_append_row)\nclass CppListCtrlGenerator(ListCtrlPropertyGeneratorMixin, wcodegen.CppWidgetCodeWriter):\nimport_modules = ['<wx/listctrl.h>']\ntmpl = '%(name)s = new %(klass)s(%(parent)s, %(id)s%(style)s);\\n'\n+ def _get_row_col_templates(self):\ntmpl_append_column = '%(name)s->AppendColumn(%(heading)s, wxLIST_FORMAT_LEFT, %(width)d);\\n'\n+ return (tmpl_append_column, None)\ndef xrc_code_generator(obj):\n",
        "chatgpt_cot": "\"Fixed setData method in LaunchListModel to correctly set mimeData for clipboard, resolves issue with incorrect data format.\""
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/main_window.py b/node_manager_fkie/src/node_manager_fkie/main_window.py @@ -345,6 +345,8 @@ class MainWindow(QMainWindow):\nself._sub_extended_log = rospy.Subscriber('/diagnostics_agg', DiagnosticArray, self._callback_diagnostics)\nself.launch_dock.launchlist_model.reloadPackages()\nself._select_index = 0\n+ self._shortcut_restart_nodes = QShortcut(QKeySequence(self.tr(\"Ctrl+R\", \"restart selected nodes\")), self)\n+ self._shortcut_restart_nodes.activated.connect(self._restart_nodes)\ndef _dock_widget_in(self, area=Qt.LeftDockWidgetArea, only_visible=False):\nresult = []\n@@ -2078,6 +2080,10 @@ class MainWindow(QMainWindow):\nelse:\nreturn utf8(url.host())\n+ def _restart_nodes(self):\n+ if self.currentMaster is not None:\n+ self.currentMaster.on_force_start_nodes()\n+\ndef keyPressEvent(self, event):\n'''\n'''\n",
        "org_msg": "node_manager_fkie: added shortcut Ctrl+R to restart nodes",
        "sim_msg": "additional cleanup and bugfix for Viv-specific docks.",
        "sim_diff": "diff --git a/vivisect/qt/main.py b/vivisect/qt/main.py @@ -231,8 +231,8 @@ class VQVivMainWindow(viv_base.VivEventDist, vq_app.VQMainCmdWindow):\ndwcls = settings.value('%s/DockClasses' % guid)\nstate = settings.value('%s/DockState' % guid)\ngeom = settings.value('%s/DockGeometry' % guid)\n+ basename = '%s/VQDockWidget%%d' % guid\n- # PyQt4 is very different here\nif compat_isNone(dwcls):\nnames = self.vw.filemeta.keys()\nnames.sort()\n@@ -240,17 +240,18 @@ class VQVivMainWindow(viv_base.VivEventDist, vq_app.VQMainCmdWindow):\ndwcls = settings.value('%s/DockClasses' % name)\nstate = settings.value('%s/DockState' % name)\ngeom = settings.value('%s/DockGeometry' % name)\n+ basename = '%s/VQDockWidget%%d' % name\nif compat_isNone(dwcls):\ndwcls = settings.value('DockClasses')\nstate = settings.value('DockState')\ngeom = settings.value('DockGeometry')\n+ basename = 'VQDockWidget%d'\nif not compat_isNone(dwcls):\n- print repr(dwcls)\nfor i, clsname in enumerate(compat_strList(dwcls)):\n- name = 'VQDockWidget%d' % i\n+ name = basename % i\ntry:\ntup = self.vqBuildDockWidget(str(clsname), floating=False)\nif tup != None:\n@@ -275,49 +276,6 @@ class VQVivMainWindow(viv_base.VivEventDist, vq_app.VQMainCmdWindow):\nreturn True\n- # or it's Qt5\n- if dwcls == None or not len(dwcls):\n- names = self.vw.filemeta.keys()\n- names.sort()\n- name = '+'.join(names)\n- dwcls = settings.value('%s/DockClasses' % name)\n- state = settings.value('%s/DockState' % name)\n- geom = settings.value('%s/DockGeometry' % name)\n-\n- if dwcls == None or not len(dwcls):\n- dwcls = settings.value('DockClasses')\n- state = settings.value('DockState')\n- geom = settings.value('DockGeometry')\n-\n-\n- if dwcls != None and len(dwcls):\n- for i, clsname in enumerate(dwcls):\n- name = 'VQDockWidget%d' % i\n- try:\n- #tup = self.vqBuildDockWidget(str(clsname)) # FIXME:, floating=True)\n- tup = self.vqBuildDockWidget(str(clsname), floating=True)\n- if tup != None:\n- d, obj = tup\n- d.setObjectName(name)\n- d.vqRestoreState(settings,name)\n- d.show()\n- except Exception, e:\n- print('Error Building: %s: %s' % (clsname,e))\n-\n- # Once dock widgets are loaded, we can restoreState\n- if not state == None:\n- self.restoreState(state)\n-\n- if not geom == None:\n- self.restoreGeometry(geom)\n-\n- # Just get all the resize activities done...\n- vq_main.eatevents()\n- for w in self.vqGetDockWidgets():\n- w.show()\n-\n- return True\n-\ndef vqSaveGuiSettings(self, settings):\ndock_classes = []\n",
        "chatgpt_cot": "Add shortcut for restarting nodes and implement restart functionality on key press event in MainWindow class."
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/master_view_proxy.py b/node_manager_fkie/src/node_manager_fkie/master_view_proxy.py @@ -386,6 +386,9 @@ class MasterViewProxy(QWidget):\n@property\ndef online(self):\n+ '''\n+ The online meens that master is discovered and master_info was received.\n+ '''\nreturn self.__online\n@online.setter\n",
        "org_msg": "node_manager_fkie: added description for online state of a master proxy",
        "sim_msg": "pass-through for version ... hmmm",
        "sim_diff": "diff --git a/txtorcon/controller.py b/txtorcon/controller.py @@ -495,6 +495,10 @@ class Tor(object):\n\"\"\"\nreturn self._protocol\n+ @property\n+ def version(self):\n+ return self._protocol.version\n+\n@property\ndef config(self):\n\"\"\"\n",
        "chatgpt_cot": "Add documentation for the online property in MasterViewProxy class."
    },
    {
        "org_diff": "diff --git a/fkie_node_manager/src/fkie_node_manager/launch_files_widget.py b/fkie_node_manager/src/fkie_node_manager/launch_files_widget.py @@ -132,8 +132,7 @@ class LaunchFilesWidget(QDockWidget):\n'''\nself.progress_queue.stop()\nself.ui_search_line.set_process_active(False)\n- if self._reload_timer is not None and self._reload_timer.is_alive():\n- self._reload_timer.cancel()\n+ self._stop_timer_reload()\ndef set_current_master(self, masteruri, mastername):\nself.launchlist_model.set_current_master(masteruri, mastername)\n@@ -194,12 +193,26 @@ class LaunchFilesWidget(QDockWidget):\ndef on_pathlist_handled(self, gpath):\nself.ui_search_line.set_process_active(False)\nself.ui_button_new.setEnabled(not self.launchlist_model.is_in_root)\n+ self._stop_timer_reload()\ndef on_error_on_path(self, gpath):\nif gpath == self._current_search or gpath == self.launchlist_model.current_path:\nself.ui_search_line.set_process_active(False)\nif self.launchlist_model.is_in_root:\n- self._reload_timer = threading.Timer(2., nm.nmd().file.list_path_threaded, args=(self.launchlist_model.current_path,))\n+ self._reload_timer = threading.Timer(2., nm.nmd().file.list_path_threaded)\n+ self._reload_timer.start()\n+\n+ def _stop_timer_reload(self):\n+ if self._reload_timer is not None and self._reload_timer.is_alive():\n+ try:\n+ self._reload_timer.cancel()\n+ self._reload_timer = None\n+ except Exception:\n+ pass\n+\n+ def _on_timer_reload_callback(self, event=None):\n+ nm.nmd().file.list_path_threaded(self.launchlist_model.current_path)\n+ self._reload_timer = threading.Timer(2., nm.nmd().file.list_path_threaded)\nself._reload_timer.start()\ndef on_launch_selection_changed(self, selected, deselected):\n",
        "org_msg": "fkie_node_manager: improved reload launch list on problems",
        "sim_msg": "Type hints for Timers",
        "sim_diff": "diff --git a/loopchain/baseservice/timer_service.py b/loopchain/baseservice/timer_service.py @@ -18,6 +18,8 @@ import threading\nimport time\nimport traceback\nfrom enum import Enum\n+from typing import Dict, Callable, Awaitable, Union\n+\nfrom loopchain import utils as util\nfrom loopchain.baseservice import CommonThread\n@@ -44,14 +46,14 @@ class Timer:\n\"\"\"\nself.target = kwargs.get(\"target\")\nself.duration = kwargs.get(\"duration\")\n- self.is_run_at_start = kwargs.get(\"is_run_at_start\", False)\n- self.is_repeat = kwargs.get(\"is_repeat\", False)\n+ self.is_run_at_start: bool = kwargs.get(\"is_run_at_start\", False)\n+ self.is_repeat: bool = kwargs.get(\"is_repeat\", False)\nself.__start_time = time.time()\n- self.__callback = kwargs.get(\"callback\", None)\n+ self.__callback: Union[Callable, Awaitable] = kwargs.get(\"callback\", None)\nself.__kwargs = kwargs.get(\"callback_kwargs\") or {}\n- def is_timeout(self):\n+ def is_timeout(self) -> bool:\nif time.time() - self.__start_time < self.duration:\nreturn False\n@@ -62,7 +64,7 @@ class Timer:\nself.__start_time = time.time()\nutil.logger.spam(f\"reset_timer: {self.target}\")\n- def remain_time(self):\n+ def remain_time(self) -> Union[int, float]:\nend_time = self.__start_time + self.duration\nremain = end_time - time.time()\nreturn remain if remain > 0 else 0\n@@ -117,7 +119,7 @@ class TimerService(CommonThread):\ndef __init__(self):\nCommonThread.__init__(self)\n- self.__timer_list = {}\n+ self.__timer_list: Dict[str, Timer] = {}\nself.__loop: asyncio.BaseEventLoop = asyncio.new_event_loop()\n# self.__loop.set_debug(True)\n@@ -126,10 +128,10 @@ class TimerService(CommonThread):\nreturn self.__loop\n@property\n- def timer_list(self):\n+ def timer_list(self) -> Dict[str, Timer]:\nreturn self.__timer_list\n- def add_timer(self, key, timer):\n+ def add_timer(self, key, timer: Timer):\n\"\"\"add timer to self.__timer_list\n:param key: key\n@@ -167,7 +169,7 @@ class TimerService(CommonThread):\nelse:\nlogging.warning(f'({key}) is not in timer list.')\n- def get_timer(self, key):\n+ def get_timer(self, key) -> Union[Timer]:\n\"\"\"get a timer by key\n:param key: key\n@@ -204,7 +206,7 @@ class TimerService(CommonThread):\nelse:\nlogging.warning(f\"restart_timer:There is no value by this key: {key}\")\n- def stop_timer(self, key, off_type=OffType.normal):\n+ def stop_timer(self, key, off_type: OffType = OffType.normal):\n\"\"\"stop timer\n:param key: key\n",
        "chatgpt_cot": "Fix compilation issue due to new method in LaunchFilesWidget. The new method _stop_timer_reload will help solve the compilation problem."
    },
    {
        "org_diff": "diff --git a/docs/agents/fabric-operator.md b/docs/agents/fabric-operator.md @@ -18,7 +18,7 @@ The k8s configuration file is needed to gain access to a k8s cluster. Many cloud\nThe config file allows you to put in details like node name, allocate k8s resources such as cpu and memory, and the certificates needed for that.\n-[Download sample config.yaml file](https://github.com/hyperledger/cello/blob/master/src/agent/fabric-operator/agent/samples/peer_config.yaml)\n+[Download sample config.json file](https://github.com/hyperledger/cello/blob/master/src/agent/fabric-operator/agent/samples/peer_config.json)\nFollow the below process to prepare zip files for setting up your fabric network:\n@@ -41,7 +41,7 @@ The zip file created in the above process is to be uploaded during the `Agent` c\nCommands for the same :-\n```\n-wget https://github.com/hyperledger/cello/blob/master/src/agent/fabric-operator/agent/samples/peer_config.yaml?raw=true\n+wget https://github.com/hyperledger/cello/blob/master/src/agent/fabric-operator/agent/samples/peer_config.json?raw=true\ntar -czvf peer_config.tgz peer_config.json\n```\n",
        "org_msg": "fix typo in doc\nchange missing `peer_config.yaml` to `peer_config.json`",
        "sim_msg": "Remove public uri when using bootstraping from public dht",
        "sim_diff": "diff --git a/docs/p2p-connection.md b/docs/p2p-connection.md @@ -123,7 +123,7 @@ aea run --connections \"fetchai/p2p_libp2p:0.2.0,fetchai/oef:0.5.0\"\n## Deployed agent communication network\n-You can connect to the deployed public test network by adding one or multiple of the following addresses as the `lipp2p_entry_peers`:\n+You can connect to the deployed public test network by adding one or multiple of the following addresses as the `libp2p_entry_peers`:\n```yaml\n/dns4/agents-p2p-dht.sandbox.fetch-ai.com/tcp/9000/p2p/16Uiu2HAkw1ypeQYQbRFV5hKUxGRHocwU5ohmVmCnyJNg36tnPFdx\n@@ -131,12 +131,11 @@ You can connect to the deployed public test network by adding one or multiple of\n/dns4/agents-p2p-dht.sandbox.fetch-ai.com/tcp/9002/p2p/16Uiu2HAmNJ8ZPRaXgYjhFf8xo8RBTX8YoUU5kzTW7Z4E5J3x9L1t\n```\n-In particular, by modiying the configuration such that:\n+In particular, by modifying the configuration such that:\n``` yaml\nconfig:\ndelegate_uri: 127.0.0.1:11001\nentry_peers: [/dns4/agents-p2p-dht.sandbox.fetch-ai.com/tcp/9000/p2p/16Uiu2HAkw1ypeQYQbRFV5hKUxGRHocwU5ohmVmCnyJNg36tnPFdx, /dns4/agents-p2p-dht.sandbox.fetch-ai.com/tcp/9001/p2p/16Uiu2HAmVWnopQAqq4pniYLw44VRvYxBUoRHqjz1Hh2SoCyjbyRW, /dns4/agents-p2p-dht.sandbox.fetch-ai.com/tcp/9002/p2p/16Uiu2HAmNJ8ZPRaXgYjhFf8xo8RBTX8YoUU5kzTW7Z4E5J3x9L1t]\nlocal_uri: 127.0.0.1:9001\nlog_file: libp2p_node.log\n- public_uri: 127.0.0.1:9001\n```\n",
        "chatgpt_cot": "Update file references and download links to use config.json instead of config.yaml for fabric-operator documentation."
    },
    {
        "org_diff": "diff --git a/sc2/bot_ai.py b/sc2/bot_ai.py @@ -226,17 +226,24 @@ class BotAI(object):\nreturn owned\n- def can_afford(self, item_id: Union[UnitTypeId, UpgradeId, AbilityId]) -> \"CanAffordWrapper\":\n+ def can_feed(self, unit_type: UnitTypeId) -> bool:\n+ \"\"\" Checks if you have enough free supply to build the unit \"\"\"\n+ return self.supply_left >= self._game_data.units[unit_type.value]._proto.food_required\n+\n+ def can_afford(self, item_id: Union[UnitTypeId, UpgradeId, AbilityId], check_supply_cost: bool=True) -> \"CanAffordWrapper\":\n\"\"\"Tests if the player has enough resources to build a unit or cast an ability.\"\"\"\n+ enough_supply = True\nif isinstance(item_id, UnitTypeId):\nunit = self._game_data.units[item_id.value]\ncost = self._game_data.calculate_ability_cost(unit.creation_ability)\n+ if check_supply_cost:\n+ enough_supply = self.can_feed(item_id)\nelif isinstance(item_id, UpgradeId):\ncost = self._game_data.upgrades[item_id.value].cost\nelse:\ncost = self._game_data.calculate_ability_cost(item_id)\n- return CanAffordWrapper(cost.minerals <= self.minerals, cost.vespene <= self.vespene)\n+ return CanAffordWrapper(cost.minerals <= self.minerals, cost.vespene <= self.vespene, enough_supply)\nasync def can_cast(self, unit: Unit, ability_id: AbilityId, target: Optional[Union[Unit, Point2, Point3]]=None, only_check_energy_and_cooldown: bool=False, cached_abilities_of_unit: List[AbilityId]=None) -> bool:\n\"\"\"Tests if a unit has an ability available and enough energy to cast it.\n@@ -497,12 +504,13 @@ class BotAI(object):\nclass CanAffordWrapper(object):\n- def __init__(self, can_afford_minerals, can_afford_vespene):\n+ def __init__(self, can_afford_minerals, can_afford_vespene, have_enough_supply):\nself.can_afford_minerals = can_afford_minerals\nself.can_afford_vespene = can_afford_vespene\n+ self.have_enough_supply = have_enough_supply\ndef __bool__(self):\n- return self.can_afford_minerals and self.can_afford_vespene\n+ return self.can_afford_minerals and self.can_afford_vespene and self.have_enough_supply\n@property\ndef action_result(self):\n@@ -510,5 +518,7 @@ class CanAffordWrapper(object):\nreturn ActionResult.NotEnoughVespene\nelif not self.can_afford_minerals:\nreturn ActionResult.NotEnoughMinerals\n+ elif not self.have_enough_supply:\n+ return ActionResult.NotEnoughFood\nelse:\nreturn None\n",
        "org_msg": "Add can_feed to can_afford check",
        "sim_msg": "Fixes based on the PR comments",
        "sim_diff": "diff --git a/packages/fetchai/skills/tac_control_contract/game.py b/packages/fetchai/skills/tac_control_contract/game.py @@ -889,7 +889,7 @@ class Game(Model):\n+ \"\\n\"\n)\nfor good_id, quantity in agent_state.quantities_by_good_id.items():\n- result += \" \" + str(good_id) + \": \" + str(quantity) + \"\\n\"\n+ result += \" \" + good_id + \": \" + str(quantity) + \"\\n\"\nfor currency_id, amount in agent_state.amount_by_currency_id.items():\nresult += \" \" + currency_id + \": \" + str(amount) + \"\\n\"\nresult += \" score: \" + str(round(agent_state.get_score(), 2)) + \"\\n\"\n@@ -901,7 +901,7 @@ class Game(Model):\n\"\"\"Get equilibrium summary.\"\"\"\nresult = \"\\n\" + \"Equilibrium prices: \\n\"\nfor good_id, eq_price in self.initialization.good_id_to_eq_prices.items():\n- result = result + str(good_id) + \" \" + str(eq_price) + \"\\n\"\n+ result = result + good_id + \" \" + str(eq_price) + \"\\n\"\nresult = result + \"\\n\"\nresult = result + \"Equilibrium good allocation: \\n\"\nfor (\n@@ -915,7 +915,7 @@ class Game(Model):\n+ \":\\n\"\n)\nfor good_id, quantity in eq_allocations.items():\n- result = result + \" \" + str(good_id) + \": \" + str(quantity) + \"\\n\"\n+ result = result + \" \" + good_id + \": \" + str(quantity) + \"\\n\"\nresult = result + \"\\n\"\nresult = result + \"Equilibrium money allocation: \\n\"\nfor (\n",
        "chatgpt_cot": "\"Add can_feed method to BotAI for checking free supply. Modify can_afford method to check supply cost and add enough_supply flag to CanAffordWrapper.\""
    },
    {
        "org_diff": "diff --git a/docs/tutorial.md b/docs/tutorial.md # Tutorial\n-**Notice: Please have a look at the [terminologies](./terminology.md) if you haven't yet.**\n+**Notice: Please have a look at the [terminology](./terminology.md) if you haven't yet.**\n-After the [installation](./install.md), operators can interact with Cello through dashboard.\n+After the [installation](./installation.md), operators can interact with Cello through dashboard.\nBy default, the dashboard will listen on port `8080` at the Master Node.\n@@ -20,7 +20,7 @@ Then you will see a jumped-out dialog to input the setup info.\nSuppose it's a Native Docker server to import as a host, input those fields\n* Name: docker_host\n-* Daemon URL: `192.168.7.220:2375` (replace this with ur docker host address)\n+* Daemon URL: `192.168.7.220:2375` (replace this with your docker host address)\n* Capacity: 5\nAfter successful adding, you can find the `docker_host` shown in the Host page, with 0 chains and Cap is 5.\n@@ -43,10 +43,10 @@ Then you can see it at the Active Chain page.\n## Use auto-mode to provision chains\n-It will be difficult if you have numbers of chains to create manually. Cello provides automatic ways to save the time.\n+It will be difficult if you have a numbers of chains to create manually. Cello provides automated ways to save time.\n-* Use the host action dropdown menu: The Fillup button will fill the host full with chains till its capacity, while the Clean button will clean all unused chains from the host.\n-* Use the Autofill checkbox: In the host configuration, you can find a `Autofill` checkbox, which will automatically watch the host and keep it's full with chains to the capacity.\n+* Use the host action dropdown menu: The Fillup button will fill the host full with chains until its at capacity, while the Clean button will clean all unused chains from the host.\n+* Use the Autofill checkbox: In the host configuration, you can find a `Autofill` checkbox, which will automatically watch the host and keep it full with chains to the capacity.\nTry these methods as you like.\n",
        "org_msg": "[CE-92]Fixed a broken link\n[ci-skip]",
        "sim_msg": "move bridges into separate function",
        "sim_diff": "diff --git a/cmd/teleproxy/teleproxy.go b/cmd/teleproxy/teleproxy.go @@ -138,38 +138,8 @@ func main() {\ndisconnect := connect()\ndefer disconnect()\n- // setup kubernetes bridge\n- w := watcher.NewWatcher(*kubeconfig)\n- defer w.Stop()\n- w.Watch(\"services\", func(w *watcher.Watcher) {\n- table := route.Table{Name: \"kubernetes\"}\n- for _, svc := range w.List(\"services\") {\n- ip, ok := svc.Spec()[\"clusterIP\"]\n- if ok {\n- table.Add(route.Route{\n- Name: svc.Name(),\n- Ip: ip.(string),\n- Proto: \"tcp\",\n- Target: \"1234\",\n- })\n- }\n- }\n- iceptor.Update(table)\n- dns.Flush()\n- })\n-\n- // setup docker bridge\n- dw := docker.NewWatcher()\n- dw.Start(func(w *docker.Watcher) {\n- table := route.Table{Name: \"docker\"}\n- for name, ip := range w.Containers {\n- table.Add(route.Route{Name: name, Ip: ip, Proto: \"tcp\"})\n- }\n- // this sometimes panics with a send on a closed channel\n- iceptor.Update(table)\n- dns.Flush()\n- })\n- defer dw.Stop()\n+ shutdown := bridges(iceptor)\n+ defer shutdown()\nch := make(chan os.Signal)\nsignal.Notify(ch, syscall.SIGINT, syscall.SIGTERM)\n@@ -210,3 +180,41 @@ func connect() func() {\npf.Shutdown()\n}\n}\n+\n+func bridges(iceptor *interceptor.Interceptor) func() {\n+ // setup kubernetes bridge\n+ w := watcher.NewWatcher(*kubeconfig)\n+ w.Watch(\"services\", func(w *watcher.Watcher) {\n+ table := route.Table{Name: \"kubernetes\"}\n+ for _, svc := range w.List(\"services\") {\n+ ip, ok := svc.Spec()[\"clusterIP\"]\n+ if ok {\n+ table.Add(route.Route{\n+ Name: svc.Name(),\n+ Ip: ip.(string),\n+ Proto: \"tcp\",\n+ Target: \"1234\",\n+ })\n+ }\n+ }\n+ iceptor.Update(table)\n+ dns.Flush()\n+ })\n+\n+ // setup docker bridge\n+ dw := docker.NewWatcher()\n+ dw.Start(func(w *docker.Watcher) {\n+ table := route.Table{Name: \"docker\"}\n+ for name, ip := range w.Containers {\n+ table.Add(route.Route{Name: name, Ip: ip, Proto: \"tcp\"})\n+ }\n+ // this sometimes panics with a send on a closed channel\n+ iceptor.Update(table)\n+ dns.Flush()\n+ })\n+\n+ return func() {\n+ dw.Stop()\n+ w.Stop()\n+ }\n+}\n",
        "chatgpt_cot": "Update tutorial.md: Fix typos in terminology and installation instructions, improve clarity in chain creation automation steps."
    },
    {
        "org_diff": "diff --git a/sc2/protocol.py b/sc2/protocol.py @@ -42,9 +42,11 @@ class Protocol:\ntry:\nresponse_bytes = await self._ws.receive_bytes()\nexcept TypeError:\n- # logger.exception(\"Cannot receive: Connection already closed.\")\n- # raise ConnectionAlreadyClosed(\"Connection already closed.\")\n- logger.info(\"Cannot receive: Connection already closed.\")\n+ if self._status == Status.ended:\n+ logger.info(\"Cannot receive: Game has already ended.\")\n+ sys.exit()\n+ else:\n+ logger.error(\"Cannot receive: Connection already closed.\")\nsys.exit(2)\nexcept asyncio.CancelledError:\n# If request is sent, the response must be received before reraising cancel\n",
        "org_msg": "Fix exit code 2 being returned after game has already ended",
        "sim_msg": "close protocol if transport reuse brings responses before requests",
        "sim_diff": "diff --git a/lbrynet/blob_exchange/client.py b/lbrynet/blob_exchange/client.py @@ -35,6 +35,9 @@ class BlobExchangeClientProtocol(asyncio.Protocol):\nif self._response_fut and not self._response_fut.done():\nself._response_fut.cancel()\nreturn\n+ if not self._response_fut:\n+ log.warning(\"Protocol received data before expected, probable race on keep alive. Closing transport.\")\n+ return self.close()\nif self._blob_bytes_received and not self.writer.closed():\nreturn self._write(data)\n",
        "chatgpt_cot": "\"Handle connection closed and game ended scenarios in protocol receive method\""
    },
    {
        "org_diff": "diff --git a/fkie_node_manager/src/fkie_node_manager/node_tree_model.py b/fkie_node_manager/src/fkie_node_manager/node_tree_model.py @@ -1009,6 +1009,7 @@ class HostItem(GroupItem):\ntooltip += '<p>'\ntooltip += '<a href=\"remove-all-launch-server://%s\">kill all launch server</a>' % utf8(self.masteruri).replace('http://', '')\ntooltip += '<p>'\n+ if self.local:\nsysmon_setup_str = '<a href=\"nmd-cfg://%s\" title=\"Configure Daemon\"><img src=\":icons/crystal_clear_settings_24.png\" alt=\"configure\"></a>' % (utf8(self.masteruri).replace('http://', ''))\nsysmon_state_str = 'disable' if self.sysmon_state else 'enable'\nsysmon_switch_str = '<a href=\"sysmon-switch://%s\">%s</a>' % (utf8(self.masteruri).replace('http://', ''), sysmon_state_str)\n",
        "org_msg": "disabled system monitoring on remote host view",
        "sim_msg": "show avids in segments and ctids in coded text",
        "sim_diff": "diff --git a/qualcoder/view_av.py b/qualcoder/view_av.py @@ -1048,9 +1048,9 @@ class DialogCodeAV(QtWidgets.QDialog):\nfor c in self.code_text:\nif c['important'] == 1:\nimp_coded.append(c)\n- self.eventFilterTT.set_codes_and_annotations(imp_coded, self.codes, self.annotations)\n+ self.eventFilterTT.set_codes_and_annotations(self.app, imp_coded, self.codes, self.annotations)\nelse:\n- self.eventFilterTT.set_codes_and_annotations(self.code_text, self.codes, self.annotations)\n+ self.eventFilterTT.set_codes_and_annotations(self.app, self.code_text, self.codes, self.annotations)\nself.unlight()\nself.highlight()\n@@ -3063,8 +3063,12 @@ class ToolTipEventFilter(QtCore.QObject):\ncodes = None\ncode_text = None\nannotations = None\n+ app = None\n+\n+ def set_codes_and_annotations(self, app, code_text, codes, annotations):\n+ \"\"\" Update codes and coded text and annotations for tooltips. \"\"\"\n- def set_codes_and_annotations(self, code_text, codes, annotations):\n+ self.app = app\nself.code_text = code_text\nself.codes = codes\nself.annotations = annotations\n@@ -3075,7 +3079,7 @@ class ToolTipEventFilter(QtCore.QObject):\nitem['color'] = c['color']\ndef eventFilter(self, receiver, event):\n- \"\"\" Tool tip event filter for ?textEdit \"\"\"\n+ \"\"\" Tool tip event filter for textEdit \"\"\"\nif event.type() == QtCore.QEvent.Type.ToolTip:\ncursor = receiver.cursorForPosition(event.pos())\n@@ -3093,6 +3097,8 @@ class ToolTipEventFilter(QtCore.QObject):\ntry:\ntext_ += '<p style=\"background-color:' + item['color']\ntext_ += '; color:' + TextColor(item['color']).recommendation + '\">' + item['name']\n+ if self.app.settings['showids'] == 'True':\n+ text_ += \" [ctid:\" + str(item['ctid']) + \"] \"\nif item['avid'] is not None:\ntext_ += \" [\" + msecs_to_hours_mins_secs(item['av_pos0'])\ntext_ += \" - \" + msecs_to_hours_mins_secs(item['av_pos1']) + \"]\"\n@@ -3425,6 +3431,8 @@ class SegmentGraphicsItem(QtWidgets.QGraphicsLineItem):\nseg_time = \"[\" + msecs_to_hours_mins_secs(self.segment['pos0']) + \" - \"\nseg_time += msecs_to_hours_mins_secs(self.segment['pos1']) + \"]\"\ntooltip += seg_time\n+ if self.app.settings['showids'] == 'True':\n+ tooltip += \" [avid:\" + str(self.segment['avid']) + \"]\"\nif self.segment['memo'] != \"\":\ntooltip += \"\\n\" + _(\"MEMO: \") + self.segment['memo']\nif self.segment['seltext'] is not None and self.segment['seltext'] != \"\":\n",
        "chatgpt_cot": "Add local system monitoring configuration option for HostItem in Node Tree Model."
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/editor/text_edit.py b/node_manager_fkie/src/node_manager_fkie/editor/text_edit.py @@ -337,7 +337,6 @@ class TextEdit(QTextEdit):\ndef _has_uncommented(self):\ncursor = QTextCursor(self.textCursor())\nif not cursor.isNull():\n-# cursor.beginEditBlock()\nstart = cursor.selectionStart()\nend = cursor.selectionEnd()\ncursor.setPosition(start)\n@@ -360,17 +359,11 @@ class TextEdit(QTextEdit):\ncursor.movePosition(QTextCursor.EndOfLine, QTextCursor.KeepAnchor)\nif xml_file:\nif not xmlre.match(cursor.selectedText()):\n-# cursor.endEditBlock()\n-# self.undo()\nreturn True\nelse:\nif not otherre.match(cursor.selectedText()):\n-# cursor.endEditBlock()\n-# self.undo()\nreturn True\ncursor.movePosition(QTextCursor.NextBlock)\n-# self.undo()\n-# cursor.endEditBlock()\nreturn False\ndef commentText(self):\n",
        "org_msg": "node_manager_fkie: editor: removed commented blocks",
        "sim_msg": "update context menu Mark avaibility",
        "sim_diff": "diff --git a/qualcoder/case_file_manager.py b/qualcoder/case_file_manager.py @@ -321,9 +321,10 @@ class DialogCaseFileManager(QtWidgets.QDialog):\naction_copy = None\nif selected_text == \"\":\naction_select_all = menu.addAction(_(\"Select all\"))\n- if selected_text != \"\":\n+ if selected_text != \"\" and not self.is_marked():\naction_mark = menu.addAction(_(\"Mark\"))\n- action_copy = menu.addAction(\"Copy\")\n+ if selected_text != \"\":\n+ action_copy = menu.addAction(_(\"Copy\"))\nfor item in self.case_text:\nif cursor.position() >= item['pos0'] and cursor.position() <= item['pos1']:\naction_unmark = menu.addAction(_(\"Unmark\"))\n@@ -340,6 +341,18 @@ class DialogCaseFileManager(QtWidgets.QDialog):\nif action == action_select_all:\nself.ui.textBrowser.selectAll()\n+ def is_marked(self):\n+ \"\"\" Check current text selection and return False if not marked and True if marked. \"\"\"\n+\n+ pos0 = self.ui.textBrowser.textCursor().selectionStart()\n+ pos1 = self.ui.textBrowser.textCursor().selectionEnd()\n+ for c in self.case_text:\n+ if pos0 >= c['pos0'] and pos0 <= c['pos1']:\n+ return True\n+ if pos1 >= c['pos0'] and pos1 <= c['pos1']:\n+ return True\n+ return False\n+\ndef copy_selected_text_to_clipboard(self):\nselected_text = self.ui.textBrowser.textCursor().selectedText()\n",
        "chatgpt_cot": "\"Remove unnecessary comments and code blocks in TextEdit class to improve readability and maintainability.\""
    },
    {
        "org_diff": "diff --git a/docs/index.html b/docs/index.html @@ -59,7 +59,7 @@ Overview</h3>\n</ul>\n</p>\n-<p><img src=\"images/ros_multimaster.png\" alt=\"ROS Multimaster\"></p>\n+<p><img src=\"../multimaster_overview.png\" alt=\"ROS Multimaster\"></p>\n<!--pre><code>$ cd your_repo_root/repo_name\n$ git fetch origin\n$ git checkout gh-pages\n",
        "org_msg": "changed docs overview image",
        "sim_msg": "added link ref to text",
        "sim_diff": "diff --git a/web-docs/index.html b/web-docs/index.html </a>\n</div>\n<div class=\"panel-heading text-center\">\n- <h3 class=\"panel-title\"><a href=\"#\">Algorithm Integration</a></h3>\n+ <h3 class=\"panel-title\"><a href=\"docs/algorithm_integration/index.html\">Algorithm Integration</a></h3>\n</div>\n</div>\n</div>\n</a>\n</div>\n<div class=\"panel-heading text-center\">\n- <h3 class=\"panel-title\"><a href=\"#\">Recipe Editor</a></h3>\n+ <h3 class=\"panel-title\"><a href=\"https://appliedis.github.io/demos/scale/#/recipes/types/2\">Recipe Editor</a></h3>\n</div>\n</div>\n</div>\n",
        "chatgpt_cot": "Update image source in index.html to fix broken image link."
    },
    {
        "org_diff": "diff --git a/docker/ansible-agent/Dockerfile.in b/docker/ansible-agent/Dockerfile.in @@ -12,7 +12,8 @@ ARG gid=1000\nRUN apt-get update && \\\napt-get install -y bash curl python-dev sshpass \\\n- python-pip build-essential openssh-client && \\\n+ python-pip build-essential openssh-client libffi-dev \\\n+ libssl-dev && \\\npip install --upgrade pip ansible boto boto3 shade \\\npyyaml openshift && \\\ngroupadd -g ${gid} ${user} && \\\n",
        "org_msg": "make docker fails\nmake docker fails at ansible-agent creation as it was missing\nlibssl and libffi packages by installing libssl-dev and libffi-dev\ndeb packages the issue is resolved.",
        "sim_msg": "Upgrade pip as part of dockerfile",
        "sim_diff": "diff --git a/docker/Dockerfile b/docker/Dockerfile @@ -75,6 +75,9 @@ RUN apk add --no-cache git make bash \\\n# Required for python cryptography support\nopenssl-dev musl-dev libffi-dev rust cargo\n+# Update pip\n+RUN pip install --upgrade pip\n+\n# Install required base-level python packages\nCOPY requirements.txt requirements.txt\nRUN pip install --no-cache-dir -U -r requirements.txt\n@@ -133,4 +136,3 @@ ENTRYPOINT [\"/bin/bash\", \"./docker/init.sh\"]\n# Launch the development server\nCMD [\"invoke\", \"server\", \"-a\", \"${INVENTREE_WEB_ADDR}:${INVENTREE_WEB_PORT}\"]\n-\n",
        "chatgpt_cot": "\"Add libffi-dev and libssl-dev to Dockerfile to support ansible-agent dependencies\""
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/cmake/version.cmake b/node_manager_fkie/cmake/version.cmake @@ -4,8 +4,8 @@ macro(generate_version)\nfind_program(GIT git)\nif (NOT GIT)\nmessage(STATUS \"git binary not found, VERSION and DATE files are not created\")\n- return()\n- endif()\n+ else(GIT)\n+ # install a file with version tag\nset(VERSION_DIR \"${CATKIN_DEVEL_PREFIX}/${CATKIN_PACKAGE_SHARE_DESTINATION}\")\nset(VERSION_FILES \"\")\nset(VERSION_FILE \"${VERSION_DIR}/VERSION\")\n@@ -35,4 +35,5 @@ macro(generate_version)\nDEPENDS ${VERSION_FILES}\nCOMMENT \"Generate version files\"\n)\n+ endif()\nendmacro()\n",
        "org_msg": "fixed install node_manager_fkie",
        "sim_msg": "Add Sci Linux compilation option to ua",
        "sim_diff": "diff --git a/src/ua/Makefile b/src/ua/Makefile @@ -22,6 +22,7 @@ VERSION := $(shell cat $(DNANEXUS_HOME)/build/info/ua_version || echo 'UNKNOWN_V\nDXTOOLKIT_GITVERSION := $(shell cat $(DNANEXUS_HOME)/build/info/version || echo 'UNKNOWN_VERSION')\nCENTOS_MAJOR_VERSION := $(shell grep -o \"CentOS release [0-9]\\+\" /etc/issue | sed -e \"s/CentOS release //\")\nRHEL_MAJOR_VERSION := $(shell test -e /etc/redhat-release && (grep -o \"Red Hat Enterprise Linux .* release [0-9]\\+\" /etc/redhat-release | sed -e \"s/Red Hat Enterprise Linux .* release //\"))\n+RHSL_MAJOR_VERSION := $(shell test -e /etc/redhat-release && (grep -o \"Scientific Linux.* release [0-9]\\+\" /etc/redhat-release | sed -e \"s/Scientific Linux.* release //\"))\ncurl_dir = $(DNANEXUS_HOME)/src/curl/stage\ncares_dir = $(DNANEXUS_HOME)/src/c-ares/stage\n@@ -79,6 +80,9 @@ else\nelse ifeq ($(RHEL_MAJOR_VERSION), 7)\nCXXFLAGS += -DLINUX_BUILD=1 -std=c++0x\nLDFLAGS += -lrt -static\n+ else ifeq ($(RHSL_MAJOR_VERSION), 7)\n+ CXXFLAGS += -DLINUX_BUILD=1 -std=c++0x\n+ LDFLAGS += -lrt -static\nelse\nCXXFLAGS += -DLINUX_BUILD=1 -std=c++0x\nLDFLAGS += -lrt -lidn -static\n",
        "chatgpt_cot": "Add handling for when git binary is not found and install a file with version tag in version.cmake file."
    },
    {
        "org_diff": "diff --git a/sc2/bot_ai.py b/sc2/bot_ai.py @@ -1021,10 +1021,14 @@ class BotAI(DistanceCalculation):\nequiv_values: Set[int] = {structure_type_value} | {\ns_type.value for s_type in EQUIVALENTS_FOR_TECH_PROGRESS.get(structure_type, set())\n}\n+ # SUPPLYDEPOTDROP is not in self._game_data.units, so bot_ai should not check the build progress via creation ability (worker abilities)\n+ if structure_type_value not in self._game_data.units:\n+ return max([s.build_progress for s in self.structures if s._proto.unit_type in equiv_values], default=0)\ncreation_ability: AbilityData = self._game_data.units[structure_type_value].creation_ability\nmax_value = max(\n[s.build_progress for s in self.structures if s._proto.unit_type in equiv_values]\n- + [self._abilities_all_units[1].get(creation_ability, 0)]\n+ + [self._abilities_all_units[1].get(creation_ability, 0)],\n+ default=0,\n)\nreturn max_value\n@@ -1061,7 +1065,7 @@ class BotAI(DistanceCalculation):\n# unit_info_id_value = self._game_data.units[structure_type.value]._proto.tech_requirement\nif not unit_info_id_value: # Equivalent to \"if unit_info_id_value == 0:\"\nreturn 1\n- progresses: List[int] = [self.structure_type_build_progress(unit_info_id_value)]\n+ progresses: List[float] = [self.structure_type_build_progress(unit_info_id_value)]\nfor equiv_structure in EQUIVALENTS_FOR_TECH_PROGRESS.get(unit_info_id, []):\nprogresses.append(self.structure_type_build_progress(equiv_structure.value))\nreturn max(progresses)\n",
        "org_msg": "Fix structure_type_build_progress(), related issue:",
        "sim_msg": "added time to the saved files",
        "sim_diff": "diff --git a/bot_manager.py b/bot_manager.py @@ -178,7 +178,7 @@ class BotManager:\ncurrent_time = game_tick_packet.gameInfo.TimeSeconds\nif self.save_data and game_tick_packet.gameInfo.bRoundActive and not old_time == current_time and not current_time == -10:\n- np_input = self.input_converter.create_input_array(game_tick_packet)\n+ np_input = self.input_converter.create_input_array(game_tick_packet, passed_time=time.time() - before2)\nnp_output = np.array(controller_input, dtype=np.float32)\nself.input_array = np.append(self.input_array, np_input)\nself.output_array = np.append(self.output_array, np_output)\n",
        "chatgpt_cot": "Fix compilation issue due to incorrect data type in build progress calculation and handle SUPPLYDEPOTDROP structure type value in bot AI."
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/node_tree_model.py b/node_manager_fkie/src/node_manager_fkie/node_tree_model.py @@ -750,8 +750,16 @@ class GroupItem(QStandardItem):\nif self.is_system_group:\nif self.name.lower() != item.lower():\nreturn True\n+ elif item.lower() == 'system':\n+ return False\nreturn self.name.lower() > item.lower()\nelif not (item is None):\n+ # put the group with SYSTEM nodes at the end\n+ if item.is_system_group:\n+ if self.name.lower() != item.lower():\n+ return True\n+ elif self.is_syste_group:\n+ return False\nreturn self.name.lower() > item.name.lower()\nreturn False\n",
        "org_msg": "node_manager_fkie: fix for SYSTEM placing",
        "sim_msg": "RENAME engine -> db_engine",
        "sim_diff": "diff --git a/packages/syft/src/syft/core/node/common/node.py b/packages/syft/src/syft/core/node/common/node.py @@ -110,7 +110,7 @@ class Node(AbstractNode):\nverify_key: Optional[VerifyKey] = None,\ndb_path: Optional[str] = None,\nTableBase: Any = None,\n- engine: Any = None,\n+ db_engine: Any = None,\ndb: Any = None,\n):\n@@ -132,14 +132,14 @@ class Node(AbstractNode):\nif db is None:\n# If a DB engine isn't provided then\n- if engine is None:\n+ if db_engine is None:\nengine = create_engine(\"sqlite://\", echo=False)\n- db = sessionmaker(bind=engine)()\n+ db = sessionmaker(bind=db_engine)()\n# cache these variables on self\nself.TableBase = TableBase\n- self.engine = engine\n+ self.db_engine = db_engine\nself.db = db\n# launch the tables in the database\n@@ -153,8 +153,9 @@ class Node(AbstractNode):\n# become quite numerous (or otherwise fill up RAM).\n# self.store is the elastic memory.\n+\nself.store = BinObjectManager(\n- db=self.db\n+ db=self.db_engine\n)\n# We need to register all the services once a node is created\n",
        "chatgpt_cot": "Fix comparison logic for system groups in node tree model. Added condition to handle system group placement."
    },
    {
        "org_diff": "diff --git a/test/autotest_bot.py b/test/autotest_bot.py @@ -223,18 +223,42 @@ class TestBot(sc2.BotAI):\n# Test if reaper grenade shows up in effects\nasync def test_botai_actions6(self):\ncenter = self._game_info.map_center\n- if self.units(UnitTypeId.REAPER).amount < 50:\n+ if self.units(UnitTypeId.REAPER).amount < 10:\nawait self._client.debug_create_unit([[UnitTypeId.REAPER, 10, center, 1]])\nfor reaper in self.units(UnitTypeId.REAPER):\nself.do(reaper(AbilityId.KD8CHARGE_KD8CHARGE, center))\nasync def test_botai_actions6_successful(self):\nif len(self.state.effects) > 2:\n+ # print(f\"Effects: {self.state.effects}\")\nfor effect in self.state.effects:\n- print(f\"Effect: {effect}\")\n+ # print(f\"Effect: {effect}\")\n+ pass\n+ # Cleanup\nawait self._client.debug_kill_unit(self.units(UnitTypeId.REAPER))\nreturn True\n+ # Test ravager effects\n+ async def test_botai_actions7(self):\n+ center = self._game_info.map_center\n+ if self.units(UnitTypeId.RAVAGER).amount < 10:\n+ await self._client.debug_create_unit([[UnitTypeId.RAVAGER, 10, center, 1]])\n+ for reaper in self.units(UnitTypeId.RAVAGER):\n+ self.do(reaper(AbilityId.EFFECT_CORROSIVEBILE, center))\n+\n+ async def test_botai_actions7_successful(self):\n+ success = False\n+ if len(self.state.effects) >= 1:\n+ # print(f\"Effects: {self.state.effects}\")\n+ for effect in self.state.effects:\n+ # print(f\"Effect: {effect}\")\n+ if effect.id == EffectId.RAVAGERCORROSIVEBILECP:\n+ success = True\n+ if success:\n+ # Cleanup\n+ await self._client.debug_kill_unit(self.units(UnitTypeId.RAVAGER))\n+ return True\n+\ndef main():\nsc2.run_game(\n",
        "org_msg": "Add ravager bile test",
        "sim_msg": "filesystem onion tests",
        "sim_diff": "diff --git a/test/test_controller.py b/test/test_controller.py @@ -1207,7 +1207,7 @@ class FactoryFunctionTests(unittest.TestCase):\n# just testing the __str__ method doesn't explode\n-class OnionFactoryTests(unittest.TestCase):\n+class EphemeralOnionFactoryTests(unittest.TestCase):\n\"\"\"\nthe onion-service factory functions verify their args\n\"\"\"\n@@ -1262,3 +1262,54 @@ class OnionFactoryTests(unittest.TestCase):\nself.assertEqual(\"deadbeef.onion\", service.hostname)\nself.assertEqual(\"BlobbyMcBlobberson\", service.private_key)\nself.assertEqual(set(['80 127.0.0.1:1234']), service.ports)\n+\n+\n+class FilesystemOnionFactoryTests(unittest.TestCase):\n+ \"\"\"\n+ the onion-service factory functions verify their args\n+ \"\"\"\n+\n+ def setUp(self):\n+ reactor = Mock()\n+ proto = Mock()\n+ directlyProvides(proto, ITorControlProtocol)\n+ self.cfg = Mock()\n+ self.tor = Tor(reactor, proto, _tor_config=self.cfg)\n+ self.hsdir = self.mktemp()\n+ os.mkdir(self.hsdir)\n+\n+ @defer.inlineCallbacks\n+ def test_ports_not_sequence(self):\n+ with self.assertRaises(ValueError) as ctx:\n+ yield self.tor.create_filesystem_onion_service(\"not a sequence\", self.hsdir)\n+\n+ @defer.inlineCallbacks\n+ def test_ports_contain_non_ints(self):\n+ with self.assertRaises(ValueError) as ctx:\n+ yield self.tor.create_filesystem_onion_service(['not an int'], self.hsdir)\n+ self.assertIn(\"contain a single int\", str(ctx.exception))\n+\n+ @defer.inlineCallbacks\n+ def test_ports_contain_non_ints(self):\n+ with self.assertRaises(ValueError) as ctx:\n+ yield self.tor.create_filesystem_onion_service([('not', 'an int')], self.hsdir)\n+ self.assertIn(\"non-integer\", str(ctx.exception))\n+\n+ @defer.inlineCallbacks\n+ def test_version_invalid(self):\n+ with self.assertRaises(ValueError) as ctx:\n+ yield self.tor.create_filesystem_onion_service([80], self.hsdir, version=1)\n+ self.assertIn(\"The only valid Onion service versions\", str(ctx.exception))\n+\n+ @defer.inlineCallbacks\n+ def test_happy_path(self):\n+ self.cfg.OnionServices = []\n+ with patch('txtorcon.controller.available_tcp_port', return_value=1234):\n+ with patch.object(self.cfg, 'tor_protocol') as proto:\n+ #proto.queue_command = Mock(return_value=\"ServiceID=deadbeef\\nPrivateKey=BlobbyMcBlobberson\")\n+ proto.queue_command = Mock(return_value=\"OK\")\n+ d = self.tor.create_filesystem_onion_service([80], self.hsdir)\n+ service = yield d\n+ self.assertEqual(\"deadbeef.onion\", service.hostname)\n+ self.assertEqual(\"BlobbyMcBlobberson\", service.private_key)\n+ self.assertEqual(set(['80 127.0.0.1:1234']), service.ports)\n",
        "chatgpt_cot": "Add test cases for reaper and ravager effects, and implement cleanup functionality to ensure successful test execution."
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/file_watcher.py b/node_manager_fkie/src/node_manager_fkie/file_watcher.py @@ -133,8 +133,10 @@ class FileWatcher(QObject):\nfor _, (binary_file, _, _) in self.binaries.items():\nbinaries.add(binary_file)\nresult.update(binaries)\n- files = self.file_watcher.files()\n- if files:\n- self.file_watcher.removePaths(files)\n- if list(result):\n- self.file_watcher.addPaths(list(result))\n+ files = set(self.file_watcher.files())\n+ to_remove = list(files - result)\n+ if to_remove:\n+ self.file_watcher.removePaths(to_remove)\n+ to_add = list(result - files)\n+ if to_add:\n+ self.file_watcher.addPaths(to_add)\n",
        "org_msg": "node_manager_fkie: fixed crash while stop or start a lot of nodes",
        "sim_msg": "syft: revert change of remove obj metadata query in delete",
        "sim_diff": "diff --git a/packages/syft/src/syft/core/node/common/node_manager/bin_obj_manager.py b/packages/syft/src/syft/core/node/common/node_manager/bin_obj_manager.py @@ -153,6 +153,12 @@ class BinObjectManager(ObjectStore):\nobject_to_delete = (\nlocal_session.query(BinObject).filter_by(id=str(key.value)).first()\n)\n+ metadata_to_delete = (\n+ local_session.query(ObjectMetadata)\n+ .filter_by(obj=str(key.value))\n+ .first()\n+ )\n+ local_session.delete(metadata_to_delete)\nlocal_session.delete(object_to_delete)\nlocal_session.commit()\nlocal_session.close()\n",
        "chatgpt_cot": "\"Optimize file watching logic in FileWatcher class to improve efficiency and performance of file monitoring operations.\""
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/MainWindow.ui b/node_manager_fkie/src/node_manager_fkie/MainWindow.ui @@ -653,9 +653,7 @@ p, li { white-space: pre-wrap; }\n</widget>\n</item>\n<item>\n- <widget class=\"QWidget\" name=\"tabPlace\" native=\"true\">\n- <zorder>masterInfoFrame</zorder>\n- </widget>\n+ <widget class=\"QWidget\" name=\"tabPlace\" native=\"true\"/>\n</item>\n</layout>\n</widget>\n@@ -1034,6 +1032,15 @@ p, li { white-space: pre-wrap; }\n<property name=\"palette\">\n<palette>\n<active>\n+ <colorrole role=\"Text\">\n+ <brush brushstyle=\"SolidPattern\">\n+ <color alpha=\"255\">\n+ <red>0</red>\n+ <green>0</green>\n+ <blue>0</blue>\n+ </color>\n+ </brush>\n+ </colorrole>\n<colorrole role=\"Base\">\n<brush brushstyle=\"SolidPattern\">\n<color alpha=\"255\">\n@@ -1045,6 +1052,15 @@ p, li { white-space: pre-wrap; }\n</colorrole>\n</active>\n<inactive>\n+ <colorrole role=\"Text\">\n+ <brush brushstyle=\"SolidPattern\">\n+ <color alpha=\"255\">\n+ <red>0</red>\n+ <green>0</green>\n+ <blue>0</blue>\n+ </color>\n+ </brush>\n+ </colorrole>\n<colorrole role=\"Base\">\n<brush brushstyle=\"SolidPattern\">\n<color alpha=\"255\">\n@@ -1056,6 +1072,15 @@ p, li { white-space: pre-wrap; }\n</colorrole>\n</inactive>\n<disabled>\n+ <colorrole role=\"Text\">\n+ <brush brushstyle=\"SolidPattern\">\n+ <color alpha=\"255\">\n+ <red>169</red>\n+ <green>167</green>\n+ <blue>167</blue>\n+ </color>\n+ </brush>\n+ </colorrole>\n<colorrole role=\"Base\">\n<brush brushstyle=\"SolidPattern\">\n<color alpha=\"255\">\n",
        "org_msg": "node_manager_fkie: changed default color in description widget",
        "sim_msg": "Use new style for simple items",
        "sim_diff": "diff --git a/gaphor/diagram/general/simpleitem.py b/gaphor/diagram/general/simpleitem.py @@ -12,12 +12,9 @@ from gaphor.diagram.style import Style\nclass Line(_Line):\n-\n- __style__ = {\"line-width\": 2, \"line-color\": (0, 0, 0, 1)}\n-\ndef __init__(self, id=None, model=None):\nsuper(Line, self).__init__()\n- self.style = Style(Line.__style__)\n+ self.style = {\"line-width\": 2, \"color\": (0, 0, 0, 1)}.__getitem__\nself._id = id\nself.fuzziness = 2\nself._handles[0].connectable = False\n@@ -56,8 +53,8 @@ class Line(_Line):\ndef draw(self, context):\ncr = context.cairo\nstyle = self.style\n- cr.set_line_width(style.line_width)\n- cr.set_source_rgba(*style.line_color)\n+ cr.set_line_width(style(\"line-width\"))\n+ cr.set_source_rgba(*style(\"color\"))\nsuper(Line, self).draw(context)\n@@ -69,15 +66,9 @@ class Box(Element):\nSW +---+ SE\n\"\"\"\n- __style__ = {\n- \"border-width\": 2,\n- \"border-color\": (0, 0, 0, 1),\n- \"fill-color\": (1, 1, 1, 0),\n- }\n-\ndef __init__(self, id=None, model=None):\nsuper(Box, self).__init__(10, 10)\n- self.style = Style(Box.__style__)\n+ self.style = {\"line-width\": 2, \"color\": (0, 0, 0, 1)}.__getitem__\nself._id = id\nid = property(lambda self: self._id, doc=\"Id\")\n@@ -103,10 +94,10 @@ class Box(Element):\nnw = self._handles[NW]\nstyle = self.style\ncr.rectangle(nw.pos.x, nw.pos.y, self.width, self.height)\n- cr.set_source_rgba(*style.fill_color)\n- cr.fill_preserve()\n- cr.set_source_rgba(*style.border_color)\n- cr.set_line_width(style.border_width)\n+ # cr.set_source_rgba(*style(\"color\"))\n+ # cr.fill_preserve()\n+ cr.set_source_rgba(*style(\"color\"))\n+ cr.set_line_width(style(\"line-width\"))\ncr.stroke()\n@@ -114,15 +105,9 @@ class Ellipse(Element):\n\"\"\"\n\"\"\"\n- __style__ = {\n- \"border-width\": 2,\n- \"border-color\": (0, 0, 0, 1),\n- \"fill-color\": (1, 1, 1, 0),\n- }\n-\ndef __init__(self, id=None, model=None):\nsuper(Ellipse, self).__init__()\n- self.style = Style(Ellipse.__style__)\n+ self.style = {\"line-width\": 2, \"color\": (0, 0, 0, 1)}.__getitem__\nself._id = id\nid = property(lambda self: self._id, doc=\"Id\")\n@@ -153,11 +138,8 @@ class Ellipse(Element):\ncr.move_to(self.width, ry)\npath_ellipse(cr, rx, ry, self.width, self.height)\n- cr.set_source_rgba(*style.fill_color)\n- cr.fill_preserve()\n- cr.set_source_rgba(*style.border_color)\n- cr.set_line_width(style.border_width)\n+ # cr.set_source_rgba(*style.fill_color)\n+ # cr.fill_preserve()\n+ cr.set_source_rgba(*style(\"color\"))\n+ cr.set_line_width(style(\"line-width\"))\ncr.stroke()\n-\n-\n-# vim:sw=4:et:ai\n",
        "chatgpt_cot": "Update MainWindow.ui to remove zorder and update color roles of the text and base palette."
    },
    {
        "org_diff": "diff --git a/fkie_node_manager/src/fkie_node_manager/master_view_proxy.py b/fkie_node_manager/src/fkie_node_manager/master_view_proxy.py @@ -1432,11 +1432,12 @@ class MasterViewProxy(QWidget):\nitem += '<td colspan=\"2\" style=\"float:left\"><span style=\"color:red;\">?sync </span>%s<td>' % (item_name)\nitem += '</tr>'\nelif list_type == 'LAUNCH':\n- item_ref = '<a href=\"%s\">%s</a>' % (i.replace('grpc://', 'open-edit://'), os.path.basename(item_name))\nif i in self.__configs and self.__configs[i].global_param_done:\nitem = '<tr>'\n+ item_ref = '<a href=\"%s\">%s</a>' % (i.replace('grpc://', 'open-edit://'), os.path.basename(item_name))\nitem += '<td>%s<td>' % (item_ref)\n- item += '<td><i>%s</i><td>' % (item_name)\n+ pkg, _path = nm.nmd().file.package_name(i)\n+ item += '<td><i>%s</i><td>' % (os.path.dirname(item_name) if pkg is None else pkg)\nitem += '</tr>'\nresult += item\nresult += '</table>\\n<br>'\n@@ -1554,13 +1555,12 @@ class MasterViewProxy(QWidget):\n# create description for a node\nns, sep, name = node.name.rpartition(rospy.names.SEP)\nlaunches = [c for c in node.cfgs if not isinstance(c, tuple)]\n- default_cfgs = [c[0] for c in node.cfgs if isinstance(c, tuple)]\ncrystal_clear_settings_24 = nm.settings().icon_path('crystal_clear_settings_24.png')\nif name == 'node_manager_daemon':\ntext += '<a href=\"nmd-cfg://%s\" title=\"Configure Daemon\"><img src=\"%s\" alt=\"configure\"></a>' % (utf8(self.masteruri).replace('http://', ''), crystal_clear_settings_24)\nelif name == 'node_manager' and nm.is_local(self.mastername):\ntext += '<a href=\"nm-cfg://%s\" title=\"Configure Node Manager\"><img src=\"%s\" alt=\"configure\"></a>' % (utf8(self.masteruri).replace('http://', ''), crystal_clear_settings_24)\n- if launches or default_cfgs:\n+ if launches:\nsekkyumu_restart_24 = nm.settings().icon_path('sekkyumu_restart_24.png')\nsekkyumu_restart_g_24 = nm.settings().icon_path('sekkyumu_restart_g_24.png')\ntext += '<a href=\"restart-node://%s\" title=\"Restart node Ctrl+Shift+R\"><img src=\"%s\" alt=\"restart\"></a>' % (node.name, sekkyumu_restart_24)\n",
        "org_msg": "fkie_node_manager: show package name in node-info instead of full path",
        "sim_msg": "Simplified grammar",
        "sim_diff": "diff --git a/packages/hagrid/hagrid/cli.py b/packages/hagrid/hagrid/cli.py @@ -21,13 +21,13 @@ def cli():\n@click.command(help=\"Start a new PyGrid domain/network node!\")\n-@click.argument(\"type\", type=click.Choice([\"domain\", \"network\"]))\n+@click.argument(\"name\", type=str)\n@click.option(\n- \"--name\",\n- default=\"\",\n+ \"--type\",\n+ default=\"domain\",\nrequired=False,\n- type=str,\n- help=\"The name of your new domain/network node. (Default: <randomly generated>)\",\n+ type=click.Choice([\"domain\", \"network\"]),\n+ help=\"The type of node you would like to deploy.\",\n)\n@click.option(\n\"--port\",\n@@ -50,7 +50,7 @@ def cli():\ntype=bool,\nhelp=\"\"\"If restarting a node that already existed, don't/do reset the database (Default: deletes the db)\"\"\",\n)\n-def launch(type, name, port, tag, keep_db, host=\"localhost\"):\n+def launch(name, type, port, tag, keep_db, host=\"localhost\"):\nif name == \"\":\nname = names.get_full_name() + \"'s \" + type.capitalize()\n@@ -110,13 +110,13 @@ def launch(type, name, port, tag, keep_db, host=\"localhost\"):\n@click.command(help=\"Stop a running PyGrid domain/network node.\")\n-@click.argument(\"type\", type=click.Choice([\"domain\", \"network\"]))\n+@click.argument(\"name\", type=str)\n@click.option(\n- \"--name\",\n- default=\"\",\n+ \"--type\",\n+ default=\"domain\",\nrequired=False,\n- type=str,\n- help=\"The name of your new domain/network node. (Default: <randomly generated>)\",\n+ type=click.Choice([\"domain\", \"network\"]),\n+ help=\"The type of node you would like to terminate.\",\n)\n@click.option(\n\"--port\",\n@@ -153,7 +153,7 @@ def land(type, name, port, tag):\nversion = check_docker()\n- motorcycle()\n+ # motorcycle()\nprint(\"Launching a \" + str(type) + \" PyGrid node on port \" + str(port) + \"!\\n\")\nprint(\" - TYPE: \" + str(type))\n",
        "chatgpt_cot": "\"Fix link creation and add package name to item description in MasterViewProxy\""
    },
    {
        "org_diff": "diff --git a/docker-compose-dev.yml b/docker-compose-dev.yml version: '3.2'\nservices:\n# nginx as front end for the operator dashboard\n- nginx:\n- image: hyperledger/cello-nginx\n- hostname: cello-nginx\n- container_name: cello-nginx\n- restart: always\n- deploy:\n- resources:\n- limits:\n- cpus: '0.50'\n- memory: 2048M\n- reservations:\n- cpus: '0.10'\n- memory: 256M\n- volumes:\n- - ./nginx/nginx.conf:/etc/nginx/nginx.default.conf\n- #- /opt/cello/nginx/log/:/var/log/nginx/\n- ports:\n- - \"80:80\"\n- - \"8080:8080\"\n- environment:\n- - BACKEND=cello-operator-dashboard\n- - PORT=8080\n- - USERNAME=admin\n- - PASSWORD=pass\n+# nginx:\n+# image: hyperledger/cello-nginx\n+# hostname: cello-nginx\n+# container_name: cello-nginx\n+# restart: always\n+# deploy:\n+# resources:\n+# limits:\n+# cpus: '0.50'\n+# memory: 2048M\n+# reservations:\n+# cpus: '0.10'\n+# memory: 256M\n+# volumes:\n+# - ./nginx/nginx.conf:/etc/nginx/nginx.default.conf\n+# #- /opt/cello/nginx/log/:/var/log/nginx/\n+# ports:\n+# - \"80:80\"\n+# - \"8080:8080\"\n+# environment:\n+# - BACKEND=cello-operator-dashboard\n+# - PORT=8080\n+# - USERNAME=admin\n+# - PASSWORD=pass\n# cello dashboard service for network operator\noperator-dashboard:\n@@ -54,8 +54,8 @@ services:\n- STATIC_FOLDER=$STATIC_FOLDER\n- TEMPLATE_FOLDER=$TEMPLATE_FOLDER\n- ENABLE_EMAIL_ACTIVE=$ENABLE_EMAIL_ACTIVE\n- expose:\n- - \"8080\"\n+ ports:\n+ - \"8080:8080\"\nvolumes: # This should be removed in product env\n- ./src/agent/docker/_compose_files:/cello\n- ./src:/app\n",
        "org_msg": "Remove nginx from compose in dev mode",
        "sim_msg": "Make DOCKERIMAGE env variable, and specify tag to use (2)",
        "sim_diff": "diff --git a/Jenkinsfile b/Jenkinsfile @@ -4,6 +4,7 @@ pipeline {\ncron('H H 1 1-12 *')\n}\nenvironment {\n+ DOCKERIMAGE = 'justaddcoffee/ubuntu20-python-3-8-5-dev:2'\nBUILDSTARTDATE = sh(script: \"echo `date +%Y%m%d`\", returnStdout: true).trim()\nS3PROJECTDIR = 'kg-covid-19' // no trailing slash\n@@ -29,7 +30,7 @@ pipeline {\nagent {\ndocker {\nreuseNode true\n- image 'justaddcoffee/ubuntu20-python-3-8-5-dev'\n+ image $DOCKERIMAGE\n}\n}\nsteps {\n@@ -51,7 +52,7 @@ pipeline {\nagent {\ndocker {\nreuseNode true\n- image 'justaddcoffee/ubuntu20-python-3-8-5-dev'\n+ image $DOCKERIMAGE\n}\n}\nsteps {\n@@ -69,7 +70,7 @@ pipeline {\nagent {\ndocker {\nreuseNode true\n- image 'justaddcoffee/ubuntu20-python-3-8-5-dev'\n+ image $DOCKERIMAGE\n}\n}\nsteps {\n@@ -102,7 +103,7 @@ pipeline {\nagent {\ndocker {\nreuseNode true\n- image 'justaddcoffee/ubuntu20-python-3-8-5-dev'\n+ image $DOCKERIMAGE\n}\n}\nsteps {\n@@ -117,7 +118,7 @@ pipeline {\nagent {\ndocker {\nreuseNode true\n- image 'justaddcoffee/ubuntu20-python-3-8-5-dev'\n+ image $DOCKERIMAGE\n}\n}\nsteps {\n@@ -133,7 +134,7 @@ pipeline {\nagent {\ndocker {\nreuseNode true\n- image 'justaddcoffee/ubuntu20-python-3-8-5-dev'\n+ image $DOCKERIMAGE\n}\n}\nsteps {\n@@ -155,7 +156,7 @@ pipeline {\nagent {\ndocker {\nreuseNode true\n- image 'justaddcoffee/ubuntu20-python-3-8-5-dev'\n+ image $DOCKERIMAGE\n}\n}\nsteps {\n@@ -250,7 +251,7 @@ pipeline {\nagent {\ndocker {\nreuseNode true\n- image 'justaddcoffee/ubuntu20-python-3-8-5-dev'\n+ image $DOCKERIMAGE\n}\n}\nwhen { anyOf { branch 'master' } }\n",
        "chatgpt_cot": "Remove redundant nginx service configuration and consolidate port mapping for operator dashboard service in docker-compose file."
    },
    {
        "org_diff": "diff --git a/rasa_core_sdk/__init__.py b/rasa_core_sdk/__init__.py @@ -169,7 +169,9 @@ class ActionExecutionRejected(Exception):\ndef __init__(self, action_name, message=None):\nself.action_name = action_name\n- self.message = message\n+ self.message = (message or\n+ \"Custom action '{}' rejected to run\"\n+ \"\".format(action_name))\ndef __str__(self):\nreturn self.message\n",
        "org_msg": "add default message to ActionExecutionRejected RasaHQ/roadmap#280",
        "sim_msg": "core: remove unused SecurityError.",
        "sim_diff": "diff --git a/mitogen/core.py b/mitogen/core.py @@ -83,10 +83,6 @@ class Error(Exception):\nException.__init__(self, fmt)\n-class SecurityError(Error):\n- pass\n-\n-\nclass CallError(Error):\ndef __init__(self, e):\ns = '%s.%s: %s' % (type(e).__module__, type(e).__name__, e)\n",
        "chatgpt_cot": "Add default message for ActionExecutionRejected exception to include action name when no message is provided."
    },
    {
        "org_diff": "diff --git a/fkie_node_manager/src/fkie_node_manager/echo_dialog.py b/fkie_node_manager/src/fkie_node_manager/echo_dialog.py @@ -442,6 +442,8 @@ class EchoDialog(QDialog):\nif self.chars_limit != 0 and len(msg) > self.chars_limit:\nmsg = msg[0:self.chars_limit]\nmsg_cated = True\n+ ver_srollbar = self.display.verticalScrollBar()\n+ scroll_is_at_end = ver_srollbar.maximum() - ver_srollbar.value() <= 10\n# create a notification about scrapped messages\nif self._scrapped_msgs_sl > 0:\ntxt = '<pre style=\"color:red; font-family:Fixedsys,Courier,monospace; padding:10px;\">scrapped %s message because of Hz-settings</pre>' % self._scrapped_msgs_sl\n@@ -454,6 +456,8 @@ class EchoDialog(QDialog):\nif msg_cated:\ntxt = '<pre style=\"color:red; font-family:Fixedsys,Courier,monospace; padding:10px;\">message has been cut off</pre>'\nself.display.append(txt)\n+ if scroll_is_at_end:\n+ ver_srollbar.setValue(ver_srollbar.maximum()) # Scrolls to the bottom\nif store:\nself._print_status()\n",
        "org_msg": "fkie_node_manager: fix scroll in the echo dialog",
        "sim_msg": "minor update to re-naming files",
        "sim_diff": "diff --git a/QualCoder/manage_files.py b/QualCoder/manage_files.py @@ -210,31 +210,33 @@ class DialogManageFiles(QtWidgets.QDialog):\nx = self.ui.tableWidget.currentRow()\ny = self.ui.tableWidget.currentColumn()\nif y == self.NAME_COLUMN:\n- newText = str(self.ui.tableWidget.item(x, y).text()).strip()\n+ new_text = str(self.ui.tableWidget.item(x, y).text()).strip()\n# check that no other source file has this text and this is is not empty\nupdate = True\n- if newText == \"\":\n+ if new_text == \"\":\nupdate = False\nfor c in self.source:\n- if c['name'] == newText:\n+ if c['name'] == new_text:\n+ update = False\n+ # .transcribed suffix is not to be used on a media file\n+ if new_text[-12:] == \".transcribed\" and self.source[x]['mediapath'] is not None:\nupdate = False\n# Need to preserve names of a/v files and their\n# dependent transcribed files: filename.type.transcribed\nif update:\n- print(self.source[x]) # tmp\n- if self.source[x]['mediapath'] is not None:\n+ if self.source[x]['mediapath'] is not None and self.source[x]['mediapath'][:2] in ('/a', '/v'):\nmsg = \"If there is an associated '.transcribed' file please rename \"\nmsg += \"it to match the media file plus '.transcribed'\"\nQtWidgets.QMessageBox.warning(None, \"Media name\", msg)\n- if \".transcribed\" in self.source[x]['name']:\n+ if self.source[x]['name'][-12:] == \".transcribed\":\nmsg = \"If there is an associated media file please rename \"\nmsg += \"it to match the media file before the '.transcribed' suffix\"\nQtWidgets.QMessageBox.warning(None, \"Media name\", msg)\n# update source list and database\n- self.source[x]['name'] = newText\n+ self.source[x]['name'] = new_text\ncur = self.settings['conn'].cursor()\n- cur.execute(\"update source set name=? where id=?\", (newText, self.source[x]['id']))\n+ cur.execute(\"update source set name=? where id=?\", (new_text, self.source[x]['id']))\nself.settings['conn'].commit()\nelse: # put the original text in the cell\nself.ui.tableWidget.item(x, y).setText(self.source[x]['name'])\n",
        "chatgpt_cot": "Fix scrolling issue in EchoDialog by adding functionality to scroll to the bottom when new messages are added to the display."
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/capability_table.py b/node_manager_fkie/src/node_manager_fkie/capability_table.py @@ -417,7 +417,6 @@ class CapabilityTable(QTableWidget):\nrobot_index = self._robotHeader.index(masteruri)\nrobot_name = description.robot_name if description.robot_name else nm.nameres().mastername(masteruri)\n# append a new robot\n- new_robot = False\ndescr_utf8 = utf8(description.robot_descr.replace(\"\\\\n \", \"\\n\"))\nif robot_index == -1:\nrobot_index = self._robotHeader.insertSortedItem(masteruri, robot_name)\n@@ -429,7 +428,6 @@ class CapabilityTable(QTableWidget):\nitem.setSizeHint(QSize(96, 96))\nself.setHorizontalHeaderItem(robot_index, item)\nself.horizontalHeaderItem(robot_index).setText(robot_name)\n- new_robot = True\nelse:\n# update\nself._robotHeader.setDescription(robot_index, cfg_name, masteruri, robot_name, description.robot_type, descr_utf8, description.robot_images)\n@@ -439,7 +437,7 @@ class CapabilityTable(QTableWidget):\ncname = utf8(c.name)\ncdescription = utf8(c.description.replace(\"\\\\n \", \"\\n\"))\ncap_index = self._capabilityHeader.index(cname)\n- if cap_index == -1 or new_robot:\n+ if cap_index == -1 or self.cellWidget(cap_index, robot_index) is None:\nif cap_index == -1:\n# append a new capability\ncap_index = self._capabilityHeader.insertSortedItem(cname, cname)\n",
        "org_msg": "node_manager_fkie: fix capability table for robots with same configuration",
        "sim_msg": "vertical header max size 300px and tooltips",
        "sim_diff": "diff --git a/qualcoder/report_codes.py b/qualcoder/report_codes.py @@ -1913,6 +1913,8 @@ class DialogReportCodes(QtWidgets.QDialog):\nself.ui.tableWidget.setHorizontalHeaderLabels(horizontal_labels)\nself.ui.tableWidget.setRowCount(len(vertical_labels))\nself.ui.tableWidget.setVerticalHeaderLabels(vertical_labels)\n+ for i, vl in enumerate(vertical_labels):\n+ self.ui.tableWidget.verticalHeaderItem(i).setToolTip(vl)\n# Need to create a table of separate textEdits for reference for cursorPositionChanged event.\nself.te = []\nfor vl in vertical_labels:\n@@ -1980,6 +1982,7 @@ class DialogReportCodes(QtWidgets.QDialog):\nself.ui.tableWidget.horizontalHeader().setSectionResizeMode(0, QtWidgets.QHeaderView.ResizeMode.Stretch)\nif self.ui.tableWidget.rowCount() == 1:\nself.ui.tableWidget.verticalHeader().setSectionResizeMode(0, QtWidgets.QHeaderView.ResizeMode.Stretch)\n+ self.ui.tableWidget.verticalHeader().setMaximumWidth(300)\nself.ui.splitter.setSizes([100, 300, 300])\ndef matrix_fill_by_categories(self, results_, ids, type_=\"file\"):\n@@ -2051,6 +2054,8 @@ class DialogReportCodes(QtWidgets.QDialog):\nself.ui.tableWidget.setHorizontalHeaderLabels(horizontal_labels)\nself.ui.tableWidget.setRowCount(len(id_and_name))\nself.ui.tableWidget.setVerticalHeaderLabels(vertical_labels)\n+ for i, vl in enumerate(vertical_labels):\n+ self.ui.tableWidget.verticalHeaderItem(i).setToolTip(vl)\n# Need to create a table of separate textEdits for reference for cursorPositionChanged event.\nself.te = []\nchoice = self.ui.comboBox_memos.currentText()\n@@ -2114,6 +2119,7 @@ class DialogReportCodes(QtWidgets.QDialog):\nself.ui.tableWidget.horizontalHeader().setSectionResizeMode(0, QtWidgets.QHeaderView.ResizeMode.Stretch)\nif self.ui.tableWidget.rowCount() == 1:\nself.ui.tableWidget.verticalHeader().setSectionResizeMode(0, QtWidgets.QHeaderView.ResizeMode.Stretch)\n+ self.ui.tableWidget.verticalHeader().setMaximumWidth(300)\nself.ui.splitter.setSizes([100, 300, 300])\ndef matrix_fill_by_top_categories(self, results_, ids, type_=\"file\"):\n@@ -2186,7 +2192,8 @@ class DialogReportCodes(QtWidgets.QDialog):\ntranspose = self.ui.checkBox_matrix_transpose.isChecked()\nif transpose:\nvertical_labels, horizontal_labels = horizontal_labels, vertical_labels\n-\n+ for i, vl in enumerate(vertical_labels):\n+ self.ui.tableWidget.verticalHeaderItem(i).setToolTip(vl)\n# Clear and fill the tableWidget\ndoc_font = 'font: ' + str(self.app.settings['docfontsize']) + 'pt '\ndoc_font += '\"' + self.app.settings['font'] + '\";'\n@@ -2256,6 +2263,7 @@ class DialogReportCodes(QtWidgets.QDialog):\nself.ui.tableWidget.horizontalHeader().setSectionResizeMode(0, QtWidgets.QHeaderView.ResizeMode.Stretch)\nif self.ui.tableWidget.rowCount() == 1:\nself.ui.tableWidget.verticalHeader().setSectionResizeMode(0, QtWidgets.QHeaderView.ResizeMode.Stretch)\n+ self.ui.tableWidget.verticalHeader().setMaximumWidth(300)\nself.ui.splitter.setSizes([100, 300, 300])\ndef table_text_edit_menu(self, position):\n",
        "chatgpt_cot": "\"Fix issue with adding new robot and capability in CapabilityTable\""
    },
    {
        "org_diff": "diff --git a/sc2/sc2process.py b/sc2/sc2process.py @@ -198,6 +198,8 @@ class SC2Process:\nreturn subprocess.Popen(\nargs,\ncwd=sc2_cwd,\n+ # Suppress Wine error messages\n+ stderr=subprocess.DEVNULL\n# , env=run_config.env\n)\n",
        "org_msg": "Redirect subprocess stderr to subprocess.DEVNULL (suppress error/warning messages)",
        "sim_msg": "hide subprocess log",
        "sim_diff": "diff --git a/slm_lab/lib/util.py b/slm_lab/lib/util.py @@ -577,7 +577,7 @@ def run_cmd(cmd, wait=False):\nstdout = subprocess.PIPE\nstderr = subprocess.STDOUT\nelse:\n- stdout = stderr = None\n+ stdout = stderr = subprocess.DEVNULL\nprint(f'+ {cmd}')\nproc = subprocess.Popen(cmd, cwd=ROOT_DIR, shell=True, stdout=stdout, stderr=stderr, close_fds=True)\nif wait:\n",
        "chatgpt_cot": "\"Suppress Wine error messages in SC2Process subprocess.Popen\""
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/launch_list_model.py b/node_manager_fkie/src/node_manager_fkie/launch_list_model.py @@ -247,6 +247,7 @@ class PathItem(QStandardItem):\nself._isnew = False\nelse:\nnm.nmd().rename(self.path, new_path)\n+ self.reload_current_path(clear_cache=True)\n# check for new file extension\nif new_id != self.id:\nself.id = new_id\n",
        "org_msg": "node_manager_fkie: fixed reload after copy file",
        "sim_msg": "stupid backslashes in file paths",
        "sim_diff": "diff --git a/source1/content_manager.py b/source1/content_manager.py @@ -58,7 +58,8 @@ class ContentManager(metaclass=SingletonMeta):\nreturn False, path\ndef find_file(self, filepath: str, additional_dir=None, extension=None):\n- new_filepath = Path(filepath)\n+\n+ new_filepath = Path(str(filepath).strip('/\\\\').rstrip('/\\\\'))\nif additional_dir:\nnew_filepath = Path(additional_dir, new_filepath)\nif extension:\n",
        "chatgpt_cot": "Add method to reload current path in PathItem class to clear cache and fix file extension issue."
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/node_tree_model.py b/node_manager_fkie/src/node_manager_fkie/node_tree_model.py @@ -1007,11 +1007,11 @@ class HostItem(GroupItem):\ntooltip += '<p>'\ntooltip += '<a href=\"remove-all-launch-server://%s\">kill all launch server</a>' % utf8(self.masteruri).replace('http://', '')\ntooltip += '<p>'\n- sysmon_str = 'Disable' if self.sysmon_state else 'Enable'\n- tooltip += '<a href=\"sysmon-switch://%s\">%s system monitor</a>' % (utf8(self.masteruri).replace('http://', ''), sysmon_str)\n- tooltip += '<p>'\n+ sysmon_setup_str = '<a href=\"nmd-cfg://%s\">setup</a>' % (utf8(self.masteruri).replace('http://', ''))\n+ sysmon_state_str = 'disable' if self.sysmon_state else 'enable'\n+ sysmon_switch_str = '<a href=\"sysmon-switch://%s\">%s</a>' % (utf8(self.masteruri).replace('http://', ''), sysmon_state_str)\n+ tooltip += '<h3>System Monitoring (%s) (%s):</h3>' % (sysmon_switch_str, sysmon_setup_str)\nif self._diagnostics:\n- tooltip += '<h3>System Monitoring (<a href=\"nmd-cfg://%s\">setup</a>):</h3><dl>' % (utf8(self.masteruri).replace('http://', ''))\nfor diag in self._diagnostics:\ntry:\nfree = None\n@@ -1048,7 +1048,6 @@ class HostItem(GroupItem):\nexcept Exception as err:\ntooltip += '\\n<dt><font color=\"red\">%s</font></dt>' % (utf8(err))\ntooltip += '<br>'\n- tooltip += '</dl>'\n# get sensors\ncapabilities = []\n",
        "org_msg": "node_manager_fkie: changed system monitor configuration",
        "sim_msg": "Update docs to include standardization of VM diagnostics\nVM diagnostics has been updated with v2.48 to include a standard formatting.\nThis change will update the admin documentation to mention the new standard\nformatting.\nCloses-bug:",
        "sim_diff": "diff --git a/doc/source/admin/common/nova-show-usage-statistics-for-hosts-instances.rst b/doc/source/admin/common/nova-show-usage-statistics-for-hosts-instances.rst @@ -90,6 +90,57 @@ Show instance usage statistics\n#. Get diagnostic statistics:\n+ .. note::\n+\n+ As of microversion v2.48, diagnostics information for all virt drivers will\n+ have a standard format as below. For more details on diagnostics\n+ response message see `server diagnostics api\n+ <https://developer.openstack.org/api-ref/compute/#servers-diagnostics-servers-diagnostics>`__\n+ documentation.\n+\n+ .. code-block:: console\n+\n+ $ nova diagnostics myCirrosServer\n+ +----------------+------------------------------------------------------------------------+\n+ | Property | Value |\n+ +----------------+------------------------------------------------------------------------+\n+ | config_drive | False |\n+ | cpu_details | [] |\n+ | disk_details | [{\"read_requests\": 887, \"errors_count\": -1, \"read_bytes\": 20273152, |\n+ | | \"write_requests\": 89, \"write_bytes\": 303104}] |\n+ | driver | libvirt |\n+ | hypervisor | qemu |\n+ | hypervisor_os | linux |\n+ | memory_details | {\"used\": 0, \"maximum\": 0} |\n+ | nic_details | [{\"rx_packets\": 9, \"rx_drop\": 0, \"tx_octets\": 1464, \"tx_errors\": 0, |\n+ | | \"mac_address\": \"fa:16:3e:fa:db:d3\", \"rx_octets\": 958, \"rx_rate\": null, |\n+ | | \"rx_errors\": 0, \"tx_drop\": 0, \"tx_packets\": 9, \"tx_rate\": null}] |\n+ | num_cpus | 0 |\n+ | num_disks | 1 |\n+ | num_nics | 1 |\n+ | state | running |\n+ | uptime | 5528 |\n+ +----------------+------------------------------------------------------------------------+\n+\n+ ``config_drive`` indicates if the config drive is supported on the\n+ instance.\n+\n+ ``cpu_details`` contains a list of details per vCPU.\n+\n+ ``disk_details`` contains a list of details per disk.\n+\n+ ``driver`` indicates the current driver on which the VM is running.\n+\n+ ``hypervisor`` indicates the current hypervisor on which the VM is running.\n+\n+ ``nic_details`` containts a list of details per vNIC.\n+\n+ ``uptime`` is the amount of time in seconds that the VM has been runnning.\n+\n+ |\n+\n+ Diagnostics prior to v2.48:\n+\n.. code-block:: console\n$ nova diagnostics myCirrosServer\n",
        "chatgpt_cot": "\"Refactor system monitoring link and tooltip in HostItem class for improved readability and functionality.\""
    },
    {
        "org_diff": "diff --git a/node_manager_daemon_fkie/src/node_manager_daemon_fkie/monitor/mem_usage.py b/node_manager_daemon_fkie/src/node_manager_daemon_fkie/monitor/mem_usage.py @@ -55,12 +55,12 @@ class MemUsage(SensorInterface):\nwarn_level = self._mem_usage_warn\nif diag_level == DiagnosticStatus.WARN:\nwarn_level = warn_level * 0.9\n- if mem.available <= 1024 * 1024 * warn_level:\n+ if mem.total - mem.used <= 1024 * 1024 * warn_level:\ndiag_level = DiagnosticStatus.WARN\n- diag_msg = 'Memory available %s (warn <%s)' % (sizeof_fmt(mem.available), sizeof_fmt(self._mem_usage_warn * 1024 * 1024))\n+ diag_msg = 'Memory available %s (warn <%s)' % (sizeof_fmt(mem.total - mem.used), sizeof_fmt(self._mem_usage_warn * 1024 * 1024))\n# print \"MEM available \", mem.available, diag_level\n- diag_vals.append(KeyValue(key='Free', value=mem.free))\n- diag_vals.append(KeyValue(key='Free [%]', value='%.2f' % (float(mem.free) * 100.0 / float(mem.total))))\n+ diag_vals.append(KeyValue(key='Free', value=mem.total - mem.used))\n+ diag_vals.append(KeyValue(key='Free [%]', value='%.2f' % (float(mem.total - mem.used) * 100.0 / float(mem.total))))\n# Update status\nwith self.mutex:\n",
        "org_msg": "node_manager_daemon_fkie: changed free memory calculation",
        "sim_msg": "remove daemon print",
        "sim_diff": "diff --git a/mppsolar/libs/daemon.py b/mppsolar/libs/daemon.py @@ -32,7 +32,6 @@ class Daemon:\nself.keepalive = daemon_config.get(\"keepalive\", 60)\nlog.info(f\"got daemon type: {self.type}, keepalive: {self.keepalive}\")\n- print(f\"got daemon type: {self.type}, keepalive: {self.keepalive}\")\nif self.type == \"systemd\":\ntry:\n@@ -51,6 +50,7 @@ class Daemon:\nself._notify = self._dummyNotify\nself._journal = self._dummyNotify\nself._Notification = dummyNotification\n+ self._notify(f\"got daemon type: {self.type}, keepalive: {self.keepalive}\")\ndef initialize(self, *args, **kwargs):\n# Send READY=1\n@@ -83,5 +83,6 @@ class Daemon:\ndef _dummyNotify(self, *args, **kwargs):\n# Print log message\n- if args:\n- print(args[0])\n+ # if args:\n+ # print(args[0])\n+ pass\n",
        "chatgpt_cot": "Update memory usage calculation in MemUsage class to correctly calculate available memory and free memory percentage. Fix calculation bug in mem.available and diag_vals values."
    },
    {
        "org_diff": "diff --git a/rasa_core_sdk/forms.py b/rasa_core_sdk/forms.py @@ -72,7 +72,8 @@ class FormAction(Action):\nreturn [FormActivated(self.name())]\ndef run(self, dispatcher, tracker, domain):\n- if tracker.active_form == self.name():\n+\n+ if tracker.active_form == self.name() and tracker.latest_action_name == 'action_listen':\nevents = self.validate(tracker)\nelse:\nevents = []\n",
        "org_msg": "add check if latest action is action listen",
        "sim_msg": "Fix type in action items\nStill used old code",
        "sim_diff": "diff --git a/gaphor/diagram/actions/action.py b/gaphor/diagram/actions/action.py @@ -42,7 +42,7 @@ class SendSignalActionItem(ElementPresentation):\nname = TextBox()\n- watch_name(self, name)\n+ self.watch(\"subject<NamedElement>.name\")\nself.layout = Box(\nname,\n@@ -74,7 +74,7 @@ class AcceptEventActionItem(ElementPresentation):\nname = TextBox(style={})\n- watch_name(self, name),\n+ self.watch(\"subject<NamedElement>.name\")\nself.layout = Box(\nname,\n",
        "chatgpt_cot": "Add condition to check for active form and latest action name in FormAction run method."
    },
    {
        "org_diff": "diff --git a/sc2/unit.py b/sc2/unit.py @@ -100,6 +100,7 @@ class Unit:\nself._bot_object: BotAI = bot_object\n# Used by property_immutable_cache\nself.cache = {}\n+ self.game_loop: int = bot_object.state.game_loop\ndef __repr__(self) -> str:\n\"\"\" Returns string of this form: Unit(name='SCV', tag=4396941328). \"\"\"\n@@ -365,6 +366,21 @@ class Unit:\nreturn 0\nreturn self._proto.energy / self._proto.energy_max\n+ @property\n+ def age_in_frames(self) -> int:\n+ \"\"\" Returns how old the unit object data is (in game frames). This age does not reflect the unit was created / trained / morphed! \"\"\"\n+ return self._bot_object.state.game_loop - self.game_loop\n+\n+ @property\n+ def age(self) -> float:\n+ \"\"\" Returns how old the unit object data is (in game seconds). This age does not reflect when the unit was created / trained / morphed! \"\"\"\n+ return (self._bot_object.state.game_loop - self.game_loop) / 22.4\n+\n+ @property\n+ def is_memory(self) -> bool:\n+ \"\"\" Returns True if this Unit object is referenced from the future and is outdated. \"\"\"\n+ return self.game_loop != self._bot_object.state.game_loop\n+\n@property_immutable_cache\ndef is_snapshot(self) -> bool:\n\"\"\" Checks if the unit is only available as a snapshot for the bot.\n",
        "org_msg": "Add unit.game_loop and unit.is_memory properties as suggested by DrInfy",
        "sim_msg": "Adds the ability to save to input data to file\nThis saves real same input as the skeleton tf model to a file.",
        "sim_diff": "diff --git a/bot_manager.py b/bot_manager.py @@ -90,6 +90,10 @@ class BotManager:\nplayer_input.bBoost = controller_input[6]\nplayer_input.bHandbrake = controller_input[7]\n+ if self.save_data and game_tick_packet.gameInfo.bRoundActive and old_time is not 0 and not old_time == current_time:\n+ self.game_file.writelines(str(self.create_input_array(game_tick_packet)) + '\\n')\n+ self.game_file.writelines(str(controller_input) + '\\n')\n+\n# Ratelimit here\nafter = datetime.now()\n# print('Latency of ' + self.name + ': ' + str(after - before))\n@@ -99,5 +103,16 @@ class BotManager:\n# If terminated, send callback\nself.callbackEvent.set()\n-\n-\n+ def create_input_array(self, gameTickPacket):\n+ return [\n+ gameTickPacket.gameball.Location.X,\n+ gameTickPacket.gameball.Location.Y,\n+ gameTickPacket.gamecars[self.index].Location.X,\n+ gameTickPacket.gamecars[self.index].Location.Y,\n+ float(gameTickPacket.gamecars[self.index].Rotation.Pitch),\n+ float(gameTickPacket.gamecars[self.index].Rotation.Yaw),\n+ gameTickPacket.gamecars[enemy_index].Location.X,\n+ gameTickPacket.gamecars[enemy_index].Location.Y,\n+ float(gameTickPacket.gamecars[enemy_index].Rotation.Pitch),\n+ float(gameTickPacket.gamecars[enemy_index].Rotation.Yaw),\n+ ]\n",
        "chatgpt_cot": "\"Add game loop and age properties to Unit class\""
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/ssh_handler.py b/node_manager_fkie/src/node_manager_fkie/ssh_handler.py import os\nimport paramiko\nimport shlex\n-import sys\nimport threading\nimport rospy\n@@ -41,6 +40,16 @@ import rospy\nfrom supervised_popen import SupervisedPopen\nimport node_manager_fkie as nm\n+import Crypto.Cipher.AES\n+orig_new = Crypto.Cipher.AES.new\n+\n+\n+# workaround for https://github.com/paramiko/paramiko/pull/714\n+def fixed_AES_new(key, mode, IV='', counter=None, segment_size=0):\n+ if Crypto.Cipher.AES.MODE_CTR == mode:\n+ IV = ''\n+ return orig_new(key, mode, IV, counter, segment_size)\n+\nclass AuthenticationRequest(Exception):\n''' '''\n@@ -63,6 +72,8 @@ class SSHhandler(object):\nSSH_AUTH = {} # host : user\ndef __init__(self):\n+ # workaround for https://github.com/paramiko/paramiko/pull/714\n+ Crypto.Cipher.AES.new = fixed_AES_new\nself.mutex = threading.RLock()\ndef remove(self, host):\n",
        "org_msg": "node_manager_fkie: added a workaround for \"CTR mode needs counter parameter, not IV\"",
        "sim_msg": "Moved again crypto imports within the method",
        "sim_diff": "diff --git a/resources/lib/common/credentials.py b/resources/lib/common/credentials.py @@ -23,15 +23,6 @@ from .fileops import load_file\nfrom .kodi_ops import get_local_string\nfrom .uuid_device import get_crypt_key\n-try: # The crypto package depends on the library installed (see Wiki)\n- from Crypto import Random\n- from Crypto.Cipher import AES\n- from Crypto.Util import Padding\n-except ImportError:\n- from Cryptodome import Random\n- from Cryptodome.Cipher import AES\n- from Cryptodome.Util import Padding\n-\n__BLOCK_SIZE__ = 32\n@@ -42,6 +33,16 @@ def encrypt_credential(raw):\n:type raw: str\n:returns: string -- Encoded data\n\"\"\"\n+ # Keep these imports within the method otherwise if the packages are not installed,\n+ # the addon crashes and the user does not read the warning message\n+ try: # The crypto package depends on the library installed (see Wiki)\n+ from Crypto import Random\n+ from Crypto.Cipher import AES\n+ from Crypto.Util import Padding\n+ except ImportError:\n+ from Cryptodome import Random\n+ from Cryptodome.Cipher import AES\n+ from Cryptodome.Util import Padding\nraw = bytes(Padding.pad(data_to_pad=raw.encode('utf-8'), block_size=__BLOCK_SIZE__))\niv = Random.new().read(AES.block_size)\ncipher = AES.new(get_crypt_key(), AES.MODE_CBC, iv)\n@@ -55,6 +56,14 @@ def decrypt_credential(enc):\n:type enc: str\n:returns: string -- Decoded data\n\"\"\"\n+ # Keep these imports within the method otherwise if the packages are not installed,\n+ # the addon crashes and the user does not read the warning message\n+ try: # The crypto package depends on the library installed (see Wiki)\n+ from Crypto.Cipher import AES\n+ from Crypto.Util import Padding\n+ except ImportError:\n+ from Cryptodome.Cipher import AES\n+ from Cryptodome.Util import Padding\nenc = base64.b64decode(enc)\niv = enc[:AES.block_size]\ncipher = AES.new(get_crypt_key(), AES.MODE_CBC, iv)\n@@ -139,6 +148,14 @@ def run_nf_authentication_key():\ndef _get_authentication_key_data(file_path, pin):\n\"\"\"Open the auth key file\"\"\"\nfrom resources.lib.kodi import ui\n+ # Keep these imports within the method otherwise if the packages are not installed,\n+ # the addon crashes and the user does not read the warning message\n+ try: # The crypto package depends on the library installed (see Wiki)\n+ from Crypto.Cipher import AES\n+ from Crypto.Util import Padding\n+ except ImportError:\n+ from Cryptodome.Cipher import AES\n+ from Cryptodome.Util import Padding\ntry:\nfile_content = load_file(file_path)\niv = '\\x00' * 16\n",
        "chatgpt_cot": "\"Workaround for paramiko issue, fixing AES initialization in SSH handler\""
    },
    {
        "org_diff": "diff --git a/src/api-engine/api/routes/node/views.py b/src/api-engine/api/routes/node/views.py @@ -140,6 +140,7 @@ class NodeViewSet(viewsets.ViewSet):\n#\"channel\": str(node.organization.channel.id) if node.organization.channel else None,\n\"ports\": node.port,\n\"created_at\": node.created_at,\n+ \"status\": node.status\n}\nfor node in nodes\n]\n",
        "org_msg": "Add node status field to the response Node.",
        "sim_msg": "Make airport IATA code case insensitive in Rest API",
        "sim_diff": "diff --git a/api/views.py b/api/views.py @@ -688,5 +688,6 @@ class AirportViewSet(viewsets.ReadOnlyModelViewSet):\npermission_classes = (IsAuthenticated, IsAdmin)\nqueryset = Airport.objects.all()\nserializer_class = AirportSerializer\n- lookup_field = 'iata'\n+ lookup_field = 'iata__iexact'\n+ lookup_url_kwarg = 'iata'\npagination_class = StandardResultsSetPagination\n",
        "chatgpt_cot": "Add 'status' field to NodeViewSet response in views.py."
    },
    {
        "org_diff": "diff --git a/docs/setup_master.md b/docs/setup_master.md @@ -12,8 +12,8 @@ The [Master Node](terminology.md) includes several services:\n* Hardware: 8c16g100g\n* Linux Kernel >= 3.0.0\n-* Docker engine: 1.10.0~1.13.0 (Docker 17.0+ support is experimental)\n-* docker-compose: 1.8.0~1.12.0\n+* Docker engine: 1.10.0+ (Docker 17.0+ support is experimental)\n+* docker-compose: 1.10.0+\nThe [Master Node](terminology.md) can be deployed by in 2 steps:\n",
        "org_msg": "Fix docker version range\nFix docker version range to 1.10+.",
        "sim_msg": "Remove oef dependency from echo skill",
        "sim_diff": "diff --git a/docs/quickstart.md b/docs/quickstart.md ## Preliminaries\n+Make sure you are running desktop <a href=\"https://docs.docker.com/install/\" target=_blank>Docker</a> and <a href=\"https://docs.docker.com/compose/install/\" target=_blank>Docker Compose</a>.\n+\nCreate and cd into a new working directory.\n``` bash\n@@ -18,7 +20,7 @@ If you don't have it, install it. Instructions are <a href=\"https://pypi.org/pro\nOnce installed, create a new environment and open it.\n``` bash\n-pipenv --python 3.7 && pipenv shell\n+touch Pipfile && pipenv --python 3.7 && pipenv shell\n```\n@@ -26,7 +28,7 @@ pipenv --python 3.7 && pipenv shell\nInstall the Autonomous Economic Agent framework.\n-The following installs the basic application.\n+The following installs the basic application without the cli. If in doubt, install `aea[all]`.\n``` bash\npip install aea\n```\n@@ -37,17 +39,22 @@ pip install aea[all]\n```\n-The following installs just the cli.\n+The following only installs the cli.\n``` bash\npip install aea[cli]\n```\n-## Echo Agent demo\n-### Download the examples and scripts directories.\n+## Echo skill demo\n+\n+The echo skill is a simple demo that prints logs from the agent's main loop as it calls registered `Task` and `Behaviour` code.\n+\n+\n+\n+### Download the examples, scripts, and packages directories.\n``` bash\n-svn export https://github.com/fetchai/agents-aea.git/trunk/examples\nsvn export https://github.com/fetchai/agents-aea.git/trunk/scripts\n+svn export https://github.com/fetchai/agents-aea.git/trunk/packages\n```\n### Create a new agent\n@@ -62,21 +69,18 @@ cd my_first_agent\naea add skill echo\n```\n-### Launch the OEF\n-\n-\n-Open a new terminal and launch the OEF.\n+### Add a local connection\n``` bash\n-python scripts/oef/launch.py -c ./scripts/oef/launch_config.json\n+aea add connection local\n```\n### Run the agent locally\n-Go back to the other terminal and run the agent.\n+Run the agent with the connection.\n``` bash\n-aea run\n+aea run --connection local\n```\nYou will see the echo task running in the terminal window.\n",
        "chatgpt_cot": "Update Docker engine and docker-compose versions in setup_master.md to meet the minimum requirements and improve compatibility with Docker 17.0+."
    },
    {
        "org_diff": "diff --git a/fkie_node_manager/src/fkie_node_manager/main_window.py b/fkie_node_manager/src/fkie_node_manager/main_window.py @@ -134,6 +134,8 @@ class MainWindow(QMainWindow):\nself._last_window_state = False\nself._description_history = []\nself._description_accept = ''\n+ self._nmd_last_errors = {} # msg: timestamp\n+ self._ts_nmd_error_last_check = 0\n# self.setAttribute(Qt.WA_AlwaysShowToolTips, True)\n# setup main window frame\nself.setObjectName('MainWindow')\n@@ -2326,6 +2328,24 @@ class MainWindow(QMainWindow):\n'Error while parse parameter',\n'%s' % utf8(err))\n+ def _throttle_nmd_errrors(self, reason, url, error, delay=60):\n+ now = time.time()\n+ doprint = False\n+ key = (reason, url, error.details())\n+ if key not in self._nmd_last_errors.keys():\n+ doprint = True\n+ elif now - self._nmd_last_errors[key] > delay:\n+ doprint = True\n+ if doprint:\n+ rospy.logwarn(\"Error while %s from %s: %s\" % (reason, url, utf8(error)))\n+ self._nmd_last_errors[key] = now\n+ if now - self._ts_nmd_error_last_check > 120:\n+ # clean old messages\n+ self._ts_nmd_error_last_check = now\n+ for key, ts in self._nmd_last_errors.items():\n+ if now - ts > 240:\n+ del self._nmd_last_errors[key]\n+\ndef on_nmd_err(self, method, url, path, error):\n'''\nHandles the error messages from node_manager_daemon.\n@@ -2342,7 +2362,7 @@ class MainWindow(QMainWindow):\nreason = method\nif method == '_get_nodes':\nreason = 'get launch configuration'\n- rospy.logwarn(\"Error while %s from %s: %s\" % (reason, url, utf8(error)))\n+ self._throttle_nmd_errrors(reason, url, error, 60)\nif hasattr(error, 'code'):\nif error.code() == grpc.StatusCode.UNIMPLEMENTED:\nmuri = nmdurl.masteruri(url)\n",
        "org_msg": "fkie_node_manager: added throttle daemon error output",
        "sim_msg": "rqda menu import option",
        "sim_diff": "diff --git a/qualcoder/GUI/ui_main.py b/qualcoder/GUI/ui_main.py @@ -111,6 +111,8 @@ class Ui_MainWindow(object):\nself.actionREFI_QDA_Project_import.setObjectName(\"actionREFI_QDA_Project_import\")\nself.actionView_Graph_2 = QtWidgets.QAction(MainWindow)\nself.actionView_Graph_2.setObjectName(\"actionView_Graph_2\")\n+ self.actionRQDA_Project_import = QtWidgets.QAction(MainWindow)\n+ self.actionRQDA_Project_import.setObjectName(\"actionRQDA_Project_import\")\nself.menuProject.addAction(self.actionCreate_New_Project)\nself.menuProject.addAction(self.actionOpen_Project)\nself.menuProject.addAction(self.actionClose_Project)\n@@ -121,6 +123,7 @@ class Ui_MainWindow(object):\nself.menuProject.addAction(self.actionProject_Exchange_Export)\nself.menuProject.addAction(self.actionREFI_Codebook_import)\nself.menuProject.addAction(self.actionREFI_QDA_Project_import)\n+ self.menuProject.addAction(self.actionRQDA_Project_import)\nself.menuProject.addSeparator()\nself.menuProject.addAction(self.actionExit)\nself.menuFiles_and_Cases.addAction(self.actionManage_files)\n@@ -196,6 +199,7 @@ class Ui_MainWindow(object):\nself.actionREFI_Codebook_import.setText(_translate(\"MainWindow\", \"REFI-QDA Codebook import\"))\nself.actionREFI_QDA_Project_import.setText(_translate(\"MainWindow\", \"REFI-QDA Project import\"))\nself.actionView_Graph_2.setText(_translate(\"MainWindow\", \"View Graph 2\"))\n+ self.actionRQDA_Project_import.setText(_translate(\"MainWindow\", \"RQDA Project import\"))\nif __name__ == \"__main__\":\n",
        "chatgpt_cot": "Add method to throttle error messages in MainWindow. The method throttles and logs errors from node_manager_daemon to avoid flooding the logs."
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/message_frame.py b/node_manager_fkie/src/node_manager_fkie/message_frame.py @@ -165,8 +165,12 @@ class MessageFrame(QFrame):\npass\nif self.questionid != questionid or self.text != text or data != self.data:\nself._queue.add(questionid, text, data)\n- elif data.data_list: # update the list of files or nodes which causes this question\n- self._update_list_label(data.data_list)\n+ elif data.data_list: # same question again\n+ # update the list of files or nodes which causes this question in current question\n+ for dt in data.data_list:\n+ if dt not in self.data.data_list:\n+ self.data.data_list.append(dt)\n+ self._update_list_label(self.data.data_list)\n# if no question is active pop first element from the queue\nif self.questionid == self.TYPE_INVALID:\nself._new_request = self._read_next_item()\n@@ -201,6 +205,7 @@ class MessageFrame(QFrame):\nPut list elements into the list label in the question frame\n'''\nif items:\n+ self.frameui.listLabel.setText('')\nfor item in items:\nltext = self.frameui.listLabel.text()\nif ltext:\n",
        "org_msg": "node_manager_fkie: fixed visualization of same changed files in question",
        "sim_msg": "Added Check on Chat Message to add a user who may have gotten dumped from the streamSIDList",
        "sim_diff": "diff --git a/app.py b/app.py @@ -3850,8 +3850,14 @@ def text(message):\nchannelQuery = Channel.Channel.query.filter_by(channelLoc=room).first()\n+ global streamSIDList\n+\nif channelQuery != None:\n+ userSID = request.sid\n+ if userSID not in streamSIDList[channelQuery.channelLoc]:\n+ streamSIDList[channelQuery.channelLoc].append(userSID)\n+\npictureLocation = current_user.pictureLocation\nif current_user.pictureLocation == None:\npictureLocation = '/static/img/user2.png'\n",
        "chatgpt_cot": "\"Fix queue and list label update issue in MessageFrame.\""
    },
    {
        "org_diff": "diff --git a/fkie_master_discovery/src/fkie_master_discovery/master_monitor.py b/fkie_master_discovery/src/fkie_master_discovery/master_monitor.py @@ -47,6 +47,7 @@ import roslib.message\nimport rospy\nimport socket\nimport subprocess\n+import sys\nimport threading\nimport time\nimport traceback\n@@ -350,7 +351,8 @@ class MasterMonitor(object):\nheader = {'probe': '1', 'md5sum': '*',\n'callerid': self.ros_node_name, 'service': service}\nroslib.network.write_ros_handshake_header(s, header)\n- stype = roslib.network.read_ros_handshake_header(s, io.StringIO(), 2048)\n+ buf = io.StringIO() if sys.version_info < (3, 0) else io.BytesIO()\n+ stype = roslib.network.read_ros_handshake_header(s, buf, 2048)\nwith self._lock:\nself.__new_master_state.getService(service).type = stype['type']\nself.__cached_services[service] = (uri, stype['type'], time.time())\n",
        "org_msg": "fkie_master_discovery: python 3 compatibility while get service definition",
        "sim_msg": "Update latest changes\nChange Response type from mother peer\nChange dispatcher param type. It needs dumped string, not a dict\nitself.",
        "sim_diff": "diff --git a/loopchain/baseservice/node_subscriber.py b/loopchain/baseservice/node_subscriber.py @@ -22,7 +22,8 @@ from urllib import parse\nimport websockets\nfrom earlgrey import MessageQueueService\nfrom jsonrpcclient.requests import Request\n-from jsonrpcserver.aio import AsyncMethods\n+from jsonrpcserver import async_dispatch\n+from jsonrpcserver.methods import Methods\nfrom websockets import WebSocketClientProtocol\nfrom loopchain import configure as conf\n@@ -34,7 +35,7 @@ from loopchain.blockchain.votes import Votes\nfrom loopchain.channel.channel_property import ChannelProperty\nfrom loopchain.protos import message_code\n-ws_methods = AsyncMethods()\n+ws_methods = Methods()\nCONNECTION_FAIL_CONDITIONS = {\nmessage_code.Response.fail_subscribe_limit,\nmessage_code.Response.fail_connection_closed,\n@@ -50,11 +51,12 @@ class UnregisteredException(Exception):\npass\n-def convert_response_to_dict(response: bytes) -> dict:\n- response_dict: dict = json.loads(response)\n- response_dict = _check_error_in_response(response_dict)\n+def validate_response(response: str) -> str:\n+ res: dict = json.loads(response)\n+ res = _check_error_in_response(res)\n+ res: str = json.dumps(res)\n- return response_dict\n+ return res\ndef _check_error_in_response(response_dict: dict) -> dict:\n@@ -132,13 +134,13 @@ class NodeSubscriber:\nawait self._websocket.send(json.dumps(request))\nasync def _recv_until_timeout(self):\n- response: bytes = await asyncio.wait_for(\n+ response: str = await asyncio.wait_for(\nfut=self._websocket.recv(),\ntimeout=2 * conf.TIMEOUT_FOR_WS_HEARTBEAT\n)\n- response_dict = convert_response_to_dict(response)\n+ response = validate_response(response)\n- await ws_methods.dispatch(response_dict)\n+ await async_dispatch(response, ws_methods)\nasync def _run(self):\ntry:\n",
        "chatgpt_cot": "Add import for sys module to fix compilation issue in master_monitor.py file."
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/main_window.py b/node_manager_fkie/src/node_manager_fkie/main_window.py @@ -1058,7 +1058,7 @@ class MainWindow(QMainWindow):\n'''\nOpen a dialog to run a ROS node without a configuration\n'''\n- from run_dialog import RunDialog\n+ from .run_dialog import RunDialog\nif self.currentMaster is not None:\ndia = RunDialog(get_hostname(self.currentMaster.masteruri), self.currentMaster.masteruri)\nif dia.exec_():\n",
        "org_msg": "node_manager_fkie: fixed import for run_dialog",
        "sim_msg": "core: ensure early debug messages are logged correctly.\nThe magical _v and _vv were being set too late. Drag _setup_logging()\nout of the Router constructor and call it at the right moment during\nbootstrap.",
        "sim_diff": "diff --git a/mitogen/core.py b/mitogen/core.py @@ -2414,11 +2414,7 @@ class Router(object):\ndef __init__(self, broker):\nself.broker = broker\nlisten(broker, 'exit', self._on_broker_exit)\n-\n- # Here seems as good a place as any.\n- global _v, _vv\n- _v = logging.getLogger().level <= logging.DEBUG\n- _vv = IOLOG.level <= logging.DEBUG\n+ self._setup_logging()\n#: context ID -> Stream\nself._stream_by_id = {}\n@@ -2434,6 +2430,18 @@ class Router(object):\ndef __repr__(self):\nreturn 'Router(%r)' % (self.broker,)\n+ def _setup_logging(self):\n+ \"\"\"\n+ This is done in the :class:`Router` constructor for historical reasons.\n+ It must be called before ExternalContext logs its first messages, but\n+ after logging has been setup. It must also be called when any router is\n+ constructed for a consumer app.\n+ \"\"\"\n+ # Here seems as good a place as any.\n+ global _v, _vv\n+ _v = logging.getLogger().level <= logging.DEBUG\n+ _vv = IOLOG.level <= logging.DEBUG\n+\ndef _on_del_route(self, msg):\n\"\"\"\nStub :data:`DEL_ROUTE` handler; fires 'disconnect' events on the\n@@ -3240,11 +3248,16 @@ class ExternalContext(object):\nself.dispatcher = Dispatcher(self)\nself.router.register(self.parent, self.stream)\n+ self.router._setup_logging()\nself.log_handler.uncork()\nsys.executable = os.environ.pop('ARGV0', sys.executable)\n- _v and LOG.debug('Connected to %s; my ID is %r, PID is %r',\n- self.parent, mitogen.context_id, os.getpid())\n+ _v and LOG.debug('Connected to context %s; my ID is %r',\n+ self.parent, mitogen.context_id)\n+ _v and LOG.debug('pid:%r ppid:%r uid:%r/%r, gid:%r/%r host:%r',\n+ os.getpid(), os.getppid(), os.geteuid(),\n+ os.getuid(), os.getegid(), os.getgid(),\n+ socket.gethostname())\n_v and LOG.debug('Recovered sys.executable: %r', sys.executable)\nself.dispatcher.run()\n",
        "chatgpt_cot": "Fix import path for RunDialog in MainWindow to resolve relative import issue."
    },
    {
        "org_diff": "diff --git a/sc2/position.py b/sc2/position.py @@ -44,11 +44,17 @@ class Pointlike(tuple):\nreturn (self[0] - p2[0]) ** 2 + (self[1] - p2[1]) ** 2\ndef is_closer_than(self, d: Union[int, float], p: Union[\"Unit\", \"Point2\"]) -> bool:\n- \"\"\" Check if another point (or unit) is closer than the given distance. More efficient than\n- distance_to(p) < d.\"\"\"\n+ \"\"\" Check if another point (or unit) is closer than the given distance.\n+ More efficient than distance_to(p) < d.\"\"\"\np = p.position\nreturn self._distance_squared(p) < d ** 2\n+ def is_further_than(self, d: Union[int, float], p: Union[\"Unit\", \"Point2\"]) -> bool:\n+ \"\"\" Check if another point (or unit) is further than the given distance.\n+ More efficient than distance_to(p) > d.\"\"\"\n+ p = p.position\n+ return self._distance_squared(p) > d ** 2\n+\ndef sort_by_distance(self, ps: Union[\"Units\", List[\"Point2\"]]) -> List[\"Point2\"]:\n\"\"\" This returns the target points sorted as list. You should not pass a set or dict since those are not sortable.\nIf you want to sort your units towards a point, use 'units.sorted_by_distance_to(point)' instead. \"\"\"\n",
        "org_msg": "Add is_further_than",
        "sim_msg": "Added distances and distances_indices_sorted functions.",
        "sim_diff": "diff --git a/pymatgen/analysis/chemenv/utils/coordination_geometry_utils.py b/pymatgen/analysis/chemenv/utils/coordination_geometry_utils.py @@ -682,11 +682,32 @@ class Plane(object):\ndef distance_to_point(self, point):\n\"\"\"\nComputes the absolute distance from the plane to the point\n- :param point:\n- :return:\n+ :param point: Point for which distance is computed\n+ :return: Distance between the plane and the point\n\"\"\"\nreturn np.abs(np.dot(self.normal_vector, point) + self.d)\n+ def distances(self, points):\n+ \"\"\"\n+ Computes the distances from the plane to each of the points. Positive distances are on the side of the\n+ normal of the plane while negative distances are on the other side\n+ :param points: Points for which distances are computed\n+ :return: Distances from the plane to the points (positive values on the side of the normal to the plane,\n+ negative values on the other side)\n+ \"\"\"\n+ return [np.dot(self.normal_vector, pp) + self.d for pp in points]\n+\n+ def distances_indices_sorted(self, points):\n+ \"\"\"\n+ Computes the distances from the plane to each of the points. Positive distances are on the side of the\n+ normal of the plane while negative distances are on the other side\n+ :param points: Points for which distances are computed\n+ :return: Distances from the plane to the points (positive values on the side of the normal to the plane,\n+ negative values on the other side), as well as indices of the points from closest to furthest.\n+ \"\"\"\n+ distances = [np.dot(self.normal_vector, pp) + self.d for pp in points]\n+ return distances, sorted(range(len(distances)), key=lambda k: np.abs(distances[k]))\n+\ndef projectionpoints(self, pps):\n\"\"\"\nProjects each points in the point list pps on plane and returns the list of projected points\n",
        "chatgpt_cot": "Add method is_further_than to Pointlike class for checking distance efficiency. Enhances functionality for distance comparison in position.py."
    },
    {
        "org_diff": "diff --git a/build_image/docker/api-engine/Dockerfile.in b/build_image/docker/api-engine/Dockerfile.in FROM python:3.6\n-RUN apt-get update && apt-get install -y gettext-base graphviz && \\\n+RUN apt-get update && apt-get install -y gettext-base graphviz libgraphviz-dev && \\\napt-get autoclean && apt-get clean && apt-get autoremove && rm -rf /var/cache/apt/\nCOPY src/api-engine/requirements.txt /\nRUN cd / && \\\n",
        "org_msg": "Fix api engine image build failed\nFix graphviz/cgraph.h not found for api engine image.",
        "sim_msg": "Add redis-server to Docker image to reactivate celery tests.",
        "sim_diff": "diff --git a/docker/Dockerfile b/docker/Dockerfile @@ -19,6 +19,7 @@ RUN apt-get update -y \\\npython3-dev python3-distutils python3-pip \\\nbuild-essential \\\npostgresql \\\n+ redis-server \\\npostgresql-client-${V_PG} \\\npostgresql-${V_PG} \\\nsudo make graphviz \\\n",
        "chatgpt_cot": "\"Add libgraphviz-dev to Dockerfile to resolve dependency issue in api-engine\""
    },
    {
        "org_diff": "diff --git a/fkie_node_manager/src/fkie_node_manager/name_resolution.py b/fkie_node_manager/src/fkie_node_manager/name_resolution.py @@ -70,7 +70,6 @@ class MasterEntry(object):\nreturn mastername in self._masternames\ndef has_address(self, address):\n- with self.mutex:\nreturn address in self._addresses\ndef add_mastername(self, mastername):\n@@ -78,10 +77,10 @@ class MasterEntry(object):\nself._masternames.insert(0, mastername)\ndef add_address(self, address):\n+ with self.mutex:\nif address and not self.has_address(address):\nif self.is_legal_ip(address):\n# it is an IP, try to get the hostname\n- with self.mutex:\nself._addresses.append(address)\n# resolve the name in a thread\nthread = Thread(target=self._get_hostname, args=((address,)))\n@@ -89,7 +88,6 @@ class MasterEntry(object):\nthread.start()\nelse:\n# it is a hostname: add at the fist place and try to get an IP for this host\n- with self.mutex:\nself._addresses.insert(0, address)\n# resolve the name in a thread\nthread = Thread(target=self._get_address, args=((address,)))\n",
        "org_msg": "fkie_node_manager: requests for name resolution",
        "sim_msg": "give names to vlan nodes, makes it a little each to see which one is getting an indication",
        "sim_diff": "diff --git a/py27/bacpypes/vlan.py b/py27/bacpypes/vlan.py @@ -25,9 +25,10 @@ _log = ModuleLogger(globals())\n@bacpypes_debugging\nclass Network:\n- def __init__(self, dropPercent=0.0):\n- if _debug: Network._debug(\"__init__ dropPercent=%r\", dropPercent)\n+ def __init__(self, name='', dropPercent=0.0):\n+ if _debug: Network._debug(\"__init__ name=%r dropPercent=%r\", name, dropPercent)\n+ self.name = name\nself.nodes = []\nself.dropPercent = dropPercent\n@@ -38,6 +39,10 @@ class Network:\nself.nodes.append(node)\nnode.lan = self\n+ # update the node name\n+ if not node.name:\n+ node.name = '[%s:%s]' % (self.name, node.address)\n+\ndef remove_node(self, node):\n\"\"\" Remove a node from this network. \"\"\"\nif _debug: Network._debug(\"remove_node %r\", node)\n@@ -60,14 +65,14 @@ class Network:\nraise RuntimeError(\"invalid destination address: %r\" % (pdu.pduDestination,))\nelif pdu.pduDestination.addrType == Address.localBroadcastAddr:\n- for n in self.nodes:\n- if (pdu.pduSource != n.address):\n- n.response(deepcopy(pdu))\n+ for node in self.nodes:\n+ if (pdu.pduSource != node.address):\n+ node.response(deepcopy(pdu))\nelif pdu.pduDestination.addrType == Address.localStationAddr:\n- for n in self.nodes:\n- if n.promiscuous or (pdu.pduDestination == n.address):\n- n.response(deepcopy(pdu))\n+ for node in self.nodes:\n+ if node.promiscuous or (pdu.pduDestination == node.address):\n+ node.response(deepcopy(pdu))\nelse:\nraise RuntimeError(\"invalid destination address type: %r\" % (pdu.pduDestination,))\n@@ -94,6 +99,10 @@ class Node(Server):\nif not isinstance(addr, Address):\nraise TypeError(\"addr must be an address\")\n+ # start out with no name\n+ self.name = ''\n+\n+ # unbound\nself.lan = None\nself.address = addr\n@@ -113,7 +122,7 @@ class Node(Server):\ndef indication(self, pdu):\n\"\"\"Send a message.\"\"\"\n- if _debug: Node._debug(\"indication %r\", pdu)\n+ if _debug: Node._debug(\"%sindication %r\", self.name, pdu)\n# make sure we're connected\nif not self.lan:\n",
        "chatgpt_cot": "Fix mutex usage in name_resolution.py to resolve the compilation issue and improve the performance of the MasterEntry class."
    },
    {
        "org_diff": "diff --git a/README.md b/README.md @@ -12,7 +12,7 @@ where active development is ongoing. Issue tracking is handled in [Jira](https:/\nThis project is a Hyperledger project in _Incubation_. It was proposed to the community and documented [here](https://docs.google.com/document/d/1E2i5GRqWsIag7KTxjQ_jQdDiWcuikv3KqXeuw7NaceM/edit), and was approved by [Hyperledger TSC at 2017-01-07](https://lists.hyperledger.org/pipermail/hyperledger-tsc/2017-January/000535.html). Information on what _Incubation_ entails can be found in the [Hyperledger Project Lifecycle document](https://goo.gl/4edNRc).\n-Using Cello, we can\n+Using Cello, we can:\n* Provision customizable Blockchains instantly, e.g., a 6-node fabric chain using PBFT consensus.\n* Maintain a pool of running blockchains healthy with no manual operations.\n@@ -51,7 +51,7 @@ You can also find more [scenarios](docs/scenario.md).\n* [Develop react js](docs/reactjs.md)\n## Why named Cello?\n-Can u find anyone better at playing chains? :)\n+Can you find anyone better at playing chains? :)\n## License <a name=\"license\"></a>\nThe Hyperledger Cello project uses the [Apache License Version 2.0](LICENSE) software license.\n",
        "org_msg": "Few typographical errors `fixed in README.md",
        "sim_msg": "Nice README.",
        "sim_diff": "diff --git a/README.md b/README.md @@ -362,7 +362,7 @@ Currently alive channels\n| [/r/trippinthroughtime](https://www.reddit.com/r/trippinthroughtime/) | [@medieval_memes](https://t.me/medieval_memes) | 1 hour |\n| [/r/onepunchman](https://www.reddit.com/r/onepunchman/) | [@r_opm](https://t.me/r_opm) | 1 hour |\n| [/r/preppers](https://www.reddit.com/r/preppers/) | [@r_preppers](https://t.me/r_preppers) | 1 hour |\n-| [/r/Chainlink+Vechain+FetchAI_Community+perlin+Qtum+NEO+hashgraph+IoTeX+elrondnetwork+Aeternity+loopringorg+waltonchain+nebulas+IOStoken+NavCoin+viacoin+skycoin+MoedaBanking+WabiToken+EnjinCoin+OntologyNetwork+PolymathNetwork+insolar+nexusearth+zcoin+zilliqa+quarkchainio+tezos+Neblio+helloicon+ArkEcosystem+kybernetwork+0xProject+BATProject+SysCoin+omise_go+pivx+civicplatform+factom+nem+Stellar+Ripple+Wavesplatform+statusim+Ardor+stratisplatform+GolemProject+komodoplatform+storj+vergecurrency+eos+siacoin](https://www.reddit.com/r/Chainlink+Vechain+FetchAI_Community+perlin+Qtum+NEO+hashgraph+IoTeX+elrondnetwork+Aeternity+loopringorg+waltonchain+nebulas+IOStoken+NavCoin+viacoin+skycoin+MoedaBanking+WabiToken+EnjinCoin+OntologyNetwork+PolymathNetwork+insolar+nexusearth+zcoin+zilliqa+quarkchainio+tezos+Neblio+helloicon+ArkEcosystem+kybernetwork+0xProject+BATProject+SysCoin+omise_go+pivx+civicplatform+factom+nem+Stellar+Ripple+Wavesplatform+statusim+Ardor+stratisplatform+GolemProject+komodoplatform+storj+vergecurrency+eos+siacoin/) | [@cryptoinstantnews2](https://t.me/cryptoinstantnews2) | 1 hour |\n+| [/r/%A_LOT_OF_CRYPTO_RELATED%](https://www.reddit.com/r/Chainlink+Vechain+FetchAI_Community+perlin+Qtum+NEO+hashgraph+IoTeX+elrondnetwork+Aeternity+loopringorg+waltonchain+nebulas+IOStoken+NavCoin+viacoin+skycoin+MoedaBanking+WabiToken+EnjinCoin+OntologyNetwork+PolymathNetwork+insolar+nexusearth+zcoin+zilliqa+quarkchainio+tezos+Neblio+helloicon+ArkEcosystem+kybernetwork+0xProject+BATProject+SysCoin+omise_go+pivx+civicplatform+factom+nem+Stellar+Ripple+Wavesplatform+statusim+Ardor+stratisplatform+GolemProject+komodoplatform+storj+vergecurrency+eos+siacoin/) | [@cryptoinstantnews2](https://t.me/cryptoinstantnews2) | 1 hour |\n| [/r/LeagueOfMemes](https://www.reddit.com/r/LeagueOfMemes/) | [@r_league_of_memes](https://t.me/r_league_of_memes) | 1 hour |\n| [/r/VirtualYoutubers](https://www.reddit.com/r/VirtualYoutubers/) | [@vtuber_en](https://t.me/vtuber_en) | 1 hour |\n| | ... be the next one ... | |@\n",
        "chatgpt_cot": "Update README.md to fix grammatical errors and add punctuation. Also, update information about the project's status and capabilities."
    },
    {
        "org_diff": "diff --git a/fkie_node_manager/src/fkie_node_manager/main_window.py b/fkie_node_manager/src/fkie_node_manager/main_window.py @@ -983,6 +983,8 @@ class MainWindow(QMainWindow):\nusr = username\nif username == 'last used':\nusr = nm.settings().host_user(hostname)\n+ else:\n+ nm.settings().set_host_user(hostname, usr)\nif log_master_discovery:\nself._progress_queue.add2queue(utf8(uuid.uuid4()),\n'%s: show log of master discovery' % hostname,\n@@ -1540,6 +1542,8 @@ class MainWindow(QMainWindow):\nusr = username\nif username == 'last used':\nusr = nm.settings().host_user(hostname)\n+ else:\n+ nm.settings().set_host_user(hostname, usr)\nmuri = None if masteruri == 'ROS_MASTER_URI' else utf8(masteruri)\nself._progress_queue.add2queue(utf8(uuid.uuid4()),\n'start discovering on %s' % hostname,\n",
        "org_msg": "fkie_node_manager: update default user on start master_discovery",
        "sim_msg": "Fix for Instances where forwarded IP = malicious domain/IP",
        "sim_diff": "diff --git a/app.py b/app.py @@ -669,9 +669,14 @@ def do_before_request():\nGuestQuery.UUID = session['guestUUID']\ndb.session.commit()\nelse:\n+ if len(requestIP) <= 100:\nNewGuest = Sec.Guest(session['guestUUID'], requestIP)\ndb.session.add(NewGuest)\ndb.session.commit()\n+ else:\n+ NewGuest = Sec.Guest(session['guestUUID'], requestIP[0:100])\n+ db.session.add(NewGuest)\n+ db.session.commit()\nexcept:\npass\n",
        "chatgpt_cot": "Fix issue with setting host user in main window. New method \"set_host_user\" added to the MainWindow class to handle setting the host user."
    },
    {
        "org_diff": "diff --git a/sc2/main.py b/sc2/main.py @@ -23,6 +23,9 @@ class SlidingTimeWindow:\ndef push(self, value: float):\nself.window = (self.window + [value])[-self.window_size:]\n+ def clear(self):\n+ self.window = []\n+\n@property\ndef sum(self) -> float:\nreturn sum(self.window)\n@@ -155,6 +158,7 @@ async def _play_game_ai(client, player_id, ai, realtime, step_time_limit, game_t\nraise RuntimeError(\"Out of time\")\nelse:\ntime_penalty_cooldown = int(time_penalty)\n+ time_window.clear()\nexcept Exception as e:\n# NOTE: this message is caught by pytest suite\nlogger.exception(f\"AI step threw an error\") # DO NOT EDIT!\n",
        "org_msg": "Clear sliding window on timeout penalty",
        "sim_msg": "add comment for previous commit",
        "sim_diff": "diff --git a/edit_windows.py b/edit_windows.py @@ -1057,7 +1057,7 @@ class EditStylesMixin(np.PropertyOwner):\nself.create_widget()\ncompat.SizerItem_SetWindow(si, self.widget)\ncompat.DestroyLater(old_widget)\n- self.sizer.item_properties_modified(self)\n+ self.sizer.item_properties_modified(self) # will call toplevel Refresh as well\nself.finish_widget_creation(re_add=False)\nself.sizer.layout()\n",
        "chatgpt_cot": "\"Add clear method to SlidingTimeWindow class and clear the window when out of time in _play_game_ai method\""
    },
    {
        "org_diff": "diff --git a/fkie_master_sync/src/fkie_master_sync/master_sync.py b/fkie_master_sync/src/fkie_master_sync/master_sync.py @@ -376,7 +376,7 @@ class Main(object):\nif md5sum is not None:\nkey = KeyValue()\nkey.key = topicname\n- key.value = ttype\n+ key.value = str(ttype)\ndiag_state.values.append(key)\nda.status.append(diag_state)\n# add warnings if a topic with different type is synchrinozied to local host\n@@ -392,7 +392,7 @@ class Main(object):\n(md5sum, ttype) = tmtype\nkey = KeyValue()\nkey.key = topicname\n- key.value = ttype\n+ key.value = str(ttype)\ndiag_state.values.append(key)\nda.status.append(diag_state)\nelse:\n",
        "org_msg": "fkie_master_sync: convert diagnostic value to string",
        "sim_msg": "Add kucoin mainnet and testnet to setup_service",
        "sim_diff": "diff --git a/safe_transaction_service/history/management/commands/setup_service.py b/safe_transaction_service/history/management/commands/setup_service.py @@ -320,6 +320,14 @@ MASTER_COPIES: Dict[EthereumNetwork, List[Tuple[str, int, str]]] = {\n(\"0x3E5c63644E683549055b9Be8653de26E0B4CD36E\", 13743076, \"1.3.0+L2\"),\n(\"0xd9Db270c1B5E3Bd161E8c8503c55cEABeE709552\", 13743082, \"1.3.0\"),\n],\n+ EthereumNetwork.KCC_MAINNET: [\n+ (\"0x3E5c63644E683549055b9Be8653de26E0B4CD36E\", 4860807, \"1.3.0+L2\"),\n+ (\"0xd9Db270c1B5E3Bd161E8c8503c55cEABeE709552\", 4860810, \"1.3.0\"),\n+ ],\n+ EthereumNetwork.KCC_TESTNET: [\n+ (\"0x3E5c63644E683549055b9Be8653de26E0B4CD36E\", 12147586, \"1.3.0+L2\"),\n+ (\"0xd9Db270c1B5E3Bd161E8c8503c55cEABeE709552\", 12147596, \"1.3.0\"),\n+ ],\n}\nPROXY_FACTORIES: Dict[EthereumNetwork, List[Tuple[str, int]]] = {\n@@ -471,6 +479,12 @@ PROXY_FACTORIES: Dict[EthereumNetwork, List[Tuple[str, int]]] = {\nEthereumNetwork.CLOUDWALK_TESTNET: [\n(\"0xa6B71E26C5e0845f74c812102Ca7114b6a896AB2\", 13743040), # v1.3.0\n],\n+ EthereumNetwork.KCC_MAINNET: [\n+ (\"0xa6B71E26C5e0845f74c812102Ca7114b6a896AB2\", 4860798), # v1.3.0\n+ ],\n+ EthereumNetwork.KCC_TESTNET: [\n+ (\"0xa6B71E26C5e0845f74c812102Ca7114b6a896AB2\", 12147567), # v1.3.0\n+ ],\n}\n",
        "chatgpt_cot": "Fix type conversion issue by converting ttype to string to ensure synchronization of topics with different types to local host."
    },
    {
        "org_diff": "diff --git a/test/autotest_bot.py b/test/autotest_bot.py @@ -265,7 +265,7 @@ class TestBot(sc2.BotAI):\ndef main():\nsc2.run_game(\n- sc2.maps.get(\"(2)CatalystLE\"),\n+ sc2.maps.get(\"Acropolis\"),\n[Bot(Race.Terran, TestBot()), Computer(Race.Zerg, Difficulty.Easy)],\nrealtime=False,\n)\n",
        "org_msg": "Make testbot use map Acropolis",
        "sim_msg": "[plague] bot object",
        "sim_diff": "diff --git a/plaguegame/plague.py b/plaguegame/plague.py @@ -11,6 +11,7 @@ class Plague(commands.Cog):\n\"\"\"A plague game.\"\"\"\ndef __init__(self, bot):\n+ self.bot = bot\nself.config = Config.get_conf(self, identifier=2395486659)\ndefault_global = {\"plagueName\": \"Plague\", \"logChannel\": None}\ndefault_user = {\n",
        "chatgpt_cot": "\"Update map name in autotest_bot.py for compatibility with new map version\""
    },
    {
        "org_diff": "diff --git a/fkie_node_manager/src/fkie_node_manager/parameter_dialog.py b/fkie_node_manager/src/fkie_node_manager/parameter_dialog.py @@ -1577,4 +1577,9 @@ class ServiceDialog(ParameterDialog):\ndef _handle_resp(self, req, resp):\nself.setWindowTitle(''.join(['Request / Response of ', self.service.name]))\n- self.setText('\\n'.join([utf8(req), '---', utf8(resp)]))\n+ # replace some of Escape Characters\n+ resp_str = utf8(resp).replace('\\\\r\\\\n', '\\n')\n+ resp_str = resp_str.replace('\\\\n', '\\n')\n+ resp_str = resp_str.replace('\\\\t', '\\t')\n+ resp_str = resp_str.replace('\\\\v', '\\v')\n+ self.setText('\\n'.join([utf8(req), '---', resp_str]))\n",
        "org_msg": "replace escape sequences in service responses",
        "sim_msg": "ADD new columns to the node.requests results",
        "sim_diff": "diff --git a/packages/syft/src/syft/core/node/domain/client.py b/packages/syft/src/syft/core/node/domain/client.py @@ -121,15 +121,30 @@ class RequestQueueClient(AbstractNodeClient):\n@property\ndef pandas(self) -> pd.DataFrame:\n+ # TODO:\n+ # Replace all the hardcoded string by enums / abstractions.\nrequest_lines = [\n{\n- \"Requested Object's tags\": request.object_tags,\n- \"Reason\": request.request_description,\n- \"Request ID\": request.id,\n- \"Requested Object's ID\": request.object_id,\n- \"Requested Object's type\": request.object_type,\n+ \"Requested Object's tags\": req.object_tags,\n+ \"Name\": req.user_name,\n+ \"Email\": req.user_email,\n+ \"Role\": req.user_role,\n+ \"Request Type\": req.request_type.upper(),\n+ \"Status\": req.status,\n+ \"Reason\": req.request_description,\n+ \"Request ID\": req.id,\n+ \"Requested Object's ID\": req.object_id\n+ if req.request_type == \"data\"\n+ else None,\n+ \"Requested Object's tags\": req.object_tags,\n+ \"Requested Budget\": req.requested_budget\n+ if req.request_type == \"budget\"\n+ else None,\n+ \"Current Budget\": req.current_budget\n+ if req.request_type == \"budget\"\n+ else None,\n}\n- for request in self.requests\n+ for req in self.requests\n]\nreturn pd.DataFrame(request_lines)\n",
        "chatgpt_cot": "Replace escape characters in response string to improve readability and display in ServiceDialog."
    },
    {
        "org_diff": "diff --git a/rasa_core_sdk/forms.py b/rasa_core_sdk/forms.py @@ -160,6 +160,19 @@ class FormAction(Action):\nelse:\nreturn [Form(self.name())]\n+ @staticmethod\n+ def _predicted_no_validation(tracker):\n+ # type: (Tracker) -> bool\n+ \"\"\"Check whether previous call to the form was rejected\"\"\"\n+ for e in reversed(tracker.events):\n+ if e['event'] == 'action':\n+ if e['name'] == 'action_no_form_validation':\n+ return True\n+\n+ break\n+\n+ return False\n+\ndef _validate_if_required(self, dispatcher, tracker, domain):\n# type: (CollectingDispatcher, Tracker, Dict[Text, Any]) -> List[Dict]\n\"\"\"Return a list of events from `self.validate`\n@@ -168,7 +181,8 @@ class FormAction(Action):\n- the form is called after `action_listen`\n\"\"\"\nif (tracker.active_form == self.name() and\n- tracker.latest_action_name == 'action_listen'):\n+ tracker.latest_action_name == 'action_listen' and\n+ not self._predicted_no_validation(tracker)):\nreturn self.validate(dispatcher, tracker, domain)\nelse:\nreturn []\n",
        "org_msg": "add ability learn when do not validate RasaHQ/roadmap#280",
        "sim_msg": "[1755] Actions.py: add ignore for mypy\nSome method was being overridden by methods with a slightly different\nsignature (the arguments changed). This caused mypy errors.\n`# type: ignore` helps \"hide\" these errors.",
        "sim_diff": "diff --git a/amy/autoemails/actions.py b/amy/autoemails/actions.py @@ -231,7 +231,7 @@ class NewInstructorAction(BaseAction):\nreturn \"\"\n@staticmethod\n- def check(task: Task):\n+ def check(task: Task): # type: ignore\n\"\"\"Conditions for creating a NewInstructorAction.\"\"\"\nreturn bool(\n# 2019-11-01: we accept instructors without `may_contact` agreement\n@@ -327,7 +327,7 @@ class NewSupportingInstructorAction(BaseAction):\nreturn \"\"\n@staticmethod\n- def check(task: Task):\n+ def check(task: Task): # type: ignore\n\"\"\"Conditions for creating a NewSupportingInstructorAction.\"\"\"\nreturn bool(\ntask.role.name == \"supporting-instructor\"\n@@ -457,7 +457,7 @@ class PostWorkshopAction(BaseAction):\nreturn \"\"\n@staticmethod\n- def check(event: Event):\n+ def check(event: Event): # type: ignore\n\"\"\"Conditions for creating a PostWorkshopAction.\"\"\"\nreturn bool(\n# end date is required and in future\n@@ -585,7 +585,7 @@ class SelfOrganisedRequestAction(BaseAction):\nreturn \"\"\n@staticmethod\n- def check(event: Event):\n+ def check(event: Event): # type: ignore\n\"\"\"Conditions for creating a SelfOrganisedRequestAction.\"\"\"\ntry:\nreturn bool(\n@@ -697,7 +697,7 @@ class InstructorsHostIntroductionAction(BaseAction):\nreturn None\n@staticmethod\n- def check(event: Event):\n+ def check(event: Event): # type: ignore\n\"\"\"Conditions for creating a SelfOrganisedRequestAction.\"\"\"\n# there is 1 host task and 2 instructor tasks\ntry:\n@@ -858,7 +858,7 @@ class AskForWebsiteAction(BaseAction):\nreturn \"\"\n@staticmethod\n- def check(event: Event):\n+ def check(event: Event): # type: ignore\n\"\"\"Conditions for creating a AskForWebsiteAction.\"\"\"\ninstructors = event.task_set.filter(\nrole__name__in=AskForWebsiteAction.role_names\n@@ -988,7 +988,7 @@ class RecruitHelpersAction(BaseAction):\nreturn \"\"\n@staticmethod\n- def check(event: Event):\n+ def check(event: Event): # type: ignore\n\"\"\"Conditions for creating a RecruitHelpersAction.\"\"\"\nhosts = event.task_set.filter(role__name=\"host\")\ninstructors = event.task_set.filter(role__name=\"instructor\")\n",
        "chatgpt_cot": "Add a static method to check if the previous call to the form was rejected, and modify the validate method to account for this check."
    },
    {
        "org_diff": "diff --git a/sc2/bot_ai.py b/sc2/bot_ai.py @@ -530,7 +530,7 @@ class BotAI(object):\n\"\"\"\nawait self._issue_unit_dead_events()\nawait self._issue_unit_added_events()\n- for unit in self.units:\n+ for unit in self.units.structure:\nawait self._issue_building_complete_event(unit)\nasync def _issue_unit_added_events(self):\n",
        "org_msg": "Only check structures for building completion",
        "sim_msg": "added more frame slowdown info",
        "sim_diff": "diff --git a/bot_manager.py b/bot_manager.py @@ -68,6 +68,7 @@ class BotManager:\nself.game_file = open(filename.replace(\" \", \"\"), 'wb')\nold_time = 0\ncurrent_time = -10\n+ counter = 0\n# Run until main process tells to stop\nwhile not self.terminateEvent.is_set():\n@@ -109,7 +110,11 @@ class BotManager:\nafter = datetime.now()\nafter2 = time.time()\nif after2 - before2 > 0.03:\n- print('Too slow for ' + self.name + ': ' + str(after2 - before2))\n+ print('Too slow for ' + self.name + ': ' + str(after2 - before2) +\n+ ' frames since slowdown ' + str(counter))\n+ counter = 0\n+ else:\n+ counter += 1\n#print('Latency of ' + self.name + ': ' + str(after2 - before2))\nr.acquire(after-before)\n",
        "chatgpt_cot": "\"Refactor unit iteration to include only structures for issue_building_complete_event\""
    },
    {
        "org_diff": "diff --git a/sc2/constants.py b/sc2/constants.py @@ -4,7 +4,8 @@ from .ids.buff_id import *\nfrom .ids.effect_id import *\nfrom .ids.unit_typeid import *\nfrom .ids.upgrade_id import *\n-from typing import Dict\n+from collections import defaultdict\n+from typing import Dict, List\nmineral_ids = {\nRICHMINERALFIELD.value,\n@@ -228,3 +229,81 @@ FakeEffectID: Dict[int, str] = {\nUnitTypeId.PARASITICBOMBDUMMY.value: \"PARASITICBOMB\",\nUnitTypeId.FORCEFIELD.value: \"FORCEFIELD\",\n}\n+\n+\n+TERRAN_TECH_REQUIREMENT: Dict[UnitTypeId, UnitTypeId] = defaultdict(\n+ list,\n+ {\n+ MISSILETURRET: ENGINEERINGBAY,\n+ SENSORTOWER: ENGINEERINGBAY,\n+ PLANETARYFORTRESS: ENGINEERINGBAY,\n+ BARRACKS: SUPPLYDEPOT,\n+ ORBITALCOMMAND: BARRACKS,\n+ BUNKER: BARRACKS,\n+ GHOST: GHOSTACADEMY,\n+ GHOSTACADEMY: BARRACKS,\n+ FACTORY: BARRACKS,\n+ ARMORY: FACTORY,\n+ HELLIONTANK: ARMORY,\n+ THOR: ARMORY,\n+ STARPORT: FACTORY,\n+ FUSIONCORE: STARPORT,\n+ BATTLECRUISER: FUSIONCORE,\n+ },\n+)\n+PROTOSS_TECH_REQUIREMENT: Dict[UnitTypeId, UnitTypeId] = defaultdict(\n+ list,\n+ {\n+ PHOTONCANNON: FORGE,\n+ CYBERNETICSCORE: GATEWAY,\n+ SENTRY: CYBERNETICSCORE,\n+ STALKER: CYBERNETICSCORE,\n+ ADEPT: CYBERNETICSCORE,\n+ TWILIGHTCOUNCIL: CYBERNETICSCORE,\n+ SHIELDBATTERY: CYBERNETICSCORE,\n+ TEMPLARARCHIVE: TWILIGHTCOUNCIL,\n+ DARKSHRINE: TWILIGHTCOUNCIL,\n+ HIGHTEMPLAR: TEMPLARARCHIVE,\n+ DARKTEMPLAR: DARKSHRINE,\n+ STARGATE: CYBERNETICSCORE,\n+ TEMPEST: FLEETBEACON,\n+ CARRIER: FLEETBEACON,\n+ MOTHERSHIP: FLEETBEACON,\n+ ROBOTICSFACILITY: CYBERNETICSCORE,\n+ ROBOTICSBAY: ROBOTICSFACILITY,\n+ COLOSSUS: ROBOTICSBAY,\n+ DISRUPTOR: ROBOTICSBAY,\n+ },\n+)\n+ZERG_TECH_REQUIREMENT: Dict[UnitTypeId, UnitTypeId] = defaultdict(\n+ list,\n+ {\n+ ZERGLING: SPAWNINGPOOL,\n+ QUEEN: SPAWNINGPOOL,\n+ ROACHWARREN: SPAWNINGPOOL,\n+ BANELINGNEST: SPAWNINGPOOL,\n+ SPINECRAWLER: SPAWNINGPOOL,\n+ SPORECRAWLER: SPAWNINGPOOL,\n+ ROACH: ROACHWARREN,\n+ BANELING: BANELINGNEST,\n+ LAIR: SPAWNINGPOOL,\n+ OVERSEER: LAIR,\n+ OVERLORDTRANSPORT: LAIR,\n+ INFESTATIONPIT: LAIR,\n+ INFESTOR: INFESTATIONPIT,\n+ SWARMHOSTMP: INFESTATIONPIT,\n+ HYDRALISKDEN: LAIR,\n+ HYDRALISK: HYDRALISKDEN,\n+ LURKERDENMP: HYDRALISKDEN,\n+ LURKERMP: LURKERDENMP,\n+ SPIRE: LAIR,\n+ MUTALISK: SPIRE,\n+ CORRUPTOR: SPIRE,\n+ NYDUSNETWORK: LAIR,\n+ HIVE: INFESTATIONPIT,\n+ VIPER: HIVE,\n+ ULTRALISKCAVERN: HIVE,\n+ GREATERSPIRE: HIVE,\n+ BROODLORD: GREATERSPIRE,\n+ },\n+)\n",
        "org_msg": "Add custom tech requirement because the on in the API does not work reliably (thor and ghost are not correct)",
        "sim_msg": "Updating plugins compose file",
        "sim_diff": "diff --git a/docker/docker-compose/plugins-compose.yml b/docker/docker-compose/plugins-compose.yml version: '3.5'\n+x-definitions: &common-env\n+ BG_HOST: brew-view\n+ BG_SSL_ENABLED: \"False\"\n+\n+x-definitions: &complex-env\n+ DB_NAME: complex\n+ DB_PASS: supersecret\n+\nx-definitions: &plugin\nimage: bgio/example-plugins\nnetworks:\n- bg-network\nenvironment:\n- BG_HOST: brew-view\n- BG_SSL_ENABLED: \"False\"\n+ <<: *common-env\n+\nservices:\ncomplex-c1:\ncommand: [\"complex\", \"c1\", \"c1-host\", \"c1-port\"]\n+ environment:\n+ <<: [*common-env, *complex-env]\n<<: *plugin\ncomplex-c2:\ncommand: [\"complex\", \"c2\", \"c2-host\", \"c2-port\"]\n+ environment:\n+ <<: [*common-env, *complex-env]\n+ <<: *plugin\n+\n+ concurrent-sleeper:\n+ command: [\"concurrent_sleeper\"]\n<<: *plugin\ncustom-display:\n@@ -41,6 +57,7 @@ services:\ncommand: [\"sleeper\"]\n<<: *plugin\n+\nnetworks:\nbg-network:\nexternal: true\n",
        "chatgpt_cot": "\"Add default tech requirements for Terran, Protoss, and Zerg units to constants.py\""
    },
    {
        "org_diff": "diff --git a/sc2/game_state.py b/sc2/game_state.py @@ -104,6 +104,7 @@ class EffectData:\nclass GameState:\ndef __init__(self, response_observation):\n+ self.response_observation = response_observation\nself.actions = response_observation.actions # successful actions since last loop\nself.action_errors = response_observation.action_errors # error actions since last loop\n",
        "org_msg": "Add add self.response_observation for tests",
        "sim_msg": "statistics now allows non-bot output",
        "sim_diff": "diff --git a/trainer/utils/controller_statistics.py b/trainer/utils/controller_statistics.py @@ -10,32 +10,34 @@ class OutputChecks:\ngame_tick_packet = None\naccuracy_over_time = None\nbot_data_over_time = None\n+ requires_output = False\ndef __init__(self, packets, model_output, game_tick_packet, input_array, tf_session, action_handler,\n- tutorial_bot=None):\n+ bot=None):\nself.sess = tf_session\nself.packets = packets\nself.game_tick_packet = game_tick_packet\nself.input_array = input_array\nself.packet_generator = random_packet_creator.TensorflowPacketGenerator(packets)\n- self.tutorial_bot = tutorial_bot\n+ self.tutorial_bot = bot\nself.model_output = model_output\nself.actionHandler = action_handler\nif self.tutorial_bot is None:\n- self.tutorial_bot = tutorial_bot_output.TutorialBotOutput(packets)\n+ self.requires_output = True\ndef create_model(self):\n# clear history\nself.accuracy_over_time = []\nself.bot_data_over_time = []\n- def get_amounts(self):\n+ def get_amounts(self, bot_output=None):\ncontrols = tf.transpose(\nself.actionHandler.create_tensorflow_controller_from_selection(self.model_output, self.packets))\n- expected = self.tutorial_bot.get_output_vector(self.game_tick_packet)\n+ if not self.requires_output:\n+ bot_output = self.tutorial_bot.get_output_vector(self.game_tick_packet)\n- output, bot_output = self.sess.run([controls, expected])\n+ output = self.sess.run(controls)\naccuracy = np.sum(np.isclose(output, bot_output, 0.01), 1) / np.size(output[1])\nself.accuracy_over_time.append(accuracy)\n@@ -63,14 +65,13 @@ class OutputChecks:\nnumber_prints = len(self.accuracy_over_time)\naccuracy = np.transpose(self.accuracy_over_time)\nnp.set_printoptions(formatter={'float': '{: 0.2f}'.format})\n- ten = number_prints * .1\n- twfive = number_prints * .25\n- fifty = number_prints * .5\n+ percentages = [10, 25, 50]\nnames = [\"Throttle\", \"Steer\", \"Pitch\", \"Yaw\", \"Roll\", \"Jump\", \"Boost\", \"Handbrake\"]\n- print(\"Every action is printed four times, once all values and then averages over 10%, 25% and 50%\")\n+ print(\"Every action is printed multiple times, once all values and then averages over percentages\")\nfor n in range(8):\nprint(names[n] + \":\")\nprint(\"All: \", accuracy[n])\n- print(\"Averages every 10%\", np.array([average(accuracy[n][int(i * ten):int(i * ten + ten) if not int(i * ten + ten) is int(i * ten) else int(i * ten) + 1]) for i in range(10)]))\n- print(\" 25%\", np.array([average(accuracy[n][int(i * twfive):int(i * twfive + twfive) if not int(i * twfive + twfive) is int(i * twfive) else int(i * twfive) + 1]) for i in range(4)]))\n- print(\" 50%\", np.array([average(accuracy[n][int(i * fifty):int(i * fifty + fifty) if not int(i * fifty + fifty) is int(i * fifty) else int(i * fifty) + 1]) for i in range(2)]))\n+ for p in percentages:\n+ r = int(100 / p)\n+ step = int(number_prints * p / 100)\n+ print(str(p) + \"%:\", np.array([average(accuracy[n][int(i * step):int(i * step + step) if not int(i * step + step) is int(i * step) else int(i * step) + 1]) for i in range(r)]))\n",
        "chatgpt_cot": "Add response_observation attribute to GameState constructor to store response_observation data for game state management."
    },
    {
        "org_diff": "diff --git a/sc2/generate_ids.py b/sc2/generate_ids.py @@ -164,10 +164,10 @@ class IdGenerator:\n# Apply formatting]\ntry:\n- subprocess.run([\"black\", \"--line-length\", \"120\", ids_file_path])\n+ subprocess.run([\"poetry\", \"run\", \"yapf\", ids_file_path, \"-i\"])\nexcept FileNotFoundError:\nprint(\n- f\"Black is not installed. Please use 'pip install black' to install black formatter.\\nCould not autoformat file {ids_file_path}\"\n+ f\"Yapf is not installed. Please use 'pip install yapf' to install yapf formatter.\\nCould not autoformat file {ids_file_path}\"\n)\nif self.game_version is not None:\n",
        "org_msg": "Update generate ids to use yapf instead of black formatter",
        "sim_msg": "ignore errors when binding events in preview; fix issue",
        "sim_diff": "diff --git a/codegen/py_codegen.py b/codegen/py_codegen.py @@ -396,8 +396,8 @@ from %(top_win_module)s import %(top_win_class)s\\n\\n\"\"\"\nindent = self.tabs(1) # one additional level\nlines.insert(0, '%stry:\\n'%tab)\nlines[1] = indent + lines[1] # indent by one level\n- lines.append( '%sexcept AttributeError:\\n'%tab )\n- lines.append( '%s%sprint(\"unknown event %s\")\\n'%(indent, tab, event) )\n+ lines.append( '%sexcept:\\n'%tab )\n+ lines.append( '%s%sprint(\"could not bind event %s - ignoring error for preview\")\\n'%(indent, tab, event) )\ncode_lines += lines\n",
        "chatgpt_cot": "\"Switch code formatter from Black to Yapf to resolve installation issue and apply formatting in IdGenerator class.\""
    },
    {
        "org_diff": "diff --git a/src/agent/ansible/roles/deploy_k8s/fabricsetup/templates/fabric-pod.j2 b/src/agent/ansible/roles/deploy_k8s/fabricsetup/templates/fabric-pod.j2 @@ -21,12 +21,25 @@ metadata:\nname: {{ zookeeper }}\nlabels:\nk8s-app: {{ zookeeper }}\n+ type: zookeeper\nspec:\n{% if creds %}\nimagePullSecrets:\n- name: regcred\n{% endif %}\nrestartPolicy: OnFailure\n+ affinity:\n+ podAntiAffinity:\n+ preferredDuringSchedulingIgnoredDuringExecution:\n+ - weight: 1\n+ podAffinityTerm:\n+ labelSelector:\n+ matchExpressions:\n+ - key: type\n+ operator: In\n+ values:\n+ - zookeeper\n+ topologyKey: kubernetes.io/hostname\ncontainers:\n- name: {{ zookeeper }}\nimage: {{ fabric.repo.url }}fabric-zookeeper:{{ fabric.helper_tag }}\n@@ -65,12 +78,25 @@ metadata:\nname: {{ kafka }}\nlabels:\nk8s-app: {{ kafka }}\n+ type: kafka\nspec:\n{% if creds %}\nimagePullSecrets:\n- name: regcred\n{% endif %}\nrestartPolicy: OnFailure\n+ affinity:\n+ podAntiAffinity:\n+ preferredDuringSchedulingIgnoredDuringExecution:\n+ - weight: 1\n+ podAffinityTerm:\n+ labelSelector:\n+ matchExpressions:\n+ - key: type\n+ operator: In\n+ values:\n+ - kafka\n+ topologyKey: kubernetes.io/hostname\ncontainers:\n- name: {{ kafka }}\nimage: {{ fabric.repo.url }}fabric-kafka:{{ fabric.helper_tag }}\n@@ -111,6 +137,7 @@ metadata:\nname: {{ ca.name }}\nlabels:\nk8s-app: {{ ca.name }}\n+ type: ca\nspec:\n{% if creds %}\nimagePullSecrets:\n@@ -121,6 +148,18 @@ spec:\n- name: task-pv-storage\npersistentVolumeClaim:\nclaimName: fabriccerts\n+ affinity:\n+ podAntiAffinity:\n+ preferredDuringSchedulingIgnoredDuringExecution:\n+ - weight: 1\n+ podAffinityTerm:\n+ labelSelector:\n+ matchExpressions:\n+ - key: type\n+ operator: In\n+ values:\n+ - ca\n+ topologyKey: kubernetes.io/hostname\ncontainers:\n- name: {{ ca.name }}\nimage: {{ fabric.repo.url }}fabric-ca:{{ fabric.ca.image_tag }}\n@@ -167,12 +206,25 @@ metadata:\nname: {{ peer.name }}\nlabels:\nk8s-app: {{ peer.name }}\n+ type: peer\nspec:\n{% if creds %}\nimagePullSecrets:\n- name: regcred\n{% endif %}\nrestartPolicy: OnFailure\n+ affinity:\n+ podAntiAffinity:\n+ preferredDuringSchedulingIgnoredDuringExecution:\n+ - weight: 1\n+ podAffinityTerm:\n+ labelSelector:\n+ matchExpressions:\n+ - key: type\n+ operator: In\n+ values:\n+ - peer\n+ topologyKey: kubernetes.io/hostname\nvolumes:\n- name: varrun\nhostPath:\n@@ -264,6 +316,7 @@ metadata:\nname: {{ orderer.name }}\nlabels:\nk8s-app: {{ orderer.name }}\n+ type: orderer\nspec:\n{% if creds %}\nimagePullSecrets:\n@@ -274,6 +327,18 @@ spec:\n- name: task-pv-storage\npersistentVolumeClaim:\nclaimName: fabriccerts\n+ affinity:\n+ podAntiAffinity:\n+ preferredDuringSchedulingIgnoredDuringExecution:\n+ - weight: 1\n+ podAffinityTerm:\n+ labelSelector:\n+ matchExpressions:\n+ - key: type\n+ operator: In\n+ values:\n+ - orderer\n+ topologyKey: kubernetes.io/hostname\ncontainers:\n- name: {{ orderer.name }}\nimage: {{ fabric.repo.url }}fabric-orderer:{{ fabric.baseimage_tag }}\n",
        "org_msg": "Support PodAntiAffinity in cello/ansible\nSupport deployment to support equal distribution of pods across nodes\nwhen using kubernetes in Cello/ansible by using PodAntiAffinity concept\nin kubernetes.",
        "sim_msg": "autoscale site\n* autoscale site\n* fix site deploy\nremove explicit namespace\n* bump\n* bump",
        "sim_diff": "diff --git a/site/deployment.yaml b/site/deployment.yaml -apiVersion: apps/v1beta2\n+apiVersion: apps/v1\nkind: Deployment\nmetadata:\nname: site-deployment\n@@ -9,7 +9,7 @@ spec:\nselector:\nmatchLabels:\napp: site\n- replicas: 1\n+ replicas: 2\ntemplate:\nmetadata:\nlabels:\n@@ -19,9 +19,26 @@ spec:\n{% if deploy %}\npriorityClassName: production\n{% endif %}\n+ affinity:\n+ podAntiAffinity:\n+ requiredDuringSchedulingIgnoredDuringExecution:\n+ - labelSelector:\n+ matchExpressions:\n+ - key: \"app\"\n+ operator: In\n+ values:\n+ - site\n+ topologyKey: \"kubernetes.io/hostname\"\ncontainers:\n- name: site\nimage: \"{{ site_image.image }}\"\n+ resources:\n+ requests:\n+ memory: \"250M\"\n+ cpu: \"100m\"\n+ limits:\n+ memory: \"1G\"\n+ cpu: \"1\"\nports:\n- containerPort: 80\nlivenessProbe:\n@@ -36,3 +53,20 @@ spec:\nport: 80\ninitialDelaySeconds: 5\nperiodSeconds: 5\n+---\n+apiVersion: autoscaling/v2beta1\n+kind: HorizontalPodAutoscaler\n+metadata:\n+ name: site\n+spec:\n+ scaleTargetRef:\n+ apiVersion: apps/v1\n+ kind: Deployment\n+ name: site\n+ minReplicas: 2\n+ maxReplicas: 10\n+ metrics:\n+ - type: Resource\n+ resource:\n+ name: cpu\n+ targetAverageUtilization: 80\n",
        "chatgpt_cot": "Add type label and affinity rules for zookeeper, kafka, ca, peer, and orderer pods to improve pod scheduling and anti-affinity."
    },
    {
        "org_diff": "diff --git a/sc2/constants.py b/sc2/constants.py @@ -230,9 +230,12 @@ FakeEffectID: Dict[int, str] = {\nUnitTypeId.FORCEFIELD.value: \"FORCEFIELD\",\n}\n+def return_NOTAUNIT():\n+ # NOTAUNIT = 0\n+ return NOTAUNIT\nTERRAN_TECH_REQUIREMENT: Dict[UnitTypeId, UnitTypeId] = defaultdict(\n- list,\n+ return_NOTAUNIT,\n{\nMISSILETURRET: ENGINEERINGBAY,\nSENSORTOWER: ENGINEERINGBAY,\n@@ -252,7 +255,7 @@ TERRAN_TECH_REQUIREMENT: Dict[UnitTypeId, UnitTypeId] = defaultdict(\n},\n)\nPROTOSS_TECH_REQUIREMENT: Dict[UnitTypeId, UnitTypeId] = defaultdict(\n- list,\n+ return_NOTAUNIT,\n{\nPHOTONCANNON: FORGE,\nCYBERNETICSCORE: GATEWAY,\n@@ -276,7 +279,7 @@ PROTOSS_TECH_REQUIREMENT: Dict[UnitTypeId, UnitTypeId] = defaultdict(\n},\n)\nZERG_TECH_REQUIREMENT: Dict[UnitTypeId, UnitTypeId] = defaultdict(\n- list,\n+ return_NOTAUNIT,\n{\nZERGLING: SPAWNINGPOOL,\nQUEEN: SPAWNINGPOOL,\n",
        "org_msg": "Change defaultdict return value to UnitTypeId instead of None",
        "sim_msg": "Constants upgraded with contracts options.",
        "sim_diff": "diff --git a/aea/cli/utils/constants.py b/aea/cli/utils/constants.py @@ -24,6 +24,7 @@ from typing import Dict\nfrom aea.configurations.base import (\nDEFAULT_CONNECTION_CONFIG_FILE,\n+ DEFAULT_CONTRACT_CONFIG_FILE,\nDEFAULT_PROTOCOL_CONFIG_FILE,\nDEFAULT_SKILL_CONFIG_FILE,\n)\n@@ -45,10 +46,11 @@ NOT_PERMITTED_AUTHORS = [\nFROM_STRING_TO_TYPE = dict(str=str, int=int, bool=bool, float=float)\n-ALLOWED_PATH_ROOTS = [\"agent\", \"skills\", \"protocols\", \"connections\", \"vendor\"]\n+ALLOWED_PATH_ROOTS = [\"agent\", \"skills\", \"protocols\", \"connections\", \"contracts\", \"vendor\"]\nRESOURCE_TYPE_TO_CONFIG_FILE = {\n\"skills\": DEFAULT_SKILL_CONFIG_FILE,\n\"protocols\": DEFAULT_PROTOCOL_CONFIG_FILE,\n\"connections\": DEFAULT_CONNECTION_CONFIG_FILE,\n+ \"contracts\": DEFAULT_CONTRACT_CONFIG_FILE\n} # type: Dict[str, str]\nFALSE_EQUIVALENTS = [\"f\", \"false\", \"False\"]\n",
        "chatgpt_cot": "Add new function return_NOTAUNIT to fix compilation issue in constants.py related to tech requirements for Terran, Protoss, and Zerg units."
    },
    {
        "org_diff": "diff --git a/fkie_node_manager/src/fkie_node_manager/logscreen/logger_handler.py b/fkie_node_manager/src/fkie_node_manager/logscreen/logger_handler.py @@ -114,7 +114,7 @@ class LoggerHandler(QObject):\nwhile self.layout.count() > 1:\nitem = self.layout.takeAt(0)\nwd = item.widget()\n- if wd.current_level is not None:\n+ if wd.current_level is not None and wd.loggername != 'all':\nself._stored_values[wd.loggername] = wd.current_level\nwd.setParent(None)\nself._logger_items.clear()\n",
        "org_msg": "fixed change all loglevel",
        "sim_msg": "fix for Classic",
        "sim_diff": "diff --git a/tree.py b/tree.py @@ -272,7 +272,7 @@ class WidgetTree(wx.TreeCtrl):#, Tree):\n# new implementation:\ndef on_delete_item(self, event):\nitem = event.GetItem()\n- editor = self.GetItemData( item )\n+ editor = self._GetItemData( item )\nif DEBUG:\nprint(\"on_delete_item\", utilities.hx(item), editor, editor and editor.item or None)\nif editor is not None and editor.item is item:\n",
        "chatgpt_cot": "\"Refactor LoggerHandler to store current level only if loggername is not 'all' to improve performance and reduce unnecessary data storage.\""
    },
    {
        "org_diff": "diff --git a/fkie_node_manager/nodes/script_runner.py b/fkie_node_manager/nodes/script_runner.py @@ -112,14 +112,14 @@ class RunThread(threading.Thread):\nself._cmd.append(cmd)\nself.setDaemon(True)\nself.spopen = None\n- self.stop = False\n+ self.stopped = False\ndef run(self):\n'''\n'''\ntry:\nself.spopen = SupervisedPopen(self._cmd)\n- while not self.stop and self.spopen.popen.returncode is None:\n+ while not self.stopped and self.spopen.popen.returncode is None:\nif self.spopen.popen.stderr is not None:\nreserr = self.spopen.popen.stderr.read()\nif reserr:\n@@ -131,10 +131,12 @@ class RunThread(threading.Thread):\nexcept OSError as err:\nrospy.logerr(\"Error while run '%s': %s\" % (self._script, err))\nos.kill(os.getpid(), signal.SIGKILL)\n+ rospy.loginfo('script finished with code: %d' % self.spopen.popen.returncode)\n+ rospy.signal_shutdown('script finished with code: %d' % self.spopen.popen.returncode)\n- def stop(self):\n- self.stop = True\n- if self.spopen is not None:\n+ def stop(self, send_sigint=True):\n+ self.stopped = True\n+ if send_sigint and self.spopen is not None:\nif self.spopen.popen.pid is not None and self.spopen.popen.returncode is None:\nrospy.loginfo(\"stop process %d\" % self.spopen.popen.pid)\nself.spopen.popen.send_signal(signal.SIGINT)\n@@ -159,7 +161,7 @@ if __name__ == '__main__':\nrospy.spin()\n# stop the script\nif param_stop_script:\n- runthread.stop = True\n+ runthread.stop(False)\nrospy.loginfo(\"stop using %s\" % param_stop_script)\nstopthread = RunThread(param_stop_script)\nstopthread.start()\n@@ -170,7 +172,7 @@ if __name__ == '__main__':\nif reserr:\nrospy.logwarn(\"stop script has follow exception: %s\" % reserr)\nelse:\n- runthread.stop = True\n+ runthread.stop()\nrunthread.join(3)\nif runthread.is_alive():\nrospy.logwarn(\"Script does not stop, try to kill %d...\" % runthread.spopen.popen.pid)\n",
        "org_msg": "fkie_node_manager: fixed script runner; stop also node if script dies",
        "sim_msg": "synctl warns when no process is stopped and avoids start\n* If an error occurs when stopping a process synctl now logs a warning.\n* During a restart, synctl will avoid attempting to start Synapse if an error\noccurs during stopping Synapse.",
        "sim_diff": "diff --git a/synctl b/synctl @@ -142,12 +142,23 @@ def start_worker(app: str, configfile: str, worker_configfile: str) -> bool:\nreturn False\n-def stop(pidfile, app):\n+def stop(pidfile: str, app: str) -> bool:\n+ \"\"\"Attempts to kill a synapse worker from the pidfile.\n+ Args:\n+ pidfile: path to file containing worker's pid\n+ app: name of the worker's appservice\n+\n+ Returns:\n+ True if the process stopped successfully\n+ False if process was already stopped or an error occured\n+ \"\"\"\n+\nif os.path.exists(pidfile):\npid = int(open(pidfile).read())\ntry:\nos.kill(pid, signal.SIGTERM)\nwrite(\"stopped %s\" % (app,), colour=GREEN)\n+ return True\nexcept OSError as err:\nif err.errno == errno.ESRCH:\nwrite(\"%s not running\" % (app,), colour=YELLOW)\n@@ -155,6 +166,14 @@ def stop(pidfile, app):\nabort(\"Cannot stop %s: Operation not permitted\" % (app,))\nelse:\nabort(\"Cannot stop %s: Unknown error\" % (app,))\n+ return False\n+ else:\n+ write(\n+ \"No running worker of %s found (from %s)\\nThe process might be managed by another controller (e.g. systemd)\"\n+ % (app, pidfile),\n+ colour=YELLOW,\n+ )\n+ return False\nWorker = collections.namedtuple(\n@@ -300,11 +319,17 @@ def main():\naction = options.action\nif action == \"stop\" or action == \"restart\":\n+ has_stopped = True\nfor worker in workers:\n- stop(worker.pidfile, worker.app)\n+ if not stop(worker.pidfile, worker.app):\n+ # A worker could not be stopped.\n+ has_stopped = False\nif start_stop_synapse:\n- stop(pidfile, \"synapse.app.homeserver\")\n+ if not stop(pidfile, \"synapse.app.homeserver\"):\n+ has_stopped = False\n+ if not has_stopped:\n+ sys.exit(1)\n# Wait for synapse to actually shutdown before starting it again\nif action == \"restart\":\n",
        "chatgpt_cot": "Refactor stop method in RunThread to use boolean flag for better clarity and add logging for script completion in script_runner.py."
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/editor/xmlformatter.py b/node_manager_fkie/src/node_manager_fkie/editor/xmlformatter.py @@ -39,15 +39,22 @@ DEFAULT_INDENT_CHAR = \" \"\nDEFAULT_INLINE = True\nDEFAULT_ENCODING_INPUT = None\nDEFAULT_ENCODING_OUTPUT = None\n+DEFAULT_NOEMPTYTAG = False\n+DEFAULT_EMPTYATTR = True\n+DEFAULT_INDENT_DATA = True\nclass Formatter():\n# Use internal encoding:\nencoding_internal = None\n- def __init__(self, indent = DEFAULT_INDENT, preserve = [], compress = DEFAULT_COMPRESS, indent_char = DEFAULT_INDENT_CHAR, encoding_input = DEFAULT_ENCODING_INPUT, encoding_output = DEFAULT_ENCODING_OUTPUT, inline = DEFAULT_INLINE, correct = DEFAULT_CORRECT):\n+ def __init__(self, indent = DEFAULT_INDENT, preserve = [], compress = DEFAULT_COMPRESS, indent_char = DEFAULT_INDENT_CHAR, encoding_input = DEFAULT_ENCODING_INPUT, encoding_output = DEFAULT_ENCODING_OUTPUT, inline = DEFAULT_INLINE, correct = DEFAULT_CORRECT, noemptytag = DEFAULT_NOEMPTYTAG, emptyattr = DEFAULT_EMPTYATTR, indent_data = DEFAULT_INDENT_DATA):\n# Minify the XML document:\nself.compress = compress\n+ # Allow self closing tag also it not compress\n+ self.noemptytag = noemptytag\n+ # Allow attributes with empty value\n+ self.emptyattr = emptyattr\n# Correct text nodes\nself.correct = correct\n# Decode the XML document:\n@@ -58,6 +65,8 @@ class Formatter():\nself.indent = int(indent)\n# Indent by char:\nself.indent_char = indent_char\n+ # Indent also data\n+ self.indent_data = indent_data\n# Format inline objects:\nself.inline = inline\n# Don't compress this elements and their descendants:\n@@ -417,7 +426,7 @@ class Formatter():\nreturn self.formatter.correct\ndef attribute(self, key, value):\n- if (key and value):\n+ if ((key and value) or self.formatter.emptyattr):\nreturn \" %s=\\\"%s\\\"\" % (key, value)\nreturn \"\"\n@@ -494,6 +503,8 @@ class Formatter():\nif not self.cdata_section:\nstr = re.sub(r'&', '&amp;', str)\nstr = re.sub(r'<', '&lt;', str)\n+ if str and self.formatter.indent_data:\n+ str = \"%s%s\" % (self.indent_create(self.level + 1), str)\nreturn str\ndef pre_operate(self):\n@@ -580,8 +591,8 @@ class Formatter():\ndef __unicode__(self):\nstr = \"\"\n# Don't close empty nodes on compression mode:\n- if (not self.formatter.compress or self.list[self.pos-1].name != \"StartElement\"):\n- if (self.preserve in [0] and self.indent):\n+ if (self.formatter.noemptytag or self.list[self.pos - 1].name != \"StartElement\"):\n+ if (not self.formatter.compress or self.preserve in [0] and self.indent):\nstr += self.indent_insert()\nstr += \"</%s>\" % self.arg[0]\nreturn str\n@@ -653,7 +664,7 @@ class Formatter():\nstr += \"<%s\" %self.arg[0]\nfor attr in sorted(self.arg[1].keys()):\nstr += self.attribute(attr, self.arg[1][attr])\n- if (self.list[self.pos+1].end and self.formatter.compress):\n+ if (self.list[self.pos + 1].end and not self.formatter.noemptytag):\nstr += \"/>\"\nelse:\nstr += \">\"\n",
        "org_msg": "node_manager_fkie: changed xmlformatter",
        "sim_msg": "Type unicode becomes str in Python3",
        "sim_diff": "diff --git a/gaphor/misc/xmlwriter.py b/gaphor/misc/xmlwriter.py import sys\nimport xml.sax.handler\n+from builtins import str\nfrom xml.sax.saxutils import escape, quoteattr\n-from past.builtins import basestring\n-\n# See whether the xmlcharrefreplace error handler is\n# supported\ntry:\n@@ -15,6 +14,7 @@ try:\nexcept ImportError:\n_error_handling = \"strict\"\n+\nclass XMLWriter(xml.sax.handler.ContentHandler):\ndef __init__(self, out=None, encoding=None):\n@@ -38,7 +38,7 @@ class XMLWriter(xml.sax.handler.ContentHandler):\nOnly the tag should be marked this way. Other stuff, such as\nnamespaces and attributes can be written directly to the file.\n\"\"\"\n- if not isinstance(text, unicode):\n+ if not isinstance(text, str):\ntext = text.decode(self._encoding, _error_handling)\nif self._next_newline:\n",
        "chatgpt_cot": "Add options to the XML formatter for no empty tag and empty attribute. Add options for indenting data in formatter."
    },
    {
        "org_diff": "diff --git a/src/dashboard/src/pages/Operator/Agent/Agent.js b/src/dashboard/src/pages/Operator/Agent/Agent.js @@ -185,7 +185,7 @@ class Agent extends PureComponent {\nsize={'large'}\nrowKey={'id'}\nloading={loadingAgents}\n- pagination={paginationProps}\n+ pagination={agents.length > 0 ? paginationProps : false}\ndataSource={agents}\nrenderItem={item => (\n<List.Item\n",
        "org_msg": "[CE-643]Hide the pagination when agents is empty\nPagination is displayed only if the agent is not empty.",
        "sim_msg": "fix logging of webhook url",
        "sim_diff": "diff --git a/demo/runners/support/agent.py b/demo/runners/support/agent.py @@ -525,7 +525,7 @@ class DemoAgent:\nmethod = getattr(self, handler, None)\nif method:\nself.log(\n- f\"Agent called controller webhook: POST {self.webhook_url}\",\n+ f\"Agent called controller webhook: POST {self.webhook_url}/topic/{topic}/\",\n(f\"\\nFor wallet: {wallet_id}\" if wallet_id else \"\"),\n(f\"\\nPayload: {repr_json(payload)}\" if payload else repr_json({})),\n)\n",
        "chatgpt_cot": "Fix pagination display condition based on agents length in Agent component."
    },
    {
        "org_diff": "diff --git a/Makefile b/Makefile @@ -29,13 +29,13 @@ RESET := $(shell tput -Txterm sgr0)\nARCH := $(shell uname -m)\n# changelog specific version tags\n-PREV_VERSION?=0.7\n+PREV_VERSION?=0.8.0-beta\n# Building image usage\nDOCKER_NS ?= hyperledger\nBASENAME ?= $(DOCKER_NS)/cello\n-VERSION ?= 0.8.0-beta\n-IS_RELEASE=true\n+VERSION ?= 0.8.0-rc1\n+IS_RELEASE=false\nDOCKER_BASE_x86_64=ubuntu:xenial\nDOCKER_BASE_ppc64le=ppc64le/ubuntu:xenial\n",
        "org_msg": "Update Makefile\nUpdate Makefile to comply by release cycle\npolicy of cello.",
        "sim_msg": "UI now has a latest docker tag",
        "sim_diff": "diff --git a/src/ui/Makefile b/src/ui/Makefile @@ -72,8 +72,9 @@ package: clean ## builds distribution\n# Docker\ndocker-build: package ## build docker image\n- docker build -t $(DOCKER_NAME):$(VERSION) .\n- docker tag $(DOCKER_NAME):$(VERSION) $(DOCKER_NAME):$(SHORT_VERSION)\n+ docker build -t $(DOCKER_NAME):latest .\n+ docker tag $(DOCKER_NAME):latest $(DOCKER_NAME):$(VERSION)\n+ docker tag $(DOCKER_NAME):latest $(DOCKER_NAME):$(SHORT_VERSION)\ndocker-build-unstable: package ## build nightly docker image\ndocker build -t $(DOCKER_NAME):unstable .\n@@ -81,6 +82,7 @@ docker-build-unstable: package ## build nightly docker image\n# Publishing\npublish-docker: docker-build ## push the docker image\n+ docker push $(DOCKER_NAME):latest\ndocker push $(DOCKER_NAME):$(VERSION)\ndocker push $(DOCKER_NAME):$(SHORT_VERSION)\n",
        "chatgpt_cot": "Update version and release type in Makefile to 0.8.0-rc1 and false respectively, preparing for the release candidate build."
    },
    {
        "org_diff": "diff --git a/dockerhub/latest/operator-dashboard/Dockerfile b/dockerhub/latest/operator-dashboard/Dockerfile FROM node:8.11 as build_js\nMAINTAINER haitao yue \"hightall@me.com\"\nRUN cd /tmp && git clone https://github.com/hyperledger/cello.git\n-RUN cp -r /tmp/cello/src/themes/react/static /var/www\n+RUN cp -r /tmp/cello/src/static /var/www\nRUN cd /var/www/dashboard && npm install && npm run build\nFROM hyperledger/cello-baseimage:x86_64-latest\n",
        "org_msg": "Fix operator dashboard build error\nChange static dir in operator dashboard dockerfile.",
        "sim_msg": "updated Dockerfile in myems-web",
        "sim_diff": "diff --git a/myems-web/Dockerfile b/myems-web/Dockerfile FROM node:latest as build-stage\nWORKDIR /opt\nCOPY . .\n-RUN npm install --unsafe-perm=true --allow-root --legacy-peer-deps --registry https://registry.npm.taobao.org\n+\n+# use this with node v17.x.x or v18.x.x\n+RUN npm install --unsafe-perm=true --allow-root --legacy-peer-deps\n+\n+# use this if https://registry.npmjs.org is slow or unavialiable\n+# RUN npm install --unsafe-perm=true --allow-root --legacy-peer-deps --registry https://registry.npm.taobao.org\n+\n+# use this with node v16.x.x\n+# RUN npm install --unsafe-perm=true --allow-root --legacy-peer-deps\n+\nRUN npm run build\n",
        "chatgpt_cot": "Update file path in Dockerfile to fix build issue\nExplanation: The scope of code changes is to modify the file path in the Dockerfile, and according to the filename \"Dockerfile\" and the function of the file could be related to building the docker image. The purpose of the modification is to fix the build issue by updating the file path."
    },
    {
        "org_diff": "diff --git a/generate_id_constants_from_stableid.py b/generate_id_constants_from_stableid.py @@ -29,38 +29,51 @@ FILE_TRANSLATE = {\n}\n-def clike_enum_parse(data):\n+def make_key(key):\n+ if key[0].isdigit():\n+ key = \"_\" + key\n+ return key.upper().replace(\" \", \"_\")\n+\n+def parse_data(data):\n# for d in data: # Units, Abilities, Upgrades, Buffs, Effects\n- units = parse_simple('Units', data)\n- upgrades = parse_simple('Upgrades', data)\n- effects = parse_simple('Effects', data)\n- buffs = parse_simple('Buffs', data)\n+ units = parse_simple(\"Units\", data)\n+ upgrades = parse_simple(\"Upgrades\", data)\n+ effects = parse_simple(\"Effects\", data)\n+ buffs = parse_simple(\"Buffs\", data)\nabilities = {}\n- for v in data['Abilities']:\n- key = v['buttonname']\n+ for v in data[\"Abilities\"]:\n+ key = v[\"buttonname\"]\n+ remapid = v.get(\"remapid\")\n- if not key:\n+ if (not key) and (remapid is None):\n+ assert v[\"buttonname\"] == \"\"\ncontinue\n+ if not key:\n+ if v[\"friendlyname\"] != \"\":\n+ key = v[\"friendlyname\"]\n+ else:\n+ exit(f\"Not mapped: {v !r}\")\n+\nkey = key.upper().replace(\" \", \"_\")\n- if 'name' in v:\n- key = \"{}_{}\".format(v['name'].upper().replace(\" \", \"_\"), key)\n+ if \"name\" in v:\n+ key = \"{}_{}\".format(v[\"name\"].upper().replace(\" \", \"_\"), key)\n- if 'friendlyname' in v:\n- key = v['friendlyname'].upper().replace(\" \", \"_\")\n+ if \"friendlyname\" in v:\n+ key = v[\"friendlyname\"].upper().replace(\" \", \"_\")\nif key[0].isdigit():\nkey = \"_\" + key\n- if key in abilities and v['index'] == 0:\n+ if key in abilities and v[\"index\"] == 0:\nprint(key)\nraise ValueError\n- abilities[key] = v['id']\n+ abilities[key] = v[\"id\"]\n- abilities['SMART'] = 1\n+ abilities[\"SMART\"] = 1\nenums = {}\nenums[\"Units\"] = units\n@@ -75,16 +88,13 @@ def clike_enum_parse(data):\ndef parse_simple(d, data):\nunits = {}\nfor v in data[d]:\n- key = v['name']\n+ key = v[\"name\"]\nif not key:\ncontinue\n- if key[0].isdigit():\n- key = \"_\" + key\n+ units[make_key(key)] = v[\"id\"]\n- key = key.upper().replace(\" \", \"_\")\n- units[key] = v['id']\nreturn units\n@@ -126,7 +136,7 @@ def generate_python_code(enums):\nf.write(\"\\n\".join(code))\n-if __name__ == '__main__':\n- with open(DATA_JSON[PF], encoding='utf-8') as data_file:\n+if __name__ == \"__main__\":\n+ with open(DATA_JSON[PF], encoding=\"utf-8\") as data_file:\ndata = json.loads(data_file.read())\n- generate_python_code(clike_enum_parse(data))\n+ generate_python_code(parse_data(data))\n",
        "org_msg": "Clean up stable id generate script",
        "sim_msg": "Fix an important typo",
        "sim_diff": "diff --git a/source2/utils/keyvalues.py b/source2/utils/keyvalues.py @@ -353,7 +353,7 @@ class KeyValues:\nreturn KeyValues.read_data(open(filename, 'r', encoding='utf-8'), filename)\n@staticmethod\n- def read_data(stream: typing.TextIO, filename: str = '<input'):\n+ def read_data(stream: typing.TextIO, filename: str = '<input>'):\nreturn Parser(stream, filename).parse_file()\n@staticmethod\n",
        "chatgpt_cot": "Refactor code to improve readability and maintainability. Add new method \"make_key\" to generate keys, update method names, and improve error handling in data parsing functions."
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/topic_list_model.py b/node_manager_fkie/src/node_manager_fkie/topic_list_model.py @@ -284,6 +284,8 @@ class TopicGroupItem(QStandardItem):\ndname = '{%s}' % name\nelif name != rospy.names.SEP:\ndname = '%s/' % name\n+ else:\n+ dname = 'topics@master'\nQStandardItem.__init__(self, dname)\nself.parent_item = parent\nself._name = name\n@@ -415,6 +417,7 @@ class TopicGroupItem(QStandardItem):\nlns, rns = lnamespace(group_name)\nif lns == rospy.names.SEP:\nlns, rns = lnamespace(rns)\n+ lns = '/%s' % lns\nif lns == rospy.names.SEP:\nreturn self\nfor i in range(self.rowCount()):\n",
        "org_msg": "node_manager_fkie: changed root of topic view",
        "sim_msg": "add deserialize and serialize to ContentManager",
        "sim_diff": "diff --git a/source1/content_manager.py b/source1/content_manager.py @@ -54,6 +54,25 @@ class ContentManager(metaclass=SingletonMeta):\nself.sub_managers[root_path.stem] = sub_manager\nprint(f'Registered sub manager for {source_game_path.stem}')\n+ def deserialize(self, data: Dict[str, str]):\n+ for name, path in data.items():\n+ if path.endswith('.vpk'):\n+ sub_manager = VPKSubManager(Path(path))\n+ self.sub_managers[name] = sub_manager\n+ elif path.endswith('.txt'):\n+ sub_manager = Gameinfo(Path(path))\n+ self.sub_managers[name] = sub_manager\n+ elif path.endswith('.bps'):\n+ from .bsp.bsp_file import BSPFile, LumpTypes\n+ bsp = BSPFile(path)\n+ bsp.parse()\n+ pak_lump = bsp.get_lump(LumpTypes.LUMP_PAK)\n+ if pak_lump:\n+ self.sub_managers[name] = pak_lump\n+ else:\n+ sub_manager = NonSourceSubManager(Path(path))\n+ self.sub_managers[name] = sub_manager\n+\n@staticmethod\ndef is_source_mod(path: Path, second=False):\nif path.name == 'gameinfo.txt':\n@@ -88,3 +107,6 @@ class ContentManager(metaclass=SingletonMeta):\ndef find_material(self, filepath):\nreturn self.find_file(filepath, 'materials', extension='.vmt')\n+\n+ def serialize(self):\n+ return {name: str(sub_manager.filepath) for name, sub_manager in self.sub_managers.items()}\n",
        "chatgpt_cot": "Fix default topic name generation and namespace handling in TopicGroupItem class. Add condition to handle default topic name and adjust namespace."
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/editor/xml_highlighter.py b/node_manager_fkie/src/node_manager_fkie/editor/xml_highlighter.py @@ -179,13 +179,14 @@ class XmlHighlighter(QSyntaxHighlighter):\nself.rules.append((self._create_regexp(\"<!DOCTYPE.*>\"), self._create_format(Qt.lightGray)))\nself.rules.append((self._create_regexp(\"<\\\\?xml.*\\\\?>\"), self._create_format(Qt.lightGray)))\n# create patterns for yaml parameter inside\n- self.rules.append((self._create_regexp(\"^\\s*[_.\\w]*\\s*:\"), self._create_format(Qt.darkBlue)))\n+ self.rules.append((self._create_regexp(\"[_.\\w]*\\s*:\"), self._create_format(Qt.darkBlue)))\n# create patterns for yaml oneline strings inside\nself.rules.append((self._create_regexp(\"'.*'\"), self._create_format(Qt.blue)))\n# create pattern for list signes\nself.rules.append((self._create_regexp(\"^\\s*-\"), self._create_format(Qt.darkRed, 'bold')))\n# create pattern for digits\nself.rules.append((self._create_regexp(\"\\\\d+\"), self._create_format(QColor(127, 64, 127))))\n+ self.yaml_comment_rule = (self._create_regexp(\"#[.]*\"), self._create_format(Qt.darkGray))\n# create patterns for strings\nself.string_pattern = QRegExp(\"\\\"\")\nself.string_format = self._create_format(Qt.blue)\n@@ -226,9 +227,13 @@ class XmlHighlighter(QSyntaxHighlighter):\nfrmt.setFontWeight(QFont.Bold)\nself.setFormat(index, length, frmt)\nindex = pattern.indexIn(text, index + length)\n+ # search for YAML comments\n+ index = self.yaml_comment_rule[0].indexIn(text)\n+ if index >= 0:\n+ self.setFormat(index, len(text) - index, self.yaml_comment_rule[1])\nself._tag_hl_range = []\nself.setCurrentBlockState(0)\n- # detection for comments\n+ # detection for XML comments\nself._comments_idx = []\nidx_start_cmt = 0\ncomment_length = 0\n",
        "org_msg": "node_manager_fkie: fixed highlightnig YAML data in XML",
        "sim_msg": "Some markdown formatting\n# H1, ## H2, ### H3, **text** bold, *text* italic",
        "sim_diff": "diff --git a/qualcoder/journals.py b/qualcoder/journals.py @@ -26,6 +26,8 @@ https://github.com/ccbogel/QualCoder\nhttps://qualcoder.wordpress.com/\n\"\"\"\n+'''from PyQt6.QtGui import QSyntaxHighlighter, QTextCharFormat, QBrush, QFont, QColor\n+from PyQt6.QtCore import *'''\nfrom PyQt6 import QtCore, QtWidgets, QtGui\nimport datetime\nimport os\n@@ -160,8 +162,9 @@ class DialogJournals(QtWidgets.QDialog):\nself.ui.checkBox_search_all_journals.stateChanged.connect(self.search_for_text)\nself.ui.textEdit.textChanged.connect(self.text_changed)\nself.ui.textEdit.installEventFilter(self)\n- self.ui.tableWidget.installEventFilter(self)\n+ highlighter = Highlighter(self.ui.textEdit, self.app)\n+ self.ui.tableWidget.installEventFilter(self)\n@staticmethod\ndef help():\n@@ -511,3 +514,55 @@ class DialogJournals(QtWidgets.QDialog):\ncursor.setPosition(cursor.position() + next_result[2], QtGui.QTextCursor.MoveMode.KeepAnchor)\nself.ui.textEdit.setTextCursor(cursor)\nself.ui.label_search_totals.setText(str(self.search_index + 1) + \" / \" + str(len(self.search_indices)))\n+\n+\n+class Highlighter(QtGui.QSyntaxHighlighter):\n+ \"\"\" Journal text mardown highlighter. \"\"\"\n+\n+ highlighting_rules = []\n+ app = None\n+\n+ def __init__(self, parent, app):\n+ QtGui.QSyntaxHighlighter.__init__(self, parent)\n+ self.parent = parent\n+ self.app = app\n+ self.highlighting_rules = []\n+ self.rules()\n+\n+ def rules(self):\n+ \"\"\" Sets formatting rules for markdown text.\n+ H1 H2 H3 and bold\n+ \"\"\"\n+\n+ # Heading 1\n+ h1_format = QtGui.QTextCharFormat()\n+ h1_format.setFontPointSize(self.app.settings['docfontsize'] + 6)\n+ h1_format.setFontWeight(QtGui.QFont.Weight.Bold)\n+ self.highlighting_rules += [(QtCore.QRegularExpression(\"# [^\\n]*\"), h1_format)]\n+ # Heading 2\n+ h2_format = QtGui.QTextCharFormat()\n+ h2_format.setFontPointSize(self.app.settings['docfontsize'] + 4)\n+ h2_format.setFontWeight(QtGui.QFont.Weight.Bold)\n+ self.highlighting_rules += [(QtCore.QRegularExpression(\"## [^\\n]*\"), h2_format)]\n+ # Heading 3\n+ h3_format = QtGui.QTextCharFormat()\n+ h3_format.setFontPointSize(self.app.settings['docfontsize'] + 2)\n+ h3_format.setFontWeight(QtGui.QFont.Weight.Bold)\n+ self.highlighting_rules += [(QtCore.QRegularExpression(\"### [^\\n]*\"), h3_format)]\n+ # Italic\n+ italic_format = QtGui.QTextCharFormat()\n+ italic_format.setFontItalic(True)\n+ self.highlighting_rules += [(QtCore.QRegularExpression(\"\\*.*\\*\"), italic_format)]\n+ # Bold\n+ bold_format = QtGui.QTextCharFormat()\n+ bold_format.setFontWeight(QtGui.QFont.Weight.Bold)\n+ self.highlighting_rules += [(QtCore.QRegularExpression(\"\\*\\*.*\\*\\*\"), bold_format)]\n+\n+ def highlightBlock(self, text):\n+ for pattern, format_ in self.highlighting_rules:\n+ reg_exp = QtCore.QRegularExpression(pattern)\n+ i = reg_exp.globalMatch(text)\n+ while i.hasNext():\n+ match = i.next()\n+ self.setFormat(match.capturedStart(), match.capturedLength(), format_)\n+\n",
        "chatgpt_cot": "Add YAML comment highlighting, fix YAML parameter pattern, and improve XML comment detection in XmlHighlighter."
    },
    {
        "org_diff": "diff --git a/rasa_core_sdk/forms.py b/rasa_core_sdk/forms.py @@ -111,6 +111,12 @@ class FormAction(Action):\nreturn [Form(None), SlotSet(REQUESTED_SLOT, None)]\n+ def next_slot_to_request(self, tracker):\n+ for slot in self.required_slots():\n+ if self._should_request_slot(tracker, slot):\n+ return slot\n+ return None\n+\ndef run(self, dispatcher, tracker, domain):\n# type: (CollectingDispatcher, Tracker, Dict[Text, Any]) -> List[Dict]\n\"\"\"Execute the side effects of this form:\n@@ -132,15 +138,13 @@ class FormAction(Action):\ntemp_tracker.slots[e[\"name\"]] = e[\"value\"]\n# request next slot\n- for slot in self.required_slots():\n- if self._should_request_slot(temp_tracker, slot):\n-\n+ slot = self.next_slot_to_request(temp_tracker)\n+ if slot is not None:\ndispatcher.utter_template(\"utter_ask_{}\".format(slot), tracker)\n-\nevents.append(SlotSet(REQUESTED_SLOT, slot))\n-\nreturn events\n+\n# there is nothing more to request, so we can submit\nevents.extend(self.submit(dispatcher, temp_tracker, domain))\n# deactivate the form after submission\n",
        "org_msg": "separate logic for which slot to request next",
        "sim_msg": "remove id location as it passed in args",
        "sim_diff": "diff --git a/packages/syft/src/syft/core/node/common/action/run_class_method_smpc_action.py b/packages/syft/src/syft/core/node/common/action/run_class_method_smpc_action.py @@ -157,7 +157,7 @@ class RunClassMethodSMPCAction(ImmediateActionWithoutReply):\n}\n# Get the list of actions to be run\n- actions = actions_generator(self._self.id_at_location, *args_id, **kwargs) # type: ignore\n+ actions = actions_generator(*args_id, **kwargs) # type: ignore\nactions = SMPCActionMessage.filter_actions_after_rank(\nresolved_self.data.rank, actions\n)\n",
        "chatgpt_cot": "Add method next_slot_to_request to FormAction for better slot handling and request logic, improving form execution and submission in Rasa Core SDK."
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/main_window.py b/node_manager_fkie/src/node_manager_fkie/main_window.py @@ -930,6 +930,7 @@ class MainWindow(QMainWindow):\nparams = {'Host': ('string', 'localhost'),\n'Show master discovery log': ('bool', True),\n'Show master sync log': ('bool', False),\n+ 'Show daemon log': ('bool', False),\n'Username': ('string', user_list),\n'Only screen log': ('bool', True),\n# 'Optional Parameter': ('list', params_optional)\n@@ -945,6 +946,7 @@ class MainWindow(QMainWindow):\nhostnames = params['Host'] if isinstance(params['Host'], list) else [params['Host']]\nlog_master_discovery = params['Show master discovery log']\nlog_master_sync = params['Show master sync log']\n+ log_nm_daemon = params['Show daemon log']\nusername = params['Username']\nscreen_only = params['Only screen log']\nfor hostname in hostnames:\n@@ -962,6 +964,11 @@ class MainWindow(QMainWindow):\n'%s: show log of master sync' % hostname,\nnm.starter().openLog,\n('/master_sync', hostname, usr, screen_only))\n+ if log_nm_daemon:\n+ self._progress_queue.add2queue(utf8(uuid.uuid4()),\n+ '%s: show log of nm daemon' % hostname,\n+ nm.starter().openLog,\n+ ('/node_manager_daemon', hostname, usr, screen_only))\nexcept (Exception, nm.StartException) as err:\nimport traceback\nprint traceback.format_exc(1)\n@@ -1140,12 +1147,14 @@ class MainWindow(QMainWindow):\nif self._sync_dialog.exec_():\ntry:\nhost = get_hostname(master.masteruri)\n- if self._sync_dialog.interface_filename is not None:\n+ if self._sync_dialog.interface_filename is not None and not nm.is_local(host):\n+ nmd_uri = nmdurl.nmduri(master.masteruri)\n+ sync_file = nmdurl.join(nmdurl.nmduri(), self._sync_dialog.interface_filename)\n# copy the interface file to remote machine\nself._progress_queue_sync.add2queue(utf8(uuid.uuid4()),\n- 'Transfer sync interface %s' % host,\n- nm.starter().transfer_files,\n- (\"%s\" % host, self._sync_dialog.interface_filename, False, master.current_user))\n+ 'Transfer sync interface to %s' % nmd_uri,\n+ nm.starter().transfer_file_nmd,\n+ (\"%s\" % nmd_uri, sync_file, False, master.current_user))\nself._progress_queue_sync.add2queue(utf8(uuid.uuid4()),\n'Start sync on %s' % host,\nnm.starter().runNodeWithoutConfig,\n",
        "org_msg": "node_manager_fkie: added daemon to log request dialog",
        "sim_msg": "[copy] make --verbose show a progress bar\n* [copy] make --verbose show a progress bar\nCHANGELOG: `hailtop.aiotools.copy` will always show a progress bar when `--verbose` is passed.\n* fix",
        "sim_diff": "diff --git a/hail/python/hailtop/aiotools/copy.py b/hail/python/hailtop/aiotools/copy.py @@ -7,7 +7,7 @@ import sys\nfrom concurrent.futures import ThreadPoolExecutor\n-from ..utils import tqdm\n+from ..utils import tqdm, TqdmDisableOption\nfrom . import Transfer, Copier\nfrom .router_fs import RouterAsyncFS\nfrom .utils import make_tqdm_listener\n@@ -30,6 +30,7 @@ async def copy(*,\nazure_kwargs: Optional[dict] = None,\ns3_kwargs: Optional[dict] = None,\ntransfers: List[Transfer],\n+ verbose: bool = False,\n) -> None:\nwith ThreadPoolExecutor() as thread_pool:\nif max_simultaneous_transfers is None:\n@@ -50,9 +51,10 @@ async def copy(*,\nazure_kwargs=azure_kwargs,\ns3_kwargs=s3_kwargs) as fs:\nsema = asyncio.Semaphore(max_simultaneous_transfers)\n+ should_disable_tqdm = not verbose or TqdmDisableOption.default\nasync with sema:\n- with tqdm(desc='files', leave=False, position=0, unit='file') as file_pbar, \\\n- tqdm(desc='bytes', leave=False, position=1, unit='byte', unit_scale=True, smoothing=0.1) as byte_pbar:\n+ with tqdm(desc='files', leave=False, position=0, unit='file', disable=should_disable_tqdm) as file_pbar, \\\n+ tqdm(desc='bytes', leave=False, position=1, unit='byte', unit_scale=True, smoothing=0.1, disable=should_disable_tqdm) as byte_pbar:\ncopy_report = await Copier.copy(\nfs,\nsema,\n@@ -75,7 +77,8 @@ async def copy_from_dict(*,\ngcs_kwargs: Optional[dict] = None,\nazure_kwargs: Optional[dict] = None,\ns3_kwargs: Optional[dict] = None,\n- files: List[Dict[str, str]]\n+ files: List[Dict[str, str]],\n+ verbose: bool = False,\n) -> None:\ntransfers = [make_transfer(json_object) for json_object in files]\nawait copy(\n@@ -84,7 +87,8 @@ async def copy_from_dict(*,\ngcs_kwargs=gcs_kwargs,\nazure_kwargs=azure_kwargs,\ns3_kwargs=s3_kwargs,\n- transfers=transfers\n+ transfers=transfers,\n+ verbose=verbose,\n)\n@@ -114,7 +118,8 @@ async def main() -> None:\nawait copy_from_dict(\nmax_simultaneous_transfers=args.max_simultaneous_transfers,\ngcs_kwargs=gcs_kwargs,\n- files=files\n+ files=files,\n+ verbose=args.verbose\n)\n",
        "chatgpt_cot": "\"Add daemon log option and fix sync interface transfer to remote machine\""
    },
    {
        "org_diff": "diff --git a/src/themes/basic/templates/layout.html b/src/themes/basic/templates/layout.html <input id=\"host_capacity\" type=\"number\" name=\"capacity\"\nclass=\"form-control\" min=\"0\" max=\"1000\" value=1 required>\n</div>\n+ {% if host_types|length > 0 %}\n+ <div class=\"form-group form-inline\">\n+ <label for=\"host_type\" style=\"width: 20%\">Host Type</label>\n+ <select id=\"host_type\" class=\"c-select host_type\"\n+ name=\"host_type\" required>\n+ <option selected\n+ value=\"{{host_types[0]}}\">{{host_types[0]|upper }}</option>\n+ {% for c in host_types[1:] %}\n+ <option value=\"{{c}}\">{{c|upper}}</option>\n+ {% endfor %}\n+ </select>\n+ </div>\n+ {% endif %}\n{% if log_levels|length > 0 %}\n<div class=\"form-group form-inline\">\n<label for=\"log_level\" style=\"width: 20%\">Logging Level</label>\n",
        "org_msg": "Fix fail to create swarm worker node\n1. this patchset will allow user to chose host_type\nvia our jinja2 dashboard",
        "sim_msg": "Added Settings panel shell",
        "sim_diff": "diff --git a/templates/themes/Defaultv3/admin.html b/templates/themes/Defaultv3/admin.html </div>\n</div>\n</div>\n+ </div></div>\n+ <div class=\"tab-pane fade show w-100\" id=\"settings\" role=\"tabpanel\" aria-labelledby=\"settings-tab\">\n+ <div class=\"row mt-4 mx-4\">\n+ <div class=\"col-12\">\n+ <div class=\"info-panel-box system-settings-box\">\n+ <div class=\"info-panel-box-header boxShadow textShadow\">\n+ <b>Settings</b>\n+ </div>\n+ <div class=\"info-panel-box-body boxShadow\">\n+ <div class=\"form-group\">\n+ <label for=\"settings-servername-input\">Server Name</label>\n+ <input type=\"text\" id=\"settings-servername-input\" class=\"form-control\">\n+ </div>\n+ <div class=\"form-group\">\n+ <label for=\"settings-protocol-input\">Protocol</label>\n+ <select id=\"settings-protocol-input\" class=\"form-control\">\n+ <option value=\"https\">https://</option>\n+ <option value=\"http\">http://</option>\n+ </select>\n+ <label for=\"settings-hostname-input\">Hostname / IP Address</label>\n+ <input type=\"text\" id=\"settings-hostname-input\" class=\"form-control\">\n+ </div>\n+ </div>\n+ </div>\n+ </div>\n</div>\n- <div class=\"tab-pane fade\" id=\"profile\" role=\"tabpanel\" aria-labelledby=\"profile-tab\">...</div>\n<div class=\"tab-pane fade\" id=\"contact\" role=\"tabpanel\" aria-labelledby=\"contact-tab\">...</div>\n</div>\n{% endblock %}\n",
        "chatgpt_cot": "Add conditional rendering for host type selection based on the length of the host_types array to the layout.html file."
    },
    {
        "org_diff": "diff --git a/sc2/game_state.py b/sc2/game_state.py @@ -124,10 +124,6 @@ class GameState:\n# https://github.com/Blizzard/s2client-proto/blob/33f0ecf615aa06ca845ffe4739ef3133f37265a9/s2clientprotocol/score.proto#L31\nself.score: ScoreDetails = ScoreDetails(self.observation.score)\nself.abilities = self.observation.abilities # abilities of selected units\n-\n- neutral = Alliance.Neutral.value\n- friend = Alliance.Self.value\n- enemy = Alliance.Enemy.value\n# Fix for enemy units detected by my sensor tower, as blips have less unit information than normal visible units\nvisibleUnits, blipUnits, minerals, geysers, destructables, enemy, own, watchtowers = ([] for _ in range(8))\n@@ -137,11 +133,13 @@ class GameState:\nelse:\nvisibleUnits.append(unit)\nalliance = unit.alliance\n- if alliance == neutral:\n+ # Alliance.Neutral.value = 3\n+ if alliance == 3:\nunit_type = unit.unit_type\n- # all destructable rocks except the one below the main base ramps\n+ # XELNAGATOWER = 149\nif unit_type == 149:\nwatchtowers.append(unit)\n+ # all destructable rocks except the one below the main base ramps\nelif unit.radius > 1.5:\ndestructables.append(unit)\n# mineral field enums\n@@ -150,9 +148,11 @@ class GameState:\n# geyser enums\nelif unit_type in geyser_ids:\ngeysers.append(unit)\n- elif alliance == friend:\n+ # Alliance.Self.value = 1\n+ elif alliance == 1:\nown.append(unit)\n- elif alliance == enemy:\n+ # Alliance.Enemy.value = 4\n+ elif alliance == 4:\nenemy.append(unit)\nself.own_units: Units = Units.from_proto(own)\n",
        "org_msg": "Fix game state alliance bug",
        "sim_msg": "Only refresh shares in AST public mul when zeros destroy shares",
        "sim_diff": "diff --git a/syft/frameworks/torch/tensors/interpreters/additive_shared.py b/syft/frameworks/torch/tensors/interpreters/additive_shared.py @@ -395,6 +395,9 @@ class AdditiveSharingTensor(AbstractTensor):\n\"\"\"Multiplies an AdditiveSharingTensor with a non-private value\n(int, torch tensor, MultiPointerTensor, etc.)\n+ When other is a constant equal to zero, the shares vanish so we need to add fresh\n+ shares of zero.\n+\nArgs:\nshares (dict): a dictionary <location_id -> PointerTensor) of shares corresponding to\nself. Equivalent to calling self.child.\n@@ -407,22 +410,29 @@ class AdditiveSharingTensor(AbstractTensor):\n\"\"\"\nassert equation == \"mul\" or equation == \"matmul\"\ncmd = getattr(torch, equation)\n-\nif isinstance(other, dict):\nreturn {\nworker: (cmd(share, other[worker]) % self.field) for worker, share in shares.items()\n}\nelse:\n+ other_is_zero = False\nif isinstance(other, torch.LongTensor) or isinstance(other, torch.IntTensor):\nother = other.wrap()\n+ if (other == 0).any():\n+ other_is_zero = True\n+ elif other == 0:\n+ other_is_zero = True\n- # Refresh shares\n- zero_shares = self.zero().child\n-\n+ if other_is_zero:\n+ zero = self.zero().child\nreturn {\n- worker: ((cmd(share, other) + zero_shares[worker]) % self.field)\n+ worker: ((cmd(share, other) + zero[worker]) % self.field)\nfor worker, share in shares.items()\n}\n+ else:\n+ return {\n+ worker: (cmd(share, other) % self.field) for worker, share in shares.items()\n+ }\ndef mul(self, other):\n\"\"\"Multiplies two tensors together\n",
        "chatgpt_cot": "\"Refactor GameState class to use Alliance enum values for comparison and remove redundant neutral, friend, and enemy assignments.\""
    },
    {
        "org_diff": "diff --git a/fkie_multimaster_msgs/cmake/grpc_protoc.cmake b/fkie_multimaster_msgs/cmake/grpc_protoc.cmake @@ -25,11 +25,13 @@ macro(generate_grpc)\nadd_custom_command(\nOUTPUT ${GRPC_GENERATED_SRC_DIR}/${PROTO_FILE}_pb2.py\nCOMMAND \"${PYTHON_EXECUTABLE}\" -m grpc_tools.protoc -I${MM_ROOT} --python_out=${DST_ROOT}/. ${ABS_PROTO_FILE}\n+ COMMAND ${CMAKE_COMMAND} -E echo \"from .${PROTO_FILE}_pb2 import *\" >> \"${GRPC_GENERATED_SRC_DIR}/__init__.py\"\nDEPENDS ${GRPC_GENERATED_SRC_DIR} ${ABS_PROTO_FILE}\n)\nadd_custom_command(\nOUTPUT ${GRPC_GENERATED_SRC_DIR}/${PROTO_FILE}_pb2_grpc.py\nCOMMAND \"${PYTHON_EXECUTABLE}\" -m grpc_tools.protoc -I${MM_ROOT} --grpc_python_out=${DST_ROOT}/. ${ABS_PROTO_FILE}\n+ COMMAND ${CMAKE_COMMAND} -E echo \"from .${PROTO_FILE}_pb2_grpc import *\" >> \"${GRPC_GENERATED_SRC_DIR}/__init__.py\"\nDEPENDS ${GRPC_GENERATED_SRC_DIR} ${ABS_PROTO_FILE}\n)\nendforeach()\n",
        "org_msg": "added imports to generated grpc init",
        "sim_msg": "attempt to make it work on linux",
        "sim_diff": "diff --git a/GearBot/commands/Test.py b/GearBot/commands/Test.py @@ -46,7 +46,7 @@ async def runRealTest(client:discord.Client, channel:discord.Channel):\nos.makedirs(gearbox)\nelse:\nshutil.rmtree(r\"gearbox/BuildCraft\")\n- await runCommand([\"git\", \"clone\", \"--depth=1\",\"https://github.com/BuildCraft/BuildCraft\"], shell=True)\n+ await runCommand([\"git clone --depth=1 https://github.com/BuildCraft/BuildCraft\"], shell=True)\nprops = {}\nembed = discord.Embed(title=\"Extracted information\")\nwith open(gearbox + r\"/BuildCraft/build.properties\", \"r\") as file:\n@@ -59,13 +59,13 @@ async def runRealTest(client:discord.Client, channel:discord.Channel):\nembed.add_field(name=kv[0], value=kv[1])\nawait client.send_message(channel, \"Clone complete\", embed=embed)\n- await runCommand([\"git\", \"submodule\", \"init\"], folder=\"BuildCraft\", shell=True)\n- await runCommand([\"git\", \"submodule\", \"update\"], folder=\"BuildCraft\", shell=True)\n+ await runCommand([\"git submodule init\"], folder=\"BuildCraft\", shell=True)\n+ await runCommand([\"git submodule update\"], folder=\"BuildCraft\", shell=True)\nawait client.send_message(channel, \"Submodules ready\")\ncommands = []\ncompileP = Popen([rf\"{os.getcwd()}/gearbox/BuildCraft/gradlew.bat\", \"build\", \"--no-daemon\"], cwd=rf\"{os.getcwd()}/gearbox/BuildCraft\")\n- await runCommand([\"wget\", f\"http://files.minecraftforge.net/maven/net/minecraftforge/forge/{props['mc_version']}-{props['forge_version']}/forge-{props['mc_version']}-{props['forge_version']}-installer.jar\"], shell=True)\n+ await runCommand([f\"wget http://files.minecraftforge.net/maven/net/minecraftforge/forge/{props['mc_version']}-{props['forge_version']}/forge-{props['mc_version']}-{props['forge_version']}-installer.jar\"], shell=True)\nwhile compileP.poll() is None:\nawait asyncio.sleep(2)\nawait client.send_file(channel, rf\"{gearbox}/BuildCraft/build/libs/{props['mod_version']}/buildcraft-{props['mod_version']}.jar\", content=\"Done\")\n",
        "chatgpt_cot": "\"Add import statements to __init__.py for generated grpc files to enable usage in other modules.\""
    },
    {
        "org_diff": "diff --git a/sc2/unit.py b/sc2/unit.py @@ -353,19 +353,23 @@ class Unit:\nreturn 0\nreturn self._proto.energy / self._proto.energy_max\n- @property\n+ @property_immutable_cache\ndef is_snapshot(self) -> bool:\n\"\"\" Checks if the unit is only available as a snapshot for the bot.\nEnemy buildings that have been scouted and are in the fog of war or\nattacking enemy units on higher, not visible ground appear this way. \"\"\"\n- return self._proto.display_type == IS_SNAPSHOT\n+ # TODO: remove usage of bot.state.visibility when display_type is fixed by blizzard: https://github.com/Blizzard/s2client-proto/issues/167\n+ if self._proto.display_type == IS_SNAPSHOT:\n+ return True\n+ position = self.position.rounded\n+ return self._bot_object.state.visibility.data_numpy[position[1], position[0]] != 2\n- @property\n+ @property_immutable_cache\ndef is_visible(self) -> bool:\n\"\"\" Checks if the unit is visible for the bot.\nNOTE: This means the bot has vision of the position of the unit!\nIt does not give any information about the cloak status of the unit.\"\"\"\n- return self._proto.display_type == IS_VISIBLE\n+ return self._proto.display_type == IS_VISIBLE and not self.is_snapshot\n@property\ndef alliance(self) -> Alliance:\n@@ -830,6 +834,8 @@ class Unit:\n# TODO What does this do?\nreturn self._proto.engaged_target_tag\n+ # TODO: Add rally targets https://github.com/Blizzard/s2client-proto/commit/80484692fa9e0ea6e7be04e728e4f5995c64daa3#diff-3b331650a4f7c9271a579b31cf771ed5R88-R92\n+\n# Unit functions\ndef has_buff(self, buff: BuffId) -> bool:\n",
        "org_msg": "Add temporary fix for is_snapshot and is_visibile",
        "sim_msg": "[AddImage] add option to toggle bot owner global images",
        "sim_diff": "diff --git a/addimage/addimage.py b/addimage/addimage.py @@ -30,7 +30,7 @@ class AddImage(commands.Cog):\ntemp_folder = cog_data_path(self) / \"global\"\ntemp_folder.mkdir(exist_ok=True, parents=True)\ndefault_global = {\"images\": []}\n- default_guild = {\"images\": []}\n+ default_guild = {\"images\": [], \"ignore_global\": False}\nself.config = Config.get_conf(self, 16446735546)\nself.config.register_global(**default_global)\nself.config.register_guild(**default_guild)\n@@ -166,8 +166,8 @@ class AddImage(commands.Cog):\nreturn\nif not await self.check_ignored_channel(message):\nreturn\n-\n- if alias in [x[\"command_name\"] for x in await self.config.images()]:\n+ ignore_global = await self.config.guild(guild).ignore_global()\n+ if alias in [x[\"command_name\"] for x in await self.config.images()] and not ignore_global:\nif channel.permissions_for(channel.guild.me).attach_files:\nawait channel.trigger_typing()\nimage = await self.get_image(alias)\n@@ -182,7 +182,7 @@ class AddImage(commands.Cog):\nexcept discord.errors.Forbidden:\npass\n- elif alias in [x[\"command_name\"] for x in await self.config.guild(guild).images()]:\n+ if alias in [x[\"command_name\"] for x in await self.config.guild(guild).images()]:\nif channel.permissions_for(channel.guild.me).attach_files:\nawait channel.trigger_typing()\nimage = await self.get_image(alias, guild)\n@@ -215,6 +215,19 @@ class AddImage(commands.Cog):\n\"\"\"\npass\n+ @addimage.command(name=\"ignoreglobal\")\n+ @checks.mod_or_permissions(manage_channels=True)\n+ async def ignore_global_commands(self, ctx):\n+ \"\"\"\n+ Toggle usage of bot owner set global images on this server\n+ \"\"\"\n+ ignore_global = await self.config.guild(ctx.guild).ignore_global()\n+ await self.config.guild(ctx.guild).ignore_global.set(not ignore_global)\n+ if ignore_global:\n+ await ctx.send(_(\"Ignoring bot owner global images.\"))\n+ else:\n+ await ctx.send(_(\"Bot owner global images enabled.\"))\n+\n@addimage.command(name=\"list\")\n@commands.bot_has_permissions(embed_links=True)\nasync def listimages(self, ctx, image_loc=\"guild\", server_id: discord.Guild = None):\n",
        "chatgpt_cot": "Add new properties with immutable cache and handle snapshot and visibility status in Unit class. Fix display_type comparison and add TODOs for future improvements."
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/__init__.py b/node_manager_fkie/src/node_manager_fkie/__init__.py @@ -58,8 +58,8 @@ PKG_NAME = 'node_manager_fkie'\n__author__ = \"Alexander Tiderko (Alexander.Tiderko@fkie.fraunhofer.de)\"\n__copyright__ = \"Copyright (c) 2012 Alexander Tiderko, Fraunhofer FKIE/US\"\n__license__ = \"BSD\"\n-__version__ = \"0.7.5\" # git describe --tags --dirty --always\n-__date__ = \"2017-07-17\" # git log -1 --date=iso\n+__version__ = \"0.7.6\" # git describe --tags --dirty --always\n+__date__ = \"2017-10-04\" # git log -1 --date=iso\n# PYTHONVER = (2, 7, 1)\n# if sys.version_info < PYTHONVER:\n",
        "org_msg": "node_manager_fkie: updated version",
        "sim_msg": "MAINT: fix release version in docs conf.py",
        "sim_diff": "diff --git a/docs/conf.py b/docs/conf.py @@ -22,7 +22,7 @@ copyright = '2020, Projeto Jupiter'\nauthor = 'Giovani Hdalgo Ceotto'\n# The full version, including alpha/beta/rc tags\n-release = '0.9.7'\n+release = '0.9.8'\n# -- General configuration ---------------------------------------------------\n",
        "chatgpt_cot": "Update version and date in init file to reflect latest changes."
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/screen_handler.py b/node_manager_fkie/src/node_manager_fkie/screen_handler.py @@ -181,4 +181,4 @@ class ScreenHandler(object):\nelse:\nnm.ssh().ssh_exec(host, [screen.SCREEN, '-wipe'], close_stdin=True, close_stdout=True, close_stderr=True)\nexcept nm.AuthenticationRequest as e:\n- raise nm.InteractionNeededError(e, cls.killScreens, (node, host, auto_ok_request))\n+ raise nm.InteractionNeededError(e, cls.kill_screens, (node, host, auto_ok_request))\n",
        "org_msg": "node_manager_fkie: fix kill screen",
        "sim_msg": "fix validating data",
        "sim_diff": "diff --git a/home.admin/config.scripts/internet.sshtunnel.py b/home.admin/config.scripts/internet.sshtunnel.py @@ -45,17 +45,18 @@ if sys.argv[1] == \"on\":\n# sys.exit(1)\n# check server address\n- ssh_server = sys.argv[2]\n- if ssh_server.count(\"@\") != 1:\n+ if len(sys.argv) < 3:\n+ print(\"[USER]@[SERVER] missing - use 'internet.sshtunnel.py -h' for help\")\n+ sys.exit(1)\n+ if sys.argv[2].count(\"@\") != 1:\nprint(\"[USER]@[SERVER] wrong - use 'internet.sshtunnel.py -h' for help\")\nsys.exit(1)\n+ ssh_server = sys.argv[2]\n- # check minimal forwardings\n+ # genenate additional parameter for autossh (forwarding ports)\nif len(sys.argv) < 4:\nprint(\"[INTERNAL-PORT]:[EXTERNAL-PORT] missing - run 'internet.sshtunnel.py off' first\")\nsys.exit(1)\n-\n- # genenate additional parameter for autossh (forwarding ports)\nadditional_parameters=\"\"\ni = 3\nwhile i < len(sys.argv):\n",
        "chatgpt_cot": "Fix method name to follow Python naming convention in ScreenHandler class. Fixes nm.InteractionNeededError and improves code readability."
    },
    {
        "org_diff": "diff --git a/docs/setup/server.md b/docs/setup/server.md @@ -78,7 +78,7 @@ $ git clone https://github.com/hyperledger/cello.git\n```\n* If there is any error or you still cannot register, change the permission of the folder\n```bash\n- $ sudo chown !(whoami): /opt/cello\n+ $ sudo chown -R !(whoami): /opt/cello\n```\n<a rel=\"license\" href=\"http://creativecommons.org/licenses/by/4.0/\"><img alt=\"Creative Commons License\" style=\"border-width:0\" src=\"https://i.creativecommons.org/l/by/4.0/88x31.png\" /></a><br />This work is licensed under a <a rel=\"license\" href=\"http://creativecommons.org/licenses/by/4.0/\">Creative Commons Attribution 4.0 International License</a>.\n",
        "org_msg": "Add recursive flag\nAdd recursive flag for the 'chown' command.",
        "sim_msg": "update gitignore to remove some files that got put on my machine",
        "sim_diff": "diff --git a/.gitignore b/.gitignore *.pyc\n.*.swp\n+*~\n.DS_Store\n_trial_temp/\n@@ -13,6 +14,7 @@ docs/build/\ncmdclient_config.json\nhomeserver*.db\nhomeserver*.log\n+homeserver*.log.*\nhomeserver*.pid\nhomeserver*.yaml\n@@ -40,6 +42,7 @@ media_store/\n*.tac\nbuild/\n+venv/\nlocalhost-800*/\nstatic/client/register/register_config.js\n",
        "chatgpt_cot": "Update permission change command in server setup documentation to recursively change ownership of /opt/cello folder to fix registration issues."
    },
    {
        "org_diff": "diff --git a/rasa_core_sdk/forms.py b/rasa_core_sdk/forms.py @@ -45,7 +45,7 @@ class FormAction(Action):\n- an extracted entity\n- a dictionary of intent: value pairs\n- a whole message\n- or a list of all of them\"\"\"\n+ or a list of all of them, where a first match will be picked\"\"\"\nreturn dict(zip(self.required_slots(), self.required_slots()))\n",
        "org_msg": "add comment to slot_mapping RasaHQ/roadmap#280",
        "sim_msg": "Lexer: override TokenAction.__repr__ to ease debugging\n(no-tn-check)",
        "sim_diff": "diff --git a/langkit/lexer.py b/langkit/lexer.py @@ -163,6 +163,9 @@ class TokenAction(Action):\n)\nreturn \"{}{}\".format(pfx, self.base_name.upper)\n+ def __repr__(self):\n+ return '<{} {}>'.format(type(self).__name__, self.name.camel or '???')\n+\nclass WithText(TokenAction):\n\"\"\"\n",
        "chatgpt_cot": "\"Add support for a list of entities in FormAction\""
    },
    {
        "org_diff": "diff --git a/user-dashboard/js/dashboard/src/routes/Chain/New/index.js b/user-dashboard/js/dashboard/src/routes/Chain/New/index.js @@ -32,43 +32,22 @@ class NewChain extends PureComponent {\nselectedConfig: null,\nchainType: '',\nconfigs: [\n+ //{\n+ // id: 1,\n+ // type: \"fabric\",\n+ // configName: \"Fabric\",\n+ // configType: 'basic',\n+ // config: {\n+ // size: 1,\n+ // org: 1,\n+ // peer: 1\n+ // }\n+ //}\n+ //,\n{\nid: 1,\ntype: \"fabric\",\nconfigName: \"Fabric\",\n- configType: 'basic',\n- config: {\n- size: 1,\n- org: 1,\n- peer: 1\n- }\n- },\n- {\n- id: 2,\n- type: \"fabric\",\n- configName: \"Fabric\",\n- configType: 'advance',\n- config: {\n- size: 4,\n- org: 2,\n- peer: 4\n- }\n- },\n- {\n- id: 3,\n- type: \"ink\",\n- configName: \"InkChain\",\n- configType: 'basic',\n- config: {\n- size: 1,\n- org: 1,\n- peer: 2\n- }\n- },\n- {\n- id: 4,\n- type: \"ink\",\n- configName: \"InkChain\",\nconfigType: 'advance',\nconfig: {\nsize: 4,\n@@ -213,7 +192,6 @@ class NewChain extends PureComponent {\n})(\n<Select onChange={this.onTypeChange} placeholder={intl.formatMessage(messages.form.placeholder.chainType)}>\n<Option value=\"fabric\">Fabric</Option>\n- <Option value=\"ink\">InkChain</Option>\n</Select>\n)}\n</FormItem>\n",
        "org_msg": "Modify options for new chain\nDelete unused options and configuration.",
        "sim_msg": "Released constraints of cube_config schema",
        "sim_diff": "diff --git a/xcube/cli/_gen2/genconfig.py b/xcube/cli/_gen2/genconfig.py @@ -60,8 +60,8 @@ class InputConfig:\nstore_id=JsonStringSchema(min_length=1),\nopener_id=JsonStringSchema(min_length=1),\ndata_id=JsonStringSchema(min_length=1),\n- store_params=JsonObjectSchema(),\n- open_params=JsonObjectSchema()\n+ store_params=JsonObjectSchema(additional_properties=True),\n+ open_params=JsonObjectSchema(additional_properties=True)\n),\nadditional_properties=False,\nrequired=['data_id'],\n@@ -137,8 +137,8 @@ class OutputConfig:\nstore_id=JsonStringSchema(min_length=1),\nwriter_id=JsonStringSchema(min_length=1),\ndata_id=JsonStringSchema(default=None),\n- store_params=JsonObjectSchema(),\n- write_params=JsonObjectSchema(),\n+ store_params=JsonObjectSchema(additional_properties=True),\n+ write_params=JsonObjectSchema(additional_properties=True),\nreplace=JsonBooleanSchema(default=False),\n),\nadditional_properties=False,\n@@ -202,21 +202,32 @@ class CubeConfig:\nreturn JsonObjectSchema(\nproperties=dict(\nvariable_names=JsonArraySchema(\n- items=JsonStringSchema(min_length=1), min_items=0),\n- crs=JsonStringSchema(nullable=True, default='WGS84',\n- enum=[None, 'WGS84']),\n- bbox=JsonArraySchema(items=[JsonNumberSchema(),\n+ items=JsonStringSchema(min_length=1),\n+ min_items=0\n+ ),\n+ crs=JsonStringSchema(\n+ nullable=True,\n+ min_length=1\n+ ),\n+ bbox=JsonArraySchema(\n+ nullable=True,\n+ items=[JsonNumberSchema(),\nJsonNumberSchema(),\nJsonNumberSchema(),\nJsonNumberSchema()]),\n- spatial_res=JsonNumberSchema(exclusive_minimum=0.0),\n- time_range=JsonDateSchema.new_range(nullable=True),\n+ spatial_res=JsonNumberSchema(\n+ nullable=True,\n+ exclusive_minimum=0.0),\n+ time_range=JsonDateSchema.new_range(\n+ nullable=True\n+ ),\ntime_period=JsonStringSchema(\n- pattern=r'^([1-9][0-9]*)?[DWMY]$',\n- nullable=True),\n+ nullable=True,\n+ pattern=r'^([1-9][0-9]*)?[DWMY]$'\n+ ),\n),\n+ required=['variable_names'],\nadditional_properties=False,\n- required=['variable_names', 'bbox', 'spatial_res', 'time_range'],\nfactory=cls\n)\n",
        "chatgpt_cot": "Refactor NewChain component to update fabric config structure and remove ink config options for clarity and consistency."
    },
    {
        "org_diff": "diff --git a/rasa_core_sdk/forms.py b/rasa_core_sdk/forms.py @@ -50,13 +50,18 @@ class FormAction(Action):\ndef from_text(intent=None):\nreturn {\"type\": \"from_text\", \"intent\": intent}\n- def slot_mapping(self):\n+ # noinspection PyMethodMayBeStatic\n+ def slots_mappings(self):\n# type: () -> Dict[Text: Union[Dict, List[Dict]]]\n\"\"\"A dictionary to map required slots to\n- - an extracted entity (default behaviour)\n+ - an extracted entity\n- intent: value pairs\n- a whole message\n- or a list of them, where a first match will be picked\"\"\"\n+ or a list of them, where a first match will be picked\n+\n+ Empty dict converted to extracted entity\n+ with the same name as a slot\n+ \"\"\"\nreturn {}\n@@ -71,33 +76,33 @@ class FormAction(Action):\nslot_to_fill = tracker.get_slot(REQUESTED_SLOT)\n# map requested_slot to entity\n- slot_mappings = self.slot_mapping().get(slot_to_fill)\n- if not slot_mappings:\n- slot_mappings = self.from_entity(slot_to_fill)\n+ requested_slot_mappings = self.slots_mappings().get(slot_to_fill)\n+ if not requested_slot_mappings:\n+ requested_slot_mappings = self.from_entity(slot_to_fill)\n- if not isinstance(slot_mappings, list):\n- slot_mappings = [slot_mappings]\n+ if not isinstance(requested_slot_mappings, list):\n+ requested_slot_mappings = [requested_slot_mappings]\n- for slot_mapping in slot_mappings:\n- if (not isinstance(slot_mapping, dict) or\n- slot_mapping.get(\"type\") is None):\n+ for requested_slot_mapping in requested_slot_mappings:\n+ if (not isinstance(requested_slot_mapping, dict) or\n+ requested_slot_mapping.get(\"type\") is None):\nraise TypeError(\"Provided incompatible slot_mapping\")\n- mapping_intent = slot_mapping.get(\"intent\")\n+ mapping_intent = requested_slot_mapping.get(\"intent\")\nintent = tracker.latest_message.get(\"intent\",\n{}).get(\"name\")\nif mapping_intent is None or mapping_intent == intent:\n- mapping_type = slot_mapping[\"type\"]\n+ mapping_type = requested_slot_mapping[\"type\"]\nif mapping_type == \"from_entity\":\nentity_value = next(tracker.get_latest_entity_values(\n- slot_mapping.get(\"entity\")), None)\n+ requested_slot_mapping.get(\"entity\")), None)\nif entity_value is not None:\nreturn [SlotSet(slot_to_fill, entity_value)]\nelif mapping_type == \"from_intent\":\nreturn [SlotSet(slot_to_fill,\n- slot_mapping.get(\"value\"))]\n+ requested_slot_mapping.get(\"value\"))]\nelif mapping_type == \"from_text\":\nreturn [SlotSet(slot_to_fill,\n",
        "org_msg": "rename slot_mapping() to slots_mappings() RasaHQ/roadmap#280",
        "sim_msg": "Add back CoreMappingKeys mismatch logic",
        "sim_diff": "diff --git a/ambassador/ambassador/ir/irhttpmappinggroup.py b/ambassador/ambassador/ir/irhttpmappinggroup.py @@ -120,17 +120,17 @@ class IRHTTPMappingGroup (IRBaseMappingGroup):\ndef add_mapping(self, aconf: Config, mapping: IRBaseMapping) -> None:\nmismatches = []\n- # for k in IRHTTPMappingGroup.CoreMappingKeys:\n- # if (k in mapping) and ((k not in self) or\n- # (mapping[k] != self[k])):\n- # mismatches.append((k, mapping[k], self.get(k, '-unset-')))\n- #\n- # if mismatches:\n- # self.post_error(\"cannot accept new mapping %s with mismatched %s\" % (\n- # mapping.name,\n- # \", \".join([ \"%s: %s != %s\" % (x, y, z) for x, y, z in mismatches ])\n- # ))\n- # return\n+ for k in IRHTTPMappingGroup.CoreMappingKeys:\n+ if (k in mapping) and ((k not in self) or\n+ (mapping[k] != self[k])):\n+ mismatches.append((k, mapping[k], self.get(k, '-unset-')))\n+\n+ if mismatches:\n+ self.post_error(\"cannot accept new mapping %s with mismatched %s\" % (\n+ mapping.name,\n+ \", \".join([ \"%s: %s != %s\" % (x, y, z) for x, y, z in mismatches ])\n+ ))\n+ return\n# self.ir.logger.debug(\"%s: add mapping %s\" % (self, mapping.as_json()))\n",
        "chatgpt_cot": "\"Fix compilation issue in FormAction class by adding slots_mappings method and modifying slot_mapping method to requested_slot_mappings to map requested slot to entity.\""
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/__init__.py b/node_manager_fkie/src/node_manager_fkie/__init__.py @@ -58,8 +58,8 @@ PKG_NAME = 'node_manager_fkie'\n__author__ = \"Alexander Tiderko (Alexander.Tiderko@fkie.fraunhofer.de)\"\n__copyright__ = \"Copyright (c) 2012 Alexander Tiderko, Fraunhofer FKIE/US\"\n__license__ = \"BSD\"\n-__version__ = \"0.8.2\" # git describe --tags --dirty --always\n-__date__ = \"2018-08-10\" # git log -1 --date=iso\n+__version__ = \"0.8.2-13-ga511911-dirty\" # git describe --tags --dirty --always\n+__date__ = \"2018-11-03\" # git log -1 --date=iso\n# PYTHONVER = (2, 7, 1)\n# if sys.version_info < PYTHONVER:\n",
        "org_msg": "node_manager_fkie: updated version tag",
        "sim_msg": "MAINT: fix release version in docs conf.py",
        "sim_diff": "diff --git a/docs/conf.py b/docs/conf.py @@ -22,7 +22,7 @@ copyright = '2020, Projeto Jupiter'\nauthor = 'Giovani Hdalgo Ceotto'\n# The full version, including alpha/beta/rc tags\n-release = '0.9.7'\n+release = '0.9.8'\n# -- General configuration ---------------------------------------------------\n",
        "chatgpt_cot": "Update version and date in init file to reflect the latest changes."
    },
    {
        "org_diff": "diff --git a/Makefile b/Makefile @@ -127,7 +127,7 @@ test-case: ##@Code Run test case for flask server\n@$(MAKE) -C test/ all\nclean: ##@Code Clean tox result\n- rm -rf .tox .cache *.egg-info\n+ rm -rf .tox .cache *.egg-info build/\nfind . -name \"*.pyc\" -o -name \"__pycache__\" -exec rm -rf \"{}\" \\;\n# TODO (david_dornseier): As long as there are no release versions, always rewrite\n@@ -152,10 +152,9 @@ logs: ##@Log tail for all service log\nredeploy: ##@Service Redeploy single service, Use like \"make redeploy service=dashboard\"\nbash scripts/master_node/redeploy.sh ${service}\n-image-clean: ##@Clean all existing images to rebuild\n+image-clean: clean ##@Clean all existing images to rebuild\necho \"Clean all cello related images, may need to remove all containers before\"\n- docker images | grep \"cello-\" | awk '{print $1}' | xargs docker rmi -f\n- docker rmi $(docker images -f dangling=true -q)\n+ docker images | grep \"hyperledger/cello-\" | awk '{print $3}' | xargs docker rmi -f\ninitial-env: ##@Configuration Initial Configuration for dashboard\n$(SED) 's/\\(STATIC_FOLDER=\\).*/\\1${STATIC_FOLDER}/' .env\n",
        "org_msg": "Update clean & image-clean targets\nUpdated `make clean` & `make image-clean` targets\nwhich now deletes `build/` and locally built docker images.",
        "sim_msg": "hammer: Changing cleanup command to make sure error codes from trying to remove containers/volumes aren't swallowed up",
        "sim_diff": "diff --git a/scale/job/execution/tasks/cleanup_task.py b/scale/job/execution/tasks/cleanup_task.py @@ -73,8 +73,14 @@ class CleanupTask(NodeTask):\nvolumes.extend(job_exe.docker_volumes)\n# Container/volume lists are generated by greping entire list from Docker against the specific\n# containers/volumes we are looking for\n+ if containers:\ncontainer_list_cmd = '%s | grep -e %s' % (all_containers_cmd, ' -e '.join(containers))\n+ else:\n+ container_list_cmd = ':'\n+ if volumes:\nvolume_list_cmd = '%s | grep -e %s' % (all_volumes_cmd, ' -e '.join(volumes))\n+ else:\n+ volume_list_cmd = ':'\n# Delete containers that are stuck so that volumes can be cleaned up properly\ndelete_stuck_container_cmd = for_cmd % ('cont',\n@@ -86,7 +92,10 @@ class CleanupTask(NodeTask):\ndelete_volumes_cmd = for_cmd % ('vol', volume_list_cmd, volume_delete_cmd)\n# Create overall command that deletes containers and volumes for the job executions\n- self._command = '%s; %s; %s' % (delete_containers_cmd, delete_stuck_container_cmd, delete_volumes_cmd)\n+ # try to delete stuck containers first, but discard any error codes\n+ # if there are any errors deleting containers or volumes, short circuit and report the error\n+ # so it can be reported and retried\n+ self._command = '%s; %s && %s' % (delete_stuck_container_cmd, delete_containers_cmd, delete_volumes_cmd)\n# Node task properties\nself.task_type = 'cleanup'\n",
        "chatgpt_cot": "Refactor Makefile for image-clean task, align with clean task, update docker image cleanup to target specific images, and improve initial configuration."
    },
    {
        "org_diff": "diff --git a/sc2/unit.py b/sc2/unit.py @@ -1117,7 +1117,8 @@ class Unit:\n:param position:\n:param queue:\n\"\"\"\n- # TODO: add asserts to make sure \"position\" is not a Point2 or Point3 if \"unit\" is extractor / refinery / assimilator\n+ if unit in {UnitTypeId.EXTRACTOR, UnitTypeId.ASSIMILATOR, UnitTypeId.REFINERY}:\n+ assert isinstance(position, Unit), f\"When building the gas structure, the target needs to be a unit (the vespene geysir) not the position of the vespene geysir.\"\nreturn self(self._bot_object._game_data.units[unit.value].creation_ability.id, target=position, queue=queue)\ndef build_gas(self, target_geysir: Unit, queue: bool = False) -> UnitCommand:\n@@ -1130,8 +1131,8 @@ class Unit:\n:param target_geysir:\n:param queue:\n\"\"\"\n- # TODO: add asserts to make sure \"target_geysir\" is not a Point2 or Point3\ngas_structure_type_id: UnitTypeId = race_gas[self._bot_object.race]\n+ assert isinstance(target_geysir, Unit), f\"When building the gas structure, the target needs to be a unit (the vespene geysir) not the position of the vespene geysir.\"\nreturn self(\nself._bot_object._game_data.units[gas_structure_type_id.value].creation_ability.id,\ntarget=target_geysir,\n",
        "org_msg": "Add assert to unit.build and unit.build_gas",
        "sim_msg": "Fix sending tensors in chain to different workers",
        "sim_diff": "diff --git a/syft/core/frameworks/torch/tensor.py b/syft/core/frameworks/torch/tensor.py @@ -257,20 +257,26 @@ class _PointerTensor(_SyftTensor):\ndef get(self, parent):\nobj, cleanup = self.owner.request_obj(self.id_at_location, self.location)\n+ syft_obj = obj\nobj = obj.child\nif(isinstance(obj, torch.Tensor)):\nparent.native_set_(obj)\nself.owner.get_worker(obj.owner).rm_obj(obj.id)\n- self.owner.set_obj(self.id, obj.child)\n+ self.owner.set_obj(self.id, syft_obj)\n+ self.owner.rm_obj(syft_obj.id)\n- if(hasattr(obj, 'child') and obj.child is not None):\n- obj.child.id = self.id\n- self = obj.child\n+ syft_obj.id = self.id\n+ self = syft_obj\n+\n+ \"\"\"if(hasattr(obj, 'child') and obj.child is not None):\n+ syft_obj.id = self.id\n+ self = syft_obj\nelse:\n+ raise Exception('Check this.')\nobj.id = self.id\n- self = obj\n+ self = obj\"\"\"\nparent.child = self\nreturn self\n@@ -439,7 +445,8 @@ class _TorchVariable(_TorchObject):\n\"\"\"\nif not isinstance(self, sy.autograd.Variable):\nraise TypeError('Only ofr Variable')\n- self.data.send(worker, new_id)\n+ # TODO: want to define a particular id ? cant use new_id 2 or 3 times\n+ self.data.send(worker, new_id=None)\n# TODO: add pointer on attr grad: create .grad as a property\n# which makes a special request asking if it exists\n# which lets us fetch the pointers in a lazy way\n",
        "chatgpt_cot": "Add assertions to ensure correct target type in build methods to prevent errors."
    },
    {
        "org_diff": "diff --git a/fkie_node_manager/src/fkie_node_manager/parameter_dialog.py b/fkie_node_manager/src/fkie_node_manager/parameter_dialog.py @@ -104,7 +104,9 @@ class ValueWidget(QWidget):\nself.parameter_description = parameter_description\nself._value_widget = None\nself.warn_label = QLabel(parent=self)\n+ self.warn_label.setTextInteractionFlags(Qt.TextSelectableByMouse)\nself.help_label = QLabel(parameter_description.hint, parent=self)\n+ self.help_label.setTextInteractionFlags(Qt.TextSelectableByMouse)\nvw = QWidget(self)\nhlayout = QHBoxLayout(vw)\nhlayout.setContentsMargins(0, 0, 0, 0)\n@@ -193,6 +195,7 @@ class ValueWidget(QWidget):\nlabel = QLabel(value, parent=self)\nlabel.setMinimumHeight(20)\nlabel.setSizePolicy(QSizePolicy(QSizePolicy.Expanding, QSizePolicy.Fixed))\n+ label.setTextInteractionFlags(Qt.TextSelectableByMouse)\nself._value_widget = label\nreturn label\nelse:\n@@ -540,6 +543,7 @@ class MainBox(QFrame):\nself.hide_button.setMaximumSize(20, 20)\nself.hide_button.clicked.connect(self._on_hide_clicked)\nself.name_label = QLabel(name)\n+ self.name_label.setTextInteractionFlags(Qt.TextSelectableByMouse)\nfont = self.name_label.font()\nfont.setBold(True)\nself.name_label.setFont(font)\n@@ -628,6 +632,7 @@ class MainBox(QFrame):\nlabel = QLabel(label_name, self)\nlabel.setObjectName('%s_label' % name)\nlabel.setSizePolicy(QSizePolicy(QSizePolicy.Expanding, QSizePolicy.Expanding))\n+ label.setTextInteractionFlags(Qt.TextSelectableByMouse)\nhint = field.toolTip()\nif hint:\nlabel.setToolTip(hint)\n@@ -1111,6 +1116,7 @@ class ParameterDialog(QDialog):\ndef add_warning(self, message):\nlabel = QLabel(self)\nlabel.setWordWrap(True)\n+ label.setTextInteractionFlags(Qt.TextSelectableByMouse)\nlabel.setText(''.join([\"<font color='red'>Warning!\\n\", message, \"</font>\"]))\nself.verticalLayout.insertWidget(1, label)\n",
        "org_msg": "fkie_node_manager: set text syelectable in parameter dialog",
        "sim_msg": "changed textEdit to textBrowser\nchange required so image links can be displayed",
        "sim_diff": "diff --git a/QualCoder/GUI/ui_dialog_cases.py b/QualCoder/GUI/ui_dialog_cases.py # Form implementation generated from reading ui file 'ui_dialog_cases.ui'\n#\n-# Created: Thu Jan 10 22:32:05 2019\n+# Created: Fri Jan 18 21:16:07 2019\n# by: PyQt5 UI code generator 5.2.1\n#\n# WARNING! All changes made in this file will be lost!\n@@ -20,6 +20,12 @@ class Ui_Dialog_cases(object):\nself.groupBox_2.setObjectName(\"groupBox_2\")\nself.gridLayout_2 = QtWidgets.QGridLayout(self.groupBox_2)\nself.gridLayout_2.setObjectName(\"gridLayout_2\")\n+ self.label = QtWidgets.QLabel(self.groupBox_2)\n+ self.label.setMinimumSize(QtCore.QSize(0, 20))\n+ self.label.setMaximumSize(QtCore.QSize(16777215, 60))\n+ self.label.setWordWrap(True)\n+ self.label.setObjectName(\"label\")\n+ self.gridLayout_2.addWidget(self.label, 2, 0, 1, 1)\nself.splitter = QtWidgets.QSplitter(self.groupBox_2)\nself.splitter.setOrientation(QtCore.Qt.Horizontal)\nself.splitter.setObjectName(\"splitter\")\n@@ -27,15 +33,9 @@ class Ui_Dialog_cases(object):\nself.tableWidget.setObjectName(\"tableWidget\")\nself.tableWidget.setColumnCount(0)\nself.tableWidget.setRowCount(0)\n- self.textEdit = QtWidgets.QTextEdit(self.splitter)\n- self.textEdit.setObjectName(\"textEdit\")\n+ self.textBrowser = QtWidgets.QTextBrowser(self.splitter)\n+ self.textBrowser.setObjectName(\"textBrowser\")\nself.gridLayout_2.addWidget(self.splitter, 0, 0, 1, 1)\n- self.label = QtWidgets.QLabel(self.groupBox_2)\n- self.label.setMinimumSize(QtCore.QSize(0, 20))\n- self.label.setMaximumSize(QtCore.QSize(16777215, 60))\n- self.label.setWordWrap(True)\n- self.label.setObjectName(\"label\")\n- self.gridLayout_2.addWidget(self.label, 1, 0, 1, 1)\nself.gridLayout.addWidget(self.groupBox_2, 2, 1, 1, 1)\nself.groupBox = QtWidgets.QGroupBox(Dialog_cases)\nsizePolicy = QtWidgets.QSizePolicy(QtWidgets.QSizePolicy.Preferred, QtWidgets.QSizePolicy.Fixed)\n",
        "chatgpt_cot": "\"Add text interaction flags for mouse selection to improve user experience in parameter_dialog.py\""
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/editor/xmlformatter.py b/node_manager_fkie/src/node_manager_fkie/editor/xmlformatter.py @@ -682,20 +682,27 @@ class Formatter():\nif (self.preserve in [0, 1] and self.indent):\nstr += self.indent_insert()\nstr += \"<%s\" % self.arg[0]\n+ args_attr = ''\nordered = ['' for i in range(len(self.formatter.attr_order))]\nfor i in range(0, len(self.arg[1]), 2):\nstr_val = self.attribute(self.arg[1][i], self.arg[1][i + 1])\n+ if self.arg[1][i] == 'args':\n+ # always append args attribute\n+ args_attr = '%s %s' % (self.indent_insert(), str_val)\n+ else:\ntry:\n# if this attribute is in ordered list, it will be inserted, otherwise appended.\nidx = self.formatter.attr_order.index(self.arg[1][i])\ndel ordered[idx]\n- ordered.insert(idx, str_val)\n+ ordered.insert(idx, '%s%s' % (' ' if self.arg[1][i] == 'if' else '', str_val))\nexcept Exception:\nordered.append(str_val)\n# add attributes\nfor val in ordered:\nif val:\nstr += val\n+ if args_attr:\n+ str += args_attr\nif (self.list[self.pos + 1].end and not self.formatter.noemptytag):\nstr += \"/>\"\nelse:\n",
        "org_msg": "node_manager_fkie: xml format: args attribute always in a new line",
        "sim_msg": "advanced resolve",
        "sim_diff": "diff --git a/lbry/wallet/server/db/elastic_search.py b/lbry/wallet/server/db/elastic_search.py @@ -23,6 +23,8 @@ class SearchIndex:\nself.sync_timeout = 600 # wont hit that 99% of the time, but can hit on a fresh import\nasync def start(self):\n+ if self.client:\n+ return\nself.client = AsyncElasticsearch(timeout=self.sync_timeout)\ntry:\nif await self.client.indices.exists(self.index):\n@@ -288,6 +290,10 @@ REPLACEMENTS = {\ndef expand_query(**kwargs):\n+ if \"amount_order\" in kwargs:\n+ kwargs[\"limit\"] = 1\n+ kwargs[\"order_by\"] = \"effective_amount\"\n+ kwargs[\"offset\"] = int(kwargs[\"amount_order\"]) - 1\nif 'name' in kwargs:\nkwargs['name'] = normalize_name(kwargs.pop('name'))\nquery = {'must': [], 'must_not': []}\n@@ -387,6 +393,8 @@ def expand_query(**kwargs):\nif 'offset' in kwargs:\nquery[\"from\"] = kwargs[\"offset\"]\nif 'order_by' in kwargs:\n+ if isinstance(kwargs[\"order_by\"], str):\n+ kwargs[\"order_by\"] = [kwargs[\"order_by\"]]\nfor value in kwargs['order_by']:\nis_asc = value.startswith('^')\nvalue = value[1:] if is_asc else value\n",
        "chatgpt_cot": "Add handling for 'args' attribute in XML formatter to ensure proper insertion, fixing attribute order issue and preserving formatting in the editor."
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/echo_dialog.py b/node_manager_fkie/src/node_manager_fkie/echo_dialog.py @@ -156,6 +156,7 @@ class EchoDialog(QDialog):\nself.combobox_displ_hz.addItems([str(self.MESSAGE_HZ_LIMIT), '0', '0.1', '1', '50', '100', '1000'])\nself.combobox_displ_hz.activated[str].connect(self.on_combobox_hz_activated)\nself.combobox_displ_hz.setEditable(True)\n+ self.combobox_displ_hz.setToolTip(\"Set maximum displayed message rate in Hz. 0 disables the limit.\")\nhLayout.addWidget(self.combobox_displ_hz)\ndispl_hz_label = QLabel('Hz', self)\nhLayout.addWidget(displ_hz_label)\n",
        "org_msg": "node_manager_fkie: add tooltip to a filter in echo dialog",
        "sim_msg": "label for file code attribute counts",
        "sim_diff": "diff --git a/qualcoder/GUI/ui_dialog_report_codings.py b/qualcoder/GUI/ui_dialog_report_codings.py @@ -14,10 +14,15 @@ class Ui_Dialog_reportCodings(object):\ndef setupUi(self, Dialog_reportCodings):\nDialog_reportCodings.setObjectName(\"Dialog_reportCodings\")\nDialog_reportCodings.setWindowModality(QtCore.Qt.NonModal)\n- Dialog_reportCodings.resize(989, 694)\n+ Dialog_reportCodings.resize(989, 510)\nself.verticalLayout = QtWidgets.QVBoxLayout(Dialog_reportCodings)\nself.verticalLayout.setObjectName(\"verticalLayout\")\nself.groupBox = QtWidgets.QGroupBox(Dialog_reportCodings)\n+ sizePolicy = QtWidgets.QSizePolicy(QtWidgets.QSizePolicy.Preferred, QtWidgets.QSizePolicy.Preferred)\n+ sizePolicy.setHorizontalStretch(0)\n+ sizePolicy.setVerticalStretch(0)\n+ sizePolicy.setHeightForWidth(self.groupBox.sizePolicy().hasHeightForWidth())\n+ self.groupBox.setSizePolicy(sizePolicy)\nself.groupBox.setMinimumSize(QtCore.QSize(0, 120))\nself.groupBox.setMaximumSize(QtCore.QSize(16777215, 120))\nself.groupBox.setTitle(\"\")\n@@ -60,9 +65,19 @@ class Ui_Dialog_reportCodings(object):\nself.comboBox_export.addItem(\"\")\nself.comboBox_export.addItem(\"\")\nself.verticalLayout.addWidget(self.groupBox)\n+ self.label_counts = QtWidgets.QLabel(Dialog_reportCodings)\n+ self.label_counts.setMinimumSize(QtCore.QSize(0, 20))\n+ self.label_counts.setMaximumSize(QtCore.QSize(16777215, 20))\n+ self.label_counts.setObjectName(\"label_counts\")\n+ self.verticalLayout.addWidget(self.label_counts)\nself.label_selections = QtWidgets.QLabel(Dialog_reportCodings)\n+ sizePolicy = QtWidgets.QSizePolicy(QtWidgets.QSizePolicy.Preferred, QtWidgets.QSizePolicy.MinimumExpanding)\n+ sizePolicy.setHorizontalStretch(0)\n+ sizePolicy.setVerticalStretch(0)\n+ sizePolicy.setHeightForWidth(self.label_selections.sizePolicy().hasHeightForWidth())\n+ self.label_selections.setSizePolicy(sizePolicy)\nself.label_selections.setMinimumSize(QtCore.QSize(0, 50))\n- self.label_selections.setMaximumSize(QtCore.QSize(16777213, 60))\n+ self.label_selections.setMaximumSize(QtCore.QSize(16777213, 50))\nself.label_selections.setScaledContents(True)\nself.label_selections.setWordWrap(True)\nself.label_selections.setObjectName(\"label_selections\")\n@@ -110,6 +125,7 @@ class Ui_Dialog_reportCodings(object):\nself.comboBox_export.setItemText(2, _translate(\"Dialog_reportCodings\", \"txt\"))\nself.comboBox_export.setItemText(3, _translate(\"Dialog_reportCodings\", \"odt\"))\nself.comboBox_export.setItemText(4, _translate(\"Dialog_reportCodings\", \"csv\"))\n+ self.label_counts.setText(_translate(\"Dialog_reportCodings\", \"Counts:\"))\nself.label_selections.setText(_translate(\"Dialog_reportCodings\", \"Search selections:\"))\n",
        "chatgpt_cot": "Add tooltip to display message rate combobox in EchoDialog. Set maximum displayed message rate in Hz. 0 disables the limit."
    },
    {
        "org_diff": "diff --git a/fkie_master_discovery/src/fkie_master_discovery/udp.py b/fkie_master_discovery/src/fkie_master_discovery/udp.py @@ -541,7 +541,7 @@ class UcastSocket(socket.socket):\ndef close(self):\n\"\"\" Cleanup and close the socket\"\"\"\n- self.sendto('', (self.interface, self.port))\n+ self.sendto(b'', (self.interface, self.port))\nsocket.socket.close(self)\n@staticmethod\n",
        "org_msg": "fkie_master_discovery: fixed python3 compatibility on close",
        "sim_msg": "refactor closing peers",
        "sim_diff": "diff --git a/lbrynet/core/client/ConnectionManager.py b/lbrynet/core/client/ConnectionManager.py @@ -46,19 +46,12 @@ class ConnectionManager(object):\nif self._next_manage_call is not None and self._next_manage_call.active() is True:\nself._next_manage_call.cancel()\nself._next_manage_call = None\n- closing_deferreds = []\n- for peer in self._peer_connections.keys():\n- def close_connection(p):\n- log.info(\n- \"Abruptly closing a connection to %s due to downloading being paused\", p)\n+ return self._close_peers()\n- if self._peer_connections[p].factory.p is not None:\n- d = self._peer_connections[p].factory.p.cancel_requests()\n- else:\n- d = defer.succeed(True)\n+ def _close_peers(self):\n- def disconnect_peer():\n+ def disconnect_peer(p):\nd = defer.Deferred()\nself._connections_closing[p] = d\nself._peer_connections[p].connection.disconnect()\n@@ -66,10 +59,16 @@ class ConnectionManager(object):\ndel self._peer_connections[p]\nreturn d\n- d.addBoth(lambda _: disconnect_peer())\n+ def close_connection(p):\n+ log.info(\"Abruptly closing a connection to %s due to downloading being paused\", p)\n+ if self._peer_connections[p].factory.p is not None:\n+ d = self._peer_connections[p].factory.p.cancel_requests()\n+ else:\n+ d = defer.succeed(True)\n+ d.addBoth(lambda _: disconnect_peer(p))\nreturn d\n- closing_deferreds.append(close_connection(peer))\n+ closing_deferreds = [close_connection(peer) for peer in self._peer_connections.keys()]\nreturn defer.DeferredList(closing_deferreds)\n@defer.inlineCallbacks\n",
        "chatgpt_cot": "Fix issue with socket sendto method in UcastSocket class"
    },
    {
        "org_diff": "diff --git a/examples/terran/ramp_wall.py b/examples/terran/ramp_wall.py @@ -124,10 +124,10 @@ class RampWallBot(sc2.BotAI):\ncolor = Point3((0, 255, 255))\nif p in ramp.lower:\ncolor = Point3((0, 0, 255))\n- self._client.debug_box2_out(pos, half_vertex_length=0.25, color=color)\n+ self._client.debug_box2_out(pos + Point2((0.5, 0.5)), half_vertex_length=0.25, color=color)\n# Identical to above:\n- # p0 = Point3((pos.x - 0.25, pos.y - 0.25, pos.z + 0.25))\n- # p1 = Point3((pos.x + 0.25, pos.y + 0.25, pos.z - 0.25))\n+ # p0 = Point3((pos.x + 0.25, pos.y + 0.25, pos.z + 0.25))\n+ # p1 = Point3((pos.x + 0.75, pos.y + 0.75, pos.z - 0.25))\n# print(f\"Drawing {p0} to {p1}\")\n# self._client.debug_box_out(p0, p1, color=color)\n@@ -275,7 +275,7 @@ def main():\n\"HonorgroundsLE\", # Has 4 or 9 upper points at the large main base ramp\n]\n)\n- map = \"GoldenWallLE\"\n+ map = \"PillarsofGoldLE\"\nsc2.run_game(\nsc2.maps.get(map),\n[Bot(Race.Terran, RampWallBot()), Computer(Race.Zerg, Difficulty.Hard)],\n",
        "org_msg": "Re-adjust ramp wall points",
        "sim_msg": "Handle a degenerate case better",
        "sim_diff": "diff --git a/histomicstk/segmentation/label/trace_object_boundaries.py b/histomicstk/segmentation/label/trace_object_boundaries.py @@ -131,7 +131,7 @@ def trace_object_boundaries(im_label,\nreturn X, Y\n-def _remove_thin_colinear_spurs(px, py, eps_colinear_area=1.0):\n+def _remove_thin_colinear_spurs(px, py, eps_colinear_area=0.0):\n\"\"\"Simplifies the given list of points by removing colinear spurs\n\"\"\"\n@@ -143,7 +143,14 @@ def _remove_thin_colinear_spurs(px, py, eps_colinear_area=1.0):\nwhile testpos < len(px):\n# get coords of next triplet of points to test\n- ind = [anchor, testpos, (testpos + 1) % len(px)]\n+ if testpos == len(px) - 1:\n+ if not len(keep):\n+ break\n+ nextpos = keep[0]\n+ else:\n+ nextpos = testpos + 1\n+\n+ ind = [anchor, testpos, nextpos]\nx1, x2, x3 = px[ind]\ny1, y2, y3 = py[ind]\n@@ -162,9 +169,6 @@ def _remove_thin_colinear_spurs(px, py, eps_colinear_area=1.0):\nelse:\ntestpos += 1\n- if len(keep) < 2: # degenerate case\n- keep = [0, -1]\n-\npx = px[keep]\npy = py[keep]\n",
        "chatgpt_cot": "Change map name from \"GoldenWallLE\" to \"PillarsofGoldLE\" in RampWallBot to update map information."
    },
    {
        "org_diff": "diff --git a/examples/simulate_fight_scenario.py b/examples/simulate_fight_scenario.py @@ -14,7 +14,7 @@ class FightBot(BotAI):\nself.fight_started = False\nasync def on_step(self, iteration):\n- # before everything else - retrieve control\n+ # retrieve control by enabling enemy control and showing whole map\nif iteration == 0:\n# we need this one for `self.enemy_units` to \"see\" all units on the map\nawait self._client.debug_show_map()\n@@ -26,7 +26,7 @@ class FightBot(BotAI):\n# prepare my side\nme = 1\ncc = self.townhalls.first\n- p = cc.position.towards(self.game_info.map_center, 3)\n+ p = cc.position.towards(self.game_info.map_center, 4)\n# create supply\nawait self._client.debug_create_unit([[UnitTypeId.SUPPLYDEPOT, 1, p, me]])\n# destroy command center\n@@ -40,7 +40,7 @@ class FightBot(BotAI):\n# prepare opponent side\npc = 2\ncc = self.enemy_structures.first\n- p = cc.position.towards(self.game_info.map_center, 3)\n+ p = cc.position.towards(self.game_info.map_center, 4)\n# create supply\nawait self._client.debug_create_unit([[UnitTypeId.SUPPLYDEPOT, 1, p, pc]])\n# destroy command center\n@@ -66,6 +66,11 @@ class FightBot(BotAI):\n# await self.chat_send(\"fight started\")\nself.fight_started = True\n+ # in case of no units left - do not wait for game to finish\n+ if self.fight_started and (not self.units or not self.enemy_units):\n+ logger.info(\"LOSE\" if not self.units else \"WIN\")\n+ await self._client.quit() # await self._client.debug_leave() # or reset level\n+\nfor u in self.units(UnitTypeId.MARINE):\nu.attack(self.enemy_structures.first.position)\n# TODO: implement your fight logic here\n@@ -75,19 +80,11 @@ class FightBot(BotAI):\n# u.attack(self.enemy_structures.first.position)\n# pass\n- # in case of no units left - do not wait for game to finish\n- if self.fight_started:\n- if not self.units or not self.enemy_units:\n- if not self.units:\n- logger.error(\"LOSE\")\n- else:\n- logger.success(\"WIN\")\n- await self._client.quit() # await self._client.debug_leave() # or reset level\n-\ndef main():\nrun_game(\nmaps.get(\"Flat64\"),\n+ # NOTE: you can have to bots fighting with each other here\n[Bot(Race.Terran, FightBot()), Computer(Race.Terran, Difficulty.Medium)],\nrealtime=True\n)\n",
        "org_msg": "simplify game end",
        "sim_msg": "commands leave",
        "sim_diff": "diff --git a/baron/baron.py b/baron/baron.py @@ -360,9 +360,7 @@ class Baron(commands.Cog):\nexcept KeyError:\nguilds.append((guild, 0))\nelse:\n- total_commands = 0\n- for value in guild_data.values():\n- total_commands += value\n+ total_commands = sum(guild_data.values())\nif total_commands < commands:\nguilds.append((guild, total_commands))\nguilds.sort(key=lambda x: x[1], reverse=highest_first)\n@@ -455,6 +453,31 @@ class Baron(commands.Cog):\nf\"I have automatically left this server since it has less than {members} members.\",\n)\n+ @commands.check(comstats_cog)\n+ @leave.command(name=\"commands\")\n+ async def leave_commands(self, ctx: commands.Context, commands: int):\n+ \"\"\"Leave all servers that have used less commands than the given number.\"\"\"\n+ cog = self.bot.get_cog(\"CommandStats\")\n+ data = await cog.config.guilddata()\n+ guilds = []\n+\n+ for guild in self.bot.guilds:\n+ try:\n+ guild_data = data[str(guild.id)]\n+ except KeyError:\n+ guilds.append((guild, 0))\n+ else:\n+ total_commands = sum(guild_data.values())\n+ if total_commands < commands:\n+ guilds.append((guild, total_commands))\n+ if not guilds:\n+ await ctx.send(f\"There are no servers with a command usage count less than {commands}.\")\n+ await self.leave_guilds(\n+ ctx,\n+ guilds,\n+ f\"I have automatically left this server since it has used less than {commands} commands.\",\n+ )\n+\nasync def leave_guilds(self, ctx: commands.Context, guilds: list, message: str):\ndata = await self.config.all()\nunwl_guilds = [guild for guild in guilds if guild.id not in data[\"whitelist\"]]\n",
        "chatgpt_cot": "Refactor FightBot class for better control and display in simulate_fight_scenario.py. Updated position calculation and win/lose condition handling for improved gameplay."
    },
    {
        "org_diff": "diff --git a/fkie_node_manager/src/fkie_node_manager/main_window.py b/fkie_node_manager/src/fkie_node_manager/main_window.py @@ -2082,7 +2082,6 @@ class MainWindow(QMainWindow):\ndef _nmd_yaml_cfg(self, data, nmdurl):\nparams = ruamel.yaml.load(data, Loader=ruamel.yaml.Loader)\ndia = ParameterDialog(params, store_geometry=\"nmd_cfg_dialog\")\n- dia.setFilterVisible(False)\ndia.setWindowTitle('Daemon Configuration')\ndia.setFocusField('load_warn_level')\nif dia.exec_():\n",
        "org_msg": "fkie_node_manager: added filter field in node manager daemon setup",
        "sim_msg": "technica info and summary added",
        "sim_diff": "diff --git a/README.md b/README.md @@ -222,5 +222,3 @@ Each environment is configured with a `yaml` file. Examples of `yaml` files can\n<!-- @fei: \"resolution\". list valid values-->\n<!-- @fei: \"timestep\" and \"frameskip\". if you remember, we had decided to clarify this with an example for newbies.-->\n<!-- @fei: \"mode\". We need to define what each of \"gui\" and \"headless\" exactly do. We should expect people to find them by trial and error-->\n-\n-\n",
        "chatgpt_cot": "Remove unused method setFilterVisible to clean up code and improve readability in MainWindow class."
    },
    {
        "org_diff": "diff --git a/.github/workflows/ci.yml b/.github/workflows/ci.yml @@ -184,9 +184,9 @@ jobs:\n- name: Load and build docker image\n# Build docker image from Dockerfile using specific python and sc2 version\nenv:\n- BUILD_ARGS: --build-arg PYTHON_VERSION=$LATEST_PYTHON_VERSION --build-arg SC2_VERSION=$LATEST_SC2_VERSION\n+ BUILD_ARGS: --build-arg PYTHON_VERSION=${{ env.LATEST_PYTHON_VERSION }} --build-arg SC2_VERSION=${{ env.LATEST_SC2_VERSION }}\nrun: |\n- docker build -f test/Dockerfile -t $IMAGE_NAME $BUILD_ARGS --build-arg VERSION_NUMBER=$VERSION_NUMBER .\n+ docker build -f test/Dockerfile -t $IMAGE_NAME $BUILD_ARGS --build-arg VERSION_NUMBER=${{ env.VERSION_NUMBER }} .\n- name: Run example bots vs computer\nrun: |\n",
        "org_msg": "Add curly braces again where required",
        "sim_msg": "Debug: Print version before building the package.",
        "sim_diff": "diff --git a/.github/workflows/build-docker-image.yml b/.github/workflows/build-docker-image.yml @@ -17,6 +17,8 @@ jobs:\nuses: actions/setup-python@v1\nwith:\npython-version: 3.7\n+ - name: Determine version\n+ run: python setup.py --version\n#- name: Install build environment\n# run: python -m pip install build --user\n# - name: Build source tarball\n",
        "chatgpt_cot": "Fix environment variable interpolation in Docker build command to resolve build issues."
    },
    {
        "org_diff": "diff --git a/fkie_master_discovery/src/fkie_master_discovery/__init__.py b/fkie_master_discovery/src/fkie_master_discovery/__init__.py @@ -38,6 +38,8 @@ import sys\nimport roslib\nimport rospy\n+import time\n+\ntry:\nfrom urlparse import urlparse # python 2 compatibility\nexcept ImportError:\n@@ -54,7 +56,7 @@ def get_default_rtcp_port(zeroconf=False):\ntry:\nfrom fkie_master_discovery.common import masteruri_from_ros\nmasteruri = masteruri_from_ros()\n- rospy.loginfo(\"ROS Master URI: %s\", masteruri)\n+ # rospy.loginfo(\"ROS Master URI: %s\", masteruri)\nreturn urlparse(masteruri).port + (600 if zeroconf else 300)\nexcept:\nimport traceback\n@@ -91,11 +93,38 @@ def set_process_name(name):\npass\n+def is_port_in_use(port):\n+ import socket, errno\n+ result = False\n+ s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n+ try:\n+ s.bind(('localhost', port))\n+ except socket.error as e:\n+ if e.errno == errno.EADDRINUSE:\n+ result = True\n+ else:\n+ # something else raised the socket.error exception\n+ print(e)\n+ s.close()\n+ return result\n+\n+\n+def wait_for_free_port():\n+ wait_index = 0\n+ rpc_port = get_default_rtcp_port()\n+ while wait_index < 12 and is_port_in_use(rpc_port):\n+ wait_index += 1\n+ if wait_index == 1:\n+ print('RPC port %d is already in use, is there another instance of master_discovery running?' % rpc_port)\n+ time.sleep(1)\n+\n+\ndef main():\n'''\nCreates and runs the ROS node using multicast messages for discovering\n'''\nimport fkie_master_discovery.master_discovery as master_discovery\n+ wait_for_free_port()\n# setup the loglevel\ntry:\nlog_level = getattr(rospy, rospy.get_param('/%s/log_level' % PROCESS_NAME, \"INFO\"))\n@@ -118,7 +147,6 @@ def main():\nimport traceback\nrospy.logerr(\"%s\\nError while start master_discovery: %s\" % (traceback.format_exc(), str(e)))\nos.kill(os.getpid(), signal.SIGKILL)\n- import time\ntime.sleep(10)\n@@ -128,6 +156,7 @@ def main_zeroconf():\n'''\nimport fkie_master_discovery.zeroconf as zeroconf\nPROCESS_NAME = \"zeroconf\"\n+ wait_for_free_port()\n# setup the loglevel\ntry:\nlog_level = getattr(rospy, rospy.get_param('/%s/log_level' % PROCESS_NAME, \"INFO\"))\n",
        "org_msg": "wait until RCP port is free to avoid shutdown because of \"new node registered with same name\"",
        "sim_msg": "fix for python3/noetic",
        "sim_diff": "diff --git a/core/rosbuild/core/rosbuild/bin/download_checkmd5.py b/core/rosbuild/core/rosbuild/bin/download_checkmd5.py import hashlib\nimport os\nimport sys\n-import urllib\n+import urllib.request\nfrom optparse import OptionParser\nNAME = 'download_checkmd5.py'\n@@ -61,12 +61,12 @@ def main():\nif not os.path.exists(dest):\nsys.stdout.write('[rosbuild] Downloading %s to %s...' % (uri, dest))\nsys.stdout.flush()\n- urllib.urlretrieve(uri, dest)\n+ urllib.request.urlretrieve(uri, dest)\nsys.stdout.write('Done\\n')\nfresh = True\nif md5sum:\n- m = hashlib.md5(open(dest).read())\n+ m = hashlib.md5(open(dest, \"rb\").read())\nd = m.hexdigest()\nprint('[rosbuild] Checking md5sum on %s' % (dest))\n@@ -77,7 +77,7 @@ def main():\nos.remove(dest)\n# Try one more time\n- urllib.urlretrieve(uri, dest)\n+ urllib.request.urlretrieve(uri, dest)\nm = hashlib.md5(open(dest).read())\nd = m.hexdigest()\n",
        "chatgpt_cot": "Add new method \"wait_for_free_port\" and \"is_port_in_use\" to check for available ports before running the ROS node in main and main_zeroconf functions."
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/node_tree_model.py b/node_manager_fkie/src/node_manager_fkie/node_tree_model.py @@ -636,6 +636,9 @@ class GroupItem(QStandardItem):\nif isinstance(item, (GroupItem, NodeItem)):\nif item.state == NodeItem.STATE_WARNING:\nself.setIcon(QIcon(':/icons/crystal_clear_warning.png'))\n+ self._state = NodeItem.STATE_WARNING\n+ if self.parent_item is not None:\n+ self.parent_item.updateIcon()\nreturn\nelif item.state == NodeItem.STATE_OFF:\nhas_off = True\n",
        "org_msg": "node_manager_fkie: fixed update group state if one child has warnings",
        "sim_msg": "Removed redundant internalPointer query",
        "sim_diff": "diff --git a/avalon/tools/cbsceneinventory/model.py b/avalon/tools/cbsceneinventory/model.py @@ -50,7 +50,6 @@ class InventoryModel(TreeModel):\nif role == QtCore.Qt.DecorationRole:\nif index.column() == 0:\n# Override color\n- node = index.internalPointer()\ncolor = node.get(\"color\", style.colors.default)\nif not index.parent().isValid(): # group-item\nreturn qta.icon(\"fa.folder\", color=color)\n@@ -62,7 +61,6 @@ class InventoryModel(TreeModel):\nreturn node.get(\"familyIcon\", None)\nif role == self.UniqueRole:\n- node = index.internalPointer()\nreturn node['representation'] + node.get(\"objectName\", \"<none>\")\nreturn super(InventoryModel, self).data(index, role)\n",
        "chatgpt_cot": "\"Add updateIcon method to GroupItem for updating parent_item icon\""
    },
    {
        "org_diff": "diff --git a/fkie_node_manager/src/fkie_node_manager/main_window.py b/fkie_node_manager/src/fkie_node_manager/main_window.py @@ -174,9 +174,9 @@ class MainWindow(QMainWindow):\nself.logButton.clicked.connect(self._on_log_button_clicked)\nself.settingsButton.clicked.connect(self._on_settings_button_clicked)\n# setup screen dock\n- self.screen_dock = ScreenDock()\n- self.screen_dock.hide()\n+ self.screen_dock = ScreenDock(self)\nself.addDockWidget(Qt.BottomDockWidgetArea, self.screen_dock)\n+ self.screen_dock.hide()\n# setup the launch files view\nself.launch_dock = LaunchFilesWidget()\nself.launch_dock.load_signal.connect(self.on_load_launch_file)\n@@ -191,13 +191,9 @@ class MainWindow(QMainWindow):\nself.setWindowTitle(\"Node Manager\")\nself.setWindowIcon(self.mIcon)\n# self.setCentralWidget(mainWindow)\n-\n# init the stack layout which contains the information about different ros master\nself.stackedLayout = QStackedLayout()\nself.stackedLayout.setObjectName('stackedLayout')\n- emptyWidget = QWidget()\n- emptyWidget.setObjectName('emptyWidget')\n- self.stackedLayout.addWidget(emptyWidget)\nself.tabWidget.currentChanged.connect(self.on_currentChanged_tab)\nself.tabLayout = QVBoxLayout(self.tabPlace)\nself.tabLayout.setObjectName(\"tabLayout\")\n",
        "org_msg": "fkie_node_manager: removed empty widget",
        "sim_msg": "tabbed widget holding activity log and a note pad",
        "sim_diff": "diff --git a/qualcoder/GUI/ui_main.py b/qualcoder/GUI/ui_main.py @@ -18,9 +18,25 @@ class Ui_MainWindow(object):\nself.centralwidget.setObjectName(\"centralwidget\")\nself.gridLayout = QtWidgets.QGridLayout(self.centralwidget)\nself.gridLayout.setObjectName(\"gridLayout\")\n- self.textEdit = QtWidgets.QTextEdit(self.centralwidget)\n+ self.tabWidget = QtWidgets.QTabWidget(self.centralwidget)\n+ self.tabWidget.setObjectName(\"tabWidget\")\n+ self.tab = QtWidgets.QWidget()\n+ self.tab.setObjectName(\"tab\")\n+ self.gridLayout_2 = QtWidgets.QGridLayout(self.tab)\n+ self.gridLayout_2.setObjectName(\"gridLayout_2\")\n+ self.textEdit = QtWidgets.QTextEdit(self.tab)\nself.textEdit.setObjectName(\"textEdit\")\n- self.gridLayout.addWidget(self.textEdit, 0, 0, 1, 1)\n+ self.gridLayout_2.addWidget(self.textEdit, 0, 0, 1, 1)\n+ self.tabWidget.addTab(self.tab, \"\")\n+ self.tab_2 = QtWidgets.QWidget()\n+ self.tab_2.setObjectName(\"tab_2\")\n+ self.gridLayout_3 = QtWidgets.QGridLayout(self.tab_2)\n+ self.gridLayout_3.setObjectName(\"gridLayout_3\")\n+ self.textEdit_notes = QtWidgets.QTextEdit(self.tab_2)\n+ self.textEdit_notes.setObjectName(\"textEdit_notes\")\n+ self.gridLayout_3.addWidget(self.textEdit_notes, 0, 0, 1, 1)\n+ self.tabWidget.addTab(self.tab_2, \"\")\n+ self.gridLayout.addWidget(self.tabWidget, 0, 0, 1, 1)\nMainWindow.setCentralWidget(self.centralwidget)\nself.menubar = QtWidgets.QMenuBar(MainWindow)\nself.menubar.setGeometry(QtCore.QRect(0, 0, 602, 22))\n@@ -165,11 +181,14 @@ class Ui_MainWindow(object):\nself.menubar.addAction(self.menuHelp.menuAction())\nself.retranslateUi(MainWindow)\n+ self.tabWidget.setCurrentIndex(0)\nQtCore.QMetaObject.connectSlotsByName(MainWindow)\ndef retranslateUi(self, MainWindow):\n_translate = QtCore.QCoreApplication.translate\nMainWindow.setWindowTitle(_translate(\"MainWindow\", \"QualCoder\"))\n+ self.tabWidget.setTabText(self.tabWidget.indexOf(self.tab), _translate(\"MainWindow\", \"Action log\"))\n+ self.tabWidget.setTabText(self.tabWidget.indexOf(self.tab_2), _translate(\"MainWindow\", \"Temporary notes\"))\nself.menuProject.setTitle(_translate(\"MainWindow\", \"Project\"))\nself.menuOpen_Recent_Project.setTitle(_translate(\"MainWindow\", \"Open Recent Project\"))\nself.menuExport.setTitle(_translate(\"MainWindow\", \"Export\"))\n",
        "chatgpt_cot": "Refactor MainWindow class: initialize ScreenDock with self, remove redundant code for stackedLayout initialization, and connect tab change signal for tabWidget."
    },
    {
        "org_diff": "diff --git a/fkie_master_sync/src/fkie_master_sync/sync_thread.py b/fkie_master_sync/src/fkie_master_sync/sync_thread.py @@ -90,7 +90,7 @@ class SyncThread(object):\nself.masteruri_local = masteruri_from_ros()\nself.hostname_local = get_hostname(self.masteruri_local)\n- rospy.logdebug(\"SyncThread[%s]: create this sync thread, discoverer_name: %s\", (self.name, self.discoverer_name))\n+ rospy.logdebug(\"SyncThread[%s]: create this sync thread, discoverer_name: %s\", self.name, self.discoverer_name)\n# synchronization variables\nself.__lock_info = threading.RLock()\nself.__lock_intern = threading.RLock()\n",
        "org_msg": "fkie_master_sync: fixed debug output",
        "sim_msg": "test: add potentially related python issue test",
        "sim_diff": "diff --git a/tests/integration/issues/issue936/test_flow_with_sse_no_deadlock.py b/tests/integration/issues/issue936/test_flow_with_sse_no_deadlock.py @@ -73,3 +73,49 @@ def test_pod_with_sse_no_deadlock_thread():\nwith p:\ntime.sleep(1)\npass\n+\n+\n+# Child process is not capable to get the released RLock\n+def test_issue_python():\n+ import os, sys, threading, time\n+\n+ class ThreadStuff(threading.Thread):\n+ def __init(self):\n+ print(f' ThreadStuff: init')\n+ threading.Thread.__init__(self)\n+\n+ def start_doing_stuff(self):\n+ self.start()\n+\n+ def run(self):\n+ print(f'ThreadStuff id: {threading.get_ident()}')\n+\n+ print(\"ThreadStuff: running (rlock = %s)\" % global_rlock)\n+\n+ global_rlock.acquire()\n+ print(\"ThreadStuff: I OWN THE LOCK\")\n+ time.sleep(5)\n+ global_rlock.release()\n+ print(\"ThreadStuff: dropped it. Sleeping forever\")\n+ time.sleep(86400)\n+\n+ # ---\n+\n+ global_rlock = threading.RLock(verbose=True)\n+ print(f'global_rlock {global_rlock}')\n+\n+ ts = ThreadStuff()\n+ ts.start()\n+\n+ time.sleep(1)\n+ print(\"forking\")\n+ pid = os.fork()\n+ if pid:\n+ print(\"parent: running (rlock = %s)\" % global_rlock)\n+ else:\n+ print(\"child: running (rlock = %s) getting the lock...\" % global_rlock)\n+ global_rlock.acquire()\n+ print(\"child: got the lock\")\n+ sys.exit(0)\n+\n+ time.sleep(10)\n",
        "chatgpt_cot": "Fix logdebug format in SyncThread class to correctly display the thread name and discoverer name."
    },
    {
        "org_diff": "diff --git a/fkie_master_sync/nodes/param_sync.py b/fkie_master_sync/nodes/param_sync.py @@ -8,7 +8,7 @@ from fkie_master_discovery.common import masteruri_from_master\nfrom fkie_multimaster_msgs.msg import MasterState\ndef master_changed(msg, cb_args):\n- param_cache, local_master = cb_args\n+ param_cache, local_master, __add_ns = cb_args\nlocal_name = ''\nif local_master:\nlocal_name = local_master[0]\n@@ -23,9 +23,13 @@ def master_changed(msg, cb_args):\nif '/'+local_name in params_from:\ndel params_from['/'+local_name]\nrospy.logdebug(\"Syncing params from {} to {}...\".format(msg.master.name, local_name))\n- if param_cache.get('', None) != params_from:\n- param_cache[''] = params_from\n- master_to['/'] = params_from\n+ if __add_ns:\n+ _ns = msg.master.name\n+ else:\n+ _ns = ''\n+ if param_cache.get(_ns, None) != params_from:\n+ param_cache[_ns] = params_from\n+ master_to['/'+_ns] = params_from\nrospy.logdebug(\"Done syncing params from {} to {}.\".format(msg.master.name, local_name))\nelse:\nrospy.logdebug(\"Params have not changed from {} to {}.\".format(msg.master.name, local_name))\n@@ -39,13 +43,14 @@ def master_changed(msg, cb_args):\ndef main():\n- rospy.init_node('param_sync', log_level=rospy.DEBUG, anonymous=True)\n+ rospy.init_node('param_sync', log_level=rospy.DEBUG)\nparam_cache = dict()\nlocal_master = list()\nmasteruri_from_master()\n- sub = rospy.Subscriber('master_discovery/changes', MasterState, master_changed, callback_args=(param_cache, local_master))\n+ __add_ns = rospy.get_param('~add_ns', True)\n+ sub = rospy.Subscriber('master_discovery/changes', MasterState, master_changed, callback_args=(param_cache, local_master, __add_ns))\nrospy.spin()\n",
        "org_msg": "added param for appending namespace to params",
        "sim_msg": "actually use the flag so it is applied to all checking",
        "sim_diff": "diff --git a/GearBot/Cogs/ModLog.py b/GearBot/Cogs/ModLog.py @@ -22,7 +22,7 @@ class ModLog:\nself.cache_message = None\nself.to_cache = []\nself.cache_start = 0\n- self.bot.loop.create_task(self.prep())\n+ self.bot.loop.create_task(self.prep(bot.hot_reloading))\nself.bot.loop.create_task(cache_task(self))\ndef __unload(self):\n@@ -83,7 +83,7 @@ class ModLog:\nGearbotLogging.info(\nf\"Discovered {newCount} new messages and {editCount} edited in {guild.name} (checked {count})\")\n- async def prep(self):\n+ async def prep(self, hot_reloading):\nself.cache_message = await GearbotLogging.bot_log(\nf\"{Emoji.get_chat_emoji('REFRESH')} Validating modlog cache\")\nself.to_cache = []\n@@ -91,15 +91,15 @@ class ModLog:\nif self.is_enabled(guild.id, \"EDIT_LOGS\") is not 0:\nself.to_cache.append(guild)\nfor i in range(min(3, len(self.bot.guilds))):\n- self.bot.loop.create_task(self.startup_cache())\n+ self.bot.loop.create_task(self.startup_cache(hot_reloading))\nself.cache_start = time.perf_counter()\n- async def startup_cache(self):\n+ async def startup_cache(self, hot_reloading):\nawait self.bot.change_presence(activity=discord.Activity(type=3, name='the gears turn'), status=\"idle\")\nwhile self.to_cache is not None:\nif len(self.to_cache) > 0:\nguild = self.to_cache.pop()\n- await self.buildCache(guild, startup=True, limit=50 if self.bot.hot_reloading else 500)\n+ await self.buildCache(guild, startup=True, limit=50 if hot_reloading else 500)\nawait asyncio.sleep(0)\nelse:\nself.to_cache = None\n",
        "chatgpt_cot": "Add new parameter to callback function in param_sync.py to handle namespace addition, improving synchronization functionality."
    },
    {
        "org_diff": "diff --git a/sc2/unit.py b/sc2/unit.py @@ -118,6 +118,11 @@ class Unit:\n\"\"\" Provides the unit type data. \"\"\"\nreturn self._bot_object._game_data.units[self._proto.unit_type]\n+ @property_immutable_cache\n+ def _creation_ability(self) -> AbilityData:\n+ \"\"\" Provides the AbilityData of the creation ability of this unit. \"\"\"\n+ return self._bot_object._game_data.units[self._proto.unit_type].creation_ability\n+\n@property\ndef name(self) -> str:\n\"\"\" Returns the name of the unit. \"\"\"\n@@ -734,6 +739,15 @@ class Unit:\nangle_difference = math.fabs(angle - self.facing)\nreturn angle_difference < angle_error\n+ @property\n+ def footprint_radius(self) -> float:\n+ \"\"\" For structures only.\n+ For townhalls this returns 2.5\n+ For barracks, spawning pool, gateway, this returns 1.5\n+ For supply depot, this returns 1\n+ For sensor tower, creep tumor, this return 0.5 \"\"\"\n+ return self._bot_object._game_data.units[self._proto.unit_type].creation_ability._proto.footprint_radius\n+\n@property\ndef radius(self) -> float:\n\"\"\" Half of unit size. See https://liquipedia.net/starcraft2/Unit_Statistics_(Legacy_of_the_Void) \"\"\"\n",
        "org_msg": "Add footprint_radius to Unit",
        "sim_msg": "fix compatibility bugs with XYZ and zeopp",
        "sim_diff": "diff --git a/pymatgen/io/zeopp.py b/pymatgen/io/zeopp.py @@ -234,11 +234,11 @@ class ZeoVoronoiXYZ(XYZ):\nreturn ZeoVoronoiXYZ.from_string(f.read())\ndef __str__(self):\n- output = [str(len(self._mol)), self._mol.composition.formula]\n+ output = [str(len(self._mols[0])), self._mols[0].composition.formula]\nfmtstr = \"{{}} {{:.{0}f}} {{:.{0}f}} {{:.{0}f}} {{:.{0}f}}\".format(\nself.precision\n)\n- for site in self._mol:\n+ for site in self._mols[0]:\noutput.append(fmtstr.format(\nsite.specie.symbol, site.z, site.x, site.y,\nsite.properties['voronoi_radius']\n@@ -299,7 +299,7 @@ def get_voronoi_nodes(structure, rad_dict=None, probe_rad=0.1):\ncoords.append(list(site.coords))\nprop.append(site.properties['voronoi_radius'])\n- lattice = Lattice.from_parameters(structure.lattice.parameters)\n+ lattice = Lattice.from_parameters(*structure.lattice.parameters)\nvor_node_struct = Structure(\nlattice, species, coords, coords_are_cartesian=True,\nto_unit_cell=True, site_properties={\"voronoi_radius\": prop})\n@@ -376,7 +376,7 @@ def get_high_accuracy_voronoi_nodes(structure, rad_dict, probe_rad=0.1):\ncoords.append(list(site.coords))\nprop.append(site.properties['voronoi_radius'])\n- lattice = Lattice.from_parameters(structure.lattice.parameters)\n+ lattice = Lattice.from_parameters(*structure.lattice.parameters)\nvor_node_struct = Structure(\nlattice, species, coords, coords_are_cartesian=True,\nto_unit_cell=True, site_properties={\"voronoi_radius\": prop})\n",
        "chatgpt_cot": "Add new properties to the Unit class for creation ability and footprint radius, providing data and calculations for specific unit types."
    },
    {
        "org_diff": "diff --git a/src/modules/host.py b/src/modules/host.py @@ -382,19 +382,19 @@ class HostHandler(object):\nif len(clusters) <= 0:\nreturn True\n- host = self.db_set_by_id(id, autofill=False)\n+ host = self.db_set_by_id(id, **{\"autofill\": False})\nschedulable_status = host.schedulable\nif schedulable_status:\n- host = self.db_set_by_id(id, schedulable=False)\n+ host = self.db_set_by_id(id, **{\"schedulable\": False})\nfor cluster_item in clusters:\ncid = str(cluster_item.id)\n- t = Thread(target=cluster_item.cluster_handler.delete, args=(cid,))\n+ t = Thread(target=cluster.cluster_handler.delete, args=(cid,))\nt.start()\ntime.sleep(0.2)\nif schedulable_status:\n- self.db_set_by_id(id, schedulable=schedulable_status)\n+ self.db_set_by_id(id, **{\"schedulable\": schedulable_status})\nreturn True\n",
        "org_msg": "Fix host clean operation in admin dashboard\nCan clean host in admin dashboard",
        "sim_msg": "Decr log level.",
        "sim_diff": "diff --git a/dpark/hostatus.py b/dpark/hostatus.py @@ -132,7 +132,7 @@ class TaskHostManager:\nif task_id in self.task_host_failed_dict:\nfor host in self.task_host_failed_dict[task_id]:\nself.host_dict[host].erase_failed_task(task_id)\n- logger.info('the failed hosts %s for task %s',\n+ logger.debug('the failed hosts %s for task %s',\nstr(self.task_host_failed_dict[task_id]), task_id)\ndel self.task_host_failed_dict[task_id]\n",
        "chatgpt_cot": "\"Fix issue with host handler class method parameters and cluster item reference\""
    },
    {
        "org_diff": "diff --git a/rasa_core_sdk/forms.py b/rasa_core_sdk/forms.py @@ -40,40 +40,46 @@ class FormAction(Action):\n\"that it has to fill\")\ndef slot_mapping(self):\n- # type: () -> Dict[Text: Union[Text, List[Text], Dict[Text: Any]]]\n+ # type: () -> Dict[Text: Union[Text, Dict, List[Text, Dict]]]\n\"\"\"A dictionary to map required slots to\n- - an extracted entity or a list of entities\n+ - an extracted entity\n- a dictionary of intent: value pairs\n- - a whole message\"\"\"\n+ - a whole message\n+ or a list of all of them\"\"\"\nreturn dict(zip(self.required_slots(), self.required_slots()))\n# noinspection PyUnusedLocal\n- def extract(self, dispatcher, tracker, domain):\n- # type: (CollectingDispatcher, Tracker, Dict[Text, Any]) -> Optional[List[Dict]]\n+ def extract(self,\n+ dispatcher, # type: CollectingDispatcher\n+ tracker, # type: Tracker\n+ domain # type: Dict[Text, Any]\n+ ):\n+ # type: (...) -> Optional[List[Dict]]\n\"\"\"\"Extract the user input else return an error\"\"\"\nslot_to_fill = tracker.slots[REQUESTED_SLOT]\n# map requested_slot to entity\n- slot_mapping = self.slot_mapping().get(slot_to_fill)\n+ slot_mappings = self.slot_mapping().get(slot_to_fill)\n- if slot_mapping:\n+ if slot_mappings:\n+ if not isinstance(slot_mappings, list):\n+ slot_mappings = [slot_mappings]\n+\n+ for slot_mapping in slot_mappings:\nif isinstance(slot_mapping, dict):\n- intent = tracker.latest_message.get(\"intent\", {}).get(\"name\")\n+ intent = tracker.latest_message.get(\"intent\",\n+ {}).get(\"name\")\nif intent in slot_mapping.keys():\nreturn [SlotSet(slot_to_fill, slot_mapping[intent])]\nelse:\n- required_entities = slot_mapping\n- if not isinstance(required_entities, list):\n- required_entities = [required_entities]\n-\n- for entity_name in required_entities:\nentity_value = next(tracker.get_latest_entity_values(\n- entity_name), None)\n+ slot_mapping), None)\nif entity_value is not None:\nreturn [SlotSet(slot_to_fill, entity_value)]\n- if self.FREETEXT in required_entities:\n+ # the whole text can be always extracted, so it is done in the end\n+ if self.FREETEXT in slot_mappings:\nreturn [SlotSet(slot_to_fill,\ntracker.latest_message.get(\"text\"))]\n",
        "org_msg": "allow slot_mapping to be a list of different things RasaHQ/roadmap#280",
        "sim_msg": "dataset.py: converation bulk upload logic.",
        "sim_diff": "diff --git a/labelbox/schema/dataset.py b/labelbox/schema/dataset.py @@ -226,6 +226,7 @@ class Dataset(DbObject, Updateable, Deletable):\n>>> {DataRow.row_data:\"/path/to/file1.jpg\"},\n>>> \"path/to/file2.jpg\",\n>>> {\"tileLayerUrl\" : \"http://\", ...}\n+ >>> {\"conversation\" : \"{}\", ...}\n>>> ])\nFor an example showing how to upload tiled data_rows see the following notebook:\n@@ -280,6 +281,29 @@ class Dataset(DbObject, Updateable, Deletable):\n)\nreturn attachments\n+ def validate_conversational_data(conversational_data: list) -> None:\n+ \"\"\"\n+ Checks each conversational message for keys expected as per https://docs.labelbox.com/reference/text-conversational#sample-conversational-json\n+\n+ Args:\n+ conversational_data (list): list of dictionaries.\n+ \"\"\"\n+ def check_message_keys(message):\n+ accepted_message_keys = set([\n+ \"messageId\", \"timestampUsec\", \"content\", \"user\", \"align\", \"canLabel\"])\n+ for key in message.keys():\n+ if not key in accepted_message_keys:\n+ raise KeyError(\n+ f\"Invalid {key} key found! Accepted keys in messages list is \")\n+\n+ if conversational_data and not isinstance(conversational_data, list):\n+ raise ValueError(\n+ f\"conversationalData must be a list. Found {type(conversational_data)}\"\n+ )\n+\n+ [check_message_keys(message)\n+ for message in conversational_data]\n+\ndef parse_metadata_fields(item):\nmetadata_fields = item.get('metadata_fields')\nif metadata_fields:\n@@ -321,6 +345,23 @@ class Dataset(DbObject, Updateable, Deletable):\nif \"tileLayerUrl\" in item:\nvalidate_attachments(item)\nreturn item\n+\n+ if \"conversationalData\" in item:\n+ messages = item.pop(\"conversationalData\")\n+ validate_conversational_data(messages)\n+ validate_attachments(item)\n+ one_conversation = \\\n+ {\n+ \"type\": item[\"type\"],\n+ \"version\": item[\"version\"],\n+ \"messages\": messages\n+ }\n+ conversationUrl = self.client.upload_data(json.dumps(one_conversation),\n+ content_type=\"application/json\",\n+ filename=\"conversational_data.json\")\n+ item[\"conversationalUrl\"] = conversationUrl\n+ return item\n+\n# Convert all payload variations into the same dict format\nitem = format_row(item)\n# Make sure required keys exist (and there are no extra keys)\n",
        "chatgpt_cot": "\"Fix type annotations and extract method in FormAction class for better readability and error handling.\""
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/EchoDialog.ui b/node_manager_fkie/src/node_manager_fkie/EchoDialog.ui <item>\n<widget class=\"QLabel\" name=\"maxDigitsLabel\">\n<property name=\"text\">\n- <string>digits after '.'</string>\n+ <string>decimal length</string>\n</property>\n</widget>\n</item>\n",
        "org_msg": "node_manager_fkie: label for decimal length changed",
        "sim_msg": "added label for file count",
        "sim_diff": "diff --git a/GUI_UIs/ui_dialog_manage_files.ui b/GUI_UIs/ui_dialog_manage_files.ui <string>Files</string>\n</property>\n<layout class=\"QGridLayout\" name=\"gridLayout\">\n- <item row=\"2\" column=\"0\">\n+ <item row=\"3\" column=\"0\">\n<widget class=\"QTableWidget\" name=\"tableWidget\"/>\n</item>\n<item row=\"1\" column=\"0\">\n</widget>\n</widget>\n</item>\n+ <item row=\"2\" column=\"0\">\n+ <widget class=\"QLabel\" name=\"label_fcount\">\n+ <property name=\"text\">\n+ <string>Files:</string>\n+ </property>\n+ </widget>\n+ </item>\n</layout>\n</widget>\n<resources/>\n",
        "chatgpt_cot": "\"Refactor label text in EchoDialog.ui for clarity and consistency with the functionality of the dialog.\""
    },
    {
        "org_diff": "diff --git a/sc2/bot_ai.py b/sc2/bot_ai.py @@ -69,6 +69,13 @@ class BotAI(object):\n# Not always accurate, but good enought for now.\nreturn [c.rounded for c in centers]\n+ async def expand_to_nearest(self, building, max_distance=10):\n+ assert isinstance(building, UnitTypeId)\n+\n+ location = await self.get_next_expansion()\n+ await self.build(building, near=location, max_distance=max_distance, random_alternative=False,\n+ placement_step=1)\n+\nasync def get_next_expansion(self):\nDISTANCE_THRESHOLD = 15.0\nclosest = None\n",
        "org_msg": "Add a convenience method to expand to the nearest unoccupied expansion\nThis would place the town hall flush with the mineral fields due to `random_alternative`\nbeing set to False and `placement_step` is 1.",
        "sim_msg": "update interstitial generator to give smarter names",
        "sim_diff": "diff --git a/pymatgen/analysis/defects/generators.py b/pymatgen/analysis/defects/generators.py @@ -166,6 +166,7 @@ class InterstitialGenerator(DefectGenerator):\nconv_prim_rat = int(self.structure.num_sites/prim_struct.num_sites)\nself.multiplicities = [int(interstitial_finder.get_defectsite_multiplicity(def_ind) / conv_prim_rat)\nfor def_ind in range(len(self.defect_sites))]\n+ self.count_def = 0 #for counting the index of the generated defect\ndef __next__(self):\n\"\"\"\n@@ -175,8 +176,9 @@ class InterstitialGenerator(DefectGenerator):\nif len(self.defect_sites) > 0:\nint_site = self.defect_sites.pop(0)\nmult = self.multiplicities.pop(0)\n-\n- return Interstitial(self.structure, int_site, multiplicity=mult)\n+ self.count_def += 1\n+ name = 'InFiT'+str(self.count_def)\n+ return Interstitial(self.structure, int_site, name=name, multiplicity=mult)\nelse:\nraise StopIteration\n@@ -214,6 +216,8 @@ class VoronoiInterstitialGenerator(DefectGenerator):\nif poss_site_list[0] not in self.structure:\nself.equiv_site_seq.append(poss_site_list)\n+ self.count_def = 0 #for counting the index of the generated defect\n+\ndef __next__(self):\n\"\"\"\n@@ -222,8 +226,10 @@ class VoronoiInterstitialGenerator(DefectGenerator):\n\"\"\"\nif len(self.equiv_site_seq) > 0:\ninter_site_list = self.equiv_site_seq.pop(0)\n-\n- return Interstitial(self.structure, inter_site_list[0], multiplicity=len(inter_site_list))\n+ self.count_def += 1\n+ name = 'Voronoi'+str(self.count_def)\n+ return Interstitial(self.structure, inter_site_list[0], name=name,\n+ multiplicity=len(inter_site_list))\nelse:\nraise StopIteration\n",
        "chatgpt_cot": "\"Add expand_to_nearest method to BotAI for building expansion near a location with a maximum distance constraint.\""
    },
    {
        "org_diff": "diff --git a/fkie_node_manager/src/fkie_node_manager/node_tree_model.py b/fkie_node_manager/src/fkie_node_manager/node_tree_model.py @@ -346,6 +346,9 @@ class GroupItem(QStandardItem):\n'''\ntry:\nif type(self) == HostItem:\n+ # replace last namespace separator if it is not the only one\n+ if len(ns) > 1:\n+ ns = ns.rstrip(rospy.names.SEP)\nfor _cfg, cap in self._capcabilities.items():\nfor gns, groups in cap.items():\nfor group, _decription in groups.items():\n",
        "org_msg": "fkie_node_manager: fix unattended deselection of nodes",
        "sim_msg": "Avoid Namespace error when shutting down",
        "sim_diff": "diff --git a/gaphor/ui/namespace.py b/gaphor/ui/namespace.py @@ -267,7 +267,7 @@ class NamespaceModel(Gtk.GenericTreeModel):\nself._remove_element(element)\nparent_node = self._nodes.get(element.namespace)\n- if element in parent_node:\n+ if parent_node and element in parent_node:\nparent_node.remove(element)\n# if path and parent_node and len(self._nodes[parent_node]) == 0:\n",
        "chatgpt_cot": "\"Fix removing last namespace separator if it is not the only one in GroupItem class\""
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/start_handler.py b/node_manager_fkie/src/node_manager_fkie/start_handler.py @@ -616,9 +616,7 @@ class StartHandler(object):\nif count >= 11:\nraise StartException('Cannot connect to the ROS-Master: ' + str(masteruri))\nexcept Exception as e:\n- import sys\n- print >> sys.stderr, e\n- raise\n+ raise Exception(\"Error while call '%s': %s\" % (cmd_args, e))\nelse:\nraise Exception(\"ROS master '%s' is not reachable\" % masteruri)\nfinally:\n",
        "org_msg": "node_manager_fkie: added more details on start if no screen is available",
        "sim_msg": "switch stop to inlineCallback",
        "sim_diff": "diff --git a/lbrynet/core/client/ConnectionManager.py b/lbrynet/core/client/ConnectionManager.py @@ -41,13 +41,13 @@ class ConnectionManager(object):\nself._next_manage_call = reactor.callLater(0, self._manage)\nreturn defer.succeed(True)\n+ @defer.inlineCallbacks\ndef stop(self):\nself.stopped = True\n- if self._next_manage_call is not None and self._next_manage_call.active() is True:\n+ if self._next_manage_call and self._next_manage_call.active():\nself._next_manage_call.cancel()\nself._next_manage_call = None\n-\n- return self._close_peers()\n+ yield self._close_peers()\ndef _close_peers(self):\n",
        "chatgpt_cot": "\"Refactor exception handling in StartHandler.py to raise specific exceptions and improve error message clarity for ROS master connectivity issues.\""
    },
    {
        "org_diff": "diff --git a/fkie_node_manager/src/fkie_node_manager/master_view_proxy.py b/fkie_node_manager/src/fkie_node_manager/master_view_proxy.py @@ -2107,7 +2107,7 @@ class MasterViewProxy(QWidget):\nall2start = set()\n# put into the queue and start\nfor node in nodes:\n- if node.name in cfg_nodes:\n+ if node.name in cfg_nodes and not node.name in all2start:\n# remove node from question\nself.message_frame.hide_question([MessageFrame.TYPE_BINARY], MessageData(node))\n# add associated nodes to start\n",
        "org_msg": "fkie_node_manager: fix double start of nodes while using associations",
        "sim_msg": "tree: improve popup menu handling",
        "sim_diff": "diff --git a/tree.py b/tree.py @@ -390,7 +390,8 @@ class WidgetTree(wx.TreeCtrl, Tree):\nself.Bind(wx.EVT_RIGHT_DOWN, self.popup_menu)\nself.Bind(wx.EVT_LEFT_DCLICK, self.on_left_dclick)\nself.Bind(wx.EVT_LEFT_DOWN, self.on_left_click) # allow direct placement of widgets\n- self.Bind(wx.EVT_MENU, self.show_toplevel)\n+ self.Bind(wx.EVT_MENU, self.on_menu) # for handling the selection of the first item\n+ self._popup_menu_widget = None # the widget for the popup menu\nself.Bind(wx.EVT_TREE_BEGIN_DRAG, self.begin_drag)\nself.Bind(wx.EVT_LEAVE_WINDOW, self.on_leave_window)\nself.Bind(wx.EVT_MOUSE_EVENTS, self.on_mouse_events)\n@@ -707,6 +708,12 @@ class WidgetTree(wx.TreeCtrl, Tree):\nself.SetCursor(wx.STANDARD_CURSOR)\nevent.Skip()\n+ def on_menu(self, event):\n+ # the first entry in the popup menu, i.e. the name was selected\n+ if self._popup_menu_widget is None: return\n+ if not getattr(self._popup_menu_widget, \"_is_toplevel_window\", False): return\n+ self.show_toplevel( None, self._popup_menu_widget )\n+\ndef on_mouse_events(self, event):\nif not self._drag_ongoing and not event.IsButton():\n# set cursor to indicate a possible drop\n@@ -730,8 +737,9 @@ class WidgetTree(wx.TreeCtrl, Tree):\nif not node:\nreturn\nself.select_item(node)\n- item = node.widget\n- item.popup_menu(event, pos)\n+ self._popup_menu_widget = node.widget\n+ node.widget.popup_menu(event, pos)\n+ self._popup_menu_widget = None\ndef expand(self, node=None, yes=True):\n\"expands or collapses the given node\"\n",
        "chatgpt_cot": "\"Add condition to prevent adding node to start if it's already in the start list\""
    },
    {
        "org_diff": "diff --git a/fkie_master_sync/src/fkie_master_sync/sync_thread.py b/fkie_master_sync/src/fkie_master_sync/sync_thread.py @@ -104,7 +104,7 @@ class SyncThread(object):\n# setup the filter\nself._filter = FilterInterface()\nself._filter.load(self.name,\n- ['/rosout', rospy.get_name(), self.discoverer_name, '/node_manager', '/node_manager_daemon', '/zeroconf'], [],\n+ ['/rosout', rospy.get_name(), self.discoverer_name, '/node_manager', '/node_manager_daemon', '/zeroconf', '/param_sync'], [],\n['/rosout', '/rosout_agg'], ['/'] if sync_on_demand else [],\n['/*get_loggers', '/*set_logger_level'], [],\n# do not sync the bond message of the nodelets!!\n",
        "org_msg": "fkie_masrter_sync: added param_sync node to ignore list",
        "sim_msg": "Reset Block height sync bad targets on cleanUp",
        "sim_diff": "diff --git a/loopchain/peer/block_sync.py b/loopchain/peer/block_sync.py @@ -699,6 +699,7 @@ class BlockSync:\nself._sync_done_event = None\nself._retry_queue = None\nself._retry_task = None\n+ self._block_height_sync_bad_targets.clear()\ndef stop(self):\nself._cleanup()\n",
        "chatgpt_cot": "Add '/param_sync' to the filter list in SyncThread to include param_sync topic, improving filtering functionality for synchronization in the file."
    },
    {
        "org_diff": "diff --git a/sc2/unit.py b/sc2/unit.py @@ -192,20 +192,20 @@ class Unit(object):\n@property\ndef is_moving(self):\n- return len(self.orders) > 0 and self.orders[0] in [AbilityId.MOVE]\n+ return len(self.orders) > 0 and self.orders[0].ability.id in [AbilityId.MOVE]\n@property\ndef is_attacking(self):\n- return len(self.orders) > 0 and self.orders[0] in [AbilityId.ATTACK]\n+ return len(self.orders) > 0 and self.orders[0].ability.id in [AbilityId.ATTACK]\n@property\ndef is_gathering(self):\n\"\"\" Checks if a unit is on its way to a mineral field / vespene geyser to mine \"\"\"\n- return len(self.orders) > 0 and self.orders[0] in [AbilityId.HARVEST_GATHER]\n+ return len(self.orders) > 0 and self.orders[0].ability.id in [AbilityId.HARVEST_GATHER]\n@property\ndef order_target(self):\n- \"\"\" returns the target tag from the first order \"\"\"\n+ \"\"\" Returns the target tag from the first order \"\"\"\nif len(self.orders) > 0:\nreturn self.orders[0].target\nreturn None\n@@ -232,7 +232,7 @@ class Unit(object):\n@property\ndef surplus_harvesters(self):\n- \"\"\" returns a positive number if it has too many harvesters mining, a negative number if it has too few mining \"\"\"\n+ \"\"\" Returns a positive number if it has too many harvesters mining, a negative number if it has too few mining \"\"\"\nreturn self._proto.assigned_harvesters - self._proto.ideal_harvesters\n@property\n",
        "org_msg": "Fix moving/attacking/gathering",
        "sim_msg": "Use available quantities in part table, enhance stock badge",
        "sim_diff": "diff --git a/InvenTree/templates/js/translated/part.js b/InvenTree/templates/js/translated/part.js @@ -1160,12 +1160,14 @@ function partGridTile(part) {\nif (!part.in_stock) {\nstock = `<span class='badge rounded-pill bg-danger'>{% trans \"No Stock\" %}</span>`;\n+ } else if (!part.unallocated_stock) {\n+ stock = `<span class='badge rounded-pill bg-warning'>{% trans \"Not available\" %}</span>`;\n}\nrows += `<tr><td><b>{% trans \"Stock\" %}</b></td><td>${stock}</td></tr>`;\n- if (part.on_order) {\n- rows += `<tr><td><b>{$ trans \"On Order\" %}</b></td><td>${part.on_order}</td></tr>`;\n+ if (part.ordering) {\n+ rows += `<tr><td><b>{% trans \"On Order\" %}</b></td><td>${part.ordering}</td></tr>`;\n}\nif (part.building) {\n@@ -1322,32 +1324,48 @@ function loadPartTable(table, url, options={}) {\ncolumns.push(col);\ncol = {\n- field: 'in_stock',\n- title: '{% trans \"Stock\" %}',\n+ field: 'unallocated_stock',\n+ title: '{% trans \"Available\" %}',\nsearchable: false,\nformatter: function(value, row) {\nvar link = '?display=part-stock';\n- if (value) {\n+ if (row.in_stock) {\n// There IS stock available for this part\n// Is stock \"low\" (below the 'minimum_stock' quantity)?\n- if (row.minimum_stock && row.minimum_stock > value) {\n+ if (row.minimum_stock && row.minimum_stock > row.in_stock) {\nvalue += `<span class='badge badge-right rounded-pill bg-warning'>{% trans \"Low stock\" %}</span>`;\n+ } else if (value == 0) {\n+ if (row.ordering) {\n+ // There is no available stock, but stock is on order\n+ value = `0<span class='badge badge-right rounded-pill bg-info'>{% trans \"On Order\" %}: ${row.ordering}</span>`;\n+ link = '?display=purchase-orders';\n+ } else if (row.building) {\n+ // There is no available stock, but stock is being built\n+ value = `0<span class='badge badge-right rounded-pill bg-info'>{% trans \"Building\" %}: ${row.building}</span>`;\n+ link = '?display=build-orders';\n+ } else {\n+ // There is no available stock\n+ value = `0<span class='badge badge-right rounded-pill bg-warning'>{% trans \"Not available\" %}</span>`;\n+ }\n}\n+ } else {\n+ // There IS NO stock available for this part\n- } else if (row.on_order) {\n- // There is no stock available, but stock is on order\n- value = `0<span class='badge badge-right rounded-pill bg-info'>{% trans \"On Order\" %}: ${row.on_order}</span>`;\n+ if (row.ordering) {\n+ // There is no stock, but stock is on order\n+ value = `0<span class='badge badge-right rounded-pill bg-info'>{% trans \"On Order\" %}: ${row.ordering}</span>`;\nlink = '?display=purchase-orders';\n} else if (row.building) {\n- // There is no stock available, but stock is being built\n+ // There is no stock, but stock is being built\nvalue = `0<span class='badge badge-right rounded-pill bg-info'>{% trans \"Building\" %}: ${row.building}</span>`;\nlink = '?display=build-orders';\n} else {\n- // There is no stock available\n+ // There is no stock\nvalue = `0<span class='badge badge-right rounded-pill bg-danger'>{% trans \"No Stock\" %}</span>`;\n}\n+ }\nreturn renderLink(value, `/part/${row.pk}/${link}`);\n}\n",
        "chatgpt_cot": "Refactor is_moving, is_attacking, is_gathering, order_target, and surplus_harvesters properties to use ability.id, improving code readability and maintainability."
    },
    {
        "org_diff": "diff --git a/fkie_node_manager/src/fkie_node_manager/MainWindow.ui b/fkie_node_manager/src/fkie_node_manager/MainWindow.ui @@ -874,7 +874,14 @@ p, li { white-space: pre-wrap; }\n</widget>\n</item>\n<item>\n- <widget class=\"QWebView\" name=\"ui_help_web_view\"/>\n+ <widget class=\"QWebView\" name=\"ui_help_web_view\">\n+ <property name=\"sizePolicy\">\n+ <sizepolicy hsizetype=\"Expanding\" vsizetype=\"Expanding\">\n+ <horstretch>0</horstretch>\n+ <verstretch>0</verstretch>\n+ </sizepolicy>\n+ </property>\n+ </widget>\n</item>\n</layout>\n</widget>\n",
        "org_msg": "further fix for help view",
        "sim_msg": "add functionality in gui report codings\nadd functionality for whole sentence coding by found text\nadd functionality to add context to code snippets",
        "sim_diff": "diff --git a/GUI_UIs/ui_dialog_report_codings.ui b/GUI_UIs/ui_dialog_report_codings.ui <widget class=\"QPushButton\" name=\"pushButton_caseselect\">\n<property name=\"geometry\">\n<rect>\n- <x>390</x>\n+ <x>420</x>\n<y>50</y>\n<width>191</width>\n<height>27</height>\n<widget class=\"QPushButton\" name=\"pushButton_fileselect\">\n<property name=\"geometry\">\n<rect>\n- <x>390</x>\n+ <x>420</x>\n<y>20</y>\n<width>191</width>\n<height>27</height>\n<widget class=\"QPushButton\" name=\"pushButton_search\">\n<property name=\"geometry\">\n<rect>\n- <x>610</x>\n+ <x>630</x>\n<y>30</y>\n<width>121</width>\n<height>61</height>\n<widget class=\"QLabel\" name=\"label_2\">\n<property name=\"geometry\">\n<rect>\n- <x>10</x>\n- <y>30</y>\n+ <x>20</x>\n+ <y>0</y>\n<width>61</width>\n<height>22</height>\n</rect>\n<widget class=\"QComboBox\" name=\"comboBox_coders\">\n<property name=\"geometry\">\n<rect>\n- <x>90</x>\n+ <x>10</x>\n<y>20</y>\n- <width>221</width>\n- <height>34</height>\n+ <width>211</width>\n+ <height>30</height>\n</rect>\n</property>\n</widget>\n<widget class=\"QPushButton\" name=\"pushButton_attributeselect\">\n<property name=\"geometry\">\n<rect>\n- <x>390</x>\n+ <x>420</x>\n<y>80</y>\n<width>191</width>\n<height>27</height>\n<string>Export csv file</string>\n</property>\n</widget>\n+ <widget class=\"QCheckBox\" name=\"checkBox_by_sentence\">\n+ <property name=\"geometry\">\n+ <rect>\n+ <x>230</x>\n+ <y>80</y>\n+ <width>171</width>\n+ <height>23</height>\n+ </rect>\n+ </property>\n+ <property name=\"text\">\n+ <string>by sentence</string>\n+ </property>\n+ </widget>\n+ <widget class=\"QCheckBox\" name=\"checkBox_text_context\">\n+ <property name=\"geometry\">\n+ <rect>\n+ <x>230</x>\n+ <y>20</y>\n+ <width>181</width>\n+ <height>23</height>\n+ </rect>\n+ </property>\n+ <property name=\"text\">\n+ <string>text context</string>\n+ </property>\n+ </widget>\n</widget>\n</item>\n<item>\n<property name=\"text\">\n<string>Search selections:</string>\n</property>\n+ <property name=\"scaledContents\">\n+ <bool>true</bool>\n+ </property>\n<property name=\"wordWrap\">\n<bool>true</bool>\n</property>\n",
        "chatgpt_cot": "\"Update size policy for QWebView in MainWindow.ui to allow for expanding, fixing layout issue.\""
    },
    {
        "org_diff": "diff --git a/fkie_node_manager/src/fkie_node_manager/master_view_proxy.py b/fkie_node_manager/src/fkie_node_manager/master_view_proxy.py @@ -2684,7 +2684,9 @@ class MasterViewProxy(QWidget):\nif self._progress_queue.count() < 5:\nqueue = self._progress_queue\nkey_mod = QApplication.keyboardModifiers()\n- use_log_widget = not nm.settings().open_screen_on_activate\n+ use_log_widget = activated\n+ if nm.settings().open_screen_on_activate:\n+ use_log_widget = not activated\nif activated and (key_mod & Qt.ShiftModifier or key_mod & Qt.ControlModifier):\n# show ROS log if shift or control was pressed while activating\nif use_log_widget:\n",
        "org_msg": "fkie_node_manager: fixed 'Open screen on activate' option",
        "sim_msg": "Fix proxy connection: pickling changes broke it.",
        "sim_diff": "diff --git a/mitogen/master.py b/mitogen/master.py @@ -715,15 +715,38 @@ class Context(mitogen.core.Context):\nreturn self.call_with_deadline(None, False, fn, *args, **kwargs)\n-def _proxy_connect(mitogen, name, context_id, klass, kwargs):\n- if not isinstance(mitogen.router, Router): # TODO\n- mitogen.router.__class__ = Router # TODO\n+\n+def _local_method():\n+ return Stream\n+\n+def _ssh_method():\n+ import mitogen.ssh\n+ return mitogen.ssh.Stream\n+\n+def _sudo_method():\n+ import mitogen.sudo\n+ return mitogen.sudo.Stream\n+\n+\n+METHOD_NAMES = {\n+ 'local': _local_method,\n+ 'ssh': _ssh_method,\n+ 'sudo': _sudo_method,\n+}\n+\n+\n+def upgrade_router(econtext):\n+ if not isinstance(econtext.router, Router): # TODO\n+ econtext.router.__class__ = Router # TODO\nLOG.debug('_proxy_connect(): constructing ModuleForwarder')\n- ModuleForwarder(mitogen.router, mitogen.parent, mitogen.importer)\n+ ModuleForwarder(econtext.router, econtext.parent, econtext.importer)\n+\n- context = mitogen.router._connect(\n+def _proxy_connect(econtext, name, context_id, method_name, kwargs):\n+ upgrade_router(econtext)\n+ context = econtext.router._connect(\ncontext_id,\n- klass,\n+ METHOD_NAMES[method_name](),\nname=name,\n**kwargs\n)\n@@ -759,15 +782,13 @@ class Router(mitogen.core.Router):\nreturn self._context_by_id.get(context_id)\ndef local(self, **kwargs):\n- return self.connect(Stream, **kwargs)\n+ return self.connect('local', **kwargs)\ndef sudo(self, **kwargs):\n- import mitogen.sudo\n- return self.connect(mitogen.sudo.Stream, **kwargs)\n+ return self.connect('sudo', **kwargs)\ndef ssh(self, **kwargs):\n- import mitogen.ssh\n- return self.connect(mitogen.ssh.Stream, **kwargs)\n+ return self.connect('ssh', **kwargs)\ndef _connect(self, context_id, klass, name=None, **kwargs):\ncontext = Context(self, context_id)\n@@ -779,22 +800,22 @@ class Router(mitogen.core.Router):\nself.register(context, stream)\nreturn context\n- def connect(self, klass, name=None, **kwargs):\n+ def connect(self, method_name, name=None, **kwargs):\n+ klass = METHOD_NAMES[method_name]()\nkwargs.setdefault('debug', self.debug)\nvia = kwargs.pop('via', None)\nif via is not None:\n- return self.proxy_connect(via, klass, name=name, **kwargs)\n-\n+ return self.proxy_connect(via, method_name, name=name, **kwargs)\ncontext_id = self.context_id_counter.next()\nreturn self._connect(context_id, klass, name=name, **kwargs)\n- def proxy_connect(self, via_context, klass, name=None, **kwargs):\n+ def proxy_connect(self, via_context, method_name, name=None, **kwargs):\ncontext_id = self.context_id_counter.next()\n# Must be added prior to _proxy_connect() to avoid a race.\nself.add_route(context_id, via_context.context_id)\nname = via_context.call_with_deadline(None, True,\n- _proxy_connect, name, context_id, klass, kwargs\n+ _proxy_connect, name, context_id, method_name, kwargs\n)\n# name = '%s.%s' % (via_context.name, name)\ncontext = Context(self, context_id, name=name)\n",
        "chatgpt_cot": "Fix logic error in MasterViewProxy to correctly set use_log_widget based on nm settings and activation status."
    },
    {
        "org_diff": "diff --git a/sc2/unit.py b/sc2/unit.py @@ -299,11 +299,14 @@ class Unit:\n@property\ndef movement_speed(self) -> float:\n- \"\"\" Returns the movement speed of the unit. Does not include upgrades or buffs. \"\"\"\n+ \"\"\" Returns the movement speed of the unit.\n+ This is the unit movement speed on game speed 'normal'. To convert it to 'faster' movement speed, multiply it by a factor of '1.4'. E.g. reaper movement speed is listed here as 3.75, but should actually be 5.25.\n+ Does not include upgrades or buffs. \"\"\"\nreturn self._type_data._proto.movement_speed\n@property\ndef real_speed(self) -> float:\n+ \"\"\" See 'calculate_speed'. \"\"\"\nreturn self.calculate_speed()\ndef calculate_speed(self, upgrades: Set[UpgradeId] = None) -> float:\n@@ -376,7 +379,7 @@ class Unit:\n@property\ndef health_percentage(self) -> float:\n\"\"\" Returns the percentage of health the unit has. Does not include shields. \"\"\"\n- if self._proto.health_max == 0:\n+ if not self._proto.health_max:\nreturn 0\nreturn self._proto.health / self._proto.health_max\n@@ -393,7 +396,7 @@ class Unit:\n@property\ndef shield_percentage(self) -> float:\n\"\"\" Returns the percentage of shield points the unit has. Returns 0 for non-protoss units. \"\"\"\n- if self._proto.shield_max == 0:\n+ if not self._proto.shield_max:\nreturn 0\nreturn self._proto.shield / self._proto.shield_max\n@@ -402,7 +405,7 @@ class Unit:\n\"\"\" Returns the percentage of combined shield + hp points the unit has.\nAlso takes build progress into account. \"\"\"\nmax_ = (self._proto.shield_max + self._proto.health_max) * self.build_progress\n- if max_ == 0:\n+ if not max_:\nreturn 0\nreturn (self._proto.shield + self._proto.health) / max_\n@@ -419,7 +422,7 @@ class Unit:\n@property\ndef energy_percentage(self) -> float:\n\"\"\" Returns the percentage of amount of energy the unit has. Returns 0 for units without energy. \"\"\"\n- if self._proto.energy_max == 0:\n+ if not self._proto.energy_max:\nreturn 0\nreturn self._proto.energy / self._proto.energy_max\n",
        "org_msg": "Add more docstring info to movement_speed",
        "sim_msg": "numeric keys in fps mapping dictionary instead of strings",
        "sim_diff": "diff --git a/avalon/maya/commands.py b/avalon/maya/commands.py @@ -34,29 +34,22 @@ def reset_frame_range():\ncmds.warning(\"No edit information found for %s\" % shot[\"name\"])\nreturn\n- # this handles fps set as decimal number. For example\n- # fps 25.0 is corrected to int so mapping will still work\n- avalon_fps = api.Session.get(\"AVALON_FPS\")\n- d, i = math.modf(float(api.Session.get(\"AVALON_FPS\", 25)))\n- if d == 0.0:\n- avalon_fps = int(i)\n-\n- fps = {'15': 'game',\n- '24': 'film',\n- '25': 'pal',\n- '30': 'ntsc',\n- '48': 'show',\n- '50': 'palf',\n- '60': 'ntscf',\n- '23.98': '23.976fps',\n- '23.976': '23.976fps',\n- '29.97': '29.97fps',\n- '47.952': '47.952fps',\n- '47.95': '47.952fps',\n- '59.94': '59.94fps',\n- '44100': '44100fps',\n- '48000': '48000fps'\n- }.get(str(avalon_fps), \"pal\") # Default to \"pal\"\n+ fps = {15: 'game',\n+ 24: 'film',\n+ 25: 'pal',\n+ 30: 'ntsc',\n+ 48: 'show',\n+ 50: 'palf',\n+ 60: 'ntscf',\n+ 23.98: '23.976fps',\n+ 23.976: '23.976fps',\n+ 29.97: '29.97fps',\n+ 47.952: '47.952fps',\n+ 47.95: '47.952fps',\n+ 59.94: '59.94fps',\n+ 44100: '44100fps',\n+ 48000: '48000fps'\n+ }.get(float(api.Session.get(\"AVALON_FPS\", 25)), \"pal\")\ncmds.currentUnit(time=fps)\n",
        "chatgpt_cot": "Improve documentation for movement speed and health/shield/energy percentage calculations in Unit class in sc2/unit.py."
    },
    {
        "org_diff": "diff --git a/src/modules/cluster.py b/src/modules/cluster.py @@ -150,6 +150,7 @@ class ClusterHandler(object):\nrequest_port_num = \\\nlen(ORDERER_SERVICE_PORTS.items()) + \\\nlen(ca_service_ports.items()) * ca_num + \\\n+ len(EXPLORER_PORT.items()) + \\\nsize * (len(peer_service_ports.items()))\nlogger.debug(\"request port number {}\".format(request_port_num))\n@@ -195,8 +196,8 @@ class ClusterHandler(object):\npos += 1\nfor k, v in EXPLORER_PORT.items():\n- explorer_mapped_port[k] = \\\n- v - PEER_SERVICE_PORTS['rest'] + start_port\n+ explorer_mapped_port[k] = ports[pos]\n+ pos += 1\nmapped_ports.update(peers_ports)\nmapped_ports.update(ca_mapped_ports)\n@@ -277,6 +278,9 @@ class ClusterHandler(object):\nfor k, v in orderer_service_ports.items():\nservice_urls[k] = \"{}:{}\".format(ca_host_ip, v)\n+ for k, v in explorer_mapped_port.items():\n+ service_urls[k] = \"{}:{}\".format(peer_host_ip, v)\n+\nfor k, v in service_urls.items():\nservice_port = ServicePort(name=k, ip=v.split(\":\")[0],\nport=int(v.split(\":\")[1]),\n",
        "org_msg": "Fix create chain map port for explorer\nFix use same port mapping for explorer",
        "sim_msg": "Fix multi_cluster.py",
        "sim_diff": "diff --git a/quarkchain/cluster/multi_cluster.py b/quarkchain/cluster/multi_cluster.py @@ -14,17 +14,19 @@ async def main():\nparser.add_argument(\n\"--port_start\", default=cl.PORT, type=int)\nparser.add_argument(\n- \"--db_prefix\", default=\"./db_\", type=str)\n+ \"--db_path_root\", default=\"./db\", type=str)\nparser.add_argument(\n\"--p2p_port\", default=48291, type=int)\nparser.add_argument(\n- \"--json_rpc_port\", default=58291, type=int)\n+ \"--json_rpc_port\", default=48391, type=int)\n+ parser.add_argument(\n+ \"--json_rpc_private_port\", default=48491, type=int)\nparser.add_argument(\n\"--seed_host\", default=cl.DEFAULT_ENV.config.P2P_SEED_HOST)\nparser.add_argument(\n\"--seed_port\", default=cl.DEFAULT_ENV.config.P2P_SEED_PORT)\nparser.add_argument(\n- \"--clean\", default=True)\n+ \"--clean\", default=False)\nparser.add_argument(\n\"--devp2p\", default=True, type=bool)\nparser.add_argument(\n@@ -54,9 +56,10 @@ async def main():\np2pPort=args.p2p_port + i,\nclusterPortStart=args.port_start + i * 100,\njsonRpcPort=args.json_rpc_port + i,\n+ jsonRpcPrivatePort=args.json_rpc_private_port + i,\nseedHost=args.seed_host,\nseedPort=args.seed_port,\n- dbPrefix=\"{}C{}_\".format(args.db_prefix, i),\n+ dbPathRoot=\"{}_C{}\".format(args.db_path_root, i),\ndevp2p=args.devp2p,\ndevp2p_port=args.devp2p_start_port + i,\ndevp2p_bootstrap_host=args.devp2p_bootstrap_host,\n",
        "chatgpt_cot": "Add Explorer port to ClusterHandler, update service URLs for Explorer. Fix port mapping issue."
    },
    {
        "org_diff": "diff --git a/fkie_node_manager/src/fkie_node_manager/main_window.py b/fkie_node_manager/src/fkie_node_manager/main_window.py @@ -2003,11 +2003,11 @@ class MainWindow(QMainWindow):\n'''\nif self.currentMaster:\ntry:\n- if not os.path.isdir(nm.settings().ROBOTS_DIR):\n- os.makedirs(nm.settings().ROBOTS_DIR)\n+ if not os.path.isdir(nm.settings().robots_path):\n+ os.makedirs(nm.settings().robots_path)\n(fileName, _) = QFileDialog.getOpenFileName(self,\n\"Set robot image\",\n- nm.settings().ROBOTS_DIR,\n+ nm.settings().robots_path,\n\"Image files (*.bmp *.gif *.jpg *.jpeg *.png *.pbm *.xbm);;All files (*)\")\nif fileName and self.__current_master_label_name:\np = QPixmap(fileName)\n",
        "org_msg": "fix set robot image",
        "sim_msg": "open projet now recognises default directory",
        "sim_diff": "diff --git a/qualcoder/qualcoder.py b/qualcoder/qualcoder.py @@ -833,9 +833,11 @@ class MainWindow(QtWidgets.QMainWindow):\nself.close_project()\nself.setWindowTitle(\"QualCoder\" + _(\"Open Project\"))\nif path == \"\" or path is False:\n- #print(\"appsettings dir \", self.app.settings['directory'], os.path.expanduser('~') ) # tmp\n+ default_directory = self.app.settings['directory']\n+ if default_directory == \"\":\n+ default_directory = os.path.expanduser('~')\npath = QtWidgets.QFileDialog.getExistingDirectory(self,\n- _('Open project directory'), os.path.expanduser('~') )\n+ _('Open project directory'), default_directory)\nif path == \"\" or path is False:\nreturn\nmsg = \"\"\n",
        "chatgpt_cot": "Refactor robots directory path in MainWindow class to use settings attribute directly, enhancing readability and maintainability."
    },
    {
        "org_diff": "diff --git a/rasa_core_sdk/forms.py b/rasa_core_sdk/forms.py @@ -37,7 +37,7 @@ class FormAction(Action):\nexisting_val = tracker.get_slot(slot_name)\nreturn existing_val is None\n- def validate(self, dispatcher, tracker):\n+ def validate(self, dispatcher, tracker, domain):\n# type: (Tracker) -> Dict[Text, Any]\n\"\"\"\"Validate the user input.\"\"\"\n@@ -64,12 +64,13 @@ class FormAction(Action):\ndef run(self, dispatcher, tracker, domain):\nif tracker.active_form == self.name() and tracker.latest_action_name == 'action_listen':\n- events = self.validate(dispatcher, tracker)\n+ events = self.validate(dispatcher, tracker, domain)\nelse:\nevents = []\ntemp_tracker = tracker.copy()\nfor e in events:\n+ if e['event'] == 'slot':\ntemp_tracker.slots[e[\"name\"]] = e[\"value\"]\nfor slot in self.required_slots():\nif self.should_request_slot(temp_tracker, slot):\n",
        "org_msg": "make validate signature the same as run",
        "sim_msg": "Allow users with names longer than the current limit to log in",
        "sim_diff": "diff --git a/app/forms/user.py b/app/forms/user.py @@ -78,7 +78,7 @@ class UsernameLength:\nclass LoginForm(RedirectForm):\n\"\"\" Login form. \"\"\"\n- username = StringField(_l(\"Username\"), validators=[UsernameLength()])\n+ username = StringField(_l(\"Username\"), validators=[Length(max=256)])\npassword = PasswordField(\n_l(\"Password\"), validators=[DataRequired(), Length(min=7, max=256)]\n)\n",
        "chatgpt_cot": "Fix compilation issue by adding a parameter to the validate method in FormAction to match method signature, ensuring compatibility with the Tracker and domain."
    },
    {
        "org_diff": "diff --git a/sc2/bot_ai.py b/sc2/bot_ai.py @@ -552,6 +552,9 @@ class BotAI:\nfor unit in self.units.not_structure:\nif unit.tag not in self._units_previous_map:\nawait self.on_unit_created(unit)\n+ for unit in self.units.structure:\n+ if unit.tag not in self._units_previous_map:\n+ await self.on_building_construction_started(unit)\nasync def _issue_building_complete_event(self, unit):\nif unit.build_progress < 1:\n@@ -576,6 +579,10 @@ class BotAI:\n\"\"\" Override this in your bot class. \"\"\"\npass\n+ async def on_building_construction_started(self, unit: Unit):\n+ \"\"\" Override this in your bot class. \"\"\"\n+ pass\n+\nasync def on_building_construction_complete(self, unit: Unit):\n\"\"\" Override this in your bot class. \"\"\"\npass\n",
        "org_msg": "Adds 'on_building_construction_started' event hook to the bot.",
        "sim_msg": "add function for checking my new dog's age in years",
        "sim_diff": "diff --git a/pajbot/bot.py b/pajbot/bot.py @@ -217,6 +217,7 @@ class Bot:\nself.data_cb['stream_status'] = self.c_stream_status\nself.data_cb['bot_uptime'] = self.c_uptime\nself.data_cb['current_time'] = self.c_current_time\n+ self.data_cb['molly_age_in_years'] = self.c_molly_age_in_years\nself.silent = True if args.silent else self.silent\n@@ -477,6 +478,12 @@ class Bot:\ndef c_current_time(self):\nreturn datetime.datetime.now()\n+ def c_molly_age_in_years(self):\n+ molly_birth = datetime.datetime(2018, 10, 29)\n+ now = datetime.datetime.now()\n+ diff = now-molly_birth\n+ return diff.total_seconds()/3600/24/365\n+\n@property\ndef is_online(self):\nreturn self.stream_manager.online\n",
        "chatgpt_cot": "Add new method `on_building_construction_started` in BotAI class to handle building construction events for better event handling and organization."
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/master_view_proxy.py b/node_manager_fkie/src/node_manager_fkie/master_view_proxy.py @@ -48,6 +48,7 @@ from master_discovery_fkie.common import masteruri_from_ros\nfrom master_discovery_fkie.master_info import NodeInfo\nfrom node_manager_daemon_fkie.common import interpret_path, utf8\nfrom node_manager_daemon_fkie.host import get_hostname, get_port\n+from node_manager_daemon_fkie import exceptions\nfrom node_manager_daemon_fkie import url as nmdurl\nfrom .common import package_name\nfrom .detailed_msg_box import MessageBox, DetailedError\n@@ -2498,6 +2499,9 @@ class MasterViewProxy(QWidget):\nnm.nmd().unload_launch(cfg, self.masteruri)\ndel self.__configs[cfg]\nnm.nmd().get_nodes_threaded(cfg)\n+ except exceptions.ResourceNotFound:\n+ del self.__configs[cfg]\n+ nm.nmd().get_nodes_threaded(cfg)\nexcept Exception:\nrospy.logwarn(traceback.format_exc())\n",
        "org_msg": "node_manager_fkie: fixed error while reload file on new node manager daemon",
        "sim_msg": "make ping checks on the connected domains to network parallel",
        "sim_diff": "diff --git a/packages/syft/src/syft/core/node/common/client_manager/domain_api.py b/packages/syft/src/syft/core/node/common/client_manager/domain_api.py @@ -14,6 +14,9 @@ from .....core.common.uid import UID\nfrom .....grid.client.proxy_client import ProxyClient\nfrom .....lib.python import String\nfrom .....logger import error\n+from .....logger import start\n+from .....logger import stop\n+from .....util import parallel_execution\nfrom ....node.common import AbstractNodeClient\nfrom ..node_service.peer_discovery.peer_discovery_messages import (\nGetPeerInfoMessageWithReply,\n@@ -47,26 +50,22 @@ class DomainRequestAPI(RequestAPI):\n):\n# check for logged in domains if the number of possible domains changes (if a new domain shows up)\nself.num_known_domains_even_offline_ones = len(_data)\n+ n = len(_data)\ndata = list()\n- for i, domain_metadata in enumerate(_data):\n- sys.stdout.write(\n- \"\\rChecking whether domains are online: \"\n- + str(i + 1)\n- + \" of \"\n- + str(len(_data))\n- )\n- try:\n- # syft absolute\n- import syft\n-\n- syft.logger.stop()\n- if self.get(domain_metadata[\"id\"]).ping:\n- data.append(domain_metadata)\n- syft.logger.start()\n- except Exception: # nosec\n- # if pinging the domain causes an exception we just wont\n- # include it in the array\n- pass\n+\n+ args = [\n+ (self, i, n, domain_metadata[\"id\"])\n+ for i, domain_metadata in enumerate(_data)\n+ ]\n+\n+ # Check domain status in parallel\n+ check_status = parallel_execution(check_domain_status)\n+ result = check_status(args=args) if args else []\n+\n+ for i, status in enumerate(result):\n+ if status is True:\n+ data.append(_data[i])\n+\nsys.stdout.write(\"\\r \")\nself.cache = data\n@@ -122,3 +121,25 @@ class DomainRequestAPI(RequestAPI):\ndef __getitem__(self, key: Union[str, int, UID]) -> ProxyClient:\nreturn self.get(key=key)\n+\n+\n+def check_domain_status(\n+ self: DomainRequestAPI, i: int, n: int, domain_uid: str\n+) -> bool:\n+\n+ sys.stdout.write(\n+ \"\\rChecking whether domains are online: \" + str(i + 1) + \" of \" + str(n)\n+ )\n+\n+ status = False\n+ try:\n+ stop()\n+ status = self.get(domain_uid).ping\n+ start()\n+ except Exception as e: # nosec\n+ # if pinging the domain causes an exception we just wont\n+ # include it in the array\n+ print(\"Error\", e)\n+ pass\n+\n+ return status\n",
        "chatgpt_cot": "Add exception handling for ResourceNotFound in MasterViewProxy to handle resource not found issue during node retrieval."
    },
    {
        "org_diff": "diff --git a/fkie_node_manager/src/fkie_node_manager/logscreen/logger_handler.py b/fkie_node_manager/src/fkie_node_manager/logscreen/logger_handler.py @@ -93,9 +93,13 @@ class LoggerHandler(QObject):\nself._thread_update = None\ndef _handle_loggers(self, loggers):\n+ stored_values = {}\nwhile self.layout.count() > 1:\nitem = self.layout.takeAt(0)\n- item.widget().setParent(None)\n+ wd = item.widget()\n+ if wd.current_level is not None:\n+ stored_values[wd.loggername] = wd.current_level\n+ wd.setParent(None)\nself._logger_items.clear()\nall_item = LoggerItem(self.nodename, 'all', '')\nall_item.set_callback(self.change_all)\n@@ -105,6 +109,8 @@ class LoggerHandler(QObject):\nitem = LoggerItem(self.nodename, logger.name, logger.level)\nself._logger_items[logger.name] = item\nself.layout.insertWidget(index, item)\n+ if logger.name in stored_values and stored_values[logger.name] != logger.level:\n+ item.set_level(stored_values[logger.name])\nindex += 1\ndef change_all(self, loglevel, ignore=['ros.roscpp.roscpp_internal',\n",
        "org_msg": "fkie_node_manager: set loglevel after restart of node while screen widget is open",
        "sim_msg": "Add docstrings to set_global_logger_level",
        "sim_diff": "diff --git a/qlib/log.py b/qlib/log.py @@ -165,14 +165,79 @@ class LogFilter(logging.Filter):\nreturn allow\n-@contextmanager\n-def set_global_logger_level(level: int):\n+def set_global_logger_level(level: int, return_orig_handler_level: bool = False):\n+ \"\"\"set qlib.xxx logger handlers level\n+\n+ Parameters\n+ ----------\n+ level: int\n+ logger level\n+\n+ return_orig_handler_level: bool\n+ return origin handler level map\n+\n+ Examples\n+ ---------\n+\n+ .. code-block:: python\n+\n+ import qlib\n+ import logging\n+ from qlib.log import get_module_logger, set_global_logger_level\n+ qlib.init()\n+\n+ tmp_logger_01 = get_module_logger(\"tmp_logger_01\", level=logging.INFO)\n+ tmp_logger_01.info(\"1. tmp_logger_01 info show\")\n+\n+ global_level = logging.WARNING + 1\n+ set_global_logger_level(global_level)\n+ tmp_logger_02 = get_module_logger(\"tmp_logger_02\", level=logging.INFO)\n+ tmp_logger_02.log(msg=\"2. tmp_logger_02 log show\", level=global_level)\n+\n+ tmp_logger_01.info(\"3. tmp_logger_01 info do not show\")\n+\n+ \"\"\"\n_handler_level_map = {}\nqlib_logger = logging.root.manager.loggerDict.get(\"qlib\", None)\nif qlib_logger is not None:\nfor _handler in qlib_logger.handlers:\n_handler_level_map[_handler] = _handler.level\n_handler.level = level\n+ return _handler_level_map if return_orig_handler_level else None\n+\n+\n+@contextmanager\n+def set_global_logger_level_cm(level: int):\n+ \"\"\"set qlib.xxx logger handlers level to use contextmanager\n+\n+ Parameters\n+ ----------\n+ level: int\n+ logger level\n+\n+ Examples\n+ ---------\n+\n+ .. code-block:: python\n+\n+ import qlib\n+ import logging\n+ from qlib.log import get_module_logger, set_global_logger_level_cm\n+ qlib.init()\n+\n+ tmp_logger_01 = get_module_logger(\"tmp_logger_01\", level=logging.INFO)\n+ tmp_logger_01.info(\"1. tmp_logger_01 info show\")\n+\n+ global_level = logging.WARNING + 1\n+ with set_global_logger_level_cm(global_level):\n+ tmp_logger_02 = get_module_logger(\"tmp_logger_02\", level=logging.INFO)\n+ tmp_logger_02.log(msg=\"2. tmp_logger_02 log show\", level=global_level)\n+ tmp_logger_01.info(\"3. tmp_logger_01 info do not show\")\n+\n+ tmp_logger_01.info(\"4. tmp_logger_01 info show\")\n+\n+ \"\"\"\n+ _handler_level_map = set_global_logger_level(level, return_orig_handler_level=True)\ntry:\nyield\nfinally:\n",
        "chatgpt_cot": "\"Fix logger handler to correctly store and restore logger levels during layout update\""
    },
    {
        "org_diff": "diff --git a/fkie_node_manager_daemon/src/fkie_node_manager_daemon/launcher.py b/fkie_node_manager_daemon/src/fkie_node_manager_daemon/launcher.py @@ -193,6 +193,12 @@ def run_node(startcfg):\ncwd = get_cwd(startcfg.cwd, cmd_type)\n# set environment\nnew_env = dict(os.environ)\n+ # set display variable to local display\n+ if 'DISPLAY' in startcfg.env:\n+ if not startcfg.env['DISPLAY'] or startcfg.env['DISPLAY'] == 'remote':\n+ del startcfg.env['DISPLAY']\n+ else:\n+ new_env['DISPLAY'] = ':0'\n# add environment from launch\nnew_env.update(startcfg.env)\nif startcfg.namespace:\n",
        "org_msg": "set on remote hosts the DISPLAY to :0\nthis can be avoided by adding env parameter for DISPLAY with empty value\nto launch file",
        "sim_msg": "retry startup",
        "sim_diff": "diff --git a/lbrynet/lbrynet_daemon/DaemonControl.py b/lbrynet/lbrynet_daemon/DaemonControl.py @@ -114,7 +114,7 @@ def update_settings_from_args(args):\n@defer.inlineCallbacks\n-def start_server_and_listen(launchui, use_auth, analytics_manager):\n+def start_server_and_listen(launchui, use_auth, analytics_manager, max_tries=5):\n\"\"\"The primary entry point for launching the daemon.\nArgs:\n@@ -124,13 +124,19 @@ def start_server_and_listen(launchui, use_auth, analytics_manager):\n\"\"\"\nanalytics_manager.send_server_startup()\nlog_support.configure_analytics_handler(analytics_manager)\n+ tries = 1\n+ while tries < max_tries:\n+ log.info('Making attempt %s / %s to startup', tries, max_tries)\ntry:\ndaemon_server = DaemonServer(analytics_manager)\nyield daemon_server.start(use_auth, launchui)\nanalytics_manager.send_server_startup_success()\n+ break\nexcept Exception as e:\nlog.exception('Failed to startup')\nanalytics_manager.send_server_startup_error(str(e))\n+ tries += 1\n+ else:\nreactor.callFromThread(reactor.stop)\n",
        "chatgpt_cot": "Set local display variable in launcher.py to solve configuration issue. Update environment with new display setting."
    },
    {
        "org_diff": "diff --git a/examples/arcade_bot.py b/examples/arcade_bot.py @@ -79,7 +79,7 @@ class MarineSplitChallenge(sc2.BotAI):\nstutter_step_positions = {p for p in stutter_step_positions if self.in_pathing_grid(p)}\n# find position furthest away from enemies and closest to unit\n- enemies_in_range = self.known_enemy_units.filter(lambda u: unit.target_in_range(u, -0.5))\n+ enemies_in_range = self.enemy_units.filter(lambda u: unit.target_in_range(u, -0.5))\nif stutter_step_positions and enemies_in_range:\nretreat_position = max(\n",
        "org_msg": "`self.known_enemy_units` is deprecated,\nreplacing with `self.enemy_units`",
        "sim_msg": "added time to the saved files",
        "sim_diff": "diff --git a/bot_manager.py b/bot_manager.py @@ -178,7 +178,7 @@ class BotManager:\ncurrent_time = game_tick_packet.gameInfo.TimeSeconds\nif self.save_data and game_tick_packet.gameInfo.bRoundActive and not old_time == current_time and not current_time == -10:\n- np_input = self.input_converter.create_input_array(game_tick_packet)\n+ np_input = self.input_converter.create_input_array(game_tick_packet, passed_time=time.time() - before2)\nnp_output = np.array(controller_input, dtype=np.float32)\nself.input_array = np.append(self.input_array, np_input)\nself.output_array = np.append(self.output_array, np_output)\n",
        "chatgpt_cot": "\"Refactor enemy unit filtering in MarineSplitChallenge class\""
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/editor/text_edit.py b/node_manager_fkie/src/node_manager_fkie/editor/text_edit.py @@ -119,7 +119,7 @@ class TextEdit(QTextEdit):\nself._internal_args = get_internal_args(file_content)\nself.setText(file_content)\nself._is_launchfile = False\n- if ext[1] in ['.launch', '.xml', '.xacro', '.urdf']:\n+ if ext[1] in ['.launch', '.xml', '.xacro', '.srdf', '.urdf']:\nif ext[1] in ['.launch']:\nself._is_launchfile = True\nself.hl = XmlHighlighter(self.document(), is_launch=False)\n",
        "org_msg": "node_manager_fkie: editor: added .srdf to xml highlighter",
        "sim_msg": "Fixed: Missing/ doubled accelerators in settings menu",
        "sim_diff": "diff --git a/extension/textext/asktext.py b/extension/textext/asktext.py @@ -505,7 +505,7 @@ if TOOLKIT in (GTK, GTKSOURCEVIEW):\n('ViewMenu', None, '_View'),\n('SettingsMenu', None, '_Settings'),\n('NewNodeContent', None, '_New Node Content'),\n- ('CloseShortcut', None, '_Close TexText Shortcut'),\n+ ('CloseShortcut', None, 'Close TexText _Shortcut'),\n('TabsWidth', None, '_Tabs Width'),\n]\nelse:\n@@ -551,17 +551,17 @@ if TOOLKIT in (GTK, GTKSOURCEVIEW):\nself._new_node_content_actions = [\n# name of action , stock id, label, accelerator, tooltip, callback/value\n- ('NewNodeContentEmpty', None, 'Empty', None, 'New node will be initialized with empty content', 0),\n- ('NewNodeContentInlineMath', None, 'Inline math', None, 'New node will be initialized with $ $', 1),\n- ('NewNodeContentDisplayMath', None, 'Display math', None, 'New node will be initialized with $$ $$', 2)\n+ ('NewNodeContentEmpty', None, '_Empty', None, 'New node will be initialized with empty content', 0),\n+ ('NewNodeContentInlineMath', None, '_Inline math', None, 'New node will be initialized with $ $', 1),\n+ ('NewNodeContentDisplayMath', None, '_Display math', None, 'New node will be initialized with $$ $$', 2)\n]\nnew_node_content = \"\\n\".join(\n['<menuitem action=\\'%s\\'/>' % action for (action, _, _, _, _, _) in self._new_node_content_actions])\nself._close_shortcut_actions = [\n- ('CloseShortcutEscape', None, 'ESC', None, 'TexText window closes when pressing ESC', 0),\n- ('CloseShortcutCtrlQ', None, 'CTRL + Q', None, 'TexText window closes when pressing CTRL + Q', 1),\n- ('CloseShortcutNone', None, 'None', None, 'No shortcut for closing TexText window', 2)\n+ ('CloseShortcutEscape', None, '_ESC', None, 'TexText window closes when pressing ESC', 0),\n+ ('CloseShortcutCtrlQ', None, 'CTRL + _Q', None, 'TexText window closes when pressing CTRL + Q', 1),\n+ ('CloseShortcutNone', None, '_None', None, 'No shortcut for closing TexText window', 2)\n]\nclose_shortcut = \"\\n\".join(\n['<menuitem action=\\'%s\\'/>' % action for (action, _, _, _, _, _) in self._close_shortcut_actions])\n",
        "chatgpt_cot": "Add '.srdf' to the list of file extensions for _is_launchfile."
    },
    {
        "org_diff": "diff --git a/sc2/bot_ai.py b/sc2/bot_ai.py @@ -15,7 +15,6 @@ from .game_state import GameState\nfrom .ids.ability_id import AbilityId\nfrom .ids.unit_typeid import UnitTypeId\nfrom .ids.upgrade_id import UpgradeId\n-from .points import Points\nfrom .position import Point2, Point3\nfrom .unit import Unit\nfrom .units import Units\n",
        "org_msg": "Fix bot_ai.py",
        "sim_msg": "Forgot to update iNumPlayers",
        "sim_diff": "diff --git a/v3/runner.py b/v3/runner.py @@ -63,6 +63,8 @@ if __name__ == '__main__':\ncallbacks = []\nname_dict = dict()\n+ gameInputPacket.iNumPlayers = num_bots\n+\n# Set configuration values for bots and store name and team\nfor i in range(num_bots):\nbot_config = configparser.RawConfigParser()\n",
        "chatgpt_cot": "Remove unused import of Points class in bot_ai.py file."
    },
    {
        "org_diff": "diff --git a/sc2/bot_ai.py b/sc2/bot_ai.py @@ -158,7 +158,7 @@ class BotAI:\nif not location:\nlocation = await self.get_next_expansion()\n- else:\n+\nawait self.build(\nbuilding, near=location, max_distance=max_distance, random_alternative=False, placement_step=1\n)\n",
        "org_msg": "Fix bug in expand_now when location=None",
        "sim_msg": "Forgot to update iNumPlayers",
        "sim_diff": "diff --git a/v3/runner.py b/v3/runner.py @@ -63,6 +63,8 @@ if __name__ == '__main__':\ncallbacks = []\nname_dict = dict()\n+ gameInputPacket.iNumPlayers = num_bots\n+\n# Set configuration values for bots and store name and team\nfor i in range(num_bots):\nbot_config = configparser.RawConfigParser()\n",
        "chatgpt_cot": "Refactor build method in BotAI class to use await keyword for asynchronous operation."
    },
    {
        "org_diff": "diff --git a/fkie_multimaster_msgs/cmake/grpc_protoc.cmake b/fkie_multimaster_msgs/cmake/grpc_protoc.cmake @@ -2,13 +2,17 @@ include(CMakeParseArguments)\nmacro(generate_grpc)\nfind_program(PYTHON python)\n-\n+ if (NOT PYTHON)\n+ find_program(PYTHON python3)\n+ endif()\n+ if (NOT PYTHON)\n+ message(FATAL_ERROR \"python and python3 not found!\")\n+ endif()\n# we need (for code generation) the root where the package lib goes to\nget_filename_component(DST_ROOT ${CATKIN_DEVEL_PREFIX}/${CATKIN_PACKAGE_PYTHON_DESTINATION} DIRECTORY)\n# and also the multimaster_fkie absolute path\nget_filename_component(MM_ROOT ${PROJECT_SOURCE_DIR} DIRECTORY)\nset(GRPC_GENERATED_SRC_DIR \"${DST_ROOT}/${PROJECT_NAME}/grpc\")\n- # set(GRPC_GENERATED_SRC_DIR \"${PROJECT_SOURCE_DIR}/src/${PROJECT_NAME}\")\ncmake_parse_arguments(proto_arg \"\" \"\" \"PROTO_FILES\" ${ARGN})\nmessage(STATUS \"gRPC proto files: ${proto_arg_PROTO_FILES}\")\nset(GRPC_GENERATED_SOURCES \"\")\n",
        "org_msg": "added search for python3 while generate grpc code",
        "sim_msg": "call logger.error instead of prints in 'aea generate'",
        "sim_diff": "diff --git a/aea/cli/generate.py b/aea/cli/generate.py @@ -54,7 +54,7 @@ def _generate_item(ctx: Context, item_type, specification_path):\n# check protocol buffer compiler is installed\nres = shutil.which(\"protoc\")\nif res is None:\n- print(\n+ logger.error(\n\"Please install protocol buffer first! See the following link: https://developers.google.com/protocol-buffers/\"\n)\nsys.exit(1)\n@@ -62,7 +62,7 @@ def _generate_item(ctx: Context, item_type, specification_path):\n# check black code formatter is installed\nres = shutil.which(\"black\")\nif res is None:\n- print(\n+ logger.error(\n\"Please install black code formater first! See the following link: https://black.readthedocs.io/en/stable/installation_and_usage.html\"\n)\nsys.exit(1)\n",
        "chatgpt_cot": "Fix compilation issue by adding python3 as an alternative to python and displaying a fatal error message if neither python nor python3 is found."
    },
    {
        "org_diff": "diff --git a/sc2/units.py b/sc2/units.py @@ -101,6 +101,11 @@ class Units(list):\nposition = position.position\nreturn self.filter(lambda unit: unit.position.to2.distance_to(position.to2) < distance)\n+ def further_than(self, distance, position):\n+ if isinstance(position, Unit):\n+ position = position.position\n+ return self.filter(lambda unit: unit.position.to2.distance_to(position.to2) > distance)\n+\ndef subgroup(self, units):\nreturn Units(list(units), self.game_data)\n@@ -112,17 +117,17 @@ class Units(list):\ndef tags_in(self, other):\n\"\"\" Filters all units that have their tags in the 'other' set/list/dict \"\"\"\n- # example: self.queens.tags_in(self.queens_tags_assigned_to_do_injects)\n+ # example: self.units(QUEEN).tags_in(self.queen_tags_assigned_to_do_injects)\nreturn self.filter(lambda unit: unit.tag in other)\ndef tags_not_in(self, other):\n\"\"\" Filters all units that have their tags not in the 'other' set/list/dict \"\"\"\n- # example: self.queens.tags_not_in(self.queens_tags_assigned_to_do_injects)\n+ # example: self.units(QUEEN).tags_not_in(self.queen_tags_assigned_to_do_injects)\nreturn self.filter(lambda unit: unit.tag not in other)\ndef of_type(self, other):\n\"\"\" Filters all units that are of a specific type \"\"\"\n- # example: self.townhalls.of_type([HIVE])\n+ # example: self.units.of_type([ZERGLING, ROACH, HYDRALISK, BROODLORD])\nif not isinstance(other, (tuple, list, set, dict)):\nother = [other]\nreturn self.filter(lambda unit: unit.type_id in other)\n",
        "org_msg": "Add Units.further_than filter",
        "sim_msg": "Add types to remaining UML descriptors",
        "sim_diff": "diff --git a/gaphor/UML/properties.py b/gaphor/UML/properties.py @@ -37,6 +37,7 @@ from typing import (\nTypeVar,\nOptional,\nCallable,\n+ List,\nSet,\nUnion,\n)\n@@ -108,6 +109,7 @@ class relation_many(Protocol[E]):\nT = TypeVar(\"T\", covariant=True)\nA = TypeVar(\"A\", int, str)\n+Lower = Union[Literal[0], Literal[1]]\nUpper = Union[Literal[1], Literal[\"*\"]]\n@@ -124,7 +126,7 @@ class umlproperty(Generic[T]):\nfor example in the case of event handling.\n\"\"\"\n- lower: int = 0\n+ lower: Lower = 0\nupper: Upper = 1\ndef __init__(self):\n@@ -331,7 +333,7 @@ class association(umlproperty[T]):\nself,\nname: str,\ntype: Type,\n- lower: int = 0,\n+ lower: Lower = 0,\nupper: Upper = \"*\",\ncomposite: bool = False,\nopposite: Optional[str] = None,\n@@ -529,7 +531,7 @@ class associationstub(umlproperty[T]):\nare iterated and called by their unlink() method.\n\"\"\"\n- def __init__(self, association):\n+ def __init__(self, association: association):\nsuper().__init__()\nself.association = association\nself._name = \"_stub_%x\" % id(self)\n@@ -580,7 +582,7 @@ class unioncache:\nSmall cache helper object for derivedunions.\n\"\"\"\n- def __init__(self, data, version):\n+ def __init__(self, data: object, version: int) -> None:\nself.data = data\nself.version = version\n@@ -600,7 +602,15 @@ class derived(umlproperty[T]):\nopposite = None\n- def __init__(self, name, type, lower, upper, filter, *subsets):\n+ def __init__(\n+ self,\n+ name: str,\n+ type: Type[E],\n+ lower: Lower,\n+ upper: Upper,\n+ filter: Callable[[T], List[E]],\n+ *subsets: association,\n+ ) -> None:\nsuper().__init__()\nself.name = name\nself._name = \"_\" + name\n@@ -640,14 +650,8 @@ class derived(umlproperty[T]):\n\"Derived union %s of item %s should have length 1 %s\"\n% (self.name, obj.id, tuple(u))\n)\n- # maybe code below is better instead the assertion above?\n- # if len(u) > 1:\n- # log.warning('Derived union %s of item %s should have length 1 %s' % (self.name, obj.id, tuple(u)))\n- if u:\n- u = next(iter(u))\n+ uc = unioncache(u[0] if u else None, self.version)\nelse:\n- u = None\n-\nuc = unioncache(u, self.version)\nsetattr(obj, self._name, uc)\nreturn uc\n@@ -735,7 +739,14 @@ class derivedunion(derived[T]):\nThe subsets are the properties that participate in the union (Element.name).\n\"\"\"\n- def __init__(self, name, type, lower, upper, *subsets):\n+ def __init__(\n+ self,\n+ name: str,\n+ type: Type[E],\n+ lower: Lower,\n+ upper: Upper,\n+ *subsets: association,\n+ ):\nsuper().__init__(name, type, lower, upper, self._union, *subsets)\ndef _union(self, obj, exclude=None):\n@@ -835,7 +846,9 @@ class redefine(umlproperty[T]):\nit ensures that the original values are saved and restored.\n\"\"\"\n- def __init__(self, decl_class, name, type, original):\n+ def __init__(\n+ self, decl_class: Type[E], name: str, type: Type[T], original: association\n+ ):\nsuper().__init__()\nself.decl_class = decl_class\nself.name = name\n",
        "chatgpt_cot": "\"Add further_than method to Units class to filter units further than a certain distance, and update example comments to use units method instead of specific unit types.\""
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/launch_files_widget.py b/node_manager_fkie/src/node_manager_fkie/launch_files_widget.py @@ -302,8 +302,11 @@ class LaunchFilesWidget(QDockWidget):\nif event == QKeySequence.Delete:\nselected = self._pathItemsFromIndexes(self.ui_file_view.selectionModel().selectedIndexes(), False)\nfor item in selected:\n+ if item in nm.settings().launch_history:\nnm.settings().launch_history_remove(item.path)\nself.launchlist_model.reload_current_path()\n+ else:\n+ rospy.logwarn(\"Delete files not implemented!\")\nelif not key_mod and event.key() == Qt.Key_F4 and self.ui_button_edit.isEnabled():\n# open selected launch file in xml editor by F4\nself.on_edit_xml_clicked()\n",
        "org_msg": "node_manager_fkie: print warning on delete\ndelete file currently not implemented",
        "sim_msg": "better setting of focus when removing nodes",
        "sim_diff": "diff --git a/tree.py b/tree.py @@ -609,7 +609,7 @@ class WidgetTree(wx.TreeCtrl, Tree):\ndef remove(self, node=None, delete=True):\nself.app.saved = False # update the status of the app\n- set_focus = self.current is node.widget\n+ set_focus = self.current and ( self.current is node.widget or self.current.has_ancestor(node) )\nTree.remove(self, node)\nif node is not None:\nif delete:\n",
        "chatgpt_cot": "\"Add implementation to delete files from launch history\""
    },
    {
        "org_diff": "diff --git a/src/agent/ansible/roles/deploy_compose/fabricsetup/tasks/apply.yml b/src/agent/ansible/roles/deploy_compose/fabricsetup/tasks/apply.yml orgmembers: \"{{ peers | map(attribute='org') | list | unique | sort | join(\\\".member' '\\\") | trim | replace(' ', ',') }}\"\n- name: Login to docker repo\n- command: docker login \"{{ fabric.repo.url }} -u {{ fabric.repo.username }} -p {{ fabric.repo.password }}\"\n+ command: \"docker login {{ fabric.repo.url }} -u {{ fabric.repo.username }} -p {{ fabric.repo.password }}\"\nwhen: >\nfabric.baseimage_tag | length > 0 and\nfabric.repo.username | default(\"\") | length > 0 and\n",
        "org_msg": "Fix the misplaced double quotes",
        "sim_msg": "Fix issues with download.docker.com, SNI and apt_key module",
        "sim_diff": "diff --git a/ansible/roles/worker/tasks/main.yml b/ansible/roles/worker/tasks/main.yml ---\n+# Note: Some configuration (likely SNI) on download.docker.com is causing\n+# trouble with the ansible apt_key module. For now just use the shell command\n+# to curl/use the system apt-key package.\n- name: Fetch GPG key for docker package\n- apt_key:\n- url: https://download.docker.com/linux/ubuntu/gpg\n- id: 0EBFCD88\n+ shell: >-\n+ curl https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -\nbecome: true\n- name: Add docker PPA\n",
        "chatgpt_cot": "Refactor docker login command in apply.yml for fabric setup in ansible roles. Fix command syntax and add condition for fabric base image tag and repo username."
    },
    {
        "org_diff": "diff --git a/src/agent/ansible/roles/deploy_compose/certsetup/templates/configtx.j2 b/src/agent/ansible/roles/deploy_compose/certsetup/templates/configtx.j2 @@ -38,6 +38,10 @@ Orderer: &OrdererDefaults\n{% for org in ordererorgs %}\n- *{{ org }}\n{% endfor %}\n+{% if project_version | version_compare('1.1.0','>=') %}\n+ Capabilities:\n+ <<: *OrdererCapabilities\n+{% endif %}\nApplication: &ApplicationDefaults\nOrganizations:\n@@ -50,14 +54,31 @@ Profiles:\nConsortium: FabricConsortium\nApplication:\n<<: *ApplicationDefaults\n-\n+{% if project_version | version_compare('1.1.0','>=') %}\n+ Capabilities:\n+ <<: *ApplicationCapabilities\n+{% endif %}\nOrdererGenesis:\nOrderer:\n<<: *OrdererDefaults\n-\n+{% if project_version | version_compare('1.1.0','>=') %}\n+ Capabilities:\n+ <<: *ChannelCapabilities\n+{% endif %}\nConsortiums:\nFabricConsortium:\nOrganizations:\n{% for org in peerorgs %}\n- *{{ org }}\n{% endfor %}\n+{% if project_version | version_compare('1.1.0','>=') %}\n+Capabilities:\n+ Global: &ChannelCapabilities\n+ V1_1: true\n+\n+ Orderer: &OrdererCapabilities\n+ V1_1: true\n+\n+ Application: &ApplicationCapabilities\n+ V1_1: true\n+{% endif %}\n",
        "org_msg": "changes to configtx.j2 in cello ansible\nAdding changes to configtx.j2 in cello ansible agent to support v1.1\nchannel capabilities in configtx.yml",
        "sim_msg": "serviceAccountName belongs to pod spec",
        "sim_diff": "diff --git a/templates/aes-agent.yaml b/templates/aes-agent.yaml @@ -79,7 +79,6 @@ metadata:\nproduct: aes\nspec:\nreplicas: 1\n- serviceAccountName: {{ include \"ambassador.fullname\" . }}-agent\nselector:\nmatchLabels:\napp.kubernetes.io/name: {{ include \"ambassador.fullname\" . }}-agent\n@@ -98,6 +97,7 @@ spec:\n{{- end }}\nproduct: aes\nspec:\n+ serviceAccountName: {{ include \"ambassador.fullname\" . }}-agent\ncontainers:\n- name: ambassador-agent\nimage: \"{{ .Values.agent.image.repository | default .Values.image.repository }}:{{ .Values.agent.image.tag | default .Values.image.tag }}\"\n",
        "chatgpt_cot": "\"Add version comparison for capabilities in configtx.j2 file\""
    },
    {
        "org_diff": "diff --git a/.github/workflows/pythonactions.yml b/.github/workflows/pythonactions.yml @@ -171,11 +171,10 @@ jobs:\necho ${{github.ref}}\npython -m pip install pipenv\npipenv install --dev --python ${{ matrix.python-version }}\n- rm -r docs\n- name: Build docs from scratch\nrun: |\n- mkdir docs\n+ mkdir -p docs\ncd docs_generate\npipenv run sphinx-build -a -E -b html . ../docs\ncd ..\n",
        "org_msg": "Remove \"rm -r docs\"",
        "sim_msg": "Don't use pipenv on github actions\nIt should install dependencies faster",
        "sim_diff": "diff --git a/.github/workflows/python.yml b/.github/workflows/python.yml @@ -37,25 +37,26 @@ jobs:\nuses: actions/setup-python@v2\nwith:\npython-version: ${{ matrix.python-version }}\n- - name: Install pipenv\n+ - name: Create virtualenv\nrun: |\n- python -m pip install --upgrade pipenv wheel\n+ python -m venv venv\n- uses: actions/cache@v2\nid: cache-pip\nwith:\n- path: ~/.local/share/virtualenvs\n+ path: ./venv\nkey: ${{ matrix.python-version }}-${{ hashFiles('requirements-test.txt') }}-${{ hashFiles('requirements.txt') }}\n- name: Install dependencies\nif: steps.cache-pip.outputs.cache-hit != 'true'\nrun: |\n- pipenv install -r requirements-test.txt\n- pipenv install coveralls\n+ source venv/bin/activate\n+ pip install -r requirements-test.txt coveralls wheel\nenv:\nPIP_USE_MIRRORS: true\n- name: Run tests and coverage\nrun: |\n- pipenv run python manage.py check\n- pipenv run coverage run --source=$SOURCE_FOLDER -m py.test -rxXs\n+ source venv/bin/activate\n+ python manage.py check\n+ coverage run --source=$SOURCE_FOLDER -m py.test -rxXs\nenv:\nSOURCE_FOLDER: safe_transaction_service\nDJANGO_SETTINGS_MODULE: config.settings.test\n@@ -66,20 +67,21 @@ jobs:\nCELERY_BROKER_URL: redis://localhost:6379/0\nETHEREUM_MAINNET_NODE: ${{ secrets.ETHEREUM_MAINNET_NODE }}\nCOINMARKETCAP_API_TOKEN: ${{ secrets.COINMARKETCAP_API_TOKEN }}\n- PIPENV_DONT_LOAD_ENV: 1 # By default pipenv loads .env file\n- name: Send results to coveralls\nif: ${{ env.COVERALLS_REPO_TOKEN }}\n- run: pipenv run coveralls\n+ run: |\n+ source venv/bin/activate\n+ coveralls\nenv:\nCOVERALLS_REPO_TOKEN: ${{ secrets.COVERALLS_REPO_TOKEN }}\nGITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }} # Required for coveralls\ndocker-deploy:\nruns-on: ubuntu-latest\nneeds: test-app\n+ if: github.ref == 'refs/heads/master' || github.ref == 'refs/heads/develop' || startsWith(github.ref, 'refs/tags/')\nsteps:\n- uses: actions/checkout@v2\n- name: Dockerhub login\n- if: github.ref == 'refs/heads/master' || github.ref == 'refs/heads/develop' || startsWith(github.ref, 'refs/tags/')\nuses: docker/login-action@v1\nwith:\nusername: ${{ secrets.DOCKER_USER }}\n",
        "chatgpt_cot": "Fix documentation build process by creating docs directory if not present, ensuring successful generation of documentation from scratch."
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/profile_widget.py b/node_manager_fkie/src/node_manager_fkie/profile_widget.py @@ -171,9 +171,10 @@ class ProfileWidget(QDockWidget):\ncontent[smuri]['zeroconf'] = zc_param\nif nmd_param:\ncontent[smuri]['node_manager_daemon'] = nmd_param\n- text = ruamel.yaml.dump(content, default_flow_style=False)\n+ buf = ruamel.yaml.compat.StringIO()\n+ ruamel.yaml.dump(content, buf, Dumper=ruamel.yaml.RoundTripDumper)\nwith open(path, 'w+') as f:\n- f.write(text)\n+ f.write(buf.getvalue())\nexcept Exception as e:\nimport traceback\nprint(utf8(traceback.format_exc(3)))\n",
        "org_msg": "node_manager_fkie: fixed save profile",
        "sim_msg": "ADD OpenTelemetry span decorators at user_manager methods",
        "sim_diff": "diff --git a/packages/syft/src/syft/core/node/common/node_manager/user_manager.py b/packages/syft/src/syft/core/node/common/node_manager/user_manager.py @@ -30,6 +30,8 @@ from .constants import UserApplicationStatus\nfrom .database_manager import DatabaseManager\nfrom .role_manager import RoleManager\n+from .....util import tracers\n+from .....util import span\nclass RefreshBudgetException(Exception):\npass\n@@ -69,6 +71,7 @@ class UserManager(DatabaseManager):\norg_users = org_users + list(super().query(role=role.id))\nreturn org_users\n+ @span(tracer=tracers[\"database_tracer\"])\ndef create_user_application(\nself,\nname: str,\n@@ -119,6 +122,7 @@ class UserManager(DatabaseManager):\nsession_local.close()\nreturn _obj_id\n+ @span(tracer=tracers[\"database_tracer\"])\ndef get_all_applicant(self) -> List[UserApplication]:\n\"\"\"Returns the application data of all the applicants in the database.\n@@ -130,6 +134,7 @@ class UserManager(DatabaseManager):\nsession_local.close()\nreturn result\n+ @span(tracer=tracers[\"database_tracer\"])\ndef process_user_application(\nself, candidate_id: int, status: str, verify_key: VerifyKey\n) -> None:\n@@ -190,6 +195,7 @@ class UserManager(DatabaseManager):\nsession_local.commit()\nsession_local.close()\n+ @span(tracer=tracers[\"database_tracer\"])\ndef signup(\nself,\nname: str,\n@@ -227,16 +233,19 @@ class UserManager(DatabaseManager):\ncreated_at=datetime.now(),\n)\n+ @span(tracer=tracers[\"database_tracer\"])\ndef query(self, **kwargs: Any) -> Query:\nresults = super().query(**kwargs)\nreturn results\n+ @span(tracer=tracers[\"database_tracer\"])\ndef first(self, **kwargs: Any) -> SyftUser:\nresult = super().first(**kwargs)\nif not result:\nraise UserNotFoundError\nreturn result\n+\ndef login(self, email: str, password: str) -> SyftUser:\n\"\"\"Returns the user object for the given the email and password.\n@@ -249,6 +258,7 @@ class UserManager(DatabaseManager):\n\"\"\"\nreturn self.__login_validation(email, password)\n+ @span(tracer=tracers[\"database_tracer\"])\ndef set( # nosec\nself,\nuser_id: str,\n@@ -364,6 +374,7 @@ class UserManager(DatabaseManager):\nraise UserNotFoundError\nreturn self.roles.first(id=user.role)\n+ @span(tracer=tracers[\"database_tracer\"])\ndef get_user(self, verify_key: VerifyKey) -> Optional[SyftUser]:\n\"\"\"Returns the user for the given public digital signature.\"\"\"\nreturn self.first(\n",
        "chatgpt_cot": "\"Fix issue with writing YAML file in ProfileWidget class\""
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/node_tree_model.py b/node_manager_fkie/src/node_manager_fkie/node_tree_model.py @@ -1385,7 +1385,7 @@ class NodeItem(QStandardItem):\n'''\nif cfg == '':\nself._std_config = cfg\n- elif cfg and cfg not in self._cfgs:\n+ if cfg and cfg not in self._cfgs:\nself._cfgs.append(cfg)\nself.update_displayed_config()\n@@ -1759,15 +1759,6 @@ class NodeTreeModel(QStandardItemModel):\nfor item in items:\nif item.parent_item is not None:\ngroups.add(item.parent_item)\n- # only added the config to the node, if the node is in the same group\n- if isinstance(item.parent_item, HostItem):\n- item.add_config(cfg)\n- elif hostItem.is_in_cap_group(item.name, cfg, rospy.names.namespace(item.name).rstrip(rospy.names.SEP), item.parent_item.name):\n- item.add_config(cfg)\n- # test for default group\n- elif hostItem.is_in_cap_group(item.name, '', '', item.parent_item.name):\n- item.add_config(cfg)\n- else:\nitem.add_config(cfg)\nif not items:\n# create the new node\n@@ -1892,4 +1883,3 @@ class NodeTreeModel(QStandardItemModel):\nh = root.child(i)\nh.update_description(descr_type, descr_name, descr)\nreturn h.update_tooltip()\n-\n",
        "org_msg": "node_manager_fkie: sometimes configuration for a node was not visible",
        "sim_msg": "RENAME engine -> db_engine",
        "sim_diff": "diff --git a/packages/syft/src/syft/core/node/common/node.py b/packages/syft/src/syft/core/node/common/node.py @@ -110,7 +110,7 @@ class Node(AbstractNode):\nverify_key: Optional[VerifyKey] = None,\ndb_path: Optional[str] = None,\nTableBase: Any = None,\n- engine: Any = None,\n+ db_engine: Any = None,\ndb: Any = None,\n):\n@@ -132,14 +132,14 @@ class Node(AbstractNode):\nif db is None:\n# If a DB engine isn't provided then\n- if engine is None:\n+ if db_engine is None:\nengine = create_engine(\"sqlite://\", echo=False)\n- db = sessionmaker(bind=engine)()\n+ db = sessionmaker(bind=db_engine)()\n# cache these variables on self\nself.TableBase = TableBase\n- self.engine = engine\n+ self.db_engine = db_engine\nself.db = db\n# launch the tables in the database\n@@ -153,8 +153,9 @@ class Node(AbstractNode):\n# become quite numerous (or otherwise fill up RAM).\n# self.store is the elastic memory.\n+\nself.store = BinObjectManager(\n- db=self.db\n+ db=self.db_engine\n)\n# We need to register all the services once a node is created\n",
        "chatgpt_cot": "Refactor NodeTreeModel.py: removed redundant code for adding config to the node based on group membership, improving clarity and reducing complexity."
    },
    {
        "org_diff": "diff --git a/sc2/bot_ai.py b/sc2/bot_ai.py @@ -81,17 +81,16 @@ class BotAI(object):\nclosest = None\ndistance = float(\"inf\")\nfor el in self.expansion_locations:\n- th = self.townhalls.first\n- d = await self._client.query_pathing(th.position, el)\n- if d is None:\n- continue\n-\ndef is_near_to_expansion(t): return t.position.distance_to(el) < DISTANCE_THRESHOLD\n-\nif any([t for t in map(is_near_to_expansion, self.townhalls)]):\n# already taken\ncontinue\n+ th = self.townhalls.first\n+ d = await self._client.query_pathing(th.position, el)\n+ if d is None:\n+ continue\n+\nif d < distance:\ndistance = d\nclosest = el\n",
        "org_msg": "Do expansion occupation checking first before querying pathing\nThis is to not waste the query on an occupied expansion.",
        "sim_msg": "Forgot to update iNumPlayers",
        "sim_diff": "diff --git a/v3/runner.py b/v3/runner.py @@ -63,6 +63,8 @@ if __name__ == '__main__':\ncallbacks = []\nname_dict = dict()\n+ gameInputPacket.iNumPlayers = num_bots\n+\n# Set configuration values for bots and store name and team\nfor i in range(num_bots):\nbot_config = configparser.RawConfigParser()\n",
        "chatgpt_cot": "Refactor expansion location logic in BotAI.py\n- Changed logic to find closest expansion\n- Repeated code removed\n- Improved readability and maintainability"
    },
    {
        "org_diff": "diff --git a/sc2/units.py b/sc2/units.py @@ -128,13 +128,6 @@ class Units(list):\nelse:\nreturn self.subgroup(random.sample(self, n))\n- # TODO: append, insert, remove, pop and extend functions should reset the cache for Units.positions because the number of units in the list has changed\n- # @property_immutable_cache\n- # def positions(self) -> np.ndarray:\n- # flat_units_positions = (coord for unit in self for coord in unit.position)\n- # unit_positions_np = np.fromiter(flat_units_positions, dtype=float, count=2 * len(self)).reshape((len(self), 2))\n- # return unit_positions_np\n-\ndef in_attack_range_of(self, unit: Unit, bonus_distance: Union[int, float] = 0) -> Units:\n\"\"\"\nFilters units that are in attack range of the given unit.\n",
        "org_msg": "Remove commented out code from units.py",
        "sim_msg": "datacube.model.Measurements attr access",
        "sim_diff": "diff --git a/datacube/model/__init__.py b/datacube/model/__init__.py @@ -331,6 +331,10 @@ class Measurement(dict):\nsuper().__init__(measurement_data)\n+ def __getattr__(self, key):\n+ \"\"\" Allow access to items as attributes. \"\"\"\n+ return self[key]\n+\ndef __repr__(self):\nreturn \"Measurement({})\".format(super(Measurement, self).__repr__())\n",
        "chatgpt_cot": "\"Remove obsolete property function and associated comments from Units class.\""
    },
    {
        "org_diff": "diff --git a/fkie_node_manager_daemon/src/fkie_node_manager_daemon/settings.py b/fkie_node_manager_daemon/src/fkie_node_manager_daemon/settings.py @@ -215,7 +215,7 @@ class Settings:\n:return: Create YAML string representation from configuration dictionary structure.\n:rtype: str\n'''\n- return ruamel.yaml.dump(self._cfg)\n+ return ruamel.yaml.dump(self._cfg, Dumper=ruamel.yaml.RoundTripDumper)\ndef apply(self, data):\n'''\n",
        "org_msg": "fkie_node_manager_daemon: fixed show system monitor configuration after save",
        "sim_msg": "Fixing of Serialization of Settings",
        "sim_diff": "diff --git a/classes/settings.py b/classes/settings.py @@ -54,7 +54,9 @@ class settings(db.Model):\ndef serialize(self):\nreturn {\n'siteName': self.siteName,\n- 'siteAddress': self.siteProtocol + self.siteAddress,\n+ 'siteProtocol': self.siteProtocol,\n+ 'siteAddress': self.siteAddress,\n+ 'siteURI': self.siteProtocol + self.siteAddress,\n'siteLogo': self.systemLogo,\n'serverMessage': self.serverMessage,\n'allowRecording': self.allowRecording,\n",
        "chatgpt_cot": "Update YAML dump method to use RoundTripDumper in Settings class. Fixes issue with YAML string representation in configuration dictionary."
    },
    {
        "org_diff": "diff --git a/sc2/game_data.py b/sc2/game_data.py @@ -24,7 +24,8 @@ def split_camel_case(text) -> list:\nclass GameData(object):\ndef __init__(self, data):\n- self.abilities = {a.ability_id: AbilityData(self, a) for a in data.abilities if AbilityData.id_exists(a.ability_id)}\n+ ids = tuple(a.value for a in AbilityId if a.value != 0)\n+ self.abilities = {a.ability_id: AbilityData(self, a) for a in data.abilities if a.ability_id in ids}\nself.units = {u.unit_id: UnitTypeData(self, u) for u in data.units if u.available}\nself.upgrades = {u.upgrade_id: UpgradeData(self, u) for u in data.upgrades}\n",
        "org_msg": "Add GameData parsing optimization",
        "sim_msg": "remove line normalizing capitalization. Will make a new ticket for this to do on the API side",
        "sim_diff": "diff --git a/planet/cli/data.py b/planet/cli/data.py @@ -51,8 +51,6 @@ def data(ctx, base_url):\ndef parse_item_types(ctx, param, value: str) -> List[str]:\n\"\"\"Turn a string of comma-separated names into a list of names.\"\"\"\n- # convert user-input strings to match our naming schema\n- update_value = value.lower()\ndict = {\n\"psscene\": \"PSScene\",\n",
        "chatgpt_cot": "Refactor abilities initialization in GameData\nThe scope of changes includes modifying the initialization of abilities in the GameData class. The modification aims to improve the efficiency of the initialization process."
    },
    {
        "org_diff": "diff --git a/src/api-engine/api/lib/peer/chaincode.py b/src/api-engine/api/lib/peer/chaincode.py @@ -338,8 +338,8 @@ class ChainCode(BasicEnv):\ndef query(self, orderer_url, orderer_tls_rootcert, channel_name, cc_name, args):\ntry:\nif os.getenv(\"CORE_PEER_TLS_ENABLED\") == \"false\" or os.getenv(\"CORE_PEER_TLS_ENABLED\") is None:\n- res = subprocess.Popen(\"./../bin/{}/bin/peer chaincode query -o {} --channelID {} --name {} -c '{}'\"\n- .format(self.version, orderer_url, channel_name, cc_name, args),\n+ res = subprocess.Popen(\"{} chaincode query -o {} --channelID {} --name {} -c '{}'\"\n+ .format(self.peer, orderer_url, channel_name, cc_name, args),\nshell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\nstdout, stderr = res.communicate()\nreturn_code = res.returncode\n@@ -349,8 +349,8 @@ class ChainCode(BasicEnv):\nstderr = str(stderr, encoding=\"utf-8\")\nreturn return_code, stderr\nelse:\n- res = subprocess.Popen(\"./../bin/{}/bin/peer chaincode query -o {} --tls --cafile {} --channelID {}\"\n- \" --name {} -c '{}'\".format(self.version, orderer_url, orderer_tls_rootcert,\n+ res = subprocess.Popen(\"{} chaincode query -o {} --tls --cafile {} --channelID {}\"\n+ \" --name {} -c '{}'\".format(self.peer, orderer_url, orderer_tls_rootcert,\nchannel_name, cc_name, args),\nshell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\nstdout, stderr = res.communicate()\n",
        "org_msg": "[#issue-355] There has a bug of Call cmd, need to be fixed\nThere has a bug of Call cmd, need to be fixed: Cannot find the peer binary file now.\nClose #issue-#355",
        "sim_msg": "Fix `find_confirm_info`\nConfirm info is removed after adding block",
        "sim_diff": "diff --git a/loopchain/blockchain/blockchain.py b/loopchain/blockchain/blockchain.py @@ -27,7 +27,7 @@ from loopchain import utils\nfrom loopchain.baseservice import ScoreResponse, ObjectManager\nfrom loopchain.baseservice.aging_cache import AgingCache\nfrom loopchain.blockchain.blocks import Block, BlockBuilder, BlockSerializer\n-from loopchain.blockchain.blocks import BlockProver, BlockProverType, BlockVersioner\n+from loopchain.blockchain.blocks import BlockProver, BlockProverType, BlockVersioner, v0_3\nfrom loopchain.blockchain.exception import *\nfrom loopchain.blockchain.score_base import *\nfrom loopchain.blockchain.transactions import Transaction, TransactionBuilder\n@@ -314,19 +314,36 @@ class BlockChain:\nreturn self.__find_block_by_key(key)\n- def find_confirm_info_by_hash(self, block_hash) -> bytes:\n- hash_encoded = block_hash.hex().encode(encoding='UTF-8')\n+ def find_confirm_info_by_hash(self, block_hash: Union[str, Hash32]) -> bytes:\n+ if isinstance(block_hash, Hash32):\n+ block_hash = block_hash.hex()\n+ hash_encoded = block_hash.encode('UTF-8')\n+ try:\n+ return self._blockchain_store.get(BlockChain.CONFIRM_INFO_KEY + hash_encoded)\n+ except KeyError:\n+ block = self.find_block_by_hash(block_hash)\n+ return self.find_prev_confirm_info_by_height(block.header.height + 1) if block else bytes()\n+ def find_confirm_info_by_height(self, height: int) -> bytes:\n+ block = self.find_block_by_height(height)\n+ hash_encoded = block.header.hash.hex().encode('UTF-8')\ntry:\n- return bytes(self._blockchain_store.get(BlockChain.CONFIRM_INFO_KEY + hash_encoded))\n+ return self._blockchain_store.get(BlockChain.CONFIRM_INFO_KEY + hash_encoded)\nexcept KeyError:\n+ return self.find_prev_confirm_info_by_height(block.header.height + 1)\n+\n+ def find_prev_confirm_info_by_hash(self, block_hash: Union[str, Hash32]) -> bytes:\n+ block = self.find_block_by_hash(block_hash)\n+ if block and isinstance(block.body, v0_3.BlockBody):\n+ votes_serialized = BlockVotes.serialize_votes(block.body.prev_votes)\n+ return json.dumps(votes_serialized).encode(encoding='UTF-8')\nreturn bytes()\n- def find_confirm_info_by_height(self, height) -> bytes:\n+ def find_prev_confirm_info_by_height(self, height: int) -> bytes:\nblock = self.find_block_by_height(height)\n- if block:\n- return bytes(self.find_confirm_info_by_hash(block.header.hash))\n-\n+ if block and isinstance(block.body, v0_3.BlockBody):\n+ votes_serialized = BlockVotes.serialize_votes(block.body.prev_votes)\n+ return json.dumps(votes_serialized).encode(encoding='UTF-8')\nreturn bytes()\ndef find_preps_ids_by_roothash(self, roothash: Hash32) -> List[str]:\n",
        "chatgpt_cot": "Refactor chaincode query method to use peer variable for subprocess command, improving readability and flexibility in ChainCode class."
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/launch_files_widget.py b/node_manager_fkie/src/node_manager_fkie/launch_files_widget.py @@ -330,7 +330,7 @@ class LaunchFilesWidget(QDockWidget):\nresult.append(item)\nreturn result\n- def keyReleaseEvent(self, event):\n+ def keyPressEvent(self, event):\n'''\nDefines some of shortcuts for navigation/management in launch\nlist view or topics view.\n",
        "org_msg": "node_manager_fkie: changed key event handling in launch dock to avoid double events",
        "sim_msg": "Close on browse and open.",
        "sim_diff": "diff --git a/avalon/tools/workfiles/app.py b/avalon/tools/workfiles/app.py @@ -516,7 +516,8 @@ class FilesWidget(QtWidgets.QWidget):\npass\nself._enter_session()\n- return host.open_file(filepath)\n+ host.open_file(filepath)\n+ self.window().close()\ndef save_changes_prompt(self):\nself._messagebox = QtWidgets.QMessageBox()\n@@ -596,7 +597,6 @@ class FilesWidget(QtWidgets.QWidget):\nreturn\nself.open_file(path)\n- self.window().close()\ndef on_browse_pressed(self):\n",
        "chatgpt_cot": "\"Add keyPressEvent method to enable keyboard shortcuts for navigation/management in launch list view or topics view in LaunchFilesWidget.\""
    },
    {
        "org_diff": "diff --git a/master_discovery_fkie/src/master_discovery_fkie/zeroconf.py b/master_discovery_fkie/src/master_discovery_fkie/zeroconf.py @@ -761,7 +761,9 @@ class Discoverer(Zeroconf):\nrospy.loginfo(\"Network ID: %s\" % self.network_id)\nself._use_fqdn = rospy.get_param('~fqdn', False)\nrospy.loginfo(\"Fully-Qualified Domain Name: %s\" % ('enabled' if self._use_fqdn else 'disabled'))\n- self.master_monitor = MasterMonitor(monitor_port)\n+ self._use_ipv6 = 'ROS_IPV6' in os.environ and os.environ['ROS_IPV6'] == 'on'\n+ rospy.loginfo(\"IPv6: %s\" % ('enabled' if self._use_ipv6 else 'disabled'))\n+ self.master_monitor = MasterMonitor(monitor_port, ipv6=self._use_ipv6)\nname = self.master_monitor.getMastername()\nmateruri = self.master_monitor.getMasteruri()\n# create the txtArray for the zeroconf service of the ROS master\n",
        "org_msg": "zeroconf.py: Detect IPv6 usage from environment\nSet environment ROS_IPV6=on to enable the IPv6 RPC server.",
        "sim_msg": "add new conf: tracker_servers",
        "sim_diff": "diff --git a/lbry/conf.py b/lbry/conf.py @@ -681,6 +681,10 @@ class Config(CLIConfig):\n('cdn.reflector.lbry.com', 5567)\n])\n+ tracker_servers = Servers(\"BitTorrent-compatible (BEP15) UDP trackers for helping P2P discovery\", [\n+ ('tracker.lbry.com', 1337)\n+ ])\n+\nlbryum_servers = Servers(\"SPV wallet servers\", [\n('spv11.lbry.com', 50001),\n('spv12.lbry.com', 50001),\n",
        "chatgpt_cot": "\"Add support for IPv6 in zeroconf discovery\""
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/html_delegate.py b/node_manager_fkie/src/node_manager_fkie/html_delegate.py @@ -81,7 +81,7 @@ class HTMLDelegate(QStyledItemDelegate):\ntextRect.setWidth(options.rect.width())\ntextRect.setHeight(options.rect.height())\npainter.save()\n- red = self._red_ascent if not self._dec_ascent else self._red_ascent / 2 + 1\n+ red = self._red_ascent if not self._dec_ascent else self._red_ascent / 2\npainter.translate(QPoint(textRect.topLeft().x(), textRect.topLeft().y() - red))\npainter.setClipRect(textRect.translated(-textRect.topLeft()))\ndoc.documentLayout().draw(painter, ctx)\n@@ -101,7 +101,7 @@ class HTMLDelegate(QStyledItemDelegate):\ndoc.setHtml(options.text)\ndoc.setTextWidth(options.rect.width())\nmetric = QFontMetrics(doc.defaultFont())\n- self._red_ascent = abs(metric.height() - metric.ascent())\n+ self._red_ascent = abs(metric.height() - metric.ascent()) + 1\nself._cached_size = QSize(doc.idealWidth(), metric.height() + self._red_ascent)\nreturn self._cached_size\n",
        "org_msg": "node_manager_fkie: changed html delegate",
        "sim_msg": "Fixed dark text on dark. Fixed context menu None type error.",
        "sim_diff": "diff --git a/qualcoder/view_graph.py b/qualcoder/view_graph.py @@ -100,6 +100,11 @@ class ViewGraph(QDialog):\npm = QtGui.QPixmap()\npm.loadFromData(QtCore.QByteArray.fromBase64(zoom_icon), \"png\")\nself.ui.label_zoom.setPixmap(pm.scaled(26, 26))\n+ pm = QtGui.QPixmap()\n+ pm.loadFromData(QtCore.QByteArray.fromBase64(eye_icon), \"png\")\n+ self.ui.pushButton_reveal.setIcon(QtGui.QIcon(pm))\n+ self.ui.pushButton_reveal.pressed.connect(self.reveal_hidden_items)\n+ self.ui.pushButton_reveal.hide() # TODO TMP\n# Set the scene\nself.scene = GraphicsScene()\n@@ -415,6 +420,11 @@ class ViewGraph(QDialog):\ni += 1\nreturn new_model\n+ def reveal_hidden_items(self):\n+ \"\"\" Show list of hidden items to be revealed on selection \"\"\"\n+\n+ pass\n+\ndef keyPressEvent(self, event):\n\"\"\" Plus to zoom in and Minus to zoom out. Needs focus on the QGraphicsView widget. \"\"\"\n@@ -647,6 +657,8 @@ class FreeTextGraphicsItem(QtWidgets.QGraphicsTextItem):\nmenu = QtWidgets.QMenu()\nmenu.addAction(_('Remove'))\naction = menu.exec(QtGui.QCursor.pos())\n+ if action is None:\n+ return\nif action.text() == \"Remove\":\nself.remove = True\n@@ -663,9 +675,9 @@ class FreeTextGraphicsItem(QtWidgets.QGraphicsTextItem):\npainter.drawRect(self.boundingRect())\npainter.setFont(self.font)\nfm = painter.fontMetrics()\n+ painter.setPen(QtGui.QColor(QtCore.Qt.GlobalColor.black))\nif self.app.settings['stylesheet'] == 'dark':\npainter.setPen(QtGui.QColor(QtCore.Qt.GlobalColor.white))\n- painter.setPen(QtGui.QColor(QtCore.Qt.GlobalColor.black))\nlines = self.text.split('\\\\n')\nfor row in range(0, len(lines)):\npainter.drawText(5, fm.height() * (row + 1), lines[row])\n@@ -716,6 +728,8 @@ class FreeLineGraphicsItem(QtWidgets.QGraphicsLineItem):\nmenu.addAction(_('Blue'))\nmenu.addAction(_('Remove'))\naction = menu.exec(QtGui.QCursor.pos())\n+ if action is None:\n+ return\nif action.text() == 'Thicker':\nself.line_width = self.line_width + 0.5\nif self.line_width > 5:\n@@ -957,6 +971,8 @@ class LinkGraphicsItem(QtWidgets.QGraphicsLineItem):\nmenu.addAction(_(\"Hide\"))\naction = menu.exec(QtGui.QCursor.pos())\n+ if action is None:\n+ return\nif action.text() == 'Thicker':\nself.line_width = self.line_width + 0.5\nif self.line_width > 5:\n",
        "chatgpt_cot": "Fix red ascent calculation in HTMLDelegate class. The modification to red ascent calculation helps to improve the appearance of the HTMLDelegate."
    },
    {
        "org_diff": "diff --git a/rasa_core_sdk/forms.py b/rasa_core_sdk/forms.py @@ -103,7 +103,8 @@ class FormAction(Action):\ntracker.latest_message.get(\"text\"))]\nelse:\n- raise ValueError('Provided slot_mapping[\"type\"] '\n+ raise NotImplementedError(\n+ 'Provided slot_mapping[\"type\"] '\n'is not supported')\nreturn None\n",
        "org_msg": "change ValueError to NotImplementedError RasaHQ/roadmap#280",
        "sim_msg": "Update Routes API\nADD type hints\nRemove unused imports",
        "sim_diff": "diff --git a/src/syft/grid/client/request_api/role_api.py b/src/syft/grid/client/request_api/role_api.py +# stdlib\n+from typing import Any\n+from typing import Callable\n+\n# syft relative\nfrom ...messages.role_messages import CreateRoleMessage\nfrom ...messages.role_messages import DeleteRoleMessage\n@@ -8,9 +12,9 @@ from .request_api import GridRequestAPI\nclass RoleRequestAPI(GridRequestAPI):\n- response_key = \"role\"\n+ response_key: str = \"role\"\n- def __init__(self, send):\n+ def __init__(self, send: Callable):\nsuper().__init__(\ncreate_msg=CreateRoleMessage,\nget_msg=GetRoleMessage,\n@@ -21,8 +25,8 @@ class RoleRequestAPI(GridRequestAPI):\nresponse_key=RoleRequestAPI.response_key,\n)\n- def __getitem__(self, key):\n+ def __getitem__(self, key: int) -> Any:\nreturn self.get(role_id=key)\n- def __delitem__(self, key):\n+ def __delitem__(self, key: int) -> None:\nself.delete(role_id=key)\n",
        "chatgpt_cot": "Refactor FormAction class in forms.py to raise NotImplementedError for unsupported slot mapping type instead of ValueError."
    },
    {
        "org_diff": "diff --git a/sc2/bot_ai.py b/sc2/bot_ai.py @@ -235,12 +235,12 @@ class BotAI(object):\ndef already_pending(self, unit_type):\nability = self._game_data.units[unit_type.value].creation_ability\nif self.units(unit_type).not_ready.exists:\n- return True\n+ return len(self.units(unit_type).not_ready)\nelif any(o.ability == ability for w in self.workers for o in w.orders):\n- return True\n+ return sum([o.ability == ability for w in self.workers for o in w.orders])\nelif any(egg.orders[0].ability == ability for egg in self.units(EGG)):\n- return True\n- return False\n+ return sum([egg.orders[0].ability == ability for egg in self.units(EGG)])\n+ return 0\nasync def build(self, building, near, max_distance=20, unit=None, random_alternative=True, placement_step=2):\nif isinstance(near, Unit):\n",
        "org_msg": "`BotAI.already_pending` enhancement\nImprove `BotAI.already_pending`",
        "sim_msg": "Update `send_message_to_user` function",
        "sim_diff": "diff --git a/pajbot/bot.py b/pajbot/bot.py @@ -659,14 +659,14 @@ class Bot:\ndef send_message_to_user(self, user, message, event, method=\"say\"):\nif method == \"say\":\n- self.say(user.name + \", \" + lowercase_first_letter(message))\n+ self.say(f\"@{user.name}, {lowercase_first_letter(message)}\")\nelif method == \"whisper\":\nself.whisper(user, message)\nelif method == \"me\":\nself.me(message)\nelif method == \"reply\":\nif event.type in [\"action\", \"pubmsg\"]:\n- self.say(message)\n+ self.say(f\"@{user.name}, {lowercase_first_letter(message)}\")\nelif event.type == \"whisper\":\nself.whisper(user, message)\nelse:\n",
        "chatgpt_cot": "\"Refactor already_pending method in BotAI to improve code readability and efficiency by using list comprehension and sum function for condition evaluation.\""
    },
    {
        "org_diff": "diff --git a/README.md b/README.md @@ -31,7 +31,7 @@ Finally, you'll need to download some maps. Official map downloads are available\nAfter installing the library, a StarCraft II executable, and some maps, you're ready to get started. Simply run a bot file to fire up an instance of StarCraft II with the bot running. For example:\n```\n-python3 examples/cannon_rush.py\n+python3 examples/protoss/cannon_rush.py\n```\n## Example\n",
        "org_msg": "Fix command to start cannon_rush example",
        "sim_msg": "Editted READ.me for clarity",
        "sim_diff": "diff --git a/README.md b/README.md @@ -34,7 +34,7 @@ More more information read our recent <a href=\"http://dawn.cs.stanford.edu/2017/\n## Installation\n-This file will go through the steps needed to install the required packages and software to run HoloClean. For a more detailed installation guide check out the [Holoclean_Installation_v3.pdf](https://github.com/HoloClean/HoloClean-v0.01/blob/pytorch/Holoclean_Installation_v3.pdf) file in the git repo.\n+This file will go through the steps needed to install the required packages and software to run HoloClean. For a more detailed installation guide check out the [Holoclean_Installation_v3.pdf](https://github.com/HoloClean/HoloClean/blob/pytorch-clean/docs/Holoclean_Installation_v3.pdf) file in the git repo.\n### 1. Setting Up and Using Conda\n<b>1.1 Ubuntu: </b>\n@@ -52,17 +52,17 @@ bash Anaconda-2.3.0-Linux-x86_64.sh\n```\n<h4>1.2 MacOS: <h4>\n-Follow instructions [here](https://conda.io/docs/user-guide/install/macos.html) to install conda for MacOS\n+Follow instructions [here](https://conda.io/docs/user-guide/install/macos.html) to install Anaconda (Not miniconda) for MacOS\n<h4> 1.3 Using Conda </h4>\n-Open the terminal and create a Python 2.7 environment by running the command:\n+Open/Restart the terminal and create a Python 2.7 environment by running the command:\nconda create -n py27Env python=2.7 anaconda\nThen the environment can be activated by running:\nsource activate py27Env\n-Make sure the keep the environment activated for the rest of the installation process\n+<b> Make sure the keep the environment activated for the rest of the installation process </b>\n### 2. Download and Install Spark\n@@ -74,8 +74,6 @@ Go to the directory where you downloaded the file and run:\ntar -xzf spark-2.2.0-bin-hadoop2.7.tgz\npip install pyspark\n```\n-On MacOS run `brew install apache-spark`\n-\n### 3. Install MySQL Server\n<b> 3.1 For Ubuntu: </b>\n@@ -119,4 +117,13 @@ http://pytorch.org/\nTo install pytorch\nMake sure to install version 0.3.0 or later\n+### 6. Install JDK 8\n+<b> 6.1 For Ubuntu: </b>\n+Run the following command:\n+```\n+sudo apt-get install default-jre\n+```\n+<br>\n+<b> 3.2 For MacOS </b>\n+Download JDK for MacOS from the oracle website: http://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html\n",
        "chatgpt_cot": "Change the file path in the README to correct the example command for running the bot file."
    },
    {
        "org_diff": "diff --git a/fkie_node_manager/src/fkie_node_manager/master_view_proxy.py b/fkie_node_manager/src/fkie_node_manager/master_view_proxy.py @@ -2438,7 +2438,7 @@ class MasterViewProxy(QWidget):\nsocket.setdefaulttimeout(None)\n# wait kill_on_stop is an integer\nif node.pid is not None:\n- if hasattr(node, 'kill_on_stop') and isinstance(node.kill_on_stop, (int, float)):\n+ if hasattr(node, 'kill_on_stop') and type(node.kill_on_stop) in [int, float]:\ntime.sleep(float(node.kill_on_stop) / 1000.0)\nnm.nmd().monitor.kill_process(node.pid, nmdurl.nmduri(node.masteruri))\nelif not success:\n",
        "org_msg": "fkie_node_manager: fix kill on stop every node",
        "sim_msg": "handle early lbrycrd exit in tests",
        "sim_diff": "diff --git a/lbry/wallet/orchstr8/node.py b/lbry/wallet/orchstr8/node.py @@ -228,6 +228,7 @@ class BlockchainProcess(asyncio.SubprocessProtocol):\ndef process_exited(self):\nself.stopped.set()\n+ self.ready.set()\nclass BlockchainNode:\n@@ -315,6 +316,7 @@ class BlockchainNode:\nBlockchainProcess, *command\n)\nawait self.protocol.ready.wait()\n+ assert not self.protocol.stopped.is_set()\nasync def stop(self, cleanup=True):\ntry:\n",
        "chatgpt_cot": "Fix compilation issue with MasterViewProxy due to changes in the condition expression for checking the type of node.kill_on_stop attribute."
    },
    {
        "org_diff": "diff --git a/fkie_node_manager/src/fkie_node_manager/screen_handler.py b/fkie_node_manager/src/fkie_node_manager/screen_handler.py @@ -146,13 +146,13 @@ class ScreenHandler(object):\n# Open selection\nif len(choices) > 0:\nif len(choices) == 1:\n- cls.open_screen_terminal(host, choices[0], node, use_log_widget, user)\n+ cls.open_screen_terminal(host, choices[0], node, use_log_widget=False, user=user)\nelif auto_item_request:\nfrom select_dialog import SelectDialog\nitems, _ = SelectDialog.getValue('Show screen', '', list(choices.keys()), False, store_geometry='show_screens')\nfor item in items:\n# open the selected screen\n- cls.open_screen_terminal(host, choices[item], node, use_log_widget, user)\n+ cls.open_screen_terminal(host, choices[item], node, use_log_widget=False, user=user)\nelse:\nraise ScreenSelectionRequest(choices, 'Show screen')\nelse:\n@@ -161,7 +161,8 @@ class ScreenHandler(object):\nexcept nm.AuthenticationRequest as e:\nraise nm.InteractionNeededError(e, cls.open_screen, (node, grpc_url, auto_item_request, use_log_widget))\nexcept ScreenSelectionRequest as e:\n- raise nm.InteractionNeededError(e, cls.open_screen, (node, grpc_url, auto_item_request, use_log_widget, user, pw))\n+ # set use_log_widget to False on multiple screens for same node\n+ raise nm.InteractionNeededError(e, cls.open_screen, (node, grpc_url, auto_item_request, False, user, pw))\n@classmethod\ndef kill_screens(cls, node, grpc_url, auto_ok_request=True, user=None, pw=None):\n",
        "org_msg": "fkie_node_manager: on multiple screen for a node open it in terminal instead of log widget",
        "sim_msg": "added option to jump from scr to po.  Just pass stocks spaced apart",
        "sim_diff": "diff --git a/gamestonk_terminal/screener/screener_controller.py b/gamestonk_terminal/screener/screener_controller.py @@ -14,6 +14,7 @@ from gamestonk_terminal.helper_funcs import (\n)\nfrom gamestonk_terminal.screener import finviz_view\nfrom gamestonk_terminal.screener import yahoo_finance_view\n+from gamestonk_terminal.portfolio_optimization import po_controller\nclass ScreenerController:\n@@ -34,6 +35,7 @@ class ScreenerController:\n\"performance\",\n\"technical\",\n\"signals\",\n+ \"po\",\n]\ndef __init__(self):\n@@ -69,6 +71,8 @@ class ScreenerController:\nprint(\"\")\nprint(\" signals view filter signals (e.g. -s top_gainers)\")\nprint(\"\")\n+ print(\" > po go to the portfolio optimization menu\")\n+ print(\"\")\n@staticmethod\ndef view_available_presets(other_args: List[str]):\n@@ -217,6 +221,9 @@ class ScreenerController:\n\"\"\"Process signals command\"\"\"\nfinviz_view.view_signals(other_args)\n+ def call_po(self, other_args: List[str]):\n+ return po_controller.menu(other_args)\n+\ndef menu():\n\"\"\"Screener Menu\"\"\"\n",
        "chatgpt_cot": "Fix compilation issue by setting use_log_widget to False on multiple screens for same node."
    },
    {
        "org_diff": "diff --git a/src/agent/docker-rest-agent/server.py b/src/agent/docker-rest-agent/server.py @@ -43,8 +43,8 @@ def create_node():\nport_map = ast.literal_eval(request.form.get(\"port_map\"))\nvolumes = [\n'/var/run/:/host/var/run/',\n- '/opt/fabric/{}:/etc/hyperledger/fabric'.format(node_name),\n- '/opt/production/{}:/var/hyperledger/production'.format(node_name)\n+ '/opt/hyperledger/fabric/{}:/etc/hyperledger/fabric'.format(node_name),\n+ '/opt/hyperledger/production/{}:/var/hyperledger/production'.format(node_name)\n]\nif request.form.get('type') == \"peer\":\npeer_envs = {\n",
        "org_msg": "Update local path",
        "sim_msg": "Add node config init to postinstall\nProblem: Node snapshot import by default assumes that the node directory\ntargets mainnet, thus it's not possible to import testnet snapshot to\nthe empty node data directory.\nSolution: Add `tezos-node config init` calls for all non-custom network\nservices to the postinstallation stage.",
        "sim_diff": "diff --git a/docker/package/packages.py b/docker/package/packages.py @@ -112,7 +112,10 @@ common_node_env = [\"NODE_RPC_ADDR=127.0.0.1:8732\", \"CERT_PATH=\", \"KEY_PATH=\"]\nfor network in networks:\nenv = [f\"DATA_DIR=/var/lib/tezos/node-{network}\", f\"NETWORK={network}\"] + common_node_env\nnode_units.append(mk_node_unit(suffix=network, env=env, desc=f\"Tezos node {network}\"))\n- node_postinst_steps += f\"mkdir -p /var/lib/tezos/node-{network}\\n\"\n+ node_postinst_steps += f'''mkdir -p /var/lib/tezos/node-{network}\n+[ ! -f /var/lib/tezos/node-{network}/config.json ] && tezos-node config init --data-dir /var/lib/tezos/node-{network} --network {network}\n+chown -R tezos:tezos /var/lib/tezos/node-{network}\n+'''\n# Add custom config service\nnode_units.append(mk_node_unit(suffix=\"custom\", env=[\"DATA_DIR=/var/lib/tezos/node-custom\",\n",
        "chatgpt_cot": "Fix path for fabric and production directories in create_node() function in server.py. The modification helps to correct the path for the directories."
    },
    {
        "org_diff": "diff --git a/sc2/bot_ai.py b/sc2/bot_ai.py @@ -1082,20 +1082,23 @@ class BotAI(DistanceCalculation):\n:param placement_step: \"\"\"\nassert isinstance(near, (Unit, Point2, Point3))\n- if isinstance(near, Unit):\n+ gas_buildings = {UnitTypeId.EXTRACTOR, UnitTypeId.ASSIMILATOR, UnitTypeId.REFINERY}\n+ if isinstance(near, Unit) and building not in gas_buildings:\nnear = near.position\n+ if isinstance(near, (Point2, Point3)):\nnear = near.to2\n-\nif not self.can_afford(building):\nreturn False\n-\n+ if isinstance(near, (Point2, Point3)):\np = await self.find_placement(building, near, max_distance, random_alternative, placement_step)\nif p is None:\nreturn False\n-\n- builder = build_worker or self.select_build_worker(p)\n+ builder = build_worker or self.select_build_worker(near)\nif builder is None:\nreturn False\n+ if building in gas_buildings:\n+ self.do(builder.build_gas(near))\n+ return True\nself.do(builder.build(building, p), subtract_cost=True)\nreturn True\n",
        "org_msg": "make using self.build() possible for gas buildings",
        "sim_msg": "hook is_client=true after this is not required anymore",
        "sim_diff": "diff --git a/test/federated/test_plan.py b/test/federated/test_plan.py @@ -30,6 +30,8 @@ def test_plan_built_locally(hook):\nassert isinstance(plan_abs.__str__(), str)\nassert len(plan_abs.readable_plan) > 0\n+ hook.local_worker.is_client_worker = True\n+\ndef test_plan_execute_locally(hook):\n# To run a plan locally the local worker can't be a client worker,\n@@ -44,6 +46,8 @@ def test_plan_execute_locally(hook):\nx_abs = plan_abs(x)\nassert (x_abs == th.tensor([1, 2, 3])).all()\n+ hook.local_worker.is_client_worker = True\n+\ndef test_plan_method_execute_locally(hook):\nhook.local_worker.is_client_worker = False\n@@ -66,6 +70,8 @@ def test_plan_method_execute_locally(hook):\nmodel.send(hook.local_worker)\nassert model(th.tensor([1.0, 2])) == 0\n+ hook.local_worker.is_client_worker = True\n+\ndef test_plan_built_remotely(workers):\nbob = workers[\"bob\"]\n@@ -169,6 +175,8 @@ def test_fetch_plan_built_locally(hook):\ny = th.tensor([-1, 2, 3])\nassert (fetched_plan(y) == th.tensor([-3, 6, 9])).all()\n+ hook.local_worker.is_client_worker = True\n+\ndef test_fetch_plan_built_remotely(hook):\nhook.local_worker.is_client_worker = False\n@@ -197,6 +205,8 @@ def test_fetch_plan_built_remotely(hook):\nassert (get_plan(x) == th.tensor([-3, 6, 9])).all()\nassert (fetched_plan(x) == th.tensor([-3, 6, 9])).all()\n+ hook.local_worker.is_client_worker = True\n+\ndef test_plan_serde(hook):\nhook.local_worker.is_client_worker = False\n@@ -217,6 +227,8 @@ def test_plan_serde(hook):\nx = th.tensor([-1, 2, 3])\nassert (deserialized_plan(x) == th.tensor([-42, 24, 46])).all()\n+ hook.local_worker.is_client_worker = True\n+\ndef test_plan_execute_remotely(hook, start_proc):\n\"\"\"Test plan execution remotely.\"\"\"\n@@ -249,6 +261,7 @@ def test_plan_execute_remotely(hook, start_proc):\ndel x_ptr\nserver.terminate()\n+ hook.local_worker.is_client_worker = True\ndef test_replace_worker_ids_two_strings(hook):\n",
        "chatgpt_cot": "Refactor build logic in BotAI for gas buildings, check for gas_building type before building, and select appropriate worker for construction."
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/start_handler.py b/node_manager_fkie/src/node_manager_fkie/start_handler.py @@ -593,8 +593,15 @@ class StartHandler(object):\nif ros_hostname:\nnew_env['ROS_HOSTNAME'] = ros_hostname\ncmd_args = '%s roscore --port %d' % (nm.ScreenHandler.getSceenCmd('/roscore--%d' % master_port), master_port)\n+ for n in [1, 2, 3, 4]:\ntry:\n+ if n == 1:\n+ print(\"Launch ROS Master in screen ...\")\nSupervisedPopen(shlex.split(cmd_args), env=new_env, object_id=\"ROSCORE\", description=\"Start roscore\")\n+ elif n == 2:\n+ print(\"ROS Master takes too long for start, wait for next 10 sec ...\")\n+ elif n == 3:\n+ print(\"A really slow start, wait for last 10 sec ...\")\n# wait for roscore to avoid connection problems while init_node\nresult = -1\ncount = 1\n@@ -602,11 +609,12 @@ class StartHandler(object):\ntry:\nmaster = xmlrpclib.ServerProxy(masteruri)\nresult, _, _ = master.getUri(rospy.get_name()) # _:=uri, msg\n- except:\n+ return\n+ except Exception:\ntime.sleep(1)\ncount += 1\n- if count >= 11:\n- raise StartException('Cannot connect to the ROS-Master: ' + utf8(masteruri))\n+ if n == 4 and count >= 11:\n+ raise StartException('Cannot connect to ROS-Master: %s\\n--> please run \"roscore\" manually!' % utf8(masteruri))\nexcept Exception as e:\nraise Exception(\"Error while call '%s': %s\" % (cmd_args, utf8(e)))\nelse:\n",
        "org_msg": "node_manager_fkie: added log for start and wait for ROS master at the beginning",
        "sim_msg": "dht_crawler: skip ping if known node_id",
        "sim_diff": "diff --git a/scripts/dht_crawler.py b/scripts/dht_crawler.py @@ -136,7 +136,7 @@ class Crawler:\ndef set_latency(self, peer, latency=None):\ndb_peer = self.get_from_peer(peer)\ndb_peer.latency = latency\n- if not db_peer.node_id:\n+ if not db_peer.node_id and peer.node_id:\ndb_peer.node_id = peer.node_id.hex()\nif db_peer.first_online and latency is None:\ndb_peer.last_churn = (datetime.datetime.utcnow() - db_peer.first_online).seconds\n@@ -156,24 +156,29 @@ class Crawler:\npeer = make_kademlia_peer(None, await resolve_host(host, port, 'udp'), port)\nfor attempt in range(3):\ntry:\n+ req_start = time.perf_counter_ns()\nresponse = await self.node.protocol.get_rpc_peer(peer).find_node(key)\n+ latency = time.perf_counter_ns() - req_start\n+ self.set_latency(make_kademlia_peer(key, host, port), latency)\nreturn [make_kademlia_peer(*peer_tuple) for peer_tuple in response]\nexcept asyncio.TimeoutError:\n- log.info('Previously responding peer timed out: %s:%d attempt #%d', host, port, (attempt + 1))\n+ self.set_latency(make_kademlia_peer(key, host, port), None)\ncontinue\nexcept lbry.dht.error.RemoteException as e:\n- log.info('Previously responding peer errored: %s:%d attempt #%d - %s',\n+ log.info('Peer errored: %s:%d attempt #%d - %s',\nhost, port, (attempt + 1), str(e))\nself.inc_errors(peer)\n+ self.set_latency(make_kademlia_peer(key, host, port), None)\ncontinue\nreturn []\n- async def crawl_routing_table(self, host, port):\n+ async def crawl_routing_table(self, host, port, node_id=None):\nstart = time.time()\nlog.info(\"querying %s:%d\", host, port)\naddress = await resolve_host(host, port, 'udp')\nself.add_peers(make_kademlia_peer(None, address, port))\n- key = self.node.protocol.peer_manager.get_node_id_for_endpoint(address, port)\n+ key = node_id or self.node.protocol.peer_manager.get_node_id_for_endpoint(address, port)\n+ if not key:\nlatency = None\nfor _ in range(3):\ntry:\n@@ -182,6 +187,7 @@ class Crawler:\nawait self.node.protocol.get_rpc_peer(make_kademlia_peer(None, address, port)).ping()\nkey = key or self.node.protocol.peer_manager.get_node_id_for_endpoint(address, port)\nlatency = time.perf_counter_ns() - ping_start\n+ break\nexcept asyncio.TimeoutError:\npass\nexcept lbry.dht.error.RemoteException:\n@@ -229,7 +235,8 @@ class Crawler:\nto_process = {}\ndef submit(_peer):\n- f = asyncio.ensure_future(self.crawl_routing_table(_peer.address, peer.udp_port))\n+ f = asyncio.ensure_future(\n+ self.crawl_routing_table(_peer.address, peer.udp_port, bytes.fromhex(peer.node_id)))\nto_process[_peer] = f\nf.add_done_callback(lambda _: to_process.pop(_peer))\n",
        "chatgpt_cot": "\"Add handling for ROS Master start delay and connection issue in StartHandler to improve robustness and user experience.\""
    },
    {
        "org_diff": "diff --git a/src/api-engine/api/routes/node/views.py b/src/api-engine/api/routes/node/views.py @@ -120,23 +120,6 @@ class NodeViewSet(viewsets.ViewSet):\nnodes = Node.objects.filter(**query_filter)\np = Paginator(nodes, per_page)\nnodes = p.page(page)\n- nodes = [\n- {\n- \"id\": str(node.id),\n- \"name\": node.name,\n- \"type\": node.type,\n- \"organization\": node.organization,\n- \"urls\": node.urls,\n- \"network\": str(node.organization.network.id) if node.organization.network else None,\n- \"agents\": node.agent if node.agent else None,\n- #\"channel\": str(node.organization.channel.id) if node.organization.channel else None,\n- \"ports\": node.port,\n- \"created_at\": node.created_at,\n- \"status\": node.status\n- }\n- for node in nodes\n- ]\n-\nresponse = NodeListSerializer({\"total\": p.count, \"data\": nodes})\nreturn Response(data=ok(response.data), status=status.HTTP_200_OK)\nexcept Exception as e:\n",
        "org_msg": "Fix `dict` object has no attribut `urls` error in the get nodes endpoint\nRemove node conversion because we upgraded urls field from deprecated\nJSON field to django4.0 supported one.",
        "sim_msg": "Fix deprecation warning in DRF\nSee\nfor details.",
        "sim_diff": "diff --git a/api/views.py b/api/views.py @@ -14,7 +14,7 @@ from django.db.models import (\nWhen,\n)\nfrom rest_framework import viewsets\n-from rest_framework.decorators import list_route\n+from rest_framework.decorators import action\nfrom rest_framework.generics import ListAPIView, RetrieveAPIView\nfrom rest_framework.metadata import SimpleMetadata\nfrom rest_framework.pagination import PageNumberPagination\n@@ -424,7 +424,7 @@ class ReportsViewSet(ViewSet):\nreturn iterable\n- @list_route(methods=['GET'])\n+ @action(detail=False, methods=['GET'])\ndef workshops_over_time(self, request, format=None):\n\"\"\"Cumulative number of workshops run by Software Carpentry and other\ncarpentries over time.\"\"\"\n@@ -441,7 +441,7 @@ class ReportsViewSet(ViewSet):\nreturn Response(data)\n- @list_route(methods=['GET'])\n+ @action(detail=False, methods=['GET'])\ndef learners_over_time(self, request, format=None):\n\"\"\"Cumulative number of learners attending Software-Carpentry and other\ncarpentries' workshops over time.\"\"\"\n@@ -459,7 +459,7 @@ class ReportsViewSet(ViewSet):\nreturn Response(data)\n- @list_route(methods=['GET'])\n+ @action(detail=False, methods=['GET'])\ndef instructors_over_time(self, request, format=None):\n\"\"\"Cumulative number of instructor appearances on workshops over\ntime.\"\"\"\n@@ -486,7 +486,7 @@ class ReportsViewSet(ViewSet):\nreturn Response(data)\n- @list_route(methods=['GET'])\n+ @action(detail=False, methods=['GET'])\ndef instructor_num_taught(self, request, format=None):\nbadges = Badge.objects.instructor_badges()\npersons = Person.objects.filter(badges__in=badges).annotate(\n@@ -529,7 +529,7 @@ class ReportsViewSet(ViewSet):\nreturn start, end\n- @list_route(methods=['GET'])\n+ @action(detail=False, methods=['GET'])\ndef all_activity_over_time(self, request, format=None):\n\"\"\"Workshops, instructors, and missing data in specific periods.\"\"\"\nstart, end = self._default_start_end_dates(\n@@ -645,7 +645,7 @@ class ReportsViewSet(ViewSet):\n.select_related('person', 'event', 'role')\nreturn tasks\n- @list_route(methods=['GET'])\n+ @action(detail=False, methods=['GET'])\ndef instructors_by_time(self, request, format=None):\n\"\"\"Workshops and instructors who taught in specific time period.\"\"\"\nstart, end = self._default_start_end_dates(\n",
        "chatgpt_cot": "\"Refactor NodeViewSet to use NodeListSerializer and Paginator for better code organization and readability.\""
    },
    {
        "org_diff": "diff --git a/fkie_node_manager/src/fkie_node_manager/parameter_dialog.py b/fkie_node_manager/src/fkie_node_manager/parameter_dialog.py @@ -1022,7 +1022,13 @@ class ParameterDialog(QDialog):\nif len(values) > 0 and sidebar_var in params:\nself.horizontalLayout.addWidget(self.sidebar_frame)\ntry:\n+ if ':value' in params[sidebar_var]:\n+ self.sidebar_default_val = params[sidebar_var][':value']\n+ else:\nself.sidebar_default_val = params[sidebar_var][1]\n+ # add default value to sidebar\n+ if self.sidebar_default_val and self.sidebar_default_val not in values:\n+ values.append(self.sidebar_default_val)\nexcept Exception:\nself.sidebar_default_val = ''\nvalues.sort()\n",
        "org_msg": "fkie_node_manager: add default value to sidebar in start dialog",
        "sim_msg": "added quotes option on export",
        "sim_diff": "diff --git a/qualcoder/GUI/ui_dialog_SQL.py b/qualcoder/GUI/ui_dialog_SQL.py @@ -60,6 +60,11 @@ class Ui_Dialog_sql(object):\nself.comboBox_delimiter.addItem(\"\")\nself.comboBox_delimiter.addItem(\"\")\nself.horizontalLayout.addWidget(self.comboBox_delimiter)\n+ self.checkBox_quote = QtWidgets.QCheckBox(Dialog_sql)\n+ self.checkBox_quote.setMinimumSize(QtCore.QSize(120, 0))\n+ self.checkBox_quote.setMaximumSize(QtCore.QSize(120, 16777215))\n+ self.checkBox_quote.setObjectName(\"checkBox_quote\")\n+ self.horizontalLayout.addWidget(self.checkBox_quote)\nself.verticalLayout.addLayout(self.horizontalLayout)\nself.gridLayout.addLayout(self.verticalLayout, 0, 0, 1, 1)\n@@ -77,6 +82,8 @@ class Ui_Dialog_sql(object):\nself.comboBox_delimiter.setItemText(1, _translate(\"Dialog_sql\", \",\"))\nself.comboBox_delimiter.setItemText(2, _translate(\"Dialog_sql\", \";\"))\nself.comboBox_delimiter.setItemText(3, _translate(\"Dialog_sql\", \"|\"))\n+ self.checkBox_quote.setToolTip(_translate(\"Dialog_sql\", \"All fields quoted with quotation marks.\"))\n+ self.checkBox_quote.setText(_translate(\"Dialog_sql\", \"Quote\"))\nif __name__ == \"__main__\":\n",
        "chatgpt_cot": "Add default value to sidebar if present, to ensure correct display. Fix potential issue with sidebar default value not being shown."
    },
    {
        "org_diff": "diff --git a/node_manager_daemon_fkie/src/node_manager_daemon_fkie/launcher.py b/node_manager_daemon_fkie/src/node_manager_daemon_fkie/launcher.py @@ -319,7 +319,7 @@ def _load_parameters(masteruri, params, clear_params):\nfor pkey, pval in params.items():\nvalue = pval\n# resolve path elements\n- if value.startswith('$'):\n+ if isinstance(value, types.StringTypes) and value.startswith('$'):\nvalue = interpret_path(value)\nrospy.logdebug(\"interpret parameter '%s' to '%s'\" % (value, pval))\n# add parameter to the multicall\n",
        "org_msg": "node_manager_daemon_fkie: fixed test global parameter",
        "sim_msg": "fix filename extraction",
        "sim_diff": "diff --git a/pybamm/parameters/parameter_values.py b/pybamm/parameters/parameter_values.py @@ -331,11 +331,11 @@ class ParameterValues:\ndata_path = os.path.join(\npybamm.root_dir(), \"pybamm\", \"input\", \"drive_cycles\"\n)\n- filename = os.path.join(data_path, value[14:] + \".pkl\")\n- function_name = value[14:]\n+ filename = os.path.join(data_path, value[17:] + \".pkl\")\n+ function_name = value[17:]\nelse:\n- filename = os.path.join(path, value[6:] + \".pkl\")\n- function_name = value[6:]\n+ filename = os.path.join(path, value[9:] + \".pkl\")\n+ function_name = value[9:]\nfilename = pybamm.get_parameters_filepath(filename)\nmy_pspc = PybammStandardParameterClass(pkl_filename=filename)\ndata = my_pspc.get_interpolation_parameters()\n",
        "chatgpt_cot": "\"Fix interpretation of parameters in launcher.py to handle strings starting with '$' by checking if value is an instance of types.StringTypes.\""
    },
    {
        "org_diff": "diff --git a/fkie_node_manager/src/fkie_node_manager/master_view_proxy.py b/fkie_node_manager/src/fkie_node_manager/master_view_proxy.py @@ -78,10 +78,10 @@ from .supervised_popen import SupervisedPopen\nfrom .topic_list_model import TopicModel, TopicItem, TopicGroupItem\nimport fkie_node_manager as nm\ntry:\n- from python_qt_binding.QtGui import QAction, QFileDialog, QMenu, QShortcut, QWidget\n+ from python_qt_binding.QtGui import QAction, QFileDialog, QFrame, QMenu, QShortcut, QWidget\nfrom python_qt_binding.QtGui import QApplication, QVBoxLayout\nexcept Exception:\n- from python_qt_binding.QtWidgets import QAction, QFileDialog, QMenu, QShortcut, QWidget\n+ from python_qt_binding.QtWidgets import QAction, QFileDialog, QFrame, QMenu, QShortcut, QWidget\nfrom python_qt_binding.QtWidgets import QApplication, QVBoxLayout\n@@ -426,6 +426,7 @@ class MasterViewProxy(QWidget):\n# self._shortcut_copy.activated.connect(self.on_copy_c_pressed)\nself._shortcut_copy = QShortcut(QKeySequence(self.tr(\"Ctrl+X\", \"copy selected alternative values to clipboard\")), self)\nself._shortcut_copy.activated.connect(self.on_copy_x_pressed)\n+ self.ui.controlNodesFrame.resizeEvent = self.resizeEventButtons\n# print \"================ create\", self.objectName()\n#\n@@ -454,7 +455,7 @@ class MasterViewProxy(QWidget):\nself.stop_nodes_by_name(self.__echo_topics_dialogs, only_local=False)\nself.__echo_topics_dialogs.clear()\n- def resizeEvent(self, event):\n+ def resizeEventButtons(self, event):\nch_height = 0\nincrement = 4\nmin_spacer_size = 8\n@@ -489,7 +490,7 @@ class MasterViewProxy(QWidget):\nself.ui.deleteParameterButton.setIconSize(new_size)\nself.ui.saveParameterButton.setIconSize(new_size)\nself.ui.transferParameterButton.setIconSize(new_size)\n- QWidget.resizeEvent(self, event)\n+ QFrame.resizeEvent(self, event)\n@property\ndef current_user(self):\n",
        "org_msg": "fkie_node_manager: fixed resize of control buttons",
        "sim_msg": "select all and copy in the  text edit",
        "sim_diff": "diff --git a/qualcoder/cases.py b/qualcoder/cases.py @@ -113,6 +113,8 @@ class DialogCases(QtWidgets.QDialog):\nself.ui.textBrowser.setAutoFillBackground(True)\nself.ui.textBrowser.setContextMenuPolicy(Qt.CustomContextMenu)\nself.ui.textBrowser.customContextMenuRequested.connect(self.link_clicked)\n+ self.ui.textBrowser.setContextMenuPolicy(Qt.CustomContextMenu)\n+ self.ui.textBrowser.customContextMenuRequested.connect(self.textEdit_menu)\nself.fill_tableWidget()\nself.ui.splitter.setSizes([1, 1])\ntry:\n@@ -643,6 +645,21 @@ class DialogCases(QtWidgets.QDialog):\nprint(e)\nQtWidgets.QMessageBox.warning(None, 'view av/images error', str(e), QtWidgets.QMessageBox.Ok)\n+ def textEdit_menu(self, position):\n+ \"\"\" Context menu for textEdit. Select all, Copy. \"\"\"\n+\n+ menu = QtWidgets.QMenu()\n+ action_select_all = menu.addAction(_(\"Select all\"))\n+ action_copy = menu.addAction(_(\"Copy\"))\n+ action = menu.exec_(self.ui.textBrowser.mapToGlobal(position))\n+ if action == action_select_all:\n+ self.ui.textBrowser.selectAll()\n+ if action == action_copy:\n+ selected_text = self.ui.textBrowser.textCursor().selectedText()\n+ cb = QtWidgets.QApplication.clipboard()\n+ cb.clear(mode=cb.Clipboard)\n+ cb.setText(selected_text, mode=cb.Clipboard)\n+\nif __name__ == \"__main__\":\napp = QtWidgets.QApplication(sys.argv)\n",
        "chatgpt_cot": "Fix compilation issue due to the change of QtGui to QtWidgets, and resizeEvent method to resizeEventButtons in MasterViewProxy."
    },
    {
        "org_diff": "diff --git a/sc2/position.py b/sc2/position.py @@ -44,6 +44,13 @@ class Pointlike(tuple):\n\"\"\" Function used to not take the square root as the distances will stay proportionally the same. This is to speed up the sorting process. \"\"\"\nreturn (self[0] - p2[0]) ** 2 + (self[1] - p2[1]) ** 2\n+ def is_closer_than(self, d: Union[int, float], p: Union[\"Unit\", \"Point2\"]) -> bool:\n+ \"\"\" Check if another point (or unit) is closer than the given distance. More efficient than\n+ distance_to(p) < d.\n+ \"\"\"\n+ p = p.position\n+ return self._distance_squared(p) < d ** 2\n+\ndef sort_by_distance(self, ps: Union[\"Units\", List[\"Point2\"]]) -> List[\"Point2\"]:\n\"\"\" This returns the target points sorted as list. You should not pass a set or dict since those are not sortable.\nIf you want to sort your units towards a point, use 'units.sorted_by_distance_to(point)' instead. \"\"\"\n",
        "org_msg": "Add Pointlike.is_closer_than(dist, pos)",
        "sim_msg": "Added distances and distances_indices_sorted functions.",
        "sim_diff": "diff --git a/pymatgen/analysis/chemenv/utils/coordination_geometry_utils.py b/pymatgen/analysis/chemenv/utils/coordination_geometry_utils.py @@ -682,11 +682,32 @@ class Plane(object):\ndef distance_to_point(self, point):\n\"\"\"\nComputes the absolute distance from the plane to the point\n- :param point:\n- :return:\n+ :param point: Point for which distance is computed\n+ :return: Distance between the plane and the point\n\"\"\"\nreturn np.abs(np.dot(self.normal_vector, point) + self.d)\n+ def distances(self, points):\n+ \"\"\"\n+ Computes the distances from the plane to each of the points. Positive distances are on the side of the\n+ normal of the plane while negative distances are on the other side\n+ :param points: Points for which distances are computed\n+ :return: Distances from the plane to the points (positive values on the side of the normal to the plane,\n+ negative values on the other side)\n+ \"\"\"\n+ return [np.dot(self.normal_vector, pp) + self.d for pp in points]\n+\n+ def distances_indices_sorted(self, points):\n+ \"\"\"\n+ Computes the distances from the plane to each of the points. Positive distances are on the side of the\n+ normal of the plane while negative distances are on the other side\n+ :param points: Points for which distances are computed\n+ :return: Distances from the plane to the points (positive values on the side of the normal to the plane,\n+ negative values on the other side), as well as indices of the points from closest to furthest.\n+ \"\"\"\n+ distances = [np.dot(self.normal_vector, pp) + self.d for pp in points]\n+ return distances, sorted(range(len(distances)), key=lambda k: np.abs(distances[k]))\n+\ndef projectionpoints(self, pps):\n\"\"\"\nProjects each points in the point list pps on plane and returns the list of projected points\n",
        "chatgpt_cot": "Add method to check if a point or unit is closer than a given distance for efficiency. Improve sorting process."
    },
    {
        "org_diff": "diff --git a/fkie_node_manager/src/fkie_node_manager/start_handler.py b/fkie_node_manager/src/fkie_node_manager/start_handler.py @@ -116,16 +116,10 @@ class StartHandler(object):\ncmd_type = ''\nif cmd is None or len(cmd) == 0:\nraise StartException('%s in package [%s] not found!' % (binary, package))\n+ # compatibility for python scripts installed with catkin_install_python()\n+ # avoid ask for select a binary\n+ cmd = cls._remove_src_binary(cmd)\nif len(cmd) > 1:\n- if binary in ['node_manager_daemon', 'master_discovery', 'master_sync', 'zeroconf']:\n- # use path located not in src folder\n- for c in cmd:\n- if c.find('/src/') == -1:\n- cmd_type = c\n- break\n- # should not happen\n- cmd_type = cmd[0]\n- else:\n# Open selection for executables\nerr = 'Multiple executables with same name in package [%s] found' % package\nbsel = nm.BinarySelectionRequest(cmd, err)\n@@ -196,6 +190,18 @@ class StartHandler(object):\nexcept nm.AuthenticationRequest as e:\nraise nm.InteractionNeededError(e, cls.runNodeWithoutConfig, {'host': host, 'package': package, 'binary': binary, 'name': name, 'args': args, 'masteruri': masteruri, 'use_nmd': use_nmd, 'auto_pw_request': auto_pw_request, 'user': user, 'pw': pw, 'path': path})\n+ @classmethod\n+ def _remove_src_binary(cls, cmdlist):\n+ result = []\n+ if len(cmdlist) > 1:\n+ for c in cmdlist:\n+ if c.find('/src/') == -1:\n+ result.append(c)\n+ else:\n+ result = cmdlist\n+ return result\n+\n+\n@classmethod\ndef _prepareROSMaster(cls, masteruri):\nif masteruri is None:\n",
        "org_msg": "fkie_node_manager: avoid ask for binary to select\nif located in devel and src",
        "sim_msg": "Check package download status and unpack if avail.",
        "sim_diff": "diff --git a/fedn/fedn/client.py b/fedn/fedn/client.py @@ -89,10 +89,15 @@ class Client:\nfrom fedn.common.control.package import PackageRuntime\npr = PackageRuntime(os.getcwd(), os.getcwd())\n- pr.download(config['discover_host'], config['discover_port'], config['token'])\n+ retval = pr.download(config['discover_host'], config['discover_port'], config['token'])\n+ if retval:\npr.unpack()\n+\nself.dispatcher = pr.dispatcher()\n+ try:\nself.dispatcher.run_cmd(\"startup\")\n+ except KeyError:\n+ print(\"No startup code present. skipping\")\nelse:\ndispatch_config = {'entry_points':\n{'predict': {'command': 'python3 predict.py'},\n",
        "chatgpt_cot": "\"Fix compatibility for python scripts installed with catkin_install_python() and avoid asking for selecting a binary in start_handler.py\""
    },
    {
        "org_diff": "diff --git a/docs/setup_worker_docker.md b/docs/setup_worker_docker.md @@ -26,7 +26,7 @@ ExecStart=/usr/bin/dockerd -H fd:// -H unix:///var/run/docker.sock -H tcp://0.0.\n```\n#### Ubuntu 16.04\n-Edit systemd service config file `usr/lib/systemd/system/docker.service`, update the `ExecStart` line under section `[Service]`, as the following:\n+Edit systemd service config file `/lib/systemd/system/docker.service`, update the `ExecStart` line under section `[Service]`, as the following:\n```\n[Service]\n",
        "org_msg": "Fixing docker daemon setup for Ubuntu\nI found that the location of systemd service config file in Ubuntu 16.04 is not in\nusr/lib/systemd/system/docker.service\nSo, I change current path in setup_worker_docker.md file.\n(https://gerrit.hyperledger.org/r/#/c/28003/)\nI tested in Ubuntu 16.04.5 LTS",
        "sim_msg": "Isolating the part of the docker build that fails",
        "sim_diff": "diff --git a/util/docker/backend/Dockerfile b/util/docker/backend/Dockerfile @@ -34,9 +34,10 @@ COPY ./util/docker/backend/backend.docker.config.json .\n#Might want to set these up in differant RUN statements.\nRUN set -x \\\n- && pip install . \\\n- && ./scripts/install/workers.sh \\\n- && augur config init --rc-config-file /augur/backend.docker.config.json \\\n+ && pip install .\n+\n+RUN ./scripts/install/workers.sh\n+RUN augur config init --rc-config-file /augur/backend.docker.config.json \\\n&& mkdir -p repos/ logs/\nCOPY ./util/docker/backend/entrypoint.sh /\n",
        "chatgpt_cot": "Update docker service config file path in setup_worker_docker.md for Ubuntu 16.04 to fix the file path issue."
    },
    {
        "org_diff": "diff --git a/fkie_node_manager/src/fkie_node_manager/master_view_proxy.py b/fkie_node_manager/src/fkie_node_manager/master_view_proxy.py @@ -1923,12 +1923,12 @@ class MasterViewProxy(QWidget):\nlogging = None\ndiag_canceled = False\nif use_adv_cfg:\n- log_params = {'Level': ('string', nm.settings().logging.get_alternatives('loglevel')),\n+ log_params = {'Level': {':type': 'string', ':value': nm.settings().logging.get_alternatives('loglevel')},\n# 'Level (roscpp)': ('string', nm.settings().logging.get_alternatives('loglevel_roscpp')),\n# 'Level (super)': ('string', nm.settings().logging.get_alternatives('loglevel_superdebug')),\n- 'Format': ('string', nm.settings().logging.get_alternatives('console_format'))\n+ 'Format': {':type': 'string', ':value': nm.settings().logging.get_alternatives('console_format')}\n}\n- params = {'Logging': ('dict', log_params)}\n+ params = {'Logging': log_params}\ndia = ParameterDialog(params, store_geometry=\"adv_cfg_dialog\")\ndia.setFilterVisible(False)\ndia.setWindowTitle('Start with parameters')\n@@ -2081,7 +2081,7 @@ class MasterViewProxy(QWidget):\n'''\ncursor = self.cursor()\nself.masterTab.startButton.setEnabled(False)\n- params = {'Host': ('string', 'localhost')}\n+ params = {'Host': {':type': 'string', ':value': 'localhost'}}\ndia = ParameterDialog(params, store_geometry=\"start_node_at_host_dialog\")\ndia.setFilterVisible(False)\ndia.setWindowTitle('Start node on...')\n",
        "org_msg": "fkie_node_manager: fixed paramter dialog for advanced node start",
        "sim_msg": "Modify set_global_logger_level use of contextmanager",
        "sim_diff": "diff --git a/qlib/log.py b/qlib/log.py @@ -165,8 +165,16 @@ class LogFilter(logging.Filter):\nreturn allow\n+@contextmanager\ndef set_global_logger_level(level: int):\n+ _handler_level_map = {}\nqlib_logger = logging.root.manager.loggerDict.get(\"qlib\", None)\nif qlib_logger is not None:\nfor _handler in qlib_logger.handlers:\n+ _handler_level_map[_handler] = _handler.level\n_handler.level = level\n+ try:\n+ yield\n+ finally:\n+ for _handler, _level in _handler_level_map.items():\n+ _handler.level = _level\n",
        "chatgpt_cot": "\"Fix the parameter display issue in the master view proxy file\""
    },
    {
        "org_diff": "diff --git a/examples/competitive/example_bot.py b/examples/competitive/example_bot.py import sc2\n-class ExampleBot(sc2.BotAI):\n- def __init__(self):\n- # Improves bot performance by a little bit\n- self.raw_affects_selection = True\n- # The distance calculation method: 0 for raw python, 1 for scipy pdist, 2 for scipy cdist\n- self.distance_calculation_method = 2\n+class ExampleBot(sc2.BotAI):\nasync def on_step(self, iteration):\n# Populate this function with whatever your bot should do!\npass\nasync def on_start(self):\nprint(\"Game started\")\n- # On game start or in any frame actually, you can set the game step here - do not put it in the __init__ function as the client will not have been initialized yet\n- self.client.game_step = 2\n- # On first step/frame, send all workers to attack the enemy start location\n- for worker in self.workers:\n- self.do(worker.attack(self.enemy_start_locations[0]))\n+ # Do things here before the game starts\ndef on_end(self, result):\n- print(\"OnGameEnd() was called.\")\n+ print(\"Game ended.\")\n+ # Do things here after the game ends\n",
        "org_msg": "Clean out the example competitive bot in order to use it as a standard clean template.",
        "sim_msg": "CS fixes and minor changes from comments",
        "sim_diff": "diff --git a/mpf/modes/game/code/game.py b/mpf/modes/game/code/game.py -\"\"\"Contains the Game class which is the Machine Mode that actually runs and manages an the game in a pinball machine.\n+\"\"\"Contains the Game class which is the Machine Mode that actually runs and manages\n+the game in a pinball machine.\nNote that in the Mission Pinball Framework, a distinction is made between a\n*game* and a *machine*. A *game* refers to a game in progress, whereas a\n@@ -71,13 +72,12 @@ class Game(AsyncMode):\nwhile True:\n# Wait for end ball event to be set\nyield from self._end_ball_event.wait()\n- if self._end_ball_event.is_set():\nyield from self._end_ball()\nself._end_ball_event.clear()\n@asyncio.coroutine\ndef _start_game(self):\n- \"\"\"Start a new game\"\"\"\n+ \"\"\"Start a new game.\"\"\"\nself.debug_log(\"Game start\")\n@@ -185,8 +185,8 @@ class Game(AsyncMode):\nyield from self._award_extra_ball()\nreturn\n- if (self.player.ball == self.machine.config['game']['balls_per_game'] and\n- self.player.number == self.num_players):\n+ if (self.player.ball == self.machine.config['game'][\n+ 'balls_per_game'] and self.player.number == self.num_players):\nyield from self._end_game()\nelse:\nyield from self._end_player_turn()\n@@ -256,9 +256,12 @@ class Game(AsyncMode):\ndef mode_stop(self, **kwargs):\n\"\"\"Stop mode.\"\"\"\n+ del kwargs\n+\nfor mode in self.machine.modes:\nif mode.active and mode.is_game_mode:\n- raise AssertionError(\"Mode {} is not supposed to run outside of game.\".format(mode.name))\n+ raise AssertionError(\"Mode {} is not supposed to run outside of game.\"\n+ .format(mode.name))\nself.machine.game = None\n@asyncio.coroutine\n@@ -275,9 +278,10 @@ class Game(AsyncMode):\nself.debug_log(\"***************************************************\")\nself.debug_log(\"****************** BALL STARTING ******************\")\nself.debug_log(\"** **\")\n- self.debug_log(\"** Player: {} Ball: {} Score: {}\".format(\n- self.player.number, self.player.ball,\n- self.player.score).ljust(49) + '**')\n+ self.debug_log(\"** Player: {} Ball: {} Score: {}\".format(self.player.number,\n+ self.player.ball,\n+ self.player.score\n+ ).ljust(49) + '**')\nself.debug_log(\"** **\")\nself.debug_log(\"***************************************************\")\nself.debug_log(\"***************************************************\")\n@@ -480,7 +484,8 @@ class Game(AsyncMode):\nself.machine.events.post_queue('player_adding',\nplayer=player,\nnumber=player.number,\n- callback=partial(self._player_adding_complete, player=player))\n+ callback=partial(self._player_adding_complete,\n+ player=player))\n'''event: player_adding\ndesc: A new player is in the process of being added to this game. This is a queue\nevent, and the player won't actually be finished adding until the queue is cleared.\n@@ -548,7 +553,6 @@ class Game(AsyncMode):\nThese machine variables are updated at the end of each player's\nturn, and they persist on disk so they are restored the next time\nMPF starts up.\n-\n'''\nreturn True\n",
        "chatgpt_cot": "\"Refactor ExampleBot class to use async methods and update print statements for on_start and on_end functions.\""
    },
    {
        "org_diff": "diff --git a/sc2/bot_ai.py b/sc2/bot_ai.py @@ -4,6 +4,8 @@ import random\nfrom collections import Counter\nfrom typing import Any, Dict, List, Optional, Set, Tuple, Union # mypy type checking\n+from s2clientprotocol import common_pb2 as common_pb\n+\nfrom .cache import property_cache_forever, property_cache_once_per_frame\nfrom .data import ActionResult, Alert, Race, Result, Target, race_gas, race_townhalls, race_worker\nfrom .game_data import AbilityData, GameData\n@@ -387,7 +389,9 @@ class BotAI:\ndef select_build_worker(self, pos: Union[Unit, Point2, Point3], force: bool = False) -> Optional[Unit]:\n\"\"\"Select a worker to build a building with.\"\"\"\n- workers = self.workers.filter(lambda w: (w.is_gathering or w.is_idle) and w.distance_to(pos) < 20) or self.workers\n+ workers = (\n+ self.workers.filter(lambda w: (w.is_gathering or w.is_idle) and w.distance_to(pos) < 20) or self.workers\n+ )\nif workers:\nfor worker in workers.sorted_by_distance_to(pos).prefer_idle:\nif (\n@@ -582,10 +586,12 @@ class BotAI:\nreturn r\n- async def do_actions(self, actions: List[\"UnitCommand\"]):\n+ async def do_actions(self, actions: List[\"UnitCommand\"], prevent_double=True):\n\"\"\" Unlike 'self.do()', this function does not instantly subtract minerals and vespene. \"\"\"\nif not actions:\nreturn None\n+ if prevent_double:\n+ actions = list(filter(self.prevent_double_actions, actions))\nfor action in actions:\ncost = self._game_data.calculate_ability_cost(action.ability)\nself.minerals -= cost.minerals\n@@ -593,6 +599,36 @@ class BotAI:\nreturn await self._client.actions(actions)\n+ def prevent_double_actions(self, action):\n+ if action.unit.orders:\n+ # action: UnitCommand\n+ # current_action: UnitOrder\n+ current_action = action.unit.orders[0]\n+ # always add actions if queued\n+ if action.queue:\n+ return True\n+ # different action\n+ if current_action.ability.id != action.ability:\n+ return True\n+ if (\n+ isinstance(current_action.target, int)\n+ and isinstance(action.target, Unit)\n+ and current_action.target == action.target.tag\n+ ):\n+ # remove action if same target unit\n+ return False\n+ elif (\n+ isinstance(action.target, Point2)\n+ and isinstance(current_action.target, common_pb.Point)\n+ and (action.target.x, action.target.y) == (current_action.target.x, current_action.target.y)\n+ ):\n+ # remove action if same target position\n+ return False\n+ else:\n+ return True\n+ else:\n+ return True\n+\nasync def chat_send(self, message: str):\n\"\"\"Send a chat message.\"\"\"\nassert isinstance(message, str), f\"{message} is no string\"\n",
        "org_msg": "Prevent double actions",
        "sim_msg": "Forgot to update iNumPlayers",
        "sim_diff": "diff --git a/v3/runner.py b/v3/runner.py @@ -63,6 +63,8 @@ if __name__ == '__main__':\ncallbacks = []\nname_dict = dict()\n+ gameInputPacket.iNumPlayers = num_bots\n+\n# Set configuration values for bots and store name and team\nfor i in range(num_bots):\nbot_config = configparser.RawConfigParser()\n",
        "chatgpt_cot": "\"Add prevent_double_actions method to avoid double actions and fix compilation issue due to the new method in BotAI.\""
    },
    {
        "org_diff": "diff --git a/sc2/client.py b/sc2/client.py @@ -181,8 +181,8 @@ class Client(Protocol):\nassert len(units) > 0\nresult = await self._execute(query=query_pb.RequestQuery(\nabilities=[query_pb.RequestQueryAvailableAbilities(\n- unit_tag=unit.tag) for unit in units]),\n- ignore_resource_requirements=ignore_resource_requirements\n+ unit_tag=unit.tag) for unit in units],\n+ ignore_resource_requirements=ignore_resource_requirements)\n)\nreturn [[AbilityId(a.ability_id) for a in b.abilities] for b in result.query.abilities]\n",
        "org_msg": "Fix misplaced bracket",
        "sim_msg": "read more if you have more\nKeep reading requests from a socket if the client connection read a\npartial response.",
        "sim_diff": "diff --git a/hsdev/client.py b/hsdev/client.py @@ -46,6 +46,9 @@ class HsDevConnection(object):\nreturn json.loads(req_resp)\n+ def have_more(self):\n+ return len(self.partial) > 0\n+\ndef close(self):\ntry:\nself.socket.close()\n@@ -178,6 +181,9 @@ class HsDevClient(object):\nif conn is not None:\nself.get_response(conn)\n+ # Continue to process incomplete responses -- it means we haven't read enough.\n+ while conn.have_more():\n+ self.get_response(conn)\nelse:\nLogging.log('HsDevClient.receiver: no corresponding connection {0}'.format(inp.fileobj),\nLogging.LOG_ERROR)\n",
        "chatgpt_cot": "fix syntax error in Client class for query execution to ensure proper execution of abilities with unit tags and resource requirements."
    },
    {
        "org_diff": "diff --git a/.travis.yml b/.travis.yml @@ -13,7 +13,8 @@ install:\n- pip install coveralls==1.3.0\n- pip list\nscript:\n-- travis_wait py.test tests --cov rasa_core_sdk --pep8 -v\n+- py.test --pep8 -m pep8\n+- travis_wait py.test tests --cov rasa_core_sdk -v\nafter_success:\n- coveralls\njobs:\n",
        "org_msg": "test all directories for pep8 compliance",
        "sim_msg": "travis build failing with 0 errors and 0 failures, 40 \"unexpected successes\"",
        "sim_diff": "diff --git a/.travis.yml b/.travis.yml @@ -46,8 +46,7 @@ install:\n- pip install -e .[all,test]\n- pip install coveralls\nscript:\n- #- coverage run setup.py test\n- - python setup.py test\n-#after_success:\n- #- coverage combine\n- #- coveralls\n+ - coverage run setup.py test\n+after_success:\n+ - coverage combine\n+ - coveralls\n",
        "chatgpt_cot": "Refactor travis.yml to improve test coverage and code style. Modified the script to run pep8 checks before running tests for rasa_core_sdk."
    },
    {
        "org_diff": "diff --git a/fkie_node_manager/src/fkie_node_manager/MainWindow.ui b/fkie_node_manager/src/fkie_node_manager/MainWindow.ui @@ -763,6 +763,12 @@ p, li { white-space: pre-wrap; }\n<layout class=\"QVBoxLayout\" name=\"verticalLayout_4\">\n<item>\n<widget class=\"QFrame\" name=\"ui_nav_frame\">\n+ <property name=\"sizePolicy\">\n+ <sizepolicy hsizetype=\"Preferred\" vsizetype=\"Minimum\">\n+ <horstretch>0</horstretch>\n+ <verstretch>0</verstretch>\n+ </sizepolicy>\n+ </property>\n<property name=\"frameShape\">\n<enum>QFrame::NoFrame</enum>\n</property>\n",
        "org_msg": "fix for navigation bar in help view",
        "sim_msg": "buttons to enter and exit edit mode",
        "sim_diff": "diff --git a/GUI_UIs/ui_dialog_code_text.ui b/GUI_UIs/ui_dialog_code_text.ui <rect>\n<x>0</x>\n<y>0</y>\n- <width>1024</width>\n+ <width>1054</width>\n<height>695</height>\n</rect>\n</property>\n<string>Code Text</string>\n</property>\n<layout class=\"QGridLayout\" name=\"gridLayout_2\">\n+ <item row=\"1\" column=\"0\">\n+ <widget class=\"QGroupBox\" name=\"groupBox_edit_mode\">\n+ <property name=\"minimumSize\">\n+ <size>\n+ <width>0</width>\n+ <height>80</height>\n+ </size>\n+ </property>\n+ <property name=\"maximumSize\">\n+ <size>\n+ <width>16777215</width>\n+ <height>80</height>\n+ </size>\n+ </property>\n+ <property name=\"title\">\n+ <string/>\n+ </property>\n+ <layout class=\"QGridLayout\" name=\"gridLayout_3\">\n+ <item row=\"1\" column=\"1\">\n+ <widget class=\"QPushButton\" name=\"pushButton_exit_edit\">\n+ <property name=\"minimumSize\">\n+ <size>\n+ <width>28</width>\n+ <height>28</height>\n+ </size>\n+ </property>\n+ <property name=\"maximumSize\">\n+ <size>\n+ <width>28</width>\n+ <height>28</height>\n+ </size>\n+ </property>\n+ <property name=\"toolTip\">\n+ <string>Exit Edit text </string>\n+ </property>\n+ <property name=\"text\">\n+ <string/>\n+ </property>\n+ </widget>\n+ </item>\n+ <item row=\"0\" column=\"0\" rowspan=\"2\">\n+ <widget class=\"QLabel\" name=\"label_editing\">\n+ <property name=\"enabled\">\n+ <bool>true</bool>\n+ </property>\n+ <property name=\"maximumSize\">\n+ <size>\n+ <width>16777215</width>\n+ <height>76</height>\n+ </size>\n+ </property>\n+ <property name=\"text\">\n+ <string/>\n+ </property>\n+ <property name=\"wordWrap\">\n+ <bool>true</bool>\n+ </property>\n+ </widget>\n+ </item>\n+ </layout>\n+ </widget>\n+ </item>\n<item row=\"0\" column=\"0\">\n<widget class=\"QGroupBox\" name=\"groupBox\">\n<property name=\"minimumSize\">\n</rect>\n</property>\n<property name=\"toolTip\">\n- <string>Edit text mode.\n-You can click on a position, without selecting text, to type, delete, or paste text.\n-You can select text that is not underlined and delete or paste over.\n+ <string>Edit text\n+Click on a position, without selecting text, to type, delete, or paste text.\n+Select text that is not underlined and delete or paste over.\nAvoid selecting text to delete or paste over if the selected text is underlined:\n(coded - red, annotated - yellow, case-assigned - green)\n-As all assigned positions may be wrong. </string>\n+As all assigned positions may be incorrect. </string>\n</property>\n<property name=\"text\">\n<string/>\n@@ -487,25 +549,6 @@ As all assigned positions may be wrong. </string>\n</widget>\n</widget>\n</item>\n- <item row=\"1\" column=\"0\">\n- <widget class=\"QLabel\" name=\"label_editing\">\n- <property name=\"enabled\">\n- <bool>true</bool>\n- </property>\n- <property name=\"maximumSize\">\n- <size>\n- <width>16777215</width>\n- <height>80</height>\n- </size>\n- </property>\n- <property name=\"text\">\n- <string/>\n- </property>\n- <property name=\"wordWrap\">\n- <bool>true</bool>\n- </property>\n- </widget>\n- </item>\n<item row=\"2\" column=\"0\">\n<widget class=\"QSplitter\" name=\"splitter\">\n<property name=\"orientation\">\n",
        "chatgpt_cot": "Add size policy to ui_nav_frame to ensure preferred horizontal size and minimum vertical size in MainWindow.ui."
    },
    {
        "org_diff": "diff --git a/sc2/proxy.py b/sc2/proxy.py @@ -24,7 +24,8 @@ class Proxy:\nself.controller = controller\nself.player = player\nself.port = proxyport\n- self.timeout_loop = game_time_limit * 22.4\n+ self.timeout_loop = game_time_limit * 22.4 if game_time_limit else None\n+ logger.debug(f\"Proxy Inited with ctrl {controller}({controller._process._port}), player {player}, proxyport {proxyport}, lim {game_time_limit}\")\nself.result = None\nself.player_id: int = None\n",
        "org_msg": "fix None crash",
        "sim_msg": "Use `mode.value` instead enumerate.",
        "sim_diff": "diff --git a/app/objects/player.py b/app/objects/player.py @@ -536,14 +536,14 @@ class Player:\nasync with app.state.services.database.connection() as db_conn:\nawait self.stats_from_sql_full(db_conn)\n- for idx, mode_stat in enumerate(self.stats.values()):\n+ for mode, stats in self.stats.items():\nawait app.state.services.redis.zadd(\n- f\"gulag:leaderboard:{idx}\",\n- {self.id: mode_stat.pp},\n+ f\"gulag:leaderboard:{mode.value}\",\n+ {self.id: stats.pp},\n)\nawait app.state.services.redis.zadd(\n- f\"gulag:leaderboard:{idx}:{self.geoloc['country']['acronym']}\",\n- {self.id: mode_stat.pp},\n+ f\"gulag:leaderboard:{mode.value}:{self.geoloc['country']['acronym']}\",\n+ {self.id: stats.pp},\n)\nif \"restricted\" in self.__dict__:\n",
        "chatgpt_cot": "Update timeout calculation in Proxy class to handle case when game_time_limit is None and add debug log for initialization."
    },
    {
        "org_diff": "diff --git a/.gitignore b/.gitignore @@ -7,6 +7,7 @@ __pycache__/\n.mypy_cache/\n.pytest_cache/\n+test/pickle_data/\nbuild/\ndist/\n@@ -14,8 +15,6 @@ dist/\n.cache/\n-test/pickle_data/\n-\n# SC2 things\nmaps/\nmini_games/\n@@ -25,3 +24,6 @@ mini_games/\n# Editors\n.idea/\n.vscode/\n+\n+# Temp image files\n+*.png\n\\ No newline at end of file\n",
        "org_msg": "Organize .gitignore",
        "sim_msg": "[queue][NFC] Improve .gitignore file\nIgnore emacs backup files.\nDon't bother ignoring variants of virtualenvs, we only use one.\nSee",
        "sim_diff": "diff --git a/.gitignore b/.gitignore @@ -19,12 +19,8 @@ __pycache__/\n.pytype/\n-# Virtual environments.\n-.env\n+# Virtualenv\n.venv\n-env/\n-venv/\n-ENV/\n# Reports generated by FuzzBench.\nreport/\n@@ -36,3 +32,7 @@ docs/vendor/\n# Auto-generated build files.\ndocker/generated.mk\n+\n+# Emacs backup files.\n+*~\n+\\#*\\#\n\\ No newline at end of file\n",
        "chatgpt_cot": "Add test pickle data to gitignore and ignore temp image files."
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/settings.py b/node_manager_fkie/src/node_manager_fkie/settings.py @@ -494,7 +494,7 @@ class Settings(object):\nself._terminal_emulator = t\nbreak\nif self._terminal_emulator == \"\":\n- return \"\"\n+ raise Exception(\"No Terminal found! Please install one of ['/usr/bin/x-terminal-emulator', '/usr/bin/xterm', '/opt/x11/bin/xterm']\")\nnoclose_str = noclose_str if noclose else \"\"\nreturn '%s -T \"%s\" %s -%s %s' % (self._terminal_emulator, title, noclose_str, self._terminal_command_arg, ' '.join(cmd))\n",
        "org_msg": "added a raise Exception if no terminal is availabe",
        "sim_msg": "wrong exception",
        "sim_diff": "diff --git a/openbb_terminal/parent_classes.py b/openbb_terminal/parent_classes.py @@ -681,7 +681,7 @@ class BaseController(metaclass=ABCMeta):\nf\"{sys.executable} terminal.py\", shell=True, check=False\n)\nif out.returncode != 0:\n- console.print(\"Unfortunately, resetting wasn't possible!\\n\")\n+ raise Exception(\"Error while logging out.\")\n@log_start_end(log=logger)\ndef call_whoami(self, other_args: List[str]) -> None:\n",
        "chatgpt_cot": "\"Add exception for missing terminal and update return statement to handle missing terminal in Settings.py\""
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/master_view_proxy.py b/node_manager_fkie/src/node_manager_fkie/master_view_proxy.py @@ -2140,6 +2140,9 @@ class MasterViewProxy(QWidget):\np.shutdown(rospy.get_name(), '[node manager] request from %s' % self.mastername)\n# 'print \"STOP stop finished\", node\nif node.kill_on_stop and node.pid:\n+ # wait kill_on_stop is an integer\n+ if isinstance(node.kill_on_stop, (int, float)):\n+ time.sleep(float(node.kill_on_stop) / 1000.0)\nnm.nmd().kill_process(node.pid, nmdurl.nmduri(node.masteruri))\nexcept Exception, e:\nrospy.logwarn(\"Error while stop node '%s': %s\", utf8(node.name), utf8(e))\n",
        "org_msg": "node_manager_fkie: sleep if kill_on_stop is an integer or float",
        "sim_msg": "Added logging statement for when node completes image pull",
        "sim_diff": "diff --git a/scale/scheduler/node/node_class.py b/scale/scheduler/node/node_class.py @@ -182,6 +182,7 @@ class Node(object):\nif task_update.status == TaskStatusUpdate.FINISHED:\nself._is_image_pulled = True\n+ logger.info('Node %s has finished pulling the Scale image', self._hostname)\nelif task_update.status == TaskStatusUpdate.FAILED:\nlogger.warning('Scale image pull task on host %s failed', self._hostname)\nelif task_update.status == TaskStatusUpdate.KILLED:\n",
        "chatgpt_cot": "Add check for integer/float type in kill_on_stop, wait accordingly. Fix potential issue with node kill."
    },
    {
        "org_diff": "diff --git a/docs/worker_ansible_howto.md b/docs/worker_ansible_howto.md @@ -117,13 +117,13 @@ modules for that cloud. Here are the steps to install Ansible modules for AWS,\nAzure and OpenStack respectively:\nAWS:\n- sudo pip3 install boto boto3\n+ sudo pip install boto boto3\nAzure:\n- sudo pip3 install azure\n+ sudo pip install azure\nOpenStack:\n- sudo pip3 install shade\n+ sudo pip install shade\nThese modules are used during the [Provision the servers](#provision-the-servers)\nstep. If you are not running the Ansible agent against a cloud provider, you do\n",
        "org_msg": "Remove references to `pip3`",
        "sim_msg": "kvm: fix adding tunnel info during inventory generation",
        "sim_diff": "diff --git a/kvirt/ansibleutils/__init__.py b/kvirt/ansibleutils/__init__.py @@ -123,7 +123,6 @@ def make_plan_inventory(vms_to_host, plan, vms, groups={}, user=None, yamlinvent\n:param yamlinventory:\n\"\"\"\ninventory = {}\n- clientinventory = {}\ninventoryfile = \"/tmp/%s.inv.yaml\" % plan if yamlinventory else \"/tmp/%s.inv\" % plan\npprint(\"Generating inventory %s\" % inventoryfile, color='blue')\nif groups:\n@@ -136,45 +135,31 @@ def make_plan_inventory(vms_to_host, plan, vms, groups={}, user=None, yamlinvent\nfor name in nodes:\nk = vms_to_host[name].k\nclient = vms_to_host[name].client\n- if client not in clientinventory:\n- clientinventory[client] = {'hosts': {}}\ninv = vm_inventory(k, name, user=user, yamlinventory=yamlinventory)\nif inv is not None:\n- clientinventory[client]['hosts'][name] = inv\ninventory[plan]['children'][group]['hosts'][name] = inv\n+ if vms_to_host[name].tunnel:\n+ tunnelinfo = \"-o ProxyCommand=\\\"ssh -p %s -W %%h:%%p %s@%s\\\"\" % (vms_to_host[name].port, vms_to_host[name].user, vms_to_host[name].host)\n+ if yamlinventory:\n+ inventory[plan]['children'][group]['hosts'][name]['ansible_ssh_common_args'] = tunnelinfo\n+ else:\n+ inventory[plan]['hosts'][name] += \" ansible_ssh_common_args='%s'\" % tunnelinfo\nelse:\ninventory[plan] = {'hosts': {}}\nfor name in vms:\nk = vms_to_host[name].k\nclient = vms_to_host[name].client\n- if client not in clientinventory:\n- clientinventory[client] = {'hosts': {}}\ninv = vm_inventory(k, name, user=user, yamlinventory=yamlinventory)\nif inv is not None:\ninventory[plan]['hosts'][name] = inv\n- clientinventory[client]['hosts'][name] = inv\n- for entry in vms_to_host.values():\n- client = entry.client\n- tunnel = entry.tunnel\n- tunneluser = entry.user\n- tunnelport = entry.port\n- tunnelhost = entry.host\n- if tunnel:\n- tunnelinfo = \"-o ProxyCommand=\\\"ssh -p %s -W %%h:%%p %s@%s\\\"\" % (tunnelport, tunneluser, tunnelhost)\n- if client in clientinventory and 'vars' not in clientinventory[client]:\n- clientinventory[client]['vars'] = {'ansible_ssh_common_args': tunnelinfo}\n- for name in inventory[plan]['hosts']:\n- for client in clientinventory:\n- if name in clientinventory[client]['hosts']:\n- tunnelinfo = clientinventory[client]['vars']['ansible_ssh_common_args']\n+ if vms_to_host[name].tunnel:\n+ tunnelinfo = \"-o ProxyCommand=\\\"ssh -p %s -W %%h:%%p %s@%s\\\"\" % (vms_to_host[name].port, vms_to_host[name].user, vms_to_host[name].host)\nif yamlinventory:\ninventory[plan]['hosts'][name]['ansible_ssh_common_args'] = tunnelinfo\nelse:\ninventory[plan]['hosts'][name] += \" ansible_ssh_common_args='%s'\" % tunnelinfo\n- break\nwith open(inventoryfile, \"w\") as f:\nif yamlinventory:\n- # inventory.update(clientinventory)\ndump({'all': {'children': inventory}}, f, default_flow_style=False)\nelse:\ninventorystr = ''\n",
        "chatgpt_cot": "Update pip installation commands for AWS, Azure, and OpenStack modules in worker_ansible_howto.md to use pip instead of pip3."
    },
    {
        "org_diff": "diff --git a/fkie_node_manager/src/fkie_node_manager/parameter_dialog.py b/fkie_node_manager/src/fkie_node_manager/parameter_dialog.py @@ -1019,7 +1019,7 @@ class ParameterDialog(QDialog):\nsidebarframe_verticalLayout.setObjectName(\"sidebarframe_verticalLayout\")\nsidebarframe_verticalLayout.setContentsMargins(3, 3, 3, 3)\nself._sidebar_selected = 0\n- if len(values) > 1 and sidebar_var in params:\n+ if len(values) > 0 and sidebar_var in params:\nself.horizontalLayout.addWidget(self.sidebar_frame)\ntry:\nself.sidebar_default_val = params[sidebar_var][1]\n",
        "org_msg": "fkie_node_manager: show all hosts in side bar",
        "sim_msg": "added reveal button",
        "sim_diff": "diff --git a/qualcoder/GUI/ui_dialog_graph.py b/qualcoder/GUI/ui_dialog_graph.py @@ -35,16 +35,20 @@ class Ui_DialogGraph(object):\nself.checkBox_blackandwhite.setGeometry(QtCore.QRect(0, 6, 181, 22))\nself.checkBox_blackandwhite.setObjectName(\"checkBox_blackandwhite\")\nself.pushButton_export = QtWidgets.QPushButton(self.groupBox_header)\n- self.pushButton_export.setGeometry(QtCore.QRect(840, 6, 28, 28))\n+ self.pushButton_export.setGeometry(QtCore.QRect(870, 6, 28, 28))\nself.pushButton_export.setText(\"\")\nself.pushButton_export.setObjectName(\"pushButton_export\")\nself.comboBox_fontsize = QtWidgets.QComboBox(self.groupBox_header)\nself.comboBox_fontsize.setGeometry(QtCore.QRect(290, 5, 71, 30))\nself.comboBox_fontsize.setObjectName(\"comboBox_fontsize\")\nself.label_zoom = QtWidgets.QLabel(self.groupBox_header)\n- self.label_zoom.setGeometry(QtCore.QRect(882, 7, 28, 28))\n+ self.label_zoom.setGeometry(QtCore.QRect(910, 7, 28, 28))\nself.label_zoom.setText(\"\")\nself.label_zoom.setObjectName(\"label_zoom\")\n+ self.pushButton_reveal = QtWidgets.QPushButton(self.groupBox_header)\n+ self.pushButton_reveal.setGeometry(QtCore.QRect(832, 6, 28, 28))\n+ self.pushButton_reveal.setText(\"\")\n+ self.pushButton_reveal.setObjectName(\"pushButton_reveal\")\nself.gridLayout.addWidget(self.groupBox_header, 0, 0, 1, 1)\nself.graphicsView = QtWidgets.QGraphicsView(DialogGraph)\nself.graphicsView.setLayoutDirection(QtCore.Qt.LayoutDirection.RightToLeft)\n@@ -67,6 +71,7 @@ class Ui_DialogGraph(object):\nself.checkBox_blackandwhite.setText(_translate(\"DialogGraph\", \"Black and white\"))\nself.pushButton_export.setToolTip(_translate(\"DialogGraph\", \"Export image\"))\nself.label_zoom.setToolTip(_translate(\"DialogGraph\", \"Click on the graph area and press + or - to zoom in or zoom out.\"))\n+ self.pushButton_reveal.setToolTip(_translate(\"DialogGraph\", \"Show hidden items\"))\nif __name__ == \"__main__\":\n",
        "chatgpt_cot": "Update sidebar visibility condition to display the sidebar frame only if there is at least one value and the sidebar variable is in the parameters."
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/settings_widget.py b/node_manager_fkie/src/node_manager_fkie/settings_widget.py @@ -200,7 +200,7 @@ class SettingsWidget(QDockWidget):\n'settings': nm.settings(),\n'attrname': 'check_for_nodelets_at_start',\n'value_default': nm.settings().CHECK_FOR_NODELETS_AT_START,\n- 'tooltip': \"Test the startlist for nodelet manager and all nodelets. \"\n+ 'tooltip': \"<p>Test the startlist for nodelet manager and all nodelets. \"\n\"If one of the nodes is not in the list a dialog is displayed with \"\n\"proposal to start other nodes, too.</p>\"\n},),\n@@ -208,13 +208,13 @@ class SettingsWidget(QDockWidget):\n'settings': nm.settings(),\n'attrname': 'show_noscreen_error',\n'value_default': nm.settings().SHOW_NOSCREEN_ERROR,\n- 'tooltip': \"Shows an error if requested screen for a node is not available.</p>\"\n+ 'tooltip': \"<p>Shows an error if requested screen for a node is not available.</p>\"\n},),\n'Ask for reload launch:': ({'value': nm.settings().ask_reload_launch,\n'settings': nm.settings(),\n'attrname': 'ask_reload_launch',\n'value_default': nm.settings().ASK_RELOAD_LAUNCH,\n- 'tooltip': \"On change asks for reload launch file.</p>\"\n+ 'tooltip': \"<p>On change asks for reload launch file.</p>\"\n},),\n'Show domain suffix:': ({'value': nm.settings().show_domain_suffix,\n'settings': nm.settings(),\n",
        "org_msg": "node_manager_fkie: fixed settings tooltips",
        "sim_msg": "apply workaround to avoid size changes also on other platforms; make it more clever",
        "sim_diff": "diff --git a/tree.py b/tree.py @@ -820,7 +820,10 @@ class WidgetTree(wx.TreeCtrl, Tree):\n# toplevel window or a menu/status bar\ntoplevel_widget = node.widget.widget\nsize_p = node.widget.properties.get(\"size\")\n- if size_p is not None and size_p.is_active(): set_size = size_p.get_tuple()\n+ toolbar_p = node.widget.properties.get(\"toolbar\")\n+ if size_p is not None and size_p.is_active() and toolbar_p is not None and toolbar_p.value:\n+ # apply workaround for size changes due to a toolbar; this would cause problems with automatic testing\n+ set_size = size_p.get_tuple()\nelse:\ntoplevel_widget = node.widget.widget.GetParent()\n@@ -829,7 +832,7 @@ class WidgetTree(wx.TreeCtrl, Tree):\n# added by rlawson to expand node on showing top level widget\nself.expand(node)\nself._show_widget_toplevel(node)\n- if wx.Platform == '__WXMAC__' and set_size is not None:\n+ if wx.Platform != '__WXMSW__' and set_size is not None:\nwx.CallAfter(toplevel_widget.SetSize, set_size)\nelse:\ntoplevel_widget.Hide()\n",
        "chatgpt_cot": "\"Update tooltips in SettingsWidget to include HTML formatting for better display and readability on the user interface.\""
    },
    {
        "org_diff": "diff --git a/.travis.yml b/.travis.yml @@ -6,7 +6,6 @@ env:\n- ROS_DISTRO=\"kinetic\"\n- ROS_DISTRO=\"melodic\"\ninstall:\n- - git clone --quiet --depth 1 https://github.com/ros-industrial/industrial_ci.git .ci_config -b legacy\n+ - git clone --quiet --depth 1 https://github.com/ros-industrial/industrial_ci.git .industrial_ci -b master\nscript:\n- - .ci_config/travis.sh\n-\n+ - .industrial_ci/travis.sh\n",
        "org_msg": "changed travis configuration",
        "sim_msg": "Switch off useless versions of OSX from CI.",
        "sim_diff": "diff --git a/.travis.yml b/.travis.yml @@ -20,12 +20,26 @@ install:\n- sudo apt-get update\n- chmod u+x ci/travis-ci.sh\n-script:\n- - ./ci/travis-ci.sh\n-\nenv:\n- CI_JOB=BUILD_CCORE\n- CI_JOB=UT_CCORE\n- CI_JOB=VALGRIND_CCORE\n- CI_JOB=UT_PYCLUSTERING\n- CI_JOB=DOCUMENTATION\n+\n+matrix:\n+ exclude:\n+ - os: osx\n+ env: CI_JOB=UT_CCORE\n+\n+ - os: osx\n+ env: CI_JOB=VALGRIND_CCORE\n+\n+ - os: osx\n+ env: CI_JOB=UT_PYCLUSTERING\n+\n+ - os: osx\n+ env: CI_JOB=DOCUMENTATION\n+\n+script:\n+ - ./ci/travis-ci.sh\n\\ No newline at end of file\n",
        "chatgpt_cot": "Update Travis CI configuration to use new industrial_ci directory for ROS builds."
    },
    {
        "org_diff": "diff --git a/user-dashboard/package.json b/user-dashboard/package.json \"nodemon\": \"^1.12.1\"\n},\n\"scripts\": {\n- \"start\": \"pm2 start dist/index.js -i max\",\n+ \"start\": \"pm2 --interpreter babel-node start src/index.js --no-daemon\",\n\"build\": \"babel src -s --ignore src/public -D -d dist && cp -r src/public dist/\",\n\"dev\": \"pm2 --interpreter babel-node start src/index.js --no-daemon --watch\",\n\"test\": \"echo \\\"Error: no test specified\\\" && exit 1\"\n",
        "org_msg": "Fix user dashboard start scripts\nUse src/index.js to start user dashboard",
        "sim_msg": "I'm watching you.",
        "sim_diff": "diff --git a/package.json b/package.json \"test\": \"tests\"\n},\n\"scripts\": {\n- \"start\": \"webpack-dev-server --progress --colors --port 2992 --content-base app/static/gen\",\n+ \"start\": \"webpack --progress --colors --watch --content-base app/static/gen\",\n\"build\": \"NODE_ENV=production webpack -p --optimize-minimize --progress\",\n\"test\": \"npm build\"\n},\n",
        "chatgpt_cot": "Update start script in package.json to use babel-node and pm2 to solve compilation issue."
    },
    {
        "org_diff": "diff --git a/sc2/bot_ai.py b/sc2/bot_ai.py @@ -69,7 +69,10 @@ class BotAI(object):\n# Not always accurate, but good enought for now.\nreturn [c.rounded for c in centers]\n- async def expand_to_nearest(self, building, max_distance=10):\n+ async def expand_now(self, building=None, max_distance=10):\n+ if not building:\n+ building = self.townhalls.first.type_id\n+\nassert isinstance(building, UnitTypeId)\nlocation = await self.get_next_expansion()\n",
        "org_msg": "Rename expand_to_nearest to expand_now for conciseness\nAlso allowed the building ID to be None in which case, the townhall ID would be\nderived for the current race.",
        "sim_msg": "added time to the saved files",
        "sim_diff": "diff --git a/bot_manager.py b/bot_manager.py @@ -178,7 +178,7 @@ class BotManager:\ncurrent_time = game_tick_packet.gameInfo.TimeSeconds\nif self.save_data and game_tick_packet.gameInfo.bRoundActive and not old_time == current_time and not current_time == -10:\n- np_input = self.input_converter.create_input_array(game_tick_packet)\n+ np_input = self.input_converter.create_input_array(game_tick_packet, passed_time=time.time() - before2)\nnp_output = np.array(controller_input, dtype=np.float32)\nself.input_array = np.append(self.input_array, np_input)\nself.output_array = np.append(self.output_array, np_output)\n",
        "chatgpt_cot": "\"Add expand_now method to BotAI for immediate expansion, with default building type and max distance parameters.\""
    },
    {
        "org_diff": "diff --git a/sc2/bot_ai.py b/sc2/bot_ai.py @@ -410,7 +410,10 @@ class BotAI(object):\nreturn await self.do(unit.build(building, p))\nasync def do(self, action):\n- assert self.can_afford(action)\n+ if not self.can_afford(action):\n+ logger.warning(f\"Cannot afford action {action}\")\n+ return ActionResult.Error\n+\nr = await self._client.actions(action, game_data=self._game_data)\nif not r: # success\n",
        "org_msg": "Do not exit when action cannot be afforded, just log a warning",
        "sim_msg": "Forgot to update iNumPlayers",
        "sim_diff": "diff --git a/v3/runner.py b/v3/runner.py @@ -63,6 +63,8 @@ if __name__ == '__main__':\ncallbacks = []\nname_dict = dict()\n+ gameInputPacket.iNumPlayers = num_bots\n+\n# Set configuration values for bots and store name and team\nfor i in range(num_bots):\nbot_config = configparser.RawConfigParser()\n",
        "chatgpt_cot": "\"Add warning log and return error if cannot afford action\""
    },
    {
        "org_diff": "diff --git a/sc2/bot_ai.py b/sc2/bot_ai.py @@ -322,7 +322,10 @@ class BotAI(DistanceCalculation):\nif not location:\nlocation = await self.get_next_expansion()\n-\n+ if not location:\n+ # All expansions are used up or mined out\n+ logger.warning(f\"Trying to expand_now() but bot is out of locations to expand to\")\n+ return\nawait self.build(building, near=location, max_distance=max_distance, random_alternative=False, placement_step=1)\nasync def get_next_expansion(self) -> Optional[Point2]:\n",
        "org_msg": "Fix expand_now for when all expansions are taken or all of them are mined out",
        "sim_msg": "Forgot to update iNumPlayers",
        "sim_diff": "diff --git a/v3/runner.py b/v3/runner.py @@ -63,6 +63,8 @@ if __name__ == '__main__':\ncallbacks = []\nname_dict = dict()\n+ gameInputPacket.iNumPlayers = num_bots\n+\n# Set configuration values for bots and store name and team\nfor i in range(num_bots):\nbot_config = configparser.RawConfigParser()\n",
        "chatgpt_cot": "Add warning message and return statement when bot is out of locations to expand to, to handle expansion issue."
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/editor/text_search_thread.py b/node_manager_fkie/src/node_manager_fkie/editor/text_search_thread.py @@ -110,8 +110,11 @@ class TextSearchThread(QObject, threading.Thread):\ntry:\nresult = self._path_text[path]\nexcept KeyError:\n+ try:\n_, _, data = nm.nmd().get_file_content(path)\nresult = utf8(data)\n+ except Exception as err:\n+ rospy.logwarn(\"can't get content: %s\" % (utf8(err)))\nreturn result\ndef _strip_text(self, data, pos):\n",
        "org_msg": "node_manager_fkie: handle exeption for not existing files while search in launch files",
        "sim_msg": "Fixed: ResourceWarning error when reading TeX-code from file\nWhen reading TeX code from a file (File - Open menu in TexText dialog) the following error has been thrown:\nResourceWarning: unclosed file <_io.TextIOWrapper name'...'\nThis patch fixes this error.\nCloses",
        "sim_diff": "diff --git a/textext/asktext.py b/textext/asktext.py @@ -648,7 +648,8 @@ class AskTextGTKSource(AskText):\n\"\"\"\ntry:\n- text = open(path).read()\n+ with open(path) as file_handle:\n+ text = file_handle.read()\nexcept IOError:\nprint(\"Couldn't load file: %s\", path)\nreturn False\n",
        "chatgpt_cot": "Add exception handling for getting file content in TextSearchThread. Log warning if content cannot be retrieved."
    },
    {
        "org_diff": "diff --git a/node_manager_daemon_fkie/src/node_manager_daemon_fkie/screen.py b/node_manager_daemon_fkie/src/node_manager_daemon_fkie/screen.py @@ -185,8 +185,8 @@ def get_cfgfile(session=None, node=None):\nif session is not None:\nreturn \"%s%s.conf\" % (LOG_PATH, session)\nelif node is not None:\n- return \"%s%s.log\" % (LOG_PATH, create_session_name(node))\n- return \"%s%s.log\" % (LOG_PATH, 'unknown')\n+ return \"%s%s.conf\" % (LOG_PATH, create_session_name(node))\n+ return \"%s%s.conf\" % (LOG_PATH, 'unknown')\ndef get_pidfile(session=None, node=None):\n",
        "org_msg": "fix: history screen log also for previous runs",
        "sim_msg": "Fixed: Fileinfo not shown in log file\nIn Python 2 Logger.findCaller returns a 3-tupel, however in Python 3 Logger.findCaller is expected to return a 4-tupel.",
        "sim_diff": "diff --git a/textext/utility.py b/textext/utility.py @@ -60,15 +60,17 @@ class MyLogger(logging.Logger):\nfor _ in range(2 + n_frames_upper): # <-- correct frame\nif f is not None:\nf = f.f_back\n- rv = \"(unknown file)\", 0, \"(unknown function)\"\n+ rv = \"(unknown file)\", 0, \"(unknown function)\", None\nwhile hasattr(f, \"f_code\"):\nco = f.f_code\nfilename = os.path.normcase(co.co_filename)\nif filename == logging._srcfile:\nf = f.f_back\ncontinue\n- rv = (co.co_filename, f.f_lineno, co.co_name)\n+ rv = (co.co_filename, f.f_lineno, co.co_name, None)\nbreak\n+ if sys.version_info[0] == 2: # ToDo: Remove when Python 2 support is deprecated\n+ rv = rv[0:3]\nreturn rv\n",
        "chatgpt_cot": "Fix file path generation issue in screen.py for node_manager_daemon_fkie. Changed return statement to generate correct file path based on session or node."
    },
    {
        "org_diff": "diff --git a/examples/competitive/README.md b/examples/competitive/README.md @@ -6,17 +6,19 @@ Copy the \"python-sc2/sc2\" folder inside this folder before distributing your bot\nChange the bot race in the [run.py](run.py) (line 8) and in the [ladderbots.json](ladderbots.json) file (line 4).\n+Zip the entire folder to a <YOUR_BOTS_NAME_HERE>.zip file. Make sure that the files are in the root folder of the zip.\n+https://ai-arena.net/wiki/getting-started/#wiki-toc-bot-zip\n+\n## AI Arena\nTo compete on AI Arena...\n-Zip the entire folder to a ExampleBot.zip file. Make sure that the files are in the root folder of the zip.\n-https://ai-arena.net/wiki/getting-started/#wiki-toc-bot-zip\n-\nMake sure to notify AI-Arena if you need additional requirements (python packages) for your bot to run. A \"requirements.txt\" is not going to be read.\nMake an account on https://ai-arena.net/ and upload the zip file as a new bot. Make sure to select the right race and bot type (python).\n## Sc2AI & Probots\n-The [ladderbots.json](ladderbots.json) file contains parameters to support play for Sc2AI and Probots.\n\\ No newline at end of file\n+The [ladderbots.json](ladderbots.json) file contains parameters to support play for Sc2AI and Probots. Don't forget to update them!\n+\n+Both Sc2AI and Probots will pip install your \"requirements.txt\" file for you.\n",
        "org_msg": "Improve competitive example README",
        "sim_msg": "fixed another place where paths were not being created correctly",
        "sim_diff": "diff --git a/runner.py b/runner.py @@ -102,21 +102,21 @@ def main():\nname_dict = dict()\nsave_data = True\n- save_path = os.getcwd() + '/bot_code/training/replays'\n+ save_path = os.path.join(os.getcwd(), 'bot_code', 'training', 'replays')\ngame_name = str(int(round(time.time() * 1000))) + '-' + str(random.randint(0, 1000))\nif save_data:\nprint(save_path)\nif not os.path.exists(save_path):\nprint(os.path.dirname(save_path) + ' does not exist creating')\nos.makedirs(save_path)\n- if not os.path.exists(save_path + '\\\\' + game_name):\n- os.makedirs(save_path + '\\\\' + game_name)\n+ joined_path = os.path.join(save_path, game_name)\n+ if not os.path.exists(joined_path):\n+ os.makedirs(joined_path)\nprint('gameName: ' + game_name + 'in ' + save_path)\ngameInputPacket.iNumPlayers = num_participants\nserver_manager.load_config()\n-\nnum_team_0 = 0\n# Set configuration values for bots and store name and team\nfor i in range(num_participants):\n",
        "chatgpt_cot": "\"Update README with instructions on how to compete on AI Arena and make sure to notify AI-Arena about additional requirements for your bot.\""
    },
    {
        "org_diff": "diff --git a/sc2/wsl.py b/sc2/wsl.py @@ -69,6 +69,10 @@ def kill(wsl_process):\ndef detect():\n\"\"\"Detect the current running version of WSL, and bail out if it doesn't exist\"\"\"\n+ # Allow disabling WSL detection with an environment variable\n+ if os.getenv(\"SC2_WSL_DETECT\", \"1\") == \"0\":\n+ return None\n+\nwsl_name = os.environ.get(\"WSL_DISTRO_NAME\")\nif not wsl_name:\nreturn None\n",
        "org_msg": "Allow disabling WSL detection with an environment variable",
        "sim_msg": "string replacement",
        "sim_diff": "diff --git a/home.admin/config.scripts/internet.sshtunnel.py b/home.admin/config.scripts/internet.sshtunnel.py @@ -39,7 +39,7 @@ WantedBy=multi-user.target\nif sys.argv[1] == \"on\":\n# check if already running\n- already_running = subprocess.check_output(f\"systemctl is-enabled {SERVICENAME}\" ,shell=True, universal_newlines=True)\n+ already_running = subprocess.check_output(\"systemctl is-enabled %s\" % (SERVICENAME) ,shell=True, universal_newlines=True)\nif str(already_running).count(\"enabled\") > 0:\nprint(\"already ON - run 'internet.sshtunnel.py off' first\")\nsys.exit(1)\n",
        "chatgpt_cot": "\"Add option to disable WSL detection with environment variable\""
    },
    {
        "org_diff": "diff --git a/node_manager_daemon_fkie/src/node_manager_daemon_fkie/server.py b/node_manager_daemon_fkie/src/node_manager_daemon_fkie/server.py @@ -35,6 +35,7 @@ import grpc\nimport rospy\nimport time\n+from .common import interpret_path\nfrom .file_servicer import FileServicer\nfrom .launch_servicer import LaunchServicer\nfrom .screen_servicer import ScreenServicer\n@@ -83,4 +84,4 @@ class GrpcServer:\nself.server.stop(3)\ndef load_launch_file(self, path, autostart=False):\n- self.launch_servicer.load_launch_file(path, autostart)\n+ self.launch_servicer.load_launch_file(interpret_path(path), autostart)\n",
        "org_msg": "node_manager_daemon_fkie: try to resolve path on autoload",
        "sim_msg": "increase the number of threads",
        "sim_diff": "diff --git a/fedn/fedn/common/net/grpc/server.py b/fedn/fedn/common/net/grpc/server.py @@ -6,7 +6,7 @@ import grpc\nclass Server:\ndef __init__(self, servicer, modelservicer, config):\n- self.server = grpc.server(futures.ThreadPoolExecutor(max_workers=100))\n+ self.server = grpc.server(futures.ThreadPoolExecutor(max_workers=350))\nself.certificate = None\nif isinstance(servicer, rpc.CombinerServicer):\n",
        "chatgpt_cot": "\"Add interpret_path function to server.py for path interpretation in load_launch_file method\""
    },
    {
        "org_diff": "diff --git a/sc2/util.py b/sc2/util.py def name_normalize(name):\nreturn name.replace(\" \", \"\").lower()\n-def name_matches(name1, name2):\n- return name_normalize(name1) == name_normalize(name2)\n+def name_matches(name1, name2, exact=True):\n+ n1 = name_normalize(name1)\n+ n2 = name_normalize(name2)\n+\n+ return n1 == n2 or (not exact and (n1.startswith(n2) or n2.startswith(n1)))\n",
        "org_msg": "Add non-exact name comparison",
        "sim_msg": "quick fix for quick logic fix for PR 793",
        "sim_diff": "diff --git a/pipenv/utils.py b/pipenv/utils.py @@ -739,7 +739,7 @@ def pep440_version(version):\ndef pep423_name(name):\n\"\"\"Normalize package name to PEP 423 style standard.\"\"\"\nname = name.lower()\n- if any(entry in name for entry in (VCS_LIST+FILE_LIST)):\n+ if any(i not in name for i in (VCS_LIST+FILE_LIST)):\nreturn name.replace('_', '-')\nelse:\nreturn name\n",
        "chatgpt_cot": "\"Add exact parameter to name_matches method for more flexible name comparison in name normalization function in util.py\""
    },
    {
        "org_diff": "diff --git a/sc2/paths.py b/sc2/paths.py @@ -8,6 +8,8 @@ from loguru import logger\nBASEDIR = {\n\"Windows\": \"C:/Program Files (x86)/StarCraft II\",\n+ \"WSL1\": \"/mnt/c/Program Files (x86)/StarCraft II\",\n+ \"WSL2\": \"/mnt/c/Program Files (x86)/StarCraft II\",\n\"Darwin\": \"/Applications/StarCraft II\",\n\"Linux\": \"~/StarCraftII\",\n\"WineLinux\": \"~/.wine/drive_c/Program Files (x86)/StarCraft II\",\n@@ -15,6 +17,8 @@ BASEDIR = {\nUSERPATH = {\n\"Windows\": \"\\\\Documents\\\\StarCraft II\\\\ExecuteInfo.txt\",\n+ \"WSL1\": \"/Documents/StarCraft II/ExecuteInfo.txt\",\n+ \"WSL2\": \"/Documents/StarCraft II/ExecuteInfo.txt\",\n\"Darwin\": \"/Library/Application Support/Blizzard/StarCraft II/ExecuteInfo.txt\",\n\"Linux\": None,\n\"WineLinux\": None,\n@@ -22,12 +26,21 @@ USERPATH = {\nBINPATH = {\n\"Windows\": \"SC2_x64.exe\",\n+ \"WSL1\": \"SC2_x64.exe\",\n+ \"WSL2\": \"SC2_x64.exe\",\n\"Darwin\": \"SC2.app/Contents/MacOS/SC2\",\n\"Linux\": \"SC2_x64\",\n\"WineLinux\": \"SC2_x64.exe\",\n}\n-CWD = {\"Windows\": \"Support64\", \"Darwin\": None, \"Linux\": None, \"WineLinux\": \"Support64\"}\n+CWD = {\n+ \"Windows\": \"Support64\",\n+ \"WSL1\": \"Support64\",\n+ \"WSL2\": \"Support64\",\n+ \"Darwin\": None,\n+ \"Linux\": None,\n+ \"WineLinux\": \"Support64\"\n+}\nPF = os.environ.get(\"SC2PF\", platform.system())\n",
        "org_msg": "[WSL-SUPPORT] Add paths for WSL1 and WSL2",
        "sim_msg": "added to tox",
        "sim_diff": "diff --git a/tox.ini b/tox.ini @@ -30,7 +30,8 @@ deps = pip\ncommands =\npython --version\n; install jax on windows\n- python -c \"import platform; import os; os.system('pip install https://whls.blob.core.windows.net/unstable/cpu/jaxlib-0.3.2-cp39-none-win_amd64.whl') if platform.system().lower() == 'windows' else ''\"\n+ python -c \"import platform; import os; os.system('pip install jaxlib[cpu]==0.3.2 -f https://whls.blob.core.windows.net/unstable/index.html --use-deprecated legacy-resolver') if platform.system().lower() == 'windows' else ''\"\n+ python -c \"import platform; import os; os.system('pip install jax==0.3.2 -f https://whls.blob.core.windows.net/unstable/index.html --use-deprecated legacy-resolver') if platform.system().lower() == 'windows' else ''\"\n[testenv:lint]\n; setupdir = {toxinidir}\n",
        "chatgpt_cot": "Add support for Windows Subsystem for Linux (WSL) paths in paths.py. Fixes the issue with file paths for WSL1 and WSL2."
    },
    {
        "org_diff": "diff --git a/bootup/docker-compose-files/docker-compose.yml b/bootup/docker-compose-files/docker-compose.yml @@ -202,7 +202,7 @@ services:\n- $KEYCLOAK_SERVER_HTTPS_PORT:8443\nparse:\n- image: parseplatform/parse-server:3.1.2\n+ image: hyperledger/cello-parse-server\ncontainer_name: cello-parse-server\nlinks:\n- mongo\n",
        "org_msg": "Fix parse server image for product compose\nChange parse server image name to cello-parse-server for\nproduct compose file.",
        "sim_msg": "No longer need to use rabbitmq 3.6 image",
        "sim_diff": "diff --git a/docker/docker-compose/docker-compose.yml b/docker/docker-compose/docker-compose.yml @@ -42,7 +42,7 @@ services:\n- brew-view\nmongodb:\n- image: mongo:3.6\n+ image: mongo\nnetworks:\n- bg-network\nvolumes:\n@@ -50,7 +50,7 @@ services:\n- mongo-config:/data/configdb\nrabbitmq:\n- image: rabbitmq:3.6-management-alpine\n+ image: rabbitmq:management-alpine\nnetworks:\n- bg-network\nenvironment:\n",
        "chatgpt_cot": "Change the image for parse server to hyperledger/cello-parse-server in docker-compose.yml."
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/__init__.py b/node_manager_fkie/src/node_manager_fkie/__init__.py @@ -58,8 +58,8 @@ PKG_NAME = 'node_manager_fkie'\n__author__ = \"Alexander Tiderko (Alexander.Tiderko@fkie.fraunhofer.de)\"\n__copyright__ = \"Copyright (c) 2012 Alexander Tiderko, Fraunhofer FKIE/US\"\n__license__ = \"BSD\"\n-__version__ = \"0.8.2-13-ga511911-dirty\" # git describe --tags --dirty --always\n-__date__ = \"2018-11-03\" # git log -1 --date=iso\n+__version__ = \"0.8.2-32-gf14e14b\" # git describe --tags --dirty --always\n+__date__ = \"2018-11-28\" # git log -1 --date=iso\n# PYTHONVER = (2, 7, 1)\n# if sys.version_info < PYTHONVER:\n",
        "org_msg": "updated version tag",
        "sim_msg": "Updated copyright end year",
        "sim_diff": "diff --git a/src/docs/conf.py b/src/docs/conf.py @@ -8,7 +8,7 @@ on_rtd = os.environ.get(\"READTHEDOCS\", None) == \"True\"\nproject = \"Astral\"\nauthor = \"Simon Kennedy\"\n-copyright = \"2009-2020, %s\" % author\n+copyright = \"2009-2022, %s\" % author\nversion = \"2.2\"\nrelease = \"2.2\"\n",
        "chatgpt_cot": "Update version and date in __init__.py file to reflect the latest changes."
    },
    {
        "org_diff": "diff --git a/sc2/portconfig.py b/sc2/portconfig.py +import json\nimport portpicker\nclass Portconfig(object):\n@@ -5,3 +6,23 @@ class Portconfig(object):\nself.shared = portpicker.pick_unused_port()\nself.server = [portpicker.pick_unused_port() for _ in range(2)]\nself.players = [[portpicker.pick_unused_port() for _ in range(2)] for _ in range(2)]\n+\n+ def __str__(self):\n+ return f\"Portconfig(shared={self.shared}, server={self.server}, players={self.players})\"\n+\n+ @property\n+ def as_json(self):\n+ return json.dumps({\n+ \"shared\": self.shared,\n+ \"server\": self.server,\n+ \"players\": self.players\n+ })\n+\n+ @classmethod\n+ def from_json(cls, json_data):\n+ self = cls.__new__(cls)\n+ data = json.loads(json_data)\n+ self.shared = data[\"shared\"]\n+ self.server = data[\"server\"]\n+ self.players = data[\"players\"]\n+ return self\n",
        "org_msg": "Add JSON serialization support for portconfig",
        "sim_msg": "E305/E302 expected 2 blank lines...",
        "sim_diff": "diff --git a/hvac/tests/util.py b/hvac/tests/util.py @@ -4,6 +4,7 @@ import time\nfrom semantic_version import Spec, Version\n+\nclass ServerManager(object):\ndef __init__(self, config_path, client):\nself.config_path = config_path\n@@ -51,8 +52,10 @@ class ServerManager(object):\ndef unseal(self):\nself.client.unseal_multi(self.keys)\n+\nVERSION_REGEX = re.compile('Vault v([\\d\\.]+)')\n+\ndef match_version(spec):\noutput = subprocess.check_output(['vault', 'version']).decode('ascii')\nversion = Version(VERSION_REGEX.match(output).group(1))\n",
        "chatgpt_cot": "Add methods for string representation and JSON serialization in Portconfig class. Improve functionality and usability of the Portconfig file."
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/network_discovery_dialog.py b/node_manager_fkie/src/node_manager_fkie/network_discovery_dialog.py @@ -98,10 +98,13 @@ class NetworkDiscoveryDialog(QDialog, threading.Thread):\nself.mutex = threading.RLock()\nself.sockets = []\nwith self.mutex:\n+ try:\nfor p in range(networks_count):\nmsock = DiscoverSocket(default_port + p, default_mcast_group)\nself.sockets.append(msock)\nmsock.settimeout(self.TIMEOUT)\n+ except Exception as e:\n+ self.display.setText(utf8(e))\nself.setDaemon(True)\nself.start()\n",
        "org_msg": "node_manager_fkie: fixed crash on errors while open network discovery dialog",
        "sim_msg": "Bind local server to all network interfaces",
        "sim_diff": "diff --git a/quarkchain/simple_network.py b/quarkchain/simple_network.py @@ -283,7 +283,7 @@ class SimpleNetwork:\nif self.env.config.LOCAL_SERVER_ENABLE:\ncoro = asyncio.start_server(\n- self.newLocalClient, \"127.0.0.1\", self.localPort, loop=self.loop)\n+ self.newLocalClient, \"0.0.0.0\", self.localPort, loop=self.loop)\nself.local_server = self.loop.run_until_complete(coro)\nprint(\"Listening on {} for local\".format(\nself.local_server.sockets[0].getsockname()))\n",
        "chatgpt_cot": "add exception handling for network discovery dialog to display error message if an exception occurs during socket creation."
    },
    {
        "org_diff": "diff --git a/fkie_node_manager/src/fkie_node_manager/master_view_proxy.py b/fkie_node_manager/src/fkie_node_manager/master_view_proxy.py @@ -2072,11 +2072,7 @@ class MasterViewProxy(QWidget):\nif node.name in cfg_nodes:\n# remove node from question\nself.message_frame.hide_question([MessageFrame.TYPE_BINARY], MessageData(node))\n- self._progress_queue.add2queue(utf8(uuid.uuid4()),\n- ''.join(['start ', node.node_info.name]),\n- self.start_node,\n- (node.node_info, force, cfg_nodes[node.node_info.name], force_host, logging, cmd_prefix))\n- # add associated nodes to stop\n+ # add associated nodes to start\nassociated2start = self._get_associated_nodes([node.name], ignore=all2start)\nall2start |= associated2start\nfound_nodes = self._get_nodes_by_name(list(associated2start))\n@@ -2085,6 +2081,10 @@ class MasterViewProxy(QWidget):\n'start %s' % anode.name,\nself.start_node,\n(anode.node_info, force, cfg_nodes[node.node_info.name], force_host))\n+ self._progress_queue.add2queue(utf8(uuid.uuid4()),\n+ ''.join(['start ', node.node_info.name]),\n+ self.start_node,\n+ (node.node_info, force, cfg_nodes[node.node_info.name], force_host, logging, cmd_prefix))\nself._start_queue(self._progress_queue)\ndef _check_for_nodelets(self, nodes):\n",
        "org_msg": "fkie_node_manager: start assosiated nodes first",
        "sim_msg": "[mining] adjust mining time with imbalanced hashpower",
        "sim_diff": "diff --git a/quarkchain/p2p/adjust_difficulty.py b/quarkchain/p2p/adjust_difficulty.py @@ -49,11 +49,68 @@ async def async_adjust_difficulty(args):\nawait asyncio.sleep(args.interval)\n+async def adjust_imbalanced_hashpower(args):\n+ \"\"\"\n+ does not loop, just try once\n+\n+ set to 10% clusters has 90% hash power\n+ hash power ratio of individual cluster would be 81:1 (do the math yourself)\n+ \"\"\"\n+ ip_lookup = json.loads(args.ip_lookup)\n+ try:\n+ clusters = monitoring.find_all_clusters(args.ip, args.p2p_port, args.jrpc_port, ip_lookup)\n+ clusters.sort()\n+ num_nodes = len(clusters)\n+ if num_nodes < 10:\n+ raise Exception(\"no point with < 10 clusters\")\n+\n+ num_rich = int(num_nodes / 10)\n+ print(\"***********************************************\")\n+ print(\"num_rich = \", num_rich)\n+ clusters_rich = clusters[:num_rich]\n+ clusters_poor = clusters[num_rich:]\n+ servers_rich = [(idx, Server(\"http://{}\".format(cluster))) for idx, cluster in enumerate(clusters_rich)]\n+ servers_poor = [(idx, Server(\"http://{}\".format(cluster))) for idx, cluster in enumerate(clusters_poor)]\n+ rich_root = int(num_nodes * args.base_root / 9)\n+ rich_minor = int(num_nodes * args.base_minor / 9)\n+ poor_root = num_nodes * args.base_root * 9\n+ poor_minor = num_nodes * args.base_minor * 9\n+\n+ await asyncio.gather(\n+ *[async_adjust(idx,\n+ server,\n+ rich_root,\n+ rich_minor,\n+ not args.do_not_mine)\n+ for (idx, server) in servers_rich])\n+ print(\"Successfully set {} nodes to root={},minor={} @{}\".format(\n+ len(servers_rich),\n+ rich_root,\n+ rich_minor,\n+ datetime.now()))\n+\n+ await asyncio.gather(\n+ *[async_adjust(idx,\n+ server,\n+ poor_root,\n+ poor_minor,\n+ not args.do_not_mine)\n+ for (idx, server) in servers_poor])\n+ print(\"Successfully set {} nodes to root={},minor={} @{}\".format(\n+ len(servers_poor),\n+ poor_root,\n+ poor_minor,\n+ datetime.now()))\n+ except Exception as ex:\n+ print(\"Got Exception: {}\".format(ex, args.interval))\n+ pass\n+\n+\ndef main():\nparser = argparse.ArgumentParser()\n# do not use \"localhost\", use the private ip if you run this from EC2\nparser.add_argument(\n- \"--ip\", default=\"54.186.3.84\", type=str)\n+ \"--ip\", default=\"54.201.248.108\", type=str)\nparser.add_argument(\n\"--p2p_port\", default=38291, type=int)\nparser.add_argument(\n@@ -71,7 +128,7 @@ def main():\n\"--do_not_mine\", default=False, type=bool)\nargs = parser.parse_args()\n- asyncio.get_event_loop().run_until_complete(async_adjust_difficulty(args))\n+ asyncio.get_event_loop().run_until_complete(adjust_imbalanced_hashpower(args))\nif __name__ == \"__main__\":\n",
        "chatgpt_cot": "\"Fix issue with start_node method and progress_queue in MasterViewProxy file\""
    },
    {
        "org_diff": "diff --git a/.github/workflows/pythonactions.yml b/.github/workflows/pythonactions.yml @@ -122,9 +122,9 @@ jobs:\ndocker exec -i my_container bash -c \"tree\"\ndocker rm -f my_container\n- run_examples_bots:\n- # Run test bots that download the SC2 linux client and run it\n- name: Run testbots linux\n+ run_example_bots:\n+ # Run example bots against computer\n+ name: Run example bots against computer\nruns-on: ${{ matrix.os }}\ntimeout-minutes: 60\nstrategy:\n@@ -155,7 +155,7 @@ jobs:\n# TODO Fix in main.py \"run_multiple_games\" or \"a_run_multiple_games\" or \"a_run_multiple_games_nokill\"\n# run_bot_vs_bot:\n-# # Run test bots that download the SC2 linux client and run it\n+# # Run bot vs bot\n# name: Run example bots against each other\n# runs-on: ${{ matrix.os }}\n# timeout-minutes: 30\n",
        "org_msg": "Fix workflow name",
        "sim_msg": "Use stomp docker file",
        "sim_diff": "diff --git a/.github/workflows/integration-actions.yml b/.github/workflows/integration-actions.yml @@ -276,7 +276,7 @@ jobs:\npython-version: ${{ matrix.python-version }}\n- name: Update Docker Compose\n- run: cp test/conf/docker-compose.yml docker/docker-compose/docker-compose.yml\n+ run: cp test/conf/docker-compose-stomp.yml docker/docker-compose/docker-compose.yml\nworking-directory: ./\n- name: Checkout Local Plugins\n",
        "chatgpt_cot": "Update pythonactions.yml to fix naming and comments, and improve clarity of job descriptions and instructions for running example bots."
    },
    {
        "org_diff": "diff --git a/fkie_node_manager/src/fkie_node_manager/parameter_dialog.py b/fkie_node_manager/src/fkie_node_manager/parameter_dialog.py @@ -405,7 +405,8 @@ class ParameterDescription(object):\nrvalue = value\nelse:\ntry:\n- rvalue = ruamel.yaml.load(\"[%s]\" % value, Loader=ruamel.yaml.Loader)\n+ rvalue = value.lstrip('[').rstrip(']')\n+ rvalue = ruamel.yaml.load(\"[%s]\" % rvalue, Loader=ruamel.yaml.Loader)\n# if there is no YAML, load() will return an\n# empty string. We want an empty dictionary instead\n# for our representation of empty.\n",
        "org_msg": "fkie_node_manager: fixed service call with string list arguments",
        "sim_msg": "fix due travis-ci defects",
        "sim_diff": "diff --git a/nameko/cli/main.py b/nameko/cli/main.py @@ -48,7 +48,8 @@ def _env_var_constructor(loader, node):\nraw_value = loader.construct_scalar(node)\nvalue = ENV_VAR_MATCHER.sub(_replace_env_var, raw_value)\nnew_tag = loader.resolve(yaml.ScalarNode, value, (True, False))\n- return loader.yaml_constructors[new_tag](loader, yaml.ScalarNode(new_tag, value))\n+ new_node = yaml.ScalarNode(new_tag, value)\n+ return loader.yaml_constructors[new_tag](loader, new_node)\ndef setup_yaml_parser():\n",
        "chatgpt_cot": "Fix issue with loading YAML in ParameterDescription class. Updated code to correctly load YAML and handle empty string."
    },
    {
        "org_diff": "diff --git a/examples/formbot/stories.md b/examples/formbot/stories.md -## Generated Story 6616794937268014982\n-* request_restaurant\n- - restaurant_form\n- - form{\"name\": \"restaurant_form\"}\n- - slot{\"requested_slot\": \"cuisine\"}\n-* chitchat\n- - utter_chitchat\n- - restaurant_form\n- - slot{\"requested_slot\": \"cuisine\"}\n-* inform{\"cuisine\": \"1\"}\n- - slot{\"cuisine\": \"1\"}\n- - restaurant_form\n- - slot{\"cuisine\": \"1\"}\n- - slot{\"requested_slot\": \"num_people\"}\n-* inform{\"num_people\": \"1\"}\n- - slot{\"num_people\": \"1\"}\n- - restaurant_form\n- - slot{\"num_people\": \"1\"}\n- - slot{\"requested_slot\": null}\n- - form{\"name\": null}\n-* thank\n- - utter_noworries\n-\n## Generated Story -9155310465400161964\n* request_restaurant\n- restaurant_form\n- slot{\"requested_slot\": null}\n* thank\n- utter_noworries\n-\n",
        "org_msg": "remove story without 'form: '",
        "sim_msg": "Duplicate persons: switch to table, add forms for reviewing & merging\nData representation was changed to tables, and 4 new forms were added.\nTwo forms are responsible for marking records as reviewed.\nTwo other forms are responsible for merging any two selected records.",
        "sim_diff": "diff --git a/amy/templates/reports/duplicate_persons.html b/amy/templates/reports/duplicate_persons.html {% for person in switched_persons %}\n<tr>\n<td><a href=\"{{ person.get_absolute_url }}\">{{ person }}</a></td>\n- <td><input type=\"checkbox\" name=\"id_something\" value=\"{{ person.id }}\"></td>\n+ <td><input type=\"checkbox\" name=\"person_id\" value=\"{{ person.id }}\" form=\"form_switched_names_review\"></td>\n<td>{% if not forloop.last %}<input type=\"radio\" name=\"person_a\" value=\"{{ person.id }}\" form=\"form_switched_names_merge\">{% endif %}</td>\n<td>{% if not forloop.first %}<input type=\"radio\" name=\"person_b\" value=\"{{ person.id }}\" form=\"form_switched_names_merge\">{% endif %}</td>\n</tr>\n{% endfor %}\n- </tbody>\n- </table>\n+ {% if switched_persons|length >= 2 %}\n+ <tr>\n+ <td></td>\n+ <td>\n+ <form method=\"POST\" action=\"{% url 'review_duplicate_persons' %}\" id=\"form_switched_names_review\">\n+ {% csrf_token %}\n+ <input type=\"hidden\" name=\"next\" value=\"{% url 'duplicate_persons' %}\">\n+ <input type=\"submit\" value=\"Mark as reviewed\" class=\"btn btn-success\">\n+ </form>\n+ </td>\n+ <td colspan=\"2\">\n<form method=\"GET\" action=\"{% url 'persons_merge' %}\" id=\"form_switched_names_merge\">\n+ <input type=\"hidden\" name=\"next\" value=\"{% url 'duplicate_persons' %}\">\n<input type=\"submit\" value=\"Merge selected\" class=\"btn btn-primary\">\n</form>\n+ </td>\n+ </tr>\n+ {% endif %}\n+ </tbody>\n+ </table>\n{% else %}\n<p>None.</p>\n{% endif %}\n{% for person in duplicate_persons %}\n<tr>\n<td><a href=\"{{ person.get_absolute_url }}\">{{ person }}</a></td>\n- <td><input type=\"checkbox\" name=\"id_something\" value=\"{{ person.id }}\"></td>\n+ <td><input type=\"checkbox\" name=\"person_id\" value=\"{{ person.id }}\" form=\"form_same_names_review\"></td>\n<td>{% if not forloop.last %}<input type=\"radio\" name=\"person_a\" value=\"{{ person.id }}\" form=\"form_same_names_merge\">{% endif %}</td>\n<td>{% if not forloop.first %}<input type=\"radio\" name=\"person_b\" value=\"{{ person.id }}\" form=\"form_same_names_merge\">{% endif %}</td>\n- <!--{% if not forloop.first %}\n- <a href=\"{% url 'persons_merge' %}?person_b={{ person.pk }}&person_a={{ prev_person_pk }}\" target=\"_blank\">(merge up)</a>\n- {% endif %}\n- {% assign person.pk as prev_person_pk %}-->\n</tr>\n{% endfor %}\n- </tbody>\n- </table>\n+ {% if duplicate_persons|length >= 2 %}\n+ <tr>\n+ <td></td>\n+ <td>\n+ <form method=\"POST\" action=\"{% url 'review_duplicate_persons' %}\" id=\"form_same_names_review\">\n+ {% csrf_token %}\n+ <input type=\"hidden\" name=\"next\" value=\"{% url 'duplicate_persons' %}\">\n+ <input type=\"submit\" value=\"Mark as reviewed\" class=\"btn btn-success\">\n+ </form>\n+ </td>\n+ <td colspan=\"2\">\n<form method=\"GET\" action=\"{% url 'persons_merge' %}\" id=\"form_same_names_merge\">\n+ <input type=\"hidden\" name=\"next\" value=\"{% url 'duplicate_persons' %}\">\n<input type=\"submit\" value=\"Merge selected\" class=\"btn btn-primary\">\n</form>\n+ </td>\n+ </tr>\n+ {% endif %}\n+ </tbody>\n+ </table>\n{% else %}\n<p>None.</p>\n{% endif %}\n",
        "chatgpt_cot": "\"Refactor formbot stories to remove redundant slots and streamline conversation flow.\""
    },
    {
        "org_diff": "diff --git a/fkie_node_manager/src/fkie_node_manager/main_window.py b/fkie_node_manager/src/fkie_node_manager/main_window.py @@ -1776,7 +1776,7 @@ class MainWindow(QMainWindow):\nif self.isActiveWindow() and self.isActiveWindow() != self._last_window_state:\nif hasattr(self, 'currentMaster') and self.currentMaster is not None:\n# perform delayed checks for changed files or multiple screens\n- QTimer.singleShot(700, self.currentMaster.perform_master_checks)\n+ QTimer.singleShot(250, self.currentMaster.perform_master_checks)\nself._last_window_state = self.isActiveWindow()\nQMainWindow.changeEvent(self, event)\n",
        "org_msg": "node_manager: reduced timeout for check update after window was activated",
        "sim_msg": "better help for toplevel extracode",
        "sim_diff": "diff --git a/edit_windows.py b/edit_windows.py @@ -704,6 +704,9 @@ class TopLevelBase(WindowBase, PreviewMixin):\nIS_TOPLEVEL_WINDOW = True # will be False for TopLevelPanel and MDIChildFrame\nCHILDREN = 1 # a sizer or a widget\n+ _PROPERTY_HELP={ \"extracode_pre\":\"This code will be inserted at the beginning of the constructor.\\n\",\n+ \"extracode_post\":\"This code will be inserted at the end of the constructor.\\n\" }\n+\ndef __init__(self, name, klass, parent, title=None):\nWindowBase.__init__(self, name, klass, parent, pos=None)\nself._oldname = name\n",
        "chatgpt_cot": "optimize delay time for perform_master_checks to improve user experience in MainWindow."
    },
    {
        "org_diff": "diff --git a/sc2/client.py b/sc2/client.py @@ -23,6 +23,7 @@ from .action import combine_actions\nfrom .position import Point2, Point3\nfrom .unit import Unit\n+\nclass Client(Protocol):\ndef __init__(self, ws):\nsuper().__init__(ws)\n@@ -227,3 +228,14 @@ class Client(Protocol):\nquantity=(amount_of_units)\n))]\n))\n+ async def debug_text_simple(self, texts):\n+ if not isinstance(texts, list):\n+ texts = [texts]\n+ await self._execute(debug=sc_pb.RequestDebug(\n+ debug=[debug_pb.DebugCommand(draw=debug_pb.DebugDraw(\n+ text=[debug_pb.DebugText(\n+ text=text,\n+ color=debug_pb.Color(r=1, g=1, b=1),\n+ ) for text in texts]\n+ ))]\n+ ))\n",
        "org_msg": "Add simplified debug_text to client.py",
        "sim_msg": "Grid Client Small changes\nRemove proxy/unproxy methods\nADD load method\nAdd user_key optional parameter",
        "sim_diff": "diff --git a/src/syft/grid/client/client.py b/src/syft/grid/client/client.py from typing import Any\nfrom typing import Dict\nfrom typing import Optional\n+from typing import Type\nfrom typing import Union\n# third party\n@@ -24,8 +25,10 @@ from ...core.node.device.client import DeviceClient\nfrom ...core.node.domain.client import DomainClient\nfrom ...core.node.network.client import NetworkClient\nfrom ...core.node.vm.client import VirtualMachineClient\n+from ...core.pointer.pointer import Pointer\nfrom ..messages.setup_messages import CreateInitialSetUpMessage\nfrom ..messages.setup_messages import GetSetUpMessage\n+from ..messages.transfer_messages import LoadObjectMessage\nfrom .request_api.association_api import AssociationRequestAPI\nfrom .request_api.group_api import GroupRequestAPI\nfrom .request_api.role_api import RoleRequestAPI\n@@ -38,6 +41,7 @@ def connect(\nconn_type: ClientConnection,\nclient_type: Client,\ncredentials: Dict = {},\n+ user_key: Optional[SigningKey] = None,\n) -> Any:\nclass GridClient(client_type): # type: ignore\ndef __init__(\n@@ -52,11 +56,14 @@ def connect(\nconn = conn_type(url=url) # type: ignore\nif credentials:\n- metadata, user_key = conn.login(credentials=credentials)\n- user_key = SigningKey(user_key.encode(\"utf-8\"), encoder=HexEncoder)\n+ metadata, _user_key = conn.login(credentials=credentials)\n+ _user_key = SigningKey(_user_key.encode(\"utf-8\"), encoder=HexEncoder)\nelse:\nmetadata = conn._get_metadata()\n- user_key = SigningKey.generate()\n+ if not user_key:\n+ _user_key = SigningKey.generate()\n+ else:\n+ _user_key = user_key\n(\nspec_location,\n@@ -81,22 +88,28 @@ def connect(\nvm=location_args[VirtualMachineClient],\nname=name,\nroutes=[route],\n- signing_key=user_key,\n+ signing_key=_user_key,\n)\nself.groups = GroupRequestAPI(send=self.__perform_grid_request)\nself.users = UserRequestAPI(send=self.__perform_grid_request)\nself.roles = RoleRequestAPI(send=self.__perform_grid_request)\n- self.workers = WorkerRequestAPI(send=self.__perform_grid_request)\n+ self.workers = WorkerRequestAPI(\n+ send=self.__perform_grid_request, client=self\n+ )\nself.association_requests = AssociationRequestAPI(\nsend=self.__perform_grid_request\n)\n- def proxy(self, vm_address: Address) -> None:\n- self.proxy_address = vm_address\n-\n- def unproxy(self) -> None:\n- self.proxy_address = None\n+ def load(\n+ self, obj_ptr: Type[Pointer], address: Address, searchable: bool = False\n+ ) -> None:\n+ content = {\n+ \"address\": address.serialize().SerializeToString().decode(\"ISO-8859-1\"), # type: ignore\n+ \"uid\": str(obj_ptr.id_at_location.value),\n+ \"searchable\": searchable,\n+ }\n+ self.__perform_grid_request(grid_msg=LoadObjectMessage, content=content)\ndef initial_setup(self, **kwargs: Any) -> Any:\nreturn self.__perform_grid_request(\n@@ -113,7 +126,6 @@ def connect(\n],\nroute_index: int = 0,\n) -> SyftMessage:\n-\nif self.proxy_address:\nmsg.address = self.proxy_address\n",
        "chatgpt_cot": "Add debug_text_simple method to Client class for drawing debug text on the screen. Fixes issue with drawing debug text."
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/master_view_proxy.py b/node_manager_fkie/src/node_manager_fkie/master_view_proxy.py @@ -1181,6 +1181,7 @@ class MasterViewProxy(QWidget):\n# reduce the displayed name\nitem_name = i\nif name:\n+ if item_name.startswith(name):\nitem_name = item_name.replace('%s%s' % (name, roslib.names.SEP), '~', 1)\nns = roslib.names.namespace(name)\nif item_name.startswith(ns) and ns != roslib.names.SEP:\n",
        "org_msg": "node_manager_fkie: fixed displayed topics in description panel",
        "sim_msg": "Tree: display title for e.g. Frame, allow editing of this and class name",
        "sim_diff": "diff --git a/tree.py b/tree.py @@ -484,7 +484,15 @@ class WidgetTree(wx.TreeCtrl, Tree):\nnew_value = evt.Label\nif new_value==self._build_label(node): return\n- new_name = new_label = new_title = new_tab = None\n+ new_name = new_label = new_title = new_tab = new_class = None\n+\n+ if node.widget.klass != node.widget.base and node.widget.klass != 'wxScrolledWindow':\n+ if new_value.count(\"(\")==1 and new_value.count(\")\")==1:\n+ pre, new_class = new_value.split(\"(\")\n+ new_class, post = new_class.split(\")\")\n+ if pre.endswith(\" \"): pre = pre[:-1]\n+ new_value = pre+post\n+\nif \"label\" in widget.properties and self._label_editable(widget):\nnew_name, new_label = self._split_name_label(new_value)\nelif \"label\" in widget.properties:\n@@ -507,14 +515,23 @@ class WidgetTree(wx.TreeCtrl, Tree):\nif new_name==name_p.get(): new_name = None\nif new_name:\n# check\n- name_OK = name_p.check(new_name)\n- if not name_OK: new_name = None\n+ OK = name_p.check(new_name)\n+ if not OK: new_name = None\n+\n+ # check class/klass\n+ if new_class:\n+ class_p = widget.properties[\"klass\"]\n+ if new_class==class_p.get(): new_class = None\n+ if new_class:\n+ # check\n+ OK = class_p.check(new_class)\n+ if not OK: new_class = None\n# check label\nif new_label is not None:\nlabel_p = widget.properties[\"label\"]\nif new_label==label_p.get(): new_label = None\n- if not new_name and new_label is None and new_title is None and new_tab is None:\n+ if not new_name and new_label is None and new_title is None and new_tab is None and new_class is None:\n# no change or an error\nwx.Bell()\nevt.Veto()\n@@ -543,6 +560,10 @@ class WidgetTree(wx.TreeCtrl, Tree):\nname_p.previous_value = name_p.value\nname_p.set(new_name, notify=False)\nmodified.add(\"name\")\n+ if new_class:\n+ class_p.previous_value = class_p.value\n+ class_p.set(new_class, notify=False)\n+ modified.add(\"class\")\nif new_label:\nlabel_p.previous_value = label_p.value\nlabel_p.set(new_label, notify=False)\n@@ -577,6 +598,9 @@ class WidgetTree(wx.TreeCtrl, Tree):\nif node.widget.klass != node.widget.base and node.widget.klass != 'wxScrolledWindow':\n# special case...\ns += ' (%s)' % node.widget.klass\n+ if getattr(node.widget, \"has_title\", None):\n+ # include title\n+ s += ': \"%s\"'%node.widget.title\nelif \"label\" in node.widget.properties and node.widget.properties[\"label\"].is_active():\n# include label of control\nlabel = node.widget.label\n",
        "chatgpt_cot": "\"Optimize displayed name reduction in MasterViewProxy\""
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/launch_list_model.py b/node_manager_fkie/src/node_manager_fkie/launch_list_model.py @@ -62,9 +62,9 @@ class PathItem(QStandardItem):\nPROFILE = 5\nRECENT_PROFILE = 6\nRECENT_FILE = 7\n- FILE = 10\nLAUNCH_FILE = 11\nCFG_FILE = 12\n+ FILE = 13\nPACKAGE = 20\nSTACK = 21\nFOLDER = 22\n@@ -736,7 +736,7 @@ class LaunchListModel(QStandardItemModel):\ncurr_item = root.child(i)\ninsert_item = False\nif curr_item.id not in [PathItem.ROOT]:\n- if curr_item.id == path_item[0].id or path_item[0].id in [PathItem.RECENT_FILE, PathItem.LAUNCH_FILE, PathItem.RECENT_PROFILE, PathItem.PROFILE]:\n+ if curr_item.id == path_item[0].id:\nif path_item[0].name < curr_item.name:\ninsert_item = True\nelif curr_item.id > path_item[0].id:\n",
        "org_msg": "node_manager_fkie: fixed sort in launch widget",
        "sim_msg": "improve find_widget_from_path to work on attribute children like menubar",
        "sim_diff": "diff --git a/application.py b/application.py @@ -143,7 +143,7 @@ class EditRoot(np.PropertyOwner):\nif pos<len(w.children) and w.children[pos].IS_SLOT:\nw = w.children[pos]\ncontinue\n- children = [c for c in w.children if c.name==path[index]]\n+ children = [c for c in w.get_all_children() if c.name==path[index]]\nif not children: return None\nw = children[0]\nreturn w\n",
        "chatgpt_cot": "Refactor file constants, update file category, and simplify conditional logic in LaunchListModel."
    },
    {
        "org_diff": "diff --git a/master_discovery_fkie/src/master_discovery_fkie/zeroconf.py b/master_discovery_fkie/src/master_discovery_fkie/zeroconf.py @@ -46,7 +46,8 @@ import time\nimport rospy\n-from master_monitor import MasterMonitor\n+from .common import get_hostname\n+from .master_monitor import MasterMonitor\nfrom multimaster_msgs_fkie.msg import LinkStatesStamped, MasterState, ROSMaster # , SyncMasterInfo, SyncTopicInfo\nfrom multimaster_msgs_fkie.srv import DiscoverMasters, DiscoverMastersResponse # , GetSyncInfo\n@@ -771,7 +772,7 @@ class Discoverer(Zeroconf):\nmasterhost, masterport = MasterInfo.MasteruriToAddr(materuri)\nif (masterhost in ['localhost', '127.0.0.1']):\nsys.exit(\"'%s' is not reachable for other systems. Change the ROS_MASTER_URI!\" % masterhost)\n- rpcuri = ''.join(['http://', socket.gethostname(), ':', str(monitor_port), '/'])\n+ rpcuri = 'http://%s:%s/' % (get_hostname(materuri), str(monitor_port))\ntxtArray = [\"timestamp=%s\" % str(0), \"timestamp_local=%s\" % str(0), \"master_uri=%s\" % materuri, \"zname=%s\" % rospy.get_name(), \"rpcuri=%s\" % rpcuri, \"network_id=%s\" % self.network_id]\n# the Zeroconf class, which contains the QMainLoop to receive the signals from avahi\nZeroconf.__init__(self, name, '_ros-master._tcp', masterhost, masterport, domain, txtArray)\n",
        "org_msg": "master_discovery_fkie: zeroconf use for monitoruri the same hostname from masteruri",
        "sim_msg": "do not show Mapping from-to in docstring",
        "sim_diff": "diff --git a/docs/conf.py b/docs/conf.py @@ -3,7 +3,7 @@ import sys\nimport time\nimport inspect\nfrom pathlib import Path, PurePosixPath\n-from typing import Optional, Union\n+from typing import Optional, Union, Mapping\nimport logging\nHERE = Path(__file__).parent\n@@ -81,7 +81,7 @@ html_context = {\n'github_version': 'master', # Version\n'conf_py_path': '/docs/', # Path in the checkout to the docs root\n'css_files': [ # Additional CSS\n- '_static/css/override.css',\n+ '_static/css/custom.css',\n],\n}\nif 'READTHEDOCS' in os.environ:\n@@ -226,9 +226,9 @@ fa_orig = sphinx_autodoc_typehints.format_annotation\ndef format_annotation(annotation):\nif getattr(annotation, '__origin__', None) is Union or hasattr(annotation, '__union_params__'):\nparams = getattr(annotation, '__union_params__', None) or getattr(annotation, '__args__', None)\n- if len(params or []) == 2 and getattr(params[1], '__qualname__', None) == 'NoneType':\n- return fa_orig(annotation) # Optional[...]\nreturn ', '.join(map(format_annotation, params))\n+ if getattr(annotation, '__origin__', None) is Mapping:\n+ return ':class:`~typing.Mapping`'\nif inspect.isclass(annotation):\nfull_name = '{}.{}'.format(annotation.__module__, annotation.__qualname__)\noverride = qualname_overrides.get(full_name)\n",
        "chatgpt_cot": "Fix hostname resolution in Discoverer class in zeroconf.py file. Use get_hostname method from common module. Improve ROS_MASTER_URI check for remote systems."
    },
    {
        "org_diff": "diff --git a/sc2/units.py b/sc2/units.py @@ -22,6 +22,21 @@ class Units(list):\ndef select(self, *args, **kwargs):\nreturn UnitSelection(self, *args, **kwargs)\n+ def __or__(self, other):\n+ tags = {unit.tag for unit in self}\n+ units = self + [unit for unit in other if unit.tag not in tags]\n+ return Units(units, self.game_data)\n+\n+ def __and__(self, other):\n+ tags = {unit.tag for unit in self}\n+ units = [unit for unit in other if unit.tag in tags]\n+ return Units(units, self.game_data)\n+\n+ def __sub__(self, other):\n+ tags = {unit.tag for unit in other}\n+ units = [unit for unit in self if unit.tag not in tags]\n+ return Units(units, self.game_data)\n+\n@property\ndef amount(self):\nreturn len(self)\n@@ -44,6 +59,15 @@ class Units(list):\nassert self.exists\nreturn random.choice(self)\n+ def random_group_of(self, n):\n+ assert 0 <= n <= self.amount\n+ if n == 0:\n+ return self.subgroup([])\n+ elif self.amount == n:\n+ return self\n+ else:\n+ return self.subgroup(random.sample(self, n))\n+\ndef closest_to(self, position):\nreturn min(self, key=lambda unit: unit.position.to2.distance_to(position))\n",
        "org_msg": "Add group operations",
        "sim_msg": "Support stp/regional_team in org_codes endpoint",
        "sim_diff": "diff --git a/openprescribing/api/views_org_codes.py b/openprescribing/api/views_org_codes.py @@ -2,7 +2,7 @@ from rest_framework.decorators import api_view\nfrom rest_framework.response import Response\nimport view_utils as utils\nfrom django.db.models import Q\n-from frontend.models import PCT, Practice\n+from frontend.models import PCT, Practice, STP, RegionalTeam\n@api_view(['GET'])\ndef org_codes(request, format=None):\n@@ -22,13 +22,20 @@ def org_codes(request, format=None):\ndef _get_org_from_code(q, is_exact, org_type):\nif is_exact:\n- if len(q) == 3:\n+ # Both regional teams and CCGs have 3 character codes, but I don't want\n+ # to change the API to require org_type because I don't know what else\n+ # might break\n+ if len(q) == 3 and org_type != 'regional_team':\nresults = PCT.objects.filter(Q(code=q) | Q(name=q)) \\\n.filter(org_type='CCG')\nvalues = results.values('name', 'code')\nfor v in values:\nv['id'] = v['code']\nv['type'] = 'CCG'\n+ elif org_type == 'stp':\n+ values = _get_stps_like_code(q, is_exact=True)\n+ elif org_type == 'regional_team':\n+ values = _get_regional_teams_like_code(q, is_exact=True)\nelse:\nresults = Practice.objects.filter(Q(code=q) | Q(name=q))\nvalues = results.values('name', 'code', 'ccg')\n@@ -41,6 +48,10 @@ def _get_org_from_code(q, is_exact, org_type):\nvalues += _get_practices_like_code(q)\nelif org_type == 'CCG':\nvalues += _get_pcts_like_code(q)\n+ elif org_type == 'stp':\n+ values += _get_stps_like_code(q)\n+ elif org_type == 'regional_team':\n+ values += _get_regional_teams_like_code(q)\nelse:\nvalues += _get_pcts_like_code(q)\nvalues += _get_practices_like_code(q)\n@@ -85,3 +96,38 @@ def _get_pcts_like_code(q):\np['id'] = p['code']\np['type'] = 'CCG'\nreturn pct_values\n+\n+\n+def _get_stps_like_code(q, is_exact=False):\n+ orgs = STP.objects.all()\n+ if is_exact:\n+ orgs = orgs.filter(\n+ Q(ons_code=q) | Q(name=q)\n+ )\n+ elif q:\n+ orgs = orgs.filter(\n+ Q(ons_code__istartswith=q) | Q(name__icontains=q)\n+ )\n+ org_values = orgs.values('name', 'ons_code')\n+ for org in org_values:\n+ org['code'] = org.pop('ons_code')\n+ org['id'] = org['code']\n+ org['type'] = 'stp'\n+ return org_values\n+\n+\n+def _get_regional_teams_like_code(q, is_exact=False):\n+ orgs = RegionalTeam.objects.filter(close_date__isnull=True)\n+ if is_exact:\n+ orgs = orgs.filter(\n+ Q(code=q) | Q(name=q)\n+ )\n+ elif q:\n+ orgs = orgs.filter(\n+ Q(code__istartswith=q) | Q(name__icontains=q)\n+ )\n+ org_values = orgs.values('name', 'code')\n+ for org in org_values:\n+ org['id'] = org['code']\n+ org['type'] = 'regional_team'\n+ return org_values\n",
        "chatgpt_cot": "Add methods for set operations and random group selection in Units class. Fixes compilation issues and adds functionality for unit selection."
    },
    {
        "org_diff": "diff --git a/master_discovery_fkie/src/master_discovery_fkie/zeroconf.py b/master_discovery_fkie/src/master_discovery_fkie/zeroconf.py @@ -860,7 +860,7 @@ class Discoverer(Zeroconf):\n# sets a new timestamp in zeroconf\nrpcuri = self.masterInfo.getTXTValue('rpcuri', '')\nmasteruri = self.masterInfo.getTXTValue('master_uri', '')\n- self.masterInfo.txt = [\"timestamp=%.9f\" % self.master_monitor.getCurrentState().timestamp, \"master_uri=%s\" % masteruri, \"zname=%s\" % rospy.get_name(), \"rpcuri=%s\" % rpcuri, \"network_id=%s\" % self.network_id]\n+ self.masterInfo.txt = [\"timestamp=%.9f\" % self.master_monitor.getCurrentState().timestamp_local, \"master_uri=%s\" % masteruri, \"zname=%s\" % rospy.get_name(), \"rpcuri=%s\" % rpcuri, \"network_id=%s\" % self.network_id]\nself.updateService(self.masterInfo.txt)\nreturn self.masterInfo\nexcept:\n",
        "org_msg": "master_discovery_fkie: hotfix to avoid request loop in master_sync if use zeroconf\nsee issue",
        "sim_msg": "Added a tzinfo property to return a pytz timezone",
        "sim_diff": "diff --git a/src/astral/__init__.py b/src/astral/__init__.py @@ -226,6 +226,11 @@ class LocationInfo:\n\"\"\"Return an Observer at this location\"\"\"\nreturn Observer(self.latitude, self.longitude, 0.0)\n+ @property\n+ def tzinfo(self):\n+ \"\"\"Return a pytz timezone for this location\"\"\"\n+ return pytz.timezone(self.timezone);\n+\n@property\ndef timezone_group(self):\nreturn self.timezone.split(\"/\")[0]\n",
        "chatgpt_cot": "Update zeroconf timestamp to use local timestamp instead of global timestamp. Fixes issue with incorrect timestamp in zeroconf."
    },
    {
        "org_diff": "diff --git a/Makefile b/Makefile @@ -179,10 +179,17 @@ check: ##@Code Check code format\ntest-case: ##@Code Run test case for flask server\n@$(MAKE) -C src/operator-dashboard/test/ all\n-clean: docker-clean ##@Code Clean tox result, clean built images and db files\n+clean:\n+ make stop-docker-compose\nrm -rf .tox .cache *.egg-info build/\nfind . -name \"*.pyc\" -o -name \"__pycache__\" | xargs rm -rf\n- rm -rf /opt/cello/*\n+ rm -rf /opt/cello/\n+\n+deep-clean:\n+ make stop\n+ make image-clean\n+ rm -rf /opt/cello/\n+\n# TODO (david_dornseier): As long as there are no release versions, always rewrite\n# the entire changelog (bug)\n@@ -219,6 +226,8 @@ start: ##@Service Start service\nstop-docker-compose:\necho \"Stop all services with bootup/docker-compose-files/${COMPOSE_FILE}...\"\ndocker-compose -f bootup/docker-compose-files/${COMPOSE_FILE} stop\n+\n+remove-docker-compose:\necho \"Remove all services with ${COMPOSE_FILE}...\"\ndocker-compose -f bootup/docker-compose-files/${COMPOSE_FILE} rm -f -a\n@@ -304,6 +313,7 @@ start-dashboard:\nall \\\ncheck \\\nclean \\\n+ deep-clean \\\nchangelog \\\ndoc \\\ndocker \\\n",
        "org_msg": "Modify makefile commands\nUpdate makefile commands, so then we can clean docker containers in\ndifferent level.\n* make stop\n* make clean\n* make deep-clean",
        "sim_msg": "use sudo to install docker-switch",
        "sim_diff": "diff --git a/home.admin/config.scripts/blitz.docker.sh b/home.admin/config.scripts/blitz.docker.sh @@ -86,13 +86,13 @@ if [ \"$1\" = \"1\" ] || [ \"$1\" = \"on\" ]; then\necho \"Docker Compose V2 is not installed\"\nexit 1\nfi\n- curl -fL $COMPOSE_SWITCH_URL -o /usr/local/bin/compose-switch\n- chmod +x /usr/local/bin/compose-switch\n+ sudo curl -fL $COMPOSE_SWITCH_URL -o /usr/local/bin/compose-switch\n+ sudo chmod +x /usr/local/bin/compose-switch\nCOMPOSE=$(command -v docker-compose)\nif [ \"$COMPOSE\" = /usr/local/bin/docker-compose ]; then\n# This is a manual installation of docker-compose\n# so, safe for us to rename binary\n- mv /usr/local/bin/docker-compose /usr/local/bin/docker-compose-v1\n+ sudo mv /usr/local/bin/docker-compose /usr/local/bin/docker-compose-v1\nCOMPOSE=/usr/local/bin/docker-compose-v1\nfi\nALTERNATIVES=\"update-alternatives\"\n@@ -101,9 +101,9 @@ if [ \"$1\" = \"1\" ] || [ \"$1\" = \"on\" ]; then\nfi\necho \"Configuring docker-compose alternatives\"\nif [ -n \"$COMPOSE\" ]; then\n- $ALTERNATIVES --install /usr/local/bin/docker-compose docker-compose $COMPOSE 1\n+ sudo $ALTERNATIVES --install /usr/local/bin/docker-compose docker-compose $COMPOSE 1\nfi\n- $ALTERNATIVES --install /usr/local/bin/docker-compose docker-compose /usr/local/bin/compose-switch 99\n+ sudo $ALTERNATIVES --install /usr/local/bin/docker-compose docker-compose /usr/local/bin/compose-switch 99\necho \"'docker-compose' is now set to run Compose V2\"\necho \"use '$ALTERNATIVES --config docker-compose' if you want to switch back to Compose V1\"\n@@ -113,11 +113,15 @@ if [ \"$1\" = \"1\" ] || [ \"$1\" = \"on\" ]; then\nsudo systemctl stop docker.socket\n# keep the docker dir on the OS drive if the disk is ZFS - needs special config\n- # https://docs.docker.com/storage/storagedriver/zfs-driver/#configure-docker-with-the-zfs-storage-driver\nisZFS=$(zfs list 2>/dev/null | grep -c \"/mnt/hdd\")\nif [ \"${isZFS}\" -eq 0 ]; then\n- sudo mv /var/lib/docker /mnt/hdd/\n- sudo ln -s /var/lib/docker /mnt/hdd/docker\n+ sudo mv -f /var/lib/docker /mnt/hdd/\n+ sudo ln -s /mnt/hdd/docker /var/lib/docker\n+ # move to a different partition or configure docker with ZFS\n+ # https://docs.docker.com/storage/storagedriver/zfs-driver/#configure-docker-with-the-zfs-storage-driver\n+ #else\n+ # sudo mv -f /var/lib/docker /home/admin/\n+ # sudo ln -s /home/admin/docker /var/lib/docker\nfi\nsudo systemctl start docker\nsudo systemctl start docker.socket\n",
        "chatgpt_cot": "Add new make target \"deep-clean\" to clean up the project more thoroughly, and add new make target \"remove-docker-compose\" to remove docker services."
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/README.rst b/node_manager_fkie/README.rst @@ -15,15 +15,15 @@ Shortcuts\n**F2** Renames a selected launch file.\n**F3** Opens a screen for selected node.\n**F4** Opens an XML Editor for selected node.\n-**Ctrl+R** Opens a dialog to launch a master_discovery_ node on entered host.\n-**Ctrl+E**, **F4** Opens an XML Editor for selected launch file.\n-**Ctrl+L** Loads the selected launch file into selected host.\n-**Ctrl+O** Runs on selected host default_cfg_ node with selected launch file as parameter.\n+**Alt+A** Opens a dialog to launch a master_discovery_ node on entered host.\n+**Ctrl+E** Goto location of the history file\n+**F4** Opens an XML Editor for selected launch file.\n+**Alt+O** Loads the selected launch file into selected host.\n**Alt+N** Opens a dialog to run a ROS node without a configuration. This node will be launched in a `SCREEN`.\n**Alt+R** Runs selected nodes. Ignores already running nodes.\n-**Alt+S** Stops selected nodes. If more then one node is selected, nodes ending with `rosout`, `node_manager`, `master_discovery`, `master_sync` or `default_cfg` are ignored.\n-**Ctrl+Backspace** Sends a `SIGKILL` to selected nodes. If more then one node is selected, nodes ending with `rosout`, `node_manager`, `master_discovery`, `master_sync` and `default_cfg` are ignored.\n-**Ctrl+Delete** Unregister selected nodes (their topics and services) from ROS master. If more then one node is selected, nodes ending with `rosout`, `node_manager`, `master_discovery`, `master_sync` and `default_cfg` are ignored.\n+**Alt+S** Stops selected nodes. If more then one node is selected, nodes ending with `rosout`, `node_manager`, `master_discovery`, `master_sync` or default_cfg are ignored.\n+**Ctrl+Backspace** Sends a `SIGKILL` to selected nodes. If more then one node is selected, nodes ending with `rosout`, `node_manager`, `master_discovery`, `master_sync` and default_cfg are ignored.\n+**Ctrl+Delete** Unregister selected nodes (their topics and services) from ROS master. If more then one node is selected, nodes ending with `rosout`, `node_manager`, `master_discovery`, `master_sync` and default_cfg are ignored.\n**Shift+Backspace** Sends a `SIGKILL` to assigned `SCREEN` of selected nodes.\n**Shift+S** Shows all available `SCREEN's` which contains the ROS nodes launched by node manager.\n**Ctrl+F4** Closes the loaded configurations.\n",
        "org_msg": "node_manager_fkie: fixed shortcut description in the README",
        "sim_msg": "Simplified grammar",
        "sim_diff": "diff --git a/packages/hagrid/hagrid/cli.py b/packages/hagrid/hagrid/cli.py @@ -21,13 +21,13 @@ def cli():\n@click.command(help=\"Start a new PyGrid domain/network node!\")\n-@click.argument(\"type\", type=click.Choice([\"domain\", \"network\"]))\n+@click.argument(\"name\", type=str)\n@click.option(\n- \"--name\",\n- default=\"\",\n+ \"--type\",\n+ default=\"domain\",\nrequired=False,\n- type=str,\n- help=\"The name of your new domain/network node. (Default: <randomly generated>)\",\n+ type=click.Choice([\"domain\", \"network\"]),\n+ help=\"The type of node you would like to deploy.\",\n)\n@click.option(\n\"--port\",\n@@ -50,7 +50,7 @@ def cli():\ntype=bool,\nhelp=\"\"\"If restarting a node that already existed, don't/do reset the database (Default: deletes the db)\"\"\",\n)\n-def launch(type, name, port, tag, keep_db, host=\"localhost\"):\n+def launch(name, type, port, tag, keep_db, host=\"localhost\"):\nif name == \"\":\nname = names.get_full_name() + \"'s \" + type.capitalize()\n@@ -110,13 +110,13 @@ def launch(type, name, port, tag, keep_db, host=\"localhost\"):\n@click.command(help=\"Stop a running PyGrid domain/network node.\")\n-@click.argument(\"type\", type=click.Choice([\"domain\", \"network\"]))\n+@click.argument(\"name\", type=str)\n@click.option(\n- \"--name\",\n- default=\"\",\n+ \"--type\",\n+ default=\"domain\",\nrequired=False,\n- type=str,\n- help=\"The name of your new domain/network node. (Default: <randomly generated>)\",\n+ type=click.Choice([\"domain\", \"network\"]),\n+ help=\"The type of node you would like to terminate.\",\n)\n@click.option(\n\"--port\",\n@@ -153,7 +153,7 @@ def land(type, name, port, tag):\nversion = check_docker()\n- motorcycle()\n+ # motorcycle()\nprint(\"Launching a \" + str(type) + \" PyGrid node on port \" + str(port) + \"!\\n\")\nprint(\" - TYPE: \" + str(type))\n",
        "chatgpt_cot": "\"Update keyboard shortcuts in README.rst file to reflect changes in launching and managing ROS nodes with node_manager_fkie.\""
    },
    {
        "org_diff": "diff --git a/fkie_node_manager/src/fkie_node_manager/main_window.py b/fkie_node_manager/src/fkie_node_manager/main_window.py @@ -1660,7 +1660,8 @@ class MainWindow(QMainWindow):\n'_ignore_services:=[]', '_sync_services:=[]',\n'_sync_remote_nodes:=False']\nself._append_stop_for('/master_sync', hostname, muri, self._progress_queue_sync)\n- self._progress_queue_sync.add2queue(utf8(uuid.uuid4()),\n+ self._progress_queue_sync.start()\n+ self._progress_queue.add2queue(utf8(uuid.uuid4()),\n'start sync on %s' % hostname,\nnm.starter().runNodeWithoutConfig,\n{'host': utf8(hostname),\n@@ -1673,7 +1674,6 @@ class MainWindow(QMainWindow):\n'auto_pw_request': False,\n'user': usr\n})\n- self._progress_queue_sync.start()\nelse:\nif hostname not in self._syncs_to_start:\nself._syncs_to_start.append(hostname)\n",
        "org_msg": "fkie_node_manager: start master_sync after master_discovery if both are started using start-dialog",
        "sim_msg": "root block synchronizer checks TD before starting sync task",
        "sim_diff": "diff --git a/quarkchain/cluster/master.py b/quarkchain/cluster/master.py @@ -335,6 +335,9 @@ class Synchronizer:\nself.root_block_header_list_limit = ROOT_BLOCK_HEADER_LIST_LIMIT\ndef add_task(self, header, peer):\n+ if header.total_difficulty <= peer.root_state.tip.total_difficulty:\n+ return\n+\nself.tasks[peer] = header\nLogger.info(\n\"[R] added {} {} to sync queue (running={})\".format(\n@@ -367,17 +370,33 @@ class Synchronizer:\ndef _pop_best_task(self):\n\"\"\" pop and return the task with heightest root \"\"\"\ncheck(len(self.tasks) > 0)\n- peer, header = max(\n- self.tasks.items(), key=lambda pair: pair[1].total_difficulty\n- )\n+ remove_list = []\n+ best_peer = None\n+ best_header = None\n+ for peer, header in self.tasks.items():\n+ if header.total_difficulty <= peer.root_state.tip.total_difficulty:\n+ remove_list.append(peer)\n+ continue\n+\n+ if best_header is None or header.total_difficulty > best_header.total_difficulty:\n+ best_header = header\n+ best_peer = peer\n+\n+ for peer in remove_list:\ndel self.tasks[peer]\n- return header, peer\n+ if best_peer is not None:\n+ del self.tasks[best_peer]\n+\n+ return best_header, best_peer\nasync def __run(self):\nLogger.info(\"[R] synchronizer started!\")\nwhile len(self.tasks) > 0:\nself.running_task = self._pop_best_task()\nheader, peer = self.running_task\n+ if header is None:\n+ check(len(self.tasks) == 0)\n+ break\ntask = SyncTask(header, peer, self.stats, self.root_block_header_list_limit)\nLogger.info(\n\"[R] start sync task {} {}\".format(\n",
        "chatgpt_cot": "\"Fix progress queue sync start in main window\""
    },
    {
        "org_diff": "diff --git a/test/test_pickled_data.py b/test/test_pickled_data.py @@ -826,6 +826,9 @@ def test_dicts():\nfor upgrade_id, upgrade_data in data.items():\nresearch_ability_correct: AbilityId = upgrade_data[\"ability\"]\nresearch_ability_from_api: AbilityId = bot._game_data.upgrades[upgrade_id.value].research_ability.exact_id\n+ if upgrade_id.value in {116, 117, 118}:\n+ # Research abilities for armory armor plating are mapped incorrectly in the API\n+ continue\nassert (\nresearch_ability_correct == research_ability_from_api\n), f\"Research abilities do not match: Correct one is {research_ability_correct} but API returned {research_ability_from_api}\"\n",
        "org_msg": "Fix tests - add exception for armory armor plating",
        "sim_msg": "going back to old way of testing dataset downloads",
        "sim_diff": "diff --git a/pliers/tests/test_datasets.py b/pliers/tests/test_datasets.py @@ -8,7 +8,7 @@ def test_dicts_exist_at_url_and_initialize():\n\"\"\"\ndatasets = _load_datasets()\nfor name, dataset in datasets.items():\n- r = requests.get(dataset['url'])\n+ r = requests.head(dataset['url'])\nassert r.status_code == requests.codes.ok\n# read_excel() is doing some weird things, so disable for the moment\n# data = fetch_dictionary(name, save=False)\n",
        "chatgpt_cot": "Fix incorrect mapping of research abilities for armory armor plating in test_pickled_data.py. Added condition to skip incorrect mappings."
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/message_frame.py b/node_manager_fkie/src/node_manager_fkie/message_frame.py import os\nfrom python_qt_binding import loadUi\nfrom python_qt_binding.QtCore import Qt, Signal\n-from python_qt_binding.QtGui import QPixmap\n+from python_qt_binding.QtGui import QPalette, QPixmap\nfrom node_manager_fkie.common import utf8\ntry:\n@@ -104,6 +104,8 @@ class MessageFrame(QFrame):\nui_file = os.path.join(os.path.dirname(os.path.realpath(__file__)), 'MessageFrame.ui')\nloadUi(ui_file, self.frameui)\nself.frameui.setVisible(False)\n+ bg_style = \"QFrame#questionFame { background-color: lightGray;}\"\n+ self.frameui.setStyleSheet(\"%s\" % (bg_style))\nself.frameui.questionOkButton.clicked.connect(self._on_question_ok)\nself.frameui.questionCancelButton.clicked.connect(self._on_question_cancel)\n# we use different queues for priority\n",
        "org_msg": "node_manager_fkie: changed background of question dialog to non transparent",
        "sim_msg": "add action log comment on updating link",
        "sim_diff": "diff --git a/qualcoder/manage_links.py b/qualcoder/manage_links.py @@ -34,8 +34,11 @@ import traceback\nfrom PyQt5 import QtCore, QtWidgets, QtGui\n+from code_text import DialogCodeText # for isinstance()\nfrom confirm_delete import DialogConfirmDelete\nfrom GUI.ui_dialog_manage_links import Ui_Dialog_manage_links\n+from view_image import DialogCodeImage # DialogCodeImage for isinstance()\n+from view_av import DialogCodeAV # DialogCodeAV for isinstance()\npath = os.path.abspath(os.path.dirname(__file__))\n@@ -61,12 +64,14 @@ class DialogManageLinks(QtWidgets.QDialog):\n\"\"\"\nparent_textEdit = None\n+ tab_coding = None # Tab widget coding tab\n- def __init__(self, app, parent_textEdit):\n+ def __init__(self, app, parent_textEdit, tab_coding):\nsys.excepthook = exception_handler\nself.app = app\nself.parent_textEdit = parent_textEdit\n+ self.tab_coding = tab_coding\nQtWidgets.QDialog.__init__(self)\nself.ui = Ui_Dialog_manage_links()\n@@ -115,6 +120,7 @@ class DialogManageLinks(QtWidgets.QDialog):\ndef file_selection(self, x):\n\"\"\" Select a file to replace the bad link.\nCalled by: table_menu, filename cell clicked.\n+ The path can be different but the file name must match.\n\"\"\"\nfile_path, ok = QtWidgets.QFileDialog.getOpenFileName(None, _('Select file'),\n@@ -134,14 +140,26 @@ class DialogManageLinks(QtWidgets.QDialog):\nmb.setText(msg)\nmb.exec_()\nreturn\n-\n- # All seems good so update link and database\n+ # All ok so update link and database\nself.links[x]['mediapath'] = self.links[x]['mediapath'].split(':')[0] + ':' + file_path\ncur = self.app.conn.cursor()\nsql = \"update source set mediapath=? where id=?\"\ncur.execute(sql, [self.links[x]['mediapath'], self.links[x]['id']])\nself.app.conn.commit()\nself.fill_table()\n+ # Add file to file list in any opened coding dialog\n+ contents = self.tab_coding.layout()\n+ if contents:\n+ for i in reversed(range(contents.count())):\n+ c = contents.itemAt(i).widget()\n+ if isinstance(c, DialogCodeImage):\n+ c.get_files()\n+ if isinstance(c, DialogCodeAV):\n+ c.get_files()\n+ if isinstance(c, DialogCodeText):\n+ c.get_files()\n+ self.parent_textEdit.append(_(\"Bad link fixed for file: \") + new_file_name + _(\" Path: \") + file_path)\n+ self.app.delete_backup = False\ndef cell_selected(self):\n\"\"\" When the table widget cell is selected open file select dialog.\n@@ -149,24 +167,6 @@ class DialogManageLinks(QtWidgets.QDialog):\nself.file_selection(self.ui.tableWidget.currentRow())\n- # Decided against typing in the link, instead use file select dialog\n- '''def cell_double_clicked(self):\n- \"\"\" \"\"\"\n-\n- x = self.ui.tableWidget.currentRow()\n- y = self.ui.tableWidget.currentColumn()\n-\n- if y == 0: # name column\n- self.file_selected(x)\n- if y == 1: # filepath column\n- pass'''\n-\n- '''def cell_modified(self):\n- \"\"\" File paths can be changed. \"\"\"\n-\n- x = self.ui.tableWidget.currentRow()\n- y = self.ui.tableWidget.currentColumn()'''\n-\ndef fill_table(self):\n\"\"\" Fill the table widget with file details. \"\"\"\n",
        "chatgpt_cot": "\"Add background color to question frame in MessageFrame to improve UI appearance and user experience.\""
    },
    {
        "org_diff": "diff --git a/sc2/expiring_dict.py b/sc2/expiring_dict.py @@ -83,19 +83,13 @@ class ExpiringDict(OrderedDict):\ndef __repr__(self):\n\"\"\" Printable version of the dict instead of getting memory adress \"\"\"\n- print_list = [\"ExpiringDict(\"]\n+ print_list = []\nwith self.lock:\nfor key, value in OrderedDict.items(self):\nif self.frame - value[1] < self.max_age:\n- try:\n- print_list.append(f\"{repr(key)}: {repr(value)}\")\n- except:\nprint_list.append(f\"{key}: {value}\")\n- print_list.append(\", \")\n- if print_list[-1] == \", \":\n- print_list.pop()\n- print_list.append(\")\")\n- return \"\".join(print_list)\n+ print_str = \", \".join(print_list)\n+ return f\"ExpiringDict({print_str})\"\ndef __str__(self):\nreturn self.__repr__()\n",
        "org_msg": "Simplify expiring dict repr function",
        "sim_msg": "captured non int expiry date index choice error",
        "sim_diff": "diff --git a/gamestonk_terminal/options/op_controller.py b/gamestonk_terminal/options/op_controller.py @@ -42,7 +42,7 @@ class OptionsController:\n@staticmethod\ndef print_exp_dates(expiry_date, all_dates):\n\"\"\"Print all available expiry dates.\"\"\"\n- print(f\"\\nCurrent selected expiry date: [{expiry_date}]\")\n+ print(f\"Current selected expiry date: [{expiry_date}]\")\nprint(\"\\nAvailable dates:\\n\")\nfor i, d in enumerate(all_dates):\nif len(str(i)) == 1:\n@@ -143,6 +143,11 @@ class OptionsController:\nf\"\\nSelection must be between [0 - {len(self.raw_data_options.options) - 1}]\\n\"\n)\ncontinue\n+ except ValueError:\n+ print(\"The command selected doesn't exist\\n\")\n+ self.print_exp_dates(\n+ self.expiry_date, self.raw_data_options.options\n+ )\nexcept SystemExit:\nprint(\"The command selected doesn't exist\\n\")\n",
        "chatgpt_cot": "Refactor __repr__ method in ExpiringDict to improve readability and maintainability. Fix issue with printing list and handle exception cases."
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/start_handler.py b/node_manager_fkie/src/node_manager_fkie/start_handler.py @@ -126,8 +126,6 @@ class StartHandler(object):\nraise StartException('\\n'.join(err))\nelse:\ncmd_type = cmd[0]\n- cmd_str = utf8(' '.join([screen.get_cmd(fullname), cmd_type, ' '.join(args2)]))\n- rospy.loginfo(\"Run without config: %s\", fullname if use_nmd else cmd_str)\nnew_env = {} # dict(os.environ)\nif namespace:\nnew_env['ROS_NAMESPACE'] = namespace\n@@ -144,6 +142,8 @@ class StartHandler(object):\nelse:\nlocal_env = dict(os.environ)\nlocal_env.update(new_env)\n+ cmd_str = utf8(' '.join([screen.get_cmd(fullname, local_env), cmd_type, ' '.join(args2)]))\n+ rospy.loginfo(\"Run without config: %s\", fullname if use_nmd else cmd_str)\nSupervisedPopen(shlex.split(cmd_str), env=local_env, object_id=\"Run without config\", description=\"Run without config [%s]%s\" % (utf8(package), utf8(binary)))\nelse:\n# run on a remote machine\n",
        "org_msg": "node_manager_fkie: fixed local nmdaemon start with multiple ros master",
        "sim_msg": "Fixed cli exception raised where it can just bail nicely",
        "sim_diff": "diff --git a/fedn/cli/run_cmd.py b/fedn/cli/run_cmd.py @@ -46,7 +46,7 @@ def client_cmd(ctx, discoverhost, discoverport, token, name, client_id, remote,\nwith open(config['init'], 'r') as file:\ntry:\nsettings = dict(yaml.safe_load(file))\n- except (TypeError, yaml.YAMLError) as e:\n+ except Exception as e:\nprint('Failed to read config from settings file, exiting.',flush=True)\nreturn\n#raise(e)\n",
        "chatgpt_cot": "Fix compilation issue by modifying the start_handler.py file to update the cmd_str and local_env variables for proper execution."
    },
    {
        "org_diff": "diff --git a/node_manager_daemon_fkie/src/node_manager_daemon_fkie/launcher.py b/node_manager_daemon_fkie/src/node_manager_daemon_fkie/launcher.py @@ -74,6 +74,7 @@ def create_start_config(node, launchcfg, executable='', masteruri=None, loglevel\nrospy.loginfo(\"SCREEN prefix removed before start!\")\nprefix = ''\nresult.prefix = prefix\n+ result.env = {key: value for key, value in n.env_args}\n# set remapings\nresult.remaps = {remap[0]: remap[1] for remap in n.remap_args}\n# set respawn parameter\n@@ -167,6 +168,8 @@ def run_node(startcfg):\ncwd = get_cwd(startcfg.cwd, cmd_type)\n# set environment\nnew_env = dict(os.environ)\n+ # add environment from launch\n+ new_env.extend(startcfg.env)\nif startcfg.namespace:\nnew_env['ROS_NAMESPACE'] = startcfg.namespace\n# set logging\n",
        "org_msg": "node_manager_daemon_fkie: load environment from launch file",
        "sim_msg": "add copy_spec1d to scripts; remove version spec for linetools; add ginga plugin; remove unused pytest config",
        "sim_diff": "diff --git a/setup.cfg b/setup.cfg @@ -46,11 +46,12 @@ scripts =\nbin/pypeit_chk_plugins\nbin/pypeit_clean\nbin/pypeit_version\n+ bin/copy_spec1d.py\n[options.extras_require]\ngui =\nginga>=3.0\n- linetools>0.3\n+ linetools\nqtpy>=1.9\npyside2 =\npyside2>=5.0\n@@ -103,11 +104,8 @@ console_scripts =\npypeit_show_wvcalib = pypeit.scripts.show_wvcalib:entry_point [gui]\npypeit_skysub_regions = pypeit.scripts.skysub_regions:entry_point [gui]\npypeit_view_fits = pypeit.scripts.view_fits:entry_point [gui]\n-\n-[tool:pytest]\n-testpaths = \"pypeit\"\n-astropy_header = true\n-doctest_plus = disabled\n+ginga.rv.plugins =\n+ SlitWavelength = pypeit.display:setup_SlitWavelength\n[coverage:run]\nomit =\n",
        "chatgpt_cot": "Add environment variables from launch configuration to the new environment to resolve issue with missing environment variables in launcher.py."
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/main_window.py b/node_manager_fkie/src/node_manager_fkie/main_window.py @@ -1713,17 +1713,17 @@ class MainWindow(QMainWindow):\ndef changeEvent(self, event):\n'''\n'''\n+ if self.isActiveWindow() and self.isActiveWindow() != self._last_window_state:\n+ if hasattr(self, 'currentMaster') and self.currentMaster is not None:\n+ # perform checks for changed files of multiple screens\n+ self.currentMaster.perform_master_checks()\n+ self._last_window_state = self.isActiveWindow()\nQMainWindow.changeEvent(self, event)\ndef enterEvent(self, event):\n'''\nCheck for changed files, if the main gui was entered.\n'''\n- if self.isActiveWindow() and self.isActiveWindow() != self._last_window_state:\n- if hasattr(self, 'currentMaster') and self.currentMaster is not None:\n- # perform checks for changed files of multiple screens\n- self.currentMaster.perform_master_checks()\n- self._last_window_state = self.isActiveWindow()\nQMainWindow.enterEvent(self, event)\n# ======================================================================================================================\n",
        "org_msg": "node_manager_fkie: fix not detected changes on files",
        "sim_msg": "add ctrl F to jump to search results lineEdit",
        "sim_diff": "diff --git a/qualcoder/report_codes.py b/qualcoder/report_codes.py @@ -889,15 +889,31 @@ class DialogReportCodes(QtWidgets.QDialog):\ndef eventFilter(self, object_, event):\n\"\"\" Used to detect key events in the textedit.\nH Hide / Unhide top groupbox\n+ Ctrl F Search box focus\n\"\"\"\n- if type(event) == QtGui.QKeyEvent and (self.ui.textEdit.hasFocus() or self.ui.treeWidget.hasFocus() or\n+ '''if type(event) == QtGui.QKeyEvent and (self.ui.textEdit.hasFocus() or self.ui.treeWidget.hasFocus() or\nself.ui.listWidget_files.hasFocus() or\nself.ui.listWidget_cases.hasFocus()):\nkey = event.key()\n+\n# Hide unHide top groupbox\nif key == QtCore.Qt.Key.Key_H:\nself.ui.groupBox.setHidden(not (self.ui.groupBox.isHidden()))\n+ return True'''\n+ if type(event) == QtGui.QKeyEvent:\n+ key = event.key()\n+ mod = event.modifiers()\n+ # Hide unHide top groupbox\n+ if key == QtCore.Qt.Key.Key_H and (self.ui.textEdit.hasFocus() or self.ui.treeWidget.hasFocus() or\n+ self.ui.listWidget_files.hasFocus() or\n+ self.ui.listWidget_cases.hasFocus()):\n+ self.ui.groupBox.setHidden(not (self.ui.groupBox.isHidden()))\n+ return True\n+ # Ctrl + F jump to search box\n+ if key == QtCore.Qt.Key.Key_F and mod == QtCore.Qt.KeyboardModifier.ControlModifier:\n+ self.ui.lineEdit_search_results.setFocus()\n+ self.ui.groupBox.setHidden(False)\nreturn True\nreturn False\n",
        "chatgpt_cot": "fixes issue with file changeEvent and enterEvent, adds checks for changed files and current master."
    },
    {
        "org_diff": "diff --git a/sc2/game_state.py b/sc2/game_state.py @@ -49,24 +49,24 @@ class GameState(object):\nself.psionic_matrix = PsionicMatrix.from_proto(self.observation.raw_data.player.power_sources)\nself.game_loop = self.observation.game_loop\n- destructables = [x for x in observation.observation.raw_data.units if\n+ destructables = [x for x in self.observation.raw_data.units if\nx.alliance == 3 and x.radius > 1.5] # all destructable rocks except the one below the main base ramps\nself.destructables = Units.from_proto(destructables, game_data)\n# fix for enemy units detected by my sensor tower\nvisibleUnits, hiddenUnits = [], []\n- for u in observation.observation.raw_data.units:\n+ for u in self.observation.raw_data.units:\nhiddenUnits.append(u) if u.is_blip else visibleUnits.append(u)\nself.units = Units.from_proto(visibleUnits, game_data)\n# self.blips = Units.from_proto(hiddenUnits, game_data) # TODO: fix me\n- self.visibility = PixelMap(observation.observation.raw_data.map_state.visibility)\n- self.creep = PixelMap(observation.observation.raw_data.map_state.creep)\n+ self.visibility = PixelMap(self.observation.raw_data.map_state.visibility)\n+ self.creep = PixelMap(self.observation.raw_data.map_state.creep)\nself.dead_units = {dead_unit_tag for dead_unit_tag in\n- observation.observation.raw_data.event.dead_units} # set of unit tags that died this step - sometimes has multiple entries\n+ self.observation.raw_data.event.dead_units} # set of unit tags that died this step - sometimes has multiple entries\nself.effects = {EffectData(effect) for effect in\n- observation.observation.raw_data.effects} # effects like ravager bile shot, lurker attack, everything in effect_id.py\n+ self.observation.raw_data.effects} # effects like ravager bile shot, lurker attack, everything in effect_id.py\n\"\"\" Usage:\nfor effect in self.state.effects:\nif effect.id == EffectId.RAVAGERCORROSIVEBILECP:\n@@ -75,7 +75,7 @@ class GameState(object):\n\"\"\"\nself.upgrades = {UpgradeId(upgrade) for upgrade in\n- observation.observation.raw_data.player.upgrade_ids} # usage: if TERRANINFANTRYWEAPONSLEVEL1 in self.state.upgrades: do stuff\n+ self.observation.raw_data.player.upgrade_ids} # usage: if TERRANINFANTRYWEAPONSLEVEL1 in self.state.upgrades: do stuff\n@property\ndef mineral_field(self):\n",
        "org_msg": "Fix issues created by merges",
        "sim_msg": "Change to using scipy constants.",
        "sim_diff": "diff --git a/SimPEG/FLOW/Richards/Empirical.py b/SimPEG/FLOW/Richards/Empirical.py @@ -5,6 +5,7 @@ from __future__ import unicode_literals\nimport numpy as np\nimport scipy.sparse as sp\n+from scipy import constants\nfrom SimPEG import Utils, Props\n@@ -575,77 +576,77 @@ class VanGenuchtenParams(object):\ndef sand(self):\nreturn {\n\"theta_r\": 0.020, \"theta_s\": 0.417, \"alpha\": 0.138*100.,\n- \"n\": 1.592, \"Ks\": 504.0/100./24./60./60.\n+ \"n\": 1.592, \"Ks\": 504.0*constants.centi/constants.day\n}\n@property\ndef loamy_sand(self):\nreturn {\n\"theta_r\": 0.035, \"theta_s\": 0.401, \"alpha\": 0.115*100.,\n- \"n\": 1.474, \"Ks\": 146.6/100./24./60./60.\n+ \"n\": 1.474, \"Ks\": 146.6*constants.centi/constants.day\n}\n@property\ndef sandy_loam(self):\nreturn {\n\"theta_r\": 0.041, \"theta_s\": 0.412, \"alpha\": 0.068*100.,\n- \"n\": 1.322, \"Ks\": 62.16/100./24./60./60.\n+ \"n\": 1.322, \"Ks\": 62.16*constants.centi/constants.day\n}\n@property\ndef loam(self):\nreturn {\n\"theta_r\": 0.027, \"theta_s\": 0.434, \"alpha\": 0.090*100.,\n- \"n\": 1.220, \"Ks\": 16.32/100./24./60./60.\n+ \"n\": 1.220, \"Ks\": 16.32*constants.centi/constants.day\n}\n@property\ndef silt_loam(self):\nreturn {\n\"theta_r\": 0.015, \"theta_s\": 0.486, \"alpha\": 0.048*100.,\n- \"n\": 1.211, \"Ks\": 31.68/100./24./60./60.\n+ \"n\": 1.211, \"Ks\": 31.68*constants.centi/constants.day\n}\n@property\ndef sandy_clay_loam(self):\nreturn {\n\"theta_r\": 0.068, \"theta_s\": 0.330, \"alpha\": 0.036*100.,\n- \"n\": 1.250, \"Ks\": 10.32/100./24./60./60.\n+ \"n\": 1.250, \"Ks\": 10.32*constants.centi/constants.day\n}\n@property\ndef clay_loam(self):\nreturn {\n\"theta_r\": 0.075, \"theta_s\": 0.390, \"alpha\": 0.039*100.,\n- \"n\": 1.194, \"Ks\": 5.52/100./24./60./60.\n+ \"n\": 1.194, \"Ks\": 5.52*constants.centi/constants.day\n}\n@property\ndef silty_clay_loam(self):\nreturn {\n\"theta_r\": 0.040, \"theta_s\": 0.432, \"alpha\": 0.031*100.,\n- \"n\": 1.151, \"Ks\": 3.60/100./24./60./60.\n+ \"n\": 1.151, \"Ks\": 3.60*constants.centi/constants.day\n}\n@property\ndef sandy_clay(self):\nreturn {\n\"theta_r\": 0.109, \"theta_s\": 0.321, \"alpha\": 0.034*100.,\n- \"n\": 1.168, \"Ks\": 2.88/100./24./60./60.\n+ \"n\": 1.168, \"Ks\": 2.88*constants.centi/constants.day\n}\n@property\ndef silty_clay(self):\nreturn {\n\"theta_r\": 0.056, \"theta_s\": 0.423, \"alpha\": 0.029*100.,\n- \"n\": 1.127, \"Ks\": 2.16/100./24./60./60.\n+ \"n\": 1.127, \"Ks\": 2.16*constants.centi/constants.day\n}\n@property\ndef clay(self):\nreturn {\n\"theta_r\": 0.090, \"theta_s\": 0.385, \"alpha\": 0.027*100.,\n- \"n\": 1.131, \"Ks\": 1.44/100./24./60./60.\n+ \"n\": 1.131, \"Ks\": 1.44*constants.centi/constants.day\n}\n# From:\n",
        "chatgpt_cot": "Fix compilation issue due to unqualified references to observation in GameState.py. Add self to observation to resolve the issue."
    },
    {
        "org_diff": "diff --git a/fkie_node_manager_daemon/src/fkie_node_manager_daemon/file_servicer.py b/fkie_node_manager_daemon/src/fkie_node_manager_daemon/file_servicer.py @@ -407,7 +407,6 @@ class FileServicer(fms_grpc.FileServiceServicer):\ntry:\npath = get_pkg_path(request.name)\nself._get_binaries(path, binaries)\n- result.items.extend(binaries)\n# find binaries in catkin workspace\nfrom catkin.find_in_workspaces import find_in_workspaces as catkin_find\nsearch_paths = catkin_find(search_dirs=['libexec', 'share'], project=request.name, first_matching_workspace_only=True)\n@@ -417,6 +416,13 @@ class FileServicer(fms_grpc.FileServiceServicer):\nimport traceback\nprint(traceback.format_exc())\npass\n+ for b in binaries:\n+ found = False\n+ for item in result.items:\n+ if item.path == b.path:\n+ found = True\n+ if not found:\n+ result.items.extend([b])\nreturn result\ndef Delete(self, request, context):\n",
        "org_msg": "fkie_node_manager_daemon: fix find package binaries",
        "sim_msg": "Print the error",
        "sim_diff": "diff --git a/modules/png-extraction/ImageExtractor.py b/modules/png-extraction/ImageExtractor.py @@ -207,15 +207,19 @@ def extract_images(i):\nfilemapping = filedata.iloc[i].loc['file'] + ', ' + pngfile + '\\n'\nexcept AttributeError as error:\nfound_err = error\n+ logging.error(found_err)\nfail_path = filedata.iloc[i].loc['file'], failed + '1/' + os.path.split(filedata.iloc[i].loc['file'])[1][:-4]+'.dcm'\nexcept ValueError as error:\nfound_err = error\n+ logging.error(found_err)\nfail_path = filedata.iloc[i].loc['file'], failed + '2/' + os.path.split(filedata.iloc[i].loc['file'])[1][:-4]+'.dcm'\nexcept BaseException as error:\nfound_err = error\n+ logging.error(found_err)\nfail_path = filedata.iloc[i].loc['file'], failed + '3/' + os.path.split(filedata.iloc[i].loc['file'])[1][:-4]+'.dcm'\nexcept:\nfound_err = error\n+ logging.error(found_err)\nfail_path = filedata.iloc[i].loc['file'], failed + '4/' + os.path.split(filedata.iloc[i].loc['file'])[1][:-4]+'.dcm'\nreturn (filemapping,fail_path,found_err)\n",
        "chatgpt_cot": "\"Fix file_servicer.py to add missing binaries to result items and resolve compilation issue.\""
    },
    {
        "org_diff": "diff --git a/sc2/pixel_map.py b/sc2/pixel_map.py @@ -13,6 +13,10 @@ class PixelMap:\n:param mirrored:\n\"\"\"\nself._proto = proto\n+ # Used for copying pixelmaps\n+ self._in_bits: bool = in_bits\n+ self._mirrored: bool = mirrored\n+\nassert self.width * self.height == (8 if in_bits else 1) * len(\nself._proto.data\n), f\"{self.width * self.height} {(8 if in_bits else 1)*len(self._proto.data)}\"\n@@ -49,7 +53,7 @@ class PixelMap:\n\"\"\" Example usage: self._game_info.pathing_grid[Point2((20, 20))] = 255 \"\"\"\nassert 0 <= pos[0] < self.width, f\"x is {pos[0]}, self.width is {self.width}\"\nassert 0 <= pos[1] < self.height, f\"y is {pos[1]}, self.height is {self.height}\"\n- assert 0 <= value < 256, f\"value is {value}, it should be between 0 and 255\"\n+ assert 0 <= value <= 254 * self._in_bits + 1, f\"value is {value}, it should be between 0 and {254 * self._in_bits + 1}\"\nassert isinstance(value, int), f\"value is of type {type(value)}, it should be an integer\"\nself.data_numpy[pos[1], pos[0]] = value\n@@ -62,6 +66,9 @@ class PixelMap:\ndef invert(self):\nraise NotImplementedError\n+ def copy(self):\n+ return PixelMap(self._proto, in_bits=self._in_bits, mirrored=self._mirrored)\n+\ndef flood_fill(self, start_point: Point2, pred: Callable[[int], bool]) -> Set[Point2]:\nnodes: Set[Point2] = set()\nqueue: List[Point2] = [start_point]\n",
        "org_msg": "Add variables to pixelmap to be able to copy it",
        "sim_msg": "test bug fix in discretisation.process_symbol",
        "sim_diff": "diff --git a/tests/test_discretisations/test_base_discretisations.py b/tests/test_discretisations/test_base_discretisations.py @@ -96,6 +96,48 @@ class TestDiscretise(unittest.TestCase):\n# non-spatial unary operator\n# TODO: none of these implemented yet\n+ def test_process_complex_expression(self):\n+ var1 = pybamm.Variable(\"var1\")\n+ var2 = pybamm.Variable(\"var2\")\n+ par1 = pybamm.Parameter(\"par1\")\n+ par2 = pybamm.Parameter(\"par2\")\n+ scal1 = pybamm.Scalar(\"scal1\")\n+ scal2 = pybamm.Scalar(\"scal2\")\n+ expression = (scal1 * (par1 + var2)) / ((var1 - par2) + scal2)\n+\n+ disc = pybamm.BaseDiscretisation(None)\n+ y_slices = {var1.id: slice(53), var2.id: slice(53, 59)}\n+ exp_disc = disc.process_symbol(expression, None, y_slices)\n+ self.assertTrue(isinstance(exp_disc, pybamm.Division))\n+ # left side\n+ self.assertTrue(isinstance(exp_disc.children[0], pybamm.Multiplication))\n+ self.assertTrue(isinstance(exp_disc.children[0].children[0], pybamm.Scalar))\n+ self.assertTrue(isinstance(exp_disc.children[0].children[1], pybamm.Addition))\n+ self.assertTrue(\n+ isinstance(exp_disc.children[0].children[1].children[0], pybamm.Parameter)\n+ )\n+ self.assertTrue(\n+ isinstance(exp_disc.children[0].children[1].children[1], pybamm.StateVector)\n+ )\n+ self.assertEqual(\n+ exp_disc.children[0].children[1].children[1].y_slice, y_slices[var2.id]\n+ )\n+ # right side\n+ self.assertTrue(isinstance(exp_disc.children[1], pybamm.Addition))\n+ self.assertTrue(\n+ isinstance(exp_disc.children[1].children[0], pybamm.Subtraction)\n+ )\n+ self.assertTrue(\n+ isinstance(exp_disc.children[1].children[0].children[0], pybamm.StateVector)\n+ )\n+ self.assertEqual(\n+ exp_disc.children[1].children[0].children[0].y_slice, y_slices[var1.id]\n+ )\n+ self.assertTrue(\n+ isinstance(exp_disc.children[1].children[0].children[1], pybamm.Parameter)\n+ )\n+ self.assertTrue(isinstance(exp_disc.children[1].children[1], pybamm.Scalar))\n+\ndef test_discretise_spatial_operator(self):\nmesh = MeshForTesting()\ndisc = DiscretisationForTesting(mesh)\n",
        "chatgpt_cot": "Add method to copy PixelMap, update value validation, and implement copy method."
    },
    {
        "org_diff": "diff --git a/fkie_master_discovery/src/fkie_master_discovery/master_monitor.py b/fkie_master_discovery/src/fkie_master_discovery/master_monitor.py @@ -835,6 +835,8 @@ class MasterMonitor(object):\nrospy.logwarn(timejump_msg)\nif timejump_msg not in self._master_errors:\nself._master_errors.append(timejump_msg)\n+ self._exit_timer = threading.Timer(5.0, self._timejump_exit)\n+ self._exit_timer.start()\nif do_update:\nself.updateSyncInfo()\nwith self._state_access_lock:\n@@ -848,6 +850,10 @@ class MasterMonitor(object):\nself.__master_state.check_ts = self.__new_master_state.timestamp\nreturn result\n+ def _timejump_exit(self):\n+ rospy.logwarn('Shutdown yourself to avoid system instability because of time jump into past!\\n')\n+ rospy.signal_shutdown('Shutdown yourself to avoid system instability because of time jump into past')\n+\ndef reset(self):\n'''\nSets the master state to ``None``.\n",
        "org_msg": "fkie_master_discovery: shutdown node if time jump into past detected\nthis cause whole system instability",
        "sim_msg": "fix audit log errors after the bot is kicked",
        "sim_diff": "diff --git a/GearBot/Cogs/ModLog.py b/GearBot/Cogs/ModLog.py @@ -237,7 +237,7 @@ class ModLog(BaseCog):\nif await self.bot.redis_pool.get(f\"forced_exits:{member.guild.id}-{member.id}\") is not None:\nreturn\nawait asyncio.sleep(4)\n- if member.guild.me.guild_permissions.view_audit_log and Features.is_logged(member.guild.id, \"MOD_ACTIONS\"):\n+ if member.guild.me is not None and member.guild.me.guild_permissions.view_audit_log and Features.is_logged(member.guild.id, \"MOD_ACTIONS\"):\ntry:\nasync for entry in member.guild.audit_logs(limit=25):\nif entry.action not in (AuditLogAction.kick, AuditLogAction.ban):\n",
        "chatgpt_cot": "Add method _timejump_exit to handle time jump into the past, shutdown to avoid system instability. Fix potential system stability issue due to time jump."
    },
    {
        "org_diff": "diff --git a/sc2/client.py b/sc2/client.py @@ -336,6 +336,19 @@ class Client(Protocol):\nreturn [[AbilityId(a.ability_id) for a in b.abilities] for b in result.query.abilities][0]\nreturn [[AbilityId(a.ability_id) for a in b.abilities] for b in result.query.abilities]\n+ async def query_available_abilities_with_tag(\n+ self, units: Union[List[Unit], Units], ignore_resource_requirements: bool = False\n+ ) -> Dict[Set[AbilityId]]:\n+ \"\"\" Query abilities of multiple units \"\"\"\n+\n+ result = await self._execute(\n+ query=query_pb.RequestQuery(\n+ abilities=(query_pb.RequestQueryAvailableAbilities(unit_tag=unit.tag) for unit in units),\n+ ignore_resource_requirements=ignore_resource_requirements,\n+ )\n+ )\n+ return {b.unit_tag: {AbilityId(a.ability_id) for a in b.abilities} for b in result.query.abilities}\n+\nasync def chat_send(self, message: str, team_only: bool):\n\"\"\" Writes a message to the chat \"\"\"\nch = ChatChannel.Team if team_only else ChatChannel.Broadcast\n",
        "org_msg": "client.py changes",
        "sim_msg": "add assets, activate, download to client",
        "sim_diff": "diff --git a/planet/api/client.py b/planet/api/client.py @@ -296,3 +296,15 @@ class ClientV1(_Base):\nreturn self.dispatcher.response(models.Request(\nself._url('data/v1/stats'), self.auth,\nbody_type=models.JSON, data=body, method='POST')).get_body()\n+\n+ def get_assets(self, item):\n+ assets_url = item['_links']['assets']\n+ return self._get(assets_url).get_body()\n+\n+ def activate(self, asset):\n+ activate_url = asset['_links']['activate']\n+ return self._get(activate_url).get_body()\n+\n+ def download(self, asset, callback=None):\n+ download_url = asset['location']\n+ return self._get(download_url, models.Image, callback=callback)\n",
        "chatgpt_cot": "Add query_available_abilities_with_tag method to Client class to query abilities of multiple units. Fixes issue with querying abilities for multiple units."
    },
    {
        "org_diff": "diff --git a/MAINTAINERS.md b/MAINTAINERS.md | Baohua Yang | yeasy | baohua | yangbaohua@gmail.com |\n| Haitao Yue | hightall | hightall | hightallyht@gmail.com |\n| Tong Li | tongli | tongli | litong01@us.ibm.com |\n+| Qiang Xu | XuHugo | XuHugo | xq-310@163.com |\n+\n+## Retired Maintainers\n+\n+| Name | GitHub | RocketChat | Email |\n+|---|---|---|---|\n| Luke Chen | LordGoodman | luke_chen | jiahaochen1993@gmail.com |\n<a rel=\"license\" href=\"http://creativecommons.org/licenses/by/4.0/\"><img alt=\"Creative Commons License\" style=\"border-width:0\" src=\"https://i.creativecommons.org/l/by/4.0/88x31.png\" /></a><br />This work is licensed under a <a rel=\"license\" href=\"http://creativecommons.org/licenses/by/4.0/\">Creative Commons Attribution 4.0 International License</a>.\n",
        "org_msg": "Update Maintainers\nNominate Qiang Xu as new maintainer. He has leaded the user dashboard\ndevelopment for quite a while, and actively attend the meeting\ndiscussions with code contributions.\nRetire inactive maintainer Luke Chen. Thanks a lot for his\ncontributions.",
        "sim_msg": "updated top-level README",
        "sim_diff": "diff --git a/README.md b/README.md # ACL Anthology\n-(This repo was originally wing-nus/acl and has been transferred over to acl-org\n-as of 5 Jun 2017. Please update accordingly.)\n-\n-These are basic instructions on generating the ACL Anthology website as seen on\n-<https://aclweb.org/anthology/>.\n-\n+These are basic instructions on generating the ACL Anthology website as seen on <https://aclweb.org/anthology/>.\n+The offical home of this repository is <https://github.com/acl-org/acl-anthology>.\n## Generating the Anthology\n@@ -64,21 +60,18 @@ about a minute to start.\n## Contributing\n-If you'd like to contribute to the ACL Anthology, please take a look at our\n-[information on volunteering](https://aclanthology.info/volunteer) and the\n-[detailed README](README_detailed.md) containing more in-depth information about\n-generating and modifying the website.\n+If you'd like to contribute to the ACL Anthology, please take a look at:\n+- our [Github issues page](https://github.com/acl-org/acl-anthology/issues)\n+- our [call for volunteers](https://aclanthology.info/volunteer)\n+- the [detailed README](README_detailed.md) which contains more in-depth information about generating and modifying the website.\n-## License\n+## History\n-Materials prior to 2016 here are licensed under the [Creative Commons\n-Attribution-NonCommercial-ShareAlike 3.0 International\n-License](https://creativecommons.org/licenses/by-nc-sa/3.0/). Permission is\n-granted to make copies for the purposes of teaching and research. Materials\n-published in or after 2016 are licensed on a [Creative Commons Attribution 4.0\n-License](https://creativecommons.org/licenses/by/4.0/).\n+This repo was originally wing-nus/acl and has been transferred over to acl-org as of 5 June 2017.\n-Matt Post (Editor, 2019-) / Min-Yen Kan (Editor, 2008-2018) / Steven Bird (Editor, 2001-2007)\n+## License\n-Developer team: Linh Hien Ng (linhhienng at gmail dot com), Duong Ho Tuan zamakkat at gmail dot com)\n+Materials prior to 2016 here are licensed under the [Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License](https://creativecommons.org/licenses/by-nc-sa/3.0/).\n+Permission is granted to make copies for the purposes of teaching and research.\n+Materials published in or after 2016 are licensed on a [Creative Commons Attribution 4.0 License](https://creativecommons.org/licenses/by/4.0/).\n",
        "chatgpt_cot": "Add Qiang Xu as a new maintainer and retire Luke Chen. Update MAINTAINERS.md to reflect the changes in the maintainers list."
    },
    {
        "org_diff": "diff --git a/user-dashboard/js/dashboard/src/routes/Chain/index.js b/user-dashboard/js/dashboard/src/routes/Chain/index.js @@ -90,6 +90,7 @@ class Chain extends PureComponent {\nconst {loading} = this.state;\nconst { queryByBlockId:{queryByBlockId } } = this.props.chain;\nconst { queryByTransactionId : {queryByTransactionId}} = this.props.chain\n+ const currentChainId = localStorage.getItem(`${window.apikey}-chainId`);\nconst cb = () => {\nconsole.log('expired callback')\n}\n",
        "org_msg": "Fix page crashed when apply multi chain\nSet currentChainId value in chain page.",
        "sim_msg": "added a timer in dashboard",
        "sim_diff": "diff --git a/myems-web/src/components/MyEMS/dashboard/Dashboard.js b/myems-web/src/components/MyEMS/dashboard/Dashboard.js @@ -406,6 +406,16 @@ const Dashboard = ({ setRedirect, setRedirectUrl, t }) => {\n};\n}, );\n+ useEffect(() => {\n+ let timer = setInterval(() => {\n+ let is_logged_in = getCookieValue('is_logged_in');\n+ if (is_logged_in === null || !is_logged_in) {\n+ setRedirectUrl(`/authentication/basic/login`);\n+ setRedirect(true);\n+ }\n+ }, 1000);\n+ return () => clearInterval(timer);\n+ }, [])\nreturn (\n<Fragment>\n",
        "chatgpt_cot": "Add currentChainId retrieval using localStorage in Chain component to store the chain ID, enhancing functionality in the user dashboard."
    },
    {
        "org_diff": "diff --git a/examples/simulate_fight_scenario.py b/examples/simulate_fight_scenario.py @@ -35,22 +35,18 @@ class FightBot(BotAI):\n[UnitTypeId.MARINE, 4, self.start_location.towards(self.enemy_location, 8), ME]\n])\n- # note: we should wait till workers will be destroyed\n+ # wait till workers will be destroyed and start the fight\nif not self.fight_started and self.enemy_location and not self.enemy_units(UnitTypeId.SCV) and not self.units(UnitTypeId.SCV):\n- # start fight\nfor u in self.enemy_units:\n- u.attack(self.structures.first.position)\n+ u.attack(self.start_location)\nfor u in self.units:\n- u.attack(self.enemy_structures.first.position)\n- # await self._client.move_camera(self._game_info.map_center)\n- logger.info(\"fight started\")\n- # await self.chat_send(\"fight started\")\n+ u.attack(self.enemy_location)\nself.fight_started = True\n# in case of no units left - do not wait for game to finish\nif self.fight_started and (not self.units or not self.enemy_units):\nlogger.info(\"LOSE\" if not self.units else \"WIN\")\n- await self._client.quit() # await self._client.debug_leave() # or reset level\n+ await self._client.quit() # or reset level\nfor u in self.units(UnitTypeId.MARINE):\nu.attack(self.enemy_structures.first.position)\n",
        "org_msg": "cleanup fight start",
        "sim_msg": "Test for timer player vars",
        "sim_diff": "diff --git a/mpf/tests/test_Timer.py b/mpf/tests/test_Timer.py @@ -441,3 +441,40 @@ class TestTimer(MpfFakeGameTestCase):\nself.assertEqual(7, timer.ticks)\nself.advance_time_and_run(1)\nself.assertEqual(8, timer.ticks)\n+\n+ def test_timer_player_vars_with_multiplayer(self):\n+ # add a fake player\n+ self.start_two_player_game()\n+\n+ self.assertPlayerNumber(1)\n+ self.assertBallNumber(1)\n+ self.advance_time_and_run(.1)\n+\n+ timer = self.machine.timers['timer_start_with_game']\n+ # In this test scenario, the timer is at 2 ticks by the time we get here\n+ self.assertEqual(2, timer.ticks)\n+\n+ self.advance_time_and_run(1)\n+ self.assertEqual(self.machine.game.player_list[0].mode_with_timers2_timer_start_with_game_tick, 3)\n+ self.advance_time_and_run(1)\n+ self.assertEqual(self.machine.game.player_list[0].mode_with_timers2_timer_start_with_game_tick, 4)\n+\n+ self.machine.events.post('stop_mode_with_timers2')\n+ self.drain_all_balls()\n+ self.advance_time_and_run()\n+ self.assertPlayerNumber(2)\n+ self.assertBallNumber(1)\n+ self.machine.events.post('start_mode_with_timers')\n+ self.advance_time_and_run(.1)\n+\n+ self.assertEqual(self.machine.game.player_list[0].mode_with_timers2_timer_start_with_game_tick, 4)\n+ self.assertEqual(self.machine.game.player_list[1].mode_with_timers2_timer_start_with_game_tick, 2)\n+ self.advance_time_and_run(1)\n+ self.assertEqual(self.machine.game.player_list[0].mode_with_timers2_timer_start_with_game_tick, 4)\n+ self.assertEqual(self.machine.game.player_list[1].mode_with_timers2_timer_start_with_game_tick, 3)\n+ self.advance_time_and_run(1)\n+ self.assertEqual(self.machine.game.player_list[0].mode_with_timers2_timer_start_with_game_tick, 4)\n+ self.assertEqual(self.machine.game.player_list[1].mode_with_timers2_timer_start_with_game_tick, 4)\n+ self.advance_time_and_run(1)\n+ self.assertEqual(self.machine.game.player_list[0].mode_with_timers2_timer_start_with_game_tick, 4)\n+ self.assertEqual(self.machine.game.player_list[1].mode_with_timers2_timer_start_with_game_tick, 5)\n",
        "chatgpt_cot": "\"Add logic to wait for workers to be destroyed and start the fight, and fix attack positions for units in simulate_fight_scenario.py\""
    },
    {
        "org_diff": "diff --git a/sc2/position.py b/sc2/position.py @@ -32,6 +32,9 @@ class Pointlike(tuple):\ndef closest(self, ps):\nreturn min(ps, key=lambda p: self.distance_to(p))\n+ def furthest(self, ps):\n+ return max(ps, key=lambda p: self.distance_to(p))\n+\ndef offset(self, p):\nreturn self.__class__(a+b for a, b in itertools.zip_longest(self, p[:len(self)], fillvalue=0))\n",
        "org_msg": "Add furthest away method",
        "sim_msg": "Fix score indexes pt 2",
        "sim_diff": "diff --git a/objects/score.py b/objects/score.py @@ -266,7 +266,7 @@ class Score:\ns.n300, s.n100, s.n50, s.ngeki, s.nkatu, s.nmiss, s.score, s.max_combo = map(\nint,\n- data[1:8],\n+ data[1:9],\n)\ns.perfect = data[9] == \"True\"\n",
        "chatgpt_cot": "Add method furthest to Pointlike class to find the furthest point from a list of points."
    },
    {
        "org_diff": "diff --git a/examples/protoss/warpgate_push.py b/examples/protoss/warpgate_push.py @@ -14,6 +14,20 @@ class WarpGateBot(sc2.BotAI):\ndef select_target(self, state):\nreturn self.enemy_start_locations[0]\n+ async def warp_new_units(self, proxy):\n+ for warpgate in self.units(WARPGATE).ready:\n+ abilities = await self.get_available_abilities(warpgate)\n+ # all the units have the same cooldown anyway so let's just look at ZEALOT\n+ if AbilityId.WARPGATETRAIN_ZEALOT in abilities:\n+ pos = proxy.position.to2.random_on_distance(4)\n+ placement = await self.find_placement(AbilityId.WARPGATETRAIN_STALKER, pos, placement_step=1)\n+ if placement is None:\n+ #return ActionResult.CantFindPlacementLocation\n+ print(\"can't place\")\n+ return\n+ await self.do(warpgate.warp_in(STALKER, placement))\n+\n+\nasync def on_step(self, iteration):\nawait self.distribute_workers()\n@@ -72,19 +86,10 @@ class WarpGateBot(sc2.BotAI):\nawait self.do(gateway(MORPH_WARPGATE))\nif self.proxy_built:\n- for warpgate in self.units(WARPGATE).ready:\n- abilities = await self.get_available_abilities(warpgate)\n- # all the units have the same cooldown anyway so let's just look at ZEALOT\n- if AbilityId.WARPGATETRAIN_ZEALOT in abilities:\n- placement = await self.find_placement(AbilityId.WARPGATETRAIN_STALKER, proxy.position.to2, placement_step=1)\n- if placement is None:\n- #return ActionResult.CantFindPlacementLocation\n- print(\"can't place\")\n- break\n- await self.do(warpgate.warp_in(STALKER, placement))\n+ await self.warp_new_units(proxy)\nif self.units(STALKER).amount > 3:\n- for vr in self.units(STALKER).idle:\n+ for vr in self.units(STALKER).ready.idle:\nawait self.do(vr.attack(self.select_target(self.state)))\nif self.units(CYBERNETICSCORE).amount >= 1 and not self.proxy_built and self.can_afford(PYLON):\n",
        "org_msg": "Speed up warpgate example a bit",
        "sim_msg": "properly lock antiraid to mod+",
        "sim_diff": "diff --git a/GearBot/Cogs/AntiRaid.py b/GearBot/Cogs/AntiRaid.py @@ -16,7 +16,7 @@ class AntiRaid(BaseCog):\nsuper().__init__(bot, {\n\"min\": 2,\n\"max\": 6,\n- \"required\": 0,\n+ \"required\": 2,\n\"commands\": {}\n})\nself.raid_trackers = dict()\n@@ -99,13 +99,14 @@ class AntiRaid(BaseCog):\nGearbotLogging.log_key(member.guild.id, 'raid_new', raid_id=raid.id)\n# create trackers if needed\nraider_ids = dict()\n+ terminator = self.bot.loop.create_task(self.terminator(member.guild.id))\n+ self.raid_trackers[member.guild.id] = dict(raid_id=raid.id, SHIELDS=dict(), raider_ids=raider_ids,\n+ triggered=set(), terminator=terminator, timers=[])\nfor raider in buckets[shield[\"id\"]]:\nif member.guild.id not in self.raid_trackers or member.id not in self.raid_trackers[member.guild.id][\"raider_ids\"]:\nr = Raider.create(raid=raid, user_id=raider.id, joined_at=raider.joined_at)\nraider_ids[member.id] = r.id\n- self.raid_trackers[member.guild.id] = dict(raid_id=raid.id, SHIELDS=dict(), raider_ids=raider_ids, triggered=set())\n-\n# assign the handler and call execute initial actions\nh = RaidShield(shield)\nself.raid_trackers[member.guild.id][\"SHIELDS\"][shield[\"id\"]] = h\n@@ -113,14 +114,25 @@ class AntiRaid(BaseCog):\nawait h.raid_detected(self.bot, member.guild, self.raid_trackers[member.guild.id][\"raid_id\"], self.raid_trackers[member.guild.id][\"raider_ids\"], shield)\n# create background terminator\n- self.bot.loop.create_task(\n+ timer = self.bot.loop.create_task(\nself.timers[shield[\"duration\"][\"type\"]](member.guild.id, h, shield, shield[\"duration\"]))\n+ self.raid_trackers[member.guild.id][\"timers\"].append(timer)\n# deal with them\nfor raider in buckets[shield[\"id\"]]:\nawait h.handle_raider(self.bot, raider, self.raid_trackers[member.guild.id][\"raid_id\"], self.raid_trackers[member.guild.id][\"raider_ids\"], shield)\n+ async def terminator(self, guild_id):\n+ await asyncio.sleep(10*60)\n+ if guild_id in self.raid_trackers:\n+ GearbotLogging.log_key(guild_id, \"raid_timelimit_exceeded\")\n+ info = self.raid_trackers[guild_id]\n+ del self.raid_trackers[self.raid_trackers]\n+ for t in info[\"timers\"]:\n+ t.cancel()\n+\n+\nasync def fixed_time(self, guild_id, handler, shield, data):\nawait asyncio.sleep(data[\"time\"])\n@@ -149,6 +161,7 @@ class AntiRaid(BaseCog):\nawait handler.shield_terminated(self.bot, self.bot.get_guild(guild_id), self.raid_trackers[guild_id][\"raid_id\"], self.raid_trackers[guild_id][\"raider_ids\"], shield)\nif len(self.raid_trackers[guild_id][\"SHIELDS\"]) == 0:\nGearbotLogging.log_key(guild_id, 'raid_terminated', raid_id=self.raid_trackers[guild_id]['raid_id'])\n+ self.raid_trackers[guild_id][\"terminator\"].cancel()\ndel self.raid_trackers[guild_id]\n",
        "chatgpt_cot": "Add async warp_new_units method to WarpGateBot for warping in Stalker units, improving unit production efficiency and combat effectiveness in SC2."
    },
    {
        "org_diff": "diff --git a/README.md b/README.md @@ -122,8 +122,6 @@ The API supports a number of options for configuring how it operates.\n### `unit_command_uses_self_do`\nSet this to 'True' if your bot is issueing commands using `self.do(Unit(Ability, Target))` instead of `Unit(Ability, Target)`.\n```python\n-from sc2.bot_ai import BotAI\n-\nclass MyBot(BotAI):\ndef __init__(self):\nself.unit_command_uses_self_do = True\n@@ -132,8 +130,6 @@ class MyBot(BotAI):\n### `raw_affects_selection`\nSetting this to true improves bot performance by a little bit.\n```python\n-from sc2.bot_ai import BotAI\n-\nclass MyBot(BotAI):\ndef __init__(self):\nself.raw_affects_selection = True\n@@ -145,8 +141,6 @@ The distance calculation method:\n- 1 for scipy pdist\n- 2 for scipy cdist\n```python\n-from sc2.bot_ai import BotAI\n-\nclass MyBot(BotAI):\ndef __init__(self):\nself.distance_calculation_method: int = 2\n@@ -156,8 +150,6 @@ class MyBot(BotAI):\nOn game start or in any frame actually, you can set the game step. This controls how often your bot's `step` method is called.\n__Do not set this in the \\_\\_init\\_\\_ function as the client will not have been initialized yet!__\n```python\n-from sc2.bot_ai import BotAI\n-\nclass MyBot(BotAI):\ndef __init__(self):\npass # don't set it here!\n",
        "org_msg": "Removed imports from minor examples",
        "sim_msg": "[ping] update cooldown",
        "sim_diff": "diff --git a/customping/customping.py b/customping/customping.py @@ -32,7 +32,7 @@ class CustomPing(commands.Cog):\nself.bot.add_command(old_ping)\n@checks.bot_has_permissions(embed_links=True)\n- @commands.cooldown(5, 5, commands.BucketType.user)\n+ @commands.cooldown(2, 5, commands.BucketType.user)\n@commands.group(invoke_without_command=True)\nasync def ping(self, ctx):\n\"\"\"Ping the bot...\"\"\"\n",
        "chatgpt_cot": "Refactor initialization settings in MyBot class to improve performance and readability."
    },
    {
        "org_diff": "diff --git a/examples/terran/ramp_wall.py b/examples/terran/ramp_wall.py @@ -85,18 +85,13 @@ class RampWallBot(sc2.BotAI):\nasync def on_building_construction_complete(self, unit: Unit):\nprint(f\"Construction of building {unit} completed at {unit.position}.\")\n- def terrain_to_z_height(self, h):\n- # Required for drawing ramp points\n- return round(16 * h / 255, 2)\n-\ndef draw_ramp_points(self):\nfor ramp in self.game_info.map_ramps:\nfor p in ramp.points:\n- h = self.get_terrain_height(p)\n- h2 = self.terrain_to_z_height(h)\n+ h2 = self.get_terrain_z_height(p)\npos = Point3((p.x, p.y, h2))\n- p0 = Point3((pos.x - 0.25, pos.y - 0.25, pos.z))\n- p1 = Point3((pos.x + 0.25, pos.y + 0.25, pos.z - 0.5))\n+ p0 = Point3((pos.x - 0.25, pos.y - 0.25, pos.z + 0.25))\n+ p1 = Point3((pos.x + 0.25, pos.y + 0.25, pos.z - 0.25))\n# print(f\"Drawing {p0} to {p1}\")\ncolor = Point3((255, 0, 0))\nif p in ramp.upper:\n@@ -118,22 +113,20 @@ class RampWallBot(sc2.BotAI):\nif not (map_area.y <= b < map_area.y + map_area.height):\ncontinue\np = Point2((a, b))\n- h = self.get_terrain_height(p)\n- h2 = self.terrain_to_z_height(h)\n+ h2 = self.get_terrain_z_height(p)\npos = Point3((p.x, p.y, h2))\n- p0 = Point3((pos.x - 0.25, pos.y - 0.25, pos.z))\n- p1 = Point3((pos.x + 0.25, pos.y + 0.25, pos.z - 0.5))\n+ p0 = Point3((pos.x - 0.25, pos.y - 0.25, pos.z + 0.25))\n+ p1 = Point3((pos.x + 0.25, pos.y + 0.25, pos.z - 0.25))\n# print(f\"Drawing {p0} to {p1}\")\ncolor = Point3((255, 0, 0))\nself._client.debug_box_out(p0, p1, color=color)\ndef draw_vision_blockers(self):\nfor p in self.game_info.vision_blockers:\n- h = self.get_terrain_height(p)\n- h2 = self.terrain_to_z_height(h)\n+ h2 = self.get_terrain_z_height(p)\npos = Point3((p.x, p.y, h2))\n- p0 = Point3((pos.x - 0.25, pos.y - 0.25, pos.z))\n- p1 = Point3((pos.x + 0.25, pos.y + 0.25, pos.z - 0.5))\n+ p0 = Point3((pos.x - 0.25, pos.y - 0.25, pos.z + 0.25))\n+ p1 = Point3((pos.x + 0.25, pos.y + 0.25, pos.z - 0.25))\n# print(f\"Drawing {p0} to {p1}\")\ncolor = Point3((255, 0, 0))\nself._client.debug_box_out(p0, p1, color=color)\n",
        "org_msg": "Make ramp_wall bot use bot_ai.get_terrain_z_height()",
        "sim_msg": "Added tests for distances and distances_indices_sorted functions.",
        "sim_diff": "diff --git a/pymatgen/analysis/chemenv/utils/tests/test_coordination_geometry_utils.py b/pymatgen/analysis/chemenv/utils/tests/test_coordination_geometry_utils.py @@ -214,6 +214,40 @@ class PlanesUtilsTest(PymatgenTest):\nself.assertEqual(sep[1], [3, 5])\nself.assertEqual(sep[2], [4, 7])\n+ def test_distances(self):\n+ # Test with the common test plane\n+ point_1 = np.array([0.0, 0.0, 0.0], np.float)\n+ point_2 = np.array([0.0, 0.0, 0.75], np.float)\n+ point_3 = np.array([-0.75, 0.0, 0.0], np.float)\n+ point_4 = np.array([1.0, 0.0, 0.0], np.float)\n+ point_5 = np.array([0.0, -1.5, 0.0], np.float)\n+ point_6 = np.array([10.0, 2.0, -20.0], np.float)\n+ point_7 = np.array([10.0, 10.0, 10.0], np.float)\n+ point_8 = np.array([100.0, 0.0, 0.0], np.float)\n+ plist = [point_1, point_2, point_4, point_6, point_7, point_8]\n+ distances, indices_sorted = self.plane.distances_indices_sorted(plist)\n+ self.assertArrayAlmostEqual(distances, [0.5, 0.0, 1.16666666666666,\n+ 21.1666666666666, 3.8333333333333, 67.1666666666666])\n+ self.assertArrayEqual(indices_sorted, [1, 0, 2, 4, 3, 5])\n+ # Plane 2y+1=0 (perpendicular to y)\n+ plane = Plane.from_coefficients(0, 2, 0, 1)\n+ plist = [point_1, point_5, point_6, point_7]\n+ distances, indices_sorted = plane.distances_indices_sorted(plist)\n+ self.assertArrayAlmostEqual(distances, [0.5, -1.0, 2.5, 10.5])\n+ self.assertArrayEqual(indices_sorted, [0, 1, 2, 3])\n+ plist = [point_1, point_5, point_6, point_7]\n+ distances, indices_sorted = plane.distances_indices_sorted(plist)\n+ self.assertArrayAlmostEqual(distances, [0.5, -1.0, 2.5, 10.5])\n+ self.assertArrayEqual(indices_sorted, [0, 1, 2, 3])\n+ plist = [point_5, point_1, point_6, point_7]\n+ distances, indices_sorted = plane.distances_indices_sorted(plist)\n+ self.assertArrayAlmostEqual(distances, [-1.0, 0.5, 2.5, 10.5])\n+ self.assertArrayEqual(indices_sorted, [1, 0, 2, 3])\n+ plist = [point_1, point_2, point_3, point_4, point_5, point_6, point_7, point_8]\n+ distances, indices_sorted = plane.distances_indices_sorted(plist)\n+ self.assertArrayAlmostEqual(distances, [0.5, 0.5, 0.5, 0.5, -1.0, 2.5, 10.5, 0.5])\n+ self.assertEqual(set(indices_sorted[:5]), {0, 1, 2, 3, 7})\n+\ndef test_projections(self):\n#Projections of points that are already on the plane\nexpected_projected_points = [self.p1, self.p2, self.p3, self.plane.p1, self.plane.p2, self.plane.p3]\n@@ -262,4 +296,13 @@ class PlanesUtilsTest(PymatgenTest):\nif __name__ == \"__main__\":\n+ # p1 = np.array([0.0, 0.0, 0.0])\n+ # p2 = np.array([-0.75, 3.0, 2.0])\n+ # p3 = np.array([1.0, -1.5, 2.0])\n+ # plane = Plane.from_3points(p1, p2, p3)\n+ # print(plane.distances([[0.0, 0.0, 0.0], [0.0, 0.0, 0.75], [0.0, 0.0, -0.75], [0.2, -0.3, 0.75], [-0.2, 0.3, -0.75]]))\n+ # print(plane.distances_indices_sorted([[0.0, 0.0, 0.0], [0.0, 0.0, 0.75], [0.0, 0.0, -0.75], [0.2, -0.3, 0.75], [-0.2, 0.3, -0.75]]))\n+ # print(plane.normal_vector)\n+ # print(plane.d)\n+ # exit()\nunittest.main()\n",
        "chatgpt_cot": "Refactor terrain_to_z_height method and update method calls to get_terrain_z_height. This improves consistency and readability of the code in ramp_wall.py."
    },
    {
        "org_diff": "diff --git a/src/api-engine/api/lib/peer/channel.py b/src/api-engine/api/lib/peer/channel.py import os\n+import json\nfrom api.lib.peer.basicEnv import BasicEnv\nfrom api.config import FABRIC_TOOL\n@@ -33,11 +34,12 @@ class Channel(BasicEnv):\nres = os.system(\"{} channel list > ./list.txt\".format(self.peer))\nwith open('./list.txt', 'r', encoding='utf-8') as f:\ncontent = f.read()\n- res = res >> 8\n+ content = content.split(\"\\n\")\n+ os.system(\"rm ./list.txt\")\nexcept Exception as e:\nerr_msg = \"get channel list failed for {}!\".format(e)\nraise Exception(err_msg)\n- return res, content\n+ return res, content[1:-1]\ndef update(self, channel, channel_tx, orderer_url):\n\"\"\"\n@@ -121,9 +123,13 @@ class Channel(BasicEnv):\n)\nwith open('./getinfo.txt', 'r', encoding='utf-8') as f:\ncontent = f.read()\n+ content = content.split(\"\\n\")[0].split(\":\", 1)[1]\n+ os.system(\"rm ./getinfo.txt\")\n+ block_info = json.loads(content)\n+ body = {\"block_info\": block_info}\nexcept Exception as e:\nerr_msg = \"get blockchain information of a specified channel failed. {}\".format(\ne)\nraise Exception(err_msg)\nres = res >> 8\n- return res, content\n+ return res, body\n",
        "org_msg": "[#issue-313] cmdline lib function list and getinfo has no info return\ncmdline lib function list and getinfo has no info return\nClose #issue-313",
        "sim_msg": "Create Channel Streams Endpoint",
        "sim_diff": "diff --git a/blueprints/apis/channel_ns.py b/blueprints/apis/channel_ns.py @@ -12,11 +12,13 @@ from classes import Sec\nfrom classes import topics\nfrom classes import invites\nfrom classes import views\n+from classes import Stream\nfrom classes.shared import db\nfrom functions import system\nfrom functions import cachedDbCalls\nfrom functions import channelFunc\n+from functions import templateFilters\nfrom globals import globalvars\n@@ -197,6 +199,47 @@ class api_1_ListChannel(Resource):\nreturn {'results': {'message': 'Channel Deleted'}}, 200\nreturn {'results': {'message': 'Request Error'}}, 400\n+# Invites Endpoint for a Channel\n+@api.route('/<string:channelEndpointID>/streams')\n+@api.doc(params={'channelEndpointID': 'GUID Channel Location'})\n+class api_1_Streams(Resource):\n+ @api.doc(responses={200: 'Success', 400: 'Request Error'})\n+ def get(self, channelEndpointID):\n+ \"\"\"\n+ Returns list of active streams on a channel\n+ \"\"\"\n+ sysSettings = cachedDbCalls.getSystemSettings()\n+ channelIDQuery = cachedDbCalls.getChannelIDFromLocation(channelEndpointID)\n+\n+ if channelIDQuery is not None:\n+ StreamQuery = Stream.Stream.query.filter_by(linkedChannel=channelIDQuery, active=True, complete=False)\\\n+ .with_entities(Stream.Stream.id, Stream.Stream.topic, Stream.Stream.streamName, Stream.Stream.startTimestamp, Stream.Stream.uuid, Stream.Stream.currentViewers,\n+ Stream.Stream.totalViewers).all()\n+\n+ results = []\n+ if sysSettings.adaptiveStreaming is True:\n+ streamURL = '/live-adapt/' + channelEndpointID + '.m3u8'\n+ else:\n+ streamURL = '/live/' + channelEndpointID + '/index.m3u8'\n+ for entry in StreamQuery:\n+ results.append(\n+ {\n+ 'id': entry.id,\n+ 'uuid': entry.uuid,\n+ 'topic': entry.topic,\n+ 'streamName': entry.streamName,\n+ 'startTimestamp': entry.startTimestamp,\n+ 'currentViewers': entry.currentViewers,\n+ 'totalViewers': entry.totalViewers,\n+ 'streamURL': streamURL\n+ })\n+ db.session.commit()\n+ return {'results': results}\n+\n+ db.session.commit()\n+ return {'results': {'message': 'Request Error'}}, 400\n+\n+\n# TODO Add Ability to Add/Delete/Change\n@api.route('/<string:channelEndpointID>/restreams')\n",
        "chatgpt_cot": "Refactored Channel class in channel.py, split content for better parsing, added json parsing for block info. Fixes compilation and parsing issues in blockchain information retrieval."
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/master_view_proxy.py b/node_manager_fkie/src/node_manager_fkie/master_view_proxy.py @@ -205,7 +205,8 @@ class MasterViewProxy(QWidget):\nself.node_tree_model.hostInserted.connect(self.on_host_inserted)\nfor i, (_, width) in enumerate(NodeTreeModel.header): # _:=name\nself.masterTab.nodeTreeView.setColumnWidth(i, width)\n- self.nodeNameDelegate = HTMLDelegate(dec_ascent=True, is_node=True)\n+ check_for_ros_names = not nm.settings().group_nodes_by_namespace\n+ self.nodeNameDelegate = HTMLDelegate(check_for_ros_names=check_for_ros_names, dec_ascent=True, is_node=True)\nself.masterTab.nodeTreeView.setItemDelegateForColumn(0, self.nodeNameDelegate)\nself.node_delegate = IconsDelegate()\nself.masterTab.nodeTreeView.setItemDelegateForColumn(1, self.node_delegate)\n",
        "org_msg": "node_manager_fkie: disable check for legal ros names if group by namespace is active",
        "sim_msg": "improve tree behaviour",
        "sim_diff": "diff --git a/tree.py b/tree.py @@ -755,11 +755,15 @@ class WidgetTree(wx.TreeCtrl, Tree):\nself.SetItemTextColour(item, wx.NullColour)\nself.SetItemBold( item, False )\nself.cur_widget = widget\n- if wx.Platform == \"__WXMSW__\":\nitem = widget.node.item\n+ self.EnsureVisible(item)\n+ # ensure that the icon is visible\n+ text_rect = self.GetBoundingRect(item, True)\n+ if text_rect.x<22:\n+ self.SetScrollPos(wx.HORIZONTAL, self.GetScrollPos(wx.HORIZONTAL) - 22 + text_rect.x)\n+ if wx.Platform == \"__WXMSW__\":\nself.SetItemBold(item, True)\nself.SetItemTextColour(item, wx.BLUE)\n-\ndef set_current_widget(self, widget):\n# interface from common.set_focused_widget\nif widget is None or widget is self.cur_widget: return\n@@ -904,8 +908,7 @@ class WidgetTree(wx.TreeCtrl, Tree):\nelse:\nnode.widget.widget.GetParent().Show()\n- misc.set_focused_widget(node.widget)\n-\n+ #misc.set_focused_widget(node.widget)\nnode.widget.widget.Raise()\n# set the best size for the widget (if no one is given)\nprops = node.widget.properties\n@@ -957,8 +960,8 @@ class WidgetTree(wx.TreeCtrl, Tree):\ntoplevel_widget.GetTopLevelParent().Hide()\n# added by rlawson to collapse only the toplevel node, not collapse back to root node\n- self.select_item(node)\n- misc.set_focused_widget(node.widget)\n+ #self.select_item(node)\n+ #misc.set_focused_widget(node.widget)\nif event: event.Skip()\nif \"design\" in node.widget.properties: node.widget.design.update_label()\n@@ -1096,6 +1099,7 @@ class WidgetTree(wx.TreeCtrl, Tree):\nnode = self._GetItemData(itemok)\nif parent is not None:\nself._show_widget_toplevel(parent)\n+ common.app_tree.expand(parent)\nif pos is not None:\nmisc.get_toplevel_parent(parent.widget).SetPosition(pos)\nself.select_item(node)\n",
        "chatgpt_cot": "Refactor HTMLDelegate instantiation in MasterViewProxy to check for ROS names, improving flexibility and readability."
    },
    {
        "org_diff": "diff --git a/sc2/bot_ai.py b/sc2/bot_ai.py @@ -175,9 +175,11 @@ class BotAI(object):\nexpansion_locations = self.expansion_locations\nowned_expansions = self.owned_expansions\nworker_pool = []\n+ actions = []\n+\nfor idle_worker in self.workers.idle:\nmf = self.state.mineral_field.closest_to(idle_worker)\n- await self.do(idle_worker.gather(mf))\n+ actions.append(idle_worker.gather(mf))\nfor location, townhall in owned_expansions.items():\nworkers = self.workers.closer_than(20, location)\n@@ -205,10 +207,10 @@ class BotAI(object):\nif worker_pool:\nw = worker_pool.pop()\nif len(w.orders) == 1 and w.orders[0].ability.id in [AbilityId.HARVEST_RETURN]:\n- await self.do(w.move(g))\n- await self.do(w.return_resource(queue=True))\n+ actions.push(w.move(g))\n+ actions.push(w.return_resource(queue=True))\nelse:\n- await self.do(w.gather(g))\n+ actions.push(w.gather(g))\nfor location, townhall in owned_expansions.items():\nactual = townhall.assigned_harvesters\n@@ -220,11 +222,13 @@ class BotAI(object):\nw = worker_pool.pop()\nmf = self.state.mineral_field.closest_to(townhall)\nif len(w.orders) == 1 and w.orders[0].ability.id in [AbilityId.HARVEST_RETURN]:\n- await self.do(w.move(townhall))\n- await self.do(w.return_resource(queue=True))\n- await self.do(w.gather(mf, queue=True))\n+ actions.push(w.move(townhall))\n+ actions.push(w.return_resource(queue=True))\n+ actions.push(w.gather(mf, queue=True))\nelse:\n- await self.do(w.gather(mf))\n+ actions.push(w.gather(mf))\n+\n+ await self.do_actions(actions)\n@property\ndef owned_expansions(self):\n",
        "org_msg": "Build a list of actions in distribute_workers\nWith short step time limits, doing all these actions one by one with\n`do` is too slow. This attempt tries to fix it by building a single list\nof actions and executing them all at once with `do_actions`.",
        "sim_msg": "Improve the worker cross-registration to remove warnings",
        "sim_diff": "diff --git a/syft/workers/base.py b/syft/workers/base.py @@ -69,14 +69,18 @@ class BaseWorker(AbstractWorker):\n# A core object in every BaseWorker instantiation. A Collection of\n# objects where all objects are stored using their IDs as keys.\nself._objects = {}\n+\n+ # Declare workers as appropriate\nself._known_workers = {}\nif hook.local_worker is not None:\n- for k, v in hook.local_worker._known_workers.items():\n- if v is not hook.local_worker:\n- self._known_workers[k] = v\n- v.add_worker(self)\n+ if self.id not in self.hook.local_worker._known_workers:\nhook.local_worker.add_worker(self)\n- self.add_worker(self)\n+ for worker_id, worker in hook.local_worker._known_workers.items():\n+ if worker_id not in self._known_workers:\n+ self.add_worker(worker)\n+ if self.id not in worker._known_workers:\n+ worker.add_worker(self)\n+\n# For performance, we cache each\nself._message_router = {\nMSGTYPE.CMD: self.execute_command,\n",
        "chatgpt_cot": "Add actions list and replace await self.do with actions.push. Fix compilation issue in BotAI."
    },
    {
        "org_diff": "diff --git a/src/api-engine/api/routes/network/views.py b/src/api-engine/api/routes/network/views.py @@ -76,7 +76,7 @@ HTTP_201_CREATED\nserializer = NetworkQuery(data=request.GET)\nif serializer.is_valid(raise_exception=True):\npage = serializer.validated_data.get(\"page\", 1)\n- per_page = serializer.validated_data.ger_page\", 10)\n+ per_page = serializer.validated_data.get(\"page\", 10)\nname = serializer.validated_data.get(\"name\")\nparameters = {}\nif name:\n",
        "org_msg": "Fix api-engine syntax error\nIt supposes to be `serializer.validated_data.get(\"page\", 10)`",
        "sim_msg": "api3: Making the autocomplete method use get parameters",
        "sim_diff": "diff --git a/app/views/api3.py b/app/views/api3.py @@ -770,9 +770,9 @@ def create_post():\nreturn jsonify(status='ok', pid=post.pid, sub=sub.name)\n-@API.route('/search/sub/<query>', methods=['GET'])\n-@cache.memoize(300)\n-def search_sub(query):\n+@API.route('/search/sub', methods=['GET'])\n+def search_sub():\n+ query = request.args.get('query', '')\nif len(query) < 3 or not misc.allowedNames.match(query):\nreturn jsonify(results=[])\n",
        "chatgpt_cot": "Fix typo in views.py for per_page parameter assignment. The modification corrects the typo in the code and ensures proper assignment of the per_page parameter."
    },
    {
        "org_diff": "diff --git a/test/autotest_bot.py b/test/autotest_bot.py @@ -251,20 +251,22 @@ class TestBot(sc2.BotAI):\n# Test unit.py\nasync def test_unit(self):\n- scv = self.workers.random\n-\n- assert scv.type_id == UnitTypeId.SCV\n- assert scv._type_data == self._game_data.units[UnitTypeId.SCV.value]\n- assert scv.alliance == Alliance.Self.value\n- assert scv.is_mine == True\n- assert isinstance(scv.position, Point2)\n- assert isinstance(scv.position3d, Point3)\n- assert scv.health == 45\n- assert scv.health_max == 45\n- assert scv.health_percentage == 45/45\n- assert scv.energy == 0\n- assert scv.energy_max == 0\n- assert scv.energy_percentage == 0\n+ scv1, scv2, scv3 = self.workers[:3]\n+\n+ assert scv1.type_id == UnitTypeId.SCV\n+ assert scv1._type_data == self._game_data.units[UnitTypeId.SCV.value]\n+ assert scv1.alliance == Alliance.Self.value\n+ assert scv1.is_mine == True\n+ assert isinstance(scv1.position, Point2)\n+ assert isinstance(scv1.position3d, Point3)\n+ assert scv1.health == 45\n+ assert scv1.health_max == 45\n+ assert scv1.health_percentage == 45/45\n+ assert scv1.energy == 0\n+ assert scv1.energy_max == 0\n+ assert scv1.energy_percentage == 0\n+ assert not scv1.target_in_range(self.workers.tags_not_in({scv1.tag}).furthest_to(scv1.position))\n+ assert scv1.target_in_range(scv1)\n# Test units.py\nasync def test_units(self):\n",
        "org_msg": "Add target_in_range test",
        "sim_msg": "QChem: CMIRS and ISOSVP tests for SinglePointSet",
        "sim_diff": "diff --git a/pymatgen/io/qchem/tests/test_sets.py b/pymatgen/io/qchem/tests/test_sets.py @@ -519,6 +519,33 @@ class SinglePointSetTest(PymatgenTest):\nself.assertEqual(test_SPSet.solvent, {\"dielectric\": \"10.0\"})\nself.assertEqual(test_SPSet.molecule, test_molecule)\n+ def test_isosvp_init(self):\n+ test_molecule = QCInput.from_file(os.path.join(test_dir, \"new_qchem_files/pcm.qin\")).molecule\n+ test_SPSet = SinglePointSet(molecule=test_molecule, isosvp_dielectric=10.0)\n+ self.assertEqual(\n+ test_SPSet.rem,\n+ {\n+ \"job_type\": \"sp\",\n+ \"gen_scfman\": \"true\",\n+ \"basis\": \"def2-tzvppd\",\n+ \"max_scf_cycles\": \"100\",\n+ \"method\": \"wb97xd\",\n+ \"scf_algorithm\": \"diis\",\n+ \"xc_grid\": \"3\",\n+ \"thresh\": \"14\",\n+ \"s2thresh\": \"16\",\n+ \"solvent_method\": \"isosvp\",\n+ \"symmetry\": \"false\",\n+ \"sym_ignore\": \"true\",\n+ \"resp_charges\": \"true\",\n+ },\n+ )\n+ self.assertEqual(\n+ test_SPSet.svp,\n+ {\"dielst\": \"10.0\", \"rhoiso\": \"0.001\", \"nptleb\": \"1202\", \"itrngr\": \"2\", \"irotgr\": \"2\"},\n+ )\n+ self.assertEqual(test_SPSet.molecule, test_molecule)\n+\ndef test_smd_init(self):\ntest_molecule = QCInput.from_file(os.path.join(test_dir, \"new_qchem_files/pcm.qin\")).molecule\ntest_SPSet = SinglePointSet(molecule=test_molecule, smd_solvent=\"water\")\n@@ -544,6 +571,48 @@ class SinglePointSetTest(PymatgenTest):\nself.assertEqual(test_SPSet.smx, {\"solvent\": \"water\"})\nself.assertEqual(test_SPSet.molecule, test_molecule)\n+ def test_cmirs_init(self):\n+ test_molecule = QCInput.from_file(os.path.join(test_dir, \"new_qchem_files/pcm.qin\")).molecule\n+ test_SPSet = SinglePointSet(\n+ molecule=test_molecule, cmirs_solvent=\"benzene\", overwrite_inputs={\"svp\": {\"RHOISO\": 0.0005}}\n+ )\n+ self.assertEqual(\n+ test_SPSet.rem,\n+ {\n+ \"job_type\": \"sp\",\n+ \"gen_scfman\": \"true\",\n+ \"basis\": \"def2-tzvppd\",\n+ \"max_scf_cycles\": \"100\",\n+ \"method\": \"wb97xd\",\n+ \"scf_algorithm\": \"diis\",\n+ \"xc_grid\": \"3\",\n+ \"thresh\": \"14\",\n+ \"s2thresh\": \"16\",\n+ \"solvent_method\": \"isosvp\",\n+ \"symmetry\": \"false\",\n+ \"sym_ignore\": \"true\",\n+ \"resp_charges\": \"true\",\n+ },\n+ )\n+ self.assertEqual(\n+ test_SPSet.svp,\n+ {\"dielst\": \"2.28\", \"rhoiso\": \"0.0005\", \"nptleb\": \"1202\", \"itrngr\": \"2\", \"irotgr\": \"2\", \"idefesr\": \"1\"},\n+ )\n+ self.assertEqual(\n+ test_SPSet.pcm_nonels,\n+ {\n+ \"a\": \"-0.00572\",\n+ \"b\": \"0.01116\",\n+ \"c\": None,\n+ \"d\": None,\n+ \"gamma\": None,\n+ \"solvrho\": \"0.0421\",\n+ \"gaulag_n\": \"40\",\n+ \"delta\": \"7\",\n+ },\n+ )\n+ self.assertEqual(test_SPSet.molecule, test_molecule)\n+\ndef test_plots_init(self):\ntest_molecule = QCInput.from_file(os.path.join(test_dir, \"new_qchem_files/pcm.qin\")).molecule\ntest_SPSet = SinglePointSet(molecule=test_molecule, smd_solvent=\"water\", plot_cubes=True)\n",
        "chatgpt_cot": "Refactor test_unit method to use multiple SCVs and add target_in_range check."
    },
    {
        "org_diff": "diff --git a/examples/competitive/bot.py b/examples/competitive/bot.py @@ -2,14 +2,14 @@ import sc2\nclass CompetitiveBot(sc2.BotAI):\n- async def on_step(self, iteration):\n- # Populate this function with whatever your bot should do!\n- pass\n-\nasync def on_start(self):\nprint(\"Game started\")\n# Do things here before the game starts\n+ async def on_step(self, iteration):\n+ # Populate this function with whatever your bot should do!\n+ pass\n+\ndef on_end(self, result):\nprint(\"Game ended.\")\n# Do things here after the game ends\n",
        "org_msg": "Reorder bot method definitions to mimic the order they will be called in.",
        "sim_msg": "[Hockey] Fix issue where sometimes a game will show incorrect standings data on previews",
        "sim_diff": "diff --git a/hockey/game.py b/hockey/game.py from __future__ import annotations\n+\nimport logging\nfrom datetime import datetime\n-from typing import Literal, Optional, List, Dict, Union, Tuple\n+from typing import Dict, List, Literal, Optional, Tuple, Union\nimport aiohttp\nimport discord\n@@ -12,7 +13,13 @@ from redbot.core.utils import AsyncIter, bounded_gather\nfrom .constants import BASE_URL, CONTENT_URL, TEAMS\nfrom .goal import Goal\n-from .helper import check_to_post, get_channel_obj, get_team, get_team_role, utc_to_local\n+from .helper import (\n+ check_to_post,\n+ get_channel_obj,\n+ get_team,\n+ get_team_role,\n+ utc_to_local,\n+)\nfrom .standings import Standings\n_ = Translator(\"Hockey\", __file__)\n@@ -423,7 +430,10 @@ class Game:\nstats, home_i = await Standings.get_team_standings(self.home_team)\nfor team in stats:\nif team.name == self.away_team:\n+ try:\nstreak = \"{} {}\".format(team.streak, streak_types[team.streak_type])\n+ except KeyError:\n+ streak = \"**0**\"\naway_str = msg.format(\nwins=team.wins,\nlosses=team.losses,\n@@ -433,7 +443,10 @@ class Game:\nstreak=streak,\n)\nif team.name == self.home_team:\n+ try:\nstreak = \"{} {}\".format(team.streak, streak_types[team.streak_type])\n+ except KeyError:\n+ streak = \"**0**\"\nhome_str = msg.format(\nwins=team.wins,\nlosses=team.losses,\n@@ -443,6 +456,7 @@ class Game:\nstreak=streak,\n)\nexcept Exception:\n+ log.exception(\"Error pulling stats\")\npass\nreturn home_str, away_str\n",
        "chatgpt_cot": "\"Add on_start method to CompetitiveBot class for pre-game actions and fix indentation in on_step method.\""
    },
    {
        "org_diff": "diff --git a/.travis.yml b/.travis.yml @@ -4,10 +4,10 @@ language: generic\nenv:\nmatrix:\n- ROS_DISTRO=\"indigo\" ROS_REPO=\"ros\"\n- - ROS_DISTRO=\"jade\" ROS_REPO=\"ros\"\n- ROS_DISTRO=\"kinetic\" ROS_REPO=\"ros-shadow-fixed\"\n- ROS_DISTRO=\"kinetic\" ROS_REPO=\"ros\"\n- - ROS_DISTRO=\"lunar\" ROS_REPO=\"ros\"\n+ - ROS_DISTRO=\"melodic\" ROS_REPO=\"ros-shadow-fixed\"\n+ - ROS_DISTRO=\"melodic\" ROS_REPO=\"ros\"\ninstall:\n- git clone https://github.com/ros-industrial/industrial_ci.git .ci_config\nscript:\n",
        "org_msg": "update travis targets",
        "sim_msg": "Run tests on Travis with Python 2.7.5 only",
        "sim_diff": "diff --git a/.travis.yml b/.travis.yml @@ -2,11 +2,6 @@ language: python\nmatrix:\ninclude:\n- # - os: linux\n- # sudo: required\n- # python: \"nightly\"\n- # env: TOXENV=pynightly\n- # deploy:\n- os: linux\nsudo: required\npython: \"3.6\"\n@@ -26,6 +21,37 @@ matrix:\npython: \"2.7\"\nenv: TOXENV=py27\ndeploy:\n+ - os: linux\n+ sudo: required\n+ language: generic # python 2.7.5\n+ before_install:\n+ # install python build deps\n+ - sudo apt-get install build-essential\n+ - sudo apt-get build-dep python2.7\n+ - sudo apt-get install libffi-dev libssl-dev libncurses5-dev libreadline-dev\n+ - cwd=$(pwd)\n+ # install python 2.7.5 from source\n+ - cd\n+ - wget http://python.org/ftp/python/2.7.5/Python-2.7.5.tgz\n+ - tar -xf Python-2.7.5.tgz\n+ - cd Python-2.7.5\n+ - ./configure --prefix=$HOME/python2.7.5\n+ - make\n+ - make install\n+ - export PATH=\"$HOME/python2.7.5/bin:$PATH\"\n+ # install pip\n+ - cd\n+ - wget https://bootstrap.pypa.io/get-pip.py\n+ - python get-pip.py\n+ - cd \"$cwd\"\n+ # fix InsecurePlatformWarning (possible only in pip 8.x)\n+ - pip install 'pip<9.0'\n+ - pip install pyopenssl ndg-httpsclient pyasn1\n+ # verify\n+ - python -V\n+ - pip --version\n+ # fix readline install (libreadline-dev version 6.3-8ubuntu2 needed not available on trusty/Travis)\n+ - pip install readline\n- os: osx\nlanguage: generic\nenv: TOXENV=py36\n",
        "chatgpt_cot": "Update ROS_DISTRO and ROS_REPO in .travis.yml to include melodic and remove lunar, fixing compatibility and dependency issues."
    },
    {
        "org_diff": "diff --git a/.github/workflows/pythonactions.yml b/.github/workflows/pythonactions.yml @@ -175,6 +175,7 @@ jobs:\n- name: Build docs from scratch\nrun: |\n+ mkdir docs\ncd docs_generate\npipenv run sphinx-build -a -E -b html . ../docs\ncd ..\n",
        "org_msg": "Add \"mkdir docs\" command",
        "sim_msg": "Update sphinx action: adding apidoc command",
        "sim_diff": "diff --git a/.github/workflows/build-sphinx-pages.yaml b/.github/workflows/build-sphinx-pages.yaml @@ -11,15 +11,27 @@ on:\njobs:\nbuild:\nruns-on: ubuntu-latest\n+\nsteps:\n+\n+ - name: Setup Python\n+ uses: actions/setup-python@v2\n+ with:\n+ python-version: '3.8'\n+\n- name: Checkout\nuses: actions/checkout@master\nwith:\nfetch-depth: 0 # otherwise, you will failed to push refs to dest repo\n+\n+ - name: Run Sphinx-apidoc first\n+ run: cd docs && sphinx-apidoc -f -o source/ ../fedn/fedn/\n+\n- name: Build and Commit\nuses: sphinx-notes/pages@master\nwith:\ndocumentation_path: docs/source\n+\n- name: Push changes\nuses: ad-m/github-push-action@master\nwith:\n",
        "chatgpt_cot": "Add step to create docs directory before generating documentation to fix build issue."
    },
    {
        "org_diff": "diff --git a/sc2/pixel_map.py b/sc2/pixel_map.py @@ -27,7 +27,7 @@ class PixelMap(object):\nassert 0 <= x < self.width\nassert 0 <= y < self.height\n- index = (self.height - self.width * y) + x\n+ index = (self.height - self.width * y) + x + (self.width - self.height)\nstart = index * self.bytes_per_pixel\ndata = self.data[start : start + self.bytes_per_pixel]\nreturn int.from_bytes(data, byteorder=\"little\", signed=False)\n",
        "org_msg": "Fix a bug for pixel map on non-square maps",
        "sim_msg": "Removed performance bottleneck: array data has accidentally been loaded into memory entirely",
        "sim_diff": "diff --git a/xcube/core/tile.py b/xcube/core/tile.py @@ -166,7 +166,7 @@ def new_color_mapped_image(ml_dataset,\nexception_type)\ncmap_name, cmap_range = get_var_cmap_params(var, cmap_name, cmap_range, valid_range)\ntile_grid = ml_dataset.tile_grid\n- image = ArrayImage(array.values,\n+ image = ArrayImage(array,\nimage_id=f'ai-{image_id}',\ntile_size=tile_grid.tile_size,\ntrace_perf=trace_perf)\n",
        "chatgpt_cot": "Fix calculation error in PixelMap index calculation to ensure correct mapping of pixel data in the file \"pixel_map.py\"."
    },
    {
        "org_diff": "diff --git a/node_manager_daemon_fkie/src/node_manager_daemon_fkie/launch_config.py b/node_manager_daemon_fkie/src/node_manager_daemon_fkie/launch_config.py @@ -174,6 +174,8 @@ class LaunchConfig(object):\n:raise LaunchConfigException: on load errors\n'''\ntry:\n+ self._capabilities = None\n+ self._robot_description = None\nroscfg = roslaunch.ROSLaunchConfig()\nloader = roslaunch.XmlLoader()\nself.argv = self.resolve_args(argv)\n",
        "org_msg": "node_manager_fkie: fixed multiple nodes after change node name and reload config",
        "sim_msg": "retry startup",
        "sim_diff": "diff --git a/lbrynet/lbrynet_daemon/DaemonControl.py b/lbrynet/lbrynet_daemon/DaemonControl.py @@ -114,7 +114,7 @@ def update_settings_from_args(args):\n@defer.inlineCallbacks\n-def start_server_and_listen(launchui, use_auth, analytics_manager):\n+def start_server_and_listen(launchui, use_auth, analytics_manager, max_tries=5):\n\"\"\"The primary entry point for launching the daemon.\nArgs:\n@@ -124,13 +124,19 @@ def start_server_and_listen(launchui, use_auth, analytics_manager):\n\"\"\"\nanalytics_manager.send_server_startup()\nlog_support.configure_analytics_handler(analytics_manager)\n+ tries = 1\n+ while tries < max_tries:\n+ log.info('Making attempt %s / %s to startup', tries, max_tries)\ntry:\ndaemon_server = DaemonServer(analytics_manager)\nyield daemon_server.start(use_auth, launchui)\nanalytics_manager.send_server_startup_success()\n+ break\nexcept Exception as e:\nlog.exception('Failed to startup')\nanalytics_manager.send_server_startup_error(str(e))\n+ tries += 1\n+ else:\nreactor.callFromThread(reactor.stop)\n",
        "chatgpt_cot": "\"Add new attributes for capabilities and robot description in LaunchConfig class\""
    },
    {
        "org_diff": "diff --git a/sc2/bot_ai.py b/sc2/bot_ai.py @@ -110,7 +110,7 @@ class BotAI(object):\nelse:\ncost = self._game_data.calculate_ability_cost(item_id)\n- return cost.minerals <= self.minerals and cost.vespene <= self.vespene\n+ return CanAffordWrapper(cost.minerals <= self.minerals, cost.vespene <= self.vespene)\ndef select_build_worker(self, pos, force=False):\nworkers = self.workers.closer_than(20, pos) or self.workers\n@@ -222,3 +222,22 @@ class BotAI(object):\nasync def on_step(self, iteration):\nraise NotImplementedError\n+\n+\n+class CanAffordWrapper(object):\n+\n+ def __init__(self, can_afford_minerals, can_afford_vespene):\n+ self.can_afford_minerals = can_afford_minerals\n+ self.can_afford_vespene = can_afford_vespene\n+\n+ def __bool__(self):\n+ return self.can_afford_minerals and self.can_afford_vespene\n+\n+ @property\n+ def action_result(self):\n+ if not self.can_afford_vespene:\n+ return ActionResult.NotEnoughVespene\n+ elif not self.can_afford_minerals:\n+ return ActionResult.NotEnoughMinerals\n+ else:\n+ return None\n",
        "org_msg": "`BotAI.can_afford` result wrapper\n* Add inline condition to prevent converting of 'None' to string for non-Windows platforms\n* Wrap cwd expression in parentheses\n* Wrap the response of `BotAI.can_afford` to return a wrapper\nFixes\n* Add `action_result` property to CanAffordWrapper",
        "sim_msg": "Fixes based on the PR comments",
        "sim_diff": "diff --git a/packages/fetchai/skills/tac_control_contract/game.py b/packages/fetchai/skills/tac_control_contract/game.py @@ -889,7 +889,7 @@ class Game(Model):\n+ \"\\n\"\n)\nfor good_id, quantity in agent_state.quantities_by_good_id.items():\n- result += \" \" + str(good_id) + \": \" + str(quantity) + \"\\n\"\n+ result += \" \" + good_id + \": \" + str(quantity) + \"\\n\"\nfor currency_id, amount in agent_state.amount_by_currency_id.items():\nresult += \" \" + currency_id + \": \" + str(amount) + \"\\n\"\nresult += \" score: \" + str(round(agent_state.get_score(), 2)) + \"\\n\"\n@@ -901,7 +901,7 @@ class Game(Model):\n\"\"\"Get equilibrium summary.\"\"\"\nresult = \"\\n\" + \"Equilibrium prices: \\n\"\nfor good_id, eq_price in self.initialization.good_id_to_eq_prices.items():\n- result = result + str(good_id) + \" \" + str(eq_price) + \"\\n\"\n+ result = result + good_id + \" \" + str(eq_price) + \"\\n\"\nresult = result + \"\\n\"\nresult = result + \"Equilibrium good allocation: \\n\"\nfor (\n@@ -915,7 +915,7 @@ class Game(Model):\n+ \":\\n\"\n)\nfor good_id, quantity in eq_allocations.items():\n- result = result + \" \" + str(good_id) + \": \" + str(quantity) + \"\\n\"\n+ result = result + \" \" + good_id + \": \" + str(quantity) + \"\\n\"\nresult = result + \"\\n\"\nresult = result + \"Equilibrium money allocation: \\n\"\nfor (\n",
        "chatgpt_cot": "Add CanAffordWrapper class to handle mineral and vespene affordablity checks in BotAI file. Fixes mineral and vespene affordablity logic."
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/editor/text_edit.py b/node_manager_fkie/src/node_manager_fkie/editor/text_edit.py @@ -387,7 +387,7 @@ class TextEdit(QTextEdit):\nlast_pos = res.rfind(\"- ->\")\nif last_pos > -1:\nres = \"%s-->\" % res[0:last_pos]\n- cursor.insertText(res)\n+ cursor.insertText(res.replace(\"--\", \"- - \"))\nelse: # other comments\nhash_re = re.compile(r\"# ?\")\nif do_comment:\n",
        "org_msg": "node_manager_fkie: editor: fixed unkomment of -- statements",
        "sim_msg": "Added confirmation request to close TT window when text has been changed (GTK)\nRelates to issue",
        "sim_diff": "diff --git a/extension/textext/asktext.py b/extension/textext/asktext.py @@ -196,7 +196,8 @@ class AskText(object):\nDEFAULT_INSERTSPACES = True\nDEFAULT_TABWIDTH = 4\nDEFAULT_NEW_NODE_CONTENT = \"Empty\"\n- DEFAULT_CLOSE_SHORTCUT = \"None\"\n+ DEFAULT_CLOSE_SHORTCUT = \"Escape\"\n+ DEFAULT_CONFIRM_CLOSE = True\nNEW_NODE_CONTENT = [\"Empty\", \"InlineMath\", \"DisplayMath\"]\nCLOSE_SHORTCUT = [\"Escape\", \"CtrlQ\", \"None\"]\n@@ -242,7 +243,7 @@ class AskText(object):\n@staticmethod\ndef cb_cancel(widget=None, data=None):\n\"\"\"Callback for Cancel button\"\"\"\n- raise SystemExit(1)\n+ pass\ndef cb_ok(self, widget=None, data=None):\n\"\"\"Callback for OK / Save button\"\"\"\n@@ -275,6 +276,11 @@ if TOOLKIT == TK:\nself._frame = None\nself._scale = None\n+ @staticmethod\n+ def cb_cancel(widget=None, data=None):\n+ \"\"\"Callback for Cancel button\"\"\"\n+ raise SystemExit(1)\n+\n@staticmethod\ndef validate_spinbox_input(d, i, P, s, S, v, V, W):\n\"\"\" Ensure that only floating point numbers are accepted as input of a Tk widget\n@@ -748,14 +754,28 @@ if TOOLKIT in (GTK, GTKSOURCEVIEW):\ngtk.main_quit()\nreturn False\n+ def cb_cancel(self, widget=None, data=None):\n+ \"\"\"Callback for Cancel button\"\"\"\n+ self.window_deleted_cb(widget, None, None)\n+\ndef move_cursor_cb(self, text_buffer, cursoriter, mark, view):\nself.update_position_label(text_buffer, view)\n- @staticmethod\n- def window_deleted_cb(widget, event, view):\n- gtk.main_quit()\n+ def window_deleted_cb(self, widget, event, view):\n+ if self._gui_config.get(\"confirm_close\", self.DEFAULT_CONFIRM_CLOSE) and \\\n+ self._source_buffer.get_text(self._source_buffer.get_start_iter(), self._source_buffer.get_end_iter()) \\\n+ != self.text:\n+ dlg = gtk.MessageDialog(self._window, gtk.DIALOG_MODAL, gtk.MESSAGE_QUESTION, gtk.BUTTONS_YES_NO,\n+ \"You made text changes, do you really want to close TexText?\")\n+ res = dlg.run()\n+ dlg.destroy()\n+ if res == gtk.RESPONSE_NO:\nreturn True\n+ gtk.main_quit()\n+ return False\n+\n+\ndef update_preview(self, widget):\n\"\"\"Update the preview image of the GUI using the callback it gave \"\"\"\nif self._preview_callback:\n@@ -1160,11 +1180,13 @@ if TOOLKIT in (GTK, GTKSOURCEVIEW):\nif self.text==\"\":\nif new_node_content_value=='InlineMath':\n- self._source_buffer.set_text(\"$$\")\n+ self.text=\"$$\"\n+ self._source_buffer.set_text(self.text)\niter = self._source_buffer.get_iter_at_offset(1)\nself._source_buffer.place_cursor(iter)\nif new_node_content_value=='DisplayMath':\n- self._source_buffer.set_text(\"$$$$\")\n+ self.text = \"$$$$\"\n+ self._source_buffer.set_text(self.text)\niter = self._source_buffer.get_iter_at_offset(2)\nself._source_buffer.place_cursor(iter)\n",
        "chatgpt_cot": "Fix issue with inserting text in TextEdit class"
    },
    {
        "org_diff": "diff --git a/.github/workflows/ci.yml b/.github/workflows/ci.yml @@ -58,7 +58,7 @@ jobs:\nuses: actions/cache@v3\nwith:\npath: .venv\n- key: ${{ matrix.os }}-${{ matrix.python-version }}-poetry-${{ hashFiles('poetry.lock') }}\n+ key: ${{ matrix.os }}-$(python --version)-poetry-${{ hashFiles('poetry.lock') }}\n- name: Install dependencies\nrun: |\n",
        "org_msg": "Use output of 'python --version' as cache key",
        "sim_msg": "ci: removed caching",
        "sim_diff": "diff --git a/.github/workflows/ci.yml b/.github/workflows/ci.yml @@ -35,17 +35,13 @@ jobs:\nuses: actions/setup-python@v1\nwith:\npython-version: ${{ matrix.python-version }}\n- - uses: actions/cache@v2\n- with:\n- path: ${{ env.pythonLocation }}\n- key: ${{ env.pythonLocation }}-${{ hashFiles('setup.py') }}-${{ hashFiles('extra-requirements.txt') }}-${{ hashFiles('requirements.txt') }}\n- name: Install dependencies\nrun: |\nif [ \"${{ matrix.os }}\" == \"ubuntu-latest\" ]; then\nsudo apt-get install libsndfile1\nfi\npython -m pip install --upgrade pip\n- pip install .[match-py-ver] --no-cache-dir --upgrade --upgrade-strategy eager\n+ pip install .[match-py-ver] --no-cache-dir\n- name: Lint with flake8\nrun: |\npip install flake8\n@@ -93,14 +89,10 @@ jobs:\nuses: actions/setup-python@v1\nwith:\npython-version: ${{ matrix.python-version }}\n- - uses: actions/cache@v2\n- with:\n- path: ${{ env.pythonLocation }}\n- key: ${{ env.pythonLocation }}-${{ hashFiles('setup.py') }}-${{ hashFiles('extra-requirements.txt') }}-${{ hashFiles('requirements.txt') }}\n- name: Install dependencies\nrun: |\npython -m pip install --upgrade pip\n- pip install .[match-py-ver] --no-cache-dir --upgrade --upgrade-strategy eager\n+ pip install .[match-py-ver] --no-cache-dir\n- name: Test with pytest\nrun: |\n# make sure docker exist\n",
        "chatgpt_cot": "\"Fix caching key in ci.yml to use python version instead of matrix.os\""
    },
    {
        "org_diff": "diff --git a/test/test_pickled_data.py b/test/test_pickled_data.py @@ -770,7 +770,6 @@ def test_unit():\nassert scv.is_facing(townhall, angle_error=2 * math.pi)\nassert not scv.is_facing(townhall)\nassert townhall.is_facing(scv, angle_error=2 * math.pi)\n- assert not townhall.is_facing(scv)\nassert scv.footprint_radius == 0\nassert townhall.footprint_radius == 2.5\n",
        "org_msg": "Remove 'townhall.is_facing(scv)'",
        "sim_msg": "Fix data_misfit test",
        "sim_diff": "diff --git a/tests/base/test_data.py b/tests/base/test_data.py @@ -49,7 +49,10 @@ class DataTest(unittest.TestCase):\nself.assertTrue(\nnp.allclose(\ndata.standard_deviation,\n- relative * np.abs(self.dobs) + floor * np.ones(len(self.dobs)),\n+ np.sqrt(\n+ ( relative * np.abs(self.dobs) ) ** 2 +\n+ floor ** 2 * np.ones(len(self.dobs)),\n+ )\n)\n)\n",
        "chatgpt_cot": "Remove redundant assertion in test_pickled_data.py. Update unit test for is_facing method in SCV and Townhall classes."
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/master_view_proxy.py b/node_manager_fkie/src/node_manager_fkie/master_view_proxy.py @@ -795,6 +795,8 @@ class MasterViewProxy(QWidget):\nself.message_frame.show_question(MessageFrame.TYPE_BINARY, 'Binary changed of node:<br>%s<br>restart node?' % (HTMLDelegate.toHTML(changed.name)), MessageData(changed))\ndef question_reload_changed_file(self, changed, affected):\n+ _filename, file_extension = os.path.splitext(changed)\n+ if file_extension in nm.settings().launch_view_file_ext:\nchanged_res = \"%s[%s]\" % (os.path.basename(changed), utf8(package_name(os.path.dirname(changed))[0]))\nself.message_frame.show_question(MessageFrame.TYPE_LAUNCH_FILE, 'Reload <b>%s</b>?<br>Changed files:' % os.path.basename(affected), MessageData(affected, [changed_res]))\n",
        "org_msg": "node_manager_fkie: check only files listed in \"Show files extensions\" for changes",
        "sim_msg": "enable frame size property by default",
        "sim_diff": "diff --git a/widgets/frame/frame.py b/widgets/frame/frame.py @@ -168,6 +168,7 @@ def builder(parent, sizer, pos, klass=None, base=None, name=None):\nframe = base_class(name, parent, wx.NewId(), name, klass=klass)\n#frame.properties[\"style\"].set_to_default()\nframe.properties[\"style\"].set(\"wxDEFAULT_FRAME_STYLE\")\n+ frame.properties['size'].set( (400,300), activate=True )\nnode = Node(frame)\nframe.node = node\ncommon.app_tree.add(node)\n",
        "chatgpt_cot": "Add file extension check before reloading launch file to prevent errors."
    },
    {
        "org_diff": "diff --git a/docs/install.md b/docs/install.md @@ -62,6 +62,14 @@ $ sudo systemctl daemon-reload\n$ sudo systemctl restart docker.service\n```\n+### Alternatively (for all Linux distro):\n+This will run the docker-daemon on port 2375 as long as the system is restarted or docker-daemon is killed.\n+\n+```sh\n+$ sudo systemctl stop docker.service\n+$ sudo dockerd -H tcp://0.0.0.0:2375 -H unix:///var/run/docker.sock --api-cors-header='*' --default-ulimit=nofile=8192:16384 --default-ulimit=nproc=8192:16384 -D &\n+```\n+\nAt last, run the follow test at Master node and get OK response, to make sure it can access Worker node successfully.\n```sh\n",
        "org_msg": "Added changes to install.md",
        "sim_msg": "restore lost chat about python 3.11",
        "sim_diff": "diff --git a/docs/home/guides/docker.md b/docs/home/guides/docker.md @@ -47,6 +47,33 @@ You may want to take an hour to get familiar with Docker fundamentals with the [\nDO NOT MAKE ANY CHANGES BELOW if you want this to just work. Don't change the docker image [`linuxserver.io` will not work for this, for example]; don't change the paths, etc.\n+### Prepare a small test library [optional]\n+\n+```{include} wt/wt-test-library.md\n+```\n+\n+### Starting up your terminal.\n+\n+Since most of this is typing commands into a terminal, you'll need to have a terminal open.\n+\n+````{tab} Linux\n+<br/>\n+If your Linux system is remote to your computer, connect to it via SSH. That SSH session is the terminal you will be using, so leave it open.\n+\n+If you are running this on a desktop Linux machine, start up the Terminal application. That window will be the terminal you will type commands into throughout this walkthrough, so leave it open.\n+<br/>\n+````\n+````{tab} OS X:\n+Open the Terminal app; this window will be the place you type commands throughout this walkthrough, so leave it open. The Terminal app is in Applications -> Utilities.\n+\n+You can also use iTerm or some other terminal app if you wish. If you don't know what that means, use Terminal.\n+<br/>\n+````\n+````{tab} Windows:\n+Use the Start menu to open PowerShell. This will be the window into which you type commands throughout this walkthrough, so leave it open.\n+<br/>\n+````\n+\n### Installing Docker.\nTo run Docker images, you need to have Docker installed. It is not typically installed on new Mac, Linux, or Windows machines.\n",
        "chatgpt_cot": "Add alternative method to run docker-daemon on port 2375 for all Linux distros, ensuring successful access to Worker node from Master node."
    },
    {
        "org_diff": "diff --git a/sc2/client.py b/sc2/client.py @@ -174,15 +174,16 @@ class Client(Protocol):\n))\nreturn [ActionResult(p.result) for p in result.query.placements]\n- async def query_available_abilities(self, units):\n+ async def query_available_abilities(self, units, ignore_resource_requirements=False):\nif not isinstance(units, list):\nassert isinstance(units, Unit)\nunits = [units]\nassert len(units) > 0\nresult = await self._execute(query=query_pb.RequestQuery(\nabilities=[query_pb.RequestQueryAvailableAbilities(\n- unit_tag=unit.tag) for unit in units]\n- ))\n+ unit_tag=unit.tag) for unit in units]),\n+ ignore_resource_requirements=ignore_resource_requirements\n+ )\nreturn [[AbilityId(a.ability_id) for a in b.abilities] for b in result.query.abilities]\nasync def chat_send(self, message, team_only):\n",
        "org_msg": "Add ignore_resource_requirements parameter to be used in available abilities query",
        "sim_msg": "add assets, activate, download to client",
        "sim_diff": "diff --git a/planet/api/client.py b/planet/api/client.py @@ -296,3 +296,15 @@ class ClientV1(_Base):\nreturn self.dispatcher.response(models.Request(\nself._url('data/v1/stats'), self.auth,\nbody_type=models.JSON, data=body, method='POST')).get_body()\n+\n+ def get_assets(self, item):\n+ assets_url = item['_links']['assets']\n+ return self._get(assets_url).get_body()\n+\n+ def activate(self, asset):\n+ activate_url = asset['_links']['activate']\n+ return self._get(activate_url).get_body()\n+\n+ def download(self, asset, callback=None):\n+ download_url = asset['location']\n+ return self._get(download_url, models.Image, callback=callback)\n",
        "chatgpt_cot": "Add optional parameter to query_available_abilities method to ignore resource requirements. Fix unit_tag syntax and add ignore_resource_requirements parameter to query_pb.RequestQuery."
    },
    {
        "org_diff": "diff --git a/src/api-engine/api/routes/node/views.py b/src/api-engine/api/routes/node/views.py @@ -472,6 +472,7 @@ class NodeViewSet(viewsets.ViewSet):\nraise ResourceNotFound\nelse:\n# Set file url of node\n+ if node.file:\nnode.file = request.build_absolute_uri(node.file.url)\nports = Port.objects.filter(node=node)\nnode.links = [\n",
        "org_msg": "Fix node info query crashed if no file\nIf there is no file for node, when query it will be crashed.\nCheck if file is None before use it.",
        "sim_msg": "Remove cache from drf yasg\nSeems to have some issues",
        "sim_diff": "diff --git a/config/urls.py b/config/urls.py @@ -4,35 +4,35 @@ from django.contrib import admin\nfrom django.http import HttpResponse\nfrom django.urls import path, re_path\nfrom django.views import defaults as default_views\n-from django.views.decorators.cache import cache_control\nfrom drf_yasg import openapi\nfrom drf_yasg.views import get_schema_view\n+from rest_framework import permissions\nschema_view = get_schema_view(\nopenapi.Info(\ntitle='Gnosis Safe Transaction Service API',\ndefault_version='v1',\n- description='API to store safe multisig transactions',\n+ description='API to keep track of transactions sent via Gnosis Safe smart contracts',\ncontact=openapi.Contact(email='safe@gnosis.io'),\nlicense=openapi.License(name='MIT License'),\n),\nvalidators=['flex', 'ssv'],\npublic=True,\n+ permission_classes=[permissions.AllowAny],\n)\nschema_cache_timeout = 60 * 5 # 5 minutes\n-schema_cache_decorator = cache_control(max_age=schema_cache_timeout)\nurlpatterns = [\nre_path(r'^$',\n- schema_cache_decorator(schema_view.with_ui('swagger', cache_timeout=schema_cache_timeout)),\n+ schema_view.with_ui('swagger', cache_timeout=schema_cache_timeout),\nname='schema-swagger-ui'),\nre_path(r'^swagger(?P<format>\\.json|\\.yaml)$',\n- schema_cache_decorator(schema_view.without_ui(cache_timeout=schema_cache_timeout)),\n+ schema_view.without_ui(cache_timeout=schema_cache_timeout),\nname='schema-json'),\nre_path(r'^redoc/$',\n- schema_cache_decorator(schema_view.with_ui('redoc', cache_timeout=schema_cache_timeout)),\n+ schema_view.with_ui('redoc', cache_timeout=schema_cache_timeout),\nname='schema-redoc'),\nre_path(settings.ADMIN_URL, admin.site.urls),\nre_path(r'^api/v1/', include('safe_transaction_service.history.urls', namespace='v1')),\n",
        "chatgpt_cot": "\"Add file URL to node if it exists to fix issue with file access in NodeViewSet\""
    },
    {
        "org_diff": "diff --git a/sc2/position.py b/sc2/position.py @@ -141,7 +141,7 @@ class Pointlike(tuple):\ndef __eq__(self, other):\nif not isinstance(other, tuple):\nreturn False\n- return all(a == b for a, b in zip(self, other))\n+ return all(abs(a - b) < EPSILON for a, b in itertools.zip_longest(self, other, fillvalue=0))\ndef __hash__(self):\nreturn hash(tuple(self))\n",
        "org_msg": "Fix pointlike __eq__",
        "sim_msg": "Name: implement the != operator\nUnlike what I thought, this operator does not automagically calls the ==\none...\nTN:",
        "sim_diff": "diff --git a/langkit/names.py b/langkit/names.py @@ -31,7 +31,10 @@ class Name(object):\nreturn hash(self.base_name)\ndef __eq__(self, other):\n- return self.base_name == other.base_name\n+ return isinstance(other, Name) and self.base_name == other.base_name\n+\n+ def __ne__(self, other):\n+ return not (self == other)\ndef __lt__(self, other):\nreturn self.base_name < other.base_name\n",
        "chatgpt_cot": "\"Optimize Pointlike class __eq__ method for better precision and performance\""
    },
    {
        "org_diff": "diff --git a/examples/zerg_rush.py b/examples/zerg_rush.py @@ -8,7 +8,6 @@ from sc2.player import Bot, Computer\nclass ZergRushBot(sc2.BotAI):\ndef __init__(self):\nself.drone_counter = 0\n- self.overlord_counter = 0\nself.extractor_started = False\nself.spawning_pool_started = False\nself.moved_workers_to_gas = False\n@@ -45,12 +44,10 @@ class ZergRushBot(sc2.BotAI):\nif self.supply_left < 2:\nif self.can_afford(OVERLORD) and larvae.exists:\nawait self.do(larvae.random.train(OVERLORD))\n- return\nif self.units(SPAWNINGPOOL).ready.exists:\nif larvae.exists and self.minerals > self.can_afford(ZERGLING):\nawait self.do(larvae.random.train(ZERGLING))\n- return\nif self.units(EXTRACTOR).ready.exists and not self.moved_workers_to_gas:\nself.moved_workers_to_gas = True\n@@ -67,13 +64,12 @@ class ZergRushBot(sc2.BotAI):\nbreak\nif self.drone_counter < 3:\n- if self.minerals >= self.can_afford(DRONE):\n+ if self.can_afford(DRONE):\nself.drone_counter += 1\nawait self.do(larvae.random.train(DRONE))\n- return\nif not self.extractor_started:\n- if self.minerals >= self.can_afford(EXTRACTOR):\n+ if self.can_afford(EXTRACTOR):\ndrone = self.workers.random\ntarget = state.vespene_geyser.closest_to(drone.position)\nerr = await self.do(drone.build(EXTRACTOR, target))\n@@ -81,8 +77,7 @@ class ZergRushBot(sc2.BotAI):\nself.extractor_started = True\nelif not self.spawning_pool_started:\n- if self.minerals >= self.can_afford(SPAWNINGPOOL):\n-\n+ if self.can_afford(SPAWNINGPOOL):\nfor d in range(4, 15):\npos = hatchery.position.to2.towards(self.game_info.map_center, d)\nif await self.can_place(SPAWNINGPOOL, pos):\n@@ -92,8 +87,8 @@ class ZergRushBot(sc2.BotAI):\nself.spawning_pool_started = True\nbreak\n- elif not self.queeen_started:\n- if self.minerals >= self.can_afford(QUEEN):\n+ elif not self.queeen_started and self.units(SPAWNINGPOOL).ready.exists:\n+ if self.can_afford(QUEEN):\nr = await self.do(hatchery.train(QUEEN))\nif not r:\nself.queeen_started = True\n",
        "org_msg": "Clean up ZergRushBot example",
        "sim_msg": "[plaguegame] lazy fix",
        "sim_diff": "diff --git a/plaguegame/plague.py b/plaguegame/plague.py @@ -2,6 +2,7 @@ import discord\nimport asyncio\nfrom redbot.core import Config, checks, commands, bank\n+from redbot.core.utils.menus import menu\nclass Plague(commands.Cog):\n\"\"\"A plague game.\"\"\"\n@@ -160,7 +161,7 @@ class Plague(commands.Cog):\nuserState = await self.config.user(user).gameState()\nif userState == \"infected\":\ninfected_list.append(user.mention)\n- embedDescription = \"\\n\".join(infected_list)\n+ embedDescription = \"\\n\".join(infected_list[:97])\nembed = discord.Embed(title=\"Infected Users\", description=embedDescription)\nawait ctx.send(embed=embed)\n",
        "chatgpt_cot": "Remove unused variable and fix typo in variable name in ZergRushBot class."
    },
    {
        "org_diff": "diff --git a/fkie_master_sync/src/fkie_master_sync/sync_thread.py b/fkie_master_sync/src/fkie_master_sync/sync_thread.py @@ -482,7 +482,11 @@ class SyncThread(object):\nremote_md5sums_topics = remote_monitor.getTopicsMd5sum(topic_types)\nfor rttype, rtmd5sum in remote_md5sums_topics:\ntry:\n- if roslib.message.get_message_class(rttype)._md5sum != rtmd5sum:\n+ lmd5sum = None\n+ msg_class = roslib.message.get_message_class(rttype)\n+ if msg_class is not None:\n+ lmd5sum = msg_class._md5sum\n+ if lmd5sum != rtmd5sum:\nfor topicname, topictype, node, nodeuri in topics_to_register:\nif topictype == rttype:\nif (topicname, node, nodeuri) not in self._md5warnings:\n@@ -493,6 +497,7 @@ class SyncThread(object):\nrospy.logwarn(err)\nrospy.logwarn(traceback.format_exc())\nexcept:\n+ import traceback\nrospy.logerr(\"SyncThread[%s] ERROR: %s\", self.name, traceback.format_exc())\nfinally:\nsocket.setdefaulttimeout(None)\n@@ -504,6 +509,7 @@ class SyncThread(object):\ntry:\nif topicname in self.__own_state.topics:\nown_topictype = self.__own_state.topics[topicname].type\n+ if own_topictype not in ['*', None] and topictype not in ['*', None] :\nif topictype != own_topictype:\nif (topicname, node, nodeuri) not in self._topic_type_warnings:\nrospy.logwarn(\"Different topic types detected for topic: %s, own type: %s remote type: %s, host: %s\" % (topicname, own_topictype, topictype, self.name))\n@@ -513,6 +519,7 @@ class SyncThread(object):\nrospy.logwarn(err)\nrospy.logwarn(traceback.format_exc())\nexcept:\n+ import traceback\nrospy.logerr(\"SyncThread[%s] ERROR: %s\", self.name, traceback.format_exc())\nfinally:\nsocket.setdefaulttimeout(None)\n",
        "org_msg": "fkie_master_sync: fixed warn logs",
        "sim_msg": "[hailtop] use the exact same error message for sync and async\n* [hailtop] use the exact same error message for sync and async\nImportantly, I want to see the stack trace in either case.\n* revert",
        "sim_diff": "diff --git a/hail/python/hailtop/utils/utils.py b/hail/python/hailtop/utils/utils.py @@ -629,7 +629,7 @@ async def retry_transient_errors(f: Callable[..., Awaitable[T]], *args, **kwargs\nerrors += 1\nif errors % 10 == 0:\nst = ''.join(traceback.format_stack())\n- log.warning(f'encountered {errors} errors. My stack trace is {st}. Most recent error was {e}', exc_info=True)\n+ log.warning(f'Encountered {errors} errors. My stack trace is {st}. Most recent error was {e}', exc_info=True)\ndelay = await sleep_and_backoff(delay)\n@@ -642,7 +642,8 @@ def sync_retry_transient_errors(f, *args, **kwargs):\nexcept Exception as e:\nerrors += 1\nif errors % 10 == 0:\n- log.warning(f'encountered {errors} errors, most recent one was {e}', exc_info=True)\n+ st = ''.join(traceback.format_stack())\n+ log.warning(f'Encountered {errors} errors. My stack trace is {st}. Most recent error was {e}', exc_info=True)\nif is_transient_error(e):\npass\nelse:\n",
        "chatgpt_cot": "\"Fix topic type comparison and exception handling in SyncThread\""
    },
    {
        "org_diff": "diff --git a/fkie_node_manager/src/fkie_node_manager/editor/editor.py b/fkie_node_manager/src/fkie_node_manager/editor/editor.py @@ -268,6 +268,7 @@ class Editor(QMainWindow):\nself.horizontal_layout_log_bar.setContentsMargins(2, 0, 2, 0)\nself.horizontal_layout_log_bar.setObjectName(\"horizontal_layout_log_bar\")\n# add info label\n+ self._log_warning_count = 0\nself.log_browser = QTextEdit()\nself.log_browser.setObjectName(\"log_browser\")\nself.log_browser.setSizePolicy(QSizePolicy.Expanding, QSizePolicy.Expanding)\n@@ -284,10 +285,6 @@ class Editor(QMainWindow):\nself.clear_log_button.clicked.connect(self.on_clear_log_button_clicked)\nself.clear_log_button.setFlat(True)\nself.horizontal_layout_log_bar.addWidget(self.clear_log_button)\n- self._timer_hide_log = QTimer(self)\n- self._timer_hide_log.setSingleShot(True)\n- self._timer_hide_log.setInterval(3000)\n- self._timer_hide_log.timeout.connect(self._timed_hide_log)\nself.log_dock.setWidget(self.log_bar)\nreturn self.log_dock\n@@ -447,21 +444,15 @@ class Editor(QMainWindow):\npass\ndef on_graph_info(self, msg, warning=False):\n- self._timer_hide_log.stop()\n- self._timer_hide_log.start()\ntext_color = \"#000000\"\nif warning:\n+ self._log_warning_count += 1\n+ if self._log_warning_count == 1:\n+ self.show_log_button.setIcon(self._error_icon)\ntext_color = \"#FE9A2E\"\ntext = ('<pre style=\"padding:10px;\"><dt><font color=\"%s\">'\n'%s</font></dt></pre>' % (text_color, msg))\nself.log_browser.append(text)\n- if warning:\n- self.log_dock.setVisible(True)\n- self.show_log_button.setChecked(True)\n-\n- def _timed_hide_log(self):\n- self.log_dock.setVisible(False)\n- self.show_log_button.setChecked(False)\ndef on_text_changed(self, value=\"\"):\nif self.tabWidget.currentWidget().hasFocus():\n@@ -590,6 +581,8 @@ class Editor(QMainWindow):\n##############################################################################\ndef on_clear_log_button_clicked(self):\n+ self._log_warning_count = 0\n+ self.show_log_button.setIcon(self._empty_icon)\nself.log_browser.clear()\nself.log_dock.setVisible(False)\nself.show_log_button.setChecked(False)\n",
        "org_msg": "fkie_node_manager: editor: do not open or hide log automatically",
        "sim_msg": "load text file encoding error handler using backslashreplace",
        "sim_diff": "diff --git a/qualcoder/manage_files.py b/qualcoder/manage_files.py @@ -1009,6 +1009,10 @@ class DialogManageFiles(QtWidgets.QDialog):\nfor lt_obj in layout:\nif isinstance(lt_obj, LTTextBox) or isinstance(lt_obj, LTTextLine):\ntext += lt_obj.get_text() + \"\\n\" # add line to paragraph spacing for visual format\n+ # remove excess line endings, include those with one blank space on a line\n+ text = text.replace('\\n \\n', '\\n')\n+ text = text.replace('\\n\\n\\n', '\\n\\n')\n+\n# import from html\nif import_file[-5:].lower() == \".html\" or import_file[-4:].lower() == \".htm\":\nimportErrors = 0\n@@ -1028,7 +1032,8 @@ class DialogManageFiles(QtWidgets.QDialog):\nif text == \"\":\nimport_errors = 0\ntry:\n- with open(import_file, \"r\") as sourcefile:\n+ # can get UnicodeDecode Error on Windows so using error handler\n+ with open(import_file, \"r\", encoding=\"utf-8\", errors=\"backslashreplace\") as sourcefile:\nwhile 1:\nline = sourcefile.readline()\nif not line:\n",
        "chatgpt_cot": "\"Added log warning count and modified log button icon settings to editor.py for better user experience.\""
    },
    {
        "org_diff": "diff --git a/src/api-engine/api/lib/peer/channel.py b/src/api-engine/api/lib/peer/channel.py @@ -36,3 +36,13 @@ class Channel(BasicEnv):\nerr_msg = \"get channel list failed for {}!\".format(e)\nraise Exception(err_msg)\nreturn res\n+\n+ def update(self, channel, channel_tx, orderer_url, time_out=\"90s\"):\n+ try:\n+ res = os.system(\"{} channel create -c {} -f {} -o {} --timeout {}\"\n+ .format(self.peer, channel, channel_tx, orderer_url, time_out))\n+ except Exception as e:\n+ err_msg = \"update channel failed for {e}!\"\n+ raise Exception(err_msg)\n+ res = res >> 8\n+ return res\n",
        "org_msg": "added channel updating operation\nadd an update method to channel class to achieve updating operation.",
        "sim_msg": "Create Channel Streams Endpoint",
        "sim_diff": "diff --git a/blueprints/apis/channel_ns.py b/blueprints/apis/channel_ns.py @@ -12,11 +12,13 @@ from classes import Sec\nfrom classes import topics\nfrom classes import invites\nfrom classes import views\n+from classes import Stream\nfrom classes.shared import db\nfrom functions import system\nfrom functions import cachedDbCalls\nfrom functions import channelFunc\n+from functions import templateFilters\nfrom globals import globalvars\n@@ -197,6 +199,47 @@ class api_1_ListChannel(Resource):\nreturn {'results': {'message': 'Channel Deleted'}}, 200\nreturn {'results': {'message': 'Request Error'}}, 400\n+# Invites Endpoint for a Channel\n+@api.route('/<string:channelEndpointID>/streams')\n+@api.doc(params={'channelEndpointID': 'GUID Channel Location'})\n+class api_1_Streams(Resource):\n+ @api.doc(responses={200: 'Success', 400: 'Request Error'})\n+ def get(self, channelEndpointID):\n+ \"\"\"\n+ Returns list of active streams on a channel\n+ \"\"\"\n+ sysSettings = cachedDbCalls.getSystemSettings()\n+ channelIDQuery = cachedDbCalls.getChannelIDFromLocation(channelEndpointID)\n+\n+ if channelIDQuery is not None:\n+ StreamQuery = Stream.Stream.query.filter_by(linkedChannel=channelIDQuery, active=True, complete=False)\\\n+ .with_entities(Stream.Stream.id, Stream.Stream.topic, Stream.Stream.streamName, Stream.Stream.startTimestamp, Stream.Stream.uuid, Stream.Stream.currentViewers,\n+ Stream.Stream.totalViewers).all()\n+\n+ results = []\n+ if sysSettings.adaptiveStreaming is True:\n+ streamURL = '/live-adapt/' + channelEndpointID + '.m3u8'\n+ else:\n+ streamURL = '/live/' + channelEndpointID + '/index.m3u8'\n+ for entry in StreamQuery:\n+ results.append(\n+ {\n+ 'id': entry.id,\n+ 'uuid': entry.uuid,\n+ 'topic': entry.topic,\n+ 'streamName': entry.streamName,\n+ 'startTimestamp': entry.startTimestamp,\n+ 'currentViewers': entry.currentViewers,\n+ 'totalViewers': entry.totalViewers,\n+ 'streamURL': streamURL\n+ })\n+ db.session.commit()\n+ return {'results': results}\n+\n+ db.session.commit()\n+ return {'results': {'message': 'Request Error'}}, 400\n+\n+\n# TODO Add Ability to Add/Delete/Change\n@api.route('/<string:channelEndpointID>/restreams')\n",
        "chatgpt_cot": "\"Add update method to Channel class for creating a new channel, with error handling and timeout functionality.\""
    },
    {
        "org_diff": "diff --git a/Makefile b/Makefile @@ -16,6 +16,8 @@ TEMPLATE_FOLDER?=themes\\/${THEME}\\/templates\nredeploy \\\nrestart \\\nsetup \\\n+ start \\\n+ stop \\\nall: check\n@@ -47,8 +49,7 @@ start: ##@Service Start service\nstop: ##@Service Stop service\nbash scripts/stop.sh\n-restart: ##@Service Restart service\n- stop start\n+restart: stop start ##@Service Restart service\nsetup: ##@Environment Setup dependency for service environment\nbash scripts/setup.sh\n",
        "org_msg": "Fix the make restart cmd",
        "sim_msg": "site: delete/create instead of apply",
        "sim_diff": "diff --git a/site/Makefile b/site/Makefile @@ -32,4 +32,6 @@ deploy-site:\nsed -e \"s,@sha@,$(shell git rev-parse --short=12 HEAD),\" \\\n-e \"s,@image@,$(shell cat site-image),\" \\\n< site-deployment.yaml.in > site-deployment.yaml\n- kubectl apply -f site-deployment.yaml\n+ kubectl delete -f site-deployment.yaml\n+ sleep 5\n+ kubectl create -f site-deployment.yaml\n",
        "chatgpt_cot": "Add start and stop commands, update restart command for service, and setup dependencies in Makefile for better service management."
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/message_frame.py b/node_manager_fkie/src/node_manager_fkie/message_frame.py @@ -178,6 +178,8 @@ class MessageFrame(QFrame):\nself.frameui.checkBox_dnaa.setText(\"don't %s again, for session\" % self._ask)\ndef add_info_no_screen(self, nodename):\n+ if self.is_do_not_ask(self.TYPE_NOSCREEN):\n+ return\nif self.questionid == self.TYPE_NOSCREEN:\nself.data.data.append(nodename)\nself.frameui.scrollAreaLayout.addWidget(QLabel(nodename))\n@@ -187,6 +189,13 @@ class MessageFrame(QFrame):\nself._new_request = self._read_next_item()\nself._frameui_4_request(self._new_request)\n+ def is_do_not_ask(self, questionid):\n+ try:\n+ # is it in the list for not ask again?\n+ return self._do_not_ask[questionid]\n+ except Exception:\n+ return False\n+\ndef hide_question(self, questionids):\nif self.questionid in questionids:\nself._new_request = False\n",
        "org_msg": "node_manager_fkie: fixed do not ask handling on no screen errors",
        "sim_msg": "enable frame size property by default",
        "sim_diff": "diff --git a/widgets/frame/frame.py b/widgets/frame/frame.py @@ -168,6 +168,7 @@ def builder(parent, sizer, pos, klass=None, base=None, name=None):\nframe = base_class(name, parent, wx.NewId(), name, klass=klass)\n#frame.properties[\"style\"].set_to_default()\nframe.properties[\"style\"].set(\"wxDEFAULT_FRAME_STYLE\")\n+ frame.properties['size'].set( (400,300), activate=True )\nnode = Node(frame)\nframe.node = node\ncommon.app_tree.add(node)\n",
        "chatgpt_cot": "Add method to check if a question should not be asked again to MessageFrame class in node_manager_fkie."
    },
    {
        "org_diff": "diff --git a/sc2/game_data.py b/sc2/game_data.py @@ -296,3 +296,17 @@ class Cost:\ndef __bool__(self) -> bool:\nreturn self.minerals != 0 or self.vespene != 0\n+\n+ def __add__(self, other) -> \"Cost\":\n+ if not other:\n+ return self\n+ if not self:\n+ return other\n+ if self.time is None:\n+ time = other.time\n+ elif other.time is None:\n+ time = self.time\n+ else:\n+ time = self.time + other.time\n+ return self.__class__(self.minerals + other.minerals, self.vespene + other.vespene, time=time)\n+\n",
        "org_msg": "Addition for Cost objects",
        "sim_msg": "Fixes based on the PR comments",
        "sim_diff": "diff --git a/packages/fetchai/skills/tac_control_contract/game.py b/packages/fetchai/skills/tac_control_contract/game.py @@ -889,7 +889,7 @@ class Game(Model):\n+ \"\\n\"\n)\nfor good_id, quantity in agent_state.quantities_by_good_id.items():\n- result += \" \" + str(good_id) + \": \" + str(quantity) + \"\\n\"\n+ result += \" \" + good_id + \": \" + str(quantity) + \"\\n\"\nfor currency_id, amount in agent_state.amount_by_currency_id.items():\nresult += \" \" + currency_id + \": \" + str(amount) + \"\\n\"\nresult += \" score: \" + str(round(agent_state.get_score(), 2)) + \"\\n\"\n@@ -901,7 +901,7 @@ class Game(Model):\n\"\"\"Get equilibrium summary.\"\"\"\nresult = \"\\n\" + \"Equilibrium prices: \\n\"\nfor good_id, eq_price in self.initialization.good_id_to_eq_prices.items():\n- result = result + str(good_id) + \" \" + str(eq_price) + \"\\n\"\n+ result = result + good_id + \" \" + str(eq_price) + \"\\n\"\nresult = result + \"\\n\"\nresult = result + \"Equilibrium good allocation: \\n\"\nfor (\n@@ -915,7 +915,7 @@ class Game(Model):\n+ \":\\n\"\n)\nfor good_id, quantity in eq_allocations.items():\n- result = result + \" \" + str(good_id) + \": \" + str(quantity) + \"\\n\"\n+ result = result + \" \" + good_id + \": \" + str(quantity) + \"\\n\"\nresult = result + \"\\n\"\nresult = result + \"Equilibrium money allocation: \\n\"\nfor (\n",
        "chatgpt_cot": "Add __add__ method to Cost class for combining Cost objects with proper handling of time attribute."
    },
    {
        "org_diff": "diff --git a/fkie_node_manager/src/fkie_node_manager/node_tree_model.py b/fkie_node_manager/src/fkie_node_manager/node_tree_model.py @@ -1775,7 +1775,8 @@ class NodeTreeModel(QStandardItemModel):\naddr = get_hostname(node.uri if node.uri is not None else node.masteruri)\naddresses.append(addr)\nmuris.append(node.masteruri)\n- host = (node.masteruri, addr)\n+ resaddr = nm.nameres().hostname(addr)\n+ host = (node.masteruri, resaddr)\nif host not in hosts:\nhosts[host] = dict()\nhosts[host][name] = node\n",
        "org_msg": "fkie_node_manager: add nodes to view with not reachable nodeuri",
        "sim_msg": "remove unneeded if statement in getPeersForBlob",
        "sim_diff": "diff --git a/lbrynet/dht/node.py b/lbrynet/dht/node.py @@ -220,9 +220,6 @@ class Node(object):\nif blob_hash in result:\nfor peer in result[blob_hash]:\nhost = \".\".join([str(ord(d)) for d in peer[:4]])\n- if host == \"127.0.0.1\" and \"from_peer\" in result \\\n- and result[\"from_peer\"] != \"self\":\n- host = result[\"from_peer\"]\nport, = struct.unpack('>H', peer[4:6])\nif (host, port) not in expanded_peers:\nexpanded_peers.append((host, port))\n",
        "chatgpt_cot": "\"Resolve hostname using nameres module in NodeTreeModel\""
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/nmd_client.py b/node_manager_fkie/src/node_manager_fkie/nmd_client.py @@ -335,7 +335,6 @@ class NmdClient(QObject):\ndef copy(self, grpc_path='grpc://localhost:12321', grpc_dest='grpc://localhost:12321'):\nuri, path = nmdurl.split(grpc_path)\n- uri_dest, _ = nmdurl.split(grpc_dest)\nrospy.logdebug(\"copy '%s' to '%s'\" % (grpc_path, grpc_dest))\nfm = self.get_file_manager(uri)\nfm.copy(path, grpc_dest)\n",
        "org_msg": "node_manager_fkie: removed not needed code",
        "sim_msg": "ADD processing_pointers dict as a new client attribute",
        "sim_diff": "diff --git a/packages/syft/src/syft/core/node/common/client.py b/packages/syft/src/syft/core/node/common/client.py @@ -77,6 +77,7 @@ class Client(AbstractNodeClient):\nself.routes = routes\nself.default_route_index = 0\n+ self.processing_pointers: Dict[UID, str] = {}\ngc_strategy_name = gc_get_default_strategy()\nself.gc = GarbageCollection(gc_strategy_name)\n@@ -222,6 +223,7 @@ class Client(AbstractNodeClient):\ntimeout: Optional[float] = None,\nreturn_signed: bool = False,\nroute_index: int = 0,\n+ verbose: bool = False,\n) -> Union[SyftMessage, SignedMessage]:\n# relative\n@@ -254,7 +256,7 @@ class Client(AbstractNodeClient):\nexception_msg = response.message\nexception = exception_msg.exception_type(exception_msg.exception_msg)\nerror(str(exception))\n- traceback_and_raise(exception)\n+ traceback_and_raise(exception, verbose=verbose)\nelse:\nif return_signed:\nreturn response\n",
        "chatgpt_cot": "Remove unnecessary variable assignment and log statement in NmdClient's copy method."
    },
    {
        "org_diff": "diff --git a/src/agent/k8s/cluster.py b/src/agent/k8s/cluster.py @@ -98,8 +98,8 @@ class ClusterOnKubernetes(ClusterBase):\ncluster = ClusterModel.objects.get(id=cid)\ncluster_name = cluster.name\n- kube_config = KubernetesOperation()._get_from_params(cluster\n- .host\n+ kube_config = \\\n+ KubernetesOperation()._get_config_from_params(cluster.host\n.k8s_param)\noperation = K8sClusterOperation(kube_config)\n",
        "org_msg": "Chain in k8s host thrown Exception\n1. rename \"_get_from_params\" function to \"_get_config_from_params\"",
        "sim_msg": "Add k8s envs",
        "sim_diff": "diff --git a/wca/kubernetes.py b/wca/kubernetes.py @@ -30,6 +30,10 @@ DEFAULT_EVENTS = (MetricName.INSTRUCTIONS, MetricName.CYCLES, MetricName.CACHE_M\nlog = logging.getLogger(__name__)\n+SERVICE_HOST_ENV_NAME = \"KUBERNETES_SERVICE_HOST\"\n+SERVICE_PORT_ENV_NAME = \"KUBERNETES_SERVICE_PORT\"\n+SERVICE_TOKEN_FILENAME = \"/var/run/secrets/kubernetes.io/serviceaccount/token\"\n+SERVICE_CERT_FILENAME = \"/var/run/secrets/kubernetes.io/serviceaccount/ca.crt\"\n@dataclass\nclass KubernetesTask(Task):\n",
        "chatgpt_cot": "Update KubernetesOperation method call to correctly get kube config from cluster host in ClusterOnKubernetes class."
    },
    {
        "org_diff": "diff --git a/fkie_node_manager/src/fkie_node_manager/logscreen/logger_handler.py b/fkie_node_manager/src/fkie_node_manager/logscreen/logger_handler.py @@ -80,6 +80,7 @@ class LoggerHandler(QObject):\nself._logger_items = {} # logger name: LoggerItem\nself.layout = layout\nself._change_all_cancel = False\n+ self._stored_values = {}\nself.loggers_signal.connect(self._handle_loggers)\nself._thread_update = None\nself._thread_set_all = None\n@@ -105,12 +106,11 @@ class LoggerHandler(QObject):\nself._thread_update = None\ndef _handle_loggers(self, loggers):\n- stored_values = {}\nwhile self.layout.count() > 1:\nitem = self.layout.takeAt(0)\nwd = item.widget()\nif wd.current_level is not None:\n- stored_values[wd.loggername] = wd.current_level\n+ self._stored_values[wd.loggername] = wd.current_level\nwd.setParent(None)\nself._logger_items.clear()\nall_item = LoggerItem(self.nodename, self.masteruri, 'all', '')\n@@ -121,8 +121,8 @@ class LoggerHandler(QObject):\nitem = LoggerItem(self.nodename, self.masteruri, logger.name, logger.level)\nself._logger_items[logger.name] = item\nself.layout.insertWidget(index, item)\n- if logger.name in stored_values and stored_values[logger.name] != logger.level:\n- item.set_level(stored_values[logger.name])\n+ if logger.name in self._stored_values and self._stored_values[logger.name] != logger.level:\n+ item.set_level(self._stored_values[logger.name])\nindex += 1\ndef change_all(self, loglevel, ignore=['ros.roscpp.roscpp_internal',\n",
        "org_msg": "fkie_node_manager: store all loggers states in logscreen while runtime",
        "sim_msg": "Add docstrings to set_global_logger_level",
        "sim_diff": "diff --git a/qlib/log.py b/qlib/log.py @@ -165,14 +165,79 @@ class LogFilter(logging.Filter):\nreturn allow\n-@contextmanager\n-def set_global_logger_level(level: int):\n+def set_global_logger_level(level: int, return_orig_handler_level: bool = False):\n+ \"\"\"set qlib.xxx logger handlers level\n+\n+ Parameters\n+ ----------\n+ level: int\n+ logger level\n+\n+ return_orig_handler_level: bool\n+ return origin handler level map\n+\n+ Examples\n+ ---------\n+\n+ .. code-block:: python\n+\n+ import qlib\n+ import logging\n+ from qlib.log import get_module_logger, set_global_logger_level\n+ qlib.init()\n+\n+ tmp_logger_01 = get_module_logger(\"tmp_logger_01\", level=logging.INFO)\n+ tmp_logger_01.info(\"1. tmp_logger_01 info show\")\n+\n+ global_level = logging.WARNING + 1\n+ set_global_logger_level(global_level)\n+ tmp_logger_02 = get_module_logger(\"tmp_logger_02\", level=logging.INFO)\n+ tmp_logger_02.log(msg=\"2. tmp_logger_02 log show\", level=global_level)\n+\n+ tmp_logger_01.info(\"3. tmp_logger_01 info do not show\")\n+\n+ \"\"\"\n_handler_level_map = {}\nqlib_logger = logging.root.manager.loggerDict.get(\"qlib\", None)\nif qlib_logger is not None:\nfor _handler in qlib_logger.handlers:\n_handler_level_map[_handler] = _handler.level\n_handler.level = level\n+ return _handler_level_map if return_orig_handler_level else None\n+\n+\n+@contextmanager\n+def set_global_logger_level_cm(level: int):\n+ \"\"\"set qlib.xxx logger handlers level to use contextmanager\n+\n+ Parameters\n+ ----------\n+ level: int\n+ logger level\n+\n+ Examples\n+ ---------\n+\n+ .. code-block:: python\n+\n+ import qlib\n+ import logging\n+ from qlib.log import get_module_logger, set_global_logger_level_cm\n+ qlib.init()\n+\n+ tmp_logger_01 = get_module_logger(\"tmp_logger_01\", level=logging.INFO)\n+ tmp_logger_01.info(\"1. tmp_logger_01 info show\")\n+\n+ global_level = logging.WARNING + 1\n+ with set_global_logger_level_cm(global_level):\n+ tmp_logger_02 = get_module_logger(\"tmp_logger_02\", level=logging.INFO)\n+ tmp_logger_02.log(msg=\"2. tmp_logger_02 log show\", level=global_level)\n+ tmp_logger_01.info(\"3. tmp_logger_01 info do not show\")\n+\n+ tmp_logger_01.info(\"4. tmp_logger_01 info show\")\n+\n+ \"\"\"\n+ _handler_level_map = set_global_logger_level(level, return_orig_handler_level=True)\ntry:\nyield\nfinally:\n",
        "chatgpt_cot": "add a member variable to store values in LoggerHandler."
    },
    {
        "org_diff": "diff --git a/fkie_node_manager/src/fkie_node_manager/parameter_list_model.py b/fkie_node_manager/src/fkie_node_manager/parameter_list_model.py @@ -77,7 +77,6 @@ class ParameterValueItem(QStandardItem):\n@value.setter\ndef value(self, value):\nself._value = value\n- self.setText(utf8(value) if not isinstance(value, Binary) else utf8(value))\nif isinstance(value, (str, unicode)) and value.find('\\n') > -1:\nself.setSizeHint(QSize(-1, 45))\n",
        "org_msg": "fkie_node_manager: fix set list values in parameter view",
        "sim_msg": "revert parameters to test travis",
        "sim_diff": "diff --git a/pybamm/parameters/parameter_values.py b/pybamm/parameters/parameter_values.py @@ -168,4 +168,11 @@ class ParameterValues(dict):\nreturn pybamm.Concatenation(*new_children)\nelse:\n- return copy.copy(symbol)\n+ # hack to copy the symbol but without a parent\n+ # (building tree from bottom up)\n+ # simply setting new_symbol.parent = None, after copying, raises a TreeError\n+ parent = symbol.parent\n+ symbol.parent = None\n+ new_symbol = copy.copy(symbol)\n+ symbol.parent = parent\n+ return new_symbol\n",
        "chatgpt_cot": "\"Remove unnecessary text encoding in parameter value item setter\""
    },
    {
        "org_diff": "diff --git a/sc2/helpers/control_group.py b/sc2/helpers/control_group.py @@ -14,3 +14,17 @@ class ControlGroup(set):\n@property\ndef empty(self):\nreturn self.amount == 0\n+\n+ def add_unit(self, units):\n+ self.add(unit.tag)\n+\n+ def add_units(self, units):\n+ for unit in units:\n+ self.add_unit(unit)\n+\n+ def remove_unit(self, units):\n+ self.remove(unit.tag)\n+\n+ def remove_units(self, units):\n+ for unit in units:\n+ self.remove(unit.tag)\n",
        "org_msg": "Add modification operations to control groups",
        "sim_msg": "fix property control activation",
        "sim_diff": "diff --git a/new_properties.py b/new_properties.py @@ -164,7 +164,9 @@ class Property(object):\nif active != self.deactivated: return\nfor controlname in self.CONTROLNAMES:\nif controlname==\"enabler\": continue\n- getattr(self, controlname).Enable(active)\n+ control = getattr(self, controlname, None)\n+ if control is None: continue\n+ control.Enable(active)\nself.on_value_edited(self.value, active)\nself.activate_controls()\n",
        "chatgpt_cot": "Add methods to add and remove units in ControlGroup class."
    },
    {
        "org_diff": "diff --git a/src/dashboard/src/pages/Operator/Agent/Agent.js b/src/dashboard/src/pages/Operator/Agent/Agent.js @@ -120,9 +120,10 @@ const ApplyAgentForm = Form.create()(props => {\n);\n});\n-@connect(({ agent, organization, loading }) => ({\n+@connect(({ agent, organization, user, loading }) => ({\nagent,\norganization,\n+ user,\nloadingAgents: loading.effects['agent/listAgent'],\napplyingAgent: loading.effects['agent/applyAgent'],\n}))\n@@ -148,6 +149,7 @@ class Agent extends PureComponent {\ndispatch,\nagent: { pagination },\n} = this.props;\n+ const userRole = getAuthority()[0];\ndispatch({\ntype: 'agent/listAgent',\n@@ -156,9 +158,11 @@ class Agent extends PureComponent {\npage: pagination.current,\n},\n});\n+ if (userRole === 'operator') {\ndispatch({\ntype: 'organization/listOrganization',\n});\n+ }\n};\napplyCallback = () => {\n@@ -298,12 +302,16 @@ class Agent extends PureComponent {\norganization: { organizations },\nloadingAgents,\napplyingAgent,\n+ user: {\n+ currentUser: { organization = {} },\n+ },\n} = this.props;\nconst { modalVisible } = this.state;\n+ const userRole = getAuthority()[0];\nconst filterOrgName = organizationId => {\n- const orgs = organizations.filter(organization => organizationId === organization.id);\n+ const orgs = organizations.filter(org => organizationId === org.id);\nif (orgs.length > 0) {\nreturn orgs[0].name;\n}\n@@ -413,7 +421,9 @@ class Agent extends PureComponent {\ndefaultMessage=\"Organization\"\n/>\n{' : '}\n- {filterOrgName(item.organization_id)}\n+ {userRole === 'operator'\n+ ? filterOrgName(item.organization_id)\n+ : organization.name || ''}\n</p>\n</div>\n}\n",
        "org_msg": "Fix admin can not query org in agent page\nIn agent page, admin can't query organizations.\nRemove unused files/functinons under utils.",
        "sim_msg": "(from AES) update comments",
        "sim_diff": "diff --git a/charts/ambassador/templates/ambassador-agent.yaml b/charts/ambassador/templates/ambassador-agent.yaml {{- if .Values.agent.enabled }}\n{{- $allowAgent := false -}}\n+\n+ {{- /* This next bit is ugly. */ -}}\n+ {{- /* Case 1: \"fullImageOverride\" means don't bother checking the tag. */ -}}\n+ {{- /* Case 2: Otherwise, if it's not a semver-style version number, */ -}}\n+ {{- /* assume we have a power user and turn the agent on. */ -}}\n+ {{- /* Case 3: Otherwise, if Edge Stack, we need at least 1.12.0. */ -}}\n+ {{- /* Case 4: Otherwise, it's OSS and we need at 1.13.0. */ -}}\n+\n{{- if .Values.image.fullImageOverride }}\n+ {{- /* Case 1 */ -}}\n{{- $allowAgent = true }}\n-{{- /* if the tag isn't semver, this is probably testing or yaml generation, so allow agent */ -}}\n-{{- /* Yes, this isn't the official semver regex, but if the user is not running an X.Y.Z tag, let's assume they are a power user */ -}}\n{{- else if not (regexMatch \"^\\\\d+\\\\.\\\\d+\\\\.\\\\d+$\" .Values.image.tag) }}\n+ {{- /* Case 2 above: power user */ -}}\n{{- $allowAgent = true }}\n-{{- /* agent was introduced in AES in 1.12.0 */ -}}\n{{- else if and .Values.enableAES (ne (semver \"1.12.0\" | (semver .Values.image.tag).Compare) -1) }}\n+ {{- /* Case 3 above: Edge Stack 1.12.0+ */ -}}\n{{- $allowAgent = true }}\n-{{- /* agent was introduced in the gateway in 1.13.0 */ -}}\n{{- else if ne (semver \"1.13.0\" | (semver .Values.image.tag).Compare) -1 }}\n+ {{- /* Case 4 above: OSS 1.13.0+ */ -}}\n{{- $allowAgent = true }}\n{{- end }}\n",
        "chatgpt_cot": "Add user to connect, fix compilation issue, and add userRole to handle organization display in Agent.js."
    },
    {
        "org_diff": "diff --git a/fkie_node_manager/src/fkie_node_manager/main_window.py b/fkie_node_manager/src/fkie_node_manager/main_window.py @@ -1764,8 +1764,8 @@ class MainWindow(QMainWindow):\n'''\nif self.isActiveWindow() and self.isActiveWindow() != self._last_window_state:\nif hasattr(self, 'currentMaster') and self.currentMaster is not None:\n- # perform checks for changed files of multiple screens\n- self.currentMaster.perform_master_checks()\n+ # perform delayed checks for changed files or multiple screens\n+ QTimer.singleShot(700, self.currentMaster.perform_master_checks)\nself._last_window_state = self.isActiveWindow()\nQMainWindow.changeEvent(self, event)\n",
        "org_msg": "fkie_node_manager: delay update for changed files",
        "sim_msg": "better help for toplevel extracode",
        "sim_diff": "diff --git a/edit_windows.py b/edit_windows.py @@ -704,6 +704,9 @@ class TopLevelBase(WindowBase, PreviewMixin):\nIS_TOPLEVEL_WINDOW = True # will be False for TopLevelPanel and MDIChildFrame\nCHILDREN = 1 # a sizer or a widget\n+ _PROPERTY_HELP={ \"extracode_pre\":\"This code will be inserted at the beginning of the constructor.\\n\",\n+ \"extracode_post\":\"This code will be inserted at the end of the constructor.\\n\" }\n+\ndef __init__(self, name, klass, parent, title=None):\nWindowBase.__init__(self, name, klass, parent, pos=None)\nself._oldname = name\n",
        "chatgpt_cot": "perform delayed checks for changed files or multiple screens in main window."
    },
    {
        "org_diff": "diff --git a/.github/workflows/codecoverage.yml b/.github/workflows/codecoverage.yml @@ -50,23 +50,23 @@ jobs:\n- name: Run coverage on autotest_bot.py\nrun: |\n- docker exec -i my_container bash -c \"poetry run coverage run test/travis_test_script.py test/autotest_bot.py\"\n+ docker exec -i my_container bash -c \"poetry run coverage run -a test/travis_test_script.py test/autotest_bot.py\"\n- name: Run coverage on upgradestest_bot.py\nrun: |\n- docker exec -i my_container bash -c \"poetry run coverage run test/travis_test_script.py test/upgradestest_bot.py\"\n+ docker exec -i my_container bash -c \"poetry run coverage run -a test/travis_test_script.py test/upgradestest_bot.py\"\n- name: Run coverage on damagetest_bot.py\nrun: |\n- docker exec -i my_container bash -c \"poetry run coverage run test/travis_test_script.py test/damagetest_bot.py\"\n+ docker exec -i my_container bash -c \"poetry run coverage run -a test/travis_test_script.py test/damagetest_bot.py\"\n- name: Run coverage on queries_test_bot.py\nrun: |\n- docker exec -i my_container bash -c \"poetry run coverage run test/travis_test_script.py test/queries_test_bot.py\"\n+ docker exec -i my_container bash -c \"poetry run coverage run -a test/travis_test_script.py test/queries_test_bot.py\"\n- name: Run coverage on example bots\nrun: |\n- docker exec -i my_container bash -c \"poetry run coverage run test/run_example_bots_vs_computer.py\"\n+ docker exec -i my_container bash -c \"poetry run coverage run -a test/run_example_bots_vs_computer.py\"\n- name: Generate xml coverage file\nrun: |\n",
        "org_msg": "Add '-a' parameter to coverage command",
        "sim_msg": "Move static/collectstatic calls to specific ci commands",
        "sim_diff": "diff --git a/csu b/csu @@ -316,6 +316,8 @@ cmd_logs() {\ndefhelp logs 'View logs.'\nci_test_general() {\n+ dev_static\n+ dev_collect_static\ndocker-compose exec django /docker_venv/bin/coverage run --rcfile=/cs-unplugged/.coveragerc ./manage.py test --settings=config.settings.testing --pattern \"test_*.py\" -v 3 --exclude-tag=resource --exclude-tag=management --nomigrations\ntest_status=$?\ndev_test_coverage\n@@ -325,6 +327,8 @@ ci_test_general() {\n}\nci_test_resources() {\n+ dev_static\n+ dev_collect_static\ndocker-compose exec django /docker_venv/bin/coverage run --rcfile=/cs-unplugged/.coveragerc ./manage.py test --settings=config.settings.testing --pattern \"test_*.py\" -v 3 --tag=resource --nomigrations\ntest_status=$?\ndev_test_coverage\n@@ -334,6 +338,8 @@ ci_test_resources() {\n}\nci_test_management() {\n+ dev_static\n+ dev_collect_static\ndocker-compose exec django /docker_venv/bin/coverage run --rcfile=/cs-unplugged/.coveragerc ./manage.py test --settings=config.settings.testing --pattern \"test_*.py\" -v 3 --tag=management --nomigrations\ntest_status=$?\ndev_test_coverage\n@@ -347,6 +353,8 @@ ci_style() {\n}\nci_test_backwards() {\n+ dev_static\n+ dev_collect_static\ndev_test_backwards\n}\n@@ -360,8 +368,6 @@ ci_load_content() {\ncmd_ci() {\ncmd_start\n- dev_static\n- dev_collect_static\nlocal cmd=\"$1\"\nshift\nif [ -z \"$cmd\" ]; then\n",
        "chatgpt_cot": "\"Update codecoverage.yml to append coverage results to the existing file for autotest_bot, upgradestest_bot, damagetest_bot, queries_test_bot, and run_example_bots_vs_computer.\""
    },
    {
        "org_diff": "diff --git a/docker-compose.yml b/docker-compose.yml @@ -71,18 +71,18 @@ services:\nports:\n- \"8081:8080\"\nenvironment:\n- - SV_BaseURL=http://operator-dashboard:8080/api/\n- - RESTful_Server=operator-dashboard:8080\n- - RESTful_BaseURL=/api/\n+ - NODE_ENV=production\n+ - RESTFUL_SERVER=operator-dashboard:8080\n- DEBUG=node:*\n- DEV=$DEV\n+ - LOG_LEVEL=$LOG_LEVEL\n- ENABLE_EMAIL_ACTIVE=$ENABLE_EMAIL_ACTIVE\n- SMTP_SERVER=$SMTP_SERVER\n- SMTP_PORT=$SMTP_PORT\n- SMTP_AUTH_USERNAME=$SMTP_AUTH_USERNAME\n- SMTP_AUTH_PASSWORD=$SMTP_AUTH_PASSWORD\n- FROM_EMAIL=$FROM_EMAIL\n- - WEBROOT=$WEBROOT\n+ - WEBROOT=$USER_DASHBOARD_WEBROOT\n- FABRIC_CFG_PATH=/etc/hyperledger/fabric\nvolumes:\n- /opt/cello/baas:/opt/data\n",
        "org_msg": "Fix product compose file for user-dashboard",
        "sim_msg": "Add SMTP Configuration to New Install",
        "sim_diff": "diff --git a/osp-config.sh b/osp-config.sh @@ -42,6 +42,66 @@ display_result() {\n--msgbox \"$result\" 20 70\n}\n+config_smtp() {\n+ smtpSendAs=\"\"\n+ smtpServerAddress=\"\"\n+ smtpServerPort=\"\"\n+ smtpUsername=\"\"\n+ smtpPassword=\"\"\n+ smtpEncryption=\"\"\n+exec 3>&1\n+ # Store data to $VALUES variable\n+dialog --separate-widget $'\\n' --ok-label \"Save\" \\\n+ --title \"Configure SMTP Settings\" \\\n+ --form \"Please Configure your SMTP Settings (Required)\" \\\n+20 70 0 \\\n+ \"Send Email As:\" 1 1 \"$smtpSendAs\" 1 25 40 0 \\\n+ \"SMTP Server Address:\" 2 1 \"$smtpServerAddress\" 2 25 40 0 \\\n+ \"SMTP Server Port:\" 3 1 \"$smtpServerPort\" 3 25 5 0 \\\n+ \"Username:\" 4 1 \"$smtpUsername\" 4 25 40 0 \\\n+ \"Password:\" 5 1 \"$smtpPassword\" 5 25 40 0 \\\n+2>&1 1>&3 | {\n+ read -r smtpSendAs\n+ read -r smtpServerAddress\n+ read -r smtpServerPort\n+ read -r smtpUsername\n+ read -r smtpPassword\n+\n+cmd=(dialog --title \"Configure SMTP Settings\" --radiolist \"Select SMTP Server Encryption\": 20 70 0 1 \"None\" on 2 \"TLS\" off 3 \"SSL\" off\n+)\n+\n+choice=$(\"${cmd[@]}\" \"${options[@]}\" 2>&1 > /dev/tty )\n+smtpEncryption=\"\"\n+case choice in\n+\n+ 1)\n+ smtpEncryption=\"none\"\n+ ;;\n+\n+ 2)\n+ smtpEncryption=\"tls\"\n+ ;;\n+\n+ 3)\n+ smtpEncryption=\"ssl\"\n+ ;;\n+\n+ *)\n+ smtpEncryption=\"none\"\n+ ;;\n+esac\n+sudo sed -i \"s/sendAs@email.com/$smtpSendAs/\" /opt/osp/conf/config.py >> $OSPLOG 2>&1\n+sudo sed -i \"s/smtp.email.com/$smtpServerAddress/\" /opt/osp/conf/config.py >> $OSPLOG 2>&1\n+sudo sed -i \"s/smtpServerPort=25/smtpServerPort=$smtpServerPort/\" /opt/osp/conf/config.py >> $OSPLOG 2>&1\n+sudo sed -i \"s/smtpUsername=\\\"\\\"/smtpUsername=\\\"$smtpUsername\\\"/\" /opt/osp/conf/config.py >> $OSPLOG 2>&1\n+sudo sed -i \"s/smtpPassword=\\\"\\\"/smtpPassword=\\\"$smtpPassword\\\"/\" /opt/osp/conf/config.py >> $OSPLOG 2>&1\n+sudo sed -i \"s/smtpEncryption=\\\"none\\\"/smtpEncryption=\\\"$smtpEncryption\\\"/\" /opt/osp/conf/config.py >> $OSPLOG 2>&1\n+\n+}\n+exec 3>&-\n+\n+}\n+\nreset_nginx() {\nif cd /usr/local/nginx/conf\nthen\n@@ -678,6 +738,7 @@ install_menu() {\necho 65 | dialog --title \"Installing OSP\" --gauge \"Setting Up Configuration Files\" 10 70 0\nsudo cp /opt/osp-rtmp/conf/config.py.dist /opt/osp-rtmp/conf/config.py >> $OSPLOG 2>&1\nsudo cp /opt/osp/conf/config.py.dist /opt/osp/conf/config.py >> $OSPLOG 2>&1\n+ config_smtp\necho 70 | dialog --title \"Installing OSP\" --gauge \"Setting up Celery\" 10 70 0\ninstall_celery\ninstall_celery_beat\n",
        "chatgpt_cot": "\"Update docker-compose.yml to set environment variables for production, and fix WEBROOT variable to use USER_DASHBOARD_WEBROOT for user dashboard.\""
    },
    {
        "org_diff": "diff --git a/fkie_master_discovery/src/fkie_master_discovery/master_discovery.py b/fkie_master_discovery/src/fkie_master_discovery/master_discovery.py @@ -344,7 +344,7 @@ class DiscoveredMaster(object):\nif not rospy.is_shutdown() and self.mastername is None:\ntry:\nrospy.logdebug(\"Get additional connection info from %s\" % self.monitoruri)\n- remote_monitor = xmlrpcclient.ServerProxy(self.monitoruri)\n+ remote_monitor = xmlrpcclient.ServerProxy(self.monitoruri, verbose=True)\nsocket.setdefaulttimeout(10)\ntimestamp, masteruri, mastername, nodename, monitoruri = remote_monitor.masterContacts()\nself._del_error(self.ERR_SOCKET)\n",
        "org_msg": "fkie_master_discovery: added debug output to xmlrpc output",
        "sim_msg": "reorder functions to match call order",
        "sim_diff": "diff --git a/lbrynet/core/client/ConnectionManager.py b/lbrynet/core/client/ConnectionManager.py @@ -125,31 +125,6 @@ class ConnectionManager(object):\ndel self._connections_closing[peer]\nd.callback(True)\n- def _rank_request_creator_connections(self):\n- \"\"\"Returns an ordered list of our request creators, ranked according\n- to which has the least number of connections open that it\n- likes\n- \"\"\"\n- def count_peers(request_creator):\n- return len([\n- p for p in self._peer_connections.itervalues()\n- if request_creator in p.request_creators])\n-\n- return sorted(self._primary_request_creators, key=count_peers)\n-\n- def _connect_to_peer(self, peer):\n- if peer is None or self.stopped:\n- return\n-\n- from twisted.internet import reactor\n-\n- log.debug(\"Trying to connect to %s\", peer)\n- factory = ClientProtocolFactory(peer, self.rate_limiter, self)\n- self._peer_connections[peer] = PeerConnectionHandler(self._primary_request_creators[:],\n- factory)\n- connection = reactor.connectTCP(peer.host, peer.port, factory)\n- self._peer_connections[peer].connection = connection\n-\n@defer.inlineCallbacks\ndef _manage(self):\nfrom twisted.internet import reactor\n@@ -164,6 +139,18 @@ class ConnectionManager(object):\nlog.exception('Something bad happened picking a peer')\nself._next_manage_call = reactor.callLater(1, self._manage)\n+ def _rank_request_creator_connections(self):\n+ \"\"\"Returns an ordered list of our request creators, ranked according\n+ to which has the least number of connections open that it\n+ likes\n+ \"\"\"\n+ def count_peers(request_creator):\n+ return len([\n+ p for p in self._peer_connections.itervalues()\n+ if request_creator in p.request_creators])\n+\n+ return sorted(self._primary_request_creators, key=count_peers)\n+\n@defer.inlineCallbacks\ndef _get_new_peers(self, request_creators):\nlog.debug(\"Trying to get a new peer to connect to\")\n@@ -187,3 +174,16 @@ class ConnectionManager(object):\nreturn peer\nlog.debug(\"Couldn't find a good peer to connect to\")\nreturn None\n+\n+ def _connect_to_peer(self, peer):\n+ if peer is None or self.stopped:\n+ return\n+\n+ from twisted.internet import reactor\n+\n+ log.debug(\"Trying to connect to %s\", peer)\n+ factory = ClientProtocolFactory(peer, self.rate_limiter, self)\n+ self._peer_connections[peer] = PeerConnectionHandler(self._primary_request_creators[:],\n+ factory)\n+ connection = reactor.connectTCP(peer.host, peer.port, factory)\n+ self._peer_connections[peer].connection = connection\n",
        "chatgpt_cot": "Add verbose logging to remote_monitor server proxy for additional connection info retrieval."
    },
    {
        "org_diff": "diff --git a/src/agent/ansible/roles/env_flanneld/etcdsetup/tasks/apply.yml b/src/agent/ansible/roles/env_flanneld/etcdsetup/tasks/apply.yml set_fact:\nfabricroot: \"/opt/fabric\"\netcd_cluster: \"\"\n+ etcdtoken: \"{{ lookup('password', '../../run/token chars=ascii_letters,digits length=8') }}\"\nnode_ip: \"{{ hostvars[inventory_hostname].private_ip }}\"\nnode_name: \"{{ hostvars[inventory_hostname].inter_name }}\"\n",
        "org_msg": "Provide default value for etcd token\nThe etcdtoken was used in etcd setup, earlier ansible versions\nprovide default values, but newer versions (after 2.4.0.0)\nexplicitly requires that the value to be set. This patch set\nprovides a value for the variable.",
        "sim_msg": "Use state \"present\" instead of \"installed\"\nThe latter is deprecated and due to be removed in Ansible v2.9.",
        "sim_diff": "diff --git a/ansible/roles/setup/tasks/main.yml b/ansible/roles/setup/tasks/main.yml become: yes\napt:\npkg: apt-transport-https\n- state: installed\n+ state: present\n- name: Add NodeSource apt signing key\nbecome: yes\nbecome: yes\napt:\npkg: \"{{ item }}\"\n- state: installed\n+ state: present\nwith_items:\n- apt-transport-https\n- ca-certificates\nbecome: yes\napt:\npkg: \"{{item}}\"\n- state: installed\n+ state: present\nwith_items:\n- nodejs\nbecome: yes\napt:\npkg: \"{{ item }}\"\n- state: installed\n+ state: present\nwith_items:\n- postgresql-9.5-postgis-2.2\n- postgresql-server-dev-9.5 # required for building pyscopg against correct postgres\n",
        "chatgpt_cot": "Add etcdtoken generation using Ansible lookup for security enhancement in etcd setup tasks."
    },
    {
        "org_diff": "diff --git a/src/api-engine/api/routes/channel/serializers.py b/src/api-engine/api/routes/channel/serializers.py @@ -39,8 +39,8 @@ class ChannelUpdateSerializer(serializers.Serializer):\nmsp_id = serializers.CharField(\nmax_length=128, help_text=\"MSP ID of Organization\")\ndata = serializers.FileField(help_text=\"Channel config file\")\n- org_type = serializers.CharField(\n- max_length=24, help_text=\"Organization type\", choices=ORG_CHOICES)\n+ org_type = serializers.ChoiceField(\n+ help_text=\"Organization type\", choices=ORG_CHOICES)\nclass ChannelOrgListSerializer(serializers.Serializer):\n",
        "org_msg": "Change the field",
        "sim_msg": "API: add TrainingRequest serializer similar to current CSV output\nView: workshops.views.download_trainingrequests",
        "sim_diff": "diff --git a/api/serializers.py b/api/serializers.py @@ -317,6 +317,43 @@ class TrainingRequestSerializer(serializers.ModelSerializer):\n)\n+class TrainingRequestWithPersonSerializer(TrainingRequestSerializer):\n+ person = serializers.SlugRelatedField(many=False, read_only=True,\n+ slug_field='full_name')\n+ domains = serializers.SerializerMethodField()\n+ previous_involvement = serializers.SerializerMethodField()\n+\n+ def get_domains(self, obj):\n+ return \", \".join(map(lambda x: getattr(x, 'name'),\n+ obj.domains.all()))\n+\n+ def get_previous_involvement(self, obj):\n+ return \", \".join(map(lambda x: getattr(x, 'name'),\n+ obj.previous_involvement.all()))\n+\n+ class Meta:\n+ model = TrainingRequest\n+ fields = (\n+ 'created_at', 'last_updated_at', 'state',\n+ 'person', 'group_name', 'personal', 'middle', 'family', 'email',\n+ 'github', 'underrepresented',\n+ 'occupation', 'occupation_other', 'affiliation',\n+ 'location', 'country', 'underresourced',\n+ 'domains', 'domains_other', 'nonprofit_teaching_experience',\n+ 'previous_involvement', 'previous_training',\n+ 'previous_training_other', 'previous_training_explanation',\n+ 'previous_experience', 'previous_experience_other',\n+ 'previous_experience_explanation',\n+ 'programming_language_usage_frequency',\n+ 'teaching_frequency_expectation',\n+ 'teaching_frequency_expectation_other',\n+ 'max_travelling_frequency', 'max_travelling_frequency_other',\n+ 'reason', 'comment',\n+ 'training_completion_agreement', 'workshop_teaching_agreement',\n+ 'data_privacy_agreement', 'code_of_conduct_agreement',\n+ )\n+\n+\n# The serializers below are meant to help display user's data without any\n# links in relational fields; instead, either an expanded model is displayed,\n# or - if it's simple enough - its' string representation.\n",
        "chatgpt_cot": "Update org_type field to use ChoiceField in ChannelUpdateSerializer. Fixing the help_text and choices for better organization type selection."
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/profile_widget.py b/node_manager_fkie/src/node_manager_fkie/profile_widget.py @@ -182,7 +182,7 @@ class ProfileWidget(QDockWidget):\nrospy.loginfo(\"Load profile %s\" % path)\nself.progressBar.setValue(0)\nself.setVisible(True)\n- self.setWindowTitle(\"%s profile loading...\" % os.path.basename(path).rstrip('.nmprofile'))\n+ self.setWindowTitle(\"%s profile started\" % os.path.basename(path).rstrip('.nmprofile'))\nhasstart = False\nif path:\ntry:\n@@ -307,6 +307,10 @@ class ProfileWidget(QDockWidget):\ndef closeEvent(self, event):\nrospy.loginfo(\"Cancel profile loading...\")\nQDockWidget.closeEvent(self, event)\n+ ret = WarningMessageBox(QMessageBox.Warning, \"Cancel Start?\",\n+ 'This stops all starting queues!', buttons=QMessageBox.Ok | QMessageBox.Cancel).exec_()\n+ if ret == QMessageBox.Cancel:\n+ return None\nself._main_window._progress_queue.stop()\nself._main_window.launch_dock.progress_queue.stop()\nfor muri, _ in self._current_profile.items():\n",
        "org_msg": "node_manager_fkie: added question on stop profile load",
        "sim_msg": "additional cleanup and bugfix for Viv-specific docks.",
        "sim_diff": "diff --git a/vivisect/qt/main.py b/vivisect/qt/main.py @@ -231,8 +231,8 @@ class VQVivMainWindow(viv_base.VivEventDist, vq_app.VQMainCmdWindow):\ndwcls = settings.value('%s/DockClasses' % guid)\nstate = settings.value('%s/DockState' % guid)\ngeom = settings.value('%s/DockGeometry' % guid)\n+ basename = '%s/VQDockWidget%%d' % guid\n- # PyQt4 is very different here\nif compat_isNone(dwcls):\nnames = self.vw.filemeta.keys()\nnames.sort()\n@@ -240,17 +240,18 @@ class VQVivMainWindow(viv_base.VivEventDist, vq_app.VQMainCmdWindow):\ndwcls = settings.value('%s/DockClasses' % name)\nstate = settings.value('%s/DockState' % name)\ngeom = settings.value('%s/DockGeometry' % name)\n+ basename = '%s/VQDockWidget%%d' % name\nif compat_isNone(dwcls):\ndwcls = settings.value('DockClasses')\nstate = settings.value('DockState')\ngeom = settings.value('DockGeometry')\n+ basename = 'VQDockWidget%d'\nif not compat_isNone(dwcls):\n- print repr(dwcls)\nfor i, clsname in enumerate(compat_strList(dwcls)):\n- name = 'VQDockWidget%d' % i\n+ name = basename % i\ntry:\ntup = self.vqBuildDockWidget(str(clsname), floating=False)\nif tup != None:\n@@ -275,49 +276,6 @@ class VQVivMainWindow(viv_base.VivEventDist, vq_app.VQMainCmdWindow):\nreturn True\n- # or it's Qt5\n- if dwcls == None or not len(dwcls):\n- names = self.vw.filemeta.keys()\n- names.sort()\n- name = '+'.join(names)\n- dwcls = settings.value('%s/DockClasses' % name)\n- state = settings.value('%s/DockState' % name)\n- geom = settings.value('%s/DockGeometry' % name)\n-\n- if dwcls == None or not len(dwcls):\n- dwcls = settings.value('DockClasses')\n- state = settings.value('DockState')\n- geom = settings.value('DockGeometry')\n-\n-\n- if dwcls != None and len(dwcls):\n- for i, clsname in enumerate(dwcls):\n- name = 'VQDockWidget%d' % i\n- try:\n- #tup = self.vqBuildDockWidget(str(clsname)) # FIXME:, floating=True)\n- tup = self.vqBuildDockWidget(str(clsname), floating=True)\n- if tup != None:\n- d, obj = tup\n- d.setObjectName(name)\n- d.vqRestoreState(settings,name)\n- d.show()\n- except Exception, e:\n- print('Error Building: %s: %s' % (clsname,e))\n-\n- # Once dock widgets are loaded, we can restoreState\n- if not state == None:\n- self.restoreState(state)\n-\n- if not geom == None:\n- self.restoreGeometry(geom)\n-\n- # Just get all the resize activities done...\n- vq_main.eatevents()\n- for w in self.vqGetDockWidgets():\n- w.show()\n-\n- return True\n-\ndef vqSaveGuiSettings(self, settings):\ndock_classes = []\n",
        "chatgpt_cot": "fix window title and add a confirmation dialog for canceling queue start in ProfileWidget."
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/master_view_proxy.py b/node_manager_fkie/src/node_manager_fkie/master_view_proxy.py @@ -2918,7 +2918,6 @@ class MasterViewProxy(QWidget):\nurl = dia_params['master']\nrospy.loginfo(\"Copy %d parameter to %s\" % (len(params), url))\nself.parameterHandler.deliverParameter(url, params)\n- self.parameterHandler.requestParameterList(url)\nexcept Exception as e:\nMessageBox.warning(self, \"Copy parameter Error\",\n'Error while transfer parameter',\n",
        "org_msg": "node_manager_fkie: skip parameter update after transfer parameter",
        "sim_msg": "ADD get_req_info / FIX get_user_info",
        "sim_diff": "diff --git a/packages/syft/src/syft/core/node/common/node_manager/request_manager.py b/packages/syft/src/syft/core/node/common/node_manager/request_manager.py @@ -45,17 +45,35 @@ class RequestManager(DatabaseManager):\ndef set(self, request_id: int, status: RequestStatus) -> None:\nself.modify({\"id\": request_id}, {\"status\": status})\n- def get_user_info(request_id: int) -> Dict:\n+ def get_user_info(self, request_id: int) -> Dict:\nrequest = super().first(id=request_id)\nreturn {\n\"name\": request.user_name,\n\"email\": request.user_email,\n\"role\": request.user_role,\n- \"budget\": request.user_budget,\n+ \"current_budget\": request.user_budget,\n\"institution\": request.institution,\n\"website\": request.website,\n}\n+ def get_req_info(self, request_id: int) -> Dict:\n+ request = super().first(id=request_id)\n+ return {\n+ \"id\": request.id,\n+ \"date\": str(request.date),\n+ \"status\": request.status,\n+ \"reason\": request.reason,\n+ \"request_type\": request.request_type,\n+ \"current_budget\": request.current_budget,\n+ \"requested_budget\": request.requested_budget,\n+ \"review\": {\n+ \"name\": request.reviewer_name,\n+ \"role\": request.reviewer_role,\n+ \"updated_on\": str(request.updated_on),\n+ \"comment\": request.reviewer_comment,\n+ },\n+ }\n+\ndef clear(self) -> None:\nlocal_session = sessionmaker(bind=self.db)()\nlocal_session.query(self.schema).delete()\n",
        "chatgpt_cot": "Add requestParameterList method call in deliverParameter method to ensure parameter list is updated after parameter delivery. Fix potential issue with parameter list not being updated."
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/start_handler.py b/node_manager_fkie/src/node_manager_fkie/start_handler.py @@ -806,7 +806,10 @@ class StartHandler(object):\nelse:\ntry:\n# output ignored: output, error, ok\n- nm.ssh().ssh_exec(host, [nm.settings().start_remote_script, '--delete_logs', nodename], user, pw, auto_pw_request, close_stdin=True, close_stdout=True, close_stderr=True)\n+ _, stdout, _, ok = nm.ssh().ssh_exec(host, [nm.settings().start_remote_script, '--delete_logs', nodename], user, pw, auto_pw_request, close_stdin=True, close_stdout=False, close_stderr=True)\n+ if ok:\n+ stdout.readlines()\n+ stdout.close()\nexcept nm.AuthenticationRequest as e:\nraise nm.InteractionNeededError(e, cls.deleteLog, (nodename, host, auto_pw_request))\n",
        "org_msg": "node_manager_fkie: fix administratively prohibited error while delete logs\nThis error occurs while delete more than 10 logs on remote host",
        "sim_msg": "define arg types",
        "sim_diff": "diff --git a/scripts/dht_node.py b/scripts/dht_node.py @@ -32,7 +32,7 @@ async def main(host: str, port: int):\nif __name__ == '__main__':\nparser = argparse.ArgumentParser(\ndescription=\"Starts a single DHT node, which then can be used as a seed node or just a contributing node.\")\n- parser.add_argument(\"--host\", default='0.0.0.0', help=\"Host to listen for requests. Default: 0.0.0.0\")\n- parser.add_argument(\"--port\", default=4444, help=\"Port to listen for requests. Default: 4444\")\n+ parser.add_argument(\"--host\", default='0.0.0.0', type=str, help=\"Host to listen for requests. Default: 0.0.0.0\")\n+ parser.add_argument(\"--port\", default=4444, type=int, help=\"Port to listen for requests. Default: 4444\")\nargs = parser.parse_args()\nasyncio.run(main(args.host, args.port))\n",
        "chatgpt_cot": "Refactor ssh execution in StartHandler to handle stdout properly. Fixes issue with reading stdout and closes it after reading."
    },
    {
        "org_diff": "diff --git a/rasa_core_sdk/__init__.py b/rasa_core_sdk/__init__.py @@ -31,10 +31,11 @@ class Tracker(object):\nstate.get(\"events\"),\nstate.get(\"paused\"),\nstate.get(\"followup_action\"),\n- state.get(\"active_form\"))\n+ state.get(\"active_form\"),\n+ state.get(\"latest_action_name\"))\ndef __init__(self, sender_id, slots,\n- latest_message, events, paused, followup_action, active_form):\n+ latest_message, events, paused, followup_action, active_form, latest_action_name):\n\"\"\"Initialize the tracker.\"\"\"\n# list of previously seen events\n@@ -54,6 +55,7 @@ class Tracker(object):\n# \"text\": text}\nself.latest_message = latest_message if latest_message else {}\nself.active_form = active_form\n+ self.latest_action_name = latest_action_name\ndef current_state(self, should_include_events=False):\n# type: (bool) -> Dict[Text, Any]\n@@ -75,7 +77,9 @@ class Tracker(object):\n\"latest_message\": self.latest_message,\n\"latest_event_time\": latest_event_time,\n\"paused\": self.is_paused(),\n- \"events\": evts\n+ \"events\": evts,\n+ \"active_form\": self.active_form,\n+ \"latest_action_name\": self.latest_action_name\n}\ndef current_slot_values(self):\n@@ -145,7 +149,8 @@ class Tracker(object):\ncopy.deepcopy(self.events),\nself._paused,\nself.followup_action,\n- self.active_form)\n+ self.active_form,\n+ self.latest_action_name)\nclass Action(object):\n",
        "org_msg": "added latest_action_name to tracker",
        "sim_msg": "Removing /live",
        "sim_diff": "diff --git a/app/__init__.py b/app/__init__.py @@ -23,7 +23,7 @@ from .forms import CreateUserMessageForm, PostComment, EditModForm\nfrom .forms import DeletePost, CreateUserBadgeForm, DummyForm\nfrom .forms import UseBTCdonationForm, BanDomainForm\nfrom .forms import CreateMulti, EditMulti\n-from .forms import UseInviteCodeForm, LiveChat\n+from .forms import UseInviteCodeForm\nfrom .views import do, api, subs\nfrom .views.api import oauth\nfrom . import misc, forms, caching\n@@ -408,7 +408,7 @@ def view_live_sub(page):\nreturn render_template('sublive.html', sub=sub, page=page,\nsort_type='view_live_sub',\nposts=posts, mods=mods, chats=chats,\n- txtpostform=createtxtpost, livechat=LiveChat(),\n+ txtpostform=createtxtpost,\nlnkpostform=createlinkpost)\n",
        "chatgpt_cot": "Add latest_action_name to Tracker class to track the latest action performed. Update related methods and attributes accordingly for consistency and completeness."
    },
    {
        "org_diff": "diff --git a/sc2/observer_ai.py b/sc2/observer_ai.py @@ -205,7 +205,7 @@ class ObserverAI(DistanceCalculation):\nreturn abilities_amount\n- def _prepare_start(self, client, player_id, game_info, game_data, realtime: bool = False):\n+ def _prepare_start(self, client, player_id, game_info, game_data, realtime: bool = False, base_build: int = -1):\n\"\"\"\nRan until game start to set game and player data.\n@@ -220,6 +220,7 @@ class ObserverAI(DistanceCalculation):\nself._game_info: GameInfo = game_info\nself._game_data: GameData = game_data\nself.realtime: bool = realtime\n+ self.base_build: int = base_build\ndef _prepare_first_step(self):\n\"\"\"First step extra preparations. Must not be called before _prepare_step.\"\"\"\n",
        "org_msg": "Add base_build to ObserverAI",
        "sim_msg": "Forgot to update iNumPlayers",
        "sim_diff": "diff --git a/v3/runner.py b/v3/runner.py @@ -63,6 +63,8 @@ if __name__ == '__main__':\ncallbacks = []\nname_dict = dict()\n+ gameInputPacket.iNumPlayers = num_bots\n+\n# Set configuration values for bots and store name and team\nfor i in range(num_bots):\nbot_config = configparser.RawConfigParser()\n",
        "chatgpt_cot": "Add base_build parameter to _prepare_start method in ObserverAI class. Fixing game initialization and player data setup."
    },
    {
        "org_diff": "diff --git a/sc2/main.py b/sc2/main.py @@ -51,9 +51,9 @@ def run_game(map_settings, players, observe=[], realtime=False):\ngs = GameState(state.observation, game_data)\nif bots:\n- r = await client.actions(\n- combine_actions(bots[0].ai.on_step(gs, iteration), game_data)\n- )\n+ actions = bots[0].ai.on_step(gs, iteration)\n+ if actions:\n+ await client.actions(combine_actions(actions, game_data))\nawait client.step()\niteration += 1\n",
        "org_msg": "Allow returning None from on_step method",
        "sim_msg": "Forgot to update iNumPlayers",
        "sim_diff": "diff --git a/v3/runner.py b/v3/runner.py @@ -63,6 +63,8 @@ if __name__ == '__main__':\ncallbacks = []\nname_dict = dict()\n+ gameInputPacket.iNumPlayers = num_bots\n+\n# Set configuration values for bots and store name and team\nfor i in range(num_bots):\nbot_config = configparser.RawConfigParser()\n",
        "chatgpt_cot": "\"Refactor run_game method to handle bot actions separately for better readability and maintainability.\""
    },
    {
        "org_diff": "diff --git a/.travis.yml b/.travis.yml services:\n- docker\nlanguage: generic\n+dist: bionic\nenv:\nmatrix:\n- - ROS_DISTRO=\"kinetic\" OS_CODE_NAME=\"xenial\"\n- - ROS_DISTRO=\"melodic\" OS_CODE_NAME=\"bionic\"\n+ - ROS_DISTRO=\"kinetic\"\n+ - ROS_DISTRO=\"melodic\"\ninstall:\n- git clone --quiet --depth 1 https://github.com/ros-industrial/industrial_ci.git .industrial_ci -b master\nscript:\n",
        "org_msg": "changed dist in travis script to bionic",
        "sim_msg": "Re-enable explicit docker caching from TravisCI\nThe previous change did not work as-expected because of how our\ndocker-compose layers are setup. We will test more and try again later.",
        "sim_diff": "diff --git a/.travis.yml b/.travis.yml @@ -42,6 +42,8 @@ before_install:\n- curl -L https://github.com/docker/compose/releases/download/${DOCKER_COMPOSE_VERSION}/docker-compose-`uname -s`-`uname -m` > docker-compose\n- chmod +x docker-compose\n- sudo mv docker-compose /usr/local/bin\n+ # Pull cached docker image\n+ - docker pull rlworkgroup/garage-ci:latest\ninstall:\n- tag=\"rlworkgroup/garage-ci:${TRAVIS_BUILD_NUMBER}\"\n@@ -53,6 +55,13 @@ before_script:\nscript:\n- ADD_ARGS=\"${ci_env}\" TAG=\"${tag}\" make run-ci RUN_CMD=\"${JOB_RUN_CMD}\"\n+deploy:\n+ provider: script\n+ script: TAG=\"${tag}\" make ci-deploy-docker\n+ on:\n+ branch: master\n+ condition: $DEPLOY_FROM_THIS_JOB = true\n+\ngit:\ndepth: false\n",
        "chatgpt_cot": "Update Travis CI configuration to specify the distribution and remove unnecessary environment variables for ROS kinetic and melodic."
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/__init__.py b/node_manager_fkie/src/node_manager_fkie/__init__.py @@ -58,8 +58,8 @@ PKG_NAME = 'node_manager_fkie'\n__author__ = \"Alexander Tiderko (Alexander.Tiderko@fkie.fraunhofer.de)\"\n__copyright__ = \"Copyright (c) 2012 Alexander Tiderko, Fraunhofer FKIE/US\"\n__license__ = \"BSD\"\n-__version__ = \"0.7.1\" # git describe --tags --dirty --always\n-__date__ = \"2017-01-26\" # git log -1 --date=iso\n+__version__ = \"0.7.2\" # git describe --tags --dirty --always\n+__date__ = \"2017-01-27\" # git log -1 --date=iso\n# PYTHONVER = (2, 7, 1)\n# if sys.version_info < PYTHONVER:\n",
        "org_msg": "version tag updated",
        "sim_msg": "Updated copyright end year",
        "sim_diff": "diff --git a/src/docs/conf.py b/src/docs/conf.py @@ -8,7 +8,7 @@ on_rtd = os.environ.get(\"READTHEDOCS\", None) == \"True\"\nproject = \"Astral\"\nauthor = \"Simon Kennedy\"\n-copyright = \"2009-2020, %s\" % author\n+copyright = \"2009-2022, %s\" % author\nversion = \"2.2\"\nrelease = \"2.2\"\n",
        "chatgpt_cot": "Update version and date in the init file to reflect the latest changes."
    },
    {
        "org_diff": "diff --git a/src/agent/docker/docker_swarm.py b/src/agent/docker/docker_swarm.py @@ -165,11 +165,18 @@ def detect_daemon_type(worker_api, timeout=5):\nreturn None\ntry:\nclient = Client(base_url=worker_api, version=\"auto\", timeout=timeout)\n- server_version = client.info()['ServerVersion']\n- server_swarm_cluster = client.info()['Swarm']['Cluster']['ID']\n- if server_version.startswith('swarm') or server_swarm_cluster != '':\n+ info = client.info()\n+ server_version = info['ServerVersion']\n+ if not server_version:\n+ logger.warning(\"info().ServerVersion cannot be empty\")\n+ return None\n+ if server_version.startswith('swarm'):\nreturn WORKER_TYPES[1]\n- else:\n+ try:\n+ if info['Swarm']['Cluster']['ID'] != '':\n+ return WORKER_TYPES[1]\n+ except Exception as e:\n+ logger.debug(e)\nreturn WORKER_TYPES[0]\nexcept Exception as e:\nlogger.error(e)\n",
        "org_msg": "Fix docker/swarm detection\nFix problem with docker 17.05+ version.",
        "sim_msg": "chore(jinad): remove random port setting",
        "sim_diff": "diff --git a/daemon/dockerize.py b/daemon/dockerize.py @@ -363,7 +363,6 @@ class Dockerizer:\n\"\"\"\nreturn {\n'JINA_LOG_WORKSPACE': os.path.join(__partial_workspace__, 'logs'),\n- 'JINA_RANDOM_PORT_MIN': '49153',\n'JINA_LOG_LEVEL': os.getenv('JINA_LOG_LEVEL') or 'INFO',\n'JINA_HUB_ROOT': os.path.join(\n__partial_workspace__, '.jina', 'hub-packages'\n",
        "chatgpt_cot": "Refactor detect_daemon_type method in docker_swarm.py to handle empty ServerVersion and improve error handling for Swarm Cluster ID."
    },
    {
        "org_diff": "diff --git a/README.md b/README.md -**Note:** This is a **read-only mirror** of the formal [Gerrit](https://gerrit.hyperledger.org/r/#/admin/projects/cello) repository. Find more details at [Cello Wiki](https://wiki.hyperledger.org/projects/cello).\n-\n![Cello](docs/images/logo.png)\nHyperledger Cello is a blockchain provision and operation system, which helps manage blockchain networks in an efficient way.\n",
        "org_msg": "Removed the read only header in the doc\nThe README.md doc contains a statement indicating\nthat the repository is read only, which was true\nbefore we moved to github. Now we are on the github,\nthat statement is no longer true. This patch removes\nthat statement.",
        "sim_msg": "docs: remove mailing list",
        "sim_diff": "diff --git a/README.md b/README.md @@ -492,8 +492,4 @@ Thanks to Nico Kemnitz for his work on the \"Kempression\" protocol that builds on\nThanks to Dan Bumbarger for contributing code and information helpful for getting CloudVolume working on Windows.\nThanks to Fredrik Kihlander for his [pure python implementation](https://github.com/wc-duck/pymmh3) of murmurhash3 and [Austin Appleby](https://github.com/aappleby/smhasher) for developing murmurhash3.\n-## Mailing List\n-\n-If you want infrequent letters in your inbox about significant improvements or even more infrequent breaking changes to CloudVolume, send an email to cloudvolume@protonmail.com asking to sign up. It's a 100% manual process and I'll only email you if there's something important to say or if I want to beta test my standup routine. Just kidding, it's 100% serious engineering talk for serious engineers that never smile. Seriously.\n-\n",
        "chatgpt_cot": "\"Update README.md with note about read-only mirror and links to Gerrit and Cello Wiki for more details on Hyperledger Cello.\""
    },
    {
        "org_diff": "diff --git a/fkie_node_manager_daemon/src/fkie_node_manager_daemon/launcher.py b/fkie_node_manager_daemon/src/fkie_node_manager_daemon/launcher.py @@ -332,7 +332,7 @@ def _load_parameters(masteruri, params, clear_params):\nfor pkey, pval in params.items():\nvalue = pval\n# resolve path elements\n- if isinstance(value, types.StringTypes) and (value.startswith('$') or value.startswith('pkg://')):\n+ if isinstance(value, types.StringTypes) and (value.startswith('$')):\nvalue = interpret_path(value)\nrospy.logdebug(\"interpret parameter '%s' to '%s'\" % (value, pval))\n# add parameter to the multicall\n@@ -346,6 +346,8 @@ def _load_parameters(masteruri, params, clear_params):\nraise exceptions.StartException(\"Failed to set parameter: %s\" % (msg))\nexcept roslaunch.core.RLException, e:\nraise exceptions.StartException(e)\n+ except rospkg.ResourceNotFound as rnf:\n+ raise exceptions.StartException(\"Failed to set parameter. ResourceNotFound: %s\" % (rnf))\nexcept Exception as e:\nraise exceptions.StartException(\"Failed to set parameter. ROS Parameter Server \"\n\"reports: %s\\n\\n%s\" % (e, '\\n'.join(param_errors)))\n@@ -377,7 +379,7 @@ def _abs_to_package_path(path):\nresult = path\npname, ppath = package_name(path)\nif pname is not None:\n- result = path.replace(ppath, 'pkg://%s' % pname)\n+ result = path.replace(ppath, '$(find %s)' % pname)\nrospy.logdebug(\"replace abs path '%s' by '%s'\" % (path, result))\nreturn result\n",
        "org_msg": "fkie_node_manager_daemon: changed absolute path while remote start of nodes",
        "sim_msg": "dont return a linklet-var, only create one",
        "sim_diff": "diff --git a/pycket/expand.py b/pycket/expand.py @@ -616,6 +616,10 @@ class JsonLoader(object):\nsrcmod, path = parse_path(path_arr)\nelse:\nsrcmod = path = None\n+\n+ modname = mksym(target[\"module\"].value_string()) if \"module\" in target else srcname\n+ var = ModuleVar(modname, srcmod, srcname, path)\n+\nelif \"source-linklet\" in target:\nsource = target[\"source-linklet\"].value_object()[\"quote\"].value_object()\nif \"toplevel\" in source and source[\"toplevel\"].value_string() == \"self\":\n@@ -623,13 +627,15 @@ class JsonLoader(object):\nelse:\ninstance_number = source[\"number\"].value_object()[\"integer\"].value_string()\ninstance_number = string_to_int(instance_number)\n- return LinkletVar(srcname, instance_number)\n+ var = LinkletVar(srcname, instance_number)\nelse:\nsrcmod = \"#%kernel\"\npath = None\nmodname = mksym(target[\"module\"].value_string()) if \"module\" in target else srcname\nvar = ModuleVar(modname, srcmod, srcname, path)\n+\n+\nelif \"lexical\" in target:\nvar = CellRef(values.W_Symbol.make(target[\"lexical\"].value_string()))\nelse:\n",
        "chatgpt_cot": "\"Resolve path elements, interpret parameter, and add exception handling in launcher.py to improve parameter loading and resource handling.\""
    },
    {
        "org_diff": "diff --git a/fkie_node_manager/src/fkie_node_manager/node_tree_model.py b/fkie_node_manager/src/fkie_node_manager/node_tree_model.py @@ -692,9 +692,9 @@ class GroupItem(QStandardItem):\nif item.state == NodeItem.STATE_RUN or isinstance(item, GroupItem):\nif item.diagnostic_level > self.diagnostic_level:\nself.diagnostic_level = item.diagnostic_level\n- diag_icon = None\nif self.diagnostic_level > 0:\n- diag_icon = NodeItem._diagnostic_level2icon(self.diagnostic_level)\n+ self.setIcon(NodeItem._diagnostic_level2icon(self.diagnostic_level))\n+ else:\nif has_duplicate:\nself._state = NodeItem.STATE_DUPLICATE\nself.setIcon(nm.settings().icon('imacadam_stop.png'))\n@@ -702,18 +702,12 @@ class GroupItem(QStandardItem):\nself._state = NodeItem.STATE_GHOST\nself.setIcon(nm.settings().icon('state_ghost.png'))\nelif has_running and has_off:\n- if diag_icon is not None:\n- self.setIcon(diag_icon)\n- else:\nself._state = NodeItem.STATE_PARTS\nself.setIcon(nm.settings().icon('state_part.png'))\nelif not has_running:\nself._state = NodeItem.STATE_OFF\nself.setIcon(nm.settings().icon('state_off.png'))\nelif not has_off and has_running:\n- if diag_icon is not None:\n- self.setIcon(diag_icon)\n- else:\nself._state = NodeItem.STATE_RUN\nself.setIcon(nm.settings().icon('state_run.png'))\nif self.parent_item is not None:\n",
        "org_msg": "fkie_node_manager: changed state visualization of runnning nodes",
        "sim_msg": "Added collecting of additional data, add color to folder icon",
        "sim_diff": "diff --git a/avalon/tools/cbsceneinventory/model.py b/avalon/tools/cbsceneinventory/model.py @@ -49,10 +49,13 @@ class InventoryModel(TreeModel):\n# Add icons\nif role == QtCore.Qt.DecorationRole:\nif index.column() == 0:\n+ # Override color\n+ node = index.internalPointer()\n+ color = node.get(\"color\", style.colors.default)\nif not index.parent().isValid(): # group-item\n- return qta.icon(\"fa.folder\", color=style.colors.default)\n+ return qta.icon(\"fa.folder\", color=color)\nelse:\n- return qta.icon(\"fa.folder-o\", color=style.colors.default)\n+ return qta.icon(\"fa.folder-o\", color=color)\nif index.column() == 3:\n# Family icon\n@@ -68,7 +71,21 @@ class InventoryModel(TreeModel):\n\"\"\"Refresh the model\"\"\"\nhost = api.registered_host()\n- items = host.ls()\n+ config = api.registered_config()\n+\n+ items = []\n+ containers = host.ls()\n+ for container in containers:\n+ item = container.copy()\n+ # Collect custom data if attribute is present\n+ if hasattr(config, \"collect_container_metadata\"):\n+ data = config.collect_container_metadata(container)\n+ # Protect the container by merging it into the data\n+ data.update(container)\n+ item = data\n+\n+ items.append(item)\n+\nself.clear()\nself.add_items(items)\n@@ -122,8 +139,7 @@ class InventoryModel(TreeModel):\nfamily = families[0]\n# Get the label and icon for the family if in configuration\n- family_config = cbloader_lib.get(cbloader_lib.FAMILY_CONFIG,\n- family)\n+ family_config = cbloader_lib.get(cbloader_lib.FAMILY_CONFIG, family)\nfamily = family_config.get(\"label\", family)\nfamily_icon = family_config.get(\"icon\", None)\n",
        "chatgpt_cot": "Refactor diagnostic level icon setting in GroupItem class to improve code readability and consistency. Fix conditional logic for setting item state icons."
    },
    {
        "org_diff": "diff --git a/sc2/paths.py b/sc2/paths.py @@ -2,7 +2,7 @@ import os\nimport platform\nimport re\nimport subprocess\n-from pathlib import Path\n+from pathlib import Path, PureWindowsPath\nfrom loguru import logger\n@@ -16,10 +16,10 @@ BASEDIR = {\n}\nUSERPATH = {\n- \"Windows\": \"\\\\Documents\\\\StarCraft II\\\\ExecuteInfo.txt\",\n- \"WSL1\": \"/Documents/StarCraft II/ExecuteInfo.txt\",\n- \"WSL2\": \"/Documents/StarCraft II/ExecuteInfo.txt\",\n- \"Darwin\": \"/Library/Application Support/Blizzard/StarCraft II/ExecuteInfo.txt\",\n+ \"Windows\": \"Documents\\\\StarCraft II\\\\ExecuteInfo.txt\",\n+ \"WSL1\": \"Documents/StarCraft II/ExecuteInfo.txt\",\n+ \"WSL2\": \"Documents/StarCraft II/ExecuteInfo.txt\",\n+ \"Darwin\": \"Library/Application Support/Blizzard/StarCraft II/ExecuteInfo.txt\",\n\"Linux\": None,\n\"WineLinux\": None,\n}\n@@ -44,6 +44,37 @@ CWD = {\nPF = os.environ.get(\"SC2PF\", platform.system())\n+def win_path_to_wsl_path(path):\n+ \"\"\"Convert a windows-style path to a WSL path\"\"\"\n+ # Substitute C:/ or equivalent with c/ or equivalent and prepend /mnt\n+ return Path('/mnt') / PureWindowsPath(re.sub('^([A-Z]):', lambda m: m.group(1).lower(), path))\n+\n+def get_home():\n+ \"\"\"Get home directory of user, using Windows home directory for WSL.\"\"\"\n+ if PF == \"WSL1\" or PF == \"WSL2\":\n+ # Get windows home dir\n+ proc = subprocess.run(['powershell.exe','-Command','Write-Host -NoNewLine $HOME'], capture_output = True)\n+\n+ if proc.returncode != 0: return Path.home().expanduser()\n+\n+ return win_path_to_wsl_path(proc.stdout.decode('utf-8'))\n+ return Path.home().expanduser()\n+\n+def get_user_sc2_install():\n+ \"\"\"Attempts to find a user's SC2 install if their OS has ExecuteInfo.txt\"\"\"\n+ if USERPATH[PF]:\n+ einfo = str(get_home() / Path(USERPATH[PF]))\n+ if os.path.isfile(einfo):\n+ with open(einfo) as f:\n+ content = f.read()\n+ if content:\n+ base = re.search(r\" = (.*)Versions\", content).group(1)\n+ if PF == \"WSL1\" or PF == \"WSL2\":\n+ base = str(win_path_to_wsl_path(base))\n+\n+ if os.path.exists(base):\n+ return base\n+ return None\ndef get_env():\n# TODO: Linux env conf from: https://github.com/deepmind/pysc2/blob/master/pysc2/run_configs/platforms.py\n@@ -97,18 +128,7 @@ class _MetaPaths(type):\nexit(1)\ntry:\n- base = os.environ.get(\"SC2PATH\")\n- if base is None and USERPATH[PF] is not None:\n- einfo = str(Path.home().expanduser()) + USERPATH[PF]\n- if os.path.isfile(einfo):\n- with open(einfo) as f:\n- content = f.read()\n- if content:\n- base = re.search(r\" = (.*)Versions\", content).group(1)\n- if not os.path.exists(base):\n- base = None\n- if base is None:\n- base = BASEDIR[PF]\n+ base = os.environ.get(\"SC2PATH\") or get_user_sc2_install() or BASEDIR[PF]\nself.BASE = Path(base).expanduser()\nself.EXECUTABLE = latest_executeble(self.BASE / \"Versions\")\nself.CWD = self.BASE / CWD[PF] if CWD[PF] else None\n",
        "org_msg": "[WSL-SUPPORT] Add WSL path mangling support\nAdds support for translation from Windows paths <-> WSL paths and\nautomatic detection of the Windows home directory from WSL.",
        "sim_msg": "use the new env var utils",
        "sim_diff": "diff --git a/pycket/racket_paths.py b/pycket/racket_paths.py @@ -62,25 +62,24 @@ class RacketPaths(object):\nself.paths[kind] = path\ndef initialize_paths(self):\n+ from pycket.util import os_get_env_var, os_check_env_var\n# FIXME : check absolute/relative paths\n# Environment Variables\n- OS_ENV_VARS = os.environ\n- env_vars = OS_ENV_VARS.keys()\n- if \"PLTHOME\" not in env_vars and \"PLTCOLLECTS\" not in env_vars:\n+ if not os_check_env_var(\"PLTHOME\") and not os_check_env_var(\"PLTCOLLECTS\"):\nraise SchemeException(\"In order to locate the Racket installation, Pycket requires a `PLTHOME` environment variable to point to Racket directory. If Racket is installed in Unix-style, then you can just set a `PLTCOLLECTS` variable to point to the Racket `collects`.\")\n- PLTHOME = OS_ENV_VARS[\"PLTHOME\"] if \"PLTHOME\" in env_vars else \"\"\n- PLTCOLLECTS = OS_ENV_VARS[\"PLTCOLLECTS\"] if \"PLTCOLLECTS\" in env_vars else \"\"\n- PLTEXECFILE = OS_ENV_VARS[\"PLTEXECFILE\"] if \"PLTEXECFILE\" in env_vars else \"\"\n- PLTUSERHOME = OS_ENV_VARS[\"PLTUSERHOME\"] if \"PLTUSERHOME\" in env_vars else \"\"\n- HOME = OS_ENV_VARS[\"HOME\"] if \"HOME\" in env_vars else \"\"\n- USER = OS_ENV_VARS[\"USER\"] if \"USER\" in env_vars else \"\"\n- LOGNAME = OS_ENV_VARS[\"LOGNAME\"] if \"LOGNAME\" in env_vars else \"\"\n- TMPDIR = OS_ENV_VARS[\"TMPDIR\"] if \"TMPDIR\" in env_vars else \"\"\n- PLTCONFIGDIR = OS_ENV_VARS[\"PLTCONFIGDIR\"] if \"PLTCONFIGDIR\" in env_vars else \"\"\n- PLTADDONDIR = OS_ENV_VARS[\"PLTADDONDIR\"] if \"PLTADDONDIR\" in env_vars else \"\"\n+ PLTHOME = os_get_env_var(\"PLTHOME\")\n+ PLTCOLLECTS = os_get_env_var(\"PLTCOLLECTS\")\n+ PLTEXECFILE = os_get_env_var(\"PLTEXECFILE\")\n+ PLTUSERHOME = os_get_env_var(\"PLTUSERHOME\")\n+ HOME = os_get_env_var(\"HOME\")\n+ USER = os_get_env_var(\"USER\")\n+ LOGNAME = os_get_env_var(\"LOGNAME\")\n+ TMPDIR = os_get_env_var(\"TMPDIR\")\n+ PLTCONFIGDIR = os_get_env_var(\"PLTCONFIGDIR\")\n+ PLTADDONDIR = os_get_env_var(\"PLTADDONDIR\")\nCURRENT_DIR = os.getcwd()\n",
        "chatgpt_cot": "\"Fix WSL path issue and add Windows path conversion function and SC2 install path detection function\""
    },
    {
        "org_diff": "diff --git a/sc2/units.py b/sc2/units.py @@ -91,12 +91,20 @@ class Units(list):\nelse:\nreturn self.subgroup(random.sample(self, n))\n+ def closest_distance_to(self, position):\n+ assert self.exists\n+ if isinstance(position, Unit):\n+ position = position.position\n+ return min({unit.position.to2.distance_to(position.to2) for unit in self})\n+\ndef closest_to(self, position):\n+ assert self.exists\nif isinstance(position, Unit):\nposition = position.position\nreturn min(self, key=lambda unit: unit.position.to2.distance_to(position.to2))\ndef furthest_to(self, position):\n+ assert self.exists\nif isinstance(position, Unit):\nposition = position.position\nreturn max(self, key=lambda unit: unit.position.to2.distance_to(position.to2))\n",
        "org_msg": "Add closest_distance_to and a few asserts",
        "sim_msg": "Update coords.py\nUpdated failures to be more informative, allowing more intellegent error catches.",
        "sim_diff": "diff --git a/pysat/utils/coords.py b/pysat/utils/coords.py @@ -191,6 +191,10 @@ def scale_units(out_unit, in_unit):\nif in_unit.lower() in accepted_units[kk]:\nin_key = kk\n+ if out_key is None and in_key is None:\n+ raise ValueError(''.join(['Cannot scale {:s} and '.format(in_unit)\n+ '{:s}, unknown units'.format(out_unit)]))\n+\nif out_key is None:\nraise ValueError('Unknown output unit {:}'.format(out_unit))\n",
        "chatgpt_cot": "\"Add closest_distance_to method and assert self.exists for closest_to and furthest_to methods in Units.py\""
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/main_window.py b/node_manager_fkie/src/node_manager_fkie/main_window.py @@ -1982,10 +1982,11 @@ class MainWindow(QMainWindow):\ndef _url_path(self, url):\n'''Helper class for Qt5 compatibility'''\n- if hasattr(url, 'encodedPath'):\n- return str(url.encodedPath())\n- else:\n- return str(url.path())\n+ return url.toString()\n+ # if hasattr(url, 'encodedPath'):\n+ # return str(url.encodedPath())\n+ # else:\n+ # return str(url.path())\ndef _url_host(self, url):\n'''Helper class for Qt5 compatibility'''\n",
        "org_msg": "node_manager_fkie: fixed url handling in host control",
        "sim_msg": "open projet now recognises default directory",
        "sim_diff": "diff --git a/qualcoder/qualcoder.py b/qualcoder/qualcoder.py @@ -833,9 +833,11 @@ class MainWindow(QtWidgets.QMainWindow):\nself.close_project()\nself.setWindowTitle(\"QualCoder\" + _(\"Open Project\"))\nif path == \"\" or path is False:\n- #print(\"appsettings dir \", self.app.settings['directory'], os.path.expanduser('~') ) # tmp\n+ default_directory = self.app.settings['directory']\n+ if default_directory == \"\":\n+ default_directory = os.path.expanduser('~')\npath = QtWidgets.QFileDialog.getExistingDirectory(self,\n- _('Open project directory'), os.path.expanduser('~') )\n+ _('Open project directory'), default_directory)\nif path == \"\" or path is False:\nreturn\nmsg = \"\"\n",
        "chatgpt_cot": "Refactor _url_path method for Qt5 compatibility in MainWindow. Simplify code by replacing if-else block with a single return statement."
    },
    {
        "org_diff": "diff --git a/sc2/bot_ai.py b/sc2/bot_ai.py @@ -51,9 +51,12 @@ class BotAI(DistanceCalculation):\ndef _initialize_variables(self):\nDistanceCalculation.__init__(self)\n- # Specific opponent bot ID used in sc2ai ladder games http://sc2ai.net/\n+ # Specific opponent bot ID used in sc2ai ladder games http://sc2ai.net/ and on ai arena https://ai-arena.net\n# The bot ID will stay the same each game so your bot can \"adapt\" to the opponent\n- self.opponent_id: int = None\n+ if not hasattr(self, \"opponent_id\"):\n+ # Prevent overwriting the opponent_id which is set here https://github.com/Hannessa/python-sc2-ladderbot/blob/master/__init__.py#L40\n+ # otherwise set it to None\n+ self.opponent_id: str = None\n# This value will be set to True by main.py in self._prepare_start if game is played in realtime (if true, the bot will have limited time per step)\nself.realtime: bool = False\nself.all_units: Units = Units([], self)\n",
        "org_msg": "Fix opponent_id which was set to None even though it was already set to a string value",
        "sim_msg": "[Hockey] 2.11.2 fix posting final scores after final update",
        "sim_diff": "diff --git a/hockey/hockey.py b/hockey/hockey.py @@ -48,7 +48,7 @@ class Hockey(HockeyDev, commands.Cog):\nGather information and post goal updates for NHL hockey teams\n\"\"\"\n- __version__ = \"2.11.1\"\n+ __version__ = \"2.11.2\"\n__author__ = [\"TrustyJAID\"]\ndef __init__(self, bot):\n@@ -207,7 +207,7 @@ class Hockey(HockeyDev, commands.Cog):\nself.current_games[link][\"count\"] = 10\nfor link in self.current_games:\n- if self.current_games[link] == 10:\n+ if self.current_games[link][\"count\"] == 10:\ndel self.current_games[link]\nif not self.TEST_LOOP:\nawait asyncio.sleep(60)\n",
        "chatgpt_cot": "Prevent overwriting opponent_id, set to None if not already set, to adapt to specific opponent bot IDs in sc2ai ladder games."
    },
    {
        "org_diff": "diff --git a/src/agent/docker-rest-agent/server.py b/src/agent/docker-rest-agent/server.py @@ -61,11 +61,6 @@ def create_node():\n}\nenv.update(peer_envs)\nvolumes = ['/var/run/:/host/var/run/']\n- port_map = {\n- \"7051/tcp\":\"7051\",\n- \"17051/tcp\": \"17051\"\n- }\n-\nelse:\norder_envs = {\n'FABRIC_LOGGING_SPEC':'DEBUG',\n@@ -84,10 +79,6 @@ def create_node():\n}\nenv.update(order_envs)\nvolumes = ['/var/run/:/host/var/run/']\n- port_map = {\n- \"7050/tcp\":\"7050\",\n- \"17050/tcp\": \"17050\"\n- }\ntry:\n# same as `docker run -dit yeasy/hyperledge-fabric:2.2.0 -e VARIABLES``\n@@ -101,8 +92,8 @@ def create_node():\nname=request.form.get('name'),\ndns_search=[\".\"],\nvolumes=volumes,\n- environment=env,\n- ports=port_map)\n+ environment=env\n+ )\nexcept:\nres['code'] = FAIL_CODE\nres['data'] = sys.exc_info()[0]\n",
        "org_msg": "Remove hardcode for publishing ports of HLF nodes.\nSince we are using the docker network instead, maping ports from hosts\nis no longer necessary here. I remove these lines of code in this pr.",
        "sim_msg": "Add node config init to postinstall\nProblem: Node snapshot import by default assumes that the node directory\ntargets mainnet, thus it's not possible to import testnet snapshot to\nthe empty node data directory.\nSolution: Add `tezos-node config init` calls for all non-custom network\nservices to the postinstallation stage.",
        "sim_diff": "diff --git a/docker/package/packages.py b/docker/package/packages.py @@ -112,7 +112,10 @@ common_node_env = [\"NODE_RPC_ADDR=127.0.0.1:8732\", \"CERT_PATH=\", \"KEY_PATH=\"]\nfor network in networks:\nenv = [f\"DATA_DIR=/var/lib/tezos/node-{network}\", f\"NETWORK={network}\"] + common_node_env\nnode_units.append(mk_node_unit(suffix=network, env=env, desc=f\"Tezos node {network}\"))\n- node_postinst_steps += f\"mkdir -p /var/lib/tezos/node-{network}\\n\"\n+ node_postinst_steps += f'''mkdir -p /var/lib/tezos/node-{network}\n+[ ! -f /var/lib/tezos/node-{network}/config.json ] && tezos-node config init --data-dir /var/lib/tezos/node-{network} --network {network}\n+chown -R tezos:tezos /var/lib/tezos/node-{network}\n+'''\n# Add custom config service\nnode_units.append(mk_node_unit(suffix=\"custom\", env=[\"DATA_DIR=/var/lib/tezos/node-custom\",\n",
        "chatgpt_cot": "\"Refactor create_node function, remove unnecessary port_map, and fix Docker run command to resolve compilation issues and improve code readability.\""
    },
    {
        "org_diff": "diff --git a/sc2/bot_ai.py b/sc2/bot_ai.py @@ -1269,7 +1269,7 @@ class BotAI(DistanceCalculation):\n):\n# Warp in at location\n# TODO: find fast warp in locations either random location or closest to the given parameter \"closest_to\"\n- # TODO: find out which pylons have fast warp in by checking distance to nexus.ready and warp gates\n+ # TODO: find out which pylons have fast warp in by checking distance to nexus and warpgates.ready\nif structure.type_id == UnitTypeId.WARPGATE:\npylons = self.structures(UnitTypeId.PYLON)\nlocation = pylons.random.position.random_on_distance(4)\n@@ -1350,14 +1350,17 @@ class BotAI(DistanceCalculation):\nrequirement_met = (\nrequired_tech_building is None or self.structure_type_build_progress(required_tech_building) == 1\n)\n- # Requirement not met\nif not requirement_met:\nreturn False\nis_protoss = self.race == Race.Protoss\n+ # All upgrades right now that can be researched in spire and hatch can also be researched in their morphs\nequiv_structures = {\n+ UnitTypeId.SPIRE: {UnitTypeId.SPIRE, UnitTypeId.GREATERSPIRE},\nUnitTypeId.GREATERSPIRE: {UnitTypeId.SPIRE, UnitTypeId.GREATERSPIRE},\n+ UnitTypeId.HATCHERY: {UnitTypeId.HATCHERY, UnitTypeId.LAIR, UnitTypeId.HIVE},\n+ UnitTypeId.LAIR: {UnitTypeId.HATCHERY, UnitTypeId.LAIR, UnitTypeId.HIVE},\nUnitTypeId.HIVE: {UnitTypeId.HATCHERY, UnitTypeId.LAIR, UnitTypeId.HIVE},\n}\n# Convert to a set, or equivalent structures are chosen\n@@ -1369,10 +1372,10 @@ class BotAI(DistanceCalculation):\nstructure: Unit\nfor structure in self.structures:\nif (\n- # If structure hasn't received an action/order this frame\n- structure.tag not in self.unit_tags_received_action\n# Structure can research this upgrade\n- and structure.type_id in research_structure_types\n+ structure.type_id in research_structure_types\n+ # If structure hasn't received an action/order this frame\n+ and structure.tag not in self.unit_tags_received_action\n# Structure is idle\nand structure.is_idle\n# Structure belongs to protoss and is powered (near pylon)\n",
        "org_msg": "Improve self.research()",
        "sim_msg": "Check if tags and description is not None",
        "sim_diff": "diff --git a/syft/workers/base.py b/syft/workers/base.py @@ -741,11 +741,11 @@ class BaseWorker(AbstractWorker):\nif query_item == str(key):\nmatch = True\n- if obj.tags:\n+ if obj.tags is not None:\nif query_item in obj.tags:\nmatch = True\n- if obj.description:\n+ if obj.description is not None:\nif query_item in obj.description:\nmatch = True\n",
        "chatgpt_cot": "Refactor bot AI class, fixing comments and adding equivalent structures for upgrades, improving code readability and maintainability."
    },
    {
        "org_diff": "diff --git a/src/api-engine/api/routes/chaincode/views.py b/src/api-engine/api/routes/chaincode/views.py @@ -22,6 +22,7 @@ from api.lib.peer.chaincode import ChainCode as PeerChainCode\nfrom api.common.serializers import PageQuerySerializer\nfrom api.auth import TokenAuth\nfrom api.utils.common import with_common_response\n+from api.exceptions import ResourceNotFound\nfrom api.routes.chaincode.serializers import (\nChainCodePackageBody,\n@@ -135,7 +136,10 @@ class ChainCodeViewSet(viewsets.ViewSet):\nbreak\norg = request.user.organization\n- peer_node = Node.objects.get(type=\"peer\", organization=org.id)\n+ qs = Node.objects.filter(type=\"peer\", organization=org)\n+ if not qs.exists():\n+ raise ResourceNotFound\n+ peer_node = qs.first()\nenvs = init_env_vars(peer_node, org)\npeer_channel_cli = PeerChainCode(\"v2.2.0\", **envs)\n",
        "org_msg": "Fix chaincode package failure\nChange `Node.objects.get() method` to `Node.objects.filter()` to support\nmultiple peer nodes case.",
        "sim_msg": "Adding forgotten import on api.py",
        "sim_diff": "diff --git a/app/views/api.py b/app/views/api.py @@ -11,7 +11,7 @@ from peewee import JOIN, fn\nfrom .. import misc\nfrom ..socketio import socketio\nfrom ..models import Sub, User, Grant, Token, Client, SubPost, Sub, SubPostComment, APIToken, APITokenSettings\n-from ..models import SiteMetadata, SubPostVote, SubMetadata, SubPostCommentVote\n+from ..models import SiteMetadata, SubPostVote, SubMetadata, SubPostCommentVote, SubMod\napi = Blueprint('api', __name__)\noauth = OAuth2Provider()\n",
        "chatgpt_cot": "Add exception handling for resource not found in ChainCodeViewSet to prevent errors when filtering nodes by type and organization."
    },
    {
        "org_diff": "diff --git a/README.md b/README.md @@ -42,7 +42,7 @@ Extract these maps into their respective *subdirectories* in the SC2 maps direct\ne.g. `install-dir/Maps/Ladder2017Season1/`\n#### Bot ladder maps\n-Maps that are run on the [SC2 AI Ladder](http://sc2ai.net/) and [SC2 AI Arena](https://ai-arena.net/) can be downloaded [from the sc2ai wiki](http://wiki.sc2ai.net/Ladder_Maps) and [the ai-arena wiki](https://ai-arena.net/wiki/bot-development/getting-started/#wiki-toc-maps).\n+Maps that are run on the [SC2 AI Ladder](http://sc2ai.net/) and [SC2 AI Arena](https://aiarena.net/) can be downloaded [from the sc2ai wiki](http://wiki.sc2ai.net/Ladder_Maps) and [the ai-arena wiki](https://aiarena.net/wiki/bot-development/getting-started/#wiki-toc-maps).\n**Extract these maps into the *root* of the SC2 maps directory** (otherwise ladder replays won't work).\ne.g. `install-dir/Maps/AcropolisLE.SC2Map`\n",
        "org_msg": "Fixed links to aiarena.net",
        "sim_msg": "fixed another place where paths were not being created correctly",
        "sim_diff": "diff --git a/runner.py b/runner.py @@ -102,21 +102,21 @@ def main():\nname_dict = dict()\nsave_data = True\n- save_path = os.getcwd() + '/bot_code/training/replays'\n+ save_path = os.path.join(os.getcwd(), 'bot_code', 'training', 'replays')\ngame_name = str(int(round(time.time() * 1000))) + '-' + str(random.randint(0, 1000))\nif save_data:\nprint(save_path)\nif not os.path.exists(save_path):\nprint(os.path.dirname(save_path) + ' does not exist creating')\nos.makedirs(save_path)\n- if not os.path.exists(save_path + '\\\\' + game_name):\n- os.makedirs(save_path + '\\\\' + game_name)\n+ joined_path = os.path.join(save_path, game_name)\n+ if not os.path.exists(joined_path):\n+ os.makedirs(joined_path)\nprint('gameName: ' + game_name + 'in ' + save_path)\ngameInputPacket.iNumPlayers = num_participants\nserver_manager.load_config()\n-\nnum_team_0 = 0\n# Set configuration values for bots and store name and team\nfor i in range(num_participants):\n",
        "chatgpt_cot": "\"Update AI Arena wiki link in README.md\""
    },
    {
        "org_diff": "diff --git a/node_manager_daemon_fkie/src/node_manager_daemon_fkie/monitor/sensor_interface.py b/node_manager_daemon_fkie/src/node_manager_daemon_fkie/monitor/sensor_interface.py @@ -47,7 +47,7 @@ class SensorInterface(object):\nself._interval = interval\nself._timer = None\nself._stat_msg = DiagnosticStatus()\n- self._stat_msg.name = '%s (%s)' % (sensorname, hostname)\n+ self._stat_msg.name = '%s' % (sensorname)\nself._stat_msg.level = 3\nself._stat_msg.hardware_id = hostname\nself._stat_msg.message = 'No Data'\n",
        "org_msg": "node_manager_daemon_fkie: removed hostname from each sensor",
        "sim_msg": "Subscribe to service mode events in BCP",
        "sim_diff": "diff --git a/mpf/core/bcp/bcp_interface.py b/mpf/core/bcp/bcp_interface.py @@ -264,6 +264,8 @@ class BcpInterface(MpfController):\nself._monitor_modes(client)\nelif category == \"core_events\":\nself._monitor_core_events(client)\n+ elif category == \"service_events\":\n+ self._monitor_service_events(client)\nelif category == \"status_request\":\nself._monitor_status_request(client)\nelse:\n@@ -292,6 +294,8 @@ class BcpInterface(MpfController):\nself._monitor_modes_stop(client)\nelif category == \"core_events\":\nself._monitor_core_events_stop(client)\n+ elif category == \"service_events\":\n+ self._monitor_service_events_stop(client)\nelif category == \"status_request\":\nself._monitor_status_request_stop(client)\nelse:\n@@ -520,6 +524,21 @@ class BcpInterface(MpfController):\nself.machine.events.remove_handler_by_event('player_turn_started', self._player_turn_start)\nself.machine.events.remove_handler_by_event('player_added', self._player_added)\n+ def _monitor_service_events(self, client):\n+ \"\"\"Begin monitoring all service events via the specified client.\"\"\"\n+ if not self.machine.bcp.transport.get_transports_for_handler(\"_service_events\"):\n+ for event in [\"service_mode_entered\", \"service_main_menu\", \"service_menu_selected\"]:\n+ self.add_registered_trigger_event_for_client(client, event)\n+ self.machine.bcp.transport.add_handler_to_transport(\"_service_events\", client)\n+\n+ def _monitor_service_events_stop(self, client):\n+ \"\"\"Stop monitoring all service events via the specified client.\"\"\"\n+ self.machine.bcp.transport.add_handler_to_transport(\"_service_events\", client)\n+\n+ if not self.machine.bcp.transport.get_transports_for_handler(\"_service_events\"):\n+ for event in [\"service_mode_entered\", \"service_main_menu\", \"service_menu_selected\"]:\n+ self.remove_registered_trigger_event_for_client(client, event)\n+\ndef _monitor_status_request(self, client):\n\"\"\"Begin monitoring status_request messages via the specified client.\"\"\"\nself.machine.bcp.transport.add_handler_to_transport(\"_status_request\", client)\n",
        "chatgpt_cot": "\"Refactor SensorInterface name assignment for clarity and consistency\""
    },
    {
        "org_diff": "diff --git a/examples/simulate_fight_scenario.py b/examples/simulate_fight_scenario.py @@ -12,7 +12,6 @@ class FightBot(BotAI):\nsuper().__init__()\nself.control_received = False\nself.fight_started = False\n- self.supplies_been_damaged = False\nasync def on_step(self, iteration):\n# before everything else - retrieve control\n@@ -55,16 +54,6 @@ class FightBot(BotAI):\n# await self.chat_send(\"control received\")\nself.control_received = True\n- # to speedup, we are going damage both supplies\n- if not self.supplies_been_damaged and self.structures(UnitTypeId.SUPPLYDEPOT) and self.enemy_structures(UnitTypeId.SUPPLYDEPOT):\n- for s in self.structures(UnitTypeId.SUPPLYDEPOT):\n- await self._client.debug_set_unit_value([s.tag], 2, 100)\n- for s in self.enemy_structures(UnitTypeId.SUPPLYDEPOT):\n- await self._client.debug_set_unit_value([s.tag], 2, 100)\n- logger.info(\"supplies damaged\")\n- # await self.chat_send(\"supplies damaged\")\n- self.supplies_been_damaged = True\n-\n# note: we should wait till workers will be destroyed\nif not self.fight_started and self.control_received and self.enemy_units and not self.enemy_units(UnitTypeId.SCV) and not self.units(UnitTypeId.SCV):\n# start fight\n",
        "org_msg": "remove supply damage as not needed",
        "sim_msg": "Improve the worker cross-registration to remove warnings",
        "sim_diff": "diff --git a/syft/workers/base.py b/syft/workers/base.py @@ -69,14 +69,18 @@ class BaseWorker(AbstractWorker):\n# A core object in every BaseWorker instantiation. A Collection of\n# objects where all objects are stored using their IDs as keys.\nself._objects = {}\n+\n+ # Declare workers as appropriate\nself._known_workers = {}\nif hook.local_worker is not None:\n- for k, v in hook.local_worker._known_workers.items():\n- if v is not hook.local_worker:\n- self._known_workers[k] = v\n- v.add_worker(self)\n+ if self.id not in self.hook.local_worker._known_workers:\nhook.local_worker.add_worker(self)\n- self.add_worker(self)\n+ for worker_id, worker in hook.local_worker._known_workers.items():\n+ if worker_id not in self._known_workers:\n+ self.add_worker(worker)\n+ if self.id not in worker._known_workers:\n+ worker.add_worker(self)\n+\n# For performance, we cache each\nself._message_router = {\nMSGTYPE.CMD: self.execute_command,\n",
        "chatgpt_cot": "Remove the supplies damage code and update the control and fight flags."
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/editor/line_number_widget.py b/node_manager_fkie/src/node_manager_fkie/editor/line_number_widget.py @@ -112,10 +112,13 @@ class LineNumberWidget(QFrame):\ndef eventFilter(self, obj, event):\n# Update the line numbers for all events on the text edit and the viewport.\n# This is easier than connecting all necessary signals.\n+ try:\nif obj in (self.edit, self.edit.viewport()):\nself.number_bar.update()\nreturn False\nreturn QFrame.eventFilter(obj, event)\n+ except Exception:\n+ pass\ndef get_text_edit(self):\nreturn self.edit\n",
        "org_msg": "node_manager_fkie: handle execption on Ctrl+C while questing in editor dialog is open",
        "sim_msg": "Tree: display title for e.g. Frame, allow editing of this and class name",
        "sim_diff": "diff --git a/tree.py b/tree.py @@ -484,7 +484,15 @@ class WidgetTree(wx.TreeCtrl, Tree):\nnew_value = evt.Label\nif new_value==self._build_label(node): return\n- new_name = new_label = new_title = new_tab = None\n+ new_name = new_label = new_title = new_tab = new_class = None\n+\n+ if node.widget.klass != node.widget.base and node.widget.klass != 'wxScrolledWindow':\n+ if new_value.count(\"(\")==1 and new_value.count(\")\")==1:\n+ pre, new_class = new_value.split(\"(\")\n+ new_class, post = new_class.split(\")\")\n+ if pre.endswith(\" \"): pre = pre[:-1]\n+ new_value = pre+post\n+\nif \"label\" in widget.properties and self._label_editable(widget):\nnew_name, new_label = self._split_name_label(new_value)\nelif \"label\" in widget.properties:\n@@ -507,14 +515,23 @@ class WidgetTree(wx.TreeCtrl, Tree):\nif new_name==name_p.get(): new_name = None\nif new_name:\n# check\n- name_OK = name_p.check(new_name)\n- if not name_OK: new_name = None\n+ OK = name_p.check(new_name)\n+ if not OK: new_name = None\n+\n+ # check class/klass\n+ if new_class:\n+ class_p = widget.properties[\"klass\"]\n+ if new_class==class_p.get(): new_class = None\n+ if new_class:\n+ # check\n+ OK = class_p.check(new_class)\n+ if not OK: new_class = None\n# check label\nif new_label is not None:\nlabel_p = widget.properties[\"label\"]\nif new_label==label_p.get(): new_label = None\n- if not new_name and new_label is None and new_title is None and new_tab is None:\n+ if not new_name and new_label is None and new_title is None and new_tab is None and new_class is None:\n# no change or an error\nwx.Bell()\nevt.Veto()\n@@ -543,6 +560,10 @@ class WidgetTree(wx.TreeCtrl, Tree):\nname_p.previous_value = name_p.value\nname_p.set(new_name, notify=False)\nmodified.add(\"name\")\n+ if new_class:\n+ class_p.previous_value = class_p.value\n+ class_p.set(new_class, notify=False)\n+ modified.add(\"class\")\nif new_label:\nlabel_p.previous_value = label_p.value\nlabel_p.set(new_label, notify=False)\n@@ -577,6 +598,9 @@ class WidgetTree(wx.TreeCtrl, Tree):\nif node.widget.klass != node.widget.base and node.widget.klass != 'wxScrolledWindow':\n# special case...\ns += ' (%s)' % node.widget.klass\n+ if getattr(node.widget, \"has_title\", None):\n+ # include title\n+ s += ': \"%s\"'%node.widget.title\nelif \"label\" in node.widget.properties and node.widget.properties[\"label\"].is_active():\n# include label of control\nlabel = node.widget.label\n",
        "chatgpt_cot": "Add try-except block to handle any exception in eventFilter method for LineNumberWidget. This ensures robustness and prevents crashing due to unexpected errors."
    },
    {
        "org_diff": "diff --git a/sc2/position.py b/sc2/position.py @@ -11,12 +11,6 @@ def _sign(num):\nclass Pointlike(tuple):\n- @property\n- def rounded(self) -> \"Pointlike\":\n- # return Point2((math.floor(self[0]), math.ceil(self[1])))\n- # map was flipped\n- return Point2((math.floor(self[0]), math.floor(self[1])))\n-\n@property\ndef position(self) -> \"Pointlike\":\nreturn self\n@@ -153,6 +147,10 @@ class Point2(Pointlike):\ndef from_proto(cls, data):\nreturn cls((data.x, data.y))\n+ @property\n+ def rounded(self) -> \"Point2\":\n+ return Point2((math.floor(self[0]), math.floor(self[1])))\n+\n@property\ndef x(self) -> Union[int, float]:\nreturn self[0]\n@@ -296,6 +294,10 @@ class Point3(Point2):\ndef from_proto(cls, data):\nreturn cls((data.x, data.y, data.z))\n+ @property\n+ def rounded(self) -> \"Point3\":\n+ return Point3((math.floor(self[0]), math.floor(self[1]), math.floor(self[2])))\n+\n@property\ndef z(self) -> Union[int, float]:\nreturn self[2]\n",
        "org_msg": "Add rounded for point2 and 3, remove from pointlike",
        "sim_msg": "More detailed report.",
        "sim_diff": "diff --git a/sentry.py b/sentry.py @@ -27,10 +27,15 @@ else:\ndef send_report_to_dev_chat(exc):\nr2t = utils.Reddit2TelegramSender(config['telegram_dev_chat'], config)\nlocal_vars = sys.exc_info()[2].tb_next.tb_frame.f_locals\n- subreddit = local_vars['subreddit']\n- report = '{subreddit}\\n______\\n{exeption}'.format(\n- subreddit=subreddit,\n- exeption=str(exc)\n+ line = '_______________'\n+ submodule = local_vars['subreddit']\n+ title = '{}\\n{}'.format(submodule, line)\n+ if 'submission' in local_vars:\n+ link = local_vars['submission'].shortlink\n+ title = '{}\\n{}\\n{}'.format(title, link, line)\n+ report = '{}\\n{}'.format(\n+ title,\n+ str(exc)\n)\nr2t.send_text(report)\n",
        "chatgpt_cot": "Refactor rounded method in Pointlike, Point2, and Point3 classes to correctly round coordinates. Fixes rounding issue in position calculations."
    },
    {
        "org_diff": "diff --git a/sc2/bot_ai.py b/sc2/bot_ai.py @@ -109,12 +109,9 @@ class BotAI(object):\n\"\"\"Takes new expansion.\"\"\"\nif not building:\n- if self.race == Race.Protoss:\n- building = UnitTypeId.NEXUS\n- elif self.race == Race.Terran:\n- building = UnitTypeId.COMMANDCENTER\n- elif self.race == Race.Zerg:\n- building = UnitTypeId.HATCHERY\n+ # self.race is never Race.Random\n+ start_townhall_type = {Race.Protoss: UnitTypeId.NEXUS, Race.Terran: UnitTypeId.COMMANDCENTER, Race.Zerg: UnitTypeId.HATCHERY}\n+ building = start_townhall_type[self.race]\nassert isinstance(building, UnitTypeId)\n",
        "org_msg": "Change if else to dict",
        "sim_msg": "Forgot to update iNumPlayers",
        "sim_diff": "diff --git a/v3/runner.py b/v3/runner.py @@ -63,6 +63,8 @@ if __name__ == '__main__':\ncallbacks = []\nname_dict = dict()\n+ gameInputPacket.iNumPlayers = num_bots\n+\n# Set configuration values for bots and store name and team\nfor i in range(num_bots):\nbot_config = configparser.RawConfigParser()\n",
        "chatgpt_cot": "Refactor code to use a dictionary for start_townhall_type, improving readability and simplifying the logic for selecting the building based on the race."
    },
    {
        "org_diff": "diff --git a/src/dashboard/src/pages/Operator/Agent/newAgent.js b/src/dashboard/src/pages/Operator/Agent/newAgent.js @@ -113,7 +113,7 @@ class CreateAgent extends PureComponent {\nhandleSubmit = e => {\ne.preventDefault();\n- const { action, fileList } = this.state;\n+ const { action } = this.state;\nconst {\nform: { validateFieldsAndScroll },\ndispatch,\n@@ -129,13 +129,7 @@ class CreateAgent extends PureComponent {\nconst formData = new FormData();\nObject.keys(values).forEach(key => {\n- if (key === 'config_file') {\n- if (fileList.length > 0) {\n- formData.append(key, fileList[0]);\n- }\n- } else {\nformData.append(key, values[key]);\n- }\n});\ndispatch({\n@@ -154,7 +148,7 @@ class CreateAgent extends PureComponent {\nif (Array.isArray(e)) {\nreturn e;\n}\n- return e && e.fileList;\n+ return e && e.fileList.length > 0 ? e.file : null;\n};\nrender() {\n",
        "org_msg": "Fix agent file not uploaded in UI\nFix agent file not uploaded in dashboard.",
        "sim_msg": "Update for screenshot",
        "sim_diff": "diff --git a/webapp/components/BuildDetails.js b/webapp/components/BuildDetails.js @@ -15,7 +15,7 @@ export default class BuildDetails extends Component {\n<BuildSummary>\n<Header>\n<Message>various improvements</Message>\n- <Branch>master</Branch>\n+ <Branch>ui/fix-that-thing</Branch>\n</Header>\n<Meta>\n<Duration status=\"pass\">\n@@ -38,7 +38,7 @@ export default class BuildDetails extends Component {\n<NavHeading label=\"Build Jobs\" />\n<List>\n<ListItem>just</ListItem>\n- <ListItem>finna</ListItem>\n+ <ListItem>gonna</ListItem>\n<ListItem>make</ListItem>\n<ListItem>these</ListItem>\n<ListItem>a</ListItem>\n",
        "chatgpt_cot": "Remove unnecessary file handling logic in handleSubmit method to improve code readability and maintainability in CreateAgent component."
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/editor/editor.py b/node_manager_fkie/src/node_manager_fkie/editor/editor.py @@ -276,7 +276,7 @@ class Editor(QMainWindow):\nsettings.setValue(\"window_state\", self.saveState())\nsettings.endGroup()\n- def on_load_request(self, filename, search_text=''):\n+ def on_load_request(self, filename, search_text='', insert_index=-1):\n'''\nLoads a file in a new tab or focus the tab, if the file is already open.\n@param filename: the path to file\n@@ -292,6 +292,10 @@ class Editor(QMainWindow):\ntab_name = self.__getTabName(filename)\neditor = TextEdit(filename, self.tabWidget)\nlinenumber_editor = LineNumberWidget(editor)\n+ tab_index = 0\n+ if insert_index > -1:\n+ tab_index = self.tabWidget.insertTab(insert_index, linenumber_editor, tab_name)\n+ else:\ntab_index = self.tabWidget.addTab(linenumber_editor, tab_name)\nself.files.append(filename)\neditor.setCurrentPath(os.path.basename(filename))\n@@ -434,13 +438,12 @@ class Editor(QMainWindow):\nelse:\nret = self._find_inc_file(self.tabWidget.currentWidget().filename, files)\nif ret:\n- self.on_load_request(ret, basename_cur)\n+ self.on_load_request(ret, basename_cur, self.tabWidget.currentIndex())\ndef _find_inc_file(self, filename, files):\nfor f in files:\ninc_files = LaunchConfig.getIncludedFiles(f, recursive=False)\nif filename in inc_files:\n- self.on_load_request(f, os.path.basename(filename))\nreturn f\nelse:\nretf = self._find_inc_file(filename, inc_files)\n",
        "org_msg": "node_manager_fkie: open upper files and insert these in between",
        "sim_msg": "added ExportDialog which adds a counter to filenames if needed",
        "sim_diff": "diff --git a/qualcoder/helpers.py b/qualcoder/helpers.py @@ -63,6 +63,7 @@ def msecs_to_mins_and_secs(msecs):\nremainder_secs = \"0\" + remainder_secs\nreturn str(mins) + \".\" + remainder_secs\n+\ndef msecs_to_hours_mins_secs(msecs):\n\"\"\" Convert milliseconds to hours, minutes and seconds.\nmsecs is an integer. Hours, minutes and seconds output is a string.\"\"\"\n@@ -100,6 +101,37 @@ class Message(QtWidgets.QMessageBox):\nself.setIcon(QtWidgets.QMessageBox.Critical)\n+class ExportDialog():\n+ \"\"\" Dialog to get export directory, but also to check for existing file.\n+ If an existing file found, add a counter to the file name until a new file name is made.\n+ Counter in format _1, _2, etc. \"\"\"\n+\n+ filepath = \"\"\n+\n+ def __init__(self, app, filename):\n+ \"\"\" params:\n+ app : App class\n+ title: String\n+ filename: String of filename with extension only\"\"\"\n+\n+ extension = filename.split('.')[-1]\n+ filename_only = filename[0:-len(extension) -1]\n+ options = QtWidgets.QFileDialog.DontResolveSymlinks | QtWidgets.QFileDialog.ShowDirsOnly\n+ directory = QtWidgets.QFileDialog.getExistingDirectory(None,\n+ _(\"Select directory to save file\"),\n+ app.last_export_directory, options)\n+ if directory:\n+ if directory != app.last_export_directory:\n+ app.last_export_directory = directory\n+ self.filepath = directory + \"/\" + filename_only + \".\" + extension\n+ counter = 0\n+ while os.path.exists(self.filepath):\n+ self.filepath = directory + \"/\" + filename_only + \"_\" + str(counter) + \".\" + extension\n+ counter += 1\n+ else:\n+ self.filepath = None\n+\n+\nclass DialogGetStartAndEndMarks(QtWidgets.QDialog):\n\"\"\" This dialog gets the start and end mark text to allow text to be\nautomatically assigned to the currently selected case or a code to be assigned when coding text.\n",
        "chatgpt_cot": "Add functionality to load file at specific index in tab, improving user experience in Editor class. Fix load request method to handle insert index parameter."
    },
    {
        "org_diff": "diff --git a/sc2/main.py b/sc2/main.py @@ -101,6 +101,10 @@ async def _play_game_ai(client, player_id, ai, realtime, step_time_limit, game_t\n# This game_data will become self._game_data in botAI\nai._prepare_start(client, player_id, game_info, game_data)\nstate = await client.observation()\n+ # check game result every time we get the observation\n+ if client._game_result:\n+ ai.on_end(client._game_result[player_id])\n+ return client._game_result[player_id]\ngs = GameState(state.observation)\nproto_game_info = await client._execute(game_info=sc_pb.RequestGameInfo())\nai._prepare_step(gs, proto_game_info)\n@@ -116,12 +120,12 @@ async def _play_game_ai(client, player_id, ai, realtime, step_time_limit, game_t\niteration = 0\nwhile True:\n+ if iteration != 0:\n+ state = await client.observation()\n+ # check game result every time we get the observation\nif client._game_result:\nai.on_end(client._game_result[player_id])\nreturn client._game_result[player_id]\n-\n- if iteration != 0:\n- state = await client.observation()\ngs = GameState(state.observation)\nlogger.debug(f\"Score: {gs.score.summary}\")\n",
        "org_msg": "Fix proper termination on game end, fix on_end trigger on ladder server",
        "sim_msg": "Forgot to update iNumPlayers",
        "sim_diff": "diff --git a/v3/runner.py b/v3/runner.py @@ -63,6 +63,8 @@ if __name__ == '__main__':\ncallbacks = []\nname_dict = dict()\n+ gameInputPacket.iNumPlayers = num_bots\n+\n# Set configuration values for bots and store name and team\nfor i in range(num_bots):\nbot_config = configparser.RawConfigParser()\n",
        "chatgpt_cot": "Add game result check on observation in play_game_ai to handle game end conditions and improve game result handling."
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/node_tree_model.py b/node_manager_fkie/src/node_manager_fkie/node_tree_model.py @@ -373,7 +373,7 @@ class GroupItem(QStandardItem):\nreturn newItem.get_group_item(rns, is_group)\nreturn newItem\nitems = []\n- newItem = GroupItem(group_name, self, is_group=(is_group and not rns))\n+ newItem = GroupItem(lns, self, is_group=(is_group and not rns))\nitems.append(newItem)\ncfgitem = CellItem(group_name, newItem)\nitems.append(cfgitem)\n",
        "org_msg": "node_manager_fkie: fixed namespace view",
        "sim_msg": "Tag tree troncated - fix",
        "sim_diff": "diff --git a/addons/io_scene_gltf2/blender/exp/gltf2_blender_gather_tree.py b/addons/io_scene_gltf2/blender/exp/gltf2_blender_gather_tree.py @@ -307,6 +307,7 @@ class VExportTree:\n# If parent_kept_uuid is None, and parent_uuid was not, add to root list\nif self.nodes[uuid].parent_uuid is not None and parent_kept_uuid is None:\n+ self.tree_troncated = True\nself.roots.append(uuid)\n# Modify parent uuid\n",
        "chatgpt_cot": "\"Fix group item creation by updating the parameter passed to GroupItem constructor in node_tree_model.py\""
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/nmd_client.py b/node_manager_fkie/src/node_manager_fkie/nmd_client.py @@ -210,7 +210,7 @@ class NmdClient(QObject):\ngrpc_url = nmdurl.nmduri(url)\ntry:\ndel self._cache_packages[grpc_url]\n- rospy.logdebug(\"Packages cache removed for\", grpc_url)\n+ rospy.logdebug(\"cache for packages from '%s' removed\", grpc_url)\nexcept KeyError:\npass\n",
        "org_msg": "node_manager_fkie: fixed debug output",
        "sim_msg": "Fix for rtmpPost",
        "sim_diff": "diff --git a/blueprints/apis/server_ns.py b/blueprints/apis/server_ns.py @@ -10,7 +10,7 @@ from functions import cachedDbCalls\nrtmpPost = reqparse.RequestParser()\nrtmpPost.add_argument('address', type=str, required=True)\n-rtmpPort.add_argument('hide', type=bool, default=False)\n+rtmpPost.add_argument('hide', type=bool, default=False)\nrtmpDelete = reqparse.RequestParser()\nrtmpDelete.add_argument('address', type=str, required=True)\n",
        "chatgpt_cot": "Improve logging message in NmdClient class by updating the format to include the URL when removing packages from the cache."
    },
    {
        "org_diff": "diff --git a/sc2/paths.py b/sc2/paths.py @@ -48,7 +48,7 @@ class _MetaPaths(type):\ntry:\nself.BASE = Path(os.environ.get(\"SC2PATH\", BASEDIR[PF])).expanduser()\nself.EXECUTABLE = latest_executeble(self.BASE / \"Versions\")\n- self.CWD = base_dir / CWD[PF] if CWD[PF] else None\n+ self.CWD = self.BASE / CWD[PF] if CWD[PF] else None\nself.REPLAYS = self.BASE / \"Replays\"\nself.MAPS = self.BASE / \"Maps\"\n",
        "org_msg": "Replace base_dir to self.BASE to fix unresolved variable",
        "sim_msg": "update downloader so old replays still are supported",
        "sim_diff": "diff --git a/trainer/downloader.py b/trainer/downloader.py @@ -15,8 +15,10 @@ sys.path.append('../framework/replayanalysis') # dirty way to fix the path for\nclass Downloader:\n- BASE_URL = \"http://saltie.tk:5000\"\n+ BASE_URL = 'http://138.197.6.71:5000' # for saltie replays/training\n+ BASE_REPLAY_URL = \"http://saltie.tk\" # for replay parsing/training\nAPI_KEY = '123456'\n+\ndef __init__(self, max_size_mb=100, path='mem://saltie'):\nself.max_size_mb = max_size_mb\nself.filesystem = fs.open_fs(path)\n@@ -57,7 +59,8 @@ class Downloader:\ndef get_replay(self, filename_or_filenames: list or str):\nif isinstance(filename_or_filenames, list):\ntry:\n- r = requests.post(self.BASE_URL + '/replays/download', data={'files': json.dumps(filename_or_filenames)})\n+ r = requests.post(self.BASE_URL + '/replays/download',\n+ data={'files': json.dumps(filename_or_filenames)})\nexcept ChunkedEncodingError:\nreturn []\nimf = self.create_in_memory_file(r)\n@@ -76,9 +79,9 @@ class Downloader:\ndef download_pandas_game(self, from_disk=False) -> pandas.DataFrame:\nif not from_disk:\n- js = requests.get(self.BASE_URL + '/api/v1/parsed/list?key={}'.format(self.API_KEY)).json()\n+ js = requests.get(self.BASE_REPLAY_URL + '/api/v1/parsed/list?key={}'.format(self.API_KEY)).json()\ndl = random.choice(js)\n- dl_url = self.BASE_URL + '/api/v1/parsed/{}?key={}'.format(dl, self.API_KEY)\n+ dl_url = self.BASE_REPLAY_URL + '/api/v1/parsed/{}?key={}'.format(dl, self.API_KEY)\nr = requests.get(dl_url, stream=True)\nr.raw.decode_content = True # Content-Encoding\nr.raise_for_status()\n",
        "chatgpt_cot": "Fix issue with CWD path assignment in paths.py"
    },
    {
        "org_diff": "diff --git a/src/api-engine/api_engine/urls.py b/src/api-engine/api_engine/urls.py @@ -25,7 +25,7 @@ from drf_yasg import openapi\nfrom drf_yasg.views import get_schema_view\nfrom rest_framework.routers import DefaultRouter\nfrom rest_framework_simplejwt.views import (\n- TokenObtainPairView,\n+ TokenVerifyView,\nTokenRefreshView,\n)\nfrom django.conf.urls.static import static\n@@ -79,6 +79,7 @@ urlpatterns = router.urls\nurlpatterns += [\npath('login', CelloTokenObtainPairView.as_view(), name='token_obtain_pair'),\npath('login/refresh/', TokenRefreshView.as_view(), name='token_refresh'),\n+ path('token-verify', TokenVerifyView.as_view(), name='token_verify'),\npath(\"docs/\", SchemaView.with_ui(\"swagger\", cache_timeout=0), name=\"docs\"),\npath(\"redoc/\", SchemaView.with_ui(\"redoc\", cache_timeout=0), name=\"redoc\"),\n]\n",
        "org_msg": "Add token verify endpoint",
        "sim_msg": "Remove cache from drf yasg\nSeems to have some issues",
        "sim_diff": "diff --git a/config/urls.py b/config/urls.py @@ -4,35 +4,35 @@ from django.contrib import admin\nfrom django.http import HttpResponse\nfrom django.urls import path, re_path\nfrom django.views import defaults as default_views\n-from django.views.decorators.cache import cache_control\nfrom drf_yasg import openapi\nfrom drf_yasg.views import get_schema_view\n+from rest_framework import permissions\nschema_view = get_schema_view(\nopenapi.Info(\ntitle='Gnosis Safe Transaction Service API',\ndefault_version='v1',\n- description='API to store safe multisig transactions',\n+ description='API to keep track of transactions sent via Gnosis Safe smart contracts',\ncontact=openapi.Contact(email='safe@gnosis.io'),\nlicense=openapi.License(name='MIT License'),\n),\nvalidators=['flex', 'ssv'],\npublic=True,\n+ permission_classes=[permissions.AllowAny],\n)\nschema_cache_timeout = 60 * 5 # 5 minutes\n-schema_cache_decorator = cache_control(max_age=schema_cache_timeout)\nurlpatterns = [\nre_path(r'^$',\n- schema_cache_decorator(schema_view.with_ui('swagger', cache_timeout=schema_cache_timeout)),\n+ schema_view.with_ui('swagger', cache_timeout=schema_cache_timeout),\nname='schema-swagger-ui'),\nre_path(r'^swagger(?P<format>\\.json|\\.yaml)$',\n- schema_cache_decorator(schema_view.without_ui(cache_timeout=schema_cache_timeout)),\n+ schema_view.without_ui(cache_timeout=schema_cache_timeout),\nname='schema-json'),\nre_path(r'^redoc/$',\n- schema_cache_decorator(schema_view.with_ui('redoc', cache_timeout=schema_cache_timeout)),\n+ schema_view.with_ui('redoc', cache_timeout=schema_cache_timeout),\nname='schema-redoc'),\nre_path(settings.ADMIN_URL, admin.site.urls),\nre_path(r'^api/v1/', include('safe_transaction_service.history.urls', namespace='v1')),\n",
        "chatgpt_cot": "Add TokenVerifyView and its URL path, and update TokenObtainPairView to CelloTokenObtainPairView to customize the login view."
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/settings.py b/node_manager_fkie/src/node_manager_fkie/settings.py @@ -169,6 +169,7 @@ class Settings(object):\nself._terminal_emulator = None\nself._terminal_command_arg = 'e'\nself._noclose_str = '-hold'\n+ self._terminal_title = '--title'\nself._masteruri = masteruri_from_ros()\nself.CFG_PATH = os.path.join(get_ros_home(), 'node_manager')\n# loads the current configuration path. If the path was changed, a redirection\n@@ -692,12 +693,13 @@ class Settings(object):\n\"be then load by node_manager.\")\nelif os.path.basename(os.path.realpath(t)) in ['xfce4-terminal']:\nself._noclose_str = ''\n+ self._terminal_title = '-T'\nself._terminal_emulator = t\nbreak\nif self._terminal_emulator == \"\":\nraise Exception(\"No Terminal found! Please install one of ['/usr/bin/x-terminal-emulator', '/usr/bin/xterm', '/opt/x11/bin/xterm']\")\nself._noclose_str = self._noclose_str if noclose else \"\"\n- return '%s -T \"%s\" %s -%s %s' % (self._terminal_emulator, title, self._noclose_str, self._terminal_command_arg, ' '.join(cmd))\n+ return '%s %s \"%s\" %s -%s %s' % (self._terminal_emulator, self._terminal_title, title, self._noclose_str, self._terminal_command_arg, ' '.join(cmd))\ndef qsettings(self, settings_file):\nfrom python_qt_binding.QtCore import QSettings\n",
        "org_msg": "node_manager_fkie: changed -T to --title for terminal title",
        "sim_msg": "Added directory attribute to Settings class\nNo extra handling of directory names outside\nof settings objects necessary anymore.",
        "sim_diff": "diff --git a/textext/utility.py b/textext/utility.py @@ -168,6 +168,7 @@ class Settings(object):\nif not os.path.exists(directory):\nos.makedirs(directory, exist_ok=True)\nself.values = {}\n+ self.directory = directory\nself.config_path = os.path.join(directory, basename)\ntry:\nself.load()\n",
        "chatgpt_cot": "Add new terminal title attribute and change terminal title argument to be used in terminal command."
    },
    {
        "org_diff": "diff --git a/README.md b/README.md @@ -69,6 +69,14 @@ SC2PATH=/home/burny/Games/battlenet/drive_c/Program Files (x86)/StarCraft II/\n#### WSL\n+When running WSL in Windows, python-sc2 detects WSL by default and starts Windows Starcraft 2 instead of Linux Starcraft 2.\n+If you wish to instead have the game played in Linux, you can disable this behavior by setting `SC2_WSL_DETECT`\n+environment variable to \"0\". You can do this inside python with the following code:\n+```py\n+import os\n+os.environ[\"SC2_WSL_DETECT\"] = \"0\"\n+```\n+\nWSL version 1 should not require any configuration. You may be asked to allow Python through your firewall.\nWhen running WSL version 2 you need to supply the following environment variables so that your bot can connect:\n",
        "org_msg": "Updated readme for disabling wsl detect",
        "sim_msg": "add check for reddit key",
        "sim_diff": "diff --git a/gamestonk_terminal/main_helper.py b/gamestonk_terminal/main_helper.py @@ -22,10 +22,12 @@ import pytz\nimport pyEX\nfrom pyEX.common.exception import PyEXception\nfrom tabulate import tabulate\n+import praw\n+from prawcore.exceptions import ResponseException\n# import git\n-# pylint: disable=no-member,too-many-branches\n+# pylint: disable=no-member,too-many-branches,C0302\nfrom gamestonk_terminal.helper_funcs import (\nvalid_date,\n@@ -659,7 +661,7 @@ def check_api_keys():\nelse:\nkey_dict[\"ALPHA_VANTAGE\"] = \"defined, test passed\"\n- if cfg.API_KEY_FINANCIALMODELINGPREP == \"REPLACE_ME\":\n+ if cfg.API_KEY_FINANCIALMODELINGPREP == \"REPLACE_ME\": # pragma: allowlist secret\nkey_dict[\"FINANCIAL_MODELING_PREP\"] = \"Not defined\"\nelse:\nr = requests.get(\n@@ -672,7 +674,7 @@ def check_api_keys():\nelse:\nkey_dict[\"FINANCIAL_MODELING_PREP\"] = \"defined, test inconclusive\"\n- if cfg.API_KEY_QUANDL == \"REPLACE_ME\":\n+ if cfg.API_KEY_QUANDL == \"REPLACE_ME\": # pragma: allowlist secret\nkey_dict[\"QUANDL\"] = \"Not defined\"\nelse:\ntry:\n@@ -788,9 +790,21 @@ def check_api_keys():\nif \"REPLACE_ME\" in reddit_keys:\nkey_dict[\"REDDIT\"] = \"Not defined\"\nelse:\n- key_dict[\"REDDIT\"] = \"defined, not tested\"\n+ praw_api = praw.Reddit(\n+ client_id=cfg.API_REDDIT_CLIENT_ID,\n+ client_secret=cfg.API_REDDIT_CLIENT_SECRET,\n+ username=cfg.API_REDDIT_USERNAME,\n+ user_agent=cfg.API_REDDIT_USER_AGENT,\n+ password=cfg.API_REDDIT_PASSWORD,\n+ )\n+\n+ try:\n+ praw_api.user.me()\n+ key_dict[\"REDDIT\"] = \"defined, test passed\"\n+ except ResponseException:\n+ key_dict[\"REDDIT\"] = \"defined, test failed\"\n- # Reddit keys\n+ # Twitter keys\ntwitter_keys = [\ncfg.API_TWITTER_KEY,\ncfg.API_TWITTER_SECRET_KEY,\n",
        "chatgpt_cot": "fix WSL detection in README.md to start Linux Starcraft 2 instead of Windows Starcraft 2 by disabling SC2_WSL_DETECT environment variable."
    },
    {
        "org_diff": "diff --git a/sc2/units.py b/sc2/units.py @@ -17,10 +17,16 @@ class Units(list):\n# Add keyword argument 'game_data=None' to provide downwards\n# compatibility for bots that use '__init__' or 'from_proto' functions.\n@classmethod\n- def from_proto(cls, units): # game_data=None\n+ def from_proto(cls, units, game_data=None): # game_data=None\n+ if game_data:\n+ logger.info(\"Keyword argument 'game_data' in Units classmethod 'from_proto' is deprecated.\")\n+ logger.info(\"You can safely remove it.\")\nreturn cls((Unit(u) for u in units))\n- def __init__(self, units): # game_data=None\n+ def __init__(self, units, game_data=None):\n+ if game_data:\n+ logger.info(\"Keyword argument 'game_data' in Units function '__init__' is deprecated.\")\n+ logger.info(\"You can safely remove it.\")\nsuper().__init__(units)\ndef __call__(self, *args, **kwargs):\n",
        "org_msg": "Add deprecation note for gamedata change",
        "sim_msg": "TypeRepo.Defer: intercept KeyError to create user friendly diagnostics\nTN: minor",
        "sim_diff": "diff --git a/langkit/compiled_types.py b/langkit/compiled_types.py @@ -2321,8 +2321,19 @@ class TypeRepo(object):\nor not isinstance(prefix, BaseStructType)\n):\nreturn getattr(prefix, name)\n- else:\n+\n+ try:\nreturn prefix._fields[name]\n+ except KeyError:\n+ check_source_language(\n+ False,\n+ '{prefix} has no {attr} attribute'.format(\n+ prefix=(prefix.name.camel\n+ if isinstance(prefix, CompiledType) else\n+ prefix),\n+ attr=repr(name)\n+ )\n+ )\nreturn TypeRepo.Defer(get)\ndef __call__(self, *args, **kwargs):\n",
        "chatgpt_cot": "\"Add game_data keyword argument for compatibility, deprecate usage in from_proto and __init__ functions in Units class.\""
    },
    {
        "org_diff": "diff --git a/fkie_node_manager_daemon/src/fkie_node_manager_daemon/launcher.py b/fkie_node_manager_daemon/src/fkie_node_manager_daemon/launcher.py @@ -137,11 +137,26 @@ def create_start_config(node, launchcfg, executable='', masteruri=None, loglevel\nfor cparam in launchcfg.roscfg.clear_params:\nif cparam.startswith(nodens):\nresult.clear_params.append(cparam)\n+ if reload_global_param:\n+ result.clear_params.extend(get_global_clear_params(launchcfg.roscfg))\nrospy.logdebug(\"set delete parameter:\\n %s\", '\\n '.join(result.clear_params))\nrospy.logdebug(\"add parameter:\\n %s\", '\\n '.join(\"%s: %s%s\" % (key, utf8(val)[:80], '...' if len(utf8(val)) > 80 else '') for key, val in result.params.items()))\nreturn result\n+def get_global_clear_params(roscfg):\n+ result = []\n+ for cparam in roscfg.clear_params:\n+ nodesparam = False\n+ for n in roscfg.resolved_node_names:\n+ if cparam.startswith(n):\n+ nodesparam = True\n+ break\n+ if not nodesparam:\n+ result.append(cparam)\n+ return result\n+\n+\ndef remove_src_binary(cmdlist):\nresult = []\ncount = 0\n",
        "org_msg": "fkie_node_manager_damoen: fix clear_param for group\nThese parameter are now deleted on restart nodes with reload global\nparameter",
        "sim_msg": "retry startup",
        "sim_diff": "diff --git a/lbrynet/lbrynet_daemon/DaemonControl.py b/lbrynet/lbrynet_daemon/DaemonControl.py @@ -114,7 +114,7 @@ def update_settings_from_args(args):\n@defer.inlineCallbacks\n-def start_server_and_listen(launchui, use_auth, analytics_manager):\n+def start_server_and_listen(launchui, use_auth, analytics_manager, max_tries=5):\n\"\"\"The primary entry point for launching the daemon.\nArgs:\n@@ -124,13 +124,19 @@ def start_server_and_listen(launchui, use_auth, analytics_manager):\n\"\"\"\nanalytics_manager.send_server_startup()\nlog_support.configure_analytics_handler(analytics_manager)\n+ tries = 1\n+ while tries < max_tries:\n+ log.info('Making attempt %s / %s to startup', tries, max_tries)\ntry:\ndaemon_server = DaemonServer(analytics_manager)\nyield daemon_server.start(use_auth, launchui)\nanalytics_manager.send_server_startup_success()\n+ break\nexcept Exception as e:\nlog.exception('Failed to startup')\nanalytics_manager.send_server_startup_error(str(e))\n+ tries += 1\n+ else:\nreactor.callFromThread(reactor.stop)\n",
        "chatgpt_cot": "Add method to retrieve global clear parameters in launcher.py to handle node parameters efficiently. Fix issue with clearing parameters for non-node related configurations."
    },
    {
        "org_diff": "diff --git a/src/themes/basic/templates/cluster_info.html b/src/themes/basic/templates/cluster_info.html <dt>Containers<dt>\n<dd>\n{% if item.containers|length >0 %}\n- {% for c in item.containers.keys()%}\n+ {% for c in item.containers%}\n<a href=\"\">{{ c }}</a><br>\n{% endfor %}\n{% endif %}\n",
        "org_msg": "Open chaincode info will report error\nFix the html for list object with does not have key value",
        "sim_msg": "Add block head",
        "sim_diff": "diff --git a/templates/themes/Defaultv3/layout.html b/templates/themes/Defaultv3/layout.html <link rel=\"stylesheet\" href=\"/static/css/shared.css\">\n<link rel=\"stylesheet\" href=\"/static/css/Defaultv3/theme.css\">\n<link rel=\"stylesheet\" href=\"/static/css/Defaultv3/animation.css\">\n+\n+ {% block head %}\n+ {% endblock %}\n</head>\n<body>\n<!--Navbar-->\n",
        "chatgpt_cot": "\"Fix iteration over containers in cluster_info.html\""
    },
    {
        "org_diff": "diff --git a/README.md b/README.md @@ -17,10 +17,17 @@ By installing this library you agree to be bound by the terms of the [AI and Mac\nFor this fork, you'll need Python 3.7 or newer.\n+Install the pypi package:\n+```\n+pip install pipenv\n+pip install --ugprade burnysc2\n+```\n+or directly from develop branch:\n```\npip install pipenv\npip install --upgrade --force-reinstall https://github.com/BurnySc2/python-sc2/archive/develop.zip\n```\n+Both commands will override the `sc2` library folder, so you will not be able to have Dentosal's and this fork installed at the same time, unless you use virtual environments.\nYou'll need an StarCraft II executable. If you are running Windows or macOS, just install the normal SC2 from blizzard app. [The free starter edition works too.](https://us.battle.net/account/sc2/starter-edition/). Linux users get the best experience by installing the Windows version of StarCraft II with [Wine](https://www.winehq.org). Linux user can also use the [Linux binary](https://github.com/Blizzard/s2client-proto#downloads), but it's headless so you cannot actually see the game.\n",
        "org_msg": "Update install instruction",
        "sim_msg": "allow overriding PIP_EXISTS_ACTION via environment variable",
        "sim_diff": "diff --git a/pipenv/core.py b/pipenv/core.py @@ -26,7 +26,7 @@ from .environments import (\nPIPENV_CACHE_DIR, PIPENV_COLORBLIND, PIPENV_DEFAULT_PYTHON_VERSION,\nPIPENV_DONT_USE_PYENV, PIPENV_HIDE_EMOJIS, PIPENV_MAX_SUBPROCESS,\nPIPENV_PYUP_API_KEY, PIPENV_SHELL_FANCY, PIPENV_SKIP_VALIDATION,\n- PIPENV_YES, SESSION_IS_INTERACTIVE\n+ PIPENV_YES, SESSION_IS_INTERACTIVE, PIP_EXISTS_ACTION\n)\nfrom .project import Project, SourceNotFound\nfrom .utils import (\n@@ -1503,7 +1503,7 @@ def pip_install(\n\"PIP_DESTINATION_DIR\": vistir.misc.fs_str(\ncache_dir.joinpath(\"pkgs\").as_posix()\n),\n- \"PIP_EXISTS_ACTION\": vistir.misc.fs_str(\"w\"),\n+ \"PIP_EXISTS_ACTION\": vistir.misc.fs_str(PIP_EXISTS_ACTION or \"w\"),\n\"PATH\": vistir.misc.fs_str(os.environ.get(\"PATH\")),\n}\nif src:\n",
        "chatgpt_cot": "Update installation instructions for python-sc2 library in README.md"
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/profile_widget.py b/node_manager_fkie/src/node_manager_fkie/profile_widget.py @@ -70,6 +70,8 @@ class ProfileWidget(QDockWidget):\nnm.settings().current_dialog_path,\n\"node manager profile files (*.nmprofile);;All files (*)\") # _:=filter\nif path:\n+ if not path.endswith('.nmprofile'):\n+ path = \"%s.nmprofile\" % path\nnm.settings().current_dialog_path = os.path.dirname(path)\ntry:\n(pkg, _) = package_name(os.path.dirname(path)) # _:=pkg_path\n",
        "org_msg": "node_manager_fkie: append .nmprofile if not in name",
        "sim_msg": "add alt docker to nav",
        "sim_diff": "diff --git a/docs/conf.py b/docs/conf.py @@ -123,6 +123,7 @@ html_theme_options = {\n(\"QNAP Walkthrough\", \"home/guides/qnap\"),\n(\"unRAID Walkthrough\", \"home/guides/unraid\"),\n(\"Kubernetes Walkthrough\", \"home/guides/kubernetes\"),\n+ (\"Docker images\", \"home/guides/alternative-docker\"),\n]),\n(\"Run Commands & Environment Variables\", \"home/environmental\"),\n(\"_divider\", ),\n",
        "chatgpt_cot": "Fix file extension issue in ProfileWidget class. Ensure path ends with '.nmprofile' for node manager profile files."
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/settings.py b/node_manager_fkie/src/node_manager_fkie/settings.py @@ -165,6 +165,7 @@ class Settings(object):\n'''\nself._terminal_emulator = None\nself._terminal_command_arg = 'e'\n+ self._noclose_str = '-hold'\nself._masteruri = masteruri_from_ros()\nself.CFG_PATH = os.path.join(get_ros_home(), 'node_manager')\n# loads the current configuration path. If the path was changed, a redirection\n@@ -643,7 +644,6 @@ class Settings(object):\n:return: command with a terminal prefix\n:rtype: str\n'''\n- noclose_str = '-hold'\nif self._terminal_emulator is None:\nself._terminal_emulator = \"\"\nfor t in ['/usr/bin/x-terminal-emulator', '/usr/bin/xterm', '/opt/x11/bin/xterm']:\n@@ -654,19 +654,19 @@ class Settings(object):\nelse:\nself._terminal_command_arg = 'e'\nif os.path.basename(os.path.realpath(t)) in ['terminator', 'gnome-terminal', 'gnome-terminal.wrapper']:\n- noclose_str = '--profile hold'\n+ self._noclose_str = '--profile hold'\nif noclose:\nrospy.loginfo(\"If your terminal close after the execution, you can change this behavior in \"\n\"profiles. You can also create a profile with name 'hold'. This profile will \"\n\"be then load by node_manager.\")\nelif os.path.basename(os.path.realpath(t)) in ['xfce4-terminal']:\n- noclose_str = ''\n+ self._noclose_str = ''\nself._terminal_emulator = t\nbreak\nif self._terminal_emulator == \"\":\nraise Exception(\"No Terminal found! Please install one of ['/usr/bin/x-terminal-emulator', '/usr/bin/xterm', '/opt/x11/bin/xterm']\")\n- noclose_str = noclose_str if noclose else \"\"\n- return '%s -T \"%s\" %s -%s %s' % (self._terminal_emulator, title, noclose_str, self._terminal_command_arg, ' '.join(cmd))\n+ self._noclose_str = self._noclose_str if noclose else \"\"\n+ return '%s -T \"%s\" %s -%s %s' % (self._terminal_emulator, title, self._noclose_str, self._terminal_command_arg, ' '.join(cmd))\ndef qsettings(self, settings_file):\nfrom python_qt_binding.QtCore import QSettings\n",
        "org_msg": "fix start terminal",
        "sim_msg": "reinstate hacky code",
        "sim_diff": "diff --git a/shutit_pexpect.py b/shutit_pexpect.py @@ -490,27 +490,27 @@ class ShutItPexpectSession(object):\n# Don't use send here (will mess up last_output)!\n# Space before \"echo\" here is sic - we don't need this to show up in bash history\nself.sendline(' echo EXIT_CODE:$?')\n- #while True:\n- # Sometimes pexpect gets confused at this point (TODO why?), so we expect again until all appears ok.\n+ while True:\n+ # Sometimes pexpect gets confused at this point (TODO why? - repro'd in shutitfiles test, stalls after a login), so we expect again until all appears ok.\nshutit.log('Expecting: ' + str(expect),level=logging.DEBUG)\nself.expect(expect,timeout=60)\nres = shutit_util.match_string(str(self.pexpect_child.before), '^EXIT_CODE:([0-9][0-9]?[0-9]?)$')\n- #if res is None and (isinstance(self.pexpect_child.before, pexpect.exceptions.EOF) or isinstance(self.pexpect_child.after, pexpect.exceptions.EOF)):\n- # shutit_util.handle_exit(1)\n- #if res is None:\n- # # Try before without anchor - sometimes needed when logging into obscure shells\n- # shutit.log('Un-clean login (1), trying: ' + str(self.pexpect_child.before), level=logging.DEBUG)\n- # res = shutit_util.match_string(str(self.pexpect_child.before), '.*EXIT_CODE:([0-9][0-9]?[0-9]?)$')\n- #if res is None:\n- # # Try after - for some reason needed after login\n- # shutit.log('Un-clean login (2), trying: ' + str(self.pexpect_child.after), level=logging.DEBUG)\n- # res = shutit_util.match_string(str(self.pexpect_child.after), '^EXIT_CODE:([0-9][0-9]?[0-9]?)$')\n- #if res is None:\n- # # Try after without anchor - sometimes needed when logging into obscure\n- # shutit.log('Un-clean login (3), trying: ' + str(self.pexpect_child.after), level=logging.DEBUG)\n- # res = shutit_util.match_string(str(self.pexpect_child.after), '^.*EXIT_CODE:([0-9][0-9]?[0-9]?)$')\n- #if res != None:\n- # break\n+ if res is None and (isinstance(self.pexpect_child.before, pexpect.exceptions.EOF) or isinstance(self.pexpect_child.after, pexpect.exceptions.EOF)):\n+ shutit_util.handle_exit(1)\n+ if res is None:\n+ # Try before without anchor - sometimes needed when logging into obscure shells\n+ shutit.log('Un-clean login (1), trying: ' + str(self.pexpect_child.before), level=logging.DEBUG)\n+ res = shutit_util.match_string(str(self.pexpect_child.before), '.*EXIT_CODE:([0-9][0-9]?[0-9]?)$')\n+ if res is None:\n+ # Try after - for some reason needed after login\n+ shutit.log('Un-clean login (2), trying: ' + str(self.pexpect_child.after), level=logging.DEBUG)\n+ res = shutit_util.match_string(str(self.pexpect_child.after), '^EXIT_CODE:([0-9][0-9]?[0-9]?)$')\n+ if res is None:\n+ # Try after without anchor - sometimes needed when logging into obscure\n+ shutit.log('Un-clean login (3), trying: ' + str(self.pexpect_child.after), level=logging.DEBUG)\n+ res = shutit_util.match_string(str(self.pexpect_child.after), '^.*EXIT_CODE:([0-9][0-9]?[0-9]?)$')\n+ if res != None:\n+ break\nif res not in exit_values or res is None:\nif res is None:\nres_str = str(res)\n",
        "chatgpt_cot": "\"Add noclose_str attribute to Settings class for terminal command, set to '-hold' for gnome-terminal, and '--profile hold' for xfce4-terminal.\""
    },
    {
        "org_diff": "diff --git a/default_cfg_fkie/src/default_cfg_fkie/default_cfg.py b/default_cfg_fkie/src/default_cfg_fkie/default_cfg.py @@ -123,9 +123,9 @@ class DefaultCfg(object):\nself.masteruri = self._masteruri_from_ros()\nself.roscfg = ROSLaunchConfig()\nloader = XmlLoader()\n- argv = [a for a in sys.argv if not a.startswith('__ns:=')]\n+ argv = [a for a in sys.argv if not a.startswith('__ns:=') and not a.startswith('__name:=')]\n# remove namespace from sys.argv to avoid load the launchfile info local namespace\n- sys.argv = [a for a in sys.argv if not a.startswith('__ns:=')]\n+ sys.argv = [a for a in sys.argv if not a.startswith('__ns:=') and not a.startswith('__name:=')]\n# set the global environment to empty namespace\nos.environ[ROS_NAMESPACE] = rospy.names.SEP\nloader.load(launch_path, self.roscfg, verbose=False, argv=argv)\n",
        "org_msg": "default_cfg_fkie: fixed problem with \"pass_all_args\" attribute",
        "sim_msg": "Disabling recent activity in the sidebar by default until we address the performance issues",
        "sim_diff": "diff --git a/app/config.py b/app/config.py @@ -57,7 +57,7 @@ cfg_defaults = { # key => default value\n\"trusted_proxy_count\": 0,\n\"custom_hot_sort\": False,\n\"recent_activity\": {\n- \"enabled\": True,\n+ \"enabled\": False, # TODO: Address performance issues\n\"defaults_only\": False,\n\"comments_only\": False,\n\"max_entries\": 10,\n",
        "chatgpt_cot": "\"Fix issue with loading launchfile info in local namespace by updating argv filtering in DefaultCfg class\""
    },
    {
        "org_diff": "diff --git a/.travis.yml b/.travis.yml @@ -3,8 +3,8 @@ services:\nlanguage: generic\nenv:\nmatrix:\n- - ROS_DISTRO=\"kinetic\"\n- - ROS_DISTRO=\"melodic\"\n+ - ROS_DISTRO=\"kinetic\" OS_CODE_NAME=\"xenial\"\n+ - ROS_DISTRO=\"melodic\" OS_CODE_NAME=\"bionic\"\ninstall:\n- git clone --quiet --depth 1 https://github.com/ros-industrial/industrial_ci.git .industrial_ci -b master\nscript:\n",
        "org_msg": "added OS_CODE_NAME to travis script",
        "sim_msg": "deploy to pypi as a build stage so it only happens once (at the end)",
        "sim_diff": "diff --git a/.travis.yml b/.travis.yml @@ -79,6 +79,17 @@ matrix:\n- stage: test\npython: 3.6\nenv: TOX_ENV=py36-latest-lib\n+ - stage: deploy\n+ script: skip\n+ deploy:\n+ provider: pypi\n+ user: onefinestay\n+ password:\n+ secure: Mwinp9cxGaGe/KjGFcO+T7MAgLvy5yFNeYCq9zpGniuSXsp/AFH3JIS1kWBv71tMC8S2N5kwRMVXoHNMqJt+Iq/EmYIY6vbMK8GijAUqLo8KsbxgmigWTXTn6IHKDO4gwYmQt8BDYJmbq6CNeVVCHMxWyP0Y24S25y7N35oIroU=\n+ on:\n+ tags: true\n+ repo: nameko/nameko\n+ distributions: \"sdist bdist_wheel\"\n- stage: mastereventlet\npython: 2.7\nenv: TOX_ENV=py27-mastereventlet-lib\n@@ -105,12 +116,4 @@ matrix:\nscript:\n- tox -e $TOX_ENV\n-deploy:\n- provider: pypi\n- user: onefinestay\n- password:\n- secure: Mwinp9cxGaGe/KjGFcO+T7MAgLvy5yFNeYCq9zpGniuSXsp/AFH3JIS1kWBv71tMC8S2N5kwRMVXoHNMqJt+Iq/EmYIY6vbMK8GijAUqLo8KsbxgmigWTXTn6IHKDO4gwYmQt8BDYJmbq6CNeVVCHMxWyP0Y24S25y7N35oIroU=\n- on:\n- tags: true\n- repo: nameko/nameko\n- distributions: \"sdist bdist_wheel\"\n+\n",
        "chatgpt_cot": "Update ROS_DISTRO and OS_CODE_NAME in Travis CI configuration."
    },
    {
        "org_diff": "diff --git a/src/api-engine/api/routes/agent/views.py b/src/api-engine/api/routes/agent/views.py @@ -231,7 +231,25 @@ class AgentViewSet(viewsets.ViewSet):\nPartial update special agent with id.\n\"\"\"\n- pass\n+ serializer = AgentPatchBody(data=request.data)\n+ if serializer.is_valid(raise_exception=True):\n+ name = serializer.validated_data.get(\"name\")\n+ capacity = serializer.validated_data.get(\"capacity\")\n+ log_level = serializer.validated_data.get(\"log_level\")\n+ try:\n+ agent = Agent.objects.get(id=pk)\n+ except ObjectDoesNotExist:\n+ raise ResourceNotFound\n+ else:\n+ if name:\n+ agent.name = name\n+ if capacity:\n+ agent.capacity = capacity\n+ if log_level:\n+ agent.log_level = log_level\n+ agent.save()\n+\n+ return Response(status=status.HTTP_202_ACCEPTED)\n@swagger_auto_schema(\nresponses=with_common_response(\n",
        "org_msg": "Add Partial Update to Agent API\nThis add partial update operation to the agent api.",
        "sim_msg": "fix logging of webhook url",
        "sim_diff": "diff --git a/demo/runners/support/agent.py b/demo/runners/support/agent.py @@ -525,7 +525,7 @@ class DemoAgent:\nmethod = getattr(self, handler, None)\nif method:\nself.log(\n- f\"Agent called controller webhook: POST {self.webhook_url}\",\n+ f\"Agent called controller webhook: POST {self.webhook_url}/topic/{topic}/\",\n(f\"\\nFor wallet: {wallet_id}\" if wallet_id else \"\"),\n(f\"\\nPayload: {repr_json(payload)}\" if payload else repr_json({})),\n)\n",
        "chatgpt_cot": "Add partial update functionality to AgentViewSet. Validate and update name, capacity, and log level of the agent. Fix compilation issue with AgentPatchBody."
    },
    {
        "org_diff": "diff --git a/fkie_node_manager/src/fkie_node_manager/main_window.py b/fkie_node_manager/src/fkie_node_manager/main_window.py @@ -801,17 +801,17 @@ class MainWindow(QMainWindow):\nif msg.state in [MasterState.STATE_NEW, MasterState.STATE_CHANGED]:\n# we don't know which name for host was used to start master discovery\nif host in self._syncs_to_start:\n- self.on_sync_start(msg.master.uri)\nself._syncs_to_start.remove(host)\n- elif msg.master.name in self._syncs_to_start:\nself.on_sync_start(msg.master.uri)\n+ elif msg.master.name in self._syncs_to_start:\nself._syncs_to_start.remove(msg.master.name)\n+ self.on_sync_start(msg.master.uri)\nelse:\naddresses = nm.nameres().addresses(msg.master.uri)\nfor address in addresses:\nif address in self._syncs_to_start:\n- self.on_sync_start(msg.master.uri)\nself._syncs_to_start.remove(address)\n+ self.on_sync_start(msg.master.uri)\n# if len(self.masters) == 0:\n# self._setLocalMonitoring(True)\n",
        "org_msg": "fkie_node_manager: fix for crash while start master_discovery with master_sync",
        "sim_msg": "protect against permission denied issues",
        "sim_diff": "diff --git a/GearBot/Cogs/Moderation.py b/GearBot/Cogs/Moderation.py @@ -677,6 +677,8 @@ class Moderation(BaseCog):\nawait ctx.invoke(self.bot.get_command(\"help\"), query=\"clean\")\n@clean.command(\"user\")\n+ @commands.guild_only()\n+ @commands.bot_has_permissions(manage_messages=True)\nasync def clean_user(self, ctx, users: Greedy[DiscordUser], amount: RangedInt(1) = 50):\n\"\"\"clean_user_help\"\"\"\nif len(users) is 0:\n@@ -684,16 +686,22 @@ class Moderation(BaseCog):\nawait self._clean(ctx, amount, lambda m: any(m.author.id == user.id for user in users))\n@clean.command(\"bots\")\n+ @commands.guild_only()\n+ @commands.bot_has_permissions(manage_messages=True)\nasync def clean_bots(self, ctx, amount: RangedInt(1) = 50):\n\"\"\"clean_bots_help\"\"\"\nawait self._clean(ctx, amount, lambda m: m.author.bot)\n@clean.command(\"all\")\n+ @commands.guild_only()\n+ @commands.bot_has_permissions(manage_messages=True)\nasync def clean_all(self, ctx, amount: RangedInt(1, 5000)):\n\"\"\"clean_all_help\"\"\"\nawait self._clean(ctx, amount, lambda m: True, check_amount=amount)\n@clean.command(\"last\")\n+ @commands.guild_only()\n+ @commands.bot_has_permissions(manage_messages=True)\nasync def clean_last(self, ctx, duration: Duration, excess=\"\"):\n\"\"\"clean_last_help\"\"\"\nif duration.unit is None:\n@@ -702,11 +710,15 @@ class Moderation(BaseCog):\nawait self._clean(ctx, 5000, lambda m: True, after=until)\n@clean.command(\"until\")\n+ @commands.guild_only()\n+ @commands.bot_has_permissions(manage_messages=True)\nasync def clean_until(self, ctx, message:Message(local_only=True)):\n\"\"\"clean_until_help\"\"\"\nawait self._clean(ctx, 5000, lambda m: True, after=Object(message.id-1))\n@clean.command(\"between\")\n+ @commands.guild_only()\n+ @commands.bot_has_permissions(manage_messages=True)\nasync def clean_between(self, ctx, start: Message(local_only=True), end: Message(local_only=True)):\n\"\"\"clean_between_help\"\"\"\na = min(start.id, end.id)\n@@ -714,6 +726,8 @@ class Moderation(BaseCog):\nawait self._clean(ctx, 5000, lambda m: True , before=Object(b+1), after=Object(a+1))\n@clean.command(\"everywhere\")\n+ @commands.guild_only()\n+ @commands.bot_has_permissions(manage_messages=True)\nasync def clean_everywhere(self, ctx, users: Greedy[DiscordUser], amount: RangedInt(1) = 50):\n\"\"\"clean_everywhere_help\"\"\"\nif len(users) is 0:\n",
        "chatgpt_cot": "\"Fix issue with starting syncs in main window due to removal of syncs and addresses\""
    },
    {
        "org_diff": "diff --git a/.github/workflows/ci.yml b/.github/workflows/ci.yml @@ -7,6 +7,7 @@ on:\npaths:\n- sc2/**\n- examples/**\n+ - test/**\n- docs_generate/**\n- pyproject.toml\n- poetry.lock\n@@ -55,6 +56,7 @@ jobs:\nrun: poetry config virtualenvs.in-project true\n- name: Set up cache\n+ if: matrix.os != 'windows-latest'\nuses: actions/cache@v3\nwith:\npath: .venv\n",
        "org_msg": "Disable cache on windows",
        "sim_msg": "ci: fix poetry install",
        "sim_diff": "diff --git a/.github/workflows/cicd.yaml b/.github/workflows/cicd.yaml @@ -26,6 +26,7 @@ jobs:\nwith:\nvirtualenvs-create: true\nvirtualenvs-in-project: true\n+ virtualenvs-path: \"{project-dir}/.venv\"\n- name: Load cached venv\nid: cached-poetry-dependencies\nuses: actions/cache@v3\n",
        "chatgpt_cot": "\"Add test directory to CI workflow and set up cache for non-Windows OS\""
    },
    {
        "org_diff": "diff --git a/sc2/main.py b/sc2/main.py @@ -61,13 +61,14 @@ async def _play_game(player, client, realtime, portconfig, step_time_limit=None)\nassert isinstance(realtime, bool), repr(realtime)\nplayer_id = await client.join_game(player.race, portconfig=portconfig)\n+ logging.info(f\"Player id: {player_id}\")\nif isinstance(player, Human):\nresult = await _play_game_human(client, player_id, realtime)\nelse:\nresult = await _play_game_ai(client, player_id, player.ai, realtime, step_time_limit)\n- logging.info(f\"Result for player id={player_id}: {result}\")\n+ logging.info(f\"Result for player id: {player_id}: {result}\")\nreturn result\nasync def _host_game(map_settings, players, realtime, portconfig=None, save_replay_as=None, step_time_limit=None):\n",
        "org_msg": "Log player id before game starts",
        "sim_msg": "Use `mode.value` instead enumerate.",
        "sim_diff": "diff --git a/app/objects/player.py b/app/objects/player.py @@ -536,14 +536,14 @@ class Player:\nasync with app.state.services.database.connection() as db_conn:\nawait self.stats_from_sql_full(db_conn)\n- for idx, mode_stat in enumerate(self.stats.values()):\n+ for mode, stats in self.stats.items():\nawait app.state.services.redis.zadd(\n- f\"gulag:leaderboard:{idx}\",\n- {self.id: mode_stat.pp},\n+ f\"gulag:leaderboard:{mode.value}\",\n+ {self.id: stats.pp},\n)\nawait app.state.services.redis.zadd(\n- f\"gulag:leaderboard:{idx}:{self.geoloc['country']['acronym']}\",\n- {self.id: mode_stat.pp},\n+ f\"gulag:leaderboard:{mode.value}:{self.geoloc['country']['acronym']}\",\n+ {self.id: stats.pp},\n)\nif \"restricted\" in self.__dict__:\n",
        "chatgpt_cot": "Add logging of player id in main.py for better debugging and monitoring purposes."
    },
    {
        "org_diff": "diff --git a/fkie_node_manager/src/fkie_node_manager/main_window.py b/fkie_node_manager/src/fkie_node_manager/main_window.py @@ -226,6 +226,8 @@ class MainWindow(QMainWindow):\nself._progress_queue = ProgressQueue(self.progressFrame, self.progressBar, self.progressCancelButton, 'Network')\nself._progress_queue_sync = ProgressQueue(self.progressFrame_sync, self.progressBar_sync, self.progressCancelButton_sync, 'Sync')\n+ rospy.loginfo('Detected ROS Master URI: %s' % self.getMasteruri())\n+\n# initialize the view for the discovered ROS master\nself.master_model = MasterModel(self.getMasteruri())\nself.master_model.sync_start.connect(self.on_sync_start)\n",
        "org_msg": "fkie_node_manager: added output for detected ROS Master URI",
        "sim_msg": "root block synchronizer checks TD before starting sync task",
        "sim_diff": "diff --git a/quarkchain/cluster/master.py b/quarkchain/cluster/master.py @@ -335,6 +335,9 @@ class Synchronizer:\nself.root_block_header_list_limit = ROOT_BLOCK_HEADER_LIST_LIMIT\ndef add_task(self, header, peer):\n+ if header.total_difficulty <= peer.root_state.tip.total_difficulty:\n+ return\n+\nself.tasks[peer] = header\nLogger.info(\n\"[R] added {} {} to sync queue (running={})\".format(\n@@ -367,17 +370,33 @@ class Synchronizer:\ndef _pop_best_task(self):\n\"\"\" pop and return the task with heightest root \"\"\"\ncheck(len(self.tasks) > 0)\n- peer, header = max(\n- self.tasks.items(), key=lambda pair: pair[1].total_difficulty\n- )\n+ remove_list = []\n+ best_peer = None\n+ best_header = None\n+ for peer, header in self.tasks.items():\n+ if header.total_difficulty <= peer.root_state.tip.total_difficulty:\n+ remove_list.append(peer)\n+ continue\n+\n+ if best_header is None or header.total_difficulty > best_header.total_difficulty:\n+ best_header = header\n+ best_peer = peer\n+\n+ for peer in remove_list:\ndel self.tasks[peer]\n- return header, peer\n+ if best_peer is not None:\n+ del self.tasks[best_peer]\n+\n+ return best_header, best_peer\nasync def __run(self):\nLogger.info(\"[R] synchronizer started!\")\nwhile len(self.tasks) > 0:\nself.running_task = self._pop_best_task()\nheader, peer = self.running_task\n+ if header is None:\n+ check(len(self.tasks) == 0)\n+ break\ntask = SyncTask(header, peer, self.stats, self.root_block_header_list_limit)\nLogger.info(\n\"[R] start sync task {} {}\".format(\n",
        "chatgpt_cot": "Add loginfo for detected ROS Master URI in MainWindow class. Initialize view for discovered ROS master."
    },
    {
        "org_diff": "diff --git a/src/api-engine/api/models.py b/src/api-engine/api/models.py @@ -71,7 +71,7 @@ class UserProfile(AbstractUser):\ndefault=UserRole.User.value,\nmax_length=64,\n)\n- organization = models.OneToOneField(\n+ organization = models.ForeignKey(\nOrganization, null=True, on_delete=models.CASCADE\n)\n@@ -288,7 +288,7 @@ class Node(models.Model):\nblank=True,\ndefault=dict,\n)\n- user = models.OneToOneField(\n+ user = models.ForeignKey(\nUserProfile,\nhelp_text=\"User of node\",\nnull=True,\n",
        "org_msg": "Fix OneToOne filed error\nShould use Foreign key for one to multi db relation.",
        "sim_msg": "ADD institution / website as optional fields during user creation",
        "sim_diff": "diff --git a/packages/grid/backend/grid/api/users/models.py b/packages/grid/backend/grid/api/users/models.py @@ -24,6 +24,12 @@ class UserCreate(BaseUser):\nrole: str = \"Data Scientist\"\nname: str\npassword: str\n+ institution: Optional[str]\n+ website: Optional[str]\n+\n+\n+class ApplicantStatus(BaseModel):\n+ status: str\nclass UserUpdate(BaseUser):\n@@ -45,6 +51,7 @@ class User(BaseUser):\nwebsite: Optional[str]\nadded_by: Optional[str]\n+\nclass UserPrivate(User):\nprivate_key: str\n",
        "chatgpt_cot": "Update UserProfile and Node models to use ForeignKey instead of OneToOneField for better data representation and flexibility in relationships."
    },
    {
        "org_diff": "diff --git a/rasa_core_sdk/forms.py b/rasa_core_sdk/forms.py @@ -59,8 +59,8 @@ class FormAction(Action):\n- a whole message\nor a list of them, where a first match will be picked\n- Empty dict converted to extracted entity\n- with the same name as a slot\n+ Empty dict is converted to a mapping of\n+ the slot to the extracted entity with the same name\n\"\"\"\nreturn {}\n@@ -109,7 +109,7 @@ class FormAction(Action):\ntracker.latest_message.get(\"text\"))]\nelse:\n- raise NotImplementedError(\n+ raise ValueError(\n'Provided slot_mapping[\"type\"] '\n'is not supported')\n",
        "org_msg": "change error type, update comment RasaHQ/roadmap#280",
        "sim_msg": "add deserializaton for smpc action message",
        "sim_diff": "diff --git a/packages/syft/src/syft/core/node/common/action/smpc_action_message.py b/packages/syft/src/syft/core/node/common/action/smpc_action_message.py @@ -150,7 +150,7 @@ class SMPCActionMessage(ImmediateSyftMessageWithoutReply):\nname_action=proto.name_action,\nself_id=sy.deserialize(blob=proto.self_id),\nargs_id=list(map(lambda x: sy.deserialize(blob=x), proto.args_id)),\n- kwargs_id={k: v for k, v in proto.kwargs_id.items()},\n+ kwargs_id={k: sy.deserialize(blob=v) for k, v in proto.kwargs_id.items()},\nresult_id=sy.deserialize(blob=proto.id_at_location),\naddress=proto,\n)\n",
        "chatgpt_cot": "\"Fix ValueError in FormAction due to unsupported slot_mapping type, Empty dict is converted to a mapping of the slot to the extracted entity.\""
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/master_view_proxy.py b/node_manager_fkie/src/node_manager_fkie/master_view_proxy.py @@ -1274,7 +1274,7 @@ class MasterViewProxy(QWidget):\nif count is not None:\nitem = '<a href=\"topic://%s\">%s</a>' % (i, item_name)\nitem += ' <a href=\"topicecho://%s%s\"><span style=\"color:gray;\"><i>echo</i></span></a>' % (self.mastername, i)\n- item = '<span style=\"color:gray;\">_%d_/ </span>%s' % (count, item)\n+ item = '<span style=\"color:gray;\">_%d_: </span>%s' % (count, item)\nelse:\nitem = '<a>%s</a>' % (item_name)\nitem = '<span style=\"color:red;\">!sync </span>%s' % (item)\n",
        "org_msg": "node_manager_fkie: changed visualization for topic count",
        "sim_msg": "link help pages (bug tracker, mailing list, releases)",
        "sim_diff": "diff --git a/main.py b/main.py @@ -413,7 +413,14 @@ class wxGladeFrame(wx.Frame):\nmisc.bind_menu_item(self, MANUAL, self.show_manual)\n#item = append_menu_item(help_menu, -1, _('Tutorial'))\n#misc.bind_menu_item(self, item, self.show_tutorial)\n+ help_menu.AppendSeparator() # ----------------------------------------------------------------------------------\n+ i = append_menu_item(help_menu, -1, _('Mailing list'))\n+ misc.bind_menu_item(self, i, self.show_mailing_list)\n+ i = append_menu_item(help_menu, -1, _('Bug tracker'))\n+ misc.bind_menu_item(self, i, self.show_bug_tracker)\n+ i = append_menu_item(help_menu, -1, _('Releases'))\n+ misc.bind_menu_item(self, i, self.show_releases)\nhelp_menu.AppendSeparator() # ----------------------------------------------------------------------------------\nitem = append_menu_item(help_menu, wx.ID_ABOUT, _('About'))\n@@ -897,6 +904,13 @@ class wxGladeFrame(wx.Frame):\n#\"Show the wxGlade tutorial\"\n#self._show_html(config.tutorial_file)\n+ def show_bug_tracker(self):\n+ self._show_html(\"https://github.com/wxGlade/wxGlade/issues\")\n+ def show_mailing_list(self):\n+ self._show_html(\"https://sourceforge.net/p/wxglade/mailman/wxglade-general/\")\n+ def show_releases(self):\n+ self._show_html(\"https://github.com/wxGlade/wxGlade/releases\")\n+\ndef _show_html(self, html_file):\n\"Open browser and show an HTML documentation\"\n",
        "chatgpt_cot": "Fix display issue in MasterViewProxy by changing the formatting of item count from underscore and slash to underscore and colon for better readability."
    },
    {
        "org_diff": "diff --git a/.github/stale.yml b/.github/stale.yml # SPDX-License-Identifier: Apache-2.0\n# Number of days of inactivity before an issue becomes stale\n-daysUntilStale: 0\n+daysUntilStale: 14\n# Number of days of inactivity before a stale issue is closed\n-daysUntilClose: 1\n+daysUntilClose: 7\n# Issues with these labels will never be considered stale\n# CAUTION: These issues are likely to get _less_ attention since stale bot\n# will never nag anyone about them. Stale bot just reflects the community's\n@@ -16,12 +16,6 @@ daysUntilClose: 1\nstaleLabel: stale\nonly: pulls\n# Comment to post when marking an issue as stale. Set to `false` to disable\n-markComment: >\n- Thank you for your contribution!\n- Please use gerrit for the changes, see\n- [documentation here](https://cello.readthedocs.io/en/latest/CONTRIBUTING/)\n-# Comment to post when closing a stale issue. Set to `false` to disable\n-closeComment: >\n- Thank you for your contribution!\n- Please use gerrit for the changes, see\n- [documentation here](https://cello.readthedocs.io/en/latest/CONTRIBUTING/)\n+markComment: false\n+#\n+closeComment: false\n",
        "org_msg": "Defang stalebot",
        "sim_msg": "Update kinder stale-bot config",
        "sim_diff": "diff --git a/.github/stale.yml b/.github/stale.yml # Configuration for probot-stale - https://github.com/probot/stale\n# Number of days of inactivity before an Issue or Pull Request becomes stale\n-daysUntilStale: 7\n+daysUntilStale: 10\n# Number of days of inactivity before a stale Issue or Pull Request is closed.\n# Set to false to disable. If disabled, issues still need to be closed manually, but will remain marked as stale.\n-daysUntilClose: 2\n+daysUntilClose: 7\n# Issues or Pull Requests with these labels will never be considered stale. Set to `[]` to disable\nexemptLabels:\n@@ -23,9 +23,9 @@ staleLabel: inactive\n# Comment to post when marking as stale. Set to `false` to disable\nmarkComment: >\nThis pull request has been automatically marked as stale because it has not had\n- recent activity. It will be closed if no further activity occurs, but it\n- only takes a comment to keep a contribution alive :) Thank you\n- for contributing.\n+ recent activity. It will be closed within a week if no further activity occurs, but it\n+ only takes a comment to keep a contribution alive :) Also, even if it is closed,\n+ you can always reopen the PR when you're ready. Thank you for contributing.\n# Limit the number of actions per hour, from 1-30. Default is 30\nlimitPerRun: 30\n",
        "chatgpt_cot": "\"Update stale.yml to change days until stale and close, and disable mark and close comment to reduce notifications.\""
    },
    {
        "org_diff": "diff --git a/sc2/ids/unit_typeid.py b/sc2/ids/unit_typeid.py @@ -1935,10 +1935,18 @@ class UnitTypeId(enum.Enum):\nTYCHUSHERCACGLUESCREENDUMMY = 1928\nTYCHUSGHOSTACGLUESCREENDUMMY = 1929\nTYCHUSSCVAUTOTURRETACGLUESCREENDUMMY = 1930\n- RENEGADELONGBOLTMISSILEWEAPON = 1931\n- VIKING = 1932\n- RENEGADEMISSILETURRET = 1933\n- PARASITICBOMBRELAYDUMMY = 1934\n+ ZERATULSTALKERACGLUESCREENDUMMY = 1931\n+ ZERATULSENTRYACGLUESCREENDUMMY = 1932\n+ ZERATULDARKTEMPLARACGLUESCREENDUMMY = 1933\n+ ZERATULIMMORTALACGLUESCREENDUMMY = 1934\n+ ZERATULOBSERVERACGLUESCREENDUMMY = 1935\n+ ZERATULDISRUPTORACGLUESCREENDUMMY = 1936\n+ ZERATULWARPPRISMACGLUESCREENDUMMY = 1937\n+ ZERATULPHOTONCANNONACGLUESCREENDUMMY = 1938\n+ RENEGADELONGBOLTMISSILEWEAPON = 1939\n+ VIKING = 1940\n+ RENEGADEMISSILETURRET = 1941\n+ PARASITICBOMBRELAYDUMMY = 1942\nfor item in UnitTypeId:\nassert not item.name in globals()\n",
        "org_msg": "Update unit_typeid to fix Viking enum",
        "sim_msg": "add mode priorities to Text UI",
        "sim_diff": "diff --git a/mpf/core/tui.py b/mpf/core/tui.py @@ -130,7 +130,8 @@ class TextUi(object):\nfor i, mode in enumerate(modes):\nself.screen.print_at(' ' * (int(self.screen.width / 2) - 1),\n1, i+3)\n- self.screen.print_at(mode.name, 1, i+3)\n+ self.screen.print_at('{} ({})'.format(mode.name, mode.priority),\n+ 1, i+3)\nself.screen.print_at(' ' * (int(self.screen.width / 2) - 1),\n1, len(modes) + 3)\n",
        "chatgpt_cot": "Add Zeratul units and update unit IDs in UnitTypeId enum for StarCraft II game. Fixes compilation issues and adds new units."
    },
    {
        "org_diff": "diff --git a/.github/workflows/codecoverage.yml b/.github/workflows/codecoverage.yml @@ -77,7 +77,6 @@ jobs:\nuses: codecov/codecov-action@v2\nwith:\nfiles: coverage.xml\n- fail_ci_if_error: true\n- name: Generate html coverage files in htmlcov/ folder\nrun: |\n@@ -85,7 +84,7 @@ jobs:\necho \"Upload htmlcov folder because it was mounted in container, so it will be available in host machine\"\n- name: Upload htmlcov/ folder as artifact\n- uses: actions/upload-artifact@v1\n+ uses: actions/upload-artifact@v3\nwith:\nname: Coverage_report\npath: htmlcov\n",
        "org_msg": "Set fail_ci_if_error to false",
        "sim_msg": "small fix for workflow",
        "sim_diff": "diff --git a/.github/workflows/workflow.yml b/.github/workflows/workflow.yml @@ -514,10 +514,9 @@ jobs:\nmake test\n- name: Upload coverage report\nuses: codecov/codecov-action@v1.0.2\n- working-directory: ./libs/go/libp2p_node/\nwith:\ntoken: ${{ secrets.CODECOV_TOKEN }}\n- file: ./coverage.out\n+ file: ./libs/go/libp2p_node/coverage.out\nflags: unittests_go\nname: codecov-umbrella\ncoverage_checks:\n",
        "chatgpt_cot": "Update upload artifact action to version 3 in codecoverage.yml."
    },
    {
        "org_diff": "diff --git a/docs/deployment.md b/docs/deployment.md @@ -114,7 +114,7 @@ You may check `git` and `make` are installed to clone the code.\n```sh\n$ sudo aptitude install git make -y\n-$ git clone https://github.com/yeasy/cello && cd cello\n+$ git clone http://gerrit.hyperledger.org/r/cello && cd cello\n```\n### Docker images pulling\n",
        "org_msg": "A slight change in docs, the URI of cello repository.",
        "sim_msg": "Put the keys / secrets in for PaddlePaddle.org scripts to use",
        "sim_diff": "diff --git a/scripts/deploy_docs.sh b/scripts/deploy_docs.sh @@ -50,6 +50,8 @@ docker run -it \\\n-e DEPLOY_DOCS_SH=$DEPLOY_DOCS_SH \\\n-e TRAVIS_PULL_REQUEST=$TRAVIS_PULL_REQUEST \\\n-e PPO_SCRIPT_BRANCH=$PPO_SCRIPT_BRANCH \\\n+ -e AWS_ACCESS_KEY_ID=$AWS_ACCESS_KEY_ID \\\n+ -e AWS_SECRET_ACCESS_KEY=$AWS_SECRET_ACCESS_KEY \\\n-e PADDLE_ROOT=/FluidDoc/external/Paddle \\\n-e PYTHONPATH=/FluidDoc/external/Paddle/build/python \\\n-v \"$PWD:/FluidDoc\" \\\n",
        "chatgpt_cot": "Update git clone URL to point to Hyperledger Gerrit for Cello project in deployment.md file."
    },
    {
        "org_diff": "diff --git a/fkie_node_manager/src/fkie_node_manager/master_view_proxy.py b/fkie_node_manager/src/fkie_node_manager/master_view_proxy.py @@ -1118,6 +1118,12 @@ class MasterViewProxy(QWidget):\nnew_configs.append(ld.path)\nself.__configs[ld.path].nodes = ld.nodes\nalredy_added_nodes = set()\n+ # update node configuration\n+ node_cfgs = dict()\n+ for n in ld.nodes:\n+ # if n not in alredy_added_nodes:\n+ node_cfgs[n] = ld.path\n+ self.node_tree_model.append_config(masteruri, host_addr, node_cfgs)\n# update capabilities\nfor rd in ld.robot_descriptions:\n# add capabilities\n@@ -1134,6 +1140,9 @@ class MasterViewProxy(QWidget):\nvalid_machine = False\nif rd.machine and rd.machine != host:\nrobot_addr = rd.machine\n+ valid_machine = True\n+ # print('append', masteruri, robot_addr, rd_node_cfgs)\n+ if robot_addr != host_addr:\nself.node_tree_model.append_config(masteruri, robot_addr, rd_node_cfgs)\nif valid_machine or not rd.robot_name or utf8(rd.robot_name) == self.mastername:\nself.node_tree_model.add_capabilities(masteruri, robot_addr, ld.path, caps)\n@@ -1141,11 +1150,6 @@ class MasterViewProxy(QWidget):\ntooltip = self.node_tree_model.update_host_description(masteruri, robot_addr, rd.robot_type, utf8(rd.robot_name), interpret_path(utf8(rd.robot_descr)))\nself.capabilities_update_signal.emit(masteruri, robot_addr, ld.path, [rd])\nself.host_description_updated.emit(masteruri, robot_addr, tooltip)\n- node_cfgs = dict()\n- for n in ld.nodes:\n- # if n not in alredy_added_nodes:\n- node_cfgs[n] = ld.path\n- self.node_tree_model.append_config(masteruri, host_addr, node_cfgs)\n# set the robot_icon\nif ld.path in self.__robot_icons:\nself.__robot_icons.remove(ld.path)\n",
        "org_msg": "fkie_node_manager: fixed deselect nodes while start nodes on other host",
        "sim_msg": "Remove GroupManager from network node",
        "sim_diff": "diff --git a/packages/syft/src/syft/core/node/network/network.py b/packages/syft/src/syft/core/node/network/network.py @@ -26,7 +26,6 @@ from ...io.location import Location\nfrom ...io.location import SpecificLocation\nfrom ..common.node import Node\nfrom ..common.node_manager.association_request_manager import AssociationRequestManager\n-from ..common.node_manager.group_manager import GroupManager\nfrom ..common.node_manager.node_manager import NodeManager\nfrom ..common.node_manager.node_route_manager import NodeRouteManager\nfrom ..common.node_manager.role_manager import RoleManager\n@@ -101,7 +100,6 @@ class Network(Node):\n# Database Management Instances\nself.users = UserManager(db_engine)\nself.roles = RoleManager(db_engine)\n- self.groups = GroupManager(db_engine)\nself.node = NodeManager(db_engine)\nself.node_route = NodeRouteManager(db_engine)\nself.association_requests = AssociationRequestManager(db_engine)\n",
        "chatgpt_cot": "Refactor node configuration handling in MasterViewProxy to prevent duplication and improve clarity. Fix valid_machine flag usage and remove redundant code."
    },
    {
        "org_diff": "diff --git a/rasa_core_sdk/events.py b/rasa_core_sdk/events.py @@ -157,7 +157,7 @@ def ActionExecutionRejected(action_name, policy=None, confidence=None,\ntimestamp=None):\nreturn {\n\"event\": \"action_execution_rejected\",\n- \"action_name\": action_name,\n+ \"name\": action_name,\n\"policy\": policy,\n\"confidence\": confidence,\n\"timestamp\": timestamp,\n",
        "org_msg": "rename action_name to name in as_dict in Rejected event RasaHQ/roadmap#280",
        "sim_msg": "Deleting from event_push_actions needs to use an index",
        "sim_diff": "diff --git a/synapse/storage/events.py b/synapse/storage/events.py @@ -1044,7 +1044,6 @@ class EventsStore(EventsWorkerStore):\n\"event_edge_hashes\",\n\"event_edges\",\n\"event_forward_extremities\",\n- \"event_push_actions\",\n\"event_reference_hashes\",\n\"event_search\",\n\"event_signatures\",\n@@ -1064,6 +1063,14 @@ class EventsStore(EventsWorkerStore):\n[(ev.event_id,) for ev, _ in events_and_contexts]\n)\n+ for table in (\n+ \"event_push_actions\",\n+ ):\n+ txn.executemany(\n+ \"DELETE FROM %s WHERE room_id = ? AND event_id = ?\" % (table,),\n+ [(ev.event_id,) for ev, _ in events_and_contexts]\n+ )\n+\ndef _store_event_txn(self, txn, events_and_contexts):\n\"\"\"Insert new events into the event and event_json tables\n",
        "chatgpt_cot": "\"Refactor action name key in ActionExecutionRejected event to 'name' for consistency and clarity\""
    },
    {
        "org_diff": "diff --git a/master_discovery_fkie/src/master_discovery_fkie/master_discovery.py b/master_discovery_fkie/src/master_discovery_fkie/master_discovery.py # ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE\n# POSSIBILITY OF SUCH DAMAGE.\n-from hgext.convert.convcmd import recode\nfrom urlparse import urlparse\nimport Queue\nimport errno\n",
        "org_msg": "master_discovery_fkie: removed a not needed import",
        "sim_msg": "Add deprecation warnings to poly_energy/poly_energies",
        "sim_diff": "diff --git a/dimod/higherorder/utils.py b/dimod/higherorder/utils.py # See the License for the specific language governing permissions and\n# limitations under the License.\n#\n-# ================================================================================================\n+# =============================================================================\nimport itertools\n+import warnings\n+\nfrom collections import Counter\nimport numpy as np\n+\nfrom six import iteritems\nfrom dimod.binary_quadratic_model import BinaryQuadraticModel\n-from dimod.higherorder.polynomial import Polynomial\n+from dimod.higherorder.polynomial import BinaryPolynomial\nfrom dimod.sampleset import as_samples\nfrom dimod.vartypes import Vartype\n@@ -273,7 +276,13 @@ def poly_energy(sample_like, poly):\nfloat: The energy of the sample.\n\"\"\"\n- return Polynomial(poly).energy(sample_like)\n+\n+ msg = (\"poly_energy is deprecated and will be remobed in dimod 0.9.0.\"\n+ \"In the future, use BinaryPolynomial.energy\")\n+ warnings.warn(msg, DeprecationWarning)\n+ # dev note the vartype is not used in the energy calculation and this will\n+ # be deprecated in the future\n+ return BinaryPolynomial(poly, 'SPIN').energy(sample_like)\ndef poly_energies(samples_like, poly):\n@@ -294,7 +303,12 @@ def poly_energies(samples_like, poly):\nlist/:obj:`numpy.ndarray`: The energy of the sample(s).\n\"\"\"\n- return Polynomial(poly).energies(samples_like)\n+ msg = (\"poly_energies is deprecated and will be remobed in dimod 0.9.0.\"\n+ \"In the future, use BinaryPolynomial.energies\")\n+ warnings.warn(msg, DeprecationWarning)\n+ # dev note the vartype is not used in the energy calculation and this will\n+ # be deprecated in the future\n+ return BinaryPolynomial(poly, 'SPIN').energies(samples_like)\ndef check_isin(key, key_list):\n",
        "chatgpt_cot": "Remove unused import of \"recode\" from \"hgext.convert.convcmd\" and \"Queue\" from \"Queue\". Clean up unnecessary imports."
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/screen_handler.py b/node_manager_fkie/src/node_manager_fkie/screen_handler.py @@ -181,4 +181,4 @@ class ScreenHandler(object):\nelse:\nnm.ssh().ssh_exec(host, [screen.SCREEN, '-wipe'], close_stdin=True, close_stdout=True, close_stderr=True)\nexcept nm.AuthenticationRequest as e:\n- raise nm.InteractionNeededError(e, cls.kill_screens, (grpc_url, host, auto_ok_request))\n+ raise nm.InteractionNeededError(e, cls.kill_screens, (node, grpc_url, auto_ok_request))\n",
        "org_msg": "node_manager_fkie: fixed kill screen on remote hosts",
        "sim_msg": "Typo when kcli console VM in opening remote-viewer\nIt seems the'e a typo when kcli console VM in opening remote-viewer",
        "sim_diff": "diff --git a/kvirt/kvm/__init__.py b/kvirt/kvm/__init__.py @@ -938,7 +938,7 @@ class Kvirt(object):\nurl = \"%s://%s:%s\" % (protocol, host, localport)\nif self.debug:\nprint(url)\n- consolecommand += \"; remote-viewer %s &\" % url\n+ consolecommand += \"remote-viewer %s &\" % url\n# os.popen(\"remote-viewer %s &\" % url)\nos.popen(consolecommand)\n",
        "chatgpt_cot": "\"Fix InteractionNeededError by passing correct parameters in kill_screens method to resolve authentication request issue in ScreenHandler class.\""
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/message_frame.py b/node_manager_fkie/src/node_manager_fkie/message_frame.py import os\nfrom python_qt_binding import loadUi\nfrom python_qt_binding.QtCore import Qt, Signal\n-from python_qt_binding.QtGui import QPalette, QPixmap\n+from python_qt_binding.QtGui import QColor, QPixmap\nfrom node_manager_fkie.common import utf8\nimport node_manager_fkie as nm\n@@ -105,7 +105,7 @@ class MessageFrame(QFrame):\nui_file = os.path.join(os.path.dirname(os.path.realpath(__file__)), 'MessageFrame.ui')\nloadUi(ui_file, self.frameui)\nself.frameui.setVisible(False)\n- bg_style = \"QFrame#questionFame { background-color: lightGray;}\"\n+ bg_style = \"QFrame#questionFame { background-color: %s;}\" % QColor(255, 207, 121).name()\nself.frameui.setStyleSheet(\"%s\" % (bg_style))\nself.frameui.questionOkButton.clicked.connect(self._on_question_ok)\nself.frameui.questionCancelButton.clicked.connect(self._on_question_cancel)\n@@ -155,7 +155,7 @@ class MessageFrame(QFrame):\nif self.questionid == self.QuestionNodelet:\nself.frameui.checkBox_dnaa.setText(\"don't ask again, never!\")\nelse:\n- self.frameui.checkBox_dnaa.setText(\"don't ask again, temporary\")\n+ self.frameui.checkBox_dnaa.setText(\"don't ask again, for session\")\ndef hide_question(self, questionids):\nif self.questionid in questionids:\n",
        "org_msg": "node_manager_fkie: changed color of question box",
        "sim_msg": "enable frame size property by default",
        "sim_diff": "diff --git a/widgets/frame/frame.py b/widgets/frame/frame.py @@ -168,6 +168,7 @@ def builder(parent, sizer, pos, klass=None, base=None, name=None):\nframe = base_class(name, parent, wx.NewId(), name, klass=klass)\n#frame.properties[\"style\"].set_to_default()\nframe.properties[\"style\"].set(\"wxDEFAULT_FRAME_STYLE\")\n+ frame.properties['size'].set( (400,300), activate=True )\nnode = Node(frame)\nframe.node = node\ncommon.app_tree.add(node)\n",
        "chatgpt_cot": "Update background color style and checkbox text in MessageFrame class for better user experience and consistency in node_manager_fkie module."
    },
    {
        "org_diff": "diff --git a/sc2/game_info.py b/sc2/game_info.py @@ -174,8 +174,8 @@ class Ramp:\n\"\"\"\nPylon position that powers the two wall buildings and the warpin position.\n\"\"\"\n- # if len(self.upper) not in {2, 5}:\n- # return None\n+ if len(self.upper) not in {2, 5}:\n+ return None\nif len(self.upper2_for_ramp_wall) != 2:\nraise Exception(\"Not implemented. Trying to access a ramp that has a wrong amount of upper points.\")\nmiddle = self.depot_in_middle\n@@ -210,8 +210,8 @@ class Ramp:\nPosition for a unit to block the wall created by protoss_wall_buildings.\nPowered by protoss_wall_pylon.\n\"\"\"\n- # if len(self.upper) not in {2, 5}:\n- # return None\n+ if len(self.upper) not in {2, 5}:\n+ return None\nif len(self.upper2_for_ramp_wall) != 2:\nraise Exception(\"Not implemented. Trying to access a ramp that has a wrong amount of upper points.\")\nmiddle = self.depot_in_middle\n",
        "org_msg": "Fix protoss wall on honorgrounds LE",
        "sim_msg": "pyproj.crs.CRS.from_string(\"WGS84\") fails in some (but not all!) envs",
        "sim_diff": "diff --git a/xcube/core/gen2/config.py b/xcube/core/gen2/config.py @@ -166,7 +166,7 @@ class CubeConfig:\nif crs is not None:\nassert_instance(crs, str, 'crs')\ntry:\n- pyproj.crs.CRS.from_string(crs)\n+ pyproj.crs.CRS.from_user_input(crs)\nexcept ValueError:\nraise ValueError('crs is invalid')\nself.crs = crs\n",
        "chatgpt_cot": "Fix compilation issue due to the addition of a return statement in the Ramp class's Pylon position method in the game_info.py file."
    },
    {
        "org_diff": "diff --git a/README.md b/README.md @@ -54,6 +54,8 @@ After installing the library, a StarCraft II executable, and some maps, you're r\npython3 examples/protoss/cannon_rush.py\n```\n+#### WINE and Lutris\n+\nIf you installed StarCraft II on Linux with Wine or Lutris, set the following environment variables (either globally or within your development environment, e.g. Pycharm: `Run -> Edit Configurations -> Environment Variables`):\n```sh\n@@ -65,6 +67,19 @@ WINE=usr/bin/wine\nSC2PATH=/home/burny/Games/battlenet/drive_c/Program Files (x86)/StarCraft II/\n```\n+#### WSL\n+\n+To run from a WSL1 instance, set `SC2PF=WSL1`. You may be asked to allow Python through your firewall.\n+\n+To run from a WSL2 instance, set `SC2PF=WSL2`. You also must supply\n+\n+```sh\n+SC2CLIENTHOST=<your windows IP>\n+SC2SERVERHOST=0.0.0.0\n+```\n+\n+You can find your Windows IP using `ipconfig /all` from `PowerShell.exe` or `CMD.exe`.\n+\n## Example\nAs promised, worker rush in less than twenty lines:\n",
        "org_msg": "[WSL-SUPPORT] Update README.md\nAdds notes on running the game from WSL.",
        "sim_msg": "create python user in Dockerfile",
        "sim_diff": "diff --git a/Dockerfile b/Dockerfile @@ -15,15 +15,18 @@ bzip2 && \\\napt-get clean && \\\nrm -rf /var/lib/apt/lists/* /tmp/* /var/tmp/*\n-RUN mkdir -p /home/gamestonkterminal\n-WORKDIR /home/gamestonkterminal\n+RUN useradd --create-home --shell /bin/bash python\n+USER python\n+\n+RUN mkdir -p /home/python/gamestonkterminal\n+WORKDIR /home/python/gamestonkterminal\nCOPY . .\n-RUN INSTALL_ON_LINUX=1 && pip install -r requirements.txt\n+RUN INSTALL_ON_LINUX=1 pip install -r requirements.txt\nRUN pip install git+https://github.com/DidierRLopes/TimeSeriesCrossValidation\nRUN chown -R python /home/gamestonkterminal\n-USER python\n+\nCMD [\"python\", \"gamestonk_terminal.py\"]\n",
        "chatgpt_cot": "Add instructions for running StarCraft II from WSL instances with environment variables. Update README with details for WSL1 and WSL2 configurations."
    },
    {
        "org_diff": "diff --git a/src/api-engine/api/lib/peer/channel.py b/src/api-engine/api/lib/peer/channel.py @@ -88,3 +88,38 @@ class Channel(BasicEnv):\nraise Exception(err_msg)\nres = res >> 8\nreturn res\n+\n+ def join(self, block_file):\n+ \"\"\"\n+ Joins the peer to a channel.\n+\n+ params:\n+ block_file: Path to file containing genesis block\n+ \"\"\"\n+ try:\n+ res = os.system(\n+ \"{} channel join -b {}\".format(self.peer, block_file)\n+ )\n+ except Exception as e:\n+ err_msg = \"join the peer to a channel failed. {}\".format(e)\n+ raise Exception(err_msg)\n+ res = res >> 8\n+ return res\n+\n+ def getinfo(self, channel):\n+ \"\"\"\n+ Get blockchain information of a specified channel.\n+\n+ params:\n+ channel: In case of a newChain command, the channel ID to create.\n+ \"\"\"\n+ try:\n+ res = os.system(\n+ \"{} channel getinfo -c {}\".format(self.peer, channel)\n+ )\n+ except Exception as e:\n+ err_msg = \"get blockchain information of a specified channel failed. {}\".format(\n+ e)\n+ raise Exception(err_msg)\n+ res = res >> 8\n+ return res\n",
        "org_msg": "added peer channel join and peer channel getinfo cmds.",
        "sim_msg": "Create Channel Streams Endpoint",
        "sim_diff": "diff --git a/blueprints/apis/channel_ns.py b/blueprints/apis/channel_ns.py @@ -12,11 +12,13 @@ from classes import Sec\nfrom classes import topics\nfrom classes import invites\nfrom classes import views\n+from classes import Stream\nfrom classes.shared import db\nfrom functions import system\nfrom functions import cachedDbCalls\nfrom functions import channelFunc\n+from functions import templateFilters\nfrom globals import globalvars\n@@ -197,6 +199,47 @@ class api_1_ListChannel(Resource):\nreturn {'results': {'message': 'Channel Deleted'}}, 200\nreturn {'results': {'message': 'Request Error'}}, 400\n+# Invites Endpoint for a Channel\n+@api.route('/<string:channelEndpointID>/streams')\n+@api.doc(params={'channelEndpointID': 'GUID Channel Location'})\n+class api_1_Streams(Resource):\n+ @api.doc(responses={200: 'Success', 400: 'Request Error'})\n+ def get(self, channelEndpointID):\n+ \"\"\"\n+ Returns list of active streams on a channel\n+ \"\"\"\n+ sysSettings = cachedDbCalls.getSystemSettings()\n+ channelIDQuery = cachedDbCalls.getChannelIDFromLocation(channelEndpointID)\n+\n+ if channelIDQuery is not None:\n+ StreamQuery = Stream.Stream.query.filter_by(linkedChannel=channelIDQuery, active=True, complete=False)\\\n+ .with_entities(Stream.Stream.id, Stream.Stream.topic, Stream.Stream.streamName, Stream.Stream.startTimestamp, Stream.Stream.uuid, Stream.Stream.currentViewers,\n+ Stream.Stream.totalViewers).all()\n+\n+ results = []\n+ if sysSettings.adaptiveStreaming is True:\n+ streamURL = '/live-adapt/' + channelEndpointID + '.m3u8'\n+ else:\n+ streamURL = '/live/' + channelEndpointID + '/index.m3u8'\n+ for entry in StreamQuery:\n+ results.append(\n+ {\n+ 'id': entry.id,\n+ 'uuid': entry.uuid,\n+ 'topic': entry.topic,\n+ 'streamName': entry.streamName,\n+ 'startTimestamp': entry.startTimestamp,\n+ 'currentViewers': entry.currentViewers,\n+ 'totalViewers': entry.totalViewers,\n+ 'streamURL': streamURL\n+ })\n+ db.session.commit()\n+ return {'results': results}\n+\n+ db.session.commit()\n+ return {'results': {'message': 'Request Error'}}, 400\n+\n+\n# TODO Add Ability to Add/Delete/Change\n@api.route('/<string:channelEndpointID>/restreams')\n",
        "chatgpt_cot": "\"Add methods to join peer to a channel and get blockchain information of a specified channel in Channel class to enhance functionality.\""
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/launch_list_model.py b/node_manager_fkie/src/node_manager_fkie/launch_list_model.py @@ -430,7 +430,6 @@ class LaunchListModel(QStandardItemModel):\nself._add_path(hitem, PathItem.RECENT_FILE, 0, 0, os.path.basename(hitem))\ndef _on_new_packages(self, grpc_url):\n- if not self._current_path:\nself.reload_current_path()\ndef _listed_path(self, url, path, result):\n",
        "org_msg": "node_manager_fkie: fixed reload on new packages",
        "sim_msg": "fix launch.",
        "sim_diff": "diff --git a/tools/launch.py b/tools/launch.py @@ -64,9 +64,8 @@ def submit_jobs(args, udf_command):\ntorch_cmd = torch_cmd + ' ' + '--master_addr=' + str(hosts[0][0])\ntorch_cmd = torch_cmd + ' ' + '--master_port=' + str(1234)\n- for i in range(args.num_client):\n- node_id = int(i / client_count_per_machine)\n- ip, _ = hosts[node_id]\n+ for node_id, host in enumerate(hosts):\n+ ip, _ = host\nnew_torch_cmd = torch_cmd.replace('node_rank=0', 'node_rank='+str(node_id))\nnew_udf_command = udf_command.replace('python3', 'python3 ' + new_torch_cmd)\ncmd = client_cmd + ' ' + new_udf_command\n",
        "chatgpt_cot": "\"Remove unnecessary condition in _on_new_packages method in LaunchListModel\""
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/launch_list_model.py b/node_manager_fkie/src/node_manager_fkie/launch_list_model.py @@ -238,7 +238,7 @@ class LaunchListModel(QStandardItemModel):\nitem = self.itemFromIndex(index)\nprev = '%s\\n' % text if text else ''\ntext = '%sfile://%s' % (prev, item.path)\n- mimeData.setData('text/plain', text)\n+ mimeData.setData('text/plain', str(text))\nreturn mimeData\n# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n@@ -381,7 +381,7 @@ class LaunchListModel(QStandardItemModel):\nitem = self.itemFromIndex(index)\nprev = '%s\\n' % text if text else ''\ntext = '%sfile://%s' % (prev, item.path)\n- mimeData.setData('text/plain', text)\n+ mimeData.setData('text/plain', str(text))\nQApplication.clipboard().setMimeData(mimeData)\n# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
        "org_msg": "node_manager_fkie: fixed crash on drag",
        "sim_msg": "Removed redundant internalPointer query",
        "sim_diff": "diff --git a/avalon/tools/cbsceneinventory/model.py b/avalon/tools/cbsceneinventory/model.py @@ -50,7 +50,6 @@ class InventoryModel(TreeModel):\nif role == QtCore.Qt.DecorationRole:\nif index.column() == 0:\n# Override color\n- node = index.internalPointer()\ncolor = node.get(\"color\", style.colors.default)\nif not index.parent().isValid(): # group-item\nreturn qta.icon(\"fa.folder\", color=color)\n@@ -62,7 +61,6 @@ class InventoryModel(TreeModel):\nreturn node.get(\"familyIcon\", None)\nif role == self.UniqueRole:\n- node = index.internalPointer()\nreturn node['representation'] + node.get(\"objectName\", \"<none>\")\nreturn super(InventoryModel, self).data(index, role)\n",
        "chatgpt_cot": "Fix issue with setting mime data as string in LaunchListModel. The modification of using str() function ensures the data is set as a string."
    },
    {
        "org_diff": "diff --git a/sc2/main.py b/sc2/main.py @@ -129,7 +129,7 @@ async def _play_game_ai(client, player_id, ai, realtime, step_time_limit, game_t\nreturn client._game_result[player_id]\nreturn client._game_result[player_id]\ngs = GameState(state.observation)\n- logger.debug(f\"Score: {gs.score.summary}\")\n+ logger.debug(f\"Score: {gs.score.score}\")\nif game_time_limit and (gs.game_loop * 0.725 * (1 / 16)) > game_time_limit:\nawait ai.on_end(Result.Tie)\n",
        "org_msg": "Fix logger score in main.py",
        "sim_msg": "[Hockey] same as previous error",
        "sim_diff": "diff --git a/hockey/hockey.py b/hockey/hockey.py @@ -1053,7 +1053,7 @@ class Hockey(getattr(commands, \"Cog\", object)):\nfor p in pickems:\ngame = await Game.get_games(p.home_team, p.game_start, p.game_start)\nif game[0].game_state == \"Final\":\n- await Pickems.set_guild_pickem_winner(self.bot, game)\n+ await Pickems.set_guild_pickem_winner(self.bot, game[0])\nawait ctx.send(_(\"Pickems winners set.\"))\n",
        "chatgpt_cot": "Modify debug message in main.py to display correct score value in GameState object to ensure accurate debugging information."
    },
    {
        "org_diff": "diff --git a/fkie_node_manager/src/fkie_node_manager/master_view_proxy.py b/fkie_node_manager/src/fkie_node_manager/master_view_proxy.py @@ -485,7 +485,7 @@ class MasterViewProxy(QWidget):\nnmd_node = master_info.getNode('/node_manager_daemon')\nif nmd_node is None: # do not test for PID. It can be None if daemon is busy on load big launch files\nself._has_nmd = False\n- if time.time() - self.__last_question_start_nmd > 1.:\n+ if time.time() - self.__last_question_start_nmd > 10.:\nself.__last_question_start_nmd = time.time()\nif not self.is_local:\nself.message_frame.show_question(MessageFrame.TYPE_NMD, \"node_manager_daemon not found for '%s'.\\nShould it be started?\" % self.masteruri, MessageData(self.masteruri))\n@@ -1980,7 +1980,6 @@ class MasterViewProxy(QWidget):\nself._start_queue(self._progress_queue)\ndef _check_for_nodelets(self, nodes):\n- # TODO\nself._restart_nodelets = {}\nnodenames = [n.name for n in nodes]\nnodelet_mngr = ''\n@@ -2167,15 +2166,9 @@ class MasterViewProxy(QWidget):\nif node is not None and node.uri is not None and (not self._is_in_ignore_list(node.name) or force):\ntry:\nrospy.loginfo(\"Stop node '%s'[%s]\", utf8(node.name), utf8(node.uri))\n- # TODO\n- # nm.filewatcher().rem_binary(node.name)\n- # 'print \"STOP set timeout\", node\nsocket.setdefaulttimeout(10)\n- # 'print \"STOP create xmlrpc\", node\np = xmlrpclib.ServerProxy(node.uri)\n- # 'print \"STOP send stop\", node\np.shutdown(rospy.get_name(), '[node manager] request from %s' % self.mastername)\n- # 'print \"STOP stop finished\", node\nif node.kill_on_stop and node.pid:\n# wait kill_on_stop is an integer\nif isinstance(node.kill_on_stop, (int, float)):\n",
        "org_msg": "increased timeout for question to start daemon",
        "sim_msg": "add crash code",
        "sim_diff": "diff --git a/quarkchain/experimental/raft.py b/quarkchain/experimental/raft.py @@ -84,7 +84,12 @@ class Node:\n# The simulation assumes the connections are constant (no membership feature)\nself.connectionList = []\n+ self.isCrashed = False\n+\n# Volatile (reinitialized after restart)\n+ self.initializeVolatileVariables()\n+\n+ def initializeVolatileVariables(self):\nself.state = NodeState.CANDIDATE\nself.lastHeartBeatReceived = None\nself.commitIndex = 0\n@@ -96,7 +101,7 @@ class Node:\nself.connectionList.append(conn)\ndef crash():\n- pass\n+ self.isCrashed = True\ndef handleAppendEntriesRequest(self, request):\nif request.term < self.currentTerm:\n@@ -180,6 +185,9 @@ class Node:\nreturn RequestVoteResponse(self.currentTerm, False)\nasync def start(self):\n+ self.isCrashed = False\n+ self.initializeVolatileVariables()\n+\nprint(\"Node {}: Starting\".format(self.nodeId))\nwhile True:\nprint(\n@@ -324,6 +332,10 @@ class Connection:\nlatencyMs1 = self.networkDelayGenerator()\nawait asyncio.sleep(latencyMs0 / 1000)\n+ if self.destination.isCrashed:\n+ await asyncio.sleep((self.timeoutMs - latencyMs0) / 1000)\n+ raise TimeoutError()\n+\nresp = callFunc()\nif latencyMs0 + latencyMs1 >= self.timeoutMs:\n@@ -347,6 +359,17 @@ class Connection:\nreturn self.destination.nodeId\n+async def random_crash(nodeList):\n+ while True:\n+ asyncio.sleep(2500)\n+ for node in nodeList:\n+ if node.state == NodeState.LEADER:\n+ node.crash()\n+\n+ asyncio.sleep(1000)\n+ asyncio.get_event_loop().create_task(nodeList[i].start())\n+\n+\nN = 3\nnodeList = [Node(i) for i in range(N)]\nconnectionMap = {}\n",
        "chatgpt_cot": "Update time for the last question start to 10 seconds instead of 1 second, and remove the TODO comment."
    },
    {
        "org_diff": "diff --git a/sc2/unit.py b/sc2/unit.py @@ -65,6 +65,14 @@ class Unit(object):\ndef radius(self):\nreturn self._proto.radius\n+ @property\n+ def detect_range(self):\n+ return self._proto.detect_range\n+\n+ @property\n+ def radar_range(self):\n+ return self._proto.radar_range\n+\n@property\ndef build_progress(self):\nreturn self._proto.build_progress\n@@ -82,6 +90,10 @@ class Unit(object):\n\"\"\"Detected by sensor tower.\"\"\"\nreturn self._proto.is_blip\n+ @property\n+ def is_powered(self):\n+ return self._proto.is_powered\n+\n@property\ndef is_burrowed(self):\nreturn self._proto.is_burrowed\n@@ -114,6 +126,10 @@ class Unit(object):\ndef shield(self):\nreturn self._proto.shield\n+ @property\n+ def shield_max(self):\n+ return self._proto.shield_max\n+\n@property\ndef energy(self):\nreturn self._proto.energy\n@@ -122,6 +138,10 @@ class Unit(object):\ndef mineral_contents(self):\nreturn self._proto.mineral_contents\n+ @property\n+ def vespene_contents(self):\n+ return self._proto.vespene_contents\n+\n@property\ndef is_selected(self):\nreturn self._proto.is_selected\n",
        "org_msg": "Add some new fields to the unit (from the last API update)",
        "sim_msg": "Python API: move low-level C binding for AnalysisContext\nTN:",
        "sim_diff": "diff --git a/langkit/templates/python_api/module_py.mako b/langkit/templates/python_api/module_py.mako @@ -25,8 +25,6 @@ import sys\n#\n-class _analysis_context(ctypes.c_void_p):\n- pass\nclass _analysis_unit(ctypes.c_void_p):\npass\nclass _node(ctypes.c_void_p):\n@@ -255,6 +253,9 @@ class AnalysisContext(object):\nif not _remove_analysis_unit(self._c_value, filename):\nraise KeyError('No such unit: {}'.format(filename))\n+ class _c_type(ctypes.c_void_p):\n+ pass\n+\nclass AnalysisUnit(object):\n${py_doc('langkit.analysis_unit_type', 4)}\n@@ -980,23 +981,23 @@ _create_analysis_context = _import_func(\n% if ctx.default_unit_file_provider:\n_unit_file_provider,\n% endif\n- ], _analysis_context\n+ ], AnalysisContext._c_type\n)\n_context_incref = _import_func(\n'${capi.get_name(\"context_incref\")}',\n- [_analysis_context], _analysis_context\n+ [AnalysisContext._c_type], AnalysisContext._c_type\n)\n_context_decref = _import_func(\n'${capi.get_name(\"context_decref\")}',\n- [_analysis_context], None\n+ [AnalysisContext._c_type], None\n)\n_destroy_analysis_context = _import_func(\n'${capi.get_name(\"destroy_analysis_context\")}',\n- [_analysis_context, ], None\n+ [AnalysisContext._c_type, ], None\n)\n_get_analysis_unit_from_file = _import_func(\n'${capi.get_name(\"get_analysis_unit_from_file\")}',\n- [_analysis_context, # context\n+ [AnalysisContext._c_type, # context\nctypes.c_char_p, # filename\nctypes.c_char_p, # charset\nctypes.c_int], # reparse\n@@ -1004,7 +1005,7 @@ _get_analysis_unit_from_file = _import_func(\n)\n_get_analysis_unit_from_buffer = _import_func(\n'${capi.get_name(\"get_analysis_unit_from_buffer\")}',\n- [_analysis_context, # context\n+ [AnalysisContext._c_type, # context\nctypes.c_char_p, # filename\nctypes.c_char_p, # charset\nctypes.c_char_p, # buffer\n@@ -1014,7 +1015,7 @@ _get_analysis_unit_from_buffer = _import_func(\n% if ctx.default_unit_file_provider:\n_get_analysis_unit_from_provider = _import_func(\n'${capi.get_name(\"get_analysis_unit_from_provider\")}',\n- [_analysis_context, # context\n+ [AnalysisContext._c_type, # context\n_text, # name\nctypes.c_int, # kind\nctypes.c_char_p, # charset\n@@ -1024,7 +1025,7 @@ _get_analysis_unit_from_provider = _import_func(\n% endif\n_remove_analysis_unit = _import_func(\n'${capi.get_name(\"remove_analysis_unit\")}',\n- [_analysis_context, ctypes.c_char_p], ctypes.c_int\n+ [AnalysisContext._c_type, ctypes.c_char_p], ctypes.c_int\n)\n_unit_root = _import_func(\n'${capi.get_name(\"unit_root\")}',\n@@ -1072,7 +1073,7 @@ _unit_decref = _import_func(\n)\n_unit_context = _import_func(\n'${capi.get_name(\"unit_context\")}',\n- [_analysis_unit], _analysis_context\n+ [_analysis_unit], AnalysisContext._c_type\n)\n_unit_reparse_from_file = _import_func(\n'${capi.get_name(\"unit_reparse_from_file\")}',\n",
        "chatgpt_cot": "Add new properties to Unit class for detect range, radar range, powered status, max shield, vespene contents."
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/settings.py b/node_manager_fkie/src/node_manager_fkie/settings.py @@ -648,5 +648,5 @@ class Settings(object):\nQColor(233, 224, 210).rgb(),\nQColor(236, 236, 231).rgb(),\nQColor(43, 43, 44).rgb(),\n- QColor(121, 123, 122)\n+ QColor(121, 123, 122).rgb()\n]\n",
        "org_msg": "node_manager_fkie: fix crash while assigne color",
        "sim_msg": "Updates Default System theme to Defaultv3",
        "sim_diff": "diff --git a/classes/settings.py b/classes/settings.py @@ -50,7 +50,7 @@ class settings(db.Model):\nself.showEmptyTables = showEmptyTables\nself.allowComments = allowComments\nself.sortMainBy = 0\n- self.systemTheme = \"Defaultv2\"\n+ self.systemTheme = \"Defaultv3\"\nself.version = version\nself.systemLogo = \"/static/img/logo.png\"\nself.systemLogoLight = \"/static/img/logo-light.png\"\n",
        "chatgpt_cot": "Fix QColor method call to include rgb() function for consistency in settings.py file."
    },
    {
        "org_diff": "diff --git a/fkie_node_manager/src/fkie_node_manager/editor/editor.py b/fkie_node_manager/src/fkie_node_manager/editor/editor.py @@ -401,6 +401,8 @@ class Editor(QMainWindow):\nbreak\nself.tabWidget.setUpdatesEnabled(True)\nif search_text:\n+ if only_launch:\n+ self.find_dialog.found_files_list.clear()\ntry:\nself._search_thread.stop()\nself._search_thread = None\n",
        "org_msg": "fkie_node_manager: editor: clear search results on activate and search for a node",
        "sim_msg": "add file type icons to each row in table",
        "sim_diff": "diff --git a/qualcoder/manage_files.py b/qualcoder/manage_files.py @@ -90,11 +90,10 @@ class DialogManageFiles(QtWidgets.QDialog):\napp = None\ntext_dialog = None\nheader_labels = []\n- ICON_COLUMN = 0\n- NAME_COLUMN = 1\n- MEMO_COLUMN = 2\n- DATE_COLUMN = 3\n- ID_COLUMN = 4\n+ NAME_COLUMN = 0\n+ MEMO_COLUMN = 1\n+ DATE_COLUMN = 2\n+ ID_COLUMN = 3\ndefault_import_directory = os.path.expanduser(\"~\")\nattribute_names = [] # list of dictionary name:value for additem dialog\nparent_textEdit = None\n@@ -140,7 +139,7 @@ class DialogManageFiles(QtWidgets.QDialog):\nself.source.append({'name': row[0], 'id': row[1], 'fulltext': row[2],\n'mediapath': row[3], 'memo': row[4], 'owner': row[5], 'date': row[6]})\n# attributes\n- self.header_labels = [\" \", _(\"Name\"), _(\"Memo\"), _(\"Date\"), _(\"Id\")]\n+ self.header_labels = [_(\"Name\"), _(\"Memo\"), _(\"Date\"), _(\"Id\")]\nsql = \"select name from attribute_type where caseOrFile='file'\"\ncur.execute(sql)\nresult = cur.fetchall()\n@@ -933,6 +932,25 @@ class DialogManageFiles(QtWidgets.QDialog):\nself.source.remove(item)\nself.fill_table()\n+ def get_icon(self, name):\n+ ''' Get icon to put in table. Helper method for fill_table\n+\n+ parameter: filename\n+\n+ return: QIcon '''\n+\n+ icon_text = QtGui.QIcon(\"GUI/text.png\")\n+ icon_play = QtGui.QIcon(\"GUI/play.png\")\n+ icon_picture = QtGui.QIcon(\"GUI/picture.png\")\n+\n+ suffix = name[-4:].lower()\n+ print(name, \" \", suffix)\n+ if suffix in (\".png\", \".jpg\", \"jpeg\"):\n+ return icon_picture\n+ if suffix in (\".mp4\", \".mov\", \".avi\", \".mkv\", \".mp3\", \".wav\", \".ogg\"):\n+ return icon_play\n+ return icon_text\n+\ndef fill_table(self):\n\"\"\" Reload the file data and Fill the table widget with file data. \"\"\"\n@@ -946,7 +964,9 @@ class DialogManageFiles(QtWidgets.QDialog):\nfor row, data in enumerate(self.source):\nself.ui.tableWidget.insertRow(row)\n+ icon = self.get_icon(data['name'])\nname_item = QtWidgets.QTableWidgetItem(data['name'])\n+ name_item.setIcon(icon)\n#name_item.setFlags(name_item.flags() ^ QtCore.Qt.ItemIsEditable)\nself.ui.tableWidget.setItem(row, self.NAME_COLUMN, name_item)\ndate_item = QtWidgets.QTableWidgetItem(data['date'])\n",
        "chatgpt_cot": "\"Clear found files list when only launching and fix search thread stop in Editor class\""
    },
    {
        "org_diff": "diff --git a/fkie_node_manager/src/fkie_node_manager/ssh_handler.py b/fkie_node_manager/src/fkie_node_manager/ssh_handler.py @@ -43,13 +43,16 @@ from fkie_node_manager_daemon.supervised_popen import SupervisedPopen\nimport fkie_node_manager as nm\nfrom fkie_node_manager_daemon.common import utf8\n-import Crypto.Cipher.AES\n-orig_new = Crypto.Cipher.AES.new\n+try:\n+ import Cryptodome.Cipher.AES as AES\n+except ImportError:\n+ import Crypto.Cipher.AES as AES\n+orig_new = AES.new\n# workaround for https://github.com/paramiko/paramiko/pull/714\ndef fixed_AES_new(key, mode, IV='', counter=None, segment_size=0):\n- if Crypto.Cipher.AES.MODE_CTR == mode:\n+ if AES.MODE_CTR == mode:\nIV = ''\nreturn orig_new(key, mode, IV, counter, segment_size)\n@@ -76,7 +79,7 @@ class SSHhandler(object):\ndef __init__(self):\n# workaround for https://github.com/paramiko/paramiko/pull/714\n- Crypto.Cipher.AES.new = fixed_AES_new\n+ AES.new = fixed_AES_new\nself.mutex = threading.RLock()\ndef remove(self, host):\n",
        "org_msg": "fkie_node_manager: use Cryptodome or Crypto depending on availability",
        "sim_msg": "Moved again crypto imports within the method",
        "sim_diff": "diff --git a/resources/lib/common/credentials.py b/resources/lib/common/credentials.py @@ -23,15 +23,6 @@ from .fileops import load_file\nfrom .kodi_ops import get_local_string\nfrom .uuid_device import get_crypt_key\n-try: # The crypto package depends on the library installed (see Wiki)\n- from Crypto import Random\n- from Crypto.Cipher import AES\n- from Crypto.Util import Padding\n-except ImportError:\n- from Cryptodome import Random\n- from Cryptodome.Cipher import AES\n- from Cryptodome.Util import Padding\n-\n__BLOCK_SIZE__ = 32\n@@ -42,6 +33,16 @@ def encrypt_credential(raw):\n:type raw: str\n:returns: string -- Encoded data\n\"\"\"\n+ # Keep these imports within the method otherwise if the packages are not installed,\n+ # the addon crashes and the user does not read the warning message\n+ try: # The crypto package depends on the library installed (see Wiki)\n+ from Crypto import Random\n+ from Crypto.Cipher import AES\n+ from Crypto.Util import Padding\n+ except ImportError:\n+ from Cryptodome import Random\n+ from Cryptodome.Cipher import AES\n+ from Cryptodome.Util import Padding\nraw = bytes(Padding.pad(data_to_pad=raw.encode('utf-8'), block_size=__BLOCK_SIZE__))\niv = Random.new().read(AES.block_size)\ncipher = AES.new(get_crypt_key(), AES.MODE_CBC, iv)\n@@ -55,6 +56,14 @@ def decrypt_credential(enc):\n:type enc: str\n:returns: string -- Decoded data\n\"\"\"\n+ # Keep these imports within the method otherwise if the packages are not installed,\n+ # the addon crashes and the user does not read the warning message\n+ try: # The crypto package depends on the library installed (see Wiki)\n+ from Crypto.Cipher import AES\n+ from Crypto.Util import Padding\n+ except ImportError:\n+ from Cryptodome.Cipher import AES\n+ from Cryptodome.Util import Padding\nenc = base64.b64decode(enc)\niv = enc[:AES.block_size]\ncipher = AES.new(get_crypt_key(), AES.MODE_CBC, iv)\n@@ -139,6 +148,14 @@ def run_nf_authentication_key():\ndef _get_authentication_key_data(file_path, pin):\n\"\"\"Open the auth key file\"\"\"\nfrom resources.lib.kodi import ui\n+ # Keep these imports within the method otherwise if the packages are not installed,\n+ # the addon crashes and the user does not read the warning message\n+ try: # The crypto package depends on the library installed (see Wiki)\n+ from Crypto.Cipher import AES\n+ from Crypto.Util import Padding\n+ except ImportError:\n+ from Cryptodome.Cipher import AES\n+ from Cryptodome.Util import Padding\ntry:\nfile_content = load_file(file_path)\niv = '\\x00' * 16\n",
        "chatgpt_cot": "Update AES module import to handle ImportError, fix compilation issue in SSH handler file."
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/cmake/version.cmake b/node_manager_fkie/cmake/version.cmake include(CMakeParseArguments)\nmacro(generate_version)\n+ find_program(GIT git)\n# install a file with version tag\nset(VERSION_DIR \"${CATKIN_DEVEL_PREFIX}/${CATKIN_PACKAGE_SHARE_DESTINATION}\")\nset(VERSION_FILES \"\")\n",
        "org_msg": "node_manager_fkie: fix cmake",
        "sim_msg": "add ft compile doc.",
        "sim_diff": "diff --git a/doc/paddle/install/compile/fromsource.rst b/doc/paddle/install/compile/fromsource.rst compile_CentOS.md\ncompile_MacOS.md\ncompile_Windows.md\n+ compile_FT.md\n",
        "chatgpt_cot": "Add git executable check in version.cmake to fix compilation issue."
    },
    {
        "org_diff": "diff --git a/sc2/__init__.py b/sc2/__init__.py @@ -9,6 +9,11 @@ def is_submodule(path):\n__all__ = [p.stem for p in Path(__file__).parent.iterdir() if is_submodule(p)]\n+import sys, logging\n+logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n+logger = logging.getLogger(__name__)\n+logger.setLevel(logging.INFO)\n+\nfrom . import maps\nfrom .data import *\nfrom .bot_ai import BotAI\n",
        "org_msg": "Set up logger",
        "sim_msg": "Use namespaces plt and vf for visualization and verification modules",
        "sim_diff": "diff --git a/__init__.py b/__init__.py @@ -9,7 +9,7 @@ from . import optflow\nfrom . import postprocessing\nfrom . import timeseries\nfrom . import utils\n-from . import verification\n-from . import visualization\n+from . import verification as vf\n+from . import visualization as plt\n",
        "chatgpt_cot": "Add logging configuration and logger initialization in __init__.py. Set logging level to INFO for better logging functionality."
    },
    {
        "org_diff": "diff --git a/sc2/bot_ai.py b/sc2/bot_ai.py @@ -896,8 +896,7 @@ class BotAI(DistanceCalculation):\nelse: # AbilityId\nbuilding = self._game_data.abilities[building.value]\n- if await self.can_place(building, near):\n- if not addon_place or await self.can_place(UnitTypeId.SUPPLYDEPOT, near.offset((2.5, -0.5))):\n+ if await self.can_place(building, near) and (not addon_place or await self.can_place(UnitTypeId.SUPPLYDEPOT, near.offset((2.5, -0.5)))):\nreturn near\nif max_distance == 0:\n",
        "org_msg": "combine statements",
        "sim_msg": "added time to the saved files",
        "sim_diff": "diff --git a/bot_manager.py b/bot_manager.py @@ -178,7 +178,7 @@ class BotManager:\ncurrent_time = game_tick_packet.gameInfo.TimeSeconds\nif self.save_data and game_tick_packet.gameInfo.bRoundActive and not old_time == current_time and not current_time == -10:\n- np_input = self.input_converter.create_input_array(game_tick_packet)\n+ np_input = self.input_converter.create_input_array(game_tick_packet, passed_time=time.time() - before2)\nnp_output = np.array(controller_input, dtype=np.float32)\nself.input_array = np.append(self.input_array, np_input)\nself.output_array = np.append(self.output_array, np_output)\n",
        "chatgpt_cot": "Refactor can_place method in BotAI to improve readability and maintainability. Fix conditional logic to simplify code and avoid duplication."
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/master_view_proxy.py b/node_manager_fkie/src/node_manager_fkie/master_view_proxy.py @@ -680,7 +680,8 @@ class MasterViewProxy(QWidget):\nrestart, ok = SelectDialog.getValue('Restart nodes?', \"Select nodes to restart <b>@%s</b>:\" % self.mastername, changed_nodes, False, True, '', self)\nif ok:\nself.stop_nodes_by_name(restart)\n- self.start_nodes_by_name(restart, filename, True)\n+ self.start_nodes_after_load_cfg(filename, restart, force=True)\n+ # self.start_nodes_by_name(restart, filename, force=True)\nif filename in self.__configs:\n# store expanded items\nself.__expanded_items[filename] = self._get_expanded_groups()\n",
        "org_msg": "node_manager_fkie: fixed restart nodes combined with reload launchfile",
        "sim_msg": "log exception on adding root block failure",
        "sim_diff": "diff --git a/quarkchain/cluster/master.py b/quarkchain/cluster/master.py @@ -637,6 +637,7 @@ class MasterServer():\nupdateTip = self.rootState.addBlock(rBlock)\nsuccess = True\nexcept ValueError:\n+ Logger.logException()\nsuccess = False\nif success:\n",
        "chatgpt_cot": "Refactor node restart logic in MasterViewProxy to improve readability and maintainability. Start nodes after loading configuration with force parameter."
    },
    {
        "org_diff": "diff --git a/master_discovery_fkie/src/master_discovery_fkie/zeroconf.py b/master_discovery_fkie/src/master_discovery_fkie/zeroconf.py @@ -311,6 +311,7 @@ class Zeroconf(threading.Thread):\nif self.__group is None:\nif (self.masterInfo.domain is None) or len(self.masterInfo.domain) == 0:\nself.masterInfo.domain = 'local'\n+ if '.' not in self.masterInfo.host:\nself.masterInfo.host = self.masterInfo.host + '.' + self.masterInfo.domain\nself.__group = dbus.Interface(self.__bus.get_object(avahi.DBUS_NAME,\nself.__server.EntryGroupNew()),\n@@ -746,7 +747,7 @@ class Discoverer(Zeroconf):\n'''\nROSMASTER_HZ = 1 # the test rate of ROS master state in hz\n- def __init__(self, monitor_port=11611, network_id=0, domain=''):\n+ def __init__(self, monitor_port=11611, network_id=0):\n'''\nInitialize method of the local master.\n@@ -756,21 +757,28 @@ class Discoverer(Zeroconf):\n'''\nif rospy.has_param('~rosmaster_hz'):\nDiscoverer.ROSMASTER_HZ = rospy.get_param('~rosmaster_hz')\n-\nself.network_id = str(network_id)\nrospy.loginfo(\"Network ID: %s\" % self.network_id)\n+ self._use_fqdn = rospy.get_param('~fqdn', False)\n+ rospy.loginfo(\"Fully-Qualified Domain Name: %s\" % ('enabled' if self._use_fqdn else 'disabled'))\nself.master_monitor = MasterMonitor(monitor_port)\nname = self.master_monitor.getMastername()\n- # create the txtArray for the zeroconf service of the ROS master\nmateruri = self.master_monitor.getMasteruri()\n+ # create the txtArray for the zeroconf service of the ROS master\n+ hostname = get_hostname(materuri)\n+ if self._use_fqdn:\n+ fqhostname = socket.getfqdn()\n+ materuri = materuri.replace('://%s:' % hostname, '://%s:' % fqhostname)\n+ hostname = fqhostname\n# test the host for local entry\nmasterhost, masterport = MasterInfo.MasteruriToAddr(materuri)\nif (masterhost in ['localhost', '127.0.0.1']):\nsys.exit(\"'%s' is not reachable for other systems. Change the ROS_MASTER_URI!\" % masterhost)\n- rpcuri = 'http://%s:%s/' % (get_hostname(materuri), str(monitor_port))\n+ rpcuri = 'http://%s:%s/' % (hostname, str(monitor_port))\ntxtArray = [\"timestamp=%s\" % str(0), \"timestamp_local=%s\" % str(0), \"master_uri=%s\" % materuri, \"zname=%s\" % rospy.get_name(), \"rpcuri=%s\" % rpcuri, \"network_id=%s\" % self.network_id]\n+ rospy.loginfo(\"Publish txtArray: %s\" % txtArray)\n# the Zeroconf class, which contains the QMainLoop to receive the signals from avahi\n- Zeroconf.__init__(self, name, '_ros-master._tcp', masterhost, masterport, domain, txtArray)\n+ Zeroconf.__init__(self, name, '_ros-master._tcp', hostname, masterport, domain='local', txt_array=txtArray)\n# the list with all ROS master neighbors with theirs SyncThread's and all Polling threads\nself.masters = MasterList(self.masterInfo, self.requestResolve, self.checkLocalMaster)\n# set the callback to finish all running threads\n",
        "org_msg": "master_discovery_fkie: zeroconf: added fqdn-parameter, see issue",
        "sim_msg": "add custom ssh port to autossh",
        "sim_diff": "diff --git a/home.admin/config.scripts/internet.sshtunnel.py b/home.admin/config.scripts/internet.sshtunnel.py @@ -10,7 +10,7 @@ from pathlib import Path\n# display config script info\nif len(sys.argv) <= 1 or sys.argv[1] == \"-h\" or sys.argv[1] == \"help\":\nprint(\"forward ports from another server to raspiblitz with reverse SSH tunnel\")\n- print(\"internet.sshtunnel.py [on|off|restore] [USER]@[SERVER] \\\"[INTERNAL-PORT]<[EXTERNAL-PORT]\\\"\")\n+ print(\"internet.sshtunnel.py [on|off|restore] [USER]@[SERVER:PORT] \\\"[INTERNAL-PORT]<[EXTERNAL-PORT]\\\"\")\nprint(\"note that [INTERNAL-PORT]<[EXTERNAL-PORT] can one or multiple forwardings\")\nsys.exit(1)\n@@ -70,12 +70,21 @@ if sys.argv[1] == \"on\":\n# check server address\nif len(sys.argv) < 3:\n- print(\"[USER]@[SERVER] missing - use 'internet.sshtunnel.py -h' for help\")\n+ print(\"[USER]@[SERVER:PORT] missing - use 'internet.sshtunnel.py -h' for help\")\nsys.exit(1)\nif sys.argv[2].count(\"@\") != 1:\n- print(\"[USER]@[SERVER] wrong - use 'internet.sshtunnel.py -h' for help\")\n+ print(\"[USER]@[SERVER:PORT] wrong - use 'internet.sshtunnel.py -h' for help\")\nsys.exit(1)\nssh_server = sys.argv[2]\n+ if ssh_server.count(\":\") == 0:\n+ ssh_server_host = ssh_server\n+ ssh_server_port = \"22\"\n+ elif ssh_server.count(\":\") == 1:\n+ ssh_server_split = ssh_server.split(\":\")\n+ ssh_server_host = ssh_server_split[0]\n+ ssh_server_port = ssh_server_split[1]\n+ else:\n+ print(\"[USER]@[SERVER:PORT] wrong - use 'internet.sshtunnel.py -h' for help\")\n# genenate additional parameter for autossh (forwarding ports)\nif len(sys.argv) < 4:\n@@ -116,7 +125,7 @@ if sys.argv[1] == \"on\":\n# genenate additional parameter for autossh (server)\nssh_ports = ssh_ports.strip()\n- additional_parameters= additional_parameters + ssh_server\n+ additional_parameters = additional_parameters + \"-p \" + ssh_server_port + \" \" + ssh_server_host\n# generate custom service config\nservice_data = SERVICETEMPLATE.replace(\"[PLACEHOLDER]\", additional_parameters)\n",
        "chatgpt_cot": "Update Zeroconf initialization method to handle Fully-Qualified Domain Name setting and publish txtArray with new hostname for ROS master service."
    },
    {
        "org_diff": "diff --git a/src/dashboard/src/pages/User/Login.js b/src/dashboard/src/pages/User/Login.js @@ -78,6 +78,20 @@ class LoginPage extends Component {\nthis.renderMessage(\nintl.formatMessage({ id: 'app.login.message-invalid-credentials' })\n)}\n+ <OrgName\n+ name=\"orgName\"\n+ placeholder={intl.formatMessage({ id: 'app.register.orgName' })}\n+ rules={[\n+ {\n+ required: true,\n+ message: intl.formatMessage({ id: 'validation.orgName.required' }),\n+ },\n+ {\n+ pattern: new RegExp('^[a-z][\\\\da-z]{0,61}\\\\.[a-z\\\\d]{1,62}\\\\.[a-z]{1,6}$'),\n+ message: intl.formatMessage({ id: 'validation.orgName.check' }),\n+ },\n+ ]}\n+ />\n<UserName\nname=\"username\"\nplaceholder={`${intl.formatMessage({ id: 'app.login.userName' })}: admin or user`}\n",
        "org_msg": "[#236]Add the input organization name box to the login page",
        "sim_msg": "added a timer in dashboard",
        "sim_diff": "diff --git a/myems-web/src/components/MyEMS/dashboard/Dashboard.js b/myems-web/src/components/MyEMS/dashboard/Dashboard.js @@ -406,6 +406,16 @@ const Dashboard = ({ setRedirect, setRedirectUrl, t }) => {\n};\n}, );\n+ useEffect(() => {\n+ let timer = setInterval(() => {\n+ let is_logged_in = getCookieValue('is_logged_in');\n+ if (is_logged_in === null || !is_logged_in) {\n+ setRedirectUrl(`/authentication/basic/login`);\n+ setRedirect(true);\n+ }\n+ }, 1000);\n+ return () => clearInterval(timer);\n+ }, [])\nreturn (\n<Fragment>\n",
        "chatgpt_cot": "Add OrgName component and its validation rules to the login page to validate the organization name input."
    },
    {
        "org_diff": "diff --git a/fkie_node_manager/src/fkie_node_manager/master_view_proxy.py b/fkie_node_manager/src/fkie_node_manager/master_view_proxy.py @@ -1934,13 +1934,14 @@ class MasterViewProxy(QWidget):\ndef nodesFromIndexes(self, indexes, recursive=True):\nresult = []\n+ regex = QRegExp(self.ui.nodeFilterInput.text())\nfor index in indexes:\nif index.column() == 0:\nmodel_index = self.node_proxy_model.mapToSource(index)\nitem = self.node_tree_model.itemFromIndex(model_index)\nres = self._nodesFromItems(item, recursive)\nfor r in res:\n- if r not in result:\n+ if r not in result and (not regex.pattern() or regex.indexIn(r.name) != -1):\nresult.append(r)\nreturn result\n",
        "org_msg": "fkie_node_manager: stop/restart only filtered nodes",
        "sim_msg": "Improved filterAcceptRow to filter based on match with parent or children",
        "sim_diff": "diff --git a/avalon/tools/cbsceneinventory/proxy.py b/avalon/tools/cbsceneinventory/proxy.py @@ -6,13 +6,12 @@ class RecursiveSortFilterProxyModel(QtCore.QSortFilterProxyModel):\n\"\"\"Filters to the regex if any of the children matches allow parent\"\"\"\ndef filterAcceptsRow(self, row, parent):\n+ if not self.filterRegExp().isEmpty():\n- regex = self.filterRegExp()\n- if not regex.isEmpty():\n- pattern = regex.pattern()\n- pattern = re.escape(pattern)\n+ pattern = re.escape(self.filterRegExp().pattern())\nmodel = self.sourceModel()\nsource_index = model.index(row, self.filterKeyColumn(), parent)\n+\nif source_index.isValid():\n# Check current index itself\n@@ -20,18 +19,34 @@ class RecursiveSortFilterProxyModel(QtCore.QSortFilterProxyModel):\nif re.search(pattern, key, re.IGNORECASE):\nreturn True\n- # Check children\nrows = model.rowCount(source_index)\n- for i in range(rows):\n- if self.filterAcceptsRow(i, source_index):\n+ if not rows:\nreturn True\n- # Otherwise filter it\n- return False\n+ return any([self.filterAcceptChildRow(i, source_index, pattern)\n+ for i in range(rows)])\nreturn super(RecursiveSortFilterProxyModel,\nself).filterAcceptsRow(row, parent)\n+ def filterAcceptChildRow(self, row, parent, pattern):\n+ \"\"\"\n+ Check if child row matches regex\n+ Args:\n+ row (int): row number in model\n+ parent (QtCore.QModelIndex): parent index item\n+ pattern (regex.pattern): pattern to check for in key\n+\n+ Returns:\n+ bool\n+\n+ \"\"\"\n+\n+ idx = self.sourceModel().index(row, self.filterKeyColumn(), parent)\n+ key = self.sourceModel().data(idx, self.filterRole())\n+ if re.search(pattern, key, re.IGNORECASE):\n+ return True\n+\nclass FilterProxyModel(RecursiveSortFilterProxyModel):\n\"\"\"Filter model to where key column's value is in the filtered tags\"\"\"\n",
        "chatgpt_cot": "Add regex filtering to nodesFromIndexes method in MasterViewProxy to filter nodes based on node name."
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/nmd_client.py b/node_manager_fkie/src/node_manager_fkie/nmd_client.py @@ -41,9 +41,9 @@ import threading\n# import node_manager_fkie as nm\nimport node_manager_daemon_fkie.exceptions as exceptions\n-import node_manager_daemon_fkie.generated.file_pb2_grpc as fgrpc\n+#import node_manager_daemon_fkie.generated.file_pb2_grpc as fgrpc\nimport node_manager_daemon_fkie.remote as remote\n-from node_manager_daemon_fkie.file_client_servicer import FileClientServicer\n+#from node_manager_daemon_fkie.file_client_servicer import FileClientServicer\nimport node_manager_daemon_fkie.file_stub as fstub\nimport node_manager_daemon_fkie.launch_stub as lstub\nfrom .common import grpc_join, grpc_split_url, utf8\n@@ -93,8 +93,8 @@ class NmdClient(QObject):\ndef __init__(self):\nQObject.__init__(self)\n- self.url = None\n- self.grpc_server = None\n+# self.url = None\n+# self.grpc_server = None\nself._channels = {}\nself._cache_file_content = {}\nself._cache_file_includes = {}\n@@ -148,13 +148,13 @@ class NmdClient(QObject):\ndef get_packages(self):\nreturn self._cache_packages\n- def start(self, url='[::]:12322'):\n- self.url = url\n- rospy.loginfo(\"Start grpc server on %s\" % url)\n- self.grpc_server = grpc.server(futures.ThreadPoolExecutor(max_workers=10))\n- fgrpc.add_FileClientServiceServicer_to_server(FileClientServicer(), self.grpc_server)\n- self.grpc_server.add_insecure_port(url)\n- self.grpc_server.start()\n+# def start(self, url='[::]:12322'):\n+# self.url = url\n+# rospy.loginfo(\"Start grpc server on %s\" % url)\n+# self.grpc_server = grpc.server(futures.ThreadPoolExecutor(max_workers=10))\n+# # fgrpc.add_FileClientServiceServicer_to_server(FileClientServicer(), self.grpc_server)\n+# self.grpc_server.add_insecure_port(url)\n+# self.grpc_server.start()\ndef get_file_manager(self, url='localhost:12321'):\nchannel = remote.get_insecure_channel(url)\n",
        "org_msg": "node_manager_fkie: removed grpc client server",
        "sim_msg": "make ping checks on the connected domains to network parallel",
        "sim_diff": "diff --git a/packages/syft/src/syft/core/node/common/client_manager/domain_api.py b/packages/syft/src/syft/core/node/common/client_manager/domain_api.py @@ -14,6 +14,9 @@ from .....core.common.uid import UID\nfrom .....grid.client.proxy_client import ProxyClient\nfrom .....lib.python import String\nfrom .....logger import error\n+from .....logger import start\n+from .....logger import stop\n+from .....util import parallel_execution\nfrom ....node.common import AbstractNodeClient\nfrom ..node_service.peer_discovery.peer_discovery_messages import (\nGetPeerInfoMessageWithReply,\n@@ -47,26 +50,22 @@ class DomainRequestAPI(RequestAPI):\n):\n# check for logged in domains if the number of possible domains changes (if a new domain shows up)\nself.num_known_domains_even_offline_ones = len(_data)\n+ n = len(_data)\ndata = list()\n- for i, domain_metadata in enumerate(_data):\n- sys.stdout.write(\n- \"\\rChecking whether domains are online: \"\n- + str(i + 1)\n- + \" of \"\n- + str(len(_data))\n- )\n- try:\n- # syft absolute\n- import syft\n-\n- syft.logger.stop()\n- if self.get(domain_metadata[\"id\"]).ping:\n- data.append(domain_metadata)\n- syft.logger.start()\n- except Exception: # nosec\n- # if pinging the domain causes an exception we just wont\n- # include it in the array\n- pass\n+\n+ args = [\n+ (self, i, n, domain_metadata[\"id\"])\n+ for i, domain_metadata in enumerate(_data)\n+ ]\n+\n+ # Check domain status in parallel\n+ check_status = parallel_execution(check_domain_status)\n+ result = check_status(args=args) if args else []\n+\n+ for i, status in enumerate(result):\n+ if status is True:\n+ data.append(_data[i])\n+\nsys.stdout.write(\"\\r \")\nself.cache = data\n@@ -122,3 +121,25 @@ class DomainRequestAPI(RequestAPI):\ndef __getitem__(self, key: Union[str, int, UID]) -> ProxyClient:\nreturn self.get(key=key)\n+\n+\n+def check_domain_status(\n+ self: DomainRequestAPI, i: int, n: int, domain_uid: str\n+) -> bool:\n+\n+ sys.stdout.write(\n+ \"\\rChecking whether domains are online: \" + str(i + 1) + \" of \" + str(n)\n+ )\n+\n+ status = False\n+ try:\n+ stop()\n+ status = self.get(domain_uid).ping\n+ start()\n+ except Exception as e: # nosec\n+ # if pinging the domain causes an exception we just wont\n+ # include it in the array\n+ print(\"Error\", e)\n+ pass\n+\n+ return status\n",
        "chatgpt_cot": "\"Fix compilation issue by commenting out unnecessary imports and method modifications in NmdClient.py.\""
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/supervised_popen.py b/node_manager_fkie/src/node_manager_fkie/supervised_popen.py @@ -74,7 +74,6 @@ class SupervisedPopen(QObject, subprocess.Popen):\nstartupinfo=startupinfo, creationflags=creationflags)\nexcept:\ntry:\n- print \"ARGS\", \"args=\", args, \"bufsize=\", bufsize, \"executable=\", executable, \"stdin=\", stdin, \"stdout=\", stdout, \"stderr=\", stderr, \"preexec_fn=\", preexec_fn, \"close_fds=\", close_fds, \"shell=\", shell, \"cwd=\", cwd, \"env=\", env, \"universal_newlines=\", universal_newlines, \"startupinfo=\", startupinfo, \"creationflags=\", creationflags\nsubprocess.Popen.__init__(self, args=args, bufsize=bufsize, executable=executable, stdin=stdin, stdout=stdout,\nstderr=stderr, preexec_fn=preexec_fn, close_fds=close_fds, shell=shell, cwd=cwd, env=env,\nuniversal_newlines=universal_newlines, startupinfo=startupinfo, creationflags=creationflags)\n@@ -109,6 +108,5 @@ class SupervisedPopen(QObject, subprocess.Popen):\nself.finished.emit(self._object_id)\ndef on_error(self, object_id, descr, msg):\n- print \"ON ERROR\"\nWarningMessageBox(QMessageBox.Warning, object_id, '%s\\n\\n'\n'%s' % (descr, msg), ' '.join(self._args)).exec_()\n",
        "org_msg": "removed some print statements",
        "sim_msg": "ThreatQ: Updating exception handling messages",
        "sim_diff": "diff --git a/Apps/phthreatquotient/threatq_connector.py b/Apps/phthreatquotient/threatq_connector.py @@ -152,6 +152,8 @@ class ThreatQConnector(BaseConnector):\ndetails = self.query_object_details('indicators', item, exact=exact, relationships=relationships)\nexcept Exception as e:\nerror_msg = self._get_error_message_from_exception(e)\n+ msg = '{} -- {}'.format(error_msg, traceback.format_exc())\n+ self.debug_print(msg)\naction_result.set_status(phantom.APP_ERROR, THREATQ_ERR_QUERY_OBJECT_DETAILS.format(error=error_msg))\nresults.append(action_result)\ncontinue\n@@ -1181,8 +1183,8 @@ class ThreatQConnector(BaseConnector):\nThreatQObject.bulk_upload(self.tq, objs)\nexcept Exception as e:\nerror_msg = self._get_error_message_from_exception(e)\n- msg = '{} -- {}'.format(error_msg, traceback.format_exc())\n- self.debug_print(\"{}. {}\".format(THREATQ_ERR_BULK_UPLOAD, msg))\n+ msg = '{} -- {}'.format(THREATQ_ERR_BULK_UPLOAD.format(error=error_msg), traceback.format_exc())\n+ self.debug_print(msg)\ncontinue\nuploaded.extend([u_obj for u_obj in objs if u_obj.oid])\n",
        "chatgpt_cot": "Refactor the SupervisedPopen class. Remove unnecessary print statements and add exception handling for subprocess.Popen initialization."
    },
    {
        "org_diff": "diff --git a/sc2/bot_ai.py b/sc2/bot_ai.py @@ -336,7 +336,7 @@ class BotAI(DistanceCalculation):\noffsets = [\n(x, y)\nfor x, y in itertools.product(range(-offset_range, offset_range + 1), repeat=2)\n- if math.hypot(x, y) <= 8\n+ if 4 < math.hypot(x, y) <= 8\n]\n# Dict we want to return\ncenters = {}\n@@ -356,7 +356,7 @@ class BotAI(DistanceCalculation):\n# Check if point can be built on\nif self._game_info.placement_grid[point.rounded] == 1\n# Check if all resources have enough space to point\n- and all(point.distance_to(resource) > (7 if resource in geysers else 6) for resource in resources)\n+ and all(point.distance_to(resource) >= (7 if resource._proto.unit_type in geyser_ids else 6) for resource in resources)\n)\n# Choose best fitting point\nresult: Point2 = min(\n",
        "org_msg": "Fix (Golden Wall) and improve expansion finding",
        "sim_msg": "Forgot to update iNumPlayers",
        "sim_diff": "diff --git a/v3/runner.py b/v3/runner.py @@ -63,6 +63,8 @@ if __name__ == '__main__':\ncallbacks = []\nname_dict = dict()\n+ gameInputPacket.iNumPlayers = num_bots\n+\n# Set configuration values for bots and store name and team\nfor i in range(num_bots):\nbot_config = configparser.RawConfigParser()\n",
        "chatgpt_cot": "Refine resource distance calculation in BotAI for building placement to consider resource type for better fitting point selection."
    },
    {
        "org_diff": "diff --git a/rasa_core_sdk/forms.py b/rasa_core_sdk/forms.py @@ -37,7 +37,7 @@ class FormAction(Action):\nexisting_val = tracker.get_slot(slot_name)\nreturn existing_val is None\n- def validate(self, tracker):\n+ def validate(self, dispatcher, tracker):\n# type: (Tracker) -> Dict[Text, Any]\n\"\"\"\"Validate the user input.\"\"\"\n@@ -64,7 +64,7 @@ class FormAction(Action):\ndef run(self, dispatcher, tracker, domain):\nif tracker.active_form == self.name() and tracker.latest_action_name == 'action_listen':\n- events = self.validate(tracker)\n+ events = self.validate(dispatcher, tracker)\nelse:\nevents = []\n",
        "org_msg": "add dispatcher to validate signature",
        "sim_msg": "Allow users with names longer than the current limit to log in",
        "sim_diff": "diff --git a/app/forms/user.py b/app/forms/user.py @@ -78,7 +78,7 @@ class UsernameLength:\nclass LoginForm(RedirectForm):\n\"\"\" Login form. \"\"\"\n- username = StringField(_l(\"Username\"), validators=[UsernameLength()])\n+ username = StringField(_l(\"Username\"), validators=[Length(max=256)])\npassword = PasswordField(\n_l(\"Password\"), validators=[DataRequired(), Length(min=7, max=256)]\n)\n",
        "chatgpt_cot": "Add 'dispatcher' parameter to validate method for FormAction class in forms.py to handle user input validation properly. Fix validation logic."
    },
    {
        "org_diff": "diff --git a/src/dashboard/src/models/login.js b/src/dashboard/src/models/login.js @@ -47,6 +47,8 @@ export default {\n}\n}\nyield put(routerRedux.replace(redirect || '/'));\n+ // TODO: find better method to reload token for request, reload page to obtain the token from storage\n+ window.location.reload();\n}\n},\n",
        "org_msg": "Fix first login bug for dashboard\nWhen login dashboard at first time, token will be null.",
        "sim_msg": "added a timer in dashboard",
        "sim_diff": "diff --git a/myems-web/src/components/MyEMS/dashboard/Dashboard.js b/myems-web/src/components/MyEMS/dashboard/Dashboard.js @@ -406,6 +406,16 @@ const Dashboard = ({ setRedirect, setRedirectUrl, t }) => {\n};\n}, );\n+ useEffect(() => {\n+ let timer = setInterval(() => {\n+ let is_logged_in = getCookieValue('is_logged_in');\n+ if (is_logged_in === null || !is_logged_in) {\n+ setRedirectUrl(`/authentication/basic/login`);\n+ setRedirect(true);\n+ }\n+ }, 1000);\n+ return () => clearInterval(timer);\n+ }, [])\nreturn (\n<Fragment>\n",
        "chatgpt_cot": "Add a comment and reload page to obtain token from storage for request in login.js model."
    },
    {
        "org_diff": "diff --git a/.github/workflows/pythonactions.yml b/.github/workflows/pythonactions.yml @@ -26,25 +26,34 @@ jobs:\nwith:\npython-version: ${{ matrix.python-version }}\n- - name: Cache poetry\n+ - name: Install Poetry\n+ run: |\n+ python -m pip install poetry\n+\n+ - name: Make poetry use local .venv folder\n+ run: poetry config virtualenvs.in-project true\n+\n+ - name: Set up cache\nuses: actions/cache@v2\nwith:\n- path: ~/.cache/pypoetry/virtualenvs\n- key: ${{ runner.os }}-${{ matrix.python-version }}-poetry-${{ hashFiles('poetry.lock') }}\n+ path: .venv\n+ key: ${{ matrix.os }}-${{ matrix.python-version }}-poetry-${{ hashFiles('poetry.lock') }}\n- name: Install dependencies\nrun: |\n- python -m pip install poetry\npoetry install\n# Run pylint\n- - name: Run pylint\n+ - name: Run pylint on sc2 folder\nrun: |\npoetry run pylint sc2\n+\n+ - name: Run pylint on examples folder\n+ run: |\npoetry run pylint examples\n# Run tests\n- - name: Run poetry pytest tests on pickle files\n+ - name: Run pytest\nrun: |\npoetry run pytest test\n",
        "org_msg": "Fix cache for other OS on github actions",
        "sim_msg": "setup python environment before running linting",
        "sim_diff": "diff --git a/.github/workflows/test.yml b/.github/workflows/test.yml @@ -11,8 +11,35 @@ on:\n- develop\njobs:\n+ setup:\n+ runs-on: ubuntu-latest\n+ steps:\n+ - uses: actions/checkout@v2\n+\n+ # Python dependencies\n+ - name: setup Python 3.9\n+ uses: actions/setup-python@v2\n+ with:\n+ python-version: 3.9\n+ - name: install Poetry\n+ uses: snok/install-poetry@v1.1.1\n+ - name: cache Poetry virtualenv\n+ uses: actions/cache@v2\n+ id: poetry-cache\n+ with:\n+ path: ~/.virtualenvs/\n+ key: poetry-${{ hashFiles('**/poetry.lock') }}\n+ restore-keys: |\n+ poetry-${{ hashFiles('**/poetry.lock') }}\n+ - name: set poetry config path\n+ run: poetry config virtualenvs.path ~/.virtualenvs\n+ - name: install python dependencies\n+ run: poetry install\n+\nlint:\nruns-on: ubuntu-latest\n+ needs:\n+ - setup\nsteps:\n- name: lint with flake8 and black\nrun: poetry run inv lint\n@@ -21,6 +48,7 @@ jobs:\nruns-on: ubuntu-latest\nneeds:\n- lint\n+ - setup\nservices:\npostgres:\nimage: postgres\n@@ -37,28 +65,6 @@ jobs:\nports:\n- 5432:5432\nsteps:\n- - uses: actions/checkout@v2\n-\n- # Python dependencies\n- - name: setup Python 3.9\n- uses: actions/setup-python@v2\n- with:\n- python-version: 3.9\n- - name: install Poetry\n- uses: snok/install-poetry@v1.1.1\n- - name: cache Poetry virtualenv\n- uses: actions/cache@v2\n- id: poetry-cache\n- with:\n- path: ~/.virtualenvs/\n- key: poetry-${{ hashFiles('**/poetry.lock') }}\n- restore-keys: |\n- poetry-${{ hashFiles('**/poetry.lock') }}\n- - name: set poetry config path\n- run: poetry config virtualenvs.path ~/.virtualenvs\n- - name: install python dependencies\n- run: poetry install\n-\n# node dependencies\n- name: setup Node 12\nuses: actions/setup-node@v1\n",
        "chatgpt_cot": "Update GitHub workflow to install Poetry, set up cache, and run pylint and pytest on specific folders for better dependency management and testing."
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/rqt_node_manager.py b/node_manager_fkie/src/node_manager_fkie/rqt_node_manager.py @@ -34,7 +34,7 @@ class NodeManager(Plugin):\nself._widget = MainWindow()\n# self._widget.read_view_history()\nexcept Exception, e:\n- MessageBox.critical(self, \"Node Manager\", utf8(e))\n+ MessageBox.critical(None, \"Node Manager\", utf8(e))\nraise\n# Get path to UI file which is a sibling of this file\n# in this example the .ui and .py file are in the same folder\n",
        "org_msg": "node_manager_fkie: fixed warning dialog in rqt",
        "sim_msg": "stupid backslashes in file paths",
        "sim_diff": "diff --git a/source1/content_manager.py b/source1/content_manager.py @@ -58,7 +58,8 @@ class ContentManager(metaclass=SingletonMeta):\nreturn False, path\ndef find_file(self, filepath: str, additional_dir=None, extension=None):\n- new_filepath = Path(filepath)\n+\n+ new_filepath = Path(str(filepath).strip('/\\\\').rstrip('/\\\\'))\nif additional_dir:\nnew_filepath = Path(additional_dir, new_filepath)\nif extension:\n",
        "chatgpt_cot": "Update error message display method in NodeManager class to resolve compilation issue and improve code readability."
    },
    {
        "org_diff": "diff --git a/src/agent/kubernetes-agent/src/utils/download.py b/src/agent/kubernetes-agent/src/utils/download.py @@ -12,7 +12,7 @@ def download_file(url, target_dir):\ncontent_type = r.headers[\"content-type\"]\nextension = mimetypes.guess_extension(content_type)\nfile_name = \"%s%s\" % (uuid4().hex, extension)\n- target_file = os.path.join(target_dir, file_name)\n+ target_file = os.path.join(target_dir, secure(file_name))\nif not os.path.exists(target_dir):\nos.makedirs(target_dir)\n",
        "org_msg": "Path Traversal Bug",
        "sim_msg": "use limit size if lt page size, stats output",
        "sim_diff": "diff --git a/planet/scripts/__init__.py b/planet/scripts/__init__.py @@ -816,6 +816,8 @@ def download(item_type, asset_type, filter_json, dest, limit, **kw):\n'''Activate and download'''\nreq = filters.build_request(_active_filter(filter_json, **kw), item_type)\ncl = clientv1()\n- items = cl.quick_search(active, req)\n+ page_size = min(limit, 250)\n+ items = cl.quick_search(req, page_size=page_size)\ndl = downloader(cl, asset_type, dest or '.')\n+ monitor_stats(dl.stats, lambda x: click.echo(x, nl=False))\nhandle_interrupt(dl.shutdown, dl.download, items.items_iter(limit))\n",
        "chatgpt_cot": "\"Secure file name in download function to prevent potential security vulnerabilities\""
    },
    {
        "org_diff": "diff --git a/test/test_pickled_data.py b/test/test_pickled_data.py @@ -72,7 +72,7 @@ random_bot_object: BotAI = next(bot_object_generator)\ndef test_bot_ai():\n- bot: BotAI = random_bot_object\n+ bot: BotAI = next(bot_object_generator)\n# Test initial bot attributes at game start\n# Properties from _prepare_start\n",
        "org_msg": "Improve test_bot_ai by creating a clean object for test_bot_ai",
        "sim_msg": "resolving a failing test",
        "sim_diff": "diff --git a/tests/test_cli_gui/test_search.py b/tests/test_cli_gui/test_search.py @@ -139,9 +139,12 @@ def test_real_search():\n)\nassert response_list.status_code == 200\ndata = json.loads(response_list.get_data(as_text=True))\n- assert len(data) == 9\n+ assert len(data) == 10\ni = 0\n+ assert data[i][\"id\"] == \"fetchai/webhook:0.1.0\"\n+ assert data[i][\"description\"] == \"The webhook connection that wraps a webhook functionality.\"\n+ i += 1\nassert data[i][\"id\"] == \"fetchai/gym:0.1.0\"\nassert data[i][\"description\"] == \"The gym connection wraps an OpenAI gym.\"\ni += 1\n",
        "chatgpt_cot": "Refactor test_bot_ai to use next method for bot_object_generator. Update test_pickled_data.py to enhance test coverage and accuracy."
    },
    {
        "org_diff": "diff --git a/fkie_node_manager/src/fkie_node_manager/settings.py b/fkie_node_manager/src/fkie_node_manager/settings.py @@ -148,8 +148,8 @@ class Settings(object):\n'''\nself._terminal_emulator = None\nself._terminal_command_arg = 'e'\n- self._noclose_str = '-hold'\n- self._terminal_title = '--title'\n+ self._noclose_str = ''\n+ self._terminal_title = '-T'\nself._masteruri = masteruri_from_ros()\nself.CFG_PATH = os.path.expanduser('~/.config/ros.fkie/node_manager/')\n# loads the current configuration path. If the path was changed, a redirection\n",
        "org_msg": "Use more conservative terminal emulator parameters\nThis should make the x-terminal-emulator call more compatible with\ndifferent types of terminals",
        "sim_msg": "Updates Default System theme to Defaultv3",
        "sim_diff": "diff --git a/classes/settings.py b/classes/settings.py @@ -50,7 +50,7 @@ class settings(db.Model):\nself.showEmptyTables = showEmptyTables\nself.allowComments = allowComments\nself.sortMainBy = 0\n- self.systemTheme = \"Defaultv2\"\n+ self.systemTheme = \"Defaultv3\"\nself.version = version\nself.systemLogo = \"/static/img/logo.png\"\nself.systemLogoLight = \"/static/img/logo-light.png\"\n",
        "chatgpt_cot": "Update terminal settings in Settings class to remove hold option and change title flag to '-T'."
    },
    {
        "org_diff": "diff --git a/fkie_node_manager/src/fkie_node_manager/master_view_proxy.py b/fkie_node_manager/src/fkie_node_manager/master_view_proxy.py @@ -1944,7 +1944,10 @@ class MasterViewProxy(QWidget):\n# 'Level (super)': ('string', nm.settings().logging.get_alternatives('loglevel_superdebug')),\n'Format': {':type': 'string', ':value': nm.settings().logging.get_alternatives('console_format')}\n}\n- params = {'prefix': {':type': 'string', ':value': ['', 'gdb -ex run --args', 'valgrind', 'python -m pdb']},\n+ params = {'Prefix': {':type': 'string',\n+ ':value': ['', 'gdb -ex run --args', 'valgrind', 'python -m pdb'],\n+ ':hint': 'Custom command prefix. It will be prepended before launch prefix.'\n+ },\n'Logging': log_params}\ndia = ParameterDialog(params, store_geometry=\"adv_cfg_dialog\")\ndia.setFilterVisible(False)\n@@ -1960,7 +1963,7 @@ class MasterViewProxy(QWidget):\nnm.settings().logging.console_format = params['Logging']['Format']\nnm.settings().store_logging()\nlogging = nm.settings().logging\n- cmd_prefix = params['prefix']\n+ cmd_prefix = params['Prefix']\nexcept Exception, e:\ndiag_canceled = True\nMessageBox.warning(self, \"Get advanced start parameter\",\n",
        "org_msg": "added help text for prefix field in advanced configuration",
        "sim_msg": "ensure cmd is a well formed json string",
        "sim_diff": "diff --git a/openbb_terminal/parent_classes.py b/openbb_terminal/parent_classes.py @@ -10,6 +10,7 @@ import re\nimport os\nimport difflib\nimport logging\n+import json\nfrom typing import Union, List, Dict, Any\nfrom datetime import datetime, timedelta\n@@ -242,13 +243,14 @@ class BaseController(metaclass=ABCMeta):\nself, known_cmd: str, other_args_str: str, the_input: str\n) -> None:\nif not self.contains_keys(the_input):\n- logger.info(\n- \"CMD: {'path': '%s', 'known_cmd': '%s', 'other_args': '%s', 'input': '%s'}\",\n- self.PATH,\n- known_cmd,\n- other_args_str,\n- the_input,\n- )\n+ cmd = {\n+ \"path\": self.PATH,\n+ \"known_cmd\": known_cmd,\n+ \"other_args\": other_args_str,\n+ \"input\": the_input,\n+ }\n+ logger.info(\"CMD: %s\", json.dumps(cmd))\n+\nif the_input not in self.KEYS_MENU:\nself.log_queue()\n",
        "chatgpt_cot": "Fix parameter naming and add hint to the parameter value."
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/start_handler.py b/node_manager_fkie/src/node_manager_fkie/start_handler.py @@ -554,7 +554,10 @@ class StartHandler(object):\nrospy.logwarn(\"ERROR while start '%s': %s\", name, error)\nraise StartException(''.join(['The host \"', host, '\" reports:\\n', error]))\nif output:\n- rospy.logdebug(\"STDOUT while start '%s': %s\", name, output)\n+ if output.find(\"dn't\") != -1:\n+ rospy.logwarn(\"Warning while start '%s': %s\", name, output)\n+ else:\n+ rospy.loginfo(\"STDOUT while start '%s': %s\", name, output)\nelse:\nif error:\nrospy.logwarn(\"ERROR while start '%s': %s\", name, error)\n",
        "org_msg": "node_manager_fkie: added warning if while remote start no executable was found\nrosrun throws no error if no executable was found it is only an output.",
        "sim_msg": "construction: exception handling",
        "sim_diff": "diff --git a/tutorial/tools.py b/tutorial/tools.py from server import app\n+def exception_handler(func):\n+ def wrapper(path):\n+ try:\n+ return func(path)\n+ except Exception as e:\n+ print('\\nError running {}\\n{}'.format(\n+ path,\n+ ('======================================' +\n+ '======================================')\n+ ))\n+ raise e\n+ return wrapper\n+\n+@exception_handler\ndef load_example(path):\nwith open(path, 'r') as _f:\n_source = _f.read()\n@@ -38,15 +52,7 @@ def load_example(path):\n)\nscope = {'app': app}\n- try:\nexec(_example, scope)\n- except Exception as e:\n- print('\\nError running {}\\n{}'.format(\n- path,\n- ('======================================' +\n- '======================================')\n- ))\n- raise e\nreturn (\n_source,\n",
        "chatgpt_cot": "Refactor logging in StartHandler to differentiate warnings and info messages based on output content. Fix logging message for specific output condition."
    },
    {
        "org_diff": "diff --git a/docs_generate/conf.py b/docs_generate/conf.py @@ -15,6 +15,8 @@ import sys\nsys.path.insert(0, os.path.abspath(\"..\"))\n+import sphinx_rtd_theme # nopycln: import\n+\n# -- Project information -----------------------------------------------------\nproject = \"python-sc2\"\n",
        "org_msg": "Add sphinx_rtd_theme import",
        "sim_msg": "update conf.py to make Sphinx RTD theme work",
        "sim_diff": "diff --git a/docs/conf.py b/docs/conf.py # import os\n# import sys\n# sys.path.insert(0, os.path.abspath('.'))\n-\n+import sphinx_rtd_theme\n# -- General configuration ------------------------------------------------\n@@ -94,7 +94,8 @@ todo_include_todos = False\n# a list of builtin themes.\n#\n#html_theme = 'alabaster'\n-html_theme = 'sphinx_rtd_theme'\n+html_theme = \"sphinx_rtd_theme\"\n+html_theme_path = [sphinx_rtd_theme.get_html_theme_path()]\n# Theme options are theme-specific and customize the look and feel of a theme\n# further. For a list of options available for each theme, see the\n",
        "chatgpt_cot": "Add import statement for sphinx_rtd_theme to resolve import error in conf.py for python-sc2 project."
    },
    {
        "org_diff": "diff --git a/fkie_master_discovery/src/fkie_master_discovery/filter_interface.py b/fkie_master_discovery/src/fkie_master_discovery/filter_interface.py @@ -191,9 +191,7 @@ class FilterInterface(object):\nreturn True\nif self._re_ignore_topics.match(topic):\nreturn True\n- if self._re_sync_nodes.match(node):\n- return False\n- if self._re_sync_topics.match(topic):\n+ if self._re_sync_nodes.match(node) or self._re_sync_topics.match(topic):\nreturn False\n# there are no sync nodes and topic lists defined => return False (=>sync the given topic)\nreturn not is_empty_pattern(self._re_sync_nodes) or not is_empty_pattern(self._re_sync_topics)\n@@ -281,9 +279,7 @@ class FilterInterface(object):\nreturn True\nif self._re_ignore_services.match(service.strip()):\nreturn True\n- if self._re_sync_nodes.match(node):\n- return False\n- if self._re_sync_services.match(service):\n+ if self._re_sync_nodes.match(node) or self._re_sync_services.match(service):\nreturn False\nreturn not is_empty_pattern(self._re_sync_nodes) or not is_empty_pattern(self._re_sync_services)\n",
        "org_msg": "fkie_master_sync: change filter to (sync_nodes OR sync_topics)",
        "sim_msg": "Fix no longer in scope variable ref",
        "sim_diff": "diff --git a/workers/facade_worker/contributor_interfaceable/contributor_interface.py b/workers/facade_worker/contributor_interfaceable/contributor_interface.py @@ -557,8 +557,7 @@ class ContributorInterfaceable(WorkerGitInterfaceable):\nif item['score'] > match['score']:\nmatch = item\n- self.logger.info(\"When searching for a contributor with info {}, we found the following users: {}\\n\".format(\n- contributor, match))\n+ self.logger.info(\"When searching for a contributor with info {}, we found the following users: {}\\n\".format(match))\nreturn match['login']\n@@ -762,7 +761,7 @@ class ContributorInterfaceable(WorkerGitInterfaceable):\nself.logger.info(\nf\"Deleting now resolved email failed with error: {e}\")\n- self.logger.info(\"DEBUG: Got through the new_contribs\")\n+ #self.logger.info(\"DEBUG: Got through the new_contribs\")\n# sql query used to find corresponding cntrb_id's of emails found in the contributor's table\n# i.e., if a contributor already exists, we use it!\n@@ -794,14 +793,14 @@ class ContributorInterfaceable(WorkerGitInterfaceable):\nAND commits.repo_id = :repo_id\n\"\"\")\n- self.logger.info(\"DEBUG: got passed the sql statement declaration\")\n+ #self.logger.info(\"DEBUG: got passed the sql statement declaration\")\n# Get a list of dicts that contain the emails and cntrb_id's of commits that appear in the contributor's table.\nexisting_cntrb_emails = json.loads(pd.read_sql(resolve_email_to_cntrb_id_sql, self.db, params={\n'repo_id': repo_id}).to_json(orient=\"records\"))\n- self.logger.info(\"DEBUG: got passed the sql statement's execution\")\n+ #self.logger.info(\"DEBUG: got passed the sql statement's execution\")\n- self.logger.info(f\"DEBUG: Here are the existing emails: {existing_cntrb_emails}\")\n+ #self.logger.info(f\"DEBUG: Here are the existing emails: {existing_cntrb_emails}\")\n# iterate through all the commits with emails that appear in contributors and give them the relevant cntrb_id.\nfor cntrb_email in existing_cntrb_emails:\n",
        "chatgpt_cot": "Refactor FilterInterface to simplify sync logic and improve readability. Remove redundant conditionals and combine sync checks for nodes and topics/services."
    },
    {
        "org_diff": "diff --git a/sc2/bot_ai.py b/sc2/bot_ai.py @@ -800,9 +800,6 @@ class BotAI(DistanceCalculation):\n# Required for events\nself._units_previous_map: Dict = {unit.tag: unit for unit in self.units}\nself._structures_previous_map: Dict = {structure.tag: structure for structure in self.structures}\n- self.workers: Units = self.units(race_worker[self.race])\n- self.townhalls: Units = self.structures(race_townhalls[self.race])\n- self.gas_buildings: Units = self.structures(race_gas[self.race])\nself.minerals: int = state.common.minerals\nself.vespene: int = state.common.vespene\nself.supply_army: int = state.common.food_army\n@@ -833,6 +830,9 @@ class BotAI(DistanceCalculation):\nself.destructables: Units = Units([], self)\nself.watchtowers: Units = Units([], self)\nself.all_units: Units = Units([], self)\n+ self.workers: Units = Units([], self)\n+ self.townhalls: Units = Units([], self)\n+ self.gas_buildings: Units = Units([], self)\nfor unit in self.state.observation_raw.units:\nif unit.is_blip:\n@@ -860,10 +860,17 @@ class BotAI(DistanceCalculation):\nself.destructables.append(unit_obj)\n# Alliance.Self.value = 1\nelif alliance == 1:\n+ unit_id = unit.type_id\nif unit_obj.is_structure:\nself.structures.append(unit_obj)\n+ if unit_id in race_townhalls[self.race]:\n+ self.townhalls.append(unit_obj)\n+ elif unit_id == race_gas[self.race]:\n+ self.gas_buildings.append(unit_obj)\nelse:\nself.units.append(unit_obj)\n+ if unit_id == race_worker[self.race]:\n+ self.workers.append(unit_obj)\n# Alliance.Enemy.value = 4\nelif alliance == 4:\nif unit_obj.is_structure:\n",
        "org_msg": "add workers, townhalls and gas buildings in prepare units",
        "sim_msg": "initial pass at creation of conversion from export to a labelbox format",
        "sim_diff": "diff --git a/labelbox/data/serialization/labelbox_v1/objects.py b/labelbox/data/serialization/labelbox_v1/objects.py @@ -259,17 +259,22 @@ class LBV1TextEntity(LBV1ObjectBase):\n**extra)\n+class LBV1DocumentRectangle(LBV1Rectangle):\n+ unit: str\n+ page: int\n+\n+\nclass LBV1Objects(BaseModel):\n- objects: List[Union[LBV1Line, LBV1Point, LBV1Polygon, LBV1Rectangle,\n- LBV1TextEntity, LBV1Mask, LBV1TIPoint, LBV1TILine,\n- LBV1TIPolygon, LBV1TIRectangle]]\n+ objects: List[Union[LBV1DocumentRectangle, LBV1Line, LBV1Point, LBV1Polygon,\n+ LBV1Rectangle, LBV1TextEntity, LBV1Mask, LBV1TIPoint,\n+ LBV1TILine, LBV1TIPolygon, LBV1TIRectangle,]]\ndef to_common(self) -> List[ObjectAnnotation]:\nobjects = [\n- ObjectAnnotation(value=obj.to_common(),\n+ ObjectAnnotation(\n+ value=obj.to_common(),\nclassifications=[\n- ClassificationAnnotation(\n- value=cls.to_common(),\n+ ClassificationAnnotation(value=cls.to_common(),\nfeature_schema_id=cls.schema_id,\nname=cls.title,\nextra={\n@@ -285,6 +290,8 @@ class LBV1Objects(BaseModel):\n'color': obj.color,\n'feature_id': obj.feature_id,\n'value': obj.value,\n+ 'page': obj.page if hasattr(obj, 'page') else None,\n+ 'unit': obj.unit if hasattr(obj, 'unit') else None,\n}) for obj in self.objects\n]\nreturn objects\n",
        "chatgpt_cot": "Refactor BotAI class to fix issue with workers, townhalls, and gas_buildings initialization. Add missing units to the respective lists."
    },
    {
        "org_diff": "diff --git a/fkie_multimaster/package.xml b/fkie_multimaster/package.xml The metapackage to combine the nodes required to establish and manage a multimaster network.\nThis requires no or minimal configuration. The changes are automatically detected and synchronized.\n</description>\n- <version>1.0.0</version>\n+ <version>1.1.0</version>\n<license>BSD</license>\n<author>Alexander Tiderko</author>\n<maintainer email=\"alexander.tiderko@gmail.com\">Alexander Tiderko</maintainer>\n",
        "org_msg": "fkie_multimaster: updated version",
        "sim_msg": "[Chore] Fix tezos-baking package dependencies\nProblem: There is on endorser daemon in 012 protocol. However,\n'tezos-baking' package ended up depending on 'tezos-endorser-012-psithaca'.\nAs a result, it's impossible to install/upgrade tezos-baking-12.0-rc1-0ubuntu1 :(\nSolution: Remove dependency on 'tezos-endorser-012-psithaca' package.",
        "sim_diff": "diff --git a/docker/package/model.py b/docker/package/model.py @@ -487,6 +487,7 @@ class TezosBakingServicesPackage(AbstractPackage):\nself.meta = deepcopy(meta)\nself.meta.version = self.meta.version + self.letter_version\nself.target_protos = set()\n+ self.noendorser_protos = protocols[\"active_noendorser\"]\nfor network in target_networks:\nfor proto in network_protos[network]:\nself.target_protos.add(proto)\n@@ -495,7 +496,7 @@ class TezosBakingServicesPackage(AbstractPackage):\nrequires = [f\"tezos-node-{network}.service\"]\nfor proto in network_protos[network]:\nrequires.append(f\"tezos-baker-{proto.lower()}@{network}.service\")\n- if proto not in protocols[\"active_noendorser\"]:\n+ if proto not in self.noendorser_protos:\nrequires.append(f\"tezos-endorser-{proto.lower()}@{network}.service\")\nself.systemd_units.append(\nSystemdUnit(\n@@ -537,19 +538,12 @@ class TezosBakingServicesPackage(AbstractPackage):\nshutil.copy(f\"{os.path.dirname(__file__)}/tezos_setup_wizard.py\", out_dir)\ndef gen_control_file(self, deps, ubuntu_version, out):\n- run_deps = \", \".join(\n- [\"acl\", \"tezos-client\", \"tezos-node\"]\n- + sum(\n- [\n- [\n- f\"tezos-{daemon}-{proto.lower()}\"\n- for daemon in [\"baker\", \"endorser\"]\n- ]\n- for proto in self.target_protos\n- ],\n- [],\n- )\n- )\n+ run_deps_list = [\"acl\", \"tezos-client\", \"tezos-node\"]\n+ for proto in self.target_protos:\n+ run_deps_list.append(f\"tezos-baker-{proto.lower()}\")\n+ if proto not in self.noendorser_protos:\n+ run_deps_list.append(f\"tezos-endorser-{proto.lower()}\")\n+ run_deps = \", \".join(run_deps_list)\nfile_contents = f\"\"\"\nSource: {self.name}\nSection: utils\n",
        "chatgpt_cot": "Update version to 1.1.0 for FKIE multimaster package, ensuring automatic detection and synchronization of changes for establishing and managing a multimaster network."
    },
    {
        "org_diff": "diff --git a/examples/fastreload.py b/examples/fastreload.py @@ -16,9 +16,8 @@ def main():\ngen = sc2.main._host_game_iter(sc2.maps.get(\"Abyssal Reef LE\"), player_config, realtime=False)\n- while True:\nr = next(gen)\n-\n+ while True:\ninput(\"Press enter to reload \")\nreload(zerg_rush)\n",
        "org_msg": "Fix the issue of game being launched twice without asking for the user input",
        "sim_msg": "Forgot to update iNumPlayers",
        "sim_diff": "diff --git a/v3/runner.py b/v3/runner.py @@ -63,6 +63,8 @@ if __name__ == '__main__':\ncallbacks = []\nname_dict = dict()\n+ gameInputPacket.iNumPlayers = num_bots\n+\n# Set configuration values for bots and store name and team\nfor i in range(num_bots):\nbot_config = configparser.RawConfigParser()\n",
        "chatgpt_cot": "\"Add functionality to fastreload.py for manual reload during gameplay to enhance user experience.\""
    },
    {
        "org_diff": "diff --git a/fkie_node_manager/src/fkie_node_manager/node_tree_model.py b/fkie_node_manager/src/fkie_node_manager/node_tree_model.py @@ -927,7 +927,7 @@ class HostItem(GroupItem):\nself.sysmon_state = False\nself.local = local\n- def __hash__(self) -> int:\n+ def __hash__(self):\nstr = self._masteruri + self._host\nhash_str = hashlib.md5(str.encode()).hexdigest()\nreturn int(hash_str, base=16)\n",
        "org_msg": "fkie_node_manager: fixed not compatible python2 code",
        "sim_msg": "MOVE password update from set() to change_password method",
        "sim_diff": "diff --git a/packages/syft/src/syft/core/node/common/node_manager/user_manager.py b/packages/syft/src/syft/core/node/common/node_manager/user_manager.py @@ -285,10 +285,6 @@ class UserManager(DatabaseManager):\nif email:\nkey = \"email\"\nvalue = email\n- elif password:\n- salt, hashed = self.__salt_and_hash_password(password, 12)\n- self.modify({\"id\": user_id}, {\"salt\": salt, \"hashed_password\": hashed})\n- return\nelif role != 0:\nkey = \"role\"\nvalue = role\n@@ -312,6 +308,20 @@ class UserManager(DatabaseManager):\nself.modify({\"id\": user_id}, {key: value})\n+ def change_password(self, user_id: str, current_pwd: str, new_pwd: str) -> None:\n+ user = self.first(id=user_id)\n+\n+ hashed = user.hashed_password.encode(\"UTF-8\")\n+ salt = user.salt.encode(\"UTF-8\")\n+ bytes_pass = current_pwd.encode(\"UTF-8\")\n+\n+ if checkpw(bytes_pass, salt + hashed):\n+ salt, hashed = self.__salt_and_hash_password(new_pwd, 12)\n+ self.modify({\"id\": user_id}, {\"salt\": salt, \"hashed_password\": hashed})\n+ else:\n+ # Should it warn the user about his wrong current password input?\n+ raise InvalidCredentialsError\n+\ndef can_create_users(self, verify_key: VerifyKey) -> bool:\n\"\"\"Checks if a user has permissions to create new users.\"\"\"\ntry:\n",
        "chatgpt_cot": "remove type hint from __hash__ method in HostItem class"
    },
    {
        "org_diff": "diff --git a/sc2/pixel_map.py b/sc2/pixel_map.py @@ -31,11 +31,13 @@ class PixelMap:\nreturn self._proto.bits_per_pixel // 8\ndef __getitem__(self, pos):\n+ \"\"\" Example usage: is_pathable = self._game_info.pathing_grid[Point2((20, 20))] == 0 \"\"\"\nassert 0 <= pos[0] < self.width, f\"x is {pos[0]}, self.width is {self.width}\"\nassert 0 <= pos[1] < self.height, f\"y is {pos[1]}, self.height is {self.height}\"\nreturn int(self.data_numpy[pos[1] - 1, pos[0]])\ndef __setitem__(self, pos, value):\n+ \"\"\" Example usage: self._game_info.pathing_grid[Point2((20, 20))] = 255 \"\"\"\nassert 0 <= pos[0] < self.width, f\"x is {pos[0]}, self.width is {self.width}\"\nassert 0 <= pos[1] < self.height, f\"y is {pos[1]}, self.height is {self.height}\"\nassert 0 <= value < 256, f\"value is {value}, it should be between 0 and 255\"\n",
        "org_msg": "Add example usages",
        "sim_msg": "Removed performance bottleneck: array data has accidentally been loaded into memory entirely",
        "sim_diff": "diff --git a/xcube/core/tile.py b/xcube/core/tile.py @@ -166,7 +166,7 @@ def new_color_mapped_image(ml_dataset,\nexception_type)\ncmap_name, cmap_range = get_var_cmap_params(var, cmap_name, cmap_range, valid_range)\ntile_grid = ml_dataset.tile_grid\n- image = ArrayImage(array.values,\n+ image = ArrayImage(array,\nimage_id=f'ai-{image_id}',\ntile_size=tile_grid.tile_size,\ntrace_perf=trace_perf)\n",
        "chatgpt_cot": "Add documentation for the __getitem__ and __setitem__ methods in PixelMap class."
    },
    {
        "org_diff": "diff --git a/README.md b/README.md @@ -39,14 +39,19 @@ Maps that are run on the [SC2 AI Ladder](http://sc2ai.net/) and [SC2 AI Arena](h\nAfter installing the library, a StarCraft II executable, and some maps, you're ready to get started. Simply run a bot file to fire up an instance of StarCraft II with the bot running. For example:\n-```\n+```python\npython3 examples/protoss/cannon_rush.py\n```\n-If you installed StarCraft II on Linux with Wine, set the `SC2PF` environment variable to `WineLinux`:\n+If you installed StarCraft II on Linux with Wine or Lutris, set the following environment variables (either globally or within your development environment, e.g. Pycharm: `Run -> Edit Configurations -> Environment Variables`:\n-```\n-SC2PF=WineLinux python3 examples/protoss/cannon_rush.py\n+```sh\n+SC2PF=WineLinux\n+WINE=usr/bin/wine\n+# Or a wine binary from lutris:\n+# WINE=/home/burny/.local/share/lutris/runners/wine/lutris-4.20-x86_64/bin/wine64\n+# Default Lutris StarCraftII Installation path:\n+SC2PATH=/home/burny/Games/battlenet/drive_c/Program Files (x86)/StarCraft II/\n```\n## Example\n",
        "org_msg": "Update readme for linux with wine",
        "sim_msg": "Editted READ.me for clarity",
        "sim_diff": "diff --git a/README.md b/README.md @@ -34,7 +34,7 @@ More more information read our recent <a href=\"http://dawn.cs.stanford.edu/2017/\n## Installation\n-This file will go through the steps needed to install the required packages and software to run HoloClean. For a more detailed installation guide check out the [Holoclean_Installation_v3.pdf](https://github.com/HoloClean/HoloClean-v0.01/blob/pytorch/Holoclean_Installation_v3.pdf) file in the git repo.\n+This file will go through the steps needed to install the required packages and software to run HoloClean. For a more detailed installation guide check out the [Holoclean_Installation_v3.pdf](https://github.com/HoloClean/HoloClean/blob/pytorch-clean/docs/Holoclean_Installation_v3.pdf) file in the git repo.\n### 1. Setting Up and Using Conda\n<b>1.1 Ubuntu: </b>\n@@ -52,17 +52,17 @@ bash Anaconda-2.3.0-Linux-x86_64.sh\n```\n<h4>1.2 MacOS: <h4>\n-Follow instructions [here](https://conda.io/docs/user-guide/install/macos.html) to install conda for MacOS\n+Follow instructions [here](https://conda.io/docs/user-guide/install/macos.html) to install Anaconda (Not miniconda) for MacOS\n<h4> 1.3 Using Conda </h4>\n-Open the terminal and create a Python 2.7 environment by running the command:\n+Open/Restart the terminal and create a Python 2.7 environment by running the command:\nconda create -n py27Env python=2.7 anaconda\nThen the environment can be activated by running:\nsource activate py27Env\n-Make sure the keep the environment activated for the rest of the installation process\n+<b> Make sure the keep the environment activated for the rest of the installation process </b>\n### 2. Download and Install Spark\n@@ -74,8 +74,6 @@ Go to the directory where you downloaded the file and run:\ntar -xzf spark-2.2.0-bin-hadoop2.7.tgz\npip install pyspark\n```\n-On MacOS run `brew install apache-spark`\n-\n### 3. Install MySQL Server\n<b> 3.1 For Ubuntu: </b>\n@@ -119,4 +117,13 @@ http://pytorch.org/\nTo install pytorch\nMake sure to install version 0.3.0 or later\n+### 6. Install JDK 8\n+<b> 6.1 For Ubuntu: </b>\n+Run the following command:\n+```\n+sudo apt-get install default-jre\n+```\n+<br>\n+<b> 3.2 For MacOS </b>\n+Download JDK for MacOS from the oracle website: http://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html\n",
        "chatgpt_cot": "\"Add environment variable settings for running StarCraft II on Linux with Wine or Lutris to README.md\""
    },
    {
        "org_diff": "diff --git a/sc2/unit.py b/sc2/unit.py @@ -39,7 +39,18 @@ from .constants import (\nUNIT_PHOTONCANNON,\nUNIT_COLOSSUS,\n)\n-from .data import Alliance, Attribute, CloakState, DisplayType, Race, TargetType, warpgate_abilities, TargetType, Target\n+from .data import (\n+ Alliance,\n+ Attribute,\n+ CloakState,\n+ DisplayType,\n+ Race,\n+ TargetType,\n+ warpgate_abilities,\n+ TargetType,\n+ Target,\n+ race_gas,\n+)\nfrom .ids.ability_id import AbilityId\nfrom .ids.buff_id import BuffId\nfrom .ids.upgrade_id import UpgradeId\n@@ -818,7 +829,7 @@ class Unit:\n:param queue: \"\"\"\nreturn self(self._bot_object._game_data.units[unit.value].creation_ability.id, queue=queue)\n- def build(self, unit: UnitTypeId, position: Union[Unit, Point2, Point3] = None, queue: bool = False) -> UnitCommand:\n+ def build(self, unit: UnitTypeId, position: Union[Point2, Point3] = None, queue: bool = False) -> UnitCommand:\n\"\"\" Orders unit to build another 'unit' at 'position'.\nUsage::\n@@ -830,8 +841,27 @@ class Unit:\n:param position:\n:param queue:\n\"\"\"\n+ # TODO: add asserts to make sure \"position\" is not a Point2 or Point3 if \"unit\" is extractor / refinery / assimilator\nreturn self(self._bot_object._game_data.units[unit.value].creation_ability.id, target=position, queue=queue)\n+ def build_gas(self, target_geysir: Unit, queue: bool = False) -> UnitCommand:\n+ \"\"\" Orders unit to build another 'unit' at 'position'.\n+ Usage::\n+\n+ # Target for refinery, assimilator and extractor needs to be the vespene geysir unit, not its position\n+ self.do(SCV.build_gas(target_vespene_geysir))\n+\n+ :param target_geysir:\n+ :param queue:\n+ \"\"\"\n+ # TODO: add asserts to make sure \"target_geysir\" is not a Point2 or Point3\n+ gas_structure_type_id: UnitTypeId = race_gas[self._bot_object.race]\n+ return self(\n+ self._bot_object._game_data.units[gas_structure_type_id.value].creation_ability.id,\n+ target=target_geysir,\n+ queue=queue,\n+ )\n+\ndef research(self, upgrade: UpgradeId, queue: bool = False) -> UnitCommand:\n\"\"\" Orders unit to research 'upgrade'.\nRequires UpgradeId to be passed instead of AbilityId.\n",
        "org_msg": "Add a \"build_gas\" function to unit.py",
        "sim_msg": "Removed filtering by pk, as defer_iteration breaks with querysets that already have an inequality filter. Replaced it with slicing",
        "sim_diff": "diff --git a/djangae/contrib/mappers/defer.py b/djangae/contrib/mappers/defer.py @@ -23,11 +23,10 @@ def _process_shard(model, instance_ids, callback):\nlogger.debug(\"Done processing shard.\")\n-def _shard(model, query, callback, shard_size, queue, offset_pk=1):\n+def _shard(model, query, callback, shard_size, queue, offset=0):\nlogger.debug(\"Sharding PKs for model %s into tasks on queue %s\", model.__name__, queue)\nkeys_queryset = model.objects.all()\nkeys_queryset.query = query\n- keys_queryset = keys_queryset.order_by(\"pk\")\nkeys_queryset = keys_queryset.values_list(\"pk\", flat=True)\n# Keep iterating until we are done, or until we might be hitting the task deadline\n@@ -35,7 +34,7 @@ def _shard(model, query, callback, shard_size, queue, offset_pk=1):\nmax_shards_to_defer_in_this_task = 250 # number which we think we can safely do in 10 minutes\nwhile True:\ntry:\n- ids = list(keys_queryset.filter(pk__gt=offset_pk)[:shard_size])\n+ ids = list(keys_queryset.all()[offset:offset + shard_size])\nif not ids:\n# We're done!\nlogger.debug(\n@@ -49,10 +48,10 @@ def _shard(model, query, callback, shard_size, queue, offset_pk=1):\nshards_deferred += 1\n# Set the offset to the last pk\n- offset_pk = ids[-1]\n+ offset += shard_size\nif shards_deferred >= max_shards_to_defer_in_this_task:\n- logger.debug(\"Redeferring. Offset PK: %s\", offset_pk)\n+ logger.debug(\"Redeferring. Offset PK: %s\", offset)\nraise Redefer()\nexcept (DeadlineExceededError, Redefer):\n@@ -65,7 +64,7 @@ def _shard(model, query, callback, shard_size, queue, offset_pk=1):\ncallback,\nshard_size,\nqueue,\n- offset_pk=offset_pk,\n+ offset=offset,\n_queue=queue\n)\nreturn\n@@ -88,5 +87,5 @@ def defer_iteration(queryset, callback, shard_size=500, _queue=\"default\", _targe\n# We immediately defer the _shard function so that we don't hold up execution\ndefer(\n_shard, queryset.model, queryset.query, callback, shard_size, _queue,\n- _queue=_queue, _target=_target\n+ _queue=_queue, _target=_target,\n)\n",
        "chatgpt_cot": "\"Fix the compilation issue and assert the position and target_geysir are not Point2 or Point3 when building and building gas.\""
    },
    {
        "org_diff": "diff --git a/fkie_multimaster_msgs/msg/MasterState.msg b/fkie_multimaster_msgs/msg/MasterState.msg string state\nfkie_multimaster_msgs/ROSMaster master\n-string STATE_NEW='new'\n-string STATE_REMOVED='removed'\n-string STATE_CHANGED='changed'\n+string STATE_NEW=new\n+string STATE_REMOVED=removed\n+string STATE_CHANGED=changed\n",
        "org_msg": "fix: adjust for ros msg standarts",
        "sim_msg": "and update messages.json...",
        "sim_diff": "diff --git a/messages.json b/messages.json \"1.0.3\": \"Messages/1.0.3.md\",\n\"1.1.0\": \"Messages/1.1.0.md\",\n\"1.2.0\": \"Messages/1.2.0.md\",\n- \"1.2.1\": \"Messages/1.2.1.md\"\n+ \"1.2.1\": \"Messages/1.2.1.md\",\n+ \"1.2.2\": \"Messages/1.2.1.md\"\n}\n",
        "chatgpt_cot": "Update MasterState.msg with new string values to fix compilation issue."
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/message_frame.py b/node_manager_fkie/src/node_manager_fkie/message_frame.py @@ -128,8 +128,8 @@ class MessageFrame(QFrame):\n3: QPixmap(':/icons/crystal_clear_launch_file.png').scaled(self.ICON_SIZE, self.ICON_SIZE, Qt.IgnoreAspectRatio, Qt.SmoothTransformation),\n4: QPixmap(\":/icons/default_cfg.png\").scaled(self.ICON_SIZE, self.ICON_SIZE, Qt.IgnoreAspectRatio, Qt.SmoothTransformation),\n5: QPixmap(\":/icons/crystal_clear_nodelet_q.png\").scaled(self.ICON_SIZE, self.ICON_SIZE, Qt.IgnoreAspectRatio, Qt.SmoothTransformation),\n- 6: QPixmap(\":/icons/crystal_clear_question.png\").scaled(self.ICON_SIZE, self.ICON_SIZE, Qt.IgnoreAspectRatio, Qt.SmoothTransformation),\n- 7: QPixmap(\":/icons/crystal_clear_launch_file_transfer.png\").scaled(self.ICON_SIZE, self.ICON_SIZE, Qt.IgnoreAspectRatio, Qt.SmoothTransformation),\n+ 6: QPixmap(\":/icons/crystal_clear_launch_file_transfer.png\").scaled(self.ICON_SIZE, self.ICON_SIZE, Qt.IgnoreAspectRatio, Qt.SmoothTransformation),\n+ 7: QPixmap(\":/icons/crystal_clear_question.png\").scaled(self.ICON_SIZE, self.ICON_SIZE, Qt.IgnoreAspectRatio, Qt.SmoothTransformation),\n8: QPixmap(\":/icons/crystal_clear_no_io.png\").scaled(self.ICON_SIZE, self.ICON_SIZE, Qt.IgnoreAspectRatio, Qt.SmoothTransformation)\n}\nself._new_request = False\n",
        "org_msg": "node_manager_fkie: fixed icon for transfer question",
        "sim_msg": "Python 3 compatibility and cosmetics",
        "sim_diff": "diff --git a/avalon/vendor/qtawesome/iconic_font.py b/avalon/vendor/qtawesome/iconic_font.py from __future__ import print_function\n-from ..Qt import QtCore, QtWidgets, QtGui\nimport json\nimport os\n-#from six import unichr\n+\n+from .. import six\n+from ..Qt import QtCore, QtGui\n_default_options = {\n@@ -74,7 +75,9 @@ class CharIconPainter:\npainter.setOpacity(options.get('opacity', 1.0))\n- painter.drawText(rect, QtCore.Qt.AlignCenter | QtCore.Qt.AlignVCenter, char)\n+ painter.drawText(rect,\n+ QtCore.Qt.AlignCenter | QtCore.Qt.AlignVCenter,\n+ char)\npainter.restore()\n@@ -95,7 +98,10 @@ class CharIconEngine(QtGui.QIconEngine):\ndef pixmap(self, size, mode, state):\npm = QtGui.QPixmap(size)\npm.fill(QtCore.Qt.transparent)\n- self.paint(QtGui.QPainter(pm), QtCore.QRect(QtCore.QPoint(0, 0), size), mode, state)\n+ self.paint(QtGui.QPainter(pm),\n+ QtCore.QRect(QtCore.QPoint(0, 0), size),\n+ mode,\n+ state)\nreturn pm\n@@ -122,7 +128,11 @@ class IconicFont(QtCore.QObject):\nfor fargs in args:\nself.load_font(*fargs)\n- def load_font(self, prefix, ttf_filename, charmap_filename, directory=None):\n+ def load_font(self,\n+ prefix,\n+ ttf_filename,\n+ charmap_filename,\n+ directory=None):\n\"\"\"Loads a font file and the associated charmap\nIf `directory` is None, the files will be looked up in ./fonts/\n@@ -142,7 +152,7 @@ class IconicFont(QtCore.QObject):\ndef hook(obj):\nresult = {}\nfor key in obj:\n- result[key] = unichr(int(obj[key], 16))\n+ result[key] = six.unichr(int(obj[key], 16))\nreturn result\nif directory is None:\n@@ -152,7 +162,8 @@ class IconicFont(QtCore.QObject):\nwith open(os.path.join(directory, charmap_filename), 'r') as codes:\nself.charmap[prefix] = json.load(codes, object_hook=hook)\n- id_ = QtGui.QFontDatabase.addApplicationFont(os.path.join(directory, ttf_filename))\n+ id_ = QtGui.QFontDatabase.addApplicationFont(\n+ os.path.join(directory, ttf_filename))\nloadedFontFamilies = QtGui.QFontDatabase.applicationFontFamilies(id_)\n",
        "chatgpt_cot": "Reorder icon loading in MessageFrame to fix visual inconsistency."
    },
    {
        "org_diff": "diff --git a/node_manager_daemon_fkie/src/node_manager_daemon_fkie/launcher.py b/node_manager_daemon_fkie/src/node_manager_daemon_fkie/launcher.py @@ -169,7 +169,7 @@ def run_node(startcfg):\n# set environment\nnew_env = dict(os.environ)\n# add environment from launch\n- new_env.extend(startcfg.env)\n+ new_env.update(startcfg.env)\nif startcfg.namespace:\nnew_env['ROS_NAMESPACE'] = startcfg.namespace\n# set logging\n",
        "org_msg": "node_manager_daemon_fkie: fixe env",
        "sim_msg": "retry startup",
        "sim_diff": "diff --git a/lbrynet/lbrynet_daemon/DaemonControl.py b/lbrynet/lbrynet_daemon/DaemonControl.py @@ -114,7 +114,7 @@ def update_settings_from_args(args):\n@defer.inlineCallbacks\n-def start_server_and_listen(launchui, use_auth, analytics_manager):\n+def start_server_and_listen(launchui, use_auth, analytics_manager, max_tries=5):\n\"\"\"The primary entry point for launching the daemon.\nArgs:\n@@ -124,13 +124,19 @@ def start_server_and_listen(launchui, use_auth, analytics_manager):\n\"\"\"\nanalytics_manager.send_server_startup()\nlog_support.configure_analytics_handler(analytics_manager)\n+ tries = 1\n+ while tries < max_tries:\n+ log.info('Making attempt %s / %s to startup', tries, max_tries)\ntry:\ndaemon_server = DaemonServer(analytics_manager)\nyield daemon_server.start(use_auth, launchui)\nanalytics_manager.send_server_startup_success()\n+ break\nexcept Exception as e:\nlog.exception('Failed to startup')\nanalytics_manager.send_server_startup_error(str(e))\n+ tries += 1\n+ else:\nreactor.callFromThread(reactor.stop)\n",
        "chatgpt_cot": "fix issue with environment setup in launcher file"
    },
    {
        "org_diff": "diff --git a/sc2/bot_ai.py b/sc2/bot_ai.py @@ -1056,10 +1056,12 @@ class BotAI(DistanceCalculation):\nworker_targets.add(Point2.from_proto(target))\nreturn self.structures.filter(\nlambda structure: structure.build_progress < 1\n- and structure.position not in worker_targets\n- and structure.tag not in worker_targets\n# Redundant check?\nand structure.type_id in TERRAN_STRUCTURES_REQUIRE_SCV\n+ and structure.position not in worker_targets\n+ and structure.tag not in worker_targets\n+ and structure.tag in self._structures_previous_map\n+ and self._structures_previous_map[structure.tag].build_progress == structure.build_progress\n)\nasync def build(\n@@ -1554,10 +1556,12 @@ class BotAI(DistanceCalculation):\nproto_game_info.game_info.start_raw.pathing_grid, in_bits=True, mirrored=False\n)\n# Required for events, needs to be before self.units are initialized so the old units are stored\n- self._units_previous_map: Dict = {unit.tag: unit for unit in self.units}\n- self._structures_previous_map: Dict = {structure.tag: structure for structure in self.structures}\n- self._enemy_units_previous_map: Dict = {unit.tag: unit for unit in self.enemy_units}\n- self._enemy_structures_previous_map: Dict = {structure.tag: structure for structure in self.enemy_structures}\n+ self._units_previous_map: Dict[int:Unit] = {unit.tag: unit for unit in self.units}\n+ self._structures_previous_map: Dict[int:Unit] = {structure.tag: structure for structure in self.structures}\n+ self._enemy_units_previous_map: Dict[int:Unit] = {unit.tag: unit for unit in self.enemy_units}\n+ self._enemy_structures_previous_map: Dict[int:Unit] = {\n+ structure.tag: structure for structure in self.enemy_structures\n+ }\nself._prepare_units()\nself.minerals: int = state.common.minerals\n",
        "org_msg": "Fix structures_without_construction_SCVs",
        "sim_msg": "Forgot to update iNumPlayers",
        "sim_diff": "diff --git a/v3/runner.py b/v3/runner.py @@ -63,6 +63,8 @@ if __name__ == '__main__':\ncallbacks = []\nname_dict = dict()\n+ gameInputPacket.iNumPlayers = num_bots\n+\n# Set configuration values for bots and store name and team\nfor i in range(num_bots):\nbot_config = configparser.RawConfigParser()\n",
        "chatgpt_cot": "Refactor unit and structure map initialization in BotAI for better type handling and readability."
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/settings.py b/node_manager_fkie/src/node_manager_fkie/settings.py @@ -135,7 +135,7 @@ class Settings(object):\nTIMEOUT_UPDATES = 20\nSEARCH_IN_EXT = ['.launch', '.yaml', '.conf', '.cfg', '.iface', '.nmprofile', '.sync', '.test', '.xml', '.xacro']\n- LAUNCH_VIEW_EXT = ['.launch', '.yaml', '.conf', '.cfg', '.iface', '.nmprofile', '.sync', '.test', '.xml', '.xacro']\n+ LAUNCH_VIEW_EXT = ['.launch', '.yaml', '.conf', '.cfg', '.iface', '.nmprofile', '.sync', '.test', '.xacro']\nSTORE_GEOMETRY = True\nMOVABLE_DOCK_WIDGETS = True\n",
        "org_msg": "node_manager_fkie: removed .xml files from default view in launch manager",
        "sim_msg": "additional cleanup and bugfix for Viv-specific docks.",
        "sim_diff": "diff --git a/vivisect/qt/main.py b/vivisect/qt/main.py @@ -231,8 +231,8 @@ class VQVivMainWindow(viv_base.VivEventDist, vq_app.VQMainCmdWindow):\ndwcls = settings.value('%s/DockClasses' % guid)\nstate = settings.value('%s/DockState' % guid)\ngeom = settings.value('%s/DockGeometry' % guid)\n+ basename = '%s/VQDockWidget%%d' % guid\n- # PyQt4 is very different here\nif compat_isNone(dwcls):\nnames = self.vw.filemeta.keys()\nnames.sort()\n@@ -240,17 +240,18 @@ class VQVivMainWindow(viv_base.VivEventDist, vq_app.VQMainCmdWindow):\ndwcls = settings.value('%s/DockClasses' % name)\nstate = settings.value('%s/DockState' % name)\ngeom = settings.value('%s/DockGeometry' % name)\n+ basename = '%s/VQDockWidget%%d' % name\nif compat_isNone(dwcls):\ndwcls = settings.value('DockClasses')\nstate = settings.value('DockState')\ngeom = settings.value('DockGeometry')\n+ basename = 'VQDockWidget%d'\nif not compat_isNone(dwcls):\n- print repr(dwcls)\nfor i, clsname in enumerate(compat_strList(dwcls)):\n- name = 'VQDockWidget%d' % i\n+ name = basename % i\ntry:\ntup = self.vqBuildDockWidget(str(clsname), floating=False)\nif tup != None:\n@@ -275,49 +276,6 @@ class VQVivMainWindow(viv_base.VivEventDist, vq_app.VQMainCmdWindow):\nreturn True\n- # or it's Qt5\n- if dwcls == None or not len(dwcls):\n- names = self.vw.filemeta.keys()\n- names.sort()\n- name = '+'.join(names)\n- dwcls = settings.value('%s/DockClasses' % name)\n- state = settings.value('%s/DockState' % name)\n- geom = settings.value('%s/DockGeometry' % name)\n-\n- if dwcls == None or not len(dwcls):\n- dwcls = settings.value('DockClasses')\n- state = settings.value('DockState')\n- geom = settings.value('DockGeometry')\n-\n-\n- if dwcls != None and len(dwcls):\n- for i, clsname in enumerate(dwcls):\n- name = 'VQDockWidget%d' % i\n- try:\n- #tup = self.vqBuildDockWidget(str(clsname)) # FIXME:, floating=True)\n- tup = self.vqBuildDockWidget(str(clsname), floating=True)\n- if tup != None:\n- d, obj = tup\n- d.setObjectName(name)\n- d.vqRestoreState(settings,name)\n- d.show()\n- except Exception, e:\n- print('Error Building: %s: %s' % (clsname,e))\n-\n- # Once dock widgets are loaded, we can restoreState\n- if not state == None:\n- self.restoreState(state)\n-\n- if not geom == None:\n- self.restoreGeometry(geom)\n-\n- # Just get all the resize activities done...\n- vq_main.eatevents()\n- for w in self.vqGetDockWidgets():\n- w.show()\n-\n- return True\n-\ndef vqSaveGuiSettings(self, settings):\ndock_classes = []\n",
        "chatgpt_cot": "Update LAUNCH_VIEW_EXT to exclude '.xml' file extension for launch view in Settings. Fixing file extension filter for launch views."
    },
    {
        "org_diff": "diff --git a/sc2/units.py b/sc2/units.py @@ -156,8 +156,8 @@ class Units(list):\ndef center(self):\n\"\"\" Returns the central point of all units in this list \"\"\"\nassert self.exists\n- pos = Point2((sum({unit.position.x for unit in self}) / self.amount, \\\n- sum({unit.position.y for unit in self}) / self.amount))\n+ pos = Point2((sum([unit.position.x for unit in self]) / self.amount, \\\n+ sum([unit.position.y for unit in self]) / self.amount))\nreturn pos\n@property\n",
        "org_msg": "Fix center property",
        "sim_msg": "fix for value_and_unit",
        "sim_diff": "diff --git a/apps/projects/models.py b/apps/projects/models.py @@ -261,6 +261,6 @@ class Value(Model):\nvalue = self.value\nif self.attribute.unit:\n- return str(value) + ' ' + self.attribute.unit\n+ return '%s %s' % (value, self.attribute.unit)\nelse:\nreturn value\n",
        "chatgpt_cot": "fix calculation of central point in Units class"
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/nodes/script_runner.py b/node_manager_fkie/nodes/script_runner.py @@ -104,10 +104,14 @@ class RunThread(threading.Thread):\n'''\nthreading.Thread.__init__(self)\nself._script = script\n- self._cmd = shlex.split(script)\n- if self._cmd[0].startswith(\"pkg://\"):\n- resolved = resolve_url(self._cmd.pop(0))\n- self._cmd.insert(0, resolved)\n+ cmd_list = shlex.split(script)\n+ self._cmd = []\n+ for cmd in cmd_list:\n+ if cmd.startswith(\"pkg://\"):\n+ resolved = resolve_url(cmd)\n+ self._cmd.append(resolved)\n+ else:\n+ self._cmd.append(cmd)\nself.setDaemon(True)\nself.spopen = None\nself.stop = False\n",
        "org_msg": "node_manager_fkie: resolve pkg:// in all arguments",
        "sim_msg": "Runner path uses only the last part of the path",
        "sim_diff": "diff --git a/src/app/beer_garden/local_plugins/runner.py b/src/app/beer_garden/local_plugins/runner.py @@ -146,7 +146,7 @@ class ProcessRunner(Thread):\nreturn {\n\"runner_name\": self.runner_name,\n\"runner_id\": self.runner_id,\n- \"runner_path\": str(self.process_cwd),\n+ \"runner_path\": self.process_cwd.name,\n\"instance_id\": self.instance_id,\n\"restart\": self.restart,\n\"stopped\": self.stopped,\n",
        "chatgpt_cot": "\"Refactor script_runner to handle pkg:// paths properly\""
    },
    {
        "org_diff": "diff --git a/src/agent/docker-rest-agent/server.py b/src/agent/docker-rest-agent/server.py @@ -43,7 +43,8 @@ def create_node():\nport_map = ast.literal_eval(request.form.get(\"port_map\"))\nvolumes = [\n'/var/run/:/host/var/run/',\n- '/opt/fabric/{}/msp:/etc/hyperledger/fabric/msp'.format(node_name),\n+ '/opt/fabric/{}:/etc/hyperledger/fabric'.format(node_name),\n+ '/opt/production/{}:/var/hyperledger/production'.format(node_name)\n]\nif request.form.get('type') == \"peer\":\npeer_envs = {\n@@ -65,11 +66,6 @@ def create_node():\n'CORE_OPERATIONS_LISTENADDRESS': '0.0.0.0:17051'\n}\nenv.update(peer_envs)\n- volumes.extend([\n- #'/opt/fabric/{}/core.yaml:/etc/hyperledger/fabric/core.yaml'.format(node_name),\n- '/opt/fabric/{}/chaincodes:/var/hyperledger/fabric/production/chaincodes'.format(node_name),\n- '/opt/fabric/{}/ledgersData:/var/hyperledger/fabric/production/ledgersData'.format(node_name)\n- ])\nelse:\norder_envs = {\n'FABRIC_LOGGING_SPEC':'DEBUG',\n@@ -87,11 +83,6 @@ def create_node():\n'ORDERER_GENERAL_CLUSTER_ROOTCAS': '[/etc/hyperledger/fabric/tls/ca.crt]',\n}\nenv.update(order_envs)\n- volumes.extend([\n- #'/opt/fabric/{}/orderer.yaml:/etc/hyperledger/fabric/orderer.yaml'.format(node_name),\n- '/opt/fabric/{}/orderer:/var/hyperledger/fabric/production/orderer'.format(node_name)\n- ])\n-\ntry:\n# same as `docker run -dit yeasy/hyperledge-fabric:2.2.0 -e VARIABLES``\ncontainer = client.containers.run(\n",
        "org_msg": "Fix voulume mapping\nMapping the whole folder instead of single files.",
        "sim_msg": "Add node config init to postinstall\nProblem: Node snapshot import by default assumes that the node directory\ntargets mainnet, thus it's not possible to import testnet snapshot to\nthe empty node data directory.\nSolution: Add `tezos-node config init` calls for all non-custom network\nservices to the postinstallation stage.",
        "sim_diff": "diff --git a/docker/package/packages.py b/docker/package/packages.py @@ -112,7 +112,10 @@ common_node_env = [\"NODE_RPC_ADDR=127.0.0.1:8732\", \"CERT_PATH=\", \"KEY_PATH=\"]\nfor network in networks:\nenv = [f\"DATA_DIR=/var/lib/tezos/node-{network}\", f\"NETWORK={network}\"] + common_node_env\nnode_units.append(mk_node_unit(suffix=network, env=env, desc=f\"Tezos node {network}\"))\n- node_postinst_steps += f\"mkdir -p /var/lib/tezos/node-{network}\\n\"\n+ node_postinst_steps += f'''mkdir -p /var/lib/tezos/node-{network}\n+[ ! -f /var/lib/tezos/node-{network}/config.json ] && tezos-node config init --data-dir /var/lib/tezos/node-{network} --network {network}\n+chown -R tezos:tezos /var/lib/tezos/node-{network}\n+'''\n# Add custom config service\nnode_units.append(mk_node_unit(suffix=\"custom\", env=[\"DATA_DIR=/var/lib/tezos/node-custom\",\n",
        "chatgpt_cot": "Refactor volume paths in create_node() for better organization and readability in server.py."
    },
    {
        "org_diff": "diff --git a/sc2/bot_ai.py b/sc2/bot_ai.py @@ -213,6 +213,32 @@ class BotAI(object):\nreturn CanAffordWrapper(cost.minerals <= self.minerals, cost.vespene <= self.vespene)\n+ async def can_cast(self, unit, ability_id, target=None, only_check_energy_and_cooldown=False, cached_abilities_of_unit=None):\n+ \"\"\"Tests if a unit has an ability available and enough energy to cast it.\n+ See data_pb2.py (line 161) for the numbers 1-5 to make sense\"\"\"\n+ assert isinstance(unit, Unit)\n+ assert isinstance(ability_id, AbilityId)\n+ assert isinstance(target, (type(None), Unit, Point2, Point3))\n+ # check if unit has enough energy to cast or if ability is on cooldown\n+ if cached_abilities_of_unit:\n+ abilities = cached_abilities_of_unit\n+ else:\n+ abilities = await self.get_available_abilities(unit)\n+\n+ if ability_id in abilities:\n+ if only_check_energy_and_cooldown:\n+ return True\n+ cast_range = self._game_data.abilities[ability_id.value]._proto.cast_range\n+ ability_target = self._game_data.abilities[ability_id.value]._proto.target\n+ # check if target is in range (or is a self cast like stimpack)\n+ if ability_target == 1 or ability_target == 5 and isinstance(target, (Point2, Point3)) and unit.distance_to(target) <= cast_range: # TODO: replace numbers with enums\n+ return True\n+ elif ability_target in [3, 4] and isinstance(target, Unit) and unit.distance_to(target) <= cast_range:\n+ return True\n+ elif ability_target in [2, 4] and isinstance(target, (Point2, Point3)) and unit.distance_to(target) <= cast_range:\n+ return True\n+ return False\n+\ndef select_build_worker(self, pos, force=False):\n\"\"\"Select a worker to build a bulding with.\"\"\"\n",
        "org_msg": "Add check if unit can cast an ability - energy cost and ability range",
        "sim_msg": "implement aea.helpers.search.models.ConstraintType.is_valid",
        "sim_diff": "diff --git a/aea/helpers/search/models.py b/aea/helpers/search/models.py @@ -381,28 +381,22 @@ class ConstraintType:\n:param attribute: the data model used to check the validity of the constraint type.\n:return: ``True`` if the constraint type is valid wrt the attribute, ``False`` otherwise.\n\"\"\"\n- if self.type == ConstraintTypes.EQUAL:\n- return True\n- elif self.type == ConstraintTypes.NOT_EQUAL:\n- return True\n- elif self.type == ConstraintTypes.LESS_THAN:\n- return True\n- elif self.type == ConstraintTypes.LESS_THAN_EQ:\n- return True\n- elif self.type == ConstraintTypes.GREATER_THAN:\n- return True\n- elif self.type == ConstraintTypes.GREATER_THAN_EQ:\n- return True\n- elif self.type == ConstraintTypes.WITHIN:\n- return True\n- elif self.type == ConstraintTypes.IN:\n- return True\n- elif self.type == ConstraintTypes.NOT_IN:\n- return True\n- elif self.type == ConstraintTypes.DISTANCE:\n- return attribute.type == Location\n+ return self.get_data_type() == attribute.type\n+\n+ def get_data_type(self) -> ATTRIBUTE_TYPES:\n+ \"\"\"\n+ Get the type of the data used to define the constraint type.\n+\n+ For instance:\n+ >>> c = ConstraintType(ConstraintTypes.EQUAL, 1)\n+ >>> c.get_data_type()\n+ <class 'int'>\n+\n+ \"\"\"\n+ if isinstance(self.value, (list, tuple, set)):\n+ return type(self.value[0])\nelse:\n- raise ValueError(\"Constraint type not recognized.\")\n+ return type(self.value)\ndef check(self, value: ATTRIBUTE_TYPES) -> bool:\n\"\"\"\n",
        "chatgpt_cot": "Add async method to test if a unit has an ability available and enough energy to cast it, to the BotAI class."
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/launch_config.py b/node_manager_fkie/src/node_manager_fkie/launch_config.py @@ -248,7 +248,7 @@ class LaunchConfig(QObject):\nresult.append(path)\next = os.path.splitext(path)\nif recursive and ext[1] in nm.settings().SEARCH_IN_EXT:\n- result += cls.included_files(path, regexp_filelist)\n+ result += cls.included_files(path, regexp_retruns, regexp_filelist)\nexcept Exception:\nimport traceback\nprint traceback.format_exc()\n",
        "org_msg": "node_manager_fkie: fixed trasfer of wrong files on change to remote hosts",
        "sim_msg": "fix for --collections",
        "sim_diff": "diff --git a/modules/config.py b/modules/config.py @@ -434,7 +434,7 @@ class Config:\nexcept Failed as e: logger.error(e)\nlogger.info(\"\")\nutil.seperator(\"{} Library {}Collections\".format(library.name, \"Test \" if test else \"\"))\n- collections = (library.collections.keys() & util.get_list(requested_collections)) if requested_collections else library.collections\n+ collections = {c: library.collections[c] for c in util.get_list(requested_collections) if c in library.collections} if requested_collections else library.collections\nif collections:\nlogger.info(\"\")\nutil.seperator(\"Mapping {} Library\".format(library.name))\n",
        "chatgpt_cot": "Add new parameter to included_files method in LaunchConfig to handle additional regular expression for file returns. Fix potential issue with recursive file search."
    },
    {
        "org_diff": "diff --git a/rasa_core_sdk/forms.py b/rasa_core_sdk/forms.py @@ -72,7 +72,7 @@ class FormAction(Action):\nelse:\nreturn [FormIsBack()]\nelse:\n- return [FormActivated(self.name())]\n+ return [FormActivated(self.name()), FormIsBack()]\ndef run(self, dispatcher, tracker, domain):\n@@ -87,9 +87,7 @@ class FormAction(Action):\nfor slot in self.required_slots():\nif self.should_request_slot(temp_tracker, slot):\n- dispatcher.utter_template(\n- \"utter_ask_{}\".format(slot),\n- tracker)\n+ dispatcher.utter_template(\"utter_ask_{}\".format(slot), tracker)\nevents.append(SlotSet(REQUESTED_SLOT, slot))\n",
        "org_msg": "add FormIsBack event to first call as well",
        "sim_msg": "Fix -- fix search page\nThe form on the search page didn't work, because it used POST instead of GET.",
        "sim_diff": "diff --git a/workshops/forms.py b/workshops/forms.py @@ -322,7 +322,10 @@ class SearchForm(forms.Form):\nrequired=False,\ninitial=True)\n- helper = BootstrapHelper(add_cancel_button=False)\n+ helper = BootstrapHelper(\n+ add_cancel_button=False,\n+ use_get_method=True,\n+ )\nclass DebriefForm(forms.Form):\n",
        "chatgpt_cot": "Fix FormAction method to return correct events and utter template formatting for better functionality."
    },
    {
        "org_diff": "diff --git a/sc2/player.py b/sc2/player.py @@ -44,6 +44,8 @@ class Observer(AbstractPlayer):\nclass Player(AbstractPlayer):\n@classmethod\ndef from_proto(cls, proto):\n+ if PlayerType(proto.type) == PlayerType.Observer:\n+ return cls(proto.player_id, PlayerType(proto.type), None, None, None)\nreturn cls(\nproto.player_id,\nPlayerType(proto.type),\n",
        "org_msg": "Fix an issue when joining as observer",
        "sim_msg": "Use `mode.value` instead enumerate.",
        "sim_diff": "diff --git a/app/objects/player.py b/app/objects/player.py @@ -536,14 +536,14 @@ class Player:\nasync with app.state.services.database.connection() as db_conn:\nawait self.stats_from_sql_full(db_conn)\n- for idx, mode_stat in enumerate(self.stats.values()):\n+ for mode, stats in self.stats.items():\nawait app.state.services.redis.zadd(\n- f\"gulag:leaderboard:{idx}\",\n- {self.id: mode_stat.pp},\n+ f\"gulag:leaderboard:{mode.value}\",\n+ {self.id: stats.pp},\n)\nawait app.state.services.redis.zadd(\n- f\"gulag:leaderboard:{idx}:{self.geoloc['country']['acronym']}\",\n- {self.id: mode_stat.pp},\n+ f\"gulag:leaderboard:{mode.value}:{self.geoloc['country']['acronym']}\",\n+ {self.id: stats.pp},\n)\nif \"restricted\" in self.__dict__:\n",
        "chatgpt_cot": "Add handling for Observer player type in Player class from_proto method."
    },
    {
        "org_diff": "diff --git a/dockerfiles/test_docker_image.sh b/dockerfiles/test_docker_image.sh @@ -9,7 +9,7 @@ export SC2_VERSION=${SC2_VERSION:-4.10}\n# For better readability, set local variables\nIMAGE_NAME=burnysc2/python-sc2-docker:local\n-BUILD_ARGS=--build-arg PYTHON_VERSION=$PYTHON_VERSION --build-arg SC2_VERSION=$SC2_VERSION\n+BUILD_ARGS=\"--build-arg PYTHON_VERSION=$PYTHON_VERSION --build-arg SC2_VERSION=$SC2_VERSION\"\n# Allow image squashing by enabling experimental docker features\n# https://stackoverflow.com/a/21164441/10882657\n",
        "org_msg": "Fix BUILD_ARGS",
        "sim_msg": "tests: add perl-JSON to the test images too.\nNeeded for the runner tests.",
        "sim_diff": "diff --git a/tests/build_docker_images.py b/tests/build_docker_images.py @@ -15,14 +15,16 @@ DEBIAN_DOCKERFILE = r\"\"\"\nFROM debian:stable\nRUN apt-get update\nRUN \\\n- apt-get install -y python2.7 openssh-server sudo rsync git strace && \\\n+ apt-get install -y python2.7 openssh-server sudo rsync git strace \\\n+ libjson-perl && \\\napt-get clean\n\"\"\"\nCENTOS_DOCKERFILE = r\"\"\"\nFROM centos:7\nRUN yum clean all && \\\n- yum -y install -y python2.7 openssh-server sudo rsync git strace sudo && \\\n+ yum -y install -y python2.7 openssh-server sudo rsync git strace sudo \\\n+ perl-JSON && \\\nyum clean all && \\\ngroupadd sudo && \\\nssh-keygen -t rsa -f /etc/ssh/ssh_host_rsa_key\n",
        "chatgpt_cot": "Update BUILD_ARGS variable to include quotes for better readability and fix syntax issue in test_docker_image.sh script."
    },
    {
        "org_diff": "diff --git a/sc2/protocol.py b/sc2/protocol.py @@ -41,7 +41,7 @@ class Protocol:\nexcept TypeError:\n# logger.exception(\"Cannot receive: Connection already closed.\")\n# raise ConnectionAlreadyClosed(\"Connection already closed.\")\n- logger.log(\"Cannot receive: Connection already closed.\")\n+ logger.info(\"Cannot receive: Connection already closed.\")\nsys.exit(2)\nexcept asyncio.CancelledError:\n# If request is sent, the response must be received before reraising cancel\n",
        "org_msg": "Change logger to info",
        "sim_msg": "use only the main session, dont cancel on connectionerror",
        "sim_diff": "diff --git a/torba/torba/client/basenetwork.py b/torba/torba/client/basenetwork.py @@ -78,7 +78,7 @@ class ClientSession(BaseClientSession):\nexcept ConnectionError:\nlog.warning(\"connection to %s:%i lost\", *self.server)\nself.synchronous_close()\n- raise asyncio.CancelledError(f\"connection to {self.server[0]}:{self.server[1]} lost\")\n+ raise\nexcept asyncio.TimeoutError:\nlog.info(\"timeout sending %s to %s:%i\", method, *self.server)\nraise\n@@ -203,8 +203,10 @@ class BaseNetwork:\nreturn self.client and not self.client.is_closing()\ndef rpc(self, list_or_method, args, session=None):\n- session = session or self.session_pool.fastest_session\n- if session:\n+ # fixme: use fastest unloaded session, but for now it causes issues with wallet sync\n+ # session = session or self.session_pool.fastest_session\n+ session = self.client\n+ if session and not session.is_closing():\nreturn session.send_request(list_or_method, args)\nelse:\nself.session_pool.trigger_nodelay_connect()\n",
        "chatgpt_cot": "Fix logger method in Protocol class to use info instead of log for \"Connection already closed\" message."
    },
    {
        "org_diff": "diff --git a/src/agent/ansible/roles/env_k8s/worker/tasks/apply.yml b/src/agent/ansible/roles/env_k8s/worker/tasks/apply.yml dest: \"~/.kube/config\"\nmode: 0600\n+- name: Setup kubeconfig for each node\n+ template:\n+ src: \"{{ playbook_dir }}/../env_k8s/worker/templates/kubeconfig.j2\"\n+ dest: \"/etc/kubernetes/kubeconfig\"\n+ mode: 0600\n+\n+- name: Check kubelet version\n+ command: \"{{ fabricroot }}/bin/kubelet --version\"\n+ register: kubeversion\n+\n- name: Setup worker node service variables\nset_fact:\nkubelet_params: >-\n- --api-servers={{ private_ip }}:8080\n+ --cloud-provider=''\n+ --kubeconfig=/etc/kubernetes/kubeconfig\n+ --require-kubeconfig\n--container-runtime=docker\n--cluster-dns={{ cluster.dns_service_ip }}\n--cluster-domain={{ cluster.domain }}\n--master={{ private_ip }}:8080\n--cluster-cidr={{ cluster.container_network.Network }}\n+- name: Setup worker node service variables\n+ set_fact:\n+ kubelet_params: \"{{ kubelet_params }} --fail-swap-on=false\"\n+ when: kubeversion.stdout | search('v1.8.')\n+\n- name: Configure the worker node services\ntemplate:\nsrc: \"{{ playbook_dir }}/../env_k8s/worker/templates/k8s.conf.j2\"\n",
        "org_msg": "add kubernetes 1.8.x support\nCurrently the ansible agent only supports k8s 1.7.x releases\nthis patch set will add the support for releases 1.8.3 which\nis the latest k8s release up to date.",
        "sim_msg": "Use state \"present\" instead of \"installed\"\nThe latter is deprecated and due to be removed in Ansible v2.9.",
        "sim_diff": "diff --git a/ansible/roles/setup/tasks/main.yml b/ansible/roles/setup/tasks/main.yml become: yes\napt:\npkg: apt-transport-https\n- state: installed\n+ state: present\n- name: Add NodeSource apt signing key\nbecome: yes\nbecome: yes\napt:\npkg: \"{{ item }}\"\n- state: installed\n+ state: present\nwith_items:\n- apt-transport-https\n- ca-certificates\nbecome: yes\napt:\npkg: \"{{item}}\"\n- state: installed\n+ state: present\nwith_items:\n- nodejs\nbecome: yes\napt:\npkg: \"{{ item }}\"\n- state: installed\n+ state: present\nwith_items:\n- postgresql-9.5-postgis-2.2\n- postgresql-server-dev-9.5 # required for building pyscopg against correct postgres\n",
        "chatgpt_cot": "\"Add kubelet config, set cloud provider to empty, and disable swap for worker nodes in Kubernetes role for version 1.8 compatibility.\""
    },
    {
        "org_diff": "diff --git a/MAINTAINERS.md b/MAINTAINERS.md ## Maintainers\n-| Name | GitHub | RocketChat | Email |\n-|---|---|---|---|\n-| Baohua Yang | yeasy | baohua | yangbaohua@gmail.com |\n-| Yang Feng | fengyangsy | fengyangsy | fengyang.09186@h3c.com |\n-| Yuanmao Zhu | zhuyuanmao | | yuanmao@ualberta.ca |\n+| Name | GitHub | Email |\n+|---|---|---|\n+| Baohua Yang | yeasy | yangbaohua@gmail.com |\n+| Yang Feng | fengyangsy | fengyang.09186@h3c.com |\n+| Yuanmao Zhu | zhuyuanmao | yuanmao@ualberta.ca |\n## Retired Maintainers\n-| Name | GitHub | RocketChat | Email |\n-|---|---|---|---|\n-| Luke Chen | LordGoodman | luke_chen | jiahaochen1993@gmail.com |\n-| Tong Li | tongli | tongli | litong01@us.ibm.com |\n-| Haitao Yue | hightall | hightall | hightallyht@gmail.com |\n-| Qiang Xu | XuHugo | XuHugo | xq-310@163.com |\n+| Name | GitHub | Email |\n+|---|---|---|\n+| Luke Chen | LordGoodman | jiahaochen1993@gmail.com |\n+| Tong Li | tongli | litong01@us.ibm.com |\n+| Haitao Yue | hightall | hightallyht@gmail.com |\n+| Qiang Xu | XuHugo | xq-310@163.com |\n<a rel=\"license\" href=\"http://creativecommons.org/licenses/by/4.0/\"><img alt=\"Creative Commons License\" style=\"border-width:0\" src=\"https://i.creativecommons.org/l/by/4.0/88x31.png\" /></a><br />This work is licensed under a <a rel=\"license\" href=\"http://creativecommons.org/licenses/by/4.0/\">Creative Commons Attribution 4.0 International License</a>.\n",
        "org_msg": "Remove RocketChat",
        "sim_msg": "Remove as a maintainer. :( :(",
        "sim_diff": "diff --git a/MAINTAINERS.md b/MAINTAINERS.md @@ -9,7 +9,6 @@ Maintainers are listed in alphabetical order.\n| Maintainer | GitHub ID | Affiliation |\n| ---------------- | --------------------------------------------- | --------------------------------------------------- |\n-| Aidan Hahn | [aidanhahn](https://github.com/aidanhahn) | unaffiliated |\n| Alex Gervais | [alexgervais](https://github.com/alexgervais) | [Ambassador Labs](https://www.github.com/datawire/) |\n| Alice Wasko | [aliceproxy](https://github.com/aliceproxy) | [Ambassador Labs](https://www.github.com/datawire/) |\n| Flynn | [kflynn](https://github.com/kflynn) | [Buoyant](https://www.buoyant.io) |\n@@ -28,6 +27,7 @@ of the following (also listed in alphabetical order):\n## Maintainers Emeriti\n+* Aidan Hahn ([aidanhahn](https://github.com/aidanhahn))\n* Alix Cook ([acookin](https://github.com/acookin))\n* John Esmet ([esmet](https://github.com/esmet))\n",
        "chatgpt_cot": "Update MAINTAINERS.md to remove RocketChat column and adjust email format for consistency."
    },
    {
        "org_diff": "diff --git a/.github/workflows/docker-ci.yml b/.github/workflows/docker-ci.yml @@ -36,9 +36,9 @@ jobs:\n- name: Run shell script\nenv:\n- VERSION_NUMBER: $VERSION_NUMBER\n- PYTHON_VERSION: $LATEST_PYTHON_VERSION\n- SC2_VERSION: $LATEST_SC2_VERSION\n+ VERSION_NUMBER: ${{ env.VERSION_NUMBER }}\n+ PYTHON_VERSION: ${{ env.LATEST_PYTHON_VERSION }}\n+ SC2_VERSION: ${{ env.LATEST_SC2_VERSION }}\nrun: |\nsh dockerfiles/test_docker_image.sh\n",
        "org_msg": "Fix curly braces around global env variables",
        "sim_msg": "Use stomp docker file",
        "sim_diff": "diff --git a/.github/workflows/integration-actions.yml b/.github/workflows/integration-actions.yml @@ -276,7 +276,7 @@ jobs:\npython-version: ${{ matrix.python-version }}\n- name: Update Docker Compose\n- run: cp test/conf/docker-compose.yml docker/docker-compose/docker-compose.yml\n+ run: cp test/conf/docker-compose-stomp.yml docker/docker-compose/docker-compose.yml\nworking-directory: ./\n- name: Checkout Local Plugins\n",
        "chatgpt_cot": "Update environment variables in docker-ci workflow to use dynamic values from environment, ensuring consistency and flexibility in the CI process."
    },
    {
        "org_diff": "diff --git a/test/test_pickled_data.py b/test/test_pickled_data.py @@ -109,7 +109,7 @@ class TestClass:\nassert bot.townhalls.random.position not in bot.enemy_start_locations\nassert bot.known_enemy_units == Units([])\nassert bot.known_enemy_structures == Units([])\n- bot._game_info.map_ramps = bot._game_info._find_ramps()\n+ bot._game_info.map_ramps, bot._game_info.vision_blockers = bot._game_info._find_ramps_and_vision_blockers()\nassert bot.main_base_ramp # Test if any ramp was found\n# TODO: Cache all expansion positions for a map and check if it is the same\nassert len(bot.expansion_locations) >= 12\n",
        "org_msg": "Fix tests for new ramps and vision blocker function",
        "sim_msg": "Fix data_misfit test",
        "sim_diff": "diff --git a/tests/base/test_data.py b/tests/base/test_data.py @@ -49,7 +49,10 @@ class DataTest(unittest.TestCase):\nself.assertTrue(\nnp.allclose(\ndata.standard_deviation,\n- relative * np.abs(self.dobs) + floor * np.ones(len(self.dobs)),\n+ np.sqrt(\n+ ( relative * np.abs(self.dobs) ) ** 2 +\n+ floor ** 2 * np.ones(len(self.dobs)),\n+ )\n)\n)\n",
        "chatgpt_cot": "\"Add vision blockers to map_ramps in TestClass to improve map vision and caching expansion positions for a map.\""
    },
    {
        "org_diff": "diff --git a/scripts/master_node/download_images.sh b/scripts/master_node/download_images.sh @@ -34,7 +34,7 @@ echo_b \"Check node:9.2 image.\"\n# docker image\n-for IMG in baseimage engine mongo operator-dashboard user-dashboard watchdog parse-server ; do\n+for IMG in dashboard nginx api-engine; do\nHLC_IMG=hyperledger/cello-${IMG}\n#if [ -z \"$(docker images -q ${HLC_IMG}:${ARCH}-${VERSION} 2> /dev/null)\" ]; then # not exist\necho_b \"Pulling ${HLC_IMG}:${ARCH}-${VERSION} from dockerhub\"\n",
        "org_msg": "[Fix Remove unused images download operation\nAdd api-engine/nginx/dashboard images download.",
        "sim_msg": "Add jujud-operator 2.9.3 to static container images",
        "sim_diff": "diff --git a/container-images.txt b/container-images.txt -ci-static: docker.io/diverdane/nginxdualstack:1.0.0 docker.io/library/busybox:1.32 docker.io/library/nginx:1.18 docker.io/library/ubuntu:focal docker.io/jujusolutions/juju-db:4.0 docker.io/jujusolutions/juju-db:4.4 docker.io/jujusolutions/jujud-operator:2.8.6 docker.io/jujusolutions/jujud-operator:2.8.7 docker.io/jujusolutions/jujud-operator:2.8.8 docker.io/jujusolutions/jujud-operator:2.8.9 docker.io/jujusolutions/jujud-operator:2.8.10 docker.io/jujusolutions/jujud-operator:2.8.11 docker.io/jujusolutions/jujud-operator:2.9.0 docker.io/jujusolutions/jujud-operator:2.9.1 docker.io/sonobuoy/sonobuoy:v0.20.0 docker.io/sonobuoy/sonobuoy:v0.50.0 gcr.io/google-samples/node-hello:1.0 us.gcr.io/k8s-artifacts-prod/conformance:v1.21.0 docker.io/jujusolutions/charm-base:ubuntu-20.04\n+ci-static: docker.io/diverdane/nginxdualstack:1.0.0 docker.io/library/busybox:1.32 docker.io/library/nginx:1.18 docker.io/library/ubuntu:focal docker.io/jujusolutions/juju-db:4.0 docker.io/jujusolutions/juju-db:4.4 docker.io/jujusolutions/jujud-operator:2.8.6 docker.io/jujusolutions/jujud-operator:2.8.7 docker.io/jujusolutions/jujud-operator:2.8.8 docker.io/jujusolutions/jujud-operator:2.8.9 docker.io/jujusolutions/jujud-operator:2.8.10 docker.io/jujusolutions/jujud-operator:2.8.11 docker.io/jujusolutions/jujud-operator:2.9.0 docker.io/jujusolutions/jujud-operator:2.9.1 docker.io/jujusolutions/jujud-operator:2.9.3 docker.io/sonobuoy/sonobuoy:v0.20.0 docker.io/sonobuoy/sonobuoy:v0.50.0 gcr.io/google-samples/node-hello:1.0 us.gcr.io/k8s-artifacts-prod/conformance:v1.21.0 docker.io/jujusolutions/charm-base:ubuntu-20.04\nv1.12-static: k8s.gcr.io/defaultbackend-amd64:1.5 k8s.gcr.io/defaultbackend-arm64:1.5 k8s.gcr.io/defaultbackend-s390x:1.4 k8s.gcr.io/pause-{{ arch }}:3.1 quay.io/kubernetes-ingress-controller/nginx-ingress-controller-{{ arch }}:0.16.1 quay.io/calico/node:v2.6.10 quay.io/calico/kube-controllers:v1.0.4 sonatype/nexus3:latest rancher/rancher:latest\nv1.12.8-upstream: k8s.gcr.io/addon-resizer:1.8.2 k8s.gcr.io/addon-resizer:1.8.3 k8s.gcr.io/heapster-grafana-s390x:v4.4.3 k8s.gcr.io/heapster-influxdb-s390x:v1.3.3 k8s.gcr.io/heapster-s390x:v1.6.0-beta.1 k8s.gcr.io/k8s-dns-dnsmasq-nanny:1.14.13 k8s.gcr.io/k8s-dns-kube-dns:1.14.13 k8s.gcr.io/k8s-dns-sidecar:1.14.13 k8s.gcr.io/kubernetes-dashboard-s390x:v1.10.1 k8s.gcr.io/metrics-server-s390x:v0.3.1\nv1.13-static: k8s.gcr.io/defaultbackend-amd64:1.5 k8s.gcr.io/defaultbackend-arm64:1.5 k8s.gcr.io/defaultbackend-s390x:1.4 k8s.gcr.io/pause-{{ arch }}:3.1 quay.io/kubernetes-ingress-controller/nginx-ingress-controller-amd64:0.21.0 quay.io/kubernetes-ingress-controller/nginx-ingress-controller-arm64:0.21.0 quay.io/kubernetes-ingress-controller/nginx-ingress-controller-s390x:0.20.0 quay.io/calico/node:v2.6.12 quay.io/calico/kube-controllers:v1.0.5 sonatype/nexus3:latest rancher/rancher:latest\n",
        "chatgpt_cot": "Refactor image download script to pull dashboard, nginx, and api-engine images. Streamline image pulling process for master node setup."
    },
    {
        "org_diff": "diff --git a/sc2/bot_ai.py b/sc2/bot_ai.py @@ -628,10 +628,15 @@ class BotAI(DistanceCalculation):\n:param check_supply_cost: \"\"\"\nenough_supply = True\ncost = self.calculate_cost(item_id)\n- if check_supply_cost and isinstance(item_id, UnitTypeId):\n- calculated_supply_cost = self.calculate_supply_cost(item_id)\n- enough_supply = not calculated_supply_cost or self.supply_left >= calculated_supply_cost\n- return cost.minerals <= self.minerals and cost.vespene <= self.vespene and enough_supply\n+ if not cost.minerals > self.minerals or cost.vespene > self.vespene:\n+ return False\n+ if (\n+ check_supply_cost\n+ and isinstance(item_id, UnitTypeId)\n+ and self.calculate_supply_cost(item_id) > self.supply_left\n+ ):\n+ return False\n+ return True\nasync def can_cast(\nself,\n",
        "org_msg": "Short cut can_afford",
        "sim_msg": "Fixes based on the PR comments",
        "sim_diff": "diff --git a/packages/fetchai/skills/tac_control_contract/game.py b/packages/fetchai/skills/tac_control_contract/game.py @@ -889,7 +889,7 @@ class Game(Model):\n+ \"\\n\"\n)\nfor good_id, quantity in agent_state.quantities_by_good_id.items():\n- result += \" \" + str(good_id) + \": \" + str(quantity) + \"\\n\"\n+ result += \" \" + good_id + \": \" + str(quantity) + \"\\n\"\nfor currency_id, amount in agent_state.amount_by_currency_id.items():\nresult += \" \" + currency_id + \": \" + str(amount) + \"\\n\"\nresult += \" score: \" + str(round(agent_state.get_score(), 2)) + \"\\n\"\n@@ -901,7 +901,7 @@ class Game(Model):\n\"\"\"Get equilibrium summary.\"\"\"\nresult = \"\\n\" + \"Equilibrium prices: \\n\"\nfor good_id, eq_price in self.initialization.good_id_to_eq_prices.items():\n- result = result + str(good_id) + \" \" + str(eq_price) + \"\\n\"\n+ result = result + good_id + \" \" + str(eq_price) + \"\\n\"\nresult = result + \"\\n\"\nresult = result + \"Equilibrium good allocation: \\n\"\nfor (\n@@ -915,7 +915,7 @@ class Game(Model):\n+ \":\\n\"\n)\nfor good_id, quantity in eq_allocations.items():\n- result = result + \" \" + str(good_id) + \": \" + str(quantity) + \"\\n\"\n+ result = result + \" \" + good_id + \": \" + str(quantity) + \"\\n\"\nresult = result + \"\\n\"\nresult = result + \"Equilibrium money allocation: \\n\"\nfor (\n",
        "chatgpt_cot": "Fix resource and supply cost calculation in BotAI. Add conditions to check if there are enough resources and supply for a specific item."
    },
    {
        "org_diff": "diff --git a/test/autotest_bot.py b/test/autotest_bot.py @@ -21,7 +21,7 @@ class TestBot(sc2.BotAI):\ndef __init__(self):\n# Tests related\nself.game_time_timeout_limit = 2*60\n- self.tests_target = 8\n+ self.tests_target = 7\nself.tests_done_by_name = set()\nasync def on_step(self, iteration):\n@@ -61,9 +61,9 @@ class TestBot(sc2.BotAI):\nawait self.test_botai_actions4()\nawait self.test_botai_actions4_successful()\n- elif \"test_botai_actions5_successful\" not in self.tests_done_by_name:\n- await self.test_botai_actions5()\n- await self.test_botai_actions5_successful()\n+ # elif \"test_botai_actions5_successful\" not in self.tests_done_by_name:\n+ # await self.test_botai_actions5()\n+ # await self.test_botai_actions5_successful()\n",
        "org_msg": "comment out test 5",
        "sim_msg": "added timeout of async operations to integration test setup/teardown",
        "sim_diff": "diff --git a/lbry/testcase.py b/lbry/testcase.py @@ -132,17 +132,18 @@ class AsyncioTestCase(unittest.TestCase):\nwith outcome.testPartExecutor(self):\nself.setUp()\n+ self.addTimeout()\nself.loop.run_until_complete(self.asyncSetUp())\nif outcome.success:\noutcome.expecting_failure = expecting_failure\nwith outcome.testPartExecutor(self, isTest=True):\nmaybe_coroutine = testMethod()\nif asyncio.iscoroutine(maybe_coroutine):\n- if self.TIMEOUT:\n- self.loop.call_later(self.TIMEOUT, self.cancel)\n+ self.addTimeout()\nself.loop.run_until_complete(maybe_coroutine)\noutcome.expecting_failure = False\nwith outcome.testPartExecutor(self):\n+ self.addTimeout()\nself.loop.run_until_complete(self.asyncTearDown())\nself.tearDown()\n@@ -190,6 +191,7 @@ class AsyncioTestCase(unittest.TestCase):\nwith outcome.testPartExecutor(self):\nmaybe_coroutine = function(*args, **kwargs)\nif asyncio.iscoroutine(maybe_coroutine):\n+ self.addTimeout()\nself.loop.run_until_complete(maybe_coroutine)\ndef cancel(self):\n@@ -198,6 +200,10 @@ class AsyncioTestCase(unittest.TestCase):\ntask.print_stack()\ntask.cancel()\n+ def addTimeout(self):\n+ if self.TIMEOUT:\n+ self.loop.call_later(self.TIMEOUT, self.cancel)\n+\nclass AdvanceTimeTestCase(AsyncioTestCase):\n",
        "chatgpt_cot": "Update test target to 7 and comment out test_botai_actions5 in TestBot class to adjust test execution flow."
    },
    {
        "org_diff": "diff --git a/fkie_multimaster_msgs/cmake/grpc_protoc.cmake b/fkie_multimaster_msgs/cmake/grpc_protoc.cmake include(CMakeParseArguments)\nmacro(generate_grpc)\n- find_program(PYTHON python)\n- if (NOT PYTHON)\n- find_program(PYTHON python3)\n- endif()\n- if (NOT PYTHON)\n- message(FATAL_ERROR \"python and python3 not found!\")\n- endif()\n# we need (for code generation) the root where the package lib goes to\nget_filename_component(DST_ROOT ${CATKIN_DEVEL_PREFIX}/${CATKIN_PACKAGE_PYTHON_DESTINATION} DIRECTORY)\n# and also the multimaster_fkie absolute path\n@@ -31,12 +24,12 @@ macro(generate_grpc)\nmessage(STATUS \"generate gRPC code from ${ABS_PROTO_FILE}\")\nadd_custom_command(\nOUTPUT ${GRPC_GENERATED_SRC_DIR}/${PROTO_FILE}_pb2.py\n- COMMAND \"${PYTHON}\" -m grpc_tools.protoc -I${MM_ROOT} --python_out=${DST_ROOT}/. ${ABS_PROTO_FILE}\n+ COMMAND \"${PYTHON_EXECUTABLE}\" -m grpc_tools.protoc -I${MM_ROOT} --python_out=${DST_ROOT}/. ${ABS_PROTO_FILE}\nDEPENDS ${GRPC_GENERATED_SRC_DIR} ${ABS_PROTO_FILE}\n)\nadd_custom_command(\nOUTPUT ${GRPC_GENERATED_SRC_DIR}/${PROTO_FILE}_pb2_grpc.py\n- COMMAND \"${PYTHON}\" -m grpc_tools.protoc -I${MM_ROOT} --grpc_python_out=${DST_ROOT}/. ${ABS_PROTO_FILE}\n+ COMMAND \"${PYTHON_EXECUTABLE}\" -m grpc_tools.protoc -I${MM_ROOT} --grpc_python_out=${DST_ROOT}/. ${ABS_PROTO_FILE}\nDEPENDS ${GRPC_GENERATED_SRC_DIR} ${ABS_PROTO_FILE}\n)\nendforeach()\n",
        "org_msg": "use ${PYTHON_EXECUTABLE} instead of search by itself",
        "sim_msg": "call logger.error instead of prints in 'aea generate'",
        "sim_diff": "diff --git a/aea/cli/generate.py b/aea/cli/generate.py @@ -54,7 +54,7 @@ def _generate_item(ctx: Context, item_type, specification_path):\n# check protocol buffer compiler is installed\nres = shutil.which(\"protoc\")\nif res is None:\n- print(\n+ logger.error(\n\"Please install protocol buffer first! See the following link: https://developers.google.com/protocol-buffers/\"\n)\nsys.exit(1)\n@@ -62,7 +62,7 @@ def _generate_item(ctx: Context, item_type, specification_path):\n# check black code formatter is installed\nres = shutil.which(\"black\")\nif res is None:\n- print(\n+ logger.error(\n\"Please install black code formater first! See the following link: https://black.readthedocs.io/en/stable/installation_and_usage.html\"\n)\nsys.exit(1)\n",
        "chatgpt_cot": "Fix Python executable path in grpc_protoc.cmake for code generation. Update commands to use PYTHON_EXECUTABLE instead of PYTHON for gRPC code generation."
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/main_window.py b/node_manager_fkie/src/node_manager_fkie/main_window.py @@ -1734,9 +1734,9 @@ class MainWindow(QMainWindow):\nlast_path = files[-1]\ntry:\nself.editor_dialogs[path].on_load_request(last_path, search_text)\n- self.editor_dialogs[path].raise_()\n+ self.editor_dialogs[path].restore()\nself.editor_dialogs[path].activateWindow()\n- except:\n+ except Exception:\nif trynr > 1:\nraise\ndel self.editor_dialogs[path]\n",
        "org_msg": "node_manager_fkie: restore edit dialog",
        "sim_msg": "import files directory defaults to user setting not Home",
        "sim_diff": "diff --git a/qualcoder/manage_files.py b/qualcoder/manage_files.py @@ -104,6 +104,7 @@ class DialogManageFiles(QtWidgets.QDialog):\nsys.excepthook = exception_handler\nself.app = app\n+ self.default_import_directory = self.app.settings['directory']\nself.parent_textEdit = parent_textEdit\nself.dialogList = []\nself.attributes = []\n",
        "chatgpt_cot": "\"Fix issue with main window editor dialogs to restore and activate window on load request exception\""
    },
    {
        "org_diff": "diff --git a/fkie_master_sync/src/fkie_master_sync/sync_thread.py b/fkie_master_sync/src/fkie_master_sync/sync_thread.py @@ -89,7 +89,7 @@ class SyncThread(object):\nself._offline_ts = 0\nself.masteruri_local = masteruri_from_ros()\n- rospy.logdebug(\"SyncThread[%s]: create this sync thread\", self.name)\n+ rospy.logdebug(\"SyncThread[%s]: create this sync thread, discoverer_name: %s\", (self.name, self.discoverer_name))\n# synchronization variables\nself.__lock_info = threading.RLock()\nself.__lock_intern = threading.RLock()\n@@ -115,7 +115,7 @@ class SyncThread(object):\n# setup the filter\nself._filter = FilterInterface()\nself._filter.load(self.name,\n- ['/rosout', self.discoverer_name, '/node_manager', '/node_manager_daemon', '/zeroconf', '/param_sync'], [],\n+ ['/rosout', self.discoverer_name, '/master_discovery', '/master_sync', '/node_manager', '/node_manager_daemon', '/zeroconf', '/param_sync'], [],\n['/rosout', '/rosout_agg', '/diagnostics', '/diagnostics_agg'], ['/'] if sync_on_demand else [],\n['/*get_loggers', '/*set_logger_level'], [],\n# do not sync the bond message of the nodelets!!\n",
        "org_msg": "fkie_master_sync: added master_sync and master_discovery",
        "sim_msg": "Reset Block height sync bad targets on cleanUp",
        "sim_diff": "diff --git a/loopchain/peer/block_sync.py b/loopchain/peer/block_sync.py @@ -699,6 +699,7 @@ class BlockSync:\nself._sync_done_event = None\nself._retry_queue = None\nself._retry_task = None\n+ self._block_height_sync_bad_targets.clear()\ndef stop(self):\nself._cleanup()\n",
        "chatgpt_cot": "Synchronize the thread and log the discoverer name. Sync the filter and do not sync the bond message of the nodelets."
    },
    {
        "org_diff": "diff --git a/src/api-engine/api/routes/network/views.py b/src/api-engine/api/routes/network/views.py @@ -45,7 +45,6 @@ class NetworkViewSet(viewsets.ViewSet):\ndef _genesis2base64(self, network):\n\"\"\"\nconvert genesis.block to Base64\n-\n:param network: network id\n:return: genesis block\n:rtype: bytearray\n@@ -70,7 +69,6 @@ class NetworkViewSet(viewsets.ViewSet):\ndef list(self, request):\n\"\"\"\nList network\n-\n:param request: query parameter\n:return: network list\n:rtype: list\n@@ -130,18 +128,19 @@ class NetworkViewSet(viewsets.ViewSet):\ninfo = {}\n+ org_name = org.name if node.type == \"peer\" else org.name.split(\".\", 1)[1]\n# get info of node, e.g, tls, msp, config.\ninfo[\"status\"] = node.status\ninfo[\"msp\"] = node.msp\ninfo[\"tls\"] = node.tls\ninfo[\"config_file\"] = node.config_file\ninfo[\"type\"] = node.type\n- info[\"name\"] = node.name\n+ info[\"name\"] = \"{}.{}\".format(node.name, org_name)\ninfo[\"bootstrap_block\"] = network.genesisblock\ninfo[\"urls\"] = agent.urls\ninfo[\"network_type\"] = network.type\ninfo[\"agent_type\"] = agent.type\n- info[\"ports\"] = {str(p.internal)+'/tcp': p.external for p in ports}\n+ info[\"ports\"] = ports\nreturn info\nexcept Exception as e:\nraise e\n@@ -174,7 +173,6 @@ class NetworkViewSet(viewsets.ViewSet):\ndef create(self, request):\n\"\"\"\nCreate Network\n-\n:param request: create parameter\n:return: organization ID\n:rtype: uuid\n@@ -237,7 +235,6 @@ class NetworkViewSet(viewsets.ViewSet):\ndef retrieve(self, request, pk=None):\n\"\"\"\nGet Network\n-\nGet network information\n\"\"\"\npass\n@@ -250,7 +247,6 @@ class NetworkViewSet(viewsets.ViewSet):\ndef destroy(self, request, pk=None):\n\"\"\"\nDelete Network\n-\n:param request: destory parameter\n:param pk: primary key\n:return: none\n@@ -286,11 +282,9 @@ class NetworkViewSet(viewsets.ViewSet):\n\"\"\"\nget:\nGet Peers\n-\nGet peers of network.\npost:\nAdd New Peer\n-\nAdd peer into network\n\"\"\"\npass\n@@ -306,7 +300,6 @@ class NetworkViewSet(viewsets.ViewSet):\n\"\"\"\ndelete:\nDelete Peer\n-\nDelete peer in network\n\"\"\"\npass\n\\ No newline at end of file\n",
        "org_msg": "Change hlf nodes'nanes and set hlf nodes' ports then we can use\nfabric-tools to connect them",
        "sim_msg": "sy.networks only print networks which are online",
        "sim_diff": "diff --git a/packages/syft/src/syft/registry.py b/packages/syft/src/syft/registry.py @@ -28,14 +28,34 @@ class NetworkRegistry:\ntry:\nresponse = requests.get(NETWORK_REGISTRY_URL)\nnetwork_json = response.json()\n- self.networks = network_json[\"networks\"]\n+ self.all_networks = network_json[\"networks\"]\nexcept Exception as e:\nwarning(\nf\"Failed to get Network Registry, go checkout: {NETWORK_REGISTRY_REPO}. {e}\"\n)\n+ @property\n+ def online_networks(self):\n+ online_networks = list()\n+\n+ for network in self.all_networks:\n+ url = \"http://\" + network['host_or_ip'] + \":\" + str(network['port']) + \"/\"\n+ try:\n+ res = requests.get(url, timeout=0.3)\n+ online = \"This is a PyGrid Network node.\" in res.text\n+ except requests.exceptions.ConnectTimeout:\n+ online = False\n+\n+ if online:\n+ online_networks.append(network)\n+\n+ return online_networks\n+\ndef _repr_html_(self) -> str:\n- return pd.DataFrame(self.networks)._repr_html_()\n+ on = self.online_networks\n+ if len(on) == 0:\n+ return \"(no networks online - try syft.networks.all_networks to see offline networks)\"\n+ return pd.DataFrame(self.online_networks)._repr_html_()\ndef create_client(self, network: Dict[str, Any]) -> Client:\ntry:\n@@ -49,9 +69,10 @@ class NetworkRegistry:\ndef __getitem__(self, key: Union[str, int]) -> Client:\nif isinstance(key, int):\n- return self.create_client(network=self.networks[key])\n+ return self.create_client(network=self.online_networks[key])\nelse:\n- for network in self.networks:\n+ on = self.online_networks\n+ for network in on:\nif network[\"name\"] == key:\nreturn self.create_client(network=network)\n- raise KeyError(f\"Invalid key: {key} for {self.networks}\")\n+ raise KeyError(f\"Invalid key: {key} for {on}\")\n",
        "chatgpt_cot": "\"Add org_name variable to info name, fix ports assignment, and remove unnecessary comments in NetworkViewSet in views.py\""
    },
    {
        "org_diff": "diff --git a/fkie_node_manager/src/fkie_node_manager/main_window.py b/fkie_node_manager/src/fkie_node_manager/main_window.py @@ -1644,6 +1644,7 @@ class MainWindow(QMainWindow):\ncmuri = cmuri.replace('localhost', get_hostname(lmuri))\nelif cmuri is None:\ncmuri = nm.nameres().masteruri(utf8(hostname))\n+ if cmuri is not None:\nmaster = self.getMaster(cmuri.rstrip('/') + '/', create_new=False)\nif master is not None:\nfound_nodes = master._get_nodes_by_name([nodename])\n",
        "org_msg": "fkie_node_manager: fix start master_discovery using start dialog",
        "sim_msg": "outputting info on request",
        "sim_diff": "diff --git a/xcube/webapi/viewer/viewer.py b/xcube/webapi/viewer/viewer.py @@ -77,7 +77,6 @@ class Viewer:\nserver_url = _get_server_url(port)\nself._server_url = server_url\nself._viewer_url = f\"{server_url}/viewer/?serverUrl={server_url}\"\n- self.info()\n@property\ndef server_config(self) -> Mapping[str, Any]:\n@@ -133,12 +132,16 @@ class Viewer:\nf' height=\"{height}\"'\nf'/>'\n)\n- except ImportError:\n+ except ImportError as e:\n+ print(f\"Error: {e}; Trying to open Viewer in web browser...\")\n+ try:\nimport webbrowser\nwebbrowser.open_new_tab(self.viewer_url)\n+ except:\n+ print(\"Failed too.\")\ndef info(self):\n- # Consider outputting this as HTML\n+ # Consider outputting this as HTML if in Notebook\nprint(f\"Server: {self.server_url}\")\nprint(f\"Viewer: {self.viewer_url}\")\n",
        "chatgpt_cot": "Add a condition to check if cmuri is not None before getting the master to fix potential issues related to None value."
    },
    {
        "org_diff": "diff --git a/test/real_time_worker_production.py b/test/real_time_worker_production.py @@ -79,7 +79,7 @@ class RealTimeTestBot(sc2.BotAI):\nif self.enemy_units:\nawait self.client.debug_kill_unit(self.enemy_units)\n- if self.supply_used >= 12 or self.time > 7 * 60:\n+ if self.supply_used >= 199 or self.time > 7 * 60:\nprint(f\"Test successful, bot reached 199 supply without queueing two probes at once\")\nawait self.client.leave()\n",
        "org_msg": "Increment supply_used back to >=199",
        "sim_msg": "Rename variables in websocket worker test",
        "sim_diff": "diff --git a/test/workers/test_websocket_worker.py b/test/workers/test_websocket_worker.py @@ -170,14 +170,14 @@ def test_websocket_worker_multiple_output_response(hook, start_proc):\nWebsocketServerWorker\"\"\"\nkwargs = {\"id\": \"socket_multiple_output\", \"host\": \"localhost\", \"port\": 8768, \"hook\": hook}\n- server = start_proc(WebsocketServerWorker, kwargs)\n+ process_remote_worker = start_proc(WebsocketServerWorker, kwargs)\ntime.sleep(0.1)\nx = torch.tensor([1.0, 3, 2])\n- socket_pipe = WebsocketClientWorker(**kwargs)\n+ local_worker = WebsocketClientWorker(**kwargs)\n- x = x.send(socket_pipe)\n+ x = x.send(local_worker)\np1, p2 = torch.sort(x)\nx1, x2 = p1.get(), p2.get()\n@@ -186,6 +186,6 @@ def test_websocket_worker_multiple_output_response(hook, start_proc):\ndel x\n- socket_pipe.ws.shutdown()\n+ local_worker.ws.shutdown()\ntime.sleep(0.1)\n- server.terminate()\n+ process_remote_worker.terminate()\n",
        "chatgpt_cot": "\"Adjust bot conditions to reach 199 supply without queuing two probes at once, improving bot performance and testing success.\""
    },
    {
        "org_diff": "diff --git a/sc2/unit.py b/sc2/unit.py @@ -375,12 +375,11 @@ class Unit:\n\"\"\" Returns the 3d position of the unit. \"\"\"\nreturn Point3.from_proto(self._proto.pos)\n- # TODO\ndef distance_to(self, p: Union[\"Unit\", Point2, Point3]) -> Union[int, float]:\n\"\"\" Using the 2d distance between self and p.\nTo calculate the 3d distance, use unit.position3d.distance_to(p) \"\"\"\nif isinstance(p, Unit):\n- return self._bot_object._distance_squared_unit_to_unit(self, p)\n+ return self._bot_object._distance_squared_unit_to_unit(self, p)**0.5\nreturn self._bot_object.distance_math_hypot(self.position_tuple, p)\ndef target_in_range(self, target: \"Unit\", bonus_distance: Union[int, float] = 0) -> bool:\n",
        "org_msg": "Fix distance_to in unit.py",
        "sim_msg": "improved autograd",
        "sim_diff": "diff --git a/syft/syft.py b/syft/syft.py @@ -166,6 +166,9 @@ class FloatTensor():\ndef floor_(self):\nreturn self.no_params_func(\"floor_\")\n+ def grad(self):\n+ return self.get(\"grad\", response_as_tensor=True)\n+\ndef __mul__(self, x):\nreturn self.arithmetic_operation(x, \"mul\", False)\n@@ -263,8 +266,8 @@ class FloatTensor():\ndef __str__(self):\nreturn self.no_params_func(\"print\", True, False)\n- def get(self, param_name=\"size\"):\n- return self.params_func(name=\"get\",params=[param_name], return_response=True, return_as_tensor=False)\n+ def get(self, param_name=\"size\", response_as_tensor=False):\n+ return self.params_func(name=\"get\",params=[param_name], return_response=True, return_as_tensor=response_as_tensor)\ndef cpu(self):\nreturn self.no_params_func(\"cpu\")\n",
        "chatgpt_cot": "\"Fix distance_to method calculation by taking the square root of the result to accurately calculate the 3D distance between units.\""
    },
    {
        "org_diff": "diff --git a/.github/workflows/pythonactions.yml b/.github/workflows/pythonactions.yml @@ -192,7 +192,7 @@ jobs:\nstrategy:\nmatrix:\npython-version: [3.9]\n- needs: [run_pytest_tests, run_test_bots, run_examples_bots]\n+ needs: [run_pytest_tests, run_test_bots, run_example_bots]\nsteps:\n- uses: actions/checkout@v1\n@@ -231,7 +231,7 @@ jobs:\nstrategy:\nmatrix:\npython-version: [3.9]\n- needs: [run_pytest_tests, run_test_bots, run_examples_bots]\n+ needs: [run_pytest_tests, run_test_bots, run_example_bots]\nsteps:\n- uses: actions/checkout@v1\n",
        "org_msg": "Fix missing workflow renaming",
        "sim_msg": "Add Python 3.8 build",
        "sim_diff": "diff --git a/.github/workflows/build.yml b/.github/workflows/build.yml @@ -8,7 +8,7 @@ jobs:\n- uses: actions/checkout@v1\n- uses: actions/setup-python@v1\nwith:\n- python-version: 3.7\n+ python-version: 3.8\n- run: pip install --upgrade pip\n- run: make install\n- run: make pycodestyle\n@@ -23,7 +23,7 @@ jobs:\nstrategy:\nmatrix:\nos: [ubuntu-latest, macOS-latest, windows-latest]\n- python-version: [3.6, 3.7]\n+ python-version: [3.6, 3.7, 3.8]\nsteps:\n- uses: actions/checkout@v1\n- uses: actions/setup-python@v1\n",
        "chatgpt_cot": "Fix typo in workflow file for Python actions by correcting the needs for running example bots."
    },
    {
        "org_diff": "diff --git a/sc2/unit.py b/sc2/unit.py @@ -238,7 +238,7 @@ class Unit(object):\nelse:\nawait self.do(unit.move(retreatPosition))\n\"\"\"\n- if self.can_attack_ground or self.can_attack_air:\n+ if self.can_attack:\nreturn self._proto.weapon_cooldown\nreturn -1\n@@ -271,6 +271,13 @@ class Unit(object):\ndef passengers_tags(self) -> Set[int]:\nreturn {unit.tag for unit in self._proto.passengers}\n+ @property\n+ def can_attack(self) -> bool:\n+ if hasattr(self._type_data._proto, \"weapons\"):\n+ weapons = self._type_data._proto.weapons\n+ return bool(weapons)\n+ return False\n+\n@property\ndef can_attack_ground(self) -> bool:\nif hasattr(self._type_data._proto, \"weapons\"):\n",
        "org_msg": "Add can_attack property",
        "sim_msg": "[ENH] remove unused methods from `ClassifierPipeline`\nThis PR removes unused methods from `ClassifierPipeline`, which probably got there as part of a copy-paste accident from `_HeterogeneousMetaEstimator`.",
        "sim_diff": "diff --git a/sktime/classification/compose/_pipeline.py b/sktime/classification/compose/_pipeline.py @@ -180,40 +180,6 @@ class ClassifierPipeline(BaseClassifier, _HeterogenousMetaEstimator):\nelse:\nreturn NotImplemented\n- @staticmethod\n- def _is_name_and_trafo(obj):\n- if not isinstance(obj, tuple) or len(obj) != 2:\n- return False\n- if not isinstance(obj[0], str) or not isinstance(obj[1], BaseTransformer):\n- return False\n- return True\n-\n- def _anytagis(self, tag_name, value):\n- \"\"\"Return whether any estimator in list has tag `tag_name` of value `value`.\"\"\"\n- tagis = [est.get_tag(tag_name, value) == value for _, est in self.transformers_]\n- return any(tagis)\n-\n- def _anytagis_then_set(self, tag_name, value, value_if_not):\n- \"\"\"Set self's `tag_name` tag to `value` if any estimator on the list has it.\"\"\"\n- if self._anytagis(tag_name=tag_name, value=value):\n- self.set_tags(**{tag_name: value})\n- else:\n- self.set_tags(**{tag_name: value_if_not})\n-\n- def _anytag_notnone_val(self, tag_name):\n- \"\"\"Return first non-'None' value of tag `tag_name` in estimator list.\"\"\"\n- for _, est in self.transformers_:\n- tag_val = est.get_tag(tag_name)\n- if tag_val != \"None\":\n- return tag_val\n- return tag_val\n-\n- def _anytag_notnone_set(self, tag_name):\n- \"\"\"Set self's `tag_name` tag to first non-'None' value in estimator list.\"\"\"\n- tag_val = self._anytag_notnone_val(tag_name=tag_name)\n- if tag_val != \"None\":\n- self.set_tags(**{tag_name: tag_val})\n-\ndef _fit(self, X, y):\n\"\"\"Fit time series classifier to training data.\n",
        "chatgpt_cot": "\"Refactor can_attack method in Unit class to improve readability and maintainability, and fix conditional statement to check for attack capability.\""
    },
    {
        "org_diff": "diff --git a/sc2/unit.py b/sc2/unit.py @@ -513,9 +513,11 @@ class Unit(PassengerUnit):\ndef is_using_ability(self, abilities: Union[AbilityId, Set[AbilityId]]) -> bool:\n\"\"\" Check if the unit is using one of the given abilities. \"\"\"\n+ if not self.orders:\n+ return False\nif isinstance(abilities, AbilityId):\nabilities = {abilities}\n- return bool(self.orders) and self.orders[0].ability.id in abilities\n+ return self.orders[0].ability.id in abilities\n@property_immutable_cache\ndef is_moving(self) -> bool:\n",
        "org_msg": "Shortcut is_using_ability if no orders",
        "sim_msg": "Test ObjectWithId.__eq__ method",
        "sim_diff": "diff --git a/tests/syft/core/common/object_test.py b/tests/syft/core/common/object_test.py @@ -47,18 +47,24 @@ def test_immutability_of_id():\nobj.id = \"\"\n-#\n-#\n-# def test_compare():\n-#\n-# obj = ObjectWithID()\n-# obj2 = ObjectWithID()\n-#\n-# assert obj != obj2\n-#\n-# obj.id = obj2.id\n-#\n-# assert obj == obj2\n-\n################## CLASS METHODS #######################\n+\n+\n+def test_compare():\n+ \"\"\"While uses of this feature should be quite rare, we\n+ should be able to check whether two objects are the same\n+ based on their IDs being the same by default. Note that\n+ subclasses will undoubtedly modify this behavior with other\n+ __eq__ methods.\"\"\"\n+\n+ obj = ObjectWithID()\n+ obj2 = ObjectWithID()\n+\n+ assert obj != obj2\n+\n+ obj._id = obj2.id\n+\n+ assert obj == obj2\n+\n+\n###################### SERDE ##########################\n\\ No newline at end of file\n",
        "chatgpt_cot": "\"Fix is_using_ability method to handle empty orders list\""
    },
    {
        "org_diff": "diff --git a/fkie_node_manager/src/fkie_node_manager/master_view_proxy.py b/fkie_node_manager/src/fkie_node_manager/master_view_proxy.py @@ -1879,7 +1879,7 @@ class MasterViewProxy(QWidget):\nfinally:\nself.setCursor(cursor)\n- def start_node(self, node, force, config, force_host=None, logging=None, opt_binary='', cmd_prefix=''):\n+ def start_node(self, node, force, config, force_host=None, logging=None, cmd_prefix='', opt_binary=''):\nif node is None:\nraise DetailedError(\"Start error\", 'None is not valid node name!')\n@@ -1916,7 +1916,7 @@ class MasterViewProxy(QWidget):\nexcept nm.InteractionNeededError as _:\nraise\nexcept nm.BinarySelectionRequest as bsr:\n- raise nm.InteractionNeededError(bsr, self.start_node, (node, force, config, force_host, logging, '', cmd_prefix))\n+ raise nm.InteractionNeededError(bsr, self.start_node, (node, force, config, force_host, logging, cmd_prefix))\nexcept (exceptions.StartException, nm.StartException) as e:\nrospy.logwarn(\"Error while start '%s': %s\" % (node.name, utf8(e)))\nlines = utf8(e).splitlines()\n@@ -2024,7 +2024,7 @@ class MasterViewProxy(QWidget):\nself._progress_queue.add2queue(utf8(uuid.uuid4()),\n''.join(['start ', node.node_info.name]),\nself.start_node,\n- (node.node_info, force, cfg_nodes[node.node_info.name], force_host, logging, '', cmd_prefix))\n+ (node.node_info, force, cfg_nodes[node.node_info.name], force_host, logging, cmd_prefix))\nself._start_queue(self._progress_queue)\ndef _check_for_nodelets(self, nodes):\n",
        "org_msg": "fkie_node_manager: fixed start node after selection from multiple binaries",
        "sim_msg": "ADD get_req_info / FIX get_user_info",
        "sim_diff": "diff --git a/packages/syft/src/syft/core/node/common/node_manager/request_manager.py b/packages/syft/src/syft/core/node/common/node_manager/request_manager.py @@ -45,17 +45,35 @@ class RequestManager(DatabaseManager):\ndef set(self, request_id: int, status: RequestStatus) -> None:\nself.modify({\"id\": request_id}, {\"status\": status})\n- def get_user_info(request_id: int) -> Dict:\n+ def get_user_info(self, request_id: int) -> Dict:\nrequest = super().first(id=request_id)\nreturn {\n\"name\": request.user_name,\n\"email\": request.user_email,\n\"role\": request.user_role,\n- \"budget\": request.user_budget,\n+ \"current_budget\": request.user_budget,\n\"institution\": request.institution,\n\"website\": request.website,\n}\n+ def get_req_info(self, request_id: int) -> Dict:\n+ request = super().first(id=request_id)\n+ return {\n+ \"id\": request.id,\n+ \"date\": str(request.date),\n+ \"status\": request.status,\n+ \"reason\": request.reason,\n+ \"request_type\": request.request_type,\n+ \"current_budget\": request.current_budget,\n+ \"requested_budget\": request.requested_budget,\n+ \"review\": {\n+ \"name\": request.reviewer_name,\n+ \"role\": request.reviewer_role,\n+ \"updated_on\": str(request.updated_on),\n+ \"comment\": request.reviewer_comment,\n+ },\n+ }\n+\ndef clear(self) -> None:\nlocal_session = sessionmaker(bind=self.db)()\nlocal_session.query(self.schema).delete()\n",
        "chatgpt_cot": "\"Fix start_node method parameters in MasterViewProxy to resolve compilation error and improve code readability.\""
    },
    {
        "org_diff": "diff --git a/sc2/bot_ai.py b/sc2/bot_ai.py @@ -137,6 +137,19 @@ class BotAI:\n\"\"\" Returns dict with the correct expansion position Point2 key, resources (mineral field, vespene geyser) as value \"\"\"\nreturn centers\n+ def _correct_zerg_supply(self):\n+ \"\"\" The client incorrectly rounds zerg supply down instead of up (see\n+ https://github.com/Blizzard/s2client-proto/issues/123), so self.supply_used\n+ and friends return the wrong value when there are an odd number of zerglings\n+ and banelings. This function corrects the bad values. \"\"\"\n+ # TODO: remove when Blizzard/sc2client-proto#123 gets fixed.\n+ correction = self.units({UnitTypeId.ZERGLING, UnitTypeId.ZERGLINGBURROWED,\n+ UnitTypeId.BANELING, UnitTypeId.BANELINGBURROWED,\n+ UnitTypeId.BANELINGCOCOON}).amount % 2\n+ self.supply_used += correction\n+ self.supply_army += correction\n+ self.supply_left -= correction\n+\nasync def get_available_abilities(self, units: Union[List[Unit], Units], ignore_resource_requirements=False) -> List[List[AbilityId]]:\n\"\"\" Returns available abilities of one or more units. Right know only checks cooldown, energy cost, and whether the ability has been researched.\nExample usage:\n@@ -588,6 +601,11 @@ class BotAI:\nself.supply_cap: Union[float, int] = state.common.food_cap\nself.supply_used: Union[float, int] = state.common.food_used\nself.supply_left: Union[float, int] = self.supply_cap - self.supply_used\n+\n+ # Workaround Zerg supply rounding bug\n+ if self.race == Race.Zerg:\n+ self._correct_zerg_supply()\n+\nself.idle_worker_count: int = state.common.idle_worker_count\nself.army_count: int = state.common.army_count\nself.warp_gate_count: int = state.common.warp_gate_count\n",
        "org_msg": "Workaround for zerg supply rounding bug",
        "sim_msg": "add cached rate in unchunked servers",
        "sim_diff": "diff --git a/baron/baron.py b/baron/baron.py @@ -375,7 +375,13 @@ class Baron(commands.Cog):\nguilds = [g for g in self.bot.guilds if not g.chunked]\nif not guilds:\nreturn await ctx.send(f\"There are no unchunked servers.\")\n- await self.view_guilds(ctx, guilds, \"Unchunked Servers\", page_length)\n+\n+ def insert_function(guild: discord.Guild):\n+ members = len(guild.members)\n+ percent = members/guild.member_count\n+ return f\"Members Cached: **{humanize_number(members)} ({round(percent, 2)})%**\"\n+\n+ await self.view_guilds(ctx, guilds, \"Unchunked Servers\", page_length, insert_function=insert_function)\n@baron.group(name=\"leave\")\nasync def baron_leave(self, ctx: commands.Context):\n",
        "chatgpt_cot": "fix Zerg supply rounding bug in BotAI file. Added _correct_zerg_supply method to adjust supply values for odd zerglings and banelings."
    },
    {
        "org_diff": "diff --git a/README.md b/README.md @@ -79,6 +79,41 @@ This is probably the simplest bot that has any realistic chances of winning the\nYou can find more examples in the [`examples/`](/examples) folder.\n+## API Configuration Options\n+\n+The API supports a number of options for configuring how it operates.\n+\n+### `raw_affects_selection`\n+Setting this to true improves bot performance by a little bit.\n+```python\n+class MyBot(sc2.BotAI):\n+ def __init__(self):\n+ self.raw_affects_selection = True\n+```\n+\n+### `distance_calculation_method`\n+The distance calculation method:\n+- 0 for raw python\n+- 1 for scipy pdist\n+- 2 for scipy cdist\n+```python\n+class MyBot(sc2.BotAI):\n+ def __init__(self):\n+ self.distance_calculation_method = 2\n+```\n+\n+### `game_step`\n+On game start or in any frame actually, you can set the game step. This controls how often your bot's `step` method is called.\n+__Do not set this in the \\_\\_init\\_\\_ function as the client will not have been initialized yet!__\n+```python\n+class MyBot(sc2.BotAI):\n+ def __init__(self):\n+ pass # don't set it here!\n+\n+ async def on_start(self):\n+ self.client.game_step = 2\n+```\n+\n## Community - Help and support\nYou have questions but don't want to create an issue? Join the [Starcraft 2 AI Discord server](https://discordapp.com/invite/zXHU4wM) or [ai-arena.net Discord server](https://discord.gg/yDBzbtC). Questions about this repository can be asked in text channel #python. There are discussions and questions about SC2 bot programming and this repository every day.\n",
        "org_msg": "Add documentation for config options that were previously removed from the example bot.",
        "sim_msg": "Added a table to the custom commands",
        "sim_diff": "diff --git a/GearBot/Bot.py b/GearBot/Bot.py @@ -3,6 +3,7 @@ import asyncio\nimport os\nfrom functions import configuration, protectedmessage, permissions, spam, customcommands\n+from tabulate import tabulate\nclient = discord.Client()\ncheckBot = None\n@@ -90,7 +91,8 @@ async def on_message(message):\n# Config -------------------------------------------------------------------------------------------------------------------------------------------------------------------\nelif receivedmessage.startswith('!getconfig'):\nawait protectedmessage.send_protected_message(client, message.channel,\n- ('```'+configuration.getconfigvalues(message.channel.server)+'```'))\n+ ('```' + configuration.getconfigvalues(\n+ message.channel.server) + '```'))\nelif receivedmessage.startswith('!resetconfig'):\nconfiguration.resetconfig(message.channel.server)\n@@ -155,6 +157,13 @@ async def on_message(message):\n'!(custom command): Execute a custom command```'\nif not (text is None):\nawait protectedmessage.send_protected_message(client, message.channel, text)\n+ elif message.content.lower().startswith('!getcustomcommands'):\n+ customcmd = dict(customcommands.getcommands(message.channel.server))\n+ li = []\n+ for key, value in customcmd.items():\n+ li.append([key.title(), value])\n+ await protectedmessage.send_protected_message(client, message.channel,\n+ '**Custom Commands:**\\n```' + tabulate(li) + '```')\ntry:\n",
        "chatgpt_cot": "Add API configuration options for bot performance improvement and distance calculation method selection. Set game step control in on_start method to avoid initialization issues."
    },
    {
        "org_diff": "diff --git a/rasa_core_sdk/forms.py b/rasa_core_sdk/forms.py @@ -56,7 +56,7 @@ class FormAction(Action):\ndomain # type: Dict[Text, Any]\n):\n# type: (...) -> Optional[List[Dict]]\n- \"\"\"\"Extract the user input else return an error\"\"\"\n+ \"\"\"\"Extract requested slot from a user input else return None\"\"\"\nslot_to_fill = tracker.get_slot(REQUESTED_SLOT)\n# map requested_slot to entity\n@@ -88,7 +88,7 @@ class FormAction(Action):\n# noinspection PyUnusedLocal\ndef validate(self, dispatcher, tracker, domain):\n# type: (CollectingDispatcher, Tracker, Dict[Text, Any]) -> List[Dict]\n- \"\"\"\"Extract the user input else return an error\"\"\"\n+ \"\"\"\"Validate extracted requested slot else raise an error\"\"\"\nslot_to_fill = tracker.get_slot(REQUESTED_SLOT)\nevents = self.extract(dispatcher, tracker, domain)\n",
        "org_msg": "fixes method description RasaHQ/roadmap#280",
        "sim_msg": "Allow users with names longer than the current limit to log in",
        "sim_diff": "diff --git a/app/forms/user.py b/app/forms/user.py @@ -78,7 +78,7 @@ class UsernameLength:\nclass LoginForm(RedirectForm):\n\"\"\" Login form. \"\"\"\n- username = StringField(_l(\"Username\"), validators=[UsernameLength()])\n+ username = StringField(_l(\"Username\"), validators=[Length(max=256)])\npassword = PasswordField(\n_l(\"Password\"), validators=[DataRequired(), Length(min=7, max=256)]\n)\n",
        "chatgpt_cot": "Update comments and method descriptions in FormAction class to provide more accurate and descriptive information about the purpose and functionality of the methods."
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/__init__.py b/node_manager_fkie/src/node_manager_fkie/__init__.py @@ -182,7 +182,14 @@ def is_local(hostname, wait=False):\nif isinstance(HOSTS_CACHE[hostname], threading.Thread):\nreturn False\nreturn HOSTS_CACHE[hostname]\n-\n+ try:\n+ # fix to handle the local names with domains\n+ if hostname == get_hostname(socket.gethostname()):\n+ with _LOCK:\n+ HOSTS_CACHE[hostname] = result\n+ return True\n+ except:\n+ pass\ntry:\nsocket.inet_aton(hostname)\nlocal_addresses = ['localhost'] + roslib.network.get_local_addresses()\n",
        "org_msg": "node_manager_fkie: added fix to handle the local names with domains",
        "sim_msg": "trying including dockerhost",
        "sim_diff": "diff --git a/packages/grid/backend/grid/core/node.py b/packages/grid/backend/grid/core/node.py @@ -42,6 +42,9 @@ def thread_function(*args, **kwargs) -> None:\nport=80,\n)\nexcept Exception as e:\n+\n+ try:\n+\nNETWORK_PUBLIC_HOST = \"http://localhost:80\"\nnetwork_root = sy.login(\n@@ -50,6 +53,16 @@ def thread_function(*args, **kwargs) -> None:\nurl=\"http://localhost\",\nport=80,\n)\n+ except Exception as e2:\n+\n+ NETWORK_PUBLIC_HOST = \"http://docker-host:80\"\n+\n+ network_root = sy.login(\n+ email=\"info@openmined.org\",\n+ password=\"changethis\",\n+ url=\"http://docker-host\",\n+ port=80,\n+ )\nnetwork_root.join_network(host_or_ip=NETWORK_PUBLIC_HOST)\n",
        "chatgpt_cot": "\"Fix handling of local names with domains and add exception handling for hostname lookup in node_manager_fkie/__init__.py\""
    },
    {
        "org_diff": "diff --git a/sc2/bot_ai.py b/sc2/bot_ai.py @@ -111,7 +111,7 @@ class BotAI(object):\n]\n# order by distance to resources, 7.162 magic distance number (avg resource distance of current ladder maps)\npossible_points.sort(\n- key=lambda p: statistics.mean([abs(p.distance_to(resource) - 7.162) for resource in resources])\n+ key=lambda p: statistics.mean([abs(p.distance_to(resource) - 7.162) for resource in resources if resource in self.state.mineral_field])\n)\n# choose best fitting point\ncenters[possible_points[0]] = resources\n",
        "org_msg": "Improve expansion location",
        "sim_msg": "added time to the saved files",
        "sim_diff": "diff --git a/bot_manager.py b/bot_manager.py @@ -178,7 +178,7 @@ class BotManager:\ncurrent_time = game_tick_packet.gameInfo.TimeSeconds\nif self.save_data and game_tick_packet.gameInfo.bRoundActive and not old_time == current_time and not current_time == -10:\n- np_input = self.input_converter.create_input_array(game_tick_packet)\n+ np_input = self.input_converter.create_input_array(game_tick_packet, passed_time=time.time() - before2)\nnp_output = np.array(controller_input, dtype=np.float32)\nself.input_array = np.append(self.input_array, np_input)\nself.output_array = np.append(self.output_array, np_output)\n",
        "chatgpt_cot": "\"Optimize resource distance calculation in BotAI by filtering for mineral fields in statistics.mean to improve resource gathering efficiency.\""
    },
    {
        "org_diff": "diff --git a/user-dashboard/src/index.js b/user-dashboard/src/index.js @@ -34,8 +34,23 @@ const io = require('./io').initialize(server);\nmongoose.Promise = global.Promise;\nlogger.info(config.mongodb.ip, config.mongodb.port, config.mongodb.name)\n-mongoose.connect('mongodb://'+config.mongodb.ip+':'+config.mongodb.port+'/' + config.mongodb.name, {useMongoClient: true});\n-\n+var conn = mongoose.connect('mongodb://'+config.mongodb.ip+':'+config.mongodb.port+'/' + config.mongodb.name, {useMongoClient: true});\n+conn.on('error', function(err){\n+ if (err.message && err.message.match(/failed to connect to server .* on first connect/)) {\n+ logger.info(String(err));\n+ // Wait for a bit, then try to connect again\n+ setTimeout(function () {\n+ logger.info(\"Retrying first connect...\");\n+ conn.openUri('mongodb://'+config.mongodb.ip+':'+config.mongodb.port+'/' + config.mongodb.name).catch(() => {});\n+ }, 20 * 1000);\n+ } else {\n+ // Some other error occurred. Log it.\n+ logger.error(String(err));\n+ }\n+});\n+conn.once('open',function(){\n+ logger.info(\"Connection to \" + config.mongodb.name + \" established.\")\n+});\napp.engine('html', cons.swig)\napp.set(\"views\", path.join(__dirname, \"views\"));\napp.set(\"view engine\", \"html\");\n",
        "org_msg": "DB first connection error\nUser dashboard throw error and cannot login\nlogs have error shows first connection ECONNREFUSED",
        "sim_msg": "Removed a print statement and added paremeters for MongoDB Credentials",
        "sim_diff": "diff --git a/modules/rta-extraction/RtaExtractor.py b/modules/rta-extraction/RtaExtractor.py @@ -119,7 +119,6 @@ def view_data(db_json=None, user_query=None):\nrequired_columns = data['items'][0].keys()\ndf = pd.DataFrame(data['items'])\n- print (df.head())\ntime_taken = round(time.time()-view_time, 2)\nlogging.info('Spent {} seconds viewing the data of {}.'.format(time_taken, db_json))\n@@ -142,13 +141,15 @@ if __name__ == \"__main__\":\nMeds_ExtractionFrequency = niffler['MedsDataExtractionFrequency']\nOrders_ExtractionFrequency = niffler['OrdersDataExtractionFrequency']\nMongo_URI = niffler['MongoURI']\n+ Mongo_UserName = niffler['MongoUserName']\n+ Mongo_PassCode = niffler['MongoPassCode']\nUserName = niffler['UserName']\nPassCode = niffler['PassCode']\n# Connect to MongoDB\nconnection_start_time = time.time()\ntry:\n- client = MongoClient(Mongo_URI)\n+ client = MongoClient(Mongo_URI, username=Mongo_UserName, password=Mongo_PassCode)\nlogging.info('MongoDB Connection Successful.')\nexcept:\nlogging.error('MongoDB Connection Unsuccessful.')\n",
        "chatgpt_cot": "Add error handling and retry mechanism for MongoDB connection in index.js. Ensure robust connection establishment and logging for user-dashboard."
    },
    {
        "org_diff": "diff --git a/fkie_node_manager/src/fkie_node_manager/logscreen/logger_handler.py b/fkie_node_manager/src/fkie_node_manager/logscreen/logger_handler.py @@ -124,7 +124,7 @@ class LoggerHandler(QObject):\nall_item.set_callback(self.change_all)\nself.layout.insertWidget(0, all_item)\nindex += 1\n- for logger_name, logger_level in self._stored_values.items():\n+ for logger_name, logger_level in sorted(self._stored_values.items()):\nitem = LoggerItem(self.nodename, self.masteruri, logger_name, logger_level)\nself._logger_items[logger_name] = item\nif (not logger_name in new_logger) or new_logger[logger_name] != logger_level:\n",
        "org_msg": "sort logger level",
        "sim_msg": "Generalize Research.add_logger args parsing",
        "sim_diff": "diff --git a/batchflow/research/research.py b/batchflow/research/research.py @@ -273,34 +273,36 @@ class Research:\ndef add_logger(self, logger, **kwargs):\n\"\"\" Add custom Logger into Research.\n-\nParameters\n----------\n- logger : str, tuple, list or Logger\n- if str, it can be 'basic', 'print' or 'tg',\n- if tuple, pair of str and kwargs for initialization\n- if list then list of str or Logger instances.\n+ logger : str, Logger, tuple or list\n+ if str, it can be 'basic', 'print' or 'tg'\n+ if tuple, pair of str or Logger and kwargs for them\n+ if list then of str, Logger and tuples of them and kwargs\nkwargs :\n- initialization parameters for Logger (if `logger` not a list)\n+ initialization parameters for Logger (if `logger` is str or Logger)\n\"\"\"\n- if not isinstance(logger, list):\n- logger = [logger]\n+ loggers = [logger] if not isinstance(logger, list) else logger\nself.logger = Logger()\n- for item in logger:\n- if isinstance(item, str):\n- item = (item, {})\n- if isinstance(item, tuple):\n- if item[0] == 'basic':\n+\n+ for item in loggers:\n+ if not isinstance(item, tuple):\n+ item = (item, kwargs)\n+ logger, params = item\n+\n+ if isinstance(logger, str):\n+ if logger == 'basic':\nself.logger += BasicLogger()\n- elif item[0] == 'print':\n+ elif logger == 'print':\nself.logger += PrintLogger()\n- elif item[0] == 'tg':\n- self.logger += TelegramLogger(**item[1])\n+ elif logger == 'tg':\n+ self.logger += TelegramLogger(**params)\nelse:\n- raise ValueError('Unknown logger: ' + item[0])\n+ raise ValueError('Unknown logger: ' + logger)\nelse:\n- self.logger += item\n+ self.logger += logger(**params)\n+\nreturn self\ndef load_results(self, *args, **kwargs):\n",
        "chatgpt_cot": "\"Sort stored values in LoggerHandler to ensure consistent order of logger items in logscreen\""
    },
    {
        "org_diff": "diff --git a/rasa_core_sdk/forms.py b/rasa_core_sdk/forms.py @@ -42,9 +42,10 @@ class FormAction(Action):\ndef slot_mapping(self):\n# type: () -> Dict[Text: Union[Text, Dict, List[Text, Dict]]]\n\"\"\"A dictionary to map required slots to\n- - an extracted entity\n- - a dictionary of intent: value pairs\n- - a whole message\n+ - an extracted entity;\n+ - a dictionary of intent: value pairs,\n+ if value is FREETEXT, use a whole message as value;\n+ - a whole message;\nor a list of all of them, where a first match will be picked\"\"\"\nreturn dict(zip(self.required_slots(), self.required_slots()))\n@@ -71,7 +72,13 @@ class FormAction(Action):\nintent = tracker.latest_message.get(\"intent\",\n{}).get(\"name\")\nif intent in slot_mapping.keys():\n- return [SlotSet(slot_to_fill, slot_mapping[intent])]\n+ if slot_mapping[intent] == self.FREETEXT:\n+ return [SlotSet(slot_to_fill,\n+ tracker.latest_message.get(\n+ \"text\"))]\n+ else:\n+ return [SlotSet(slot_to_fill,\n+ slot_mapping[intent])]\nelse:\nentity_value = next(tracker.get_latest_entity_values(\nslot_mapping), None)\n",
        "org_msg": "add capability to set a slot to a whole message conditioned on the intent RasaHQ/roadmap#280",
        "sim_msg": "Add stereotypes to action item",
        "sim_diff": "diff --git a/gaphor/diagram/actions/action.py b/gaphor/diagram/actions/action.py @@ -3,9 +3,10 @@ Action diagram item.\n\"\"\"\nfrom gaphor import UML\n+from gaphor.UML.modelfactory import stereotypes_str\nfrom gaphor.diagram.presentation import ElementPresentation\nfrom gaphor.diagram.support import represents\n-from gaphor.diagram.shapes import Box, EditableText, draw_boundry\n+from gaphor.diagram.shapes import Box, EditableText, Text, draw_boundry\n@represents(UML.Action)\n@@ -16,11 +17,12 @@ class ActionItem(ElementPresentation):\n\"\"\"\nsuper().__init__(id, model)\n- name = EditableText(text=lambda: self.subject and self.subject.name or \"\")\n- self.watch(\"subject<NamedElement>.name\")\n-\nself.shape = Box(\n- name,\n+ Text(\n+ text=lambda: stereotypes_str(self.subject),\n+ style={\"min-width\": 0, \"min-height\": 0},\n+ ),\n+ EditableText(text=lambda: self.subject and self.subject.name or \"\"),\nstyle={\n\"min-width\": 50,\n\"min-height\": 30,\n@@ -31,6 +33,9 @@ class ActionItem(ElementPresentation):\ndraw=draw_boundry,\n)\n+ self.watch(\"subject<NamedElement>.name\")\n+ self.watch(\"subject.appliedStereotype.classifier.name\")\n+\n@represents(UML.SendSignalAction)\nclass SendSignalActionItem(ElementPresentation):\n@@ -40,16 +45,19 @@ class SendSignalActionItem(ElementPresentation):\n\"\"\"\nsuper().__init__(id, model)\n- name = EditableText(text=lambda: self.subject and self.subject.name or \"\")\n-\n- self.watch(\"subject<NamedElement>.name\")\n-\nself.shape = Box(\n- name,\n+ Text(\n+ text=lambda: stereotypes_str(self.subject),\n+ style={\"min-width\": 0, \"min-height\": 0},\n+ ),\n+ EditableText(text=lambda: self.subject and self.subject.name or \"\"),\nstyle={\"min-width\": 50, \"min-height\": 30, \"padding\": (5, 25, 5, 10)},\ndraw=self.draw_border,\n)\n+ self.watch(\"subject<NamedElement>.name\")\n+ self.watch(\"subject.appliedStereotype.classifier.name\")\n+\ndef draw_border(self, box, context, bounding_box):\ncr = context.cairo\nd = 15\n@@ -72,16 +80,19 @@ class AcceptEventActionItem(ElementPresentation):\n\"\"\"\nsuper().__init__(id, model)\n- name = EditableText(text=lambda: self.subject and self.subject.name or \"\")\n-\n- self.watch(\"subject<NamedElement>.name\")\n-\nself.shape = Box(\n- name,\n+ Text(\n+ text=lambda: stereotypes_str(self.subject),\n+ style={\"min-width\": 0, \"min-height\": 0},\n+ ),\n+ EditableText(text=lambda: self.subject and self.subject.name or \"\"),\nstyle={\"min-width\": 50, \"min-height\": 30, \"padding\": (5, 10, 5, 25)},\ndraw=self.draw_border,\n)\n+ self.watch(\"subject<NamedElement>.name\")\n+ self.watch(\"subject.appliedStereotype.classifier.name\")\n+\ndef draw_border(self, box, context, bounding_box):\ncr = context.cairo\nd = 15\n",
        "chatgpt_cot": "\"Add support for FREETEXT value in slot mapping to use the entire message as the value.\""
    },
    {
        "org_diff": "diff --git a/rasa_core_sdk/events.py b/rasa_core_sdk/events.py @@ -134,7 +134,7 @@ def ActionExecuted(action_name, timestamp=None):\n# noinspection PyPep8Naming\ndef AgentUttered(text=None, data=None, timestamp=None):\nreturn {\n- \"event\": \"action\",\n+ \"event\": \"agent\",\n\"text\": text,\n\"data\": data,\n\"timestamp\": timestamp,\n",
        "org_msg": "Fix event name for AgentUttered event",
        "sim_msg": "[EventPoster] 1.2.1 Fix error on clear event",
        "sim_diff": "diff --git a/eventposter/eventposter.py b/eventposter/eventposter.py @@ -94,7 +94,7 @@ class EventPoster(commands.Cog):\nembed=em,\n)\nasync with self.config.guild(ctx.guild).events() as events:\n- event = await Event.from_json(events[str(ctx.author.id)])\n+ event = await Event.from_json(events[str(ctx.author.id)], ctx.guild)\nawait event.message.edit(content=\"This event has ended.\")\ndel events[str(ctx.author.id)]\nawait ctx.tick()\n",
        "chatgpt_cot": "Change event name from \"action\" to \"agent\" in AgentUttered method."
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/detailed_msg_box.py b/node_manager_fkie/src/node_manager_fkie/detailed_msg_box.py @@ -34,10 +34,10 @@ from python_qt_binding.QtCore import Qt\nfrom python_qt_binding.QtGui import QPixmap\ntry:\n- from python_qt_binding.QtGui import QPushButton, QSpacerItem, QSizePolicy, QTextEdit, QDialog\n+ from python_qt_binding.QtGui import QCheckBox, QPushButton, QSpacerItem, QSizePolicy, QTextEdit, QDialog\nfrom python_qt_binding.QtGui import QDialogButtonBox, QVBoxLayout, QHBoxLayout, QLabel, QStyle, QApplication\nexcept:\n- from python_qt_binding.QtWidgets import QPushButton, QSpacerItem, QSizePolicy, QTextEdit, QDialog\n+ from python_qt_binding.QtWidgets import QCheckBox, QPushButton, QSpacerItem, QSizePolicy, QTextEdit, QDialog\nfrom python_qt_binding.QtWidgets import QDialogButtonBox, QVBoxLayout, QHBoxLayout, QLabel, QStyle, QApplication\n@@ -90,6 +90,7 @@ class MessageBox(QDialog):\nself.setWindowFlags(self.windowFlags() & ~Qt.WindowTitleHint)\nself.setWindowFlags(self.windowFlags() & ~Qt.WindowContextHelpButtonHint & ~Qt.WindowMinimizeButtonHint)\nself.setObjectName('MessageBox')\n+ self._use_checkbox = True\nself.text = text\nself.verticalLayout = QVBoxLayout(self)\nself.verticalLayout.setObjectName(\"verticalLayout\")\n@@ -143,6 +144,7 @@ class MessageBox(QDialog):\nif detailed_text:\nself.btn_show_details = QPushButton(self.tr('Details...'))\nself.btn_show_details.setCheckable(True)\n+ self.btn_show_details.setChecked(True)\nself.btn_show_details.toggled.connect(self.on_toggled_details)\nself.buttonBox.addButton(self.btn_show_details, QDialogButtonBox.ActionRole)\n# create area for detailed text\n@@ -150,8 +152,12 @@ class MessageBox(QDialog):\ntextEdit.setObjectName(\"textEdit\")\ntextEdit.setReadOnly(True)\ntextEdit.setText(detailed_text)\n- self.textEdit.setVisible(False)\n+ # textEdit.setVisible(False)\n+ self.verticalLayout.addWidget(self.textEdit)\nself.resize(480, self.verticalLayout.totalSizeHint().height())\n+ buttons_in_box = self.buttonBox.buttons()\n+ if buttons_in_box:\n+ self.buttonBox.buttons()[0].setFocus()\ndef setAcceptButton(self, button):\n'''\n@@ -364,6 +370,11 @@ class MessageBox(QDialog):\nbt.clicked.connect(self._on_ignore_clicked)\nself.buttonBox.addButton(bt, QDialogButtonBox.AcceptRole)\nif MessageBox.Avoid & buttons:\n+ if self._use_checkbox:\n+ checkbox = QCheckBox(\"&Don't show again\", self)\n+ checkbox.stateChanged.connect(self._check_ignore)\n+ self.buttonBox.addButton(checkbox, QDialogButtonBox.HelpRole)\n+ else:\nbt = QPushButton(self.tr(\"&Don't show again\"))\nbt.setMaximumHeight(24)\nbt.clicked.connect(self._add_to_ignore)\n@@ -426,3 +437,12 @@ class MessageBox(QDialog):\ndef _add_to_ignore(self):\nIGNORED_ERRORS.append(self.text)\nself.accept()\n+\n+ def _check_ignore(self, state):\n+ if state:\n+ IGNORED_ERRORS.append(self.text)\n+ else:\n+ try:\n+ IGNORED_ERRORS.remove(self.text)\n+ except Exception:\n+ pass\n",
        "org_msg": "node_manager_fkie: changed behaviour of detailed message box",
        "sim_msg": "added labels under dropdowns",
        "sim_diff": "diff --git a/avalon/tools/cbsceneinventory/app.py b/avalon/tools/cbsceneinventory/app.py @@ -481,7 +481,15 @@ class SwitchAssetDialog(QtWidgets.QDialog):\nself._representations_box = SearchComboBox(\nplaceholder=\"<representation>\")\n- input_layout = QtWidgets.QHBoxLayout()\n+ self._asset_label = QtWidgets.QLabel('')\n+ self._subset_label = QtWidgets.QLabel('')\n+ self._repre_label = QtWidgets.QLabel('')\n+\n+ main_layout = QtWidgets.QVBoxLayout()\n+ context_layout = QtWidgets.QHBoxLayout()\n+ asset_layout = QtWidgets.QVBoxLayout()\n+ subset_layout = QtWidgets.QVBoxLayout()\n+ repre_layout = QtWidgets.QVBoxLayout()\naccept_icon = qta.icon(\"fa.check\", color=\"white\")\naccept_btn = QtWidgets.QPushButton()\n@@ -489,15 +497,23 @@ class SwitchAssetDialog(QtWidgets.QDialog):\naccept_btn.setFixedWidth(24)\naccept_btn.setFixedHeight(24)\n- input_layout.addWidget(self._assets_box)\n- input_layout.addWidget(self._subsets_box)\n- input_layout.addWidget(self._representations_box)\n- input_layout.addWidget(accept_btn)\n+ asset_layout.addWidget(self._assets_box)\n+ asset_layout.addWidget(self._asset_label)\n+ subset_layout.addWidget(self._subsets_box)\n+ subset_layout.addWidget(self._subset_label)\n+ repre_layout.addWidget(self._representations_box)\n+ repre_layout.addWidget(self._repre_label)\n+\n+ context_layout.addLayout(asset_layout)\n+ context_layout.addLayout(subset_layout)\n+ context_layout.addLayout(repre_layout)\n+ context_layout.addWidget(accept_btn)\n- self._input_layout = input_layout\nself._accept_btn = accept_btn\n- self.setLayout(input_layout)\n+\n+ main_layout.addLayout(context_layout)\n+ self.setLayout(main_layout)\nself.setWindowTitle(\"Switch selected items ...\")\nself.connections()\n@@ -522,8 +538,23 @@ class SwitchAssetDialog(QtWidgets.QDialog):\nsubsets = sorted(self._get_subsets())\nself._subsets_box.populate(subsets)\n- representations = sorted(self._get_representations())\n- self._representations_box.populate(representations)\n+ def set_labels(self):\n+ default = \"*No changes\"\n+ asset_label = default\n+ subset_label = default\n+ repre_label = default\n+\n+ if self._assets_box.currentText() != '':\n+ asset_label = self._assets_box.currentText()\n+ if self._subsets_box.currentText() != '':\n+ subset_label = self._subsets_box.currentText()\n+ if self._representations_box.currentText() != '':\n+ repre_label = self._representations_box.currentText()\n+\n+ self._asset_label.setText(asset_label)\n+ self._subset_label.setText(subset_label)\n+ self._repre_label.setText(repre_label)\n+\ndef _get_assets(self):\nfiltered_assets = []\n",
        "chatgpt_cot": "add checkbox to the message box for ignoring the message if clicked \"Don't show again\" to avoid showing the message again."
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/master_view_proxy.py b/node_manager_fkie/src/node_manager_fkie/master_view_proxy.py @@ -1427,10 +1427,6 @@ class MasterViewProxy(QWidget):\ntext += '<dt><b>URI</b>: %s</dt>' % node.node_info.uri\ntext += '<dt><b>PID</b>: %s</dt>' % node.node_info.pid\ntext += '<dt><b>ORG.MASTERURI</b>: %s</dt>' % node.node_info.masteruri\n- if node.nodelet_mngr:\n- text += '<dt><b>Nodelet manager</b>: %s</dt>' % node.nodelet_mngr\n- if node.nodelets:\n- text += '<dt>Manager for <b>%d</b> nodelets</dt>' % len(node.nodelets)\nif not is_legal_name(node.name):\ntext += '<dt><font color=\"#FF6600\"><b>This node has an illegal <node> name.<br><a href=\"http://ros.org/wiki/Names\">http://ros.org/wiki/Names</a><br>This will likely cause problems with other ROS tools.</b></font></dt>'\nif node.is_ghost:\n@@ -1463,6 +1459,10 @@ class MasterViewProxy(QWidget):\n# if len(node.diagnostic_array) > 1:\n# text += '<dt><font color=\"#FF6600\"><a href=\"view_diagnostics://%s\">view recent %d items</a></font></dt>'%(node.name, len(node.diagnostic_array))\ntext += '</dl>'\n+ if node.nodelet_mngr:\n+ text += '<dt><b>Nodelet manager</b>: %s</dt>' % self._create_html_list('', [node.nodelet_mngr], 'NODE')\n+ if node.nodelets:\n+ text += '<dt>Manager for <b>%d</b> nodelets</dt>' % len(node.nodelets)\nif nm.settings().transpose_pub_sub_descr:\ntext += self._create_html_list('Subscribed Topics:', node.subscribed, 'TOPIC_SUB', node.name)\ntext += self._create_html_list('Published Topics:', node.published, 'TOPIC_PUB', node.name)\n",
        "org_msg": "node_manager_fkie: added link for nodelet manager in description of nodelets",
        "sim_msg": "Also fixing sub views",
        "sim_diff": "diff --git a/app/__init__.py b/app/__init__.py @@ -648,10 +648,8 @@ def view_sub_new(sub, page):\nif not sub:\nabort(404)\n- posts = db.query('SELECT * FROM `sub_post` WHERE `sid`=%s AND '\n- '`deleted` != 1 ORDER BY `posted` DESC '\n- 'LIMIT %s,20',\n- (sub['sid'], (page - 1) * 20, )).fetchall()\n+ posts = misc.getPostList(misc.postListQueryBase().where(Sub.sid == sub['sid']),\n+ 'new', page).dicts()\nmods = db.get_sub_metadata(sub['sid'], 'mod2', _all=True)\ncreatetxtpost = CreateSubTextPost(sub=sub['name'])\ncreatelinkpost = CreateSubLinkPost(sub=sub['name'])\n@@ -710,9 +708,8 @@ def view_sub_top(sub, page):\nif not sub:\nabort(404)\n- posts = db.query('SELECT * FROM `sub_post` WHERE `sid`=%s AND'\n- '`deleted` != 1 ORDER BY `score` DESC LIMIT %s,20',\n- (sub['sid'], (page - 1) * 20, )).fetchall()\n+ posts = misc.getPostList(misc.postListQueryBase().where(Sub.sid == sub['sid']),\n+ 'top', page).dicts()\nmods = db.get_sub_metadata(sub['sid'], 'mod2', _all=True)\ncreatetxtpost = CreateSubTextPost(sub=sub['name'])\n@@ -735,17 +732,15 @@ def view_sub_hot(sub, page):\nif not sub:\nabort(404)\n- c = db.query('SELECT * FROM `sub_post` WHERE `sid`=%s AND '\n- '`deleted` != 1 LIMIT 500',\n- (sub['sid'], )).fetchall()\n- sorter = HotSorting(c)\n+ posts = misc.getPostList(misc.postListQueryBase().where(Sub.sid == sub['sid']),\n+ 'hot', page).dicts()\nmods = db.get_sub_metadata(sub['sid'], 'mod2', _all=True)\ncreatetxtpost = CreateSubTextPost(sub=sub['name'])\ncreatelinkpost = CreateSubLinkPost(sub=sub['name'])\nreturn render_template('sub.html', sub=sub, page=page,\nsort_type='view_sub_hot',\n- posts=sorter.getPosts(page), mods=mods,\n+ posts=posts, mods=mods,\ntxtpostform=createtxtpost,\nlnkpostform=createlinkpost)\n",
        "chatgpt_cot": "\"Refactor MasterViewProxy class by removing redundant code and adding new functionality to handle nodelet managers and nodelets.\""
    },
    {
        "org_diff": "diff --git a/sc2/action.py b/sc2/action.py @@ -11,13 +11,13 @@ def combine_actions(action_iter):\nif target is None:\ncmd = raw_pb.ActionRawUnitCommand(\nability_id=ability.value,\n- unit_tags=[u.unit.tag for u in items],\n+ unit_tags=list({u.unit.tag for u in items}),\nqueue_command=queue\n)\nelif isinstance(target, Point2):\ncmd = raw_pb.ActionRawUnitCommand(\nability_id=ability.value,\n- unit_tags=[u.unit.tag for u in items],\n+ unit_tags=list({u.unit.tag for u in items}),\nqueue_command=queue,\ntarget_world_space_pos=common_pb.Point2D(x=target.x, y=target.y)\n)\n",
        "org_msg": "Do not use same unit multiple times in one action",
        "sim_msg": "HL/LL random init_pos and target_pos",
        "sim_diff": "diff --git a/gibson2/envs/locomotor_env.py b/gibson2/envs/locomotor_env.py @@ -399,6 +399,12 @@ class NavigateEnv(BaseEnv):\ndone = True\ninfo['success'] = False\nelif p.getJointState(self.door.body_id, self.door_axis_link_id)[0] > (10.0 / 180.0 * np.pi):\n+ # # if door opens in the wrong way, reset it to neutral (closed)\n+ # p.setJointMotorControl2(bodyUniqueId=self.door.body_id,\n+ # jointIndex=self.door_axis_link_id,\n+ # controlMode=p.POSITION_CONTROL,\n+ # targetPosition=0.0,\n+ # force=500)\nprint('WRONG PUSH')\ndone = True\ninfo['success'] = False\n@@ -659,7 +665,8 @@ class InteractiveNavigateEnv(NavigateEnv):\n# pos = [0.0, 0.0, 0.0]\npos = [np.random.uniform(-2, 2), np.random.uniform(-2, 2), 0]\nelse:\n- pos = [1.5, 0.0, 0.0]\n+ # pos = [1.5, 0.0, 0.0]\n+ pos = [np.random.uniform(1, 2), np.random.uniform(-2, 2), 0]\n# pos = [0.0, 0.0, 0.0]\n# self.robots[0].set_position(pos=[pos[0], pos[1], pos[2] + 0.1])\nself.robots[0].set_position(pos=[pos[0], pos[1], pos[2]])\n@@ -667,7 +674,8 @@ class InteractiveNavigateEnv(NavigateEnv):\nif ONLY_LL:\nself.robots[0].set_orientation(orn=quatToXYZW(euler2quat(0, 0, np.random.uniform(0, np.pi * 2)), 'wxyz'))\nelse:\n- self.robots[0].set_orientation(orn=quatToXYZW(euler2quat(0, 0, np.pi), 'wxyz'))\n+ # self.robots[0].set_orientation(orn=quatToXYZW(euler2quat(0, 0, np.pi), 'wxyz'))\n+ self.robots[0].set_orientation(orn=quatToXYZW(euler2quat(0, 0, np.random.uniform(0, np.pi * 2)), 'wxyz'))\ncollision_links = []\nfor _ in range(self.simulator_loop):\n@@ -688,7 +696,8 @@ class InteractiveNavigateEnv(NavigateEnv):\n# self.target_pos = [-100, -100, 0]\nself.target_pos = [np.random.uniform(-2, 2), np.random.uniform(-2, 2), 0.0]\nelse:\n- self.target_pos = np.array([-1.5, 0.0, 0.0])\n+ # self.target_pos = np.array([-1.5, 0.0, 0.0])\n+ self.target_pos = [np.random.uniform(-2, -1), np.random.uniform(-2, 2), 0.0]\nself.door_handle_vis.set_position(pos=np.array(p.getLinkState(self.door.body_id, self.door_handle_link_id)[0]))\n@@ -847,7 +856,7 @@ class InteractiveNavigateEnv(NavigateEnv):\nif self.stage == self.stage_get_to_door_handle:\npotential = l2_distance(door_handle_pos, self.robots[0].get_end_effector_position())\nelif self.stage == self.stage_open_door:\n- potential = np.abs(door_angle + np.pi)\n+ potential = door_angle\nelif self.stage == self.stage_get_to_target_pos:\npotential = l2_distance(self.target_pos, self.get_position_of_interest())\n# print(\"get_potential (stage %d): %f\" % (self.stage, potential))\n@@ -994,6 +1003,7 @@ if __name__ == '__main__':\nfor i in range(500): # 500 steps, 50s world time\naction = nav_env.action_space.sample()\naction[:] = 0\n+ # action[:2] = 1.0\n# if nav_env.stage == 1:\n# action[:2] = -0.1\n",
        "chatgpt_cot": "Refactor unit_tags assignment in combine_actions to use set comprehension for uniqueness and clarity."
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/editor/editor.py b/node_manager_fkie/src/node_manager_fkie/editor/editor.py @@ -321,6 +321,7 @@ class Editor(QMainWindow):\nself._search_thread = TextSearchThread(search_text, filename, path_text=self.tabWidget.widget(0).document().toPlainText(), recursive=True)\nself._search_thread.search_result_signal.connect(self.on_search_result_on_open)\nself._search_thread.start()\n+ self.upperButton.setEnabled(self.tabWidget.count() > 1)\ndef on_text_changed(self, value=\"\"):\nif self.tabWidget.currentWidget().hasFocus():\n@@ -356,6 +357,7 @@ class Editor(QMainWindow):\nexcept Exception:\nimport traceback\nrospy.logwarn(\"Error while close tab %s: %s\", str(tab_index), traceback.format_exc(1))\n+ self.upperButton.setEnabled(self.tabWidget.count() > 1)\ndef reject(self):\nif self.find_dialog.isVisible():\n",
        "org_msg": "node_manager_fkie: enable / disable upper button",
        "sim_msg": "fix adding notebook page",
        "sim_diff": "diff --git a/widgets/notebook/notebook.py b/widgets/notebook/notebook.py @@ -130,12 +130,12 @@ class EditNotebook(ManagedBase, EditStylesMixin):\n# create panel and node, add to tree\nself.insert_item(None, index) # placeholder\nif add_panel:\n- panel_editor = panel.EditPanel( self.next_pane_name(), self, index )\n+ editor = panel.EditPanel( self.next_pane_name(), self, index )\nif add_sizer:\nsizer = edit_sizers._builder(panel_editor, 0)\nelse:\n# just add a slot\n- edit_base.Slot(self, index)\n+ editor = edit_base.Slot(self, index)\nif self.widget:\n# add to widget\n",
        "chatgpt_cot": "Enable upper button based on tab count in Editor class. Fix compilation issue due to missing upperButton enabled state update."
    },
    {
        "org_diff": "diff --git a/README.md b/README.md @@ -30,10 +30,21 @@ pip install --upgrade --force-reinstall https://github.com/BurnySc2/python-sc2/a\n```\nBoth commands will use the `sc2` library folder, so you will not be able to have Dentosal's and this fork installed at the same time, unless you use virtual environments or pipenv.\n+### StarCraft II\nYou'll need an StarCraft II executable. If you are running Windows or macOS, just install the normal SC2 from blizzard app. [The free starter edition works too.](https://us.battle.net/account/sc2/starter-edition/). Linux users get the best experience by installing the Windows version of StarCraft II with [Wine](https://www.winehq.org). Linux user can also use the [Linux binary](https://github.com/Blizzard/s2client-proto#downloads), but it's headless so you cannot actually see the game.\n-You probably want some maps too. Official map downloads are available from [Blizzard/s2client-proto](https://github.com/Blizzard/s2client-proto#downloads). Notice: the map files are to be extracted into *subdirectories* of the `install-dir/Maps` directory.\n-Maps that are run on the [SC2 AI Ladder](http://sc2ai.net/) and [SC2 AI Arena](https://ai-arena.net/) can be downloaded [from the sc2ai wiki](http://wiki.sc2ai.net/Ladder_Maps) and [the ai-arena wiki](https://ai-arena.net/wiki/getting-started/#wiki-toc-maps).\n+### Maps\n+You probably want some maps too.\n+\n+#### Official maps\n+Official Blizzard map downloads are available from [Blizzard/s2client-proto](https://github.com/Blizzard/s2client-proto#downloads).\n+Extract these maps into their respective *subdirectories* in the SC2 maps directory.\n+e.g. `install-dir/Maps/Ladder2017Season1/`\n+\n+#### Bot ladder maps\n+Maps that are run on the [SC2 AI Ladder](http://sc2ai.net/) and [SC2 AI Arena](https://ai-arena.net/) can be downloaded [from the sc2ai wiki](http://wiki.sc2ai.net/Ladder_Maps) and [the ai-arena wiki](https://ai-arena.net/wiki/bot-development/getting-started/#wiki-toc-maps).\n+**Extract these maps into the *root* of the SC2 maps directory** (otherwise ladder replays won't work).\n+e.g. `install-dir/Maps/AcropolisLE.SC2Map`\n### Running\n",
        "org_msg": "Update AI Arena maps link and improve map download instructions and formatting.",
        "sim_msg": "fixed another place where paths were not being created correctly",
        "sim_diff": "diff --git a/runner.py b/runner.py @@ -102,21 +102,21 @@ def main():\nname_dict = dict()\nsave_data = True\n- save_path = os.getcwd() + '/bot_code/training/replays'\n+ save_path = os.path.join(os.getcwd(), 'bot_code', 'training', 'replays')\ngame_name = str(int(round(time.time() * 1000))) + '-' + str(random.randint(0, 1000))\nif save_data:\nprint(save_path)\nif not os.path.exists(save_path):\nprint(os.path.dirname(save_path) + ' does not exist creating')\nos.makedirs(save_path)\n- if not os.path.exists(save_path + '\\\\' + game_name):\n- os.makedirs(save_path + '\\\\' + game_name)\n+ joined_path = os.path.join(save_path, game_name)\n+ if not os.path.exists(joined_path):\n+ os.makedirs(joined_path)\nprint('gameName: ' + game_name + 'in ' + save_path)\ngameInputPacket.iNumPlayers = num_participants\nserver_manager.load_config()\n-\nnum_team_0 = 0\n# Set configuration values for bots and store name and team\nfor i in range(num_participants):\n",
        "chatgpt_cot": "Refactor README.md for clarity and organization. Added subsections for maps, official maps, and bot ladder maps to improve readability and user guidance."
    },
    {
        "org_diff": "diff --git a/sc2/client.py b/sc2/client.py @@ -5,6 +5,9 @@ from s2clientprotocol import (\ndebug_pb2 as debug_pb\n)\n+import logging\n+logger = logging.getLogger(__name__)\n+\nfrom .cache import method_cache_forever\nfrom .protocol import Protocol\n@@ -50,9 +53,11 @@ class Client(Protocol):\nreturn result.join_game.player_id\nasync def save_replay(self, path):\n+ logger.debug(f\"Requesting replay from server\")\nresult = await self._execute(save_replay=sc_pb.RequestSaveReplay())\nwith open(path, \"wb\") as f:\nf.write(result.save_replay.data)\n+ logger.info(f\"Saved replay to {path}\")\nasync def observation(self):\nresult = await self._execute(observation=sc_pb.RequestObservation())\n",
        "org_msg": "Add logging for replay save operation",
        "sim_msg": "Use `mode.value` instead enumerate.",
        "sim_diff": "diff --git a/app/objects/player.py b/app/objects/player.py @@ -536,14 +536,14 @@ class Player:\nasync with app.state.services.database.connection() as db_conn:\nawait self.stats_from_sql_full(db_conn)\n- for idx, mode_stat in enumerate(self.stats.values()):\n+ for mode, stats in self.stats.items():\nawait app.state.services.redis.zadd(\n- f\"gulag:leaderboard:{idx}\",\n- {self.id: mode_stat.pp},\n+ f\"gulag:leaderboard:{mode.value}\",\n+ {self.id: stats.pp},\n)\nawait app.state.services.redis.zadd(\n- f\"gulag:leaderboard:{idx}:{self.geoloc['country']['acronym']}\",\n- {self.id: mode_stat.pp},\n+ f\"gulag:leaderboard:{mode.value}:{self.geoloc['country']['acronym']}\",\n+ {self.id: stats.pp},\n)\nif \"restricted\" in self.__dict__:\n",
        "chatgpt_cot": "Add logging to client.py for debugging and info purposes. Includes debug and info logs for save_replay method."
    },
    {
        "org_diff": "diff --git a/node_manager_daemon_fkie/src/node_manager_daemon_fkie/launch_servicer.py b/node_manager_daemon_fkie/src/node_manager_daemon_fkie/launch_servicer.py @@ -296,15 +296,15 @@ class LaunchServicer(lgrpc.LaunchServiceServicer):\nlaunch_config = LaunchConfig(launchfile, masteruri=request.masteruri, host=request.host)\n# get the list with needed launch args\nreq_args = launch_config.get_args()\n+ req_args_dict = launch_config.argv2dict(req_args)\nif request.request_args and req_args:\n- arg_dict = launch_config.argv2dict(req_args)\n- for arg, value in arg_dict.items():\n+ for arg, value in req_args_dict.items():\nif arg not in provided_args:\n- result.args.extend([lmsg.Argument(name=arg, value=value) for arg, value in arg_dict.items()])\n+ result.args.extend([lmsg.Argument(name=arg, value=value) for arg, value in req_args_dict.items()])\nresult.status.code = PARAMS_REQUIRED\nrospy.logdebug(\"..load aborted, PARAMS_REQUIRED\")\nreturn result\n- argv = [\"%s:=%s\" % (arg.name, arg.value) for arg in request.args]\n+ argv = [\"%s:=%s\" % (arg.name, arg.value) for arg in request.args if arg.name in req_args_dict]\n_loaded, _res_argv = launch_config.load(argv)\n# parse result args for reply\nresult.args.extend([lmsg.Argument(name=name, value=value) for name, value in launch_config.resolve_dict.items()])\n",
        "org_msg": "node_manager_daemon_fkie: fix load launch file\nselect only needed parameter from provided",
        "sim_msg": "Config loading: use the new array filtering method\nUse the same new way as in endpoint, to have a postgres array contains\noperator (the operator)",
        "sim_diff": "diff --git a/rest-service/manager_rest/config.py b/rest-service/manager_rest/config.py @@ -108,7 +108,10 @@ class Config(object):\ndef load_from_db(self):\nfrom manager_rest.storage import models, get_storage_manager\nsm = get_storage_manager()\n- for conf_value in sm.list(models.Config, filters={'scope': 'rest'}):\n+ stored_config = sm.list(models.Config, filters={\n+ 'scope': lambda column: column.contains(['rest'])\n+ })\n+ for conf_value in stored_config:\nsetattr(self, conf_value.name, conf_value.value)\ndef to_dict(self):\n",
        "chatgpt_cot": "Refactor LaunchServicer to use dictionary for launch args, improving readability and efficiency in launch_servicer.py."
    },
    {
        "org_diff": "diff --git a/Makefile b/Makefile @@ -179,9 +179,10 @@ check: ##@Code Check code format\ntest-case: ##@Code Run test case for flask server\n@$(MAKE) -C src/operator-dashboard/test/ all\n-clean: ##@Code Clean tox result\n+clean: docker-clean ##@Code Clean tox result, clean built images and db files\nrm -rf .tox .cache *.egg-info build/\nfind . -name \"*.pyc\" -o -name \"__pycache__\" | xargs rm -rf\n+ rm -rf /opt/cello/*\n# TODO (david_dornseier): As long as there are no release versions, always rewrite\n# the entire changelog (bug)\n",
        "org_msg": "Let `make clean` clean db files\nNow when run `make clean`, the built images, temp files and db files\nwill be cleaned. Then you can start with a fresh env.",
        "sim_msg": "Added coverage.xml to make clean command",
        "sim_diff": "diff --git a/Makefile b/Makefile @@ -27,7 +27,7 @@ docs:\nclean:\nrm -rf venv .tox ./**/__pycache__\nrm -rf dist build .egg .eggs arrow.egg-info\n- rm -f ./**/*.pyc .coverage\n+ rm -f ./**/*.pyc .coverage coverage.xml\npublish:\nrm -rf dist build .egg .eggs arrow.egg-info\n",
        "chatgpt_cot": "Refactor Makefile to include docker-clean in clean target, remove /opt/cello/ directory, and update changelog rewriting process for future versions."
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/select_dialog.py b/node_manager_fkie/src/node_manager_fkie/select_dialog.py @@ -225,10 +225,12 @@ class SelectDialog(QDialog):\n# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\ndef accept(self):\n+ self.cancel_autoclose()\nself.setResult(QDialog.Accepted)\nself.hide()\ndef reject(self):\n+ self.cancel_autoclose()\nself.setResult(QDialog.Rejected)\nself.hide()\n@@ -239,6 +241,7 @@ class SelectDialog(QDialog):\n'''\nTest the open files for changes and save this if needed.\n'''\n+ self.cancel_autoclose()\nself.setAttribute(Qt.WA_DeleteOnClose, True)\nQDialog.closeEvent(self, event)\n",
        "org_msg": "node_manager_fkie: fixed error in select_dialog on close node_manager",
        "sim_msg": "import files directory defaults to user setting not Home",
        "sim_diff": "diff --git a/qualcoder/manage_files.py b/qualcoder/manage_files.py @@ -104,6 +104,7 @@ class DialogManageFiles(QtWidgets.QDialog):\nsys.excepthook = exception_handler\nself.app = app\n+ self.default_import_directory = self.app.settings['directory']\nself.parent_textEdit = parent_textEdit\nself.dialogList = []\nself.attributes = []\n",
        "chatgpt_cot": "\"Fix issue with cancel_autoclose method in SelectDialog file\""
    },
    {
        "org_diff": "diff --git a/user-dashboard/src/app/assets/src/routes/Chain/index.js b/user-dashboard/src/app/assets/src/routes/Chain/index.js @@ -46,6 +46,13 @@ export default class CardList extends PureComponent {\n})\n);\n};\n+ clickChain = (chain) => {\n+ this.props.dispatch(\n+ routerRedux.push({\n+ pathname: `/chain/info/${chain._id}`,\n+ })\n+ );\n+ };\nrender() {\nconst { chain: { chains }, loading } = this.props;\n@@ -82,6 +89,7 @@ export default class CardList extends PureComponent {\n<Avatar size=\"large\" style={{ backgroundColor: '#08c' }} icon=\"link\" />\n}\ntitle={<a href=\"#\">{item.name}</a>}\n+ onClick={() => this.clickChain(item)}\ndescription={\n<Ellipsis className={styles.item} lines={3}>\n{item.type}\n",
        "org_msg": "Allow jump to chain info when click chain\nIn chain list page, can jump to info page when click chain card.",
        "sim_msg": "Fixing version sref on system index page",
        "sim_diff": "diff --git a/src/ui/src/js/controllers/request_index.js b/src/ui/src/js/controllers/request_index.js @@ -161,7 +161,11 @@ export default function requestIndexController(\n.withTitle('Version')\n.renderWith(function(data, type, full) {\n- return `<a ui-sref=\"base.system({systemName: '${full.system}', systemVersion: '${full.system_version}', namespace: '${full.namespace}')\">` + data + '</a>';\n+ return `<a ui-sref=\"base.system({\n+ systemName: '${full.system}',\n+ systemVersion: '${full.system_version}',\n+ namespace: '${full.namespace}'})\"\n+ >${data}</a>`;\n}),\nDTColumnBuilder\n.newColumn('instance_name')\n",
        "chatgpt_cot": "Add clickChain method to handle chain click event in CardList component. Fix routing issue by pushing chain id to URL on chain click."
    },
    {
        "org_diff": "diff --git a/sc2/bot_ai.py b/sc2/bot_ai.py @@ -630,11 +630,9 @@ class BotAI(DistanceCalculation):\ncost = self.calculate_cost(item_id)\nif cost.minerals > self.minerals or cost.vespene > self.vespene:\nreturn False\n- if (\n- check_supply_cost\n- and isinstance(item_id, UnitTypeId)\n- and self.calculate_supply_cost(item_id) > self.supply_left\n- ):\n+ if check_supply_cost and isinstance(item_id, UnitTypeId):\n+ supply_cost = self.calculate_supply_cost(item_id)\n+ if supply_cost and supply_cost > self.supply_left:\nreturn False\nreturn True\n",
        "org_msg": "Fix can_afford shortcut",
        "sim_msg": "Fixes based on the PR comments",
        "sim_diff": "diff --git a/packages/fetchai/skills/tac_control_contract/game.py b/packages/fetchai/skills/tac_control_contract/game.py @@ -889,7 +889,7 @@ class Game(Model):\n+ \"\\n\"\n)\nfor good_id, quantity in agent_state.quantities_by_good_id.items():\n- result += \" \" + str(good_id) + \": \" + str(quantity) + \"\\n\"\n+ result += \" \" + good_id + \": \" + str(quantity) + \"\\n\"\nfor currency_id, amount in agent_state.amount_by_currency_id.items():\nresult += \" \" + currency_id + \": \" + str(amount) + \"\\n\"\nresult += \" score: \" + str(round(agent_state.get_score(), 2)) + \"\\n\"\n@@ -901,7 +901,7 @@ class Game(Model):\n\"\"\"Get equilibrium summary.\"\"\"\nresult = \"\\n\" + \"Equilibrium prices: \\n\"\nfor good_id, eq_price in self.initialization.good_id_to_eq_prices.items():\n- result = result + str(good_id) + \" \" + str(eq_price) + \"\\n\"\n+ result = result + good_id + \" \" + str(eq_price) + \"\\n\"\nresult = result + \"\\n\"\nresult = result + \"Equilibrium good allocation: \\n\"\nfor (\n@@ -915,7 +915,7 @@ class Game(Model):\n+ \":\\n\"\n)\nfor good_id, quantity in eq_allocations.items():\n- result = result + \" \" + str(good_id) + \": \" + str(quantity) + \"\\n\"\n+ result = result + \" \" + good_id + \": \" + str(quantity) + \"\\n\"\nresult = result + \"\\n\"\nresult = result + \"Equilibrium money allocation: \\n\"\nfor (\n",
        "chatgpt_cot": "\"Refactor supply cost calculation in BotAI class to improve readability and simplify conditional check for supply cost and minerals/vespene.\""
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/CMakeLists.txt b/node_manager_fkie/CMakeLists.txt @@ -45,3 +45,10 @@ install(\n./src/node_manager_fkie/GUI.qrc\nDESTINATION ${CATKIN_PACKAGE_PYTHON_DESTINATION}\n)\n+\n+install(\n+ FILES\n+ ./src/node_manager_fkie/editor/GraphDockWidget.ui\n+ DESTINATION ${CATKIN_PACKAGE_PYTHON_DESTINATION}/editor/\n+)\n+\n",
        "org_msg": "node_manager_fkie: fixed install problem",
        "sim_msg": "Fix the fact that Python uses 'pip' not 'npm'",
        "sim_diff": "diff --git a/Makefile b/Makefile @@ -28,7 +28,7 @@ install:\nbash -lc '$(CONDAUPDATE) pip install --upgrade .'\ninstall-dev:\n- bash -lc '$(CONDAUPDATE) pip install pipreqs sphinx; npm install -g apidoc brunch; npm install -e .; cd frontend/ && npm install'\n+ bash -lc '$(CONDAUPDATE) pip install pipreqs sphinx; npm install -g apidoc brunch; pip install -e .; cd frontend/ && npm install'\ninstall-msr:\n@ ./docs/install-msr.sh\n",
        "chatgpt_cot": "Add installation for GraphDockWidget.ui in node_manager_fkie/CMakeLists.txt. This modification allows the file to be installed in the specified destination."
    },
    {
        "org_diff": "diff --git a/rasa_core_sdk/__init__.py b/rasa_core_sdk/__init__.py @@ -33,7 +33,8 @@ class Tracker(object):\nstate.get(\"latest_action_name\"))\ndef __init__(self, sender_id, slots,\n- latest_message, events, paused, followup_action, active_form, latest_action_name):\n+ latest_message, events, paused, followup_action,\n+ active_form, latest_action_name):\n\"\"\"Initialize the tracker.\"\"\"\n# list of previously seen events\n",
        "org_msg": "break long line RasaHQ/roadmap#280",
        "sim_msg": "re-enable sql migrations",
        "sim_diff": "diff --git a/app/api/init_api.py b/app/api/init_api.py @@ -86,6 +86,8 @@ def init_events(asgi_app: FastAPI) -> None:\n)\napp.state.services.datadog.gauge(\"gulag.online_players\", 0)\n+ await app.state.services.run_sql_migrations()\n+\nasync with app.state.services.database.connection() as db_conn:\nawait collections.initialize_ram_caches(db_conn)\n",
        "chatgpt_cot": "Refactor Tracker class constructor to remove unnecessary parameter and improve code readability."
    },
    {
        "org_diff": "diff --git a/MAINTAINERS.md b/MAINTAINERS.md |---|---|---|---|\n| Baohua Yang | yeasy | baohua | yangbaohua@gmail.com |\n| Haitao Yue | hightall | hightall | hightallyht@gmail.com |\n-| Tong Li | tongli | tongli | litong01@us.ibm.com |\n| Qiang Xu | XuHugo | XuHugo | xq-310@163.com |\n## Retired Maintainers\n| Name | GitHub | RocketChat | Email |\n|---|---|---|---|\n| Luke Chen | LordGoodman | luke_chen | jiahaochen1993@gmail.com |\n+| Tong Li | tongli | tongli | litong01@us.ibm.com |\n<a rel=\"license\" href=\"http://creativecommons.org/licenses/by/4.0/\"><img alt=\"Creative Commons License\" style=\"border-width:0\" src=\"https://i.creativecommons.org/l/by/4.0/88x31.png\" /></a><br />This work is licensed under a <a rel=\"license\" href=\"http://creativecommons.org/licenses/by/4.0/\">Creative Commons Attribution 4.0 International License</a>.\n",
        "org_msg": "Retire maintainer Tong Li\nTong has been inactive for more than 3 months, and he will focus on\nother project, without time to continue the contribution.\nThanks for his past contributions.",
        "sim_msg": "updated top-level README",
        "sim_diff": "diff --git a/README.md b/README.md # ACL Anthology\n-(This repo was originally wing-nus/acl and has been transferred over to acl-org\n-as of 5 Jun 2017. Please update accordingly.)\n-\n-These are basic instructions on generating the ACL Anthology website as seen on\n-<https://aclweb.org/anthology/>.\n-\n+These are basic instructions on generating the ACL Anthology website as seen on <https://aclweb.org/anthology/>.\n+The offical home of this repository is <https://github.com/acl-org/acl-anthology>.\n## Generating the Anthology\n@@ -64,21 +60,18 @@ about a minute to start.\n## Contributing\n-If you'd like to contribute to the ACL Anthology, please take a look at our\n-[information on volunteering](https://aclanthology.info/volunteer) and the\n-[detailed README](README_detailed.md) containing more in-depth information about\n-generating and modifying the website.\n+If you'd like to contribute to the ACL Anthology, please take a look at:\n+- our [Github issues page](https://github.com/acl-org/acl-anthology/issues)\n+- our [call for volunteers](https://aclanthology.info/volunteer)\n+- the [detailed README](README_detailed.md) which contains more in-depth information about generating and modifying the website.\n-## License\n+## History\n-Materials prior to 2016 here are licensed under the [Creative Commons\n-Attribution-NonCommercial-ShareAlike 3.0 International\n-License](https://creativecommons.org/licenses/by-nc-sa/3.0/). Permission is\n-granted to make copies for the purposes of teaching and research. Materials\n-published in or after 2016 are licensed on a [Creative Commons Attribution 4.0\n-License](https://creativecommons.org/licenses/by/4.0/).\n+This repo was originally wing-nus/acl and has been transferred over to acl-org as of 5 June 2017.\n-Matt Post (Editor, 2019-) / Min-Yen Kan (Editor, 2008-2018) / Steven Bird (Editor, 2001-2007)\n+## License\n-Developer team: Linh Hien Ng (linhhienng at gmail dot com), Duong Ho Tuan zamakkat at gmail dot com)\n+Materials prior to 2016 here are licensed under the [Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License](https://creativecommons.org/licenses/by-nc-sa/3.0/).\n+Permission is granted to make copies for the purposes of teaching and research.\n+Materials published in or after 2016 are licensed on a [Creative Commons Attribution 4.0 License](https://creativecommons.org/licenses/by/4.0/).\n",
        "chatgpt_cot": "\"Update MAINTAINERS.md to include retired maintainer Tong Li, reflecting changes in the project's maintainership.\""
    },
    {
        "org_diff": "diff --git a/Makefile b/Makefile @@ -29,13 +29,13 @@ RESET := $(shell tput -Txterm sgr0)\nARCH := $(shell uname -m)\n# changelog specific version tags\n-PREV_VERSION?=0.8.0-beta\n+PREV_VERSION?=0.8.0\n# Building image usage\nDOCKER_NS ?= hyperledger\nBASENAME ?= $(DOCKER_NS)/cello\n-VERSION ?= 0.8.0\n-IS_RELEASE=true\n+VERSION ?= 0.9.0\n+IS_RELEASE=false\nDOCKER_BASE_x86_64=ubuntu:xenial\nDOCKER_BASE_ppc64le=ppc64le/ubuntu:xenial\n",
        "org_msg": "Update Flags for v0.9.0 release\nUpdate PREV_VERSION, IS_RELEASE & VERSION flags\nto prepare for v0.9.0",
        "sim_msg": "UI now has a latest docker tag",
        "sim_diff": "diff --git a/src/ui/Makefile b/src/ui/Makefile @@ -72,8 +72,9 @@ package: clean ## builds distribution\n# Docker\ndocker-build: package ## build docker image\n- docker build -t $(DOCKER_NAME):$(VERSION) .\n- docker tag $(DOCKER_NAME):$(VERSION) $(DOCKER_NAME):$(SHORT_VERSION)\n+ docker build -t $(DOCKER_NAME):latest .\n+ docker tag $(DOCKER_NAME):latest $(DOCKER_NAME):$(VERSION)\n+ docker tag $(DOCKER_NAME):latest $(DOCKER_NAME):$(SHORT_VERSION)\ndocker-build-unstable: package ## build nightly docker image\ndocker build -t $(DOCKER_NAME):unstable .\n@@ -81,6 +82,7 @@ docker-build-unstable: package ## build nightly docker image\n# Publishing\npublish-docker: docker-build ## push the docker image\n+ docker push $(DOCKER_NAME):latest\ndocker push $(DOCKER_NAME):$(VERSION)\ndocker push $(DOCKER_NAME):$(SHORT_VERSION)\n",
        "chatgpt_cot": "Update Makefile to change version from 0.8.0 to 0.9.0 and set IS_RELEASE to false, reflecting changes in the project's version and release status."
    },
    {
        "org_diff": "diff --git a/.github/workflows/pythonactions.yml b/.github/workflows/pythonactions.yml @@ -10,7 +10,7 @@ jobs:\n# Run pytest tests on pickle files (pre-generated SC2 API observations)\nname: Run pytest\nruns-on: ${{ matrix.os }}\n- timeout-minutes: 10\n+ timeout-minutes: 30\nstrategy:\nfail-fast: false\nmatrix:\n",
        "org_msg": "Github actions: increase timeout to 30 minutes",
        "sim_msg": "add retry-step to pytests to protect from flakes\npytest-envoy and pytest-envoy-v2 flake semi-frequently.  Do a built in\n3 strikes system so that we don't have to re-execute manually.",
        "sim_diff": "diff --git a/.github/workflows/execute-pytests.yml b/.github/workflows/execute-pytests.yml @@ -96,8 +96,12 @@ jobs:\necho 'DEV_KUBECONFIG=~/.kube/kubeception.yaml' >> $GITHUB_ENV\nfi\n- name: make pytest-${{ matrix.test }} (legacy-mode:${{ matrix.pytest-settings.legacy-mode }}, fast-reconfigure:${{ matrix.pytest-settings.fast-reconfigure }} )\n- timeout-minutes: 30\n- run: |\n+ uses: nick-invision/retry@v2.4.0\n+ with:\n+ max_attempts: 3\n+ timeout_minutes: 20\n+ on_retry_command: unset CI\n+ command: |\nexport DEV_KUBE_NO_PVC=yes\nexport KAT_REQ_LIMIT=900\nexport AMBASSADOR_LEGACY_MODE=${{ matrix.pytest-settings.legacy-mode }}\n",
        "chatgpt_cot": "Increase timeout to 30 minutes in pythonactions.yml workflow file to allow sufficient time for pytest tests on pre-generated SC2 API observations."
    },
    {
        "org_diff": "diff --git a/src/agent/ansible/roles/deploy_compose/plays.yml b/src/agent/ansible/roles/deploy_compose/plays.yml - \"./../../vars/{{ env }}.yml\"\ntasks:\n- include_tasks: \"composersetup/tasks/{{ mode }}.yml\"\n+ when: fabric.composer == true or fabric.composer is undefined\ntags: \"composersetup\"\n",
        "org_msg": "Make deployment of HL Composer optional\nAdds a conditional switch to the ansible task to deploy\ncomposer, which defaults to 'true' so that original\nbehavior is preserved when no setting is provided.",
        "sim_msg": "Use state \"present\" instead of \"installed\"\nThe latter is deprecated and due to be removed in Ansible v2.9.",
        "sim_diff": "diff --git a/ansible/roles/setup/tasks/main.yml b/ansible/roles/setup/tasks/main.yml become: yes\napt:\npkg: apt-transport-https\n- state: installed\n+ state: present\n- name: Add NodeSource apt signing key\nbecome: yes\nbecome: yes\napt:\npkg: \"{{ item }}\"\n- state: installed\n+ state: present\nwith_items:\n- apt-transport-https\n- ca-certificates\nbecome: yes\napt:\npkg: \"{{item}}\"\n- state: installed\n+ state: present\nwith_items:\n- nodejs\nbecome: yes\napt:\npkg: \"{{ item }}\"\n- state: installed\n+ state: present\nwith_items:\n- postgresql-9.5-postgis-2.2\n- postgresql-server-dev-9.5 # required for building pyscopg against correct postgres\n",
        "chatgpt_cot": "\"Add condition to include tasks based on fabric.composer value in plays.yml\""
    },
    {
        "org_diff": "diff --git a/Makefile b/Makefile @@ -182,6 +182,7 @@ test-case: ##@Code Run test case for flask server\nclean:\nmake remove-docker-compose\n+\ndeep-clean:\nmake clean\nmake image-clean\n@@ -222,14 +223,12 @@ start: ##@Service Start service\nstop-docker-compose:\necho \"Stop all services with bootup/docker-compose-files/${COMPOSE_FILE}...\"\ndocker-compose -f bootup/docker-compose-files/${COMPOSE_FILE} stop\n- echo \"Stop all hyperledger-fabric nodes ...\"\n- docker ps | grep \"hyperledger-fabric\" | awk '{print $1}' | xargs docker stop\n+\nremove-docker-compose:\necho \"Remove all services with ${COMPOSE_FILE}...\"\ndocker-compose -f bootup/docker-compose-files/${COMPOSE_FILE} down -v\n- echo \"Remove all hyperledger-fabric nodes ...\"\n- docker ps -a | grep \"hyperledger-fabric\" | awk '{print $1}' | xargs docker rm -f\n+ rm -rf /opt/cello\nstart-k8s:\n@$(MAKE) -C bootup/kubernetes init-yaml\n",
        "org_msg": "Remove local volume",
        "sim_msg": "[ci] Fix buildkit make target",
        "sim_diff": "diff --git a/ci/Makefile b/ci/Makefile @@ -35,7 +35,8 @@ build-ci-utils: service-base\n.PHONY: build-hail-buildkit\nbuild-hail-buildkit:\n- ../docker-build.sh . buildkit/Dockerfile $(HAIL_BUILDKIT_IMAGE)\n+ python3 jinja2_render.py '{\"global\":{\"docker_prefix\":\"$(DOCKER_PREFIX)\"}}' buildkit/Dockerfile buildkit/Dockerfile.out\n+ ../docker-build.sh . buildkit/Dockerfile.out $(HAIL_BUILDKIT_IMAGE)\n.PHONY: build\nbuild: service-base\n",
        "chatgpt_cot": "\"Refactor Makefile, remove hyperledger-fabric nodes stop and remove commands, add deep-clean target, and start-k8s target for Kubernetes initialization.\""
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/nodes/script_runner.py b/node_manager_fkie/nodes/script_runner.py @@ -168,9 +168,11 @@ if __name__ == '__main__':\nif reserr:\nrospy.logwarn(\"stop script has follow exception: %s\" % reserr)\nelse:\n- runthread.stop()\n+ runthread.stop = True\nrunthread.join(3)\nif runthread.is_alive():\nrospy.logwarn(\"Script does not stop, try to kill %d...\" % runthread.spopen.popen.pid)\nif runthread.spopen is not None:\nrunthread.spopen.popen.send_signal(signal.SIGKILL)\n+ if runthread.spopen is not None:\n+ runthread.spopen.popen.send_signal(signal.SIGTERM)\n",
        "org_msg": "node_manager_fkie: fixed the end process",
        "sim_msg": "Removing redundant log statement",
        "sim_diff": "diff --git a/src/app/beer_garden/local_plugins/manager.py b/src/app/beer_garden/local_plugins/manager.py @@ -187,7 +187,6 @@ class PluginManager(StoppableThread):\n# ...and then kill it if necessary\nif runner.is_alive():\n- self.logger.warning(f\"Runner {runner_id} still alive, about to SIGKILL\")\nrunner.kill()\nrunner.stopped = True\n",
        "chatgpt_cot": "\"Fix stop script functionality in script_runner.py\""
    },
    {
        "org_diff": "diff --git a/fkie_node_manager/src/fkie_node_manager/master_view_proxy.py b/fkie_node_manager/src/fkie_node_manager/master_view_proxy.py @@ -1426,7 +1426,7 @@ class MasterViewProxy(QWidget):\nelif list_type == 'SERVICE':\ntry:\nsrv = self.__master_info.getService(i)\n- if name in srv.serviceProvider:\n+ if srv is not None and name in srv.serviceProvider:\nitem = '<tr>'\nitem += '<td><a href=\"servicecall://%s%s\"><span style=\"color:gray;\"><i>call</i></span></a><td>' % (self.mastername, i)\nitem += '<td><a href=\"service://%s%s\">%s</a><td>' % (self.mastername, i, item_name)\n",
        "org_msg": "fkie_node_manager: fixed not sync view of services",
        "sim_msg": "Fix part name display",
        "sim_diff": "diff --git a/InvenTree/static/script/inventree/stock.js b/InvenTree/static/script/inventree/stock.js @@ -64,7 +64,7 @@ function updateStock(items, options={}) {\nhtml += '<tr>';\n- html += '<td>' + item.part.name + '</td>';\n+ html += '<td>' + item.part.full_name + '</td>';\nif (item.location) {\nhtml += '<td>' + item.location.name + '</td>';\n@@ -289,7 +289,7 @@ function moveStockItems(items, options) {\nhtml += \"<tr>\";\n- html += \"<td>\" + item.part.name + \"</td>\";\n+ html += \"<td>\" + item.part.full_name + \"</td>\";\nhtml += \"<td>\" + item.location.pathstring + \"</td>\";\nhtml += \"<td>\" + item.quantity + \"</td>\";\n",
        "chatgpt_cot": "Fix the conditional expression in MasterViewProxy. Fix the conditional expression to check if srv is not None before accessing serviceProvider."
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/echo_dialog.py b/node_manager_fkie/src/node_manager_fkie/echo_dialog.py @@ -694,7 +694,6 @@ class EchoDialog(QDialog):\n:param field_filter: filter the fields that are strified for Messages, ``fn(Message)->iter(str)``\n:returns: string (YAML) representation of message, ``str``\n\"\"\"\n-\ntype_ = type(val)\nif type_ in (int, long, float) and fixed_numeric_width is not None:\nif type_ is float:\n@@ -754,7 +753,7 @@ class EchoDialog(QDialog):\nslot_name = f\nif isinstance(cval, (list, tuple)):\nslot_name = \"%s[%d]\" % (f, len(cval))\n- slots.append(p % (utf8(slot_name), self.strify_message(utf8(cval), ni, time_offset, current_time, field_filter, fixed_numeric_width)))\n+ slots.append(p % (utf8(slot_name), self.strify_message(cval, ni, time_offset, current_time, field_filter, fixed_numeric_width)))\nvals = '\\n'.join(slots)\nif indent:\nreturn '\\n' + vals\n",
        "org_msg": "node_manager_fkie: fix round floats in echo dialog",
        "sim_msg": "adding support for n9k on show_platform parser",
        "sim_diff": "diff --git a/nxos/show_platform.py b/nxos/show_platform.py @@ -739,7 +739,7 @@ class ShowModuleSchema(MetaParser):\n'mac_address': str,\n'serial_number': str,\n'online_diag_status': str,\n- Optional('world_wide_name'): str}\n+ Optional('slot/world_wide_name'): str}\n},\n},\n'lc':\n@@ -753,7 +753,7 @@ class ShowModuleSchema(MetaParser):\n'mac_address': str,\n'serial_number': str,\n'online_diag_status': str,\n- Optional('world_wide_name'): str}\n+ Optional('slot/world_wide_name'): str}\n},\n}\n},\n@@ -856,7 +856,7 @@ class ShowModule(ShowModuleSchema):\nmodule_dict['xbar'][header_number]['status'] = m.groupdict()['status'].strip()\ncontinue\n- p4 = re.compile(r'^\\s*(?P<number>[0-9]+) +(?P<software>[A-Z0-9\\(\\)\\.]+) +(?P<hardware>[0-9\\.]+)( +)?(?P<world_wide_name>[\\-]+)?$')\n+ p4 = re.compile(r'^\\s*(?P<number>[0-9]+) +(?P<software>[A-Z0-9\\(\\)\\.]+) +(?P<hardware>[0-9\\.]+)( +)?(?P<world_wide_name>[A-Z\\-]+)?$')\nm = p4.match(line)\nif m:\nheader_number = m.groupdict()['number']\n@@ -872,14 +872,14 @@ class ShowModule(ShowModuleSchema):\nmodule_dict['slot']['lc'][header_number][lc_name]['hardware'] = m.groupdict()['hardware'].strip()\nif world_wide_name:\nif header_number in rp_list:\n- module_dict['slot']['rp'][header_number][rp_name]['world_wide_name'] = m.groupdict()['world_wide_name'].strip()\n+ module_dict['slot']['rp'][header_number][rp_name]['slot/world_wide_name'] = m.groupdict()['world_wide_name'].strip()\nelse:\n- module_dict['slot']['lc'][header_number][lc_name]['world_wide_name'] = m.groupdict()['world_wide_name'].strip()\n+ module_dict['slot']['lc'][header_number][lc_name]['slot/world_wide_name'] = m.groupdict()['world_wide_name'].strip()\nelif table_header is 'xbar':\nmodule_dict['xbar'][header_number]['software'] = m.groupdict()['software'].strip()\nmodule_dict['xbar'][header_number]['hardware'] = m.groupdict()['hardware'].strip()\nif world_wide_name:\n- module_dict['xbar'][header_number]['world_wide_name'] = m.groupdict()['world_wide_name']\n+ module_dict['xbar'][header_number]['slot/world_wide_name'] = m.groupdict()['world_wide_name']\ncontinue\np5 = re.compile(r'^\\s*(?P<number>[0-9]+) +(?P<mac_address>[a-zA-Z0-9\\.\\-\\s]+) +(?P<serial_number>[A-Z0-9]+)$')\n",
        "chatgpt_cot": "fix compilation issue due to the modification of the strify_message method in EchoDialog."
    },
    {
        "org_diff": "diff --git a/src/api-engine/api_engine/settings.py.example b/src/api-engine/api_engine/settings.py.example @@ -11,7 +11,7 @@ https://docs.djangoproject.com/en/2.1/ref/settings/\n\"\"\"\nimport os\n-import datetime\n+from datetime import timedelta\n# Build paths inside the project like this: os.path.join(BASE_DIR, ...)\nBASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))\n@@ -216,6 +216,7 @@ MEDIA_URL = \"$WEBROOT/media/\"\nCELERY_BROKER_URL = \"$CELERY_BROKER_URL\"\nSIMPLE_JWT = {\n+ 'ACCESS_TOKEN_LIFETIME': timedelta(hours=1),\n'ROTATE_REFRESH_TOKENS': False,\n'BLACKLIST_AFTER_ROTATION': False,\n'UPDATE_LAST_LOGIN': False,\n",
        "org_msg": "Extend token expire duration\nThe token would expire in 30 seconds originally if no request is\nsent from frontend.\nSet the expire time to 60 mins now.",
        "sim_msg": "Add static host configuration for CDN",
        "sim_diff": "diff --git a/config/settings.py b/config/settings.py @@ -258,8 +258,9 @@ MIDDLEWARE = [\n# -----------------------------------------------------------------------------\n# https://docs.djangoproject.com/en/dev/ref/settings/#static-root\nSTATIC_ROOT = str(ROOT_DIR(\"staticfiles\"))\n+STATIC_HOST = env.str(\"AMY_STATIC_HOST\", default=\"\")\n# https://docs.djangoproject.com/en/dev/ref/settings/#static-url\n-STATIC_URL = \"/static/\"\n+STATIC_URL = f\"{STATIC_HOST}/static/\"\n# https://docs.djangoproject.com/en/dev/ref/contrib/staticfiles/#std:setting-STATICFILES_DIRS\nSTATICFILES_DIRS = [\nstr(APPS_DIR.path(\"static\")),\n",
        "chatgpt_cot": "\"Fix datetime import and add access token lifetime in settings\""
    },
    {
        "org_diff": "diff --git a/src/api-engine/api/lib/peer/channel.py b/src/api-engine/api/lib/peer/channel.py @@ -30,12 +30,14 @@ class Channel(BasicEnv):\ndef list(self):\ntry:\n- res = os.system(\"{} channel list\".format(self.peer))\n+ res = os.system(\"{} channel list > ./list.txt\".format(self.peer))\n+ with open('./list.txt', 'r', encoding='utf-8') as f:\n+ content = f.read()\nres = res >> 8\nexcept Exception as e:\nerr_msg = \"get channel list failed for {}!\".format(e)\nraise Exception(err_msg)\n- return res\n+ return res, content\ndef update(self, channel, channel_tx, orderer_url):\n\"\"\"\n@@ -115,11 +117,13 @@ class Channel(BasicEnv):\n\"\"\"\ntry:\nres = os.system(\n- \"{} channel getinfo -c {}\".format(self.peer, channel)\n+ \"{} channel getinfo -c {} > ./getinfo.txt\".format(self.peer, channel)\n)\n+ with open('./getinfo.txt', 'r', encoding='utf-8') as f:\n+ content = f.read()\nexcept Exception as e:\nerr_msg = \"get blockchain information of a specified channel failed. {}\".format(\ne)\nraise Exception(err_msg)\nres = res >> 8\n- return res\n+ return res, content\n",
        "org_msg": "[#issue-313] cmdline lib function list and getinfo has no info return\nAdded information processing of function list and function getinfo\nClose #issue-313",
        "sim_msg": "Testing Order Change in Swagger Def",
        "sim_diff": "diff --git a/flask-nginx-rtmp-mgmt/apiv1.py b/flask-nginx-rtmp-mgmt/apiv1.py @@ -35,12 +35,6 @@ channelParserPost.add_argument('topicID', type=int, required=True)\n@api.route('/channels/')\nclass api_1_ListChannels(Resource):\n- def get(self):\n- \"\"\"\n- Gets a List of all Public Channels\n- \"\"\"\n- channelList = Channel.Channel.query.all()\n- return {'results': [ob.serialize() for ob in channelList]}\n# Channel - Create Channel\n@api.expect(channelParserPost)\n@api.doc(security='apikey')\n@@ -50,16 +44,17 @@ class api_1_ListChannels(Resource):\nCreates a New Channel\n\"\"\"\nreturn {'results': {'message':'Channel Created'}}, 200\n+ # Channel - Get all Channels\n+ def get(self):\n+ \"\"\"\n+ Gets a List of all Public Channels\n+ \"\"\"\n+ channelList = Channel.Channel.query.all()\n+ return {'results': [ob.serialize() for ob in channelList]}\n@api.route('/channels/<string:channelEndpointID>')\n@api.doc(params={'channelEndpointID': 'Channel Endpoint Descriptor, Expressed in a UUID Value(ex:db0fe456-7823-40e2-b40e-31147882138e)'})\nclass api_1_ListChannel(Resource):\n- def get(self, channelEndpointID):\n- \"\"\"\n- Get Info for One Channel\n- \"\"\"\n- channelList = Channel.Channel.query.filter_by(channelLoc=channelEndpointID).all()\n- return json.dumps({'results': [ob.serialize() for ob in channelList]})\n# Channel - Change Channel Name or Topic ID\n@api.expect(channelParserPut)\n@api.doc(security='apikey')\n@@ -76,7 +71,13 @@ class api_1_ListChannel(Resource):\npass\nreturn {'results': {'message':'Channel Updated'}}, 200\nelse:\n- return {'results': {'message':'Request Error'}}, 400\n+ return {'results': {'message':'Request Error'}},\n+ def get(self, channelEndpointID):\n+ \"\"\"\n+ Get Info for One Channel\n+ \"\"\"\n+ channelList = Channel.Channel.query.filter_by(channelLoc=channelEndpointID).all()\n+ return json.dumps({'results': [ob.serialize() for ob in channelList]})\n@api.route('/streams/')\nclass api_1_ListStreams(Resource):\n",
        "chatgpt_cot": "\"Fix compilation issue by redirecting command output to a file and reading the content from the file for list and getinfo methods.\""
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/message_frame.py b/node_manager_fkie/src/node_manager_fkie/message_frame.py @@ -81,6 +81,9 @@ class MessageQueue(object):\nelse:\nself._queue[questionid].append(('', data))\nelse:\n+ for txt, dt in self._queue[questionid]:\n+ if txt == text and dt == data:\n+ return\nself._queue[questionid].append((text, data))\ndef get(self):\n@@ -164,6 +167,7 @@ class MessageFrame(QFrame):\nreturn\nexcept Exception:\npass\n+ if self.questionid != questionid or self.text != text or data != self.data:\nself._queue.add(questionid, text, data)\nif self.questionid == self.TYPE_INVALID:\nself._new_request = self._read_next_item()\n",
        "org_msg": "node_manager_fkie: avoid multiple question in the queue",
        "sim_msg": "[ServerStats] increment the count",
        "sim_diff": "diff --git a/serverstats/serverstats.py b/serverstats/serverstats.py @@ -820,6 +820,7 @@ class ServerStats(commands.Cog):\nawait asyncio.sleep(0.1)\nmsg += f\"{server.name}: {len(server.members)}\\n\"\nmsg_list.append(msg)\n+ count += 1\nawait menu(ctx, msg_list, DEFAULT_CONTROLS)\n@commands.command(hidden=True)\n@@ -839,6 +840,7 @@ class ServerStats(commands.Cog):\ncount = 0\nawait asyncio.sleep(0.1)\nmsg += f\"{server.name}: {len(server.members)}\\n\"\n+ count += 1\nmsg_list.append(msg)\nawait menu(ctx, msg_list, DEFAULT_CONTROLS)\n",
        "chatgpt_cot": "\"Add condition to avoid duplicate messages in MessageQueue and MessageFrame\""
    },
    {
        "org_diff": "diff --git a/README.md b/README.md @@ -18,8 +18,10 @@ By installing this library you agree to be bound by the terms of the [AI and Mac\nFor this fork, you'll need Python 3.7 or newer.\n```\n-pip3 install --user --upgrade sc2\n+pip install pipenv\n+pip install --upgrade --force-reinstall https://github.com/BurnySc2/python-sc2/archive/develop.zip\n```\n+\nYou'll need an StarCraft II executable. If you are running Windows or macOS, just install the normal SC2 from blizzard app. [The free starter edition works too.](https://us.battle.net/account/sc2/starter-edition/). Linux users get the best experience by installing the Windows version of StarCraft II with [Wine](https://www.winehq.org). Linux user can also use the [Linux binary](https://github.com/Blizzard/s2client-proto#downloads), but it's headless so you cannot actually see the game.\nYou probably want some maps too. Official map downloads are available from [Blizzard/s2client-proto](https://github.com/Blizzard/s2client-proto#downloads). Notice: the map files are to be extracted into *subdirectories* of the `install-dir/Maps` directory.\n",
        "org_msg": "Update install command in README.md",
        "sim_msg": "Windows install command",
        "sim_diff": "diff --git a/README.md b/README.md @@ -53,6 +53,10 @@ Or, if you\\'re using FreeBSD:\n# pkg install py36-pipenv\n+Or, if you\\'re using Windows:\n+\n+ # pip install --user pipenv\n+\nWhen none of the above is an option, it is recommended to use [Pipx](https://pypi.org/p/pipx):\n$ pipx install pipenv\n",
        "chatgpt_cot": "Update installation instructions for SC2 library, replacing pip3 with pipenv and adding specific upgrade command for python-sc2 library."
    },
    {
        "org_diff": "diff --git a/sc2/sc2process.py b/sc2/sc2process.py @@ -78,7 +78,7 @@ class SC2Process(object):\n\"-dataDir\", str(Paths.BASE),\n\"-tempDir\", self._tmp_dir\n],\n- cwd=str(Paths.CWD),\n+ cwd=(str(Paths.CWD) if Paths.CWD else None),\n#, env=run_config.env\n)\n",
        "org_msg": "Fix the case when Paths.CWD is None",
        "sim_msg": "Ensure that we use posix style strings instead of Path objects for chdir context manager",
        "sim_diff": "diff --git a/pipenv/utils.py b/pipenv/utils.py @@ -1367,7 +1367,9 @@ def is_virtual_environment(path):\ndef chdir(path):\n\"\"\"Context manager to change working directories.\"\"\"\nfrom ._compat import Path\n- prev_cwd = Path.cwd()\n+ prev_cwd = Path.cwd().as_posix()\n+ if isinstance(path, Path):\n+ path = path.as_posix()\nos.chdir(str(path))\ntry:\nyield\n",
        "chatgpt_cot": "Fix issue with setting current working directory in SC2Process. Updated the cwd parameter to handle None value when Paths.CWD is not available."
    },
    {
        "org_diff": "diff --git a/fkie_master_discovery/src/fkie_master_discovery/master_discovery.py b/fkie_master_discovery/src/fkie_master_discovery/master_discovery.py @@ -606,7 +606,7 @@ class Discoverer(object):\nself._init_notifications = 0\n# disable parameter, if HEARTBEAT_HZ is active (> zero)\nif self.HEARTBEAT_HZ > DiscoveredMaster.MIN_HZ_FOR_QUALILTY:\n- self._init_notifications = self.INIT_NOTIFICATION_COUNT\n+ # send init requests in mixed szenario: self._init_notifications = self.INIT_NOTIFICATION_COUNT\nself._current_change_notification_count = self.CHANGE_NOTIFICATION_COUNT\nself._timer_heartbeat = threading.Timer(1.0, self.send_heartbeat)\n# set the callback to finish all running threads\n",
        "org_msg": "fkie_master_discovery: send init requests in mixed szenario\nNetwork has hosts with different heartbeat hz",
        "sim_msg": "and a bit more renaming",
        "sim_diff": "diff --git a/InvenTree/common/notifications.py b/InvenTree/common/notifications.py @@ -80,7 +80,7 @@ class NotificationMethod:\ndef setup(self):\nreturn True\n- # def send(self, receiver)\n+ # def send(self, targets)\n# def send_bulk(self)\ndef cleanup(self):\n@@ -88,7 +88,7 @@ class NotificationMethod:\nclass SingleNotificationMethod(NotificationMethod):\n- def send(self, receiver):\n+ def send(self, target):\nraise NotImplementedError('The `send` method must be overriden!')\n@@ -126,11 +126,11 @@ class UIMessageNotification(SingleNotificationMethod):\ndef get_recipients(self):\nreturn self.targets\n- def send(self, receiver):\n+ def send(self, target):\nNotificationMessage.objects.create(\ntarget_object = self.obj,\n- source_object = receiver,\n- user = receiver,\n+ source_object = target,\n+ user = target,\ncategory = self.entry_name,\nname = self.context['name'],\nmessage = self.context['message'],\n",
        "chatgpt_cot": "Improve initialization request handling in Discoverer class by commenting out unnecessary assignment and clarifying purpose of the code."
    },
    {
        "org_diff": "diff --git a/rasa_core_sdk/forms.py b/rasa_core_sdk/forms.py @@ -101,6 +101,23 @@ class FormAction(Action):\nself.name()),\nself.name())\n+ # noinspection PyUnusedLocal\n+ def next_slot_to_request(self,\n+ dispatcher, # type: CollectingDispatcher\n+ tracker, # type: Tracker\n+ domain # type: Dict[Text, Any]\n+ ):\n+ # type: (...) -> Optional[List[Dict]]\n+ \"\"\"\"Request the next slot and utter template if needed,\n+ else return None\"\"\"\n+\n+ for slot in self.required_slots():\n+ if self._should_request_slot(tracker, slot):\n+ dispatcher.utter_template(\"utter_ask_{}\".format(slot), tracker)\n+ return [SlotSet(REQUESTED_SLOT, slot)]\n+\n+ return None\n+\ndef submit(self, dispatcher, tracker, domain):\n# type: (CollectingDispatcher, Tracker, Dict[Text, Any]) -> List[Dict]\n\"\"\"Define what the form has to do\n@@ -147,12 +164,6 @@ class FormAction(Action):\nreturn [Form(None), SlotSet(REQUESTED_SLOT, None)]\n- def next_slot_to_request(self, tracker):\n- for slot in self.required_slots():\n- if self._should_request_slot(tracker, slot):\n- return slot\n- return None\n-\ndef run(self, dispatcher, tracker, domain):\n# type: (CollectingDispatcher, Tracker, Dict[Text, Any]) -> List[Dict]\n\"\"\"Execute the side effects of this form:\n@@ -173,14 +184,12 @@ class FormAction(Action):\nif e['event'] == 'slot':\ntemp_tracker.slots[e[\"name\"]] = e[\"value\"]\n+ next_slot_events = self.next_slot_to_request(dispatcher, temp_tracker,\n+ domain)\n+ if next_slot_events is not None:\n# request next slot\n- slot = self.next_slot_to_request(temp_tracker)\n- if slot is not None:\n- dispatcher.utter_template(\"utter_ask_{}\".format(slot), tracker)\n- events.append(SlotSet(REQUESTED_SLOT, slot))\n- return events\n-\n-\n+ events.extend(next_slot_events)\n+ else:\n# there is nothing more to request, so we can submit\nevents.extend(self.submit(dispatcher, temp_tracker, domain))\n# deactivate the form after submission\n",
        "org_msg": "request slot in different method RasaHQ/roadmap#280",
        "sim_msg": "Style Select2 widgets and remove wrong filter form class\nThis fixes by removing `class=\"form-inline\"` from filter form\ndefinition (which helped getting a proper form size in the sidebar),\nand by adding attributes (SIDEBAR_DAL_WIDTH) to the Select2 widgets.",
        "sim_diff": "diff --git a/workshops/forms.py b/workshops/forms.py @@ -235,13 +235,19 @@ class WorkshopStaffForm(forms.Form):\nlabel='Airport',\nrequired=False,\nqueryset=Airport.objects.all(),\n- widget=autocomplete.ModelSelect2(url='airport-lookup')\n+ widget=autocomplete.ModelSelect2(\n+ url='airport-lookup',\n+ attrs=SIDEBAR_DAL_WIDTH,\n+ )\n)\nlanguages = forms.ModelMultipleChoiceField(\nlabel='Languages',\nrequired=False,\nqueryset=Language.objects.all(),\n- widget=autocomplete.ModelSelect2Multiple(url='language-lookup')\n+ widget=autocomplete.ModelSelect2Multiple(\n+ url='language-lookup',\n+ attrs=SIDEBAR_DAL_WIDTH,\n+ )\n)\ncountry = forms.MultipleChoiceField(choices=[])\n@@ -286,7 +292,6 @@ class WorkshopStaffForm(forms.Form):\nrequired=False)\nself.helper = FormHelper(self)\n- self.helper.form_class = 'form-inline'\nself.helper.form_method = 'get'\nself.helper.layout = Layout(\nDiv(\n",
        "chatgpt_cot": "Refactor FormAction class, remove unnecessary method next_slot_to_request, and add new method next_slot_to_request with dispatcher, tracker, domain."
    },
    {
        "org_diff": "diff --git a/src/api-engine/api/models.py b/src/api-engine/api/models.py @@ -763,7 +763,6 @@ class Channel(models.Model):\ndef get_channel_artifacts_path(self, artifact):\nreturn CELLO_HOME + \"/\" + self.network.name + \"/\" + artifact\n-\n# class ChainCode(models.Model):\n# id = models.UUIDField(\n# primary_key=True,\n",
        "org_msg": "Fix model format",
        "sim_msg": "Fixing Error when no BG image exists",
        "sim_diff": "diff --git a/classes/Channel.py b/classes/Channel.py @@ -62,7 +62,7 @@ class Channel(db.Model):\n'channelName': self.channelName,\n'description': self.description,\n'channelImage': \"/images/\" + self.imageLocation,\n- 'offlineImageLocation': \"/images/\" + self.offlineImageLocation,\n+ 'offlineImageLocation': \"/images/\" + str(self.offlineImageLocation),\n'topic': self.topic,\n'views': self.views,\n'currentViews': self.currentViewers,\n",
        "chatgpt_cot": "Remove unnecessary commented-out code in Channel class."
    },
    {
        "org_diff": "diff --git a/src/api-engine/api/routes/channel/serializers.py b/src/api-engine/api/routes/channel/serializers.py @@ -29,12 +29,18 @@ class ChannelIDSerializer(serializers.Serializer):\nid = serializers.UUIDField(help_text=\"Channel ID\")\n+ORG_CHOICES = (\n+ (\"Application\", \"Application\"),\n+ (\"Orderer\", \"Orderer\"),\n+)\n+\n+\nclass ChannelUpdateSerializer(serializers.Serializer):\nmsp_id = serializers.CharField(\nmax_length=128, help_text=\"MSP ID of Organization\")\ndata = serializers.FileField(help_text=\"Channel config file\")\norg_type = serializers.CharField(\n- max_length=24, help_text=\"Organization type\")\n+ max_length=24, help_text=\"Organization type\", choices=ORG_CHOICES)\nclass ChannelOrgListSerializer(serializers.Serializer):\n",
        "org_msg": "Only allow Application and Orderer types to update Channel Config",
        "sim_msg": "Extend PersonSerializer with ORCID data\nThis fixes",
        "sim_diff": "diff --git a/api/serializers.py b/api/serializers.py @@ -212,8 +212,8 @@ class PersonSerializer(serializers.ModelSerializer):\nmodel = Person\nfields = (\n'personal', 'middle', 'family', 'email', 'gender', 'may_contact',\n- 'publish_profile',\n- 'airport', 'github', 'twitter', 'url', 'username', 'notes',\n+ 'publish_profile', 'airport',\n+ 'github', 'twitter', 'url', 'orcid', 'username', 'notes',\n'affiliation', 'badges', 'lessons', 'domains', 'awards', 'tasks',\n)\n",
        "chatgpt_cot": "Add choices to organization type field in ChannelUpdateSerializer to restrict input options and improve data integrity."
    },
    {
        "org_diff": "diff --git a/src/agent/k8s/cluster.py b/src/agent/k8s/cluster.py @@ -58,6 +58,8 @@ class ClusterOnKubernetes(ClusterBase):\nconsensus = self._get_cluster_info(cid, config)\noperation = K8sClusterOperation(kube_config)\n+ cluster_name = self.trim_cluster_name(cluster_name)\n+\ncontainers = operation.deploy_cluster(cluster_name,\nports_index,\nnfsServer_ip,\n@@ -73,6 +75,7 @@ class ClusterOnKubernetes(ClusterBase):\nconsensus = self._get_cluster_info(cid, config)\noperation = K8sClusterOperation(kube_config)\n+ cluster_name = self.trim_cluster_name(cluster_name)\noperation.delete_cluster(cluster_name,\nports_index,\nnfsServer_ip,\n@@ -103,6 +106,7 @@ class ClusterOnKubernetes(ClusterBase):\n.k8s_param)\noperation = K8sClusterOperation(kube_config)\n+ cluster_name = self.trim_cluster_name(cluster_name)\nservices_urls = operation.get_services_urls(cluster_name)\nexcept Exception as e:\nlogger.error(\"Failed to get Kubernetes services's urls: {}\"\n@@ -117,6 +121,7 @@ class ClusterOnKubernetes(ClusterBase):\nconsensus = self._get_cluster_info(name, config)\noperation = K8sClusterOperation(kube_config)\n+ cluster_name = self.trim_cluster_name(cluster_name)\ncontainers = operation.start_cluster(cluster_name, ports_index,\nnfsServer_ip, consensus)\n@@ -150,6 +155,7 @@ class ClusterOnKubernetes(ClusterBase):\nconsensus = self._get_cluster_info(name, config)\noperation = K8sClusterOperation(kube_config)\n+ cluster_name = self.trim_cluster_name(cluster_name)\noperation.stop_cluster(cluster_name,\nports_index,\nnfsServer_ip,\n@@ -177,3 +183,8 @@ class ClusterOnKubernetes(ClusterBase):\nelse:\nlogger.error(\"Failed to Restart Kubernetes Cluster\")\nreturn None\n+\n+ def trim_cluster_name(self, cluster_name):\n+ if cluster_name.find(\"_\") != -1:\n+ cluster_name = cluster_name.replace(\"_\", \"-\")\n+ return cluster_name.lower()\n",
        "org_msg": "Kubernetes host can not run fill up\nWhile fill up operation will format the cluster name in\n{hostName}_{1,2,3...}, which is illegal in naming\nKubernetes namespace, this patch added a function to\nhandle this situation.\n#done",
        "sim_msg": "Installer: Support multiple AES pods in cluster ID check",
        "sim_diff": "diff --git a/cmd/edgectl/aes_install.go b/cmd/edgectl/aes_install.go @@ -200,14 +200,48 @@ func (i *Installer) loopUntil(what string, how func() error, lc *loopConfig) err\n// the Pod is Running (though not necessarily Ready). This should be good enough\n// to report the \"deploy\" status to metrics.\nfunc (i *Installer) GrabAESInstallID() error {\n- // Note: This is brittle. If there is more than one pod, this returns all\n- // the pod names squashed together. This should not occur in normal usage,\n- // i.e. when installing a single version of AES, maybe repeatedly.\n- pod, err := i.CaptureKubectl(\"get AES pod\", \"\", \"-n\", \"ambassador\", \"get\", \"pods\", \"-l\", \"service=ambassador\", \"-o\", \"go-template={{range .items}}{{.metadata.name}}{{end}}\")\n+ aesImage := \"quay.io/datawire/aes:1.3.1\" // FIXME\n+ podName := \"\"\n+ containerName := \"\"\n+ podInterface := i.coreClient.Pods(\"ambassador\") // namespace\n+ i.log.Print(\"> k -n ambassador get po\")\n+ pods, err := podInterface.List(k8sTypesMetaV1.ListOptions{})\nif err != nil {\nreturn err\n}\n- clusterID, err := i.CaptureKubectl(\"get cluster ID\", \"\", \"-n\", \"ambassador\", \"exec\", pod, \"python3\", \"kubewatch.py\")\n+\n+ // Find an AES Pod\n+PodsLoop:\n+ for _, pod := range pods.Items {\n+ i.log.Print(\" Pod: \", pod.Name)\n+ ContainersLoop:\n+ for _, container := range pod.Spec.Containers {\n+ // Avoid matching the Traffic Manager (container.Command == [\"traffic-proxy\"])\n+ i.log.Printf(\" Container: %s (image: %q; command: %q)\", container.Name, container.Image, container.Command)\n+ if container.Image != aesImage || container.Command != nil {\n+ continue\n+ }\n+ // Avoid matching the Traffic Agent by checking for\n+ // AGENT_SERVICE in the environment. This is how Ambassador's\n+ // Python code decides it is running as an Agent.\n+ for _, envVar := range container.Env {\n+ if envVar.Name == \"AGENT_SERVICE\" && envVar.Value != \"\" {\n+ i.log.Printf(\" AGENT_SERVICE: %q\", envVar.Value)\n+ continue ContainersLoop\n+ }\n+ }\n+ i.log.Print(\" Success\")\n+ podName = pod.Name\n+ containerName = container.Name\n+ break PodsLoop\n+ }\n+ }\n+ if podName == \"\" {\n+ return errors.New(\"no AES pods found\")\n+ }\n+\n+ // Retrieve the cluster ID\n+ clusterID, err := i.CaptureKubectl(\"get cluster ID\", \"\", \"-n\", \"ambassador\", \"exec\", podName, \"-c\", containerName, \"python3\", \"kubewatch.py\")\nif err != nil {\nreturn err\n}\n",
        "chatgpt_cot": "Add method to trim cluster name in ClusterOnKubernetes class to replace underscores with hyphens, improving cluster name consistency."
    },
    {
        "org_diff": "diff --git a/README.md b/README.md @@ -4,6 +4,8 @@ An easy-to-use library for writing AI Bots for StarCraft II in Python 3. The ult\n**This library (currently) covers only the raw scripted interface.** At this time I don't intend to add support for graphics-based interfaces.\n+Documentation is in [the Wiki](https://github.com/Dentosal/python-sc2/wiki).\n+\n## Installation\nYou'll need Python 3.6 or newer.\n",
        "org_msg": "Add wiki link to the readme",
        "sim_msg": "[Hockey] Fix issue where sometimes a game will show incorrect standings data on previews",
        "sim_diff": "diff --git a/hockey/game.py b/hockey/game.py from __future__ import annotations\n+\nimport logging\nfrom datetime import datetime\n-from typing import Literal, Optional, List, Dict, Union, Tuple\n+from typing import Dict, List, Literal, Optional, Tuple, Union\nimport aiohttp\nimport discord\n@@ -12,7 +13,13 @@ from redbot.core.utils import AsyncIter, bounded_gather\nfrom .constants import BASE_URL, CONTENT_URL, TEAMS\nfrom .goal import Goal\n-from .helper import check_to_post, get_channel_obj, get_team, get_team_role, utc_to_local\n+from .helper import (\n+ check_to_post,\n+ get_channel_obj,\n+ get_team,\n+ get_team_role,\n+ utc_to_local,\n+)\nfrom .standings import Standings\n_ = Translator(\"Hockey\", __file__)\n@@ -423,7 +430,10 @@ class Game:\nstats, home_i = await Standings.get_team_standings(self.home_team)\nfor team in stats:\nif team.name == self.away_team:\n+ try:\nstreak = \"{} {}\".format(team.streak, streak_types[team.streak_type])\n+ except KeyError:\n+ streak = \"**0**\"\naway_str = msg.format(\nwins=team.wins,\nlosses=team.losses,\n@@ -433,7 +443,10 @@ class Game:\nstreak=streak,\n)\nif team.name == self.home_team:\n+ try:\nstreak = \"{} {}\".format(team.streak, streak_types[team.streak_type])\n+ except KeyError:\n+ streak = \"**0**\"\nhome_str = msg.format(\nwins=team.wins,\nlosses=team.losses,\n@@ -443,6 +456,7 @@ class Game:\nstreak=streak,\n)\nexcept Exception:\n+ log.exception(\"Error pulling stats\")\npass\nreturn home_str, away_str\n",
        "chatgpt_cot": "Add documentation link to the README file for easy access to the Wiki."
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/master_view_proxy.py b/node_manager_fkie/src/node_manager_fkie/master_view_proxy.py @@ -1300,7 +1300,7 @@ class MasterViewProxy(QWidget):\ntext += '<b>Selected nodes:</b><br>'\nif restartable_nodes:\ntext += '<a href=\"restart-node://all_selected_nodes\" title=\"Restart %s selected nodes\"><img src=\":icons/sekkyumu_restart_24.png\" alt=\"restart\">[%d]</a>' % (len(restartable_nodes), len(restartable_nodes))\n- text += '<a href=\"restart-node-g://all_selected_nodes\" title=\"Reload global parameter and restart %s selected nodes\"><img src=\":icons/sekkyumu_restart_g_24.png\" alt=\"restart\">[%d]</a>' % (len(restartable_nodes), len(restartable_nodes))\n+ text += '&nbsp;<a href=\"restart-node-g://all_selected_nodes\" title=\"Reload global parameter and restart %s selected nodes\"><img src=\":icons/sekkyumu_restart_g_24.png\" alt=\"restart\">[%d]</a>' % (len(restartable_nodes), len(restartable_nodes))\nif killable_nodes:\n# text += '&nbsp;<a href=\"kill-node://all_selected_nodes\" title=\"Kill %s selected nodes\"><img src=\":icons/sekkyumu_kill_24.png\" alt=\"kill\">[%d]</a>' % (len(killable_nodes), len(killable_nodes))\ntext += '&nbsp;<a href=\"kill-screen://all_selected_nodes\" title=\"Kill %s screens of selected nodes\"><img src=\":icons/sekkyumu_kill_screen_24.png\" alt=\"killscreen\">[%d]</a>' % (len(killable_nodes), len(killable_nodes))\n@@ -1348,7 +1348,7 @@ class MasterViewProxy(QWidget):\ndefault_cfgs = [c[0] for c in node.cfgs if isinstance(c, tuple)]\nif launches or default_cfgs:\ntext += '<a href=\"restart-node://%s\" title=\"Restart node\"><img src=\":icons/sekkyumu_restart_24.png\" alt=\"restart\"></a>' % node.name # height=\"24\" width=\"24\"\n- text += '<a href=\"restart-node-g://%s\" title=\"Reload global parameter and restart node\"><img src=\":icons/sekkyumu_restart_g_24.png\" alt=\"restart\"></a>' % node.name # height=\"24\" width=\"24\"\n+ text += '&nbsp;<a href=\"restart-node-g://%s\" title=\"Reload global parameter and restart node\"><img src=\":icons/sekkyumu_restart_g_24.png\" alt=\"restart\"></a>' % node.name # height=\"24\" width=\"24\"\n# text += '&nbsp; <a href=\"kill-node://%s\" title=\"Kill node with pid %s\"><img src=\":icons/sekkyumu_kill_24.png\" alt=\"kill\"></a>' % (node.name, node.pid)\ntext += '&nbsp; <a href=\"kill-screen://%s\" title=\"Kill screen of the node\"><img src=\":icons/sekkyumu_kill_screen_24.png\" alt=\"killscreen\"></a>' % node.name\nif launches:\n",
        "org_msg": "node_manager_fkie: fixed icon space in description panel",
        "sim_msg": "Tree: display title for e.g. Frame, allow editing of this and class name",
        "sim_diff": "diff --git a/tree.py b/tree.py @@ -484,7 +484,15 @@ class WidgetTree(wx.TreeCtrl, Tree):\nnew_value = evt.Label\nif new_value==self._build_label(node): return\n- new_name = new_label = new_title = new_tab = None\n+ new_name = new_label = new_title = new_tab = new_class = None\n+\n+ if node.widget.klass != node.widget.base and node.widget.klass != 'wxScrolledWindow':\n+ if new_value.count(\"(\")==1 and new_value.count(\")\")==1:\n+ pre, new_class = new_value.split(\"(\")\n+ new_class, post = new_class.split(\")\")\n+ if pre.endswith(\" \"): pre = pre[:-1]\n+ new_value = pre+post\n+\nif \"label\" in widget.properties and self._label_editable(widget):\nnew_name, new_label = self._split_name_label(new_value)\nelif \"label\" in widget.properties:\n@@ -507,14 +515,23 @@ class WidgetTree(wx.TreeCtrl, Tree):\nif new_name==name_p.get(): new_name = None\nif new_name:\n# check\n- name_OK = name_p.check(new_name)\n- if not name_OK: new_name = None\n+ OK = name_p.check(new_name)\n+ if not OK: new_name = None\n+\n+ # check class/klass\n+ if new_class:\n+ class_p = widget.properties[\"klass\"]\n+ if new_class==class_p.get(): new_class = None\n+ if new_class:\n+ # check\n+ OK = class_p.check(new_class)\n+ if not OK: new_class = None\n# check label\nif new_label is not None:\nlabel_p = widget.properties[\"label\"]\nif new_label==label_p.get(): new_label = None\n- if not new_name and new_label is None and new_title is None and new_tab is None:\n+ if not new_name and new_label is None and new_title is None and new_tab is None and new_class is None:\n# no change or an error\nwx.Bell()\nevt.Veto()\n@@ -543,6 +560,10 @@ class WidgetTree(wx.TreeCtrl, Tree):\nname_p.previous_value = name_p.value\nname_p.set(new_name, notify=False)\nmodified.add(\"name\")\n+ if new_class:\n+ class_p.previous_value = class_p.value\n+ class_p.set(new_class, notify=False)\n+ modified.add(\"class\")\nif new_label:\nlabel_p.previous_value = label_p.value\nlabel_p.set(new_label, notify=False)\n@@ -577,6 +598,9 @@ class WidgetTree(wx.TreeCtrl, Tree):\nif node.widget.klass != node.widget.base and node.widget.klass != 'wxScrolledWindow':\n# special case...\ns += ' (%s)' % node.widget.klass\n+ if getattr(node.widget, \"has_title\", None):\n+ # include title\n+ s += ': \"%s\"'%node.widget.title\nelif \"label\" in node.widget.properties and node.widget.properties[\"label\"].is_active():\n# include label of control\nlabel = node.widget.label\n",
        "chatgpt_cot": "Fix formatting issue in MasterViewProxy.py file by adding missing \"&nbsp;\" to align elements properly for better readability."
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/master_view_proxy.py b/node_manager_fkie/src/node_manager_fkie/master_view_proxy.py @@ -160,6 +160,7 @@ class MasterViewProxy(QWidget):\nself.__force_update = False\nself.__configs = dict() # [file name] : LaunchConfig or tuple(ROS node name, ROS service uri, ROS master URI) : ROS nodes\nself.__online = False\n+ self.__run_id = ''\n# self.rosconfigs = dict() # [launch file path] = LaunchConfig()\nself.__in_question = [] # stores the changed files, until the user is interacted\n# self.__uses_confgs = dict() # stores the decisions of the user for used configuration to start of node\n@@ -489,7 +490,7 @@ class MasterViewProxy(QWidget):\nself.__force_update = True\ndef update_system_parameter(self):\n- self.parameterHandler_sim.requestParameterValues(self.masteruri, [\"/use_sim_time\", \"/robot_icon\", \"/roslaunch/uris\"])\n+ self.parameterHandler_sim.requestParameterValues(self.masteruri, [\"/run_id\", \"/use_sim_time\", \"/robot_icon\", \"/roslaunch/uris\"])\ndef markNodesAsDuplicateOf(self, running_nodes):\n'''\n@@ -2955,6 +2956,15 @@ class MasterViewProxy(QWidget):\nif code_n == 1:\nfor _, value in val.items():\nself.launch_server_handler.updateLaunchServerInfo(value)\n+ elif p == \"/run_id\":\n+ if self.__run_id != val:\n+ self.__run_id = val\n+ # you have to launch global parameter\n+ for filename, launch_cfg in self.__configs.items():\n+ try:\n+ launch_cfg.global_param_done.remove(masteruri)\n+ except ValueError:\n+ pass\nelse:\nrospy.logwarn(\"Error on retrieve sim parameter value from %s: %s\", str(masteruri), msg)\nif not robot_icon_found:\n",
        "org_msg": "node_manager_fkie: reload global parameter, if ROS master was restarted",
        "sim_msg": "Cast AXES_BEHIND_REVERSE_PROXY as bool.",
        "sim_diff": "diff --git a/mozillians/settings.py b/mozillians/settings.py @@ -447,7 +447,7 @@ ES_REINDEX_BATCHSIZE = config('ES_REINDEX_BATCHSIZE', default=100, cast=int)\nES_REINDEX_TIMEOUT = config('ES_REINDEX_TIMEOUT', default=1800, cast=int)\n# Setup django-axes\n-AXES_BEHIND_REVERSE_PROXY = config('AXES_BEHIND_REVERSE_PROXY', default=True)\n+AXES_BEHIND_REVERSE_PROXY = config('AXES_BEHIND_REVERSE_PROXY', default=True, cast=bool)\n# Setup sentry\nRAVEN_CONFIG = config('RAVEN_CONFIG', cast=json.loads, default='{}')\n",
        "chatgpt_cot": "\"Add run_id attribute, update system parameter, and launch global parameter on run_id change\""
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/main_window.py b/node_manager_fkie/src/node_manager_fkie/main_window.py @@ -1374,6 +1374,8 @@ class MainWindow(QMainWindow):\nif item is not None:\nself._history_selected_robot = item.master.name\nself.setCurrentMaster(item.master.uri)\n+ if not nm.nmd().get_packages(item.master.uri):\n+ nm.nmd().list_packages_threaded(nmdurl.nmduri(item.master.uri))\nif self.currentMaster.master_info is not None and not self.restricted_to_one_master:\nnode = self.currentMaster.master_info.getNodeEndsWith('master_sync')\nself.syncButton.setEnabled(True)\n",
        "org_msg": "request packages on first selection of the master",
        "sim_msg": "change apply configs",
        "sim_diff": "diff --git a/openbb_terminal/session/local_model.py b/openbb_terminal/session/local_model.py @@ -112,15 +112,10 @@ def apply_configs(configs: dict):\nconfigs : dict\nThe configurations.\n\"\"\"\n- # console.print(configs, style=\"red\")\n-\nif configs:\nsettings = configs.get(\"features_settings\", {})\n-\n- # TODO: Find a cleaner way to check if user has sync enabled.\n- obbff.SYNC_ENABLED = is_sync_enabled(settings)\n-\n- if obbff.SYNC_ENABLED:\n+ sync = update_sync_flag(settings)\n+ if sync:\nif settings:\nfor k, v in settings.items():\nif hasattr(obbff, k):\n@@ -137,8 +132,8 @@ def apply_configs(configs: dict):\nsetattr(cfg, k, v)\n-def is_sync_enabled(settings: dict) -> bool:\n- \"\"\"Check if sync is enabled.\n+def update_sync_flag(settings: dict) -> bool:\n+ \"\"\"Update the sync flag.\nParameters\n----------\n@@ -148,11 +143,13 @@ def is_sync_enabled(settings: dict) -> bool:\nReturns\n-------\nbool\n- The status of sync.\n+ The sync flag.\n\"\"\"\nif settings:\nif settings.get(\"SYNC_ENABLED\", \"\").lower() == \"false\":\n+ obbff.SYNC_ENABLED = False\nreturn False\n+ obbff.SYNC_ENABLED = True\nreturn True\n@@ -177,16 +174,20 @@ def cast_set_attr(obj, name, value):\nsetattr(obj, name, value)\n-def get_routine(name: str) -> Optional[str]:\n+def get_routine(\n+ name: str, routines_folder: Path = USER_ROUTINES_DIRECTORY\n+) -> Optional[str]:\n\"\"\"Get the routine.\nReturns\n-------\nstr\nThe routine.\n+ routines_folder : Path\n+ The routines folder.\n\"\"\"\ntry:\n- with open(USER_ROUTINES_DIRECTORY / name) as f:\n+ with open(routines_folder / name) as f:\nroutine = \"\".join(f.readlines())\nreturn routine\nexcept Exception:\n",
        "chatgpt_cot": "Add threaded package list retrieval when no packages are available."
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/select_dialog.py b/node_manager_fkie/src/node_manager_fkie/select_dialog.py @@ -272,7 +272,7 @@ class MainBox(QWidget):\nitem = self.layout().itemAt(i).widget()\nif isinstance(item, QCheckBox):\nif item.isChecked():\n- result.append(item.text())\n+ result.append(item.text().replace('&', ''))\nreturn result\ndef setState(self, state):\n",
        "org_msg": "node_manager_fkie: fixed close configuration",
        "sim_msg": "added reveal button",
        "sim_diff": "diff --git a/qualcoder/GUI/ui_dialog_graph.py b/qualcoder/GUI/ui_dialog_graph.py @@ -35,16 +35,20 @@ class Ui_DialogGraph(object):\nself.checkBox_blackandwhite.setGeometry(QtCore.QRect(0, 6, 181, 22))\nself.checkBox_blackandwhite.setObjectName(\"checkBox_blackandwhite\")\nself.pushButton_export = QtWidgets.QPushButton(self.groupBox_header)\n- self.pushButton_export.setGeometry(QtCore.QRect(840, 6, 28, 28))\n+ self.pushButton_export.setGeometry(QtCore.QRect(870, 6, 28, 28))\nself.pushButton_export.setText(\"\")\nself.pushButton_export.setObjectName(\"pushButton_export\")\nself.comboBox_fontsize = QtWidgets.QComboBox(self.groupBox_header)\nself.comboBox_fontsize.setGeometry(QtCore.QRect(290, 5, 71, 30))\nself.comboBox_fontsize.setObjectName(\"comboBox_fontsize\")\nself.label_zoom = QtWidgets.QLabel(self.groupBox_header)\n- self.label_zoom.setGeometry(QtCore.QRect(882, 7, 28, 28))\n+ self.label_zoom.setGeometry(QtCore.QRect(910, 7, 28, 28))\nself.label_zoom.setText(\"\")\nself.label_zoom.setObjectName(\"label_zoom\")\n+ self.pushButton_reveal = QtWidgets.QPushButton(self.groupBox_header)\n+ self.pushButton_reveal.setGeometry(QtCore.QRect(832, 6, 28, 28))\n+ self.pushButton_reveal.setText(\"\")\n+ self.pushButton_reveal.setObjectName(\"pushButton_reveal\")\nself.gridLayout.addWidget(self.groupBox_header, 0, 0, 1, 1)\nself.graphicsView = QtWidgets.QGraphicsView(DialogGraph)\nself.graphicsView.setLayoutDirection(QtCore.Qt.LayoutDirection.RightToLeft)\n@@ -67,6 +71,7 @@ class Ui_DialogGraph(object):\nself.checkBox_blackandwhite.setText(_translate(\"DialogGraph\", \"Black and white\"))\nself.pushButton_export.setToolTip(_translate(\"DialogGraph\", \"Export image\"))\nself.label_zoom.setToolTip(_translate(\"DialogGraph\", \"Click on the graph area and press + or - to zoom in or zoom out.\"))\n+ self.pushButton_reveal.setToolTip(_translate(\"DialogGraph\", \"Show hidden items\"))\nif __name__ == \"__main__\":\n",
        "chatgpt_cot": "Fix issue with select dialog item text containing '&' by replacing it with an empty string."
    },
    {
        "org_diff": "diff --git a/node_manager_daemon_fkie/src/node_manager_daemon_fkie/launcher.py b/node_manager_daemon_fkie/src/node_manager_daemon_fkie/launcher.py @@ -169,7 +169,7 @@ def run_node(startcfg):\nif isinstance(cmd, types.StringTypes):\ncmd = [cmd]\nif cmd is None or len(cmd) == 0:\n- raise exceptions.StartException('%s in package [%s] not found!' % (startcfg.package, startcfg.binary))\n+ raise exceptions.StartException('%s in package [%s] not found!' % (startcfg.binary, startcfg.package))\nif len(cmd) > 1:\n# Open selection for executables\nerr = 'Multiple executables with same name in package [%s] found:' % startcfg.package\n",
        "org_msg": "node_manager_daemon_fkie: fixed error message\nthe package and node name were interchanged",
        "sim_msg": "change --local-package to boolean flag",
        "sim_diff": "diff --git a/fedn/cli/run_cmd.py b/fedn/cli/run_cmd.py @@ -71,7 +71,7 @@ def run_cmd(ctx):\n@click.option('-t', '--token', required=False)\n@click.option('-n', '--name', required=False, default=\"client\" + str(uuid.uuid4())[:8])\n@click.option('-i', '--client_id', required=False)\n-@click.option('-l', '--local-package', required=False, default=False, help='Enable local compute package')\n+@click.option('-l', '--local-package', is_flag=True, help='Enable local compute package')\n@click.option('-u', '--dry-run', required=False, default=False)\n@click.option('-s', '--secure', required=False, default=True)\n@click.option('-pc', '--preshared-cert', required=False, default=False)\n@@ -148,9 +148,9 @@ def client_cmd(ctx, discoverhost, discoverport, token, name, client_id, local_pa\n@run_cmd.command('reducer')\n@click.option('-d', '--discoverhost', required=False)\n-@click.option('-p', '--discoverport', required=False, default='8090')\n+@click.option('-p', '--discoverport', required=False, default='8090', show_default=True)\n@click.option('-t', '--token', required=False, default=None)\n-@click.option('-l', '--local-package', required=False, default=False, help='Enable local compute package')\n+@click.option('-l', '--local-package', is_flag=True, help='Enable local compute package')\n@click.option('-n', '--name', required=False, default=\"reducer\" + str(uuid.uuid4())[:8])\n@click.option('-i', '--init', required=True, default=None,\nhelp='Set to a filename to (re)init reducer from file state.')\n",
        "chatgpt_cot": "Fix exception message order to display the correct package and binary names."
    },
    {
        "org_diff": "diff --git a/src/dashboard/src/pages/Operator/Node/Node.js b/src/dashboard/src/pages/Operator/Node/Node.js @@ -23,6 +23,7 @@ import moment from 'moment';\nimport PageHeaderWrapper from '@/components/PageHeaderWrapper';\nimport StandardTable from '@/components/StandardTable';\nimport styles from '../styles.less';\n+import { getAuthority } from '@/utils/authority';\nconst FormItem = Form.Item;\nconst { Option } = Select;\n@@ -350,6 +351,8 @@ class Node extends PureComponent {\nrender() {\nconst { selectedRows, registerUserFormVisible, targetNodeId } = this.state;\n+ const userRole = getAuthority()[0];\n+\nconst {\nnode: { nodes, pagination },\nloadingNodes,\n@@ -485,9 +488,12 @@ class Node extends PureComponent {\n<Card bordered={false}>\n<div className={styles.tableList}>\n<div className={styles.tableListOperator}>\n+ {\n+ userRole !== 'operator' &&\n<Button icon=\"plus\" type=\"primary\" onClick={() => router.push('/operator/node/new')}>\n<FormattedMessage id=\"form.button.new\" defaultMessage=\"New\" />\n</Button>\n+ }\n</div>\n<StandardTable\nselectedRows={selectedRows}\n",
        "org_msg": "[#54]Remove the create button in node page when the user is operator",
        "sim_msg": "Showing post title in preview. Closes",
        "sim_diff": "diff --git a/app/static/js/Post.js b/app/static/js/Post.js @@ -402,6 +402,14 @@ u.addEventForChild(document, 'click', '.btn-preview', function (e, qelem) {\nfunction (data) {\nif (data.status == \"ok\") {\nqelem.parentNode.querySelector('.cpreview-content').innerHTML = data.text;\n+ const title = qelem.parentNode.parentNode.querySelector('#title');\n+ console.log(title);\n+ if(title) {\n+ const h = document.createElement('h2');\n+ h.innerText = title.value;\n+ qelem.parentNode.querySelector('.cpreview-content').prepend(document.createElement('hr'));\n+ qelem.parentNode.querySelector('.cpreview-content').prepend(h);\n+ }\nqelem.parentNode.querySelector('.cmpreview').style.display = 'block';\n} else {\nqelem.parentNode.querySelector('.error').style.display = 'block';\n",
        "chatgpt_cot": "Add user role check for operator and hide new button if the user role is operator in Node.js file."
    },
    {
        "org_diff": "diff --git a/rasa_core_sdk/forms.py b/rasa_core_sdk/forms.py @@ -115,8 +115,11 @@ class FormAction(Action):\nmapping_type = requested_slot_mapping[\"type\"]\nif mapping_type == \"from_entity\":\n- value = next(tracker.get_latest_entity_values(\n- requested_slot_mapping.get(\"entity\")), None)\n+ # list is used to cover the case of list slot type\n+ value = list(tracker.get_latest_entity_values(\n+ requested_slot_mapping.get(\"entity\")))\n+ if len(value) == 1:\n+ value = value[0]\nelif mapping_type == \"from_intent\":\nvalue = requested_slot_mapping.get(\"value\")\nelif mapping_type == \"from_text\":\n@@ -126,7 +129,7 @@ class FormAction(Action):\n'Provided slot mapping type '\n'is not supported')\n- if value is not None:\n+ if value:\nlogger.debug(\"Successfully extracted '{}'\"\n\"\".format(value))\nreturn value\n",
        "org_msg": "handle slot list type, fixes",
        "sim_msg": "adds extract_request_param to safely extract a typed value from URL parameters in the request",
        "sim_diff": "diff --git a/utils/request.py b/utils/request.py @@ -4,6 +4,7 @@ import re\n# HTK Imports\nfrom htk.utils import htk_setting\nfrom htk.utils.constants import *\n+from htk.utils.general import strtobool_safe\ndef get_current_request():\n@@ -26,6 +27,38 @@ def extract_request_ip(request):\nreturn request.environ['REMOTE_ADDR']\n+def extract_request_param(request, param, as_type=str, allow_none=True):\n+ \"\"\"Extracts a URL parameter from the request (i.e. request.GET.get)\n+\n+ - Performs basic input validation and allows typed retrieval via `as_type`\n+ - Can designate whether `None` is allowed via `allow_none`\n+ \"\"\"\n+ default_value_map = {\n+ str: '',\n+ bool: False,\n+ int: 0,\n+ float: 0,\n+ }\n+ default_value = None if allow_none else default_value_map.get(as_type, '')\n+\n+ raw_value = request.GET.get(param, default_value)\n+\n+ if as_type == str:\n+ value = raw_value\n+ elif as_type == bool:\n+ value = strtobool_safe(raw_value)\n+ elif as_type == int:\n+ m = re.match(r'^(?:\\+|\\-)?(?P<value>\\d+)\\.?$', raw_value) if raw_value else None\n+ value = int(m.group('value')) if m else default_value\n+ elif as_type == float:\n+ m = re.match(r'^(?:\\+|\\-)?(?P<value>\\d*\\.?\\d*)$', raw_value) if raw_value else None\n+ value = float(m.group('value')) if m else default_value\n+ else:\n+ value = raw_value\n+\n+ return value\n+\n+\ndef get_request_metadata(request):\npath = request.path\nurl_name = request.resolver_match.url_name\n",
        "chatgpt_cot": "\"Fix value extraction from entity in FormAction, handle list slot type and log successful extraction.\""
    },
    {
        "org_diff": "diff --git a/node_manager_daemon_fkie/src/node_manager_daemon_fkie/launch_servicer.py b/node_manager_daemon_fkie/src/node_manager_daemon_fkie/launch_servicer.py @@ -291,9 +291,9 @@ class LaunchServicer(lgrpc.LaunchServiceServicer):\n# test for required args\nprovided_args = [\"%s\" % arg.name for arg in request.args]\nlaunch_config = LaunchConfig(launchfile, masteruri=request.masteruri, host=request.host)\n- if request.request_args:\n# get the list with needed launch args\nreq_args = launch_config.get_args()\n+ if request.request_args:\nif req_args:\narg_dict = launch_config.argv2dict(req_args)\nfor arg, value in arg_dict.items():\n",
        "org_msg": "node_manager_daemon_fkie: fix request args while load launch file",
        "sim_msg": "No longer need a system client for command choices validation",
        "sim_diff": "diff --git a/bartender/requests.py b/bartender/requests.py @@ -18,7 +18,6 @@ from bg_utils.mongo.models import Choices, Request, System\nfrom brewtils.choices import parse\nfrom brewtils.errors import ModelValidationError, RequestPublishException, ConflictError\nfrom brewtils.models import Events\n-from brewtils.rest.system_client import SystemClient\nfrom brewtils.schema_parser import SchemaParser\nlogger = logging.getLogger(__name__)\n@@ -30,8 +29,6 @@ class RequestValidator(object):\ndef __init__(self):\nself.logger = logging.getLogger(__name__)\n- self._client = SystemClient(system_name=None, **bartender.config.web)\n-\nself._session = Session()\nif not bartender.config.web.ca_verify:\nurllib3.disable_warnings()\n@@ -264,21 +261,22 @@ class RequestValidator(object):\nif isinstance(choices.value, six.string_types):\nparsed_value = parse(choices.value, parse_as=\"func\")\n- response = self._client.send_bg_request(\n- _command=parsed_value[\"name\"],\n- _system_name=request.system,\n- _system_version=request.system_version,\n- _instance_name=request.instance_name,\n- **map_param_values(parsed_value[\"args\"]),\n+\n+ choices_request = Request(\n+ system=request.system,\n+ system_version=request.system_version,\n+ instance_name=request.instance_name,\n+ command=parsed_value[\"name\"],\n+ parameters=map_param_values(parsed_value[\"args\"]),\n)\nelif isinstance(choices.value, dict):\nparsed_value = parse(choices.value[\"command\"], parse_as=\"func\")\n- response = self._client.send_bg_request(\n- _command=parsed_value[\"name\"],\n- _system_name=choices.value.get(\"system\"),\n- _system_version=choices.value.get(\"version\"),\n- _instance_name=choices.value.get(\"instance_name\", \"default\"),\n- **map_param_values(parsed_value[\"args\"]),\n+ choices_request = Request(\n+ system=choices.value.get(\"system\"),\n+ system_version=choices.value.get(\"version\"),\n+ instance_name=choices.value.get(\"instance_name\", \"default\"),\n+ command=parsed_value[\"name\"],\n+ parameters=map_param_values(parsed_value[\"args\"]),\n)\nelse:\nraise ModelValidationError(\n@@ -286,6 +284,8 @@ class RequestValidator(object):\n\" must be a string or dictionary \" % command_parameter.key\n)\n+ response = process_request(choices_request, wait_timeout=10)\n+\nparsed_output = json.loads(response.output)\nif isinstance(parsed_output, list):\nif len(parsed_output) < 1:\n",
        "chatgpt_cot": "\"Fix issue with launch_servicer.py by correcting conditional statement and handling launch arguments in LaunchServicer class.\""
    },
    {
        "org_diff": "diff --git a/sc2/units.py b/sc2/units.py @@ -2,6 +2,7 @@ import random\nfrom .unit import Unit\nfrom .ids.unit_typeid import UnitTypeId\n+from .position import Point2\nclass Units(list):\n\"\"\"A collection for units. Makes it easy to select units by selectors.\"\"\"\n@@ -137,9 +138,8 @@ class Units(list):\ndef center(self):\n\"\"\" Returns the central point of all units in this list \"\"\"\nassert self.exists\n- pos = self.random.position\n- pos.x = sum([unit.position.x for unit in self]) / self.amount\n- pos.y = sum([unit.position.y for unit in self]) / self.amount\n+ pos = Point2((sum([unit.position.x for unit in self]) / self.amount, \\\n+ sum([unit.position.y for unit in self]) / self.amount))\nreturn pos\n@property\n",
        "org_msg": "Fix \"center of units\"",
        "sim_msg": "Returns indexes instead of points if input argument 'return_index' is True (by default it is False).",
        "sim_diff": "diff --git a/pyclustering/cluster/center_initializer.py b/pyclustering/cluster/center_initializer.py @@ -204,13 +204,15 @@ class kmeans_plusplus_initializer:\nreturn shortest_distances\n- def __get_next_center(self, centers):\n+ def __get_next_center(self, centers, return_index):\n\"\"\"!\n@brief Calculates the next center for the data.\n@param[in] centers (array_like): Current initialized centers.\n+ @param[in] return_index (bool): If True then return center's index instead of point.\n- @return (array_like) Next initialized center.\n+ @return (array_like) Next initialized center.<br>\n+ (uint) Index of next initialized center if return_index is True.\n\"\"\"\n@@ -222,9 +224,30 @@ class kmeans_plusplus_initializer:\nprobabilities = self.__calculate_probabilities(distances)\ncenter_index = self.__get_probable_center(distances, probabilities)\n+ if return_index:\n+ return center_index\n+\nreturn self.__data[center_index]\n+ def __get_initial_center(self, return_index):\n+ \"\"\"!\n+ @brief Choose randomly first center.\n+\n+ @param[in] return_index (bool): If True then return center's index instead of point.\n+\n+ @return (array_like) First center.<br>\n+ (uint) Index of first center.\n+\n+ \"\"\"\n+\n+ index_center = random.randint(0, len(self.__data) - 1)\n+ if return_index:\n+ return index_center\n+\n+ return self.__data[index_center]\n+\n+\ndef __calculate_probabilities(self, distances):\n\"\"\"!\n@brief Calculates cumulative probabilities of being center of each point.\n@@ -272,20 +295,23 @@ class kmeans_plusplus_initializer:\nreturn index_best_candidate\n- def initialize(self):\n+ def initialize(self, return_index=False):\n\"\"\"!\n@brief Calculates initial centers using K-Means++ method.\n+ @param[in] return_index (bool): If True then returns indexes of points from input data instead of points itself.\n+\n@return (list) List of initialized initial centers.\n+ If argument 'return_index' is False then returns list of points.\n+ If argument 'return_index' is True then returns list of indexes.\n\"\"\"\n- index_center = random.randint(0, len(self.__data) - 1)\n- centers = [ self.__data[ index_center ] ]\n+ centers = [ self.__get_initial_center(return_index) ]\n# For each next center\nfor _ in range(1, self.__amount):\n- next_center = self.__get_next_center(centers)\n+ next_center = self.__get_next_center(centers, return_index)\ncenters.append(next_center)\nreturn centers\n\\ No newline at end of file\n",
        "chatgpt_cot": "\"Refactor center method in Units class to use Point2 for central position calculation\""
    },
    {
        "org_diff": "diff --git a/fkie_master_sync/src/fkie_master_sync/sync_thread.py b/fkie_master_sync/src/fkie_master_sync/sync_thread.py @@ -447,6 +447,7 @@ class SyncThread(object):\nelse:\nrospy.logdebug(\"SyncThread[%s]: topic subscribed: %s, %s %s, node: %s\", self.name, h[1], str(code), str(statusMessage), h[3])\nif h[0] == 'sub' and code == 1 and len(r) > 0:\n+ if not self._do_ignore_ntp(h[3], h[1], h[2]):\n# topic, nodeuri, node : list of publisher uris\npubliser_to_update[(h[1], h[4], h[3])] = r\nelif h[0] == 'pub':\n",
        "org_msg": "fkie_master_sync: do not update publisher node if it is in filter lister",
        "sim_msg": "Fixing type problems on pid subscriptions",
        "sim_diff": "diff --git a/app/socketio.py b/app/socketio.py @@ -11,6 +11,6 @@ def handle_message():\n@socketio.on('subscribe', namespace='/snt')\ndef handle_subscription(data):\n- sub = str(data['target'])\n- if not sub.startswith('user'):\n+ sub = data['target']\n+ if not str(sub).startswith('user'):\njoin_room(sub)\n",
        "chatgpt_cot": "\"Add condition to ignore NTP for specific topics and nodes in SyncThread class\""
    },
    {
        "org_diff": "diff --git a/sc2/bot_ai.py b/sc2/bot_ai.py @@ -376,12 +376,12 @@ class BotAI(DistanceCalculation):\n# if current place is a gas extraction site,\n# go to the mineral field that is near and has the most minerals left\nelse:\n- local_minerals = [\n+ local_minerals = (\nmineral for mineral in self.mineral_field if mineral.distance_to(current_place) <= 8\n- ]\n- # Local_minerals can be empty if townhall is misplaced\n- if local_minerals:\n- target_mineral = max(local_minerals, key=lambda mineral: mineral.mineral_contents)\n+ )\n+ # local_minerals can be empty if townhall is misplaced\n+ target_mineral = max(local_minerals, key=lambda mineral: mineral.mineral_contents, default=None)\n+ if target_mineral:\nself.do(worker.gather(target_mineral))\n# more workers to distribute than free mining spots\n# send to closest if worker is doing nothing\n@@ -721,7 +721,7 @@ class BotAI(DistanceCalculation):\nasync def chat_send(self, message: str):\n\"\"\" Send a chat message. \"\"\"\n- assert isinstance(message, str), f\"{message} is no string\"\n+ assert isinstance(message, str), f\"{message} is not a string\"\nawait self._client.chat_send(message, False)\n# For the functions below, make sure you are inside the boundries of the map size.\n",
        "org_msg": "use generator in distribute workers",
        "sim_msg": "Adding backlog to chat",
        "sim_diff": "diff --git a/app/socketio.py b/app/socketio.py -from flask import session\nfrom flask_socketio import SocketIO, join_room\nfrom flask_login import current_user\n-from . import database as db\n-from . import misc\n+from flask import request\n+import redis\n+import config\n+import json\nsocketio = SocketIO()\n+redis = redis.from_url(config.SOCKETIO_REDIS_URL)\n# The new stuff\n@socketio.on('msg', namespace='/snt')\ndef chat_message(g):\nif g.get('msg'):\n- socketio.emit('msg', {'user': current_user.name, 'msg': g.get('msg')},\n- namespace='/snt', room='chat')\n+ message = {'user': current_user.name, 'msg': g.get('msg')}\n+ redis.lpush('chathistory', json.dumps(message))\n+ redis.ltrim('chathistory', 0, 20)\n+ socketio.emit('msg', message, namespace='/snt', room='chat')\n@socketio.on('connect', namespace='/snt')\n@@ -32,3 +36,7 @@ def handle_subscription(data):\nreturn\nif not str(sub).startswith('user'):\njoin_room(sub)\n+ if sub == 'chat':\n+ msgs = redis.lrange('chathistory', 0, 20)\n+ for m in msgs[::-1]:\n+ socketio.emit('msg', json.loads(m), namespace='/snt', room=request.sid)\n",
        "chatgpt_cot": "Fix type and syntax issues in bot_ai.py, ensure correct iteration over mineral field, and assert message is a string in chat_send method."
    },
    {
        "org_diff": "diff --git a/master_discovery_fkie/src/master_discovery_fkie/master_discovery.py b/master_discovery_fkie/src/master_discovery_fkie/master_discovery.py @@ -987,7 +987,7 @@ class Discoverer(object):\nraise Exception(\"old heartbeat version %s detected (current: %s), please update master_discovery on %s\" % (version, Discoverer.VERSION, address))\nelse:\nraise Exception(\"heartbeat version %s expected, received: %s\" % (Discoverer.VERSION, version))\n- raise Exception(\"massage is to small\")\n+ raise Exception(\"massage is too small\")\ndef timed_stats_calculation(self):\n'''\n",
        "org_msg": "grammar fix in exception message",
        "sim_msg": "minor fixup in deployment update",
        "sim_diff": "diff --git a/rest-service/manager_rest/deployment_update/manager.py b/rest-service/manager_rest/deployment_update/manager.py @@ -164,10 +164,7 @@ class DeploymentUpdateManager(object):\nnew_blueprint = self.sm.get(models.Blueprint, new_blueprint_id)\ndeployment_update.old_blueprint = old_blueprint\ndeployment_update.new_blueprint = new_blueprint\n- deployment.blueprint = new_blueprint\nself.sm.put(deployment_update)\n- deployment.inputs = new_inputs\n- self.sm.update(deployment)\nreturn deployment_update\ndef create_deployment_update_step(self,\n@@ -300,6 +297,12 @@ class DeploymentUpdateManager(object):\nreinstall_list=reinstall_list\n)\n+ deployment = self.sm.get(models.Deployment, dep_update.deployment_id)\n+ deployment.inputs = dep_update.new_inputs\n+ if dep_update.new_blueprint:\n+ deployment.blueprint = dep_update.new_blueprint\n+ self.sm.update(deployment)\n+\ndep_update.execution = execution\ndep_update.state = STATES.EXECUTING_WORKFLOW\nself.sm.update(dep_update)\n",
        "chatgpt_cot": "Fix typo in exception message for heartbeat version check in master_discovery.py."
    },
    {
        "org_diff": "diff --git a/node_manager_daemon_fkie/src/node_manager_daemon_fkie/screen.py b/node_manager_daemon_fkie/src/node_manager_daemon_fkie/screen.py @@ -243,7 +243,7 @@ def get_cmd(node, env=[], keys=[]):\naddkeys.append('RESPAWN_DELAY')\naddkeys.append('RESPAWN_MAX')\naddkeys.append('RESPAWN_MIN_RUNTIME')\n- for key in keys:\n+ for key in addkeys:\nif not _append_env(f, key, env):\n_append_env(f, key, os.environ)\nf.close()\n",
        "org_msg": "fixed set ENV in screen",
        "sim_msg": "Safegaurd against there not being a wallet on status call\nAlso switch status call to an inlineCallback",
        "sim_diff": "diff --git a/lbrynet/lbrynet_daemon/Daemon.py b/lbrynet/lbrynet_daemon/Daemon.py @@ -1038,6 +1038,7 @@ class Daemon(AuthJSONRPCServer):\n# #\n############################################################################\n+ @defer.inlineCallbacks\ndef jsonrpc_status(self, p={}):\n\"\"\"\nReturn daemon status\n@@ -1048,11 +1049,11 @@ class Daemon(AuthJSONRPCServer):\nReturns:\ndaemon status\n\"\"\"\n-\n+ has_wallet = self.session and self.session.wallet\nresponse = {\n'lbry_id': base58.b58encode(self.lbryid)[:SHORT_ID_LEN],\n'is_running': self.announced_startup,\n- 'is_first_run': self.session.wallet.is_first_run if self.session else None,\n+ 'is_first_run': self.session.wallet.is_first_run if has_wallet else None,\n'startup_status': {\n'code': self.startup_status[0],\n'message': self.startup_status[1],\n@@ -1067,42 +1068,24 @@ class Daemon(AuthJSONRPCServer):\n},\n'blocks_behind': (\nself.session.wallet.blocks_behind\n- if self.session and self.wallet_type == LBRYUM_WALLET\n+ if has_wallet and self.wallet_type == LBRYUM_WALLET\nelse 'unknown'\n),\n}\n-\n- d = defer.succeed(None)\n-\nif p.get('session_status', False):\n- d.addCallback(lambda _: self.session.blob_manager.get_all_verified_blobs())\n-\n- def _include_session_status(blobs):\n+ blobs = yield self.session.blob_manager.get_all_verified_blobs()\nresponse['session_status'] = {\n'managed_blobs': len(blobs),\n'managed_streams': len(self.lbry_file_manager.lbry_files),\n}\n-\n- d.addCallback(_include_session_status)\n-\n- if p.get('blockchain_status', False) and self.session and self.session.wallet:\n+ if p.get('blockchain_status', False) and has_wallet:\n# calculate blocks_behind more accurately\nlocal_height = self.session.wallet.network.get_local_height()\nremote_height = self.session.wallet.network.get_server_height()\nresponse['blocks_behind'] = remote_height - local_height\n-\n- d.addCallback(lambda _: self.session.wallet.get_best_blockhash())\n-\n- def _include_blockchain_status(best_hash):\n- response['blockchain_status'] = {\n- 'best_blockhash': best_hash,\n- }\n-\n- d.addCallback(_include_blockchain_status)\n-\n- d.addCallback(lambda x: self._render_response(response))\n- return d\n- # return self._render_response(response)\n+ best_hash = yield self.session.wallet.get_best_blockhash()\n+ response['blockchain_status'] = {'best_blockhash': best_hash}\n+ defer.returnValue(response)\ndef jsonrpc_get_best_blockhash(self):\n\"\"\"\n@@ -1117,7 +1100,7 @@ class Daemon(AuthJSONRPCServer):\n\"\"\"\nDEPRECATED. Use `status` instead\n\"\"\"\n- d = self.jsonrpc_status({'blockchain_status': True})\n+ d = self.jsonrpc_status()\nd.addCallback(lambda x: self._render_response(x['is_running']))\nreturn d\n",
        "chatgpt_cot": "\"Fix issue with environment variables in screen.py by using addkeys instead of keys to append to environment.\""
    },
    {
        "org_diff": "diff --git a/default_cfg_fkie/src/default_cfg_fkie/default_cfg.py b/default_cfg_fkie/src/default_cfg_fkie/default_cfg.py @@ -103,6 +103,20 @@ class DefaultCfg(object):\nself._pending_starts = set()\nself._pending_starts_last_printed = set()\n+ def _filter_args(self, argv):\n+ afilter = ['__ns:=', '__name:=', '_package:=', '_launch_file:=']\n+ result = []\n+ for a in argv:\n+ in_filter = False\n+ for f in afilter:\n+ if a.startswith(f):\n+ in_filter = True\n+ break\n+ if ':=' not in a or in_filter:\n+ continue\n+ result.append(a)\n+ return result\n+\ndef load(self, delay_service_creation=0.):\n'''\nLoad the launch file configuration\n@@ -123,11 +137,12 @@ class DefaultCfg(object):\nself.masteruri = self._masteruri_from_ros()\nself.roscfg = ROSLaunchConfig()\nloader = XmlLoader()\n- argv = [a for a in sys.argv if not a.startswith('__ns:=') and not a.startswith('__name:=')]\n+ argv = self._filter_args(sys.argv)\n# remove namespace from sys.argv to avoid load the launchfile info local namespace\n- sys.argv = [a for a in sys.argv if not a.startswith('__ns:=') and not a.startswith('__name:=')]\n+ sys.argv = list(argv)\n# set the global environment to empty namespace\nos.environ[ROS_NAMESPACE] = rospy.names.SEP\n+ rospy.set_param('~argv', argv)\nloader.load(launch_path, self.roscfg, verbose=False, argv=argv)\n# create the list with node names\nfor item in self.roscfg.nodes:\n",
        "org_msg": "default_cfg_fkie: store the arguments to parameter server",
        "sim_msg": "Make pycodestyle consistent with black",
        "sim_diff": "diff --git a/setup.cfg b/setup.cfg @@ -11,7 +11,7 @@ filterwarnings =\n[pycodestyle]\ncount = True\n-ignore = E121,E123,E126,E133,E226,E241,E242,E704,W503,W504,W505,E741,W605,W293,W291,W292,E203\n+ignore = E121,E123,E126,E133,E226,E241,E242,E704,W503,W504,W505,E741,W605,W293,W291,W292,E203,E231\nmax-line-length = 120\nstatistics = True\nexclude=pymatgen/__init__.py,docs_rst/*.py\n@@ -19,7 +19,7 @@ exclude=pymatgen/__init__.py,docs_rst/*.py\n[flake8]\nexclude = .git,__pycache__,docs_rst/conf.py,tests,__init__.py\n# max-complexity = 10\n-extend-ignore = E741,W291,W293,E501\n+extend-ignore = E741,W291,W293,E501,E231\nmax-line-length = 120\n[pydocstyle]\n",
        "chatgpt_cot": "Add method to filter args and set global environment to empty namespace to avoid loading the launchfile info local namespace. Fix compilation issue."
    },
    {
        "org_diff": "diff --git a/rasa_core_sdk/forms.py b/rasa_core_sdk/forms.py @@ -51,7 +51,7 @@ class FormAction(Action):\nreturn {\"type\": \"from_text\", \"intent\": intent}\n# noinspection PyMethodMayBeStatic\n- def slots_mappings(self):\n+ def slot_mappings(self):\n# type: () -> Dict[Text: Union[Dict, List[Dict]]]\n\"\"\"A dictionary to map required slots to\n- an extracted entity\n@@ -76,7 +76,7 @@ class FormAction(Action):\nslot_to_fill = tracker.get_slot(REQUESTED_SLOT)\n# map requested_slot to entity\n- requested_slot_mappings = self.slots_mappings().get(slot_to_fill)\n+ requested_slot_mappings = self.slot_mappings().get(slot_to_fill)\nif not requested_slot_mappings:\nrequested_slot_mappings = self.from_entity(slot_to_fill)\n",
        "org_msg": "slots_mappings -> slot_mappings RasaHQ/roadmap#280",
        "sim_msg": "Allow users with names longer than the current limit to log in",
        "sim_diff": "diff --git a/app/forms/user.py b/app/forms/user.py @@ -78,7 +78,7 @@ class UsernameLength:\nclass LoginForm(RedirectForm):\n\"\"\" Login form. \"\"\"\n- username = StringField(_l(\"Username\"), validators=[UsernameLength()])\n+ username = StringField(_l(\"Username\"), validators=[Length(max=256)])\npassword = PasswordField(\n_l(\"Password\"), validators=[DataRequired(), Length(min=7, max=256)]\n)\n",
        "chatgpt_cot": "Update method name from slots_mappings to slot_mappings in FormAction class to maintain consistency and improve readability. Fix potential bug in slot_mappings method."
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/launch_files_widget.py b/node_manager_fkie/src/node_manager_fkie/launch_files_widget.py @@ -342,7 +342,6 @@ class LaunchFilesWidget(QDockWidget):\nif event == QKeySequence.Delete:\nselected = self._launchItemsFromIndexes(self.xmlFileView.selectionModel().selectedIndexes(), False)\nfor item in selected:\n- if item.path in self.launchlist_model.load_history:\nnm.settings().launch_history_remove(item.path)\nself.launchlist_model.reloadCurrentPath()\nelif not key_mod and event.key() == Qt.Key_F4 and self.editXmlButton.isEnabled():\n",
        "org_msg": "node_manager_fkie: fix crash while remove history file",
        "sim_msg": "better setting of focus when removing nodes",
        "sim_diff": "diff --git a/tree.py b/tree.py @@ -609,7 +609,7 @@ class WidgetTree(wx.TreeCtrl, Tree):\ndef remove(self, node=None, delete=True):\nself.app.saved = False # update the status of the app\n- set_focus = self.current is node.widget\n+ set_focus = self.current and ( self.current is node.widget or self.current.has_ancestor(node) )\nTree.remove(self, node)\nif node is not None:\nif delete:\n",
        "chatgpt_cot": "Remove item from launch history if present, reload path, and disable edit button if condition is met in LaunchFilesWidget."
    },
    {
        "org_diff": "diff --git a/fkie_node_manager/src/fkie_node_manager/start_handler.py b/fkie_node_manager/src/fkie_node_manager/start_handler.py @@ -399,6 +399,8 @@ class StartHandler(object):\nrospy.loginfo(\"open ROS log: %s\", cmd)\nSupervisedPopen(shlex.split(cmd), object_id=\"Open log\", description=\"Open log for '%s' on '%s'\" % (utf8(nodename), utf8(host)))\nfound = True\n+ if not found:\n+ rospy.logwarn('no log files found for %s' % utf8(nodename))\nreturn found\nelse:\n_ps = nm.ssh().ssh_x11_exec(host, [nm.settings().start_remote_script, '--show_screen_log', nodename], title_opt, user)\n",
        "org_msg": "fkie_node_manager: add warning if no log file was found on local host",
        "sim_msg": "remove discord raw event logging, getting a bit overkill at this point",
        "sim_diff": "diff --git a/GearBot/Util/GearbotLogging.py b/GearBot/Util/GearbotLogging.py @@ -41,10 +41,9 @@ def init_logger():\nDISCORD_LOGGER.addHandler(handler)\nLOGGER.addHandler(handler)\n- handler = TimedRotatingFileHandler(filename='logs/discord.log', encoding='utf-8', when=\"h\", interval=4,\n- backupCount=30)\n+ # handler = TimedRotatingFileHandler(filename='logs/discord.log', encoding='utf-8', when=\"h\", interval=1, backupCount=24)\n- DISCORD_LOGGER.addHandler(handler)\n+ # DISCORD_LOGGER.addHandler(handler)\nasync def onReady(bot: commands.Bot, channelID):\n",
        "chatgpt_cot": "Add a warning log message when no log files are found for the specified node."
    },
    {
        "org_diff": "diff --git a/fkie_node_manager_daemon/src/fkie_node_manager_daemon/launcher.py b/fkie_node_manager_daemon/src/fkie_node_manager_daemon/launcher.py @@ -142,7 +142,7 @@ def create_start_config(node, launchcfg, executable='', masteruri=None, loglevel\nreturn result\n-def remove_src_binary(cls, cmdlist):\n+def remove_src_binary(cmdlist):\nresult = []\ncount = 0\nif len(cmdlist) > 1:\n@@ -193,7 +193,7 @@ def run_node(startcfg):\n# get binary path from package\nif not cmd_type:\ntry:\n- cmd = roslib.packages.find_resource(startcfg.package, startcfg.binary)\n+ cmd = roslib.packages.find_node(startcfg.package, startcfg.binary)\nexcept (roslib.packages.ROSPkgException, rospkg.ResourceNotFound) as e:\n# multiple nodes, invalid package\nrospy.logwarn(\"resource not found: %s\" % utf8(e))\n",
        "org_msg": "fkie_node_manager: fixed last broken commit",
        "sim_msg": "make directories in one place when initializing",
        "sim_diff": "diff --git a/lbrynet/lbrynet_daemon/Daemon.py b/lbrynet/lbrynet_daemon/Daemon.py @@ -232,18 +232,11 @@ class Daemon(AuthJSONRPCServer):\nconf.settings.update(last_version)\nself.db_dir = conf.settings['data_dir']\nself.download_directory = conf.settings['download_directory']\n- if not os.path.exists(self.download_directory):\n- os.mkdir(self.download_directory)\n- self.created_data_dir = False\n- if not os.path.exists(self.db_dir):\n- os.mkdir(self.db_dir)\n- self.created_data_dir = True\nif conf.settings['BLOBFILES_DIR'] == \"blobfiles\":\nself.blobfile_dir = os.path.join(self.db_dir, \"blobfiles\")\nelse:\nlog.info(\"Using non-default blobfiles directory: %s\", conf.settings['BLOBFILES_DIR'])\nself.blobfile_dir = conf.settings['BLOBFILES_DIR']\n-\nself.run_on_startup = conf.settings['run_on_startup']\nself.data_rate = conf.settings['data_rate']\nself.max_key_fee = conf.settings['max_key_fee']\n@@ -296,7 +289,7 @@ class Daemon(AuthJSONRPCServer):\n}\nself.looping_call_manager = LoopingCallManager(calls)\nself.sd_identifier = StreamDescriptorIdentifier()\n- self.stream_info_manager = DBEncryptedFileMetadataManager(self.db_dir)\n+ self.stream_info_manager = None\nself.lbry_file_manager = None\n@defer.inlineCallbacks\n@@ -601,7 +594,10 @@ class Daemon(AuthJSONRPCServer):\nold_revision = 1\nself.startup_status = STARTUP_STAGES[1]\nlog.info(\"Loading databases\")\n- if self.created_data_dir:\n+ if not os.path.exists(self.download_directory):\n+ os.mkdir(self.download_directory)\n+ if not os.path.exists(self.db_dir):\n+ os.mkdir(self.db_dir)\nself._write_db_revision_file(self.current_db_revision)\nlog.debug(\"Created the db revision file: %s\", self.db_revision_file)\nif not os.path.exists(self.blobfile_dir):\n@@ -642,6 +638,7 @@ class Daemon(AuthJSONRPCServer):\ndef _setup_lbry_file_manager(self):\nlog.info('Starting to setup up file manager')\nself.startup_status = STARTUP_STAGES[3]\n+ self.stream_info_manager = DBEncryptedFileMetadataManager(self.db_dir)\nyield self.stream_info_manager.setup()\nself.lbry_file_manager = EncryptedFileManager(\nself.session,\n",
        "chatgpt_cot": "\"Fix compilation issue by removing src_binary method and updating find_resource to find_node in launcher.py\""
    },
    {
        "org_diff": "diff --git a/fkie_node_manager_daemon/src/fkie_node_manager_daemon/monitor/net_load.py b/fkie_node_manager_daemon/src/fkie_node_manager_daemon/monitor/net_load.py @@ -58,6 +58,7 @@ class NetLoad(SensorInterface):\nself.settings = settings\ndef check_sensor(self):\n+ try:\nnet_stats = psutil.net_if_stats()\nnet = psutil.net_io_counters(pernic=True)\ndiag_level = 0\n@@ -117,3 +118,8 @@ class NetLoad(SensorInterface):\nself._stat_msg.level = diag_level\nself._stat_msg.values = diag_vals\nself._stat_msg.message = diag_msg\n+ except Exception as error:\n+ import traceback\n+ print(traceback.format_exc())\n+ rospy.logwarn(\"Sensor network not checked because of error: %s\" % utf8(error))\n+ self._interval = 0\n",
        "org_msg": "fkie_node_manager_daemon: catch error if no net_if_stats available",
        "sim_msg": "CarbonBlack Response: Made quarantine device, unquarantine device, and sync event compatible with CBR 7.x",
        "sim_diff": "diff --git a/Apps/phcarbonblackresponse/carbonblack_connector.py b/Apps/phcarbonblackresponse/carbonblack_connector.py @@ -1262,9 +1262,11 @@ class CarbonblackConnector(BaseConnector):\n# any time in the future should work, but the official API uses now + 24h, so we will use that as well\n# the timezone is hard-coded to match what was seen in the web interface\n- sensor['event_log_flush_time'] = (datetime.datetime.now() + datetime.timedelta(days=1)).strftime('%a, %d %b %Y %H:%M:%S GMT')\n+ updated_sensor = dict()\n+ updated_sensor['event_log_flush_time'] = (datetime.datetime.now() + datetime.timedelta(days=1)).strftime('%a, %d %b %Y %H:%M:%S GMT')\n+ updated_sensor['group_id'] = sensor.get(\"group_id\")\n- ret_val, body = self._make_rest_call(\"/v1/sensor/{0}\".format(sensor_id), action_result, data=sensor, method=\"put\", additional_succ_codes={204: []})\n+ ret_val, body = self._make_rest_call(\"/v1/sensor/{0}\".format(sensor_id), action_result, data=updated_sensor, method=\"put\", additional_succ_codes={204: []})\nif (phantom.is_fail(ret_val)):\nreturn action_result.get_status()\n@@ -1414,11 +1416,13 @@ class CarbonblackConnector(BaseConnector):\nendpoint_id = data['id']\n# set the isolation status\n- data['network_isolation_enabled'] = state\n+ updated_data = dict()\n+ updated_data['network_isolation_enabled'] = state\n+ updated_data['group_id'] = data.get('group_id')\n# make a rest call to set the endpoint state\nret_val, response = self._make_rest_call(\"/v1/sensor/{0}\".format(endpoint_id), action_result, method=\"put\",\n- data=data, params=query_parameters, parse_response_json=False, additional_succ_codes={204: []})\n+ data=updated_data, params=query_parameters, parse_response_json=False, additional_succ_codes={204: []})\nif (phantom.is_fail(ret_val)):\nreturn (action_result.get_status(), None)\n",
        "chatgpt_cot": "Add exception handling for network sensor check to handle errors and log warnings. Fix potential issues with network sensor functionality."
    },
    {
        "org_diff": "diff --git a/sc2/cache.py b/sc2/cache.py @@ -26,13 +26,13 @@ def property_cache_once_per_frame(f):\ndef inner(self):\nproperty_cache = \"_cache_\" + f.__name__\nstate_cache = \"_frame_\" + f.__name__\n- cache_updated = hasattr(self, property_cache) and getattr(self, state_cache, None) == self.state.game_loop\n+ cache_updated = getattr(self, state_cache, -1) == self.state.game_loop\nif not cache_updated:\nsetattr(self, property_cache, f(self))\nsetattr(self, state_cache, self.state.game_loop)\ncache = getattr(self, property_cache)\n- should_copy = type(cache).__name__ == \"Units\" or isinstance(cache, (list, set, dict, Counter, np.ndarray))\n+ should_copy = callable(getattr(cache, \"copy\", None))\nif should_copy:\nreturn cache.copy()\nreturn cache\n@@ -40,8 +40,31 @@ def property_cache_once_per_frame(f):\nreturn property(inner)\n+def property_cache_once_per_frame_no_copy(f):\n+ \"\"\" This decorator caches the return value for one game loop,\n+ then clears it if it is accessed in a different game loop.\n+ Only works on properties of the bot object, because it requires\n+ access to self.state.game_loop\n+\n+ This decorator compared to the above runs a little faster, however you should only use this decorator if you are sure that you do not modify the mutable once it is calculated and cached. \"\"\"\n+\n+ @wraps(f)\n+ def inner(self):\n+ property_cache = \"_cache_\" + f.__name__\n+ state_cache = \"_frame_\" + f.__name__\n+ cache_updated = getattr(self, state_cache, -1) == self.state.game_loop\n+ if not cache_updated:\n+ setattr(self, property_cache, f(self))\n+ setattr(self, state_cache, self.state.game_loop)\n+\n+ cache = getattr(self, property_cache)\n+ return cache\n+\n+ return property(inner)\n+\n+\ndef property_immutable_cache(f):\n- \"\"\" This cache should only be used on properties that return an immutable object \"\"\"\n+ \"\"\" This cache should only be used on properties that return an immutable object (bool, str, int, float, tuple, Unit, Point2, Point3) \"\"\"\n@wraps(f)\ndef inner(self):\n",
        "org_msg": "Improve cache, add another cache decorator that does not copy mutables",
        "sim_msg": "[asset] caching",
        "sim_diff": "diff --git a/bitshares/asset.py b/bitshares/asset.py @@ -3,6 +3,9 @@ from .exceptions import AssetDoesNotExistsException\nclass Asset(dict):\n+\n+ assets_cache = dict()\n+\ndef __init__(\nself,\nasset,\n@@ -21,7 +24,10 @@ class Asset(dict):\nsuper(Asset, self).__init__(asset)\nself.cached = True\n- if not lazy and not self.cached:\n+ if self.asset in Asset.assets_cache:\n+ super(Asset, self).__init__(Asset.assets_cache[self.asset])\n+ self.cached = True\n+ elif not lazy and not self.cached:\nself.refresh()\ndef refresh(self):\n@@ -33,6 +39,9 @@ class Asset(dict):\nself[\"bitasset_data\"] = self.bitshares.rpc.get_object(asset[\"bitasset_data_id\"])\nself.cached = True\n+ # store in cache\n+ Asset.assets_cache[asset[\"symbol\"]] = asset\n+\n@property\ndef is_bitasset(self):\nreturn (\"bitasset_data_id\" in self)\n",
        "chatgpt_cot": "Add and modify property cache decorators for the SC2 cache file to optimize performance and ensure proper usage."
    },
    {
        "org_diff": "diff --git a/sc2/player.py b/sc2/player.py @@ -28,7 +28,11 @@ class Human(AbstractPlayer):\nclass Bot(AbstractPlayer):\ndef __init__(self, race, ai):\n- assert isinstance(ai, BotAI)\n+ \"\"\"\n+ AI can be None if this player object is just used to inform the\n+ server about player types.\n+ \"\"\"\n+ assert isinstance(ai, BotAI) or ai is None\nsuper().__init__(PlayerType.Participant, race)\nself.ai = ai\n",
        "org_msg": "Allow bots without AI object for external games",
        "sim_msg": "set team to red if joining a team-vs multi",
        "sim_diff": "diff --git a/objects/player.py b/objects/player.py @@ -17,7 +17,7 @@ from constants.gamemodes import GameMode\nfrom constants.mods import Mods\nfrom objects.channel import Channel\n-from objects.match import Match, SlotStatus\n+from objects.match import Match, SlotStatus, MatchTeamTypes, MatchTeams\nfrom objects.beatmap import Beatmap\nfrom objects import glob\n@@ -412,6 +412,11 @@ class Player:\nslot = m.slots[0 if slotID == -1 else slotID]\n+ # if in a teams-vs mode, switch team from neutral to red.\n+ if m.team_type in (MatchTeamTypes.team_vs,\n+ MatchTeamTypes.tag_team_vs):\n+ slot.team = MatchTeams.red\n+\nslot.status = SlotStatus.not_ready\nslot.player = self\nself.match = m\n",
        "chatgpt_cot": "Add assertion for ai parameter in Bot class to handle case where ai is None."
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/editor/text_edit.py b/node_manager_fkie/src/node_manager_fkie/editor/text_edit.py @@ -251,7 +251,7 @@ class TextEdit(QTextEdit):\nexcept Exception, e:\nMessageBox.critical(self, \"Error\", \"File not found %s\" % inc_files[0], detailed_text=utf8(e))\nexcept Exception as err:\n- MessageBox.critical(self, \"Error\", \"Error while request included file %s\" % inc_files[0], detailed_text=utf8(err))\n+ MessageBox.critical(self, \"Error\", \"Error while request included file %s\" % self.filename, detailed_text=utf8(err))\nQTextEdit.mouseReleaseEvent(self, event)\ndef mouseMoveEvent(self, event):\n",
        "org_msg": "fix bug in message",
        "sim_msg": "issues/1961 solved\nkeyword Drag And Drop By Coordinates:\nRemoved drop parameter because it did not meet the expectations.",
        "sim_diff": "diff --git a/Browser/keywords/interaction.py b/Browser/keywords/interaction.py @@ -914,14 +914,13 @@ class Interaction(LibraryComponent):\nto_x: float,\nto_y: float,\nsteps: int = 1,\n- drop: bool = True,\n):\n\"\"\"Executes a Drag&Drop operation from a coordinate to another coordinate.\nFirst it moves the mouse to the start-point,\nthen presses the left mouse button,\nthen moves to the end-point in specified number of steps,\n- then releases the mouse button depending on the drop argument.\n+ then releases the mouse button.\nStart- and end-point are defined by ``x`` and ``y`` coordinates relative to\nthe top left corner of the pages viewport.\n@@ -932,9 +931,6 @@ class Interaction(LibraryComponent):\n``steps`` defines how many intermediate mouse move events are sent.\n- ``drop`` defines whether the operation ends with a dropped mouse.\n- Defaults to true.\n-\nExample:\n| `Drag And Drop By Coordinates`\n| ... from_x=30 from_y=30\n@@ -942,7 +938,6 @@ class Interaction(LibraryComponent):\n\"\"\"\nself.mouse_button(MouseButtonAction.down, x=from_x, y=from_y)\nself.mouse_move(x=to_x, y=to_y, steps=steps)\n- if drop:\nself.mouse_button(MouseButtonAction.up)\n@keyword(tags=(\"Setter\", \"PageContent\"))\n",
        "chatgpt_cot": "Fix exception handling in TextEdit class to display the correct filename when requesting an included file."
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/editor/text_edit.py b/node_manager_fkie/src/node_manager_fkie/editor/text_edit.py @@ -305,7 +305,7 @@ class TextEdit(QTextEdit):\nident = self.getIdentOfCurretLine()\nQTextEdit.keyPressEvent(self, event)\nif event.key() in [Qt.Key_Enter, Qt.Key_Return]:\n- self.indentCurrentLine(ident)\n+ self.indentCurrentLine(ident - self.getIdentOfCurretLine())\nelse:\nevent.accept()\nQTextEdit.keyPressEvent(self, event)\n",
        "org_msg": "node_manager_fkie: editor: fix ident on new line",
        "sim_msg": "Added confirmation request to close TT window when text has been changed (GTK)\nRelates to issue",
        "sim_diff": "diff --git a/extension/textext/asktext.py b/extension/textext/asktext.py @@ -196,7 +196,8 @@ class AskText(object):\nDEFAULT_INSERTSPACES = True\nDEFAULT_TABWIDTH = 4\nDEFAULT_NEW_NODE_CONTENT = \"Empty\"\n- DEFAULT_CLOSE_SHORTCUT = \"None\"\n+ DEFAULT_CLOSE_SHORTCUT = \"Escape\"\n+ DEFAULT_CONFIRM_CLOSE = True\nNEW_NODE_CONTENT = [\"Empty\", \"InlineMath\", \"DisplayMath\"]\nCLOSE_SHORTCUT = [\"Escape\", \"CtrlQ\", \"None\"]\n@@ -242,7 +243,7 @@ class AskText(object):\n@staticmethod\ndef cb_cancel(widget=None, data=None):\n\"\"\"Callback for Cancel button\"\"\"\n- raise SystemExit(1)\n+ pass\ndef cb_ok(self, widget=None, data=None):\n\"\"\"Callback for OK / Save button\"\"\"\n@@ -275,6 +276,11 @@ if TOOLKIT == TK:\nself._frame = None\nself._scale = None\n+ @staticmethod\n+ def cb_cancel(widget=None, data=None):\n+ \"\"\"Callback for Cancel button\"\"\"\n+ raise SystemExit(1)\n+\n@staticmethod\ndef validate_spinbox_input(d, i, P, s, S, v, V, W):\n\"\"\" Ensure that only floating point numbers are accepted as input of a Tk widget\n@@ -748,14 +754,28 @@ if TOOLKIT in (GTK, GTKSOURCEVIEW):\ngtk.main_quit()\nreturn False\n+ def cb_cancel(self, widget=None, data=None):\n+ \"\"\"Callback for Cancel button\"\"\"\n+ self.window_deleted_cb(widget, None, None)\n+\ndef move_cursor_cb(self, text_buffer, cursoriter, mark, view):\nself.update_position_label(text_buffer, view)\n- @staticmethod\n- def window_deleted_cb(widget, event, view):\n- gtk.main_quit()\n+ def window_deleted_cb(self, widget, event, view):\n+ if self._gui_config.get(\"confirm_close\", self.DEFAULT_CONFIRM_CLOSE) and \\\n+ self._source_buffer.get_text(self._source_buffer.get_start_iter(), self._source_buffer.get_end_iter()) \\\n+ != self.text:\n+ dlg = gtk.MessageDialog(self._window, gtk.DIALOG_MODAL, gtk.MESSAGE_QUESTION, gtk.BUTTONS_YES_NO,\n+ \"You made text changes, do you really want to close TexText?\")\n+ res = dlg.run()\n+ dlg.destroy()\n+ if res == gtk.RESPONSE_NO:\nreturn True\n+ gtk.main_quit()\n+ return False\n+\n+\ndef update_preview(self, widget):\n\"\"\"Update the preview image of the GUI using the callback it gave \"\"\"\nif self._preview_callback:\n@@ -1160,11 +1180,13 @@ if TOOLKIT in (GTK, GTKSOURCEVIEW):\nif self.text==\"\":\nif new_node_content_value=='InlineMath':\n- self._source_buffer.set_text(\"$$\")\n+ self.text=\"$$\"\n+ self._source_buffer.set_text(self.text)\niter = self._source_buffer.get_iter_at_offset(1)\nself._source_buffer.place_cursor(iter)\nif new_node_content_value=='DisplayMath':\n- self._source_buffer.set_text(\"$$$$\")\n+ self.text = \"$$$$\"\n+ self._source_buffer.set_text(self.text)\niter = self._source_buffer.get_iter_at_offset(2)\nself._source_buffer.place_cursor(iter)\n",
        "chatgpt_cot": "\"Fix indentation issue in TextEdit class\""
    },
    {
        "org_diff": "diff --git a/sc2/client.py b/sc2/client.py @@ -363,10 +363,18 @@ class Client(Protocol):\n\"\"\" Helper function for color conversion \"\"\"\nif color is None:\nreturn debug_pb.Color(r=255, g=255, b=255)\n+ else:\n+ if isinstance(color, (tuple, list)):\n+ assert(len(color) == 3)\n+\n+ r = color[0]\n+ g = color[1]\n+ b = color[2]\nelse:\nr = getattr(color, \"r\", getattr(color, \"x\", 255))\ng = getattr(color, \"g\", getattr(color, \"y\", 255))\nb = getattr(color, \"b\", getattr(color, \"z\", 255))\n+\nif max(r, g, b) <= 1:\nr *= 255\ng *= 255\n",
        "org_msg": "Make to_debug_color accept lists and tuples as arguments",
        "sim_msg": "langkit.utils.colors: Use built-in term colors",
        "sim_diff": "diff --git a/langkit/utils/colors.py b/langkit/utils/colors.py @@ -16,12 +16,12 @@ class Colors(object):\nENDC = '\\033[0m'\nBOLD = '\\033[1m'\n- RED = '\\033[91m'\n- GREEN = '\\033[92m'\n- YELLOW = '\\033[93m'\n- BLUE = '\\033[94m'\n- MAGENTA = '\\033[95m'\n- CYAN = '\\033[96m'\n+ RED = '\\033[31m'\n+ GREEN = '\\033[32m'\n+ YELLOW = '\\033[33m'\n+ BLUE = '\\033[34m'\n+ MAGENTA = '\\033[35m'\n+ CYAN = '\\033[36m'\nGREY = '\\033[97m'\nHEADER = MAGENTA\n",
        "chatgpt_cot": "Fix color conversion function to handle tuple or list input and ensure color values are within the valid range of 0 to 255."
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/echo_dialog.py b/node_manager_fkie/src/node_manager_fkie/echo_dialog.py @@ -754,7 +754,7 @@ class EchoDialog(QDialog):\nslot_name = f\nif isinstance(cval, (list, tuple)):\nslot_name = \"%s[%d]\" % (f, len(cval))\n- slots.append(p % (slot_name, self.strify_message(cval, ni, time_offset, current_time, field_filter, fixed_numeric_width)))\n+ slots.append(p % (utf8(slot_name), self.strify_message(utf8(cval), ni, time_offset, current_time, field_filter, fixed_numeric_width)))\nvals = '\\n'.join(slots)\nif indent:\nreturn '\\n' + vals\n",
        "org_msg": "Fix echo of non-ascii values",
        "sim_msg": "change View to Open in qbutton",
        "sim_diff": "diff --git a/qualcoder/GUI/ui_dialog_manage_files.py b/qualcoder/GUI/ui_dialog_manage_files.py @@ -54,7 +54,7 @@ class Ui_Dialog_manage_files(object):\ndef retranslateUi(self, Dialog_manage_files):\n_translate = QtCore.QCoreApplication.translate\nDialog_manage_files.setWindowTitle(_translate(\"Dialog_manage_files\", \"Files\"))\n- self.pushButton_view.setText(_translate(\"Dialog_manage_files\", \"View\"))\n+ self.pushButton_view.setText(_translate(\"Dialog_manage_files\", \"Open\"))\nself.pushButton_create.setText(_translate(\"Dialog_manage_files\", \"Create\"))\nself.pushButton_export.setToolTip(_translate(\"Dialog_manage_files\", \"<html><head/><body><p>Make sure the file name does not contain unusual characters such as \\': ; &quot; \\' otherwise it will raise an error when trying to save this file. Rename the file if needed.</p></body></html>\"))\nself.pushButton_export.setText(_translate(\"Dialog_manage_files\", \"Export\"))\n",
        "chatgpt_cot": "Fix encoding issue by converting slot_name and cval to UTF-8 in strify_message method to ensure proper handling of non-ASCII characters."
    },
    {
        "org_diff": "diff --git a/sc2/bot_ai.py b/sc2/bot_ai.py @@ -1477,7 +1477,8 @@ class BotAI(DistanceCalculation):\nself.structures.append(unit_obj)\nif unit_id in race_townhalls[self.race]:\nself.townhalls.append(unit_obj)\n- elif unit_id in ALL_GAS:\n+ elif unit_id in ALL_GAS or unit_obj.vespene_contents:\n+ # TODO: remove \"or unit_obj.vespene_contents\" when a new linux client newer than version 4.10.0 is released\nself.gas_buildings.append(unit_obj)\nelif unit_id in {\nUnitTypeId.TECHLAB,\n",
        "org_msg": "Add temporary fix for linux client to include rich geysirs (e.g. EXTRACTORRICH) in gas_buildings",
        "sim_msg": "Forgot to update iNumPlayers",
        "sim_diff": "diff --git a/v3/runner.py b/v3/runner.py @@ -63,6 +63,8 @@ if __name__ == '__main__':\ncallbacks = []\nname_dict = dict()\n+ gameInputPacket.iNumPlayers = num_bots\n+\n# Set configuration values for bots and store name and team\nfor i in range(num_bots):\nbot_config = configparser.RawConfigParser()\n",
        "chatgpt_cot": "\"Add conditional check for unit_obj.vespene_contents in gas_buildings list, with a note for future removal when new linux client is released.\""
    },
    {
        "org_diff": "diff --git a/.travis.yml b/.travis.yml @@ -59,6 +59,5 @@ jobs:\n# Run the docker image\n- docker run -it -d --name app test_image\n- docker exec -i app bash -c \"python test/travis_test_script.py test/autotest_bot.py\"\n- - docker exec -i app bash -c \"cd /root/template && python test/travis_test_script.py test/autotest_bot.py\"\n# Shut down and remove container after finishing\n- docker rm -f app\n",
        "org_msg": "Fix line in .travis.yml",
        "sim_msg": "Trying to figure out multiple sequential scripts within a stage.",
        "sim_diff": "diff --git a/.travis.yml b/.travis.yml @@ -15,11 +15,12 @@ jobs:\nscript: ./infrastructure/docker-build.sh\n- stage: test\n- script: ./csu start\n- - script: ./csu dev test\n- - script: ./csu dev test_backwards\n- - script: ./csu dev style\n- - script: ./csu dev docs\n+ script:\n+ - ./csu start\n+ - ./csu dev test\n+ - ./csu dev test_backwards\n+ - ./csu dev style\n+ - ./csu dev docs\n- stage: deploy\nscript: skip\n",
        "chatgpt_cot": "\"Remove unnecessary command from Travis CI configuration\""
    },
    {
        "org_diff": "diff --git a/bootup/docker-compose-files/docker-compose.yml b/bootup/docker-compose-files/docker-compose.yml @@ -109,10 +109,10 @@ services:\n- SERVER_PUBLIC_IP=$SERVER_PUBLIC_IP\n- KEYCLOAK_REALM=$KEYCLOAK_REALM\n- KEYCLOAK_SERVER_PORT=$KEYCLOAK_SERVER_PORT\n- - PARSE_API_ROOT=http://parse:1337/parse\n+ - PARSE_SERVER_URL=http://parse:1337/parse\n- PARSE_SERVER_APPLICATION_ID=$PARSE_SERVER_APPLICATION_ID\n- PARSE_SERVER_MASTER_KEY=$PARSE_SERVER_MASTER_KEY\n- - PARSE_SERVER_REST_API_KEY=$PARSE_SERVER_REST_API_KEY\n+ - PARSE_SERVER_JAVASCRIPT_KEY=$PARSE_SERVER_JAVASCRIPT_KEY\nvolumes:\n- /opt/cello/baas:/opt/data\n",
        "org_msg": "Fix compose file for product env\nCorrect the parse variable for user dashboard.",
        "sim_msg": "Updating docker image names, using 3.6 for rabbitmq",
        "sim_diff": "diff --git a/docker/docker-compose/docker-compose.yml b/docker/docker-compose/docker-compose.yml @@ -2,7 +2,7 @@ version: '2'\nservices:\nbrew-view:\n- image: beer-garden/brew-view:release\n+ image: bgio/brew-view\ncommand: brew-view -c /conf/brew-view-config.json\nnetworks:\n- bg-network\n@@ -15,7 +15,7 @@ services:\n- rabbitmq\nbartender:\n- image: beer-garden/bartender:release\n+ image: bgio/bartender\ncommand: bartender -c /conf/bartender-config.json\nnetworks:\n- bg-network\n@@ -36,7 +36,7 @@ services:\n- mongo-config:/data/configdb\nrabbitmq:\n- image: rabbitmq:management-alpine\n+ image: rabbitmq:3.6-management-alpine\nnetworks:\n- bg-network\nenvironment:\n",
        "chatgpt_cot": "Update Parse server configuration keys in docker-compose file. Replaced PARSE_API_ROOT with PARSE_SERVER_URL and PARSE_SERVER_REST_API_KEY with PARSE_SERVER_JAVASCRIPT_KEY for consistency and clarity."
    },
    {
        "org_diff": "diff --git a/fkie_master_discovery/src/fkie_master_discovery/master_info.py b/fkie_master_discovery/src/fkie_master_discovery/master_info.py @@ -1154,17 +1154,11 @@ class MasterInfo(object):\nserviceProvider = []\nadded_nodes = []\nnodes_last_check = set()\n- # process the node filtering first, but the nodelist to send will be created later\n- for name, node in self.nodes.items():\n- if not iffilter.is_ignored_node(name):\n- if filter_interface is None or node.isLocal or (iffilter.sync_remote_nodes() and self.masteruri == str(node.masteruri)):\n- added_nodes.append(name)\n# filter the topics\nfor name, topic in self.topics.items():\npn = []\nfor n in topic.publisherNodes:\n- if n in added_nodes:\nif not iffilter.is_ignored_publisher(n, name, topic.type):\npn.append(n)\nnodes_last_check.add(n)\n@@ -1172,7 +1166,6 @@ class MasterInfo(object):\npublishers.append((name, pn))\nsn = []\nfor n in topic.subscriberNodes:\n- if n in added_nodes:\nif not iffilter.is_ignored_subscriber(n, name, topic.type):\nsn.append(n)\nnodes_last_check.add(n)\n@@ -1185,7 +1178,6 @@ class MasterInfo(object):\nfor name, service in self.services.items():\nsrv_prov = []\nfor sp in service.serviceProvider:\n- if sp in added_nodes:\nif not iffilter.is_ignored_service(sp, name):\nsrv_prov.append(sp)\nnodes_last_check.add(sp)\n",
        "org_msg": "fkie_master_discovery: fixed usage of sync_nodes and sync_topics together",
        "sim_msg": "apply new ws uri and handle exception with old ws uri as well",
        "sim_diff": "diff --git a/loopchain/baseservice/node_subscriber.py b/loopchain/baseservice/node_subscriber.py @@ -40,18 +40,15 @@ class NodeSubscriber:\ndef __init__(self, channel, rs_target):\nself.__channel = channel\nself.__rs_target = rs_target\n- self.__target_uri = f\"{'wss' if conf.SUBSCRIBE_USE_HTTPS else 'ws'}://{self.__rs_target}/api/node/{channel}\"\n+ self.__target_uri = f\"{'wss' if conf.SUBSCRIBE_USE_HTTPS else 'ws'}://{self.__rs_target}/api/ws/{channel}\"\nself.__exception = None\n+ self.__tried_with_old_uri = False\nws_methods.add(self.node_ws_PublishHeartbeat)\nws_methods.add(self.node_ws_PublishNewBlock)\nlogging.debug(f\"websocket target uri : {self.__target_uri}\")\n- @property\n- def target_uri(self):\n- return self.__target_uri\n-\nasync def subscribe(self, block_height, event: Event):\nself.__exception = None\n@@ -64,8 +61,10 @@ class NodeSubscriber:\nrequest = Request(\"node_ws_Subscribe\", height=block_height, peer_id=ChannelProperty().peer_id)\nawait websocket.send(json.dumps(request))\nawait self.__subscribe_loop(websocket)\n-\n- except (InvalidStatusCode, InvalidMessage) as e:\n+ except InvalidStatusCode as e:\n+ if not self.__tried_with_old_uri:\n+ await self.try_subscribe_to_past_uri(block_height, event)\n+ return\nlogging.warning(f\"websocket subscribe {type(e)} exception, caused by: {e}\\n\"\nf\"This target({self.__rs_target}) may not support websocket yet.\")\nraise NotImplementedError\n@@ -87,6 +86,12 @@ class NodeSubscriber:\nresponse_dict = json.loads(response)\nawait ws_methods.dispatch(response_dict)\n+ async def try_subscribe_to_past_uri(self, block_height, event: Event):\n+ self.__target_uri = self.__target_uri.replace('/ws', '/node')\n+ self.__tried_with_old_uri = True\n+ logging.info(f\"try websocket again with old uri... old uri: {self.__target_uri}\")\n+ await self.subscribe(block_height, event)\n+\nasync def node_ws_PublishNewBlock(self, **kwargs):\nif 'error' in kwargs:\nreturn ObjectManager().channel_service.shutdown_peer(message=kwargs.get('error'))\n",
        "chatgpt_cot": "Refactor node filtering in MasterInfo class to improve efficiency and readability. Remove unnecessary checks for added_nodes in topic and service filtering."
    },
    {
        "org_diff": "diff --git a/fkie_node_manager_daemon/tests/test_common.py b/fkie_node_manager_daemon/tests/test_common.py @@ -100,7 +100,10 @@ class TestCommonLib(unittest.TestCase):\ndef test_get_packages(self):\npath = os.path.dirname(self.nm_path.rstrip(os.path.sep))\npkg_res = get_packages(path)\n- self.assertEqual(6, len(pkg_res), \"wrong count of get_packages(%s), expected: %d, got: %d -> packages: %s\" % (path, 6, len(pkg_res), pkg_res))\n+ count_exp = 6\n+ if 'industrial_ci' in pkg_res:\n+ count_exp += 1\n+ self.assertEqual(count_exp, len(pkg_res), \"wrong count of get_packages(%s), expected: %d, got: %d -> packages: %s\" % (path, count_exp, len(pkg_res), pkg_res))\ndef test_get_cwd(self):\ntest_path = '/this/is/path/to'\n",
        "org_msg": "fix test for get_packages",
        "sim_msg": "issue Python 2.4 lacked Thread.name.",
        "sim_diff": "diff --git a/tests/testlib.py b/tests/testlib.py @@ -301,9 +301,10 @@ class TestCase(unittest2.TestCase):\ndef _teardown_check_threads(self):\ncounts = {}\nfor thread in threading.enumerate():\n- assert thread.name in self.ALLOWED_THREADS, \\\n- 'Found thread %r still running after tests.' % (thread.name,)\n- counts[thread.name] = counts.get(thread.name, 0) + 1\n+ name = thread.getName()\n+ assert name in self.ALLOWED_THREADS, \\\n+ 'Found thread %r still running after tests.' % (name,)\n+ counts[name] = counts.get(name, 0) + 1\nfor name in counts:\nassert counts[name] == 1, \\\n",
        "chatgpt_cot": "\"Fix count of packages in test_common.py by adjusting expected count based on package presence, and update assertion message accordingly.\""
    },
    {
        "org_diff": "diff --git a/sc2/units.py b/sc2/units.py @@ -109,6 +109,34 @@ class Units(list):\ndef sorted(self, keyfn, reverse=False):\nreturn self.subgroup(sorted(self, key=keyfn, reverse=reverse))\n+ def tags_in(self, other):\n+ \"\"\" Filters all units that have their tags in the 'other' set/list/dict \"\"\"\n+ # example: self.queens.tags_in(self.queens_tags_assigned_to_do_injects)\n+ return self.filter(lambda unit: unit.tag in other)\n+\n+ def tags_not_in(self, other):\n+ \"\"\" Filters all units that have their tags not in the 'other' set/list/dict \"\"\"\n+ # example: self.queens.tags_not_in(self.queens_tags_assigned_to_do_injects)\n+ return self.filter(lambda unit: unit.tag not in other)\n+\n+ def of_type(self, other):\n+ \"\"\" Filters all units that are of a specific type \"\"\"\n+ # example: self.townhalls.of_type([HIVE])\n+ if not isinstance(other, (tuple, list, set, dict)):\n+ other = [other]\n+ return self.filter(lambda unit: unit.type_id in other)\n+\n+ def exclude_type(self, other):\n+ \"\"\" Filters all units that are not of a specific type \"\"\"\n+ # example: self.known_enemy_units.exclude_type([OVERLORD])\n+ if not isinstance(other, (tuple, list, set, dict)):\n+ other = [other]\n+ return self.filter(lambda unit: unit.type_id not in other)\n+\n+ @property\n+ def tags(self):\n+ return {unit.tag for unit in self}\n+\n@property\ndef ready(self):\nreturn self.filter(lambda unit: unit.is_ready)\n@@ -133,6 +161,14 @@ class Units(list):\ndef enemy(self):\nreturn self.filter(lambda unit: unit.is_enemy)\n+ @property\n+ def flying(self):\n+ return self.filter(lambda unit: unit.is_flying)\n+\n+ @property\n+ def not_flying(self):\n+ return self.filter(lambda unit: not unit.is_flying)\n+\n@property\ndef structure(self):\nreturn self.filter(lambda unit: unit.is_structure)\n",
        "org_msg": "Add Units filters that use the new Unit attributes",
        "sim_msg": "Update squad_v2.py\nChange lines 100 and 102 to prevent overwriting ```predictions``` variable.",
        "sim_diff": "diff --git a/metrics/squad_v2/squad_v2.py b/metrics/squad_v2/squad_v2.py @@ -97,9 +97,9 @@ class SquadV2(datasets.Metric):\n)\ndef _compute(self, predictions, references, no_answer_threshold=1.0):\n- predictions = dict((p[\"id\"], p[\"prediction_text\"]) for p in predictions)\n- dataset = [{\"paragraphs\": [{\"qas\": references}]}]\nno_answer_probabilities = dict((p[\"id\"], p[\"no_answer_probability\"]) for p in predictions)\n+ dataset = [{\"paragraphs\": [{\"qas\": references}]}]\n+ predictions = dict((p[\"id\"], p[\"prediction_text\"]) for p in predictions)\nqid_to_has_ans = make_qid_to_has_ans(dataset) # maps qid to True/False\nhas_ans_qids = [k for k, v in qid_to_has_ans.items() if v]\n",
        "chatgpt_cot": "\"Add new methods for filtering units by tags and type, and add properties for filtering flying and non-flying units.\""
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/launch_list_model.py b/node_manager_fkie/src/node_manager_fkie/launch_list_model.py @@ -736,10 +736,16 @@ class LaunchListModel(QStandardItemModel):\npath_item = PathItem.create_row_items(path, path_id, mtime, size, name)\nfor i in range(root.rowCount()):\ncurr_item = root.child(i)\n- launch_file_cmp = path_id in [PathItem.RECENT_FILE, PathItem.LAUNCH_FILE, PathItem.RECENT_PROFILE, PathItem.PROFILE] and curr_item.name < path_item[0].name and curr_item.id not in [PathItem.ROOT]\n- launch_id_cmp = (curr_item.id > path_id and curr_item.id > PathItem.LAUNCH_FILE)\n- launch_name_cmp = (curr_item.id == path_id and path_item[0].name < curr_item.name)\n- if launch_file_cmp or launch_id_cmp or launch_name_cmp:\n+ insert_item = False\n+ print \"add\", path_item[0].name, path_item[0].id\n+ if curr_item.id not in [PathItem.ROOT]:\n+ if curr_item.id == path_item[0].id or path_item[0].id in [PathItem.RECENT_FILE, PathItem.LAUNCH_FILE, PathItem.RECENT_PROFILE, PathItem.PROFILE]:\n+ if path_item[0].name < curr_item.name:\n+ insert_item = True\n+ elif curr_item.id > path_item[0].id:\n+ if curr_item.id > PathItem.LAUNCH_FILE:\n+ insert_item = True\n+ if insert_item:\nroot.insertRow(i, path_item)\nself.pyqt_workaround[path_item[0].name] = path_item[0] # workaround for using with PyQt: store the python object to keep the defined attributes in the TopicItem subclass\nreturn True\n",
        "org_msg": "node_manager_fkie: fixed sort in launch list view",
        "sim_msg": "Added fix for error message",
        "sim_diff": "diff --git a/avalon/tools/projectmanager/model.py b/avalon/tools/projectmanager/model.py @@ -113,7 +113,8 @@ class TreeModel(QtCore.QAbstractItemModel):\nkey = self.COLUMNS[column]\nnode[key] = value\n- self.dataChanged.emit(index, index)\n+ # passing `list()` for PyQt5 (see PYSIDE-462)\n+ self.dataChanged.emit(index, index, list())\n# must return true if successful\nreturn True\n",
        "chatgpt_cot": "\"Fix insertion logic in LaunchListModel to correctly add new items based on path and ID comparison for recent and launch files.\""
    },
    {
        "org_diff": "diff --git a/sc2/game_info.py b/sc2/game_info.py @@ -232,6 +232,7 @@ class GameInfo:\nfor p in self._proto.player_info\n}\nself.start_locations: List[Point2] = [Point2.from_proto(sl) for sl in self._proto.start_raw.start_locations]\n+ self.start_locations = [Point2((round(x, 1), round(y, 1))) for x, y in self.start_locations]\nself.player_start_location: Point2 = None # Filled later by BotAI._prepare_first_step\ndef _find_ramps_and_vision_blockers(self) -> Tuple[List[Ramp], FrozenSet[Point2]]:\n",
        "org_msg": "Start locations position rounding\nStart locations position rounding, they are sligthy offset in some maps, like in InsideAndOutAIE (33.499755859375, 30.5) instead of (33.5, 30.5)",
        "sim_msg": "[Hockey] clear guild if it's none on check pickem winner",
        "sim_diff": "diff --git a/hockey/hockey.py b/hockey/hockey.py @@ -1049,6 +1049,9 @@ class Hockey(getattr(commands, \"Cog\", object)):\n\"\"\"\nfor guild_id in await self.config.all_guilds():\nguild = self.bot.get_guild(guild_id)\n+ if guild is None:\n+ await self.config._clear_scope(Config.GUILD, str(guild_id))\n+ continue\npickems = [Pickems.from_json(p) for p in await self.config.guild(guild).pickems()]\nfor p in pickems:\ngame = await Game.get_games(p.home_team, p.game_start, p.game_start)\n",
        "chatgpt_cot": "\"Round start locations coordinates to 1 decimal place for consistency in GameInfo file\""
    },
    {
        "org_diff": "diff --git a/docs/index.md b/docs/index.md ![Cello](docs/imgs/logo.png)\n+Blockchain as a Service!\n+\n**Note:** This is a **read-only mirror** of the formal [Gerrit](https://gerrit.hyperledger.org/r/#/admin/projects/cello) repository,\n-where active development is ongoing. Issue tracking is handled in [Jira](https://jira.hyperledger.org/secure/RapidBoard.jspa?rapidView=111)\n+where active development is ongoing. Issue tracking is handled in [Jira](https://jira.hyperledger.org/projects/CE/issues/).\n## Incubation Notice\nThis project is a Hyperledger project in _Incubation_. It was proposed to the community and documented [here](https://docs.google.com/document/d/1E2i5GRqWsIag7KTxjQ_jQdDiWcuikv3KqXeuw7NaceM/edit), and was approved by [Hyperledger TSC at 2017-01-07](https://lists.hyperledger.org/pipermail/hyperledger-tsc/2017-January/000535.html). Information on what _Incubation_ entails can be found in the [Hyperledger Project Lifecycle document](https://goo.gl/4edNRc).\n-Platform to provide Blockchain as a Service!\nUsing Cello, we can\n-* Provision customizable Blockchains instantly, e.g., a 6-node chain using PBFT consensus.\n+* Provision customizable Blockchains instantly, e.g., a 6-node fabric chain using PBFT consensus.\n* Maintain a pool of running blockchains healthy with no manual operations.\n* Check the system status, scale the chain numbers, change resources... through a dashboard.\n@@ -28,23 +29,22 @@ You can also find more [scenarios](docs/scenario.md).\n* Support heterogeneous architecture, e.g., Z, Power and X86, from bare-metal servers to virtual machines.\n* Extend with monitor/log/health features by employing additional components.\n-## Docs\n-\n-### User Docs\n-* [Dashboard](docs/dashboard.md)\n+## Documentation\n-### Operator Docs\n-* [Installation & Deployment](docs/deployment.md)\n-* [Scenarios](docs/scenario.md)\n-* [Production Configuration](docs/production_config.md)\n+### Operational Docs\n+* [Installation & Deployment](install.md)\n+* [Terminologies](terminology.md)\n+* [Tutorial](tutorial.md)\n+* [Scenarios](scenario.md)\n+* [Production Configuration](production_config.md)\n### Development Docs\n-* [How to contribute](docs/CONTRIBUTING.md)\n-* We're following [pep8 style guide](https://www.python.org/dev/peps/pep-0008/), [Coding Style](docs/code_style.md)\n-* [Architecture Design](docs/arch.md)\n-* [Database Model](docs/db.md)\n-* [API](api/restserver_v2.md)\n-* [Develop react js](docs/reactjs.md)\n+* [How to contribute](CONTRIBUTING.md)\n+* We're following [pep8 style guide](https://www.python.org/dev/peps/pep-0008/), [Coding Style](code_style.md)\n+* [Architecture Design](arch.md)\n+* [Database Model](db.md)\n+* [API](../api/restserver_v2.md)\n+* [Develop react js](reactjs.md)\n## Why named Cello?\nCan u find anyone better at playing chains? :)\n",
        "org_msg": "Fix for broken links in docs/index.md;\nRelated to issue #CE-2.",
        "sim_msg": "Nice README.",
        "sim_diff": "diff --git a/README.md b/README.md @@ -362,7 +362,7 @@ Currently alive channels\n| [/r/trippinthroughtime](https://www.reddit.com/r/trippinthroughtime/) | [@medieval_memes](https://t.me/medieval_memes) | 1 hour |\n| [/r/onepunchman](https://www.reddit.com/r/onepunchman/) | [@r_opm](https://t.me/r_opm) | 1 hour |\n| [/r/preppers](https://www.reddit.com/r/preppers/) | [@r_preppers](https://t.me/r_preppers) | 1 hour |\n-| [/r/Chainlink+Vechain+FetchAI_Community+perlin+Qtum+NEO+hashgraph+IoTeX+elrondnetwork+Aeternity+loopringorg+waltonchain+nebulas+IOStoken+NavCoin+viacoin+skycoin+MoedaBanking+WabiToken+EnjinCoin+OntologyNetwork+PolymathNetwork+insolar+nexusearth+zcoin+zilliqa+quarkchainio+tezos+Neblio+helloicon+ArkEcosystem+kybernetwork+0xProject+BATProject+SysCoin+omise_go+pivx+civicplatform+factom+nem+Stellar+Ripple+Wavesplatform+statusim+Ardor+stratisplatform+GolemProject+komodoplatform+storj+vergecurrency+eos+siacoin](https://www.reddit.com/r/Chainlink+Vechain+FetchAI_Community+perlin+Qtum+NEO+hashgraph+IoTeX+elrondnetwork+Aeternity+loopringorg+waltonchain+nebulas+IOStoken+NavCoin+viacoin+skycoin+MoedaBanking+WabiToken+EnjinCoin+OntologyNetwork+PolymathNetwork+insolar+nexusearth+zcoin+zilliqa+quarkchainio+tezos+Neblio+helloicon+ArkEcosystem+kybernetwork+0xProject+BATProject+SysCoin+omise_go+pivx+civicplatform+factom+nem+Stellar+Ripple+Wavesplatform+statusim+Ardor+stratisplatform+GolemProject+komodoplatform+storj+vergecurrency+eos+siacoin/) | [@cryptoinstantnews2](https://t.me/cryptoinstantnews2) | 1 hour |\n+| [/r/%A_LOT_OF_CRYPTO_RELATED%](https://www.reddit.com/r/Chainlink+Vechain+FetchAI_Community+perlin+Qtum+NEO+hashgraph+IoTeX+elrondnetwork+Aeternity+loopringorg+waltonchain+nebulas+IOStoken+NavCoin+viacoin+skycoin+MoedaBanking+WabiToken+EnjinCoin+OntologyNetwork+PolymathNetwork+insolar+nexusearth+zcoin+zilliqa+quarkchainio+tezos+Neblio+helloicon+ArkEcosystem+kybernetwork+0xProject+BATProject+SysCoin+omise_go+pivx+civicplatform+factom+nem+Stellar+Ripple+Wavesplatform+statusim+Ardor+stratisplatform+GolemProject+komodoplatform+storj+vergecurrency+eos+siacoin/) | [@cryptoinstantnews2](https://t.me/cryptoinstantnews2) | 1 hour |\n| [/r/LeagueOfMemes](https://www.reddit.com/r/LeagueOfMemes/) | [@r_league_of_memes](https://t.me/r_league_of_memes) | 1 hour |\n| [/r/VirtualYoutubers](https://www.reddit.com/r/VirtualYoutubers/) | [@vtuber_en](https://t.me/vtuber_en) | 1 hour |\n| | ... be the next one ... | |@\n",
        "chatgpt_cot": "Update documentation links and content in index.md for Cello project, reflecting changes in installation, scenarios, and development documentation for better organization and clarity."
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/editor/graph_view.py b/node_manager_fkie/src/node_manager_fkie/editor/graph_view.py @@ -233,7 +233,10 @@ class GraphViewWidget(QDockWidget):\ninc_item = None\nif inc_item is None:\npkg, _ = package_name(os.path.dirname(inc_file.inc_path))\n- itemstr = '%s _%s_ [%s]' % (os.path.basename(inc_file.inc_path), sizeof_fmt(inc_file.size), pkg)\n+ size_color = 'gray'\n+ if inc_file.size == 0 or inc_file.size > 1000000:\n+ size_color = 'orange'\n+ itemstr = '%s <span style=\"color:%s;\"><em>%s</em></span> [%s]' % (os.path.basename(inc_file.inc_path), size_color, sizeof_fmt(inc_file.size), pkg)\ninc_item = QStandardItem('%d: %s' % (inc_file.line_number, itemstr))\ninc_item.setData(inc_file.path_or_str, self.DATA_FILE)\ninc_item.setData(inc_file.line_number, self.DATA_LINE)\n",
        "org_msg": "node_manager_fkie: editor: changed size visualization in graph view",
        "sim_msg": "improved text color display",
        "sim_diff": "diff --git a/qualcoder/code_text.py b/qualcoder/code_text.py @@ -437,9 +437,6 @@ class DialogCodeText(QtWidgets.QWidget):\ncats.remove(item)\ncount += 1\n- # Need this to assign foreground color\n- font = QtGui.QFont(\"\", self.app.settings['treefontsize'])\n-\n# Add unlinked codes as top level items\nremove_items = []\nfor c in codes:\n@@ -451,9 +448,7 @@ class DialogCodeText(QtWidgets.QWidget):\ntop_item.setToolTip(2, c['memo'])\ntop_item.setBackground(0, QBrush(QtGui.QColor(c['color']), Qt.SolidPattern))\ncolor = TextColor(c['color']).recommendation\n- print(color, c['name'])\n- top_item.setForeground(0, QtGui.QBrush(QtGui.QColor(color)))\n- top_item.setFont(0, font)\n+ top_item.setForeground(0, QBrush(QtGui.QColor(color)))\ntop_item.setFlags(Qt.ItemIsSelectable | Qt.ItemIsUserCheckable | Qt.ItemIsEnabled | Qt.ItemIsDragEnabled)\nself.ui.treeWidget.addTopLevelItem(top_item)\nremove_items.append(c)\n@@ -473,9 +468,7 @@ class DialogCodeText(QtWidgets.QWidget):\nchild = QtWidgets.QTreeWidgetItem([c['name'], 'cid:' + str(c['cid']), memo])\nchild.setBackground(0, QBrush(QtGui.QColor(c['color']), Qt.SolidPattern))\ncolor = TextColor(c['color']).recommendation\n- print(color, c['name'])\n- top_item.setForeground(0, QtGui.QBrush(QtGui.QColor(color)))\n- top_item.setFont(0, font)\n+ child.setForeground(0, QBrush(QtGui.QColor(color)))\nchild.setToolTip(2, c['memo'])\nchild.setFlags(Qt.ItemIsSelectable | Qt.ItemIsUserCheckable | Qt.ItemIsEnabled | Qt.ItemIsDragEnabled)\nitem.addChild(child)\n@@ -2708,7 +2701,9 @@ class ToolTip_EventFilter(QtCore.QObject):\nseltext = \" \".join(pretext) + \" ... \" + \" \".join(posttext)\nif display_text == \"\":\ntry:\n- display_text = '<p style=\"background-color:' + item['color'] + '\"><em>' + item['name'] + \"</em><br />\" + seltext\n+ color = TextColor(item['color']).recommendation\n+ display_text = '<p style=\"background-color:' + item['color'] + \"; color:\" + color + '\"><em>'\n+ display_text += item['name'] + \"</em><br />\" + seltext\nif item['memo'] is not None and item['memo'] != \"\":\ndisplay_text += \"<br /><em>\" + _(\"Memo: \") + item['memo'] + \"</em>\"\ndisplay_text += \"</p>\"\n@@ -2718,7 +2713,9 @@ class ToolTip_EventFilter(QtCore.QObject):\nlogger.error(msg)\nelse: # Can have multiple codes on same selected area\ntry:\n- display_text += '<p style=\"background-color:' + item['color'] + '\"><em>' + item['name'] + \"</em><br />\" + seltext\n+ color = TextColor(item['color']).recommendation\n+ display_text += '<p style=\"background-color:' + item['color'] + \"; color:\" + color + '\"><em>'\n+ display_text += item['name'] + \"</em><br />\" + seltext\nif item['memo'] is not None and item['memo'] != \"\":\ndisplay_text += \"<br /><em>Memo: \" + item['memo'] + \"</em>\"\ndisplay_text += \"</p>\"\n",
        "chatgpt_cot": "\"Add color coding to file size display in GraphViewWidget for better visualization and readability.\""
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/echo_dialog.py b/node_manager_fkie/src/node_manager_fkie/echo_dialog.py @@ -366,7 +366,7 @@ class EchoDialog(QDialog):\ntxt = '<pre style=\"color:red; font-family:Fixedsys,Courier,monospace; padding:10px;\">scrapped %s message because of Hz-settings</pre>' % self._scrapped_msgs_sl\nself.display.append(txt)\nself._scrapped_msgs_sl = 0\n- txt = '<pre style=\"background-color:#FFFCCC; font-family:Fixedsys,Courier; padding:10px;\">---------- %s --------------------\\n%s</pre>' % (datetime.now().strftime(\"%d.%m.%Y %H:%M:%S.%f\"), msg)\n+ txt = '<pre style=\"background-color:#FFFCCC; color:#000000;font-family:Fixedsys,Courier; padding:10px;\">---------- %s --------------------\\n%s</pre>' % (datetime.now().strftime(\"%d.%m.%Y %H:%M:%S.%f\"), msg)\n# set the count of the displayed messages on receiving the first message\nself._update_max_msg_count(txt)\nself.display.append(txt)\n@@ -459,7 +459,7 @@ class EchoDialog(QDialog):\nself._count_messages(current_time)\n# limit the displayed text width\nm = self._trim_width(m)\n- txt = '<pre style=\"background-color:#FFFCCC; font-family:Fixedsys,Courier; padding:10px;\">---------- %s --------------------\\n%s</pre>' % (datetime.now().strftime(\"%d.%m.%Y %H:%M:%S.%f\"), m)\n+ txt = '<pre style=\"background-color:#FFFCCC; color:#000000;font-family:Fixedsys,Courier; padding:10px;\">---------- %s --------------------\\n%s</pre>' % (datetime.now().strftime(\"%d.%m.%Y %H:%M:%S.%f\"), m)\n# set the count of the displayed messages on receiving the first message\nself._update_max_msg_count(txt)\nself.display.append(txt)\n",
        "org_msg": "node_manager_fkie: changed font color in echo dialog",
        "sim_msg": "change View to Open in qbutton",
        "sim_diff": "diff --git a/qualcoder/GUI/ui_dialog_manage_files.py b/qualcoder/GUI/ui_dialog_manage_files.py @@ -54,7 +54,7 @@ class Ui_Dialog_manage_files(object):\ndef retranslateUi(self, Dialog_manage_files):\n_translate = QtCore.QCoreApplication.translate\nDialog_manage_files.setWindowTitle(_translate(\"Dialog_manage_files\", \"Files\"))\n- self.pushButton_view.setText(_translate(\"Dialog_manage_files\", \"View\"))\n+ self.pushButton_view.setText(_translate(\"Dialog_manage_files\", \"Open\"))\nself.pushButton_create.setText(_translate(\"Dialog_manage_files\", \"Create\"))\nself.pushButton_export.setToolTip(_translate(\"Dialog_manage_files\", \"<html><head/><body><p>Make sure the file name does not contain unusual characters such as \\': ; &quot; \\' otherwise it will raise an error when trying to save this file. Rename the file if needed.</p></body></html>\"))\nself.pushButton_export.setText(_translate(\"Dialog_manage_files\", \"Export\"))\n",
        "chatgpt_cot": "fix text color and font family in EchoDialog to improve readability."
    },
    {
        "org_diff": "diff --git a/src/api-engine/api/routes/channel/views.py b/src/api-engine/api/routes/channel/views.py @@ -55,7 +55,7 @@ class ChannelViewSet(viewsets.ViewSet):\nchannel_pages = Paginator(channels, per_page)\nchannels_list = channel_pages.page(page)\nresponse = ChannelListResponse(\n- data={\"data\": channels_list, \"total\": channels.count}\n+ data={\"data\": channels_list, \"total\": channels.count()}\n)\nif response.is_valid(raise_exception=True):\nreturn Response(\n",
        "org_msg": "Minor changes on the channel query endpoint.",
        "sim_msg": "Fixes to new streams endpoint",
        "sim_diff": "diff --git a/blueprints/apis/channel_ns.py b/blueprints/apis/channel_ns.py @@ -228,7 +228,7 @@ class api_1_Streams(Resource):\n'uuid': entry.uuid,\n'topic': entry.topic,\n'streamName': entry.streamName,\n- 'startTimestamp': entry.startTimestamp,\n+ 'startTimestamp': str(entry.startTimestamp),\n'currentViewers': entry.currentViewers,\n'totalViewers': entry.totalViewers,\n'streamURL': streamURL\n",
        "chatgpt_cot": "fix syntax error in ChannelViewSet response data format."
    },
    {
        "org_diff": "diff --git a/sc2/unit.py b/sc2/unit.py @@ -1171,7 +1171,7 @@ class Unit:\ndef surplus_harvesters(self) -> int:\n\"\"\" Returns a positive int if unit has too many harvesters mining,\na negative int if it has too few mining.\n- will only works for townhalls, and gasgeysers\n+ Will only works on townhalls, and gas buildings.\n\"\"\"\nreturn self._proto.assigned_harvesters - self._proto.ideal_harvesters\n",
        "org_msg": "rewritten in proper english",
        "sim_msg": "change root to root_pipeline",
        "sim_diff": "diff --git a/dataset/research/workers.py b/dataset/research/workers.py @@ -33,7 +33,7 @@ class PipelineWorker(Worker):\ntry:\nfor unit_name, base_unit in job.executable_units.items():\nif j in base_unit.execute_for:\n- if base_unit.root is not None:\n+ if base_unit.root_pipeline is not None:\njob.parallel_execute_for(unit_name)\nelif base_unit.on_root:\nself.log_info(\n",
        "chatgpt_cot": "Fix typo in surplus_harvesters method for Unit class. Updated comment to correct grammar and clarify method functionality."
    },
    {
        "org_diff": "diff --git a/examples/distributed_workers.py b/examples/distributed_workers.py @@ -21,7 +21,9 @@ class TerranBot(sc2.BotAI):\nawait self.expand_now()\nasync def build_supply(self):\n- cc = self.units(UnitTypeId.COMMANDCENTER).ready.first\n+ ccs = self.units(UnitTypeId.COMMANDCENTER).ready\n+ if ccs.exists:\n+ cc = ccs.first\nif self.supply_left < 4 and not self.already_pending(UnitTypeId.SUPPLYDEPOT):\nif self.can_afford(UnitTypeId.SUPPLYDEPOT):\nawait self.build(UnitTypeId.SUPPLYDEPOT, near=cc.position.towards(self.game_info.map_center, 5))\n",
        "org_msg": "Fix command center selection in example",
        "sim_msg": "Reduced SQL load for 'Require Stock to Complete Build' widget on homepage",
        "sim_diff": "diff --git a/InvenTree/part/api.py b/InvenTree/part/api.py @@ -7,7 +7,7 @@ from __future__ import unicode_literals\nfrom django_filters.rest_framework import DjangoFilterBackend\nfrom django.http import JsonResponse\n-from django.db.models import Q, F, Count\n+from django.db.models import Q, F, Count, Prefetch, Sum\nfrom rest_framework import status\nfrom rest_framework.response import Response\n@@ -22,11 +22,14 @@ from .models import PartParameter, PartParameterTemplate\nfrom .models import PartAttachment, PartTestTemplate\nfrom .models import PartSellPriceBreak\n+from build.models import Build\n+\nfrom . import serializers as part_serializers\nfrom InvenTree.views import TreeSerializer\nfrom InvenTree.helpers import str2bool, isNull\nfrom InvenTree.api import AttachmentMixin\n+from InvenTree.status_codes import BuildStatus\nclass PartCategoryTree(TreeSerializer):\n@@ -531,12 +534,24 @@ class PartList(generics.ListCreateAPIView):\nif stock_to_build is not None:\n# Filter only active parts\nqueryset = queryset.filter(active=True)\n+ # Prefetch current active builds\n+ build_active_queryset = Build.objects.filter(status__in=BuildStatus.ACTIVE_CODES)\n+ build_active_prefetch = Prefetch('builds',\n+ queryset=build_active_queryset,\n+ to_attr='current_builds')\n+ parts = queryset.prefetch_related(build_active_prefetch)\n+\n+ # Store parts with builds needing stock\nparts_need_stock = []\n# Find parts with active builds\n# where any subpart's stock is lower than quantity being built\n- for part in queryset:\n- if part.active_builds and part.can_build < part.quantity_being_built:\n+ for part in parts:\n+ if part.current_builds:\n+ builds_ids = [build.id for build in part.current_builds]\n+ total_build_quantity = build_active_queryset.filter(pk__in=builds_ids).aggregate(quantity=Sum('quantity'))['quantity']\n+\n+ if part.can_build < total_build_quantity:\nparts_need_stock.append(part.pk)\nqueryset = queryset.filter(pk__in=parts_need_stock)\n",
        "chatgpt_cot": "\"Add condition to check if CommandCenter exists before assigning it to cc variable in build_supply method\""
    },
    {
        "org_diff": "diff --git a/sc2/units.py b/sc2/units.py @@ -96,6 +96,11 @@ class Units(list):\nposition = position.position\nreturn min(self, key=lambda unit: unit.position.to2.distance_to(position.to2))\n+ def furthest_to(self, position):\n+ if isinstance(position, Unit):\n+ position = position.position\n+ return max(self, key=lambda unit: unit.position.to2.distance_to(position.to2))\n+\ndef closer_than(self, distance, position):\nif isinstance(position, Unit):\nposition = position.position\n@@ -143,8 +148,8 @@ class Units(list):\ndef center(self):\n\"\"\" Returns the central point of all units in this list \"\"\"\nassert self.exists\n- pos = Point2((sum([unit.position.x for unit in self]) / self.amount, \\\n- sum([unit.position.y for unit in self]) / self.amount))\n+ pos = Point2((sum({unit.position.x for unit in self}) / self.amount, \\\n+ sum({unit.position.y for unit in self}) / self.amount))\nreturn pos\n@property\n",
        "org_msg": "Add furthest_to filter mainly for units stutter stepping backwards",
        "sim_msg": "Returns indexes instead of points if input argument 'return_index' is True (by default it is False).",
        "sim_diff": "diff --git a/pyclustering/cluster/center_initializer.py b/pyclustering/cluster/center_initializer.py @@ -204,13 +204,15 @@ class kmeans_plusplus_initializer:\nreturn shortest_distances\n- def __get_next_center(self, centers):\n+ def __get_next_center(self, centers, return_index):\n\"\"\"!\n@brief Calculates the next center for the data.\n@param[in] centers (array_like): Current initialized centers.\n+ @param[in] return_index (bool): If True then return center's index instead of point.\n- @return (array_like) Next initialized center.\n+ @return (array_like) Next initialized center.<br>\n+ (uint) Index of next initialized center if return_index is True.\n\"\"\"\n@@ -222,9 +224,30 @@ class kmeans_plusplus_initializer:\nprobabilities = self.__calculate_probabilities(distances)\ncenter_index = self.__get_probable_center(distances, probabilities)\n+ if return_index:\n+ return center_index\n+\nreturn self.__data[center_index]\n+ def __get_initial_center(self, return_index):\n+ \"\"\"!\n+ @brief Choose randomly first center.\n+\n+ @param[in] return_index (bool): If True then return center's index instead of point.\n+\n+ @return (array_like) First center.<br>\n+ (uint) Index of first center.\n+\n+ \"\"\"\n+\n+ index_center = random.randint(0, len(self.__data) - 1)\n+ if return_index:\n+ return index_center\n+\n+ return self.__data[index_center]\n+\n+\ndef __calculate_probabilities(self, distances):\n\"\"\"!\n@brief Calculates cumulative probabilities of being center of each point.\n@@ -272,20 +295,23 @@ class kmeans_plusplus_initializer:\nreturn index_best_candidate\n- def initialize(self):\n+ def initialize(self, return_index=False):\n\"\"\"!\n@brief Calculates initial centers using K-Means++ method.\n+ @param[in] return_index (bool): If True then returns indexes of points from input data instead of points itself.\n+\n@return (list) List of initialized initial centers.\n+ If argument 'return_index' is False then returns list of points.\n+ If argument 'return_index' is True then returns list of indexes.\n\"\"\"\n- index_center = random.randint(0, len(self.__data) - 1)\n- centers = [ self.__data[ index_center ] ]\n+ centers = [ self.__get_initial_center(return_index) ]\n# For each next center\nfor _ in range(1, self.__amount):\n- next_center = self.__get_next_center(centers)\n+ next_center = self.__get_next_center(centers, return_index)\ncenters.append(next_center)\nreturn centers\n\\ No newline at end of file\n",
        "chatgpt_cot": "Add method furthest_to() to Units class for finding the unit furthest from a position. Fix calculation in center() method for central point."
    },
    {
        "org_diff": "diff --git a/sc2/bot_ai.py b/sc2/bot_ai.py @@ -315,7 +315,24 @@ class BotAI(object):\nreturn min(possible, key=lambda p: p.distance_to(near))\nreturn None\n- def already_pending(self, unit_type: UnitTypeId, all_units: bool=False) -> int:\n+ def already_pending_upgrade(self, upgrade_type: UpgradeId) -> Union[int, float]:\n+ \"\"\" Check if an upgrade is being researched\n+ Return values:\n+ 0: not started\n+ 0 < x < 1: researching\n+ 1: finished\n+ \"\"\"\n+ assert isinstance(upgrade_type, UpgradeId)\n+ if upgrade_type in self.state.upgrades:\n+ return 1\n+ creationAbilityID = self._game_data.upgrades[upgrade_type.value].research_ability.id\n+ for s in self.units.structure.ready:\n+ for o in s.orders:\n+ if o.ability.id == creationAbilityID:\n+ return o.progress\n+ return 0\n+\n+ def already_pending(self, unit_type: Union[UpgradeId, UnitTypeId], all_units: bool=False) -> int:\n\"\"\"\nReturns a number of buildings or units already in progress, or if a\nworker is en route to build it. This also includes queued orders for\n@@ -327,6 +344,9 @@ class BotAI(object):\n# TODO / FIXME: SCV building a structure might be counted as two units\n+ if isinstance(unit_type, UpgradeId):\n+ return self.already_pending_upgrade(unit_type)\n+\nability = self._game_data.units[unit_type.value].creation_ability\namount = len(self.units(unit_type).not_ready)\n",
        "org_msg": "Add already_pending for upgrades",
        "sim_msg": "Automatically allocate parts when a Build is created\nIf there is only one StockItem to choose from, allocate parts from that StockItem",
        "sim_diff": "diff --git a/InvenTree/build/models.py b/InvenTree/build/models.py @@ -12,6 +12,8 @@ from django.urls import reverse\nfrom django.db import models\nfrom django.core.validators import MinValueValidator\n+from stock.models import StockItem\n+\nclass Build(models.Model):\n\"\"\" A Build object organises the creation of new parts from the component parts.\n@@ -28,6 +30,50 @@ class Build(models.Model):\nnotes: Text notes\n\"\"\"\n+ def save(self, *args, **kwargs):\n+ \"\"\" Called when the Build model is saved to the database.\n+\n+ If this is a new Build, try to allocate StockItem objects automatically.\n+\n+ - If there is only one StockItem for a Part, use that one.\n+ - If there are multiple StockItem objects, leave blank and let the user decide\n+ \"\"\"\n+\n+ allocate_parts = False\n+\n+ # If there is no PK yet, then this is the first time the Build has been saved\n+ if not self.pk:\n+ allocate_parts = True\n+\n+ # Save this Build first\n+ super(Build, self).save(*args, **kwargs)\n+\n+ if allocate_parts:\n+ for item in self.part.bom_items.all():\n+ part = item.sub_part\n+ # Number of parts required for this build\n+ q_req = item.quantity * self.quantity\n+\n+ stock = StockItem.objects.filter(part=part)\n+\n+ if len(stock) == 1:\n+ stock_item = stock[0]\n+\n+ # Are there any parts available?\n+ if stock_item.quantity > 0:\n+ # If there are not enough parts, reduce the amount we will take\n+ if stock_item.quantity < q_req:\n+ q_req = stock_item.quantity\n+\n+ # Allocate parts to this build\n+ build_item = BuildItem(\n+ build=self,\n+ stock_item=stock_item,\n+ quantity=q_req)\n+\n+ build_item.save()\n+\n+\ndef __str__(self):\nreturn \"Build {q} x {part}\".format(q=self.quantity, part=str(self.part))\n",
        "chatgpt_cot": "Add method already_pending_upgrade to check upgrade progress and refactor already_pending to handle both unit and upgrade types."
    },
    {
        "org_diff": "diff --git a/build_image/docker/common/api-engine/Dockerfile.in b/build_image/docker/common/api-engine/Dockerfile.in @@ -14,6 +14,11 @@ WORKDIR /var/www/server\nCOPY src/api-engine ./\nCOPY fabric_tools/2.2.0/bins /opt/bin\nCOPY template/node /opt/node\n+\n+# Install compiled code tools from Artifactory\n+RUN curl -X GET \"https://hyperledger.jfrog.io/artifactory/fabric-binaries/hyperledger-fabric-linux-amd64-2.2-stable.tar.gz?archiveType=gzip\" > bin.tar.gz \\\n+ && tar -xzvf bin.tar.gz -C /opt/\n+\n# Install python dependencies\nRUN pip3 install -r requirements.txt\n",
        "org_msg": "Modified api-engine docker file, so the compiled code tools will be\ninstalled during the image building process.",
        "sim_msg": "Update Dockerfile\nCopying default `frontend.config.json` file into the `frontend/` directory during build, because Augurface looks for it.",
        "sim_diff": "diff --git a/util/docker/augurface/Dockerfile b/util/docker/augurface/Dockerfile @@ -4,6 +4,9 @@ FROM node:16 as build-stage\nLABEL maintainer=\"outdoors@acm.org\"\nLABEL version=\"0.27.4\"\n+WORKDIR /augur/frontend/\n+COPY ./util/docker/frontend/frontend.docker.config.json frontend.config.json\n+\nFROM build-stage as augurface\nWORKDIR /augur/augurface/\nCOPY augurface/package.json .\n",
        "chatgpt_cot": "Add installation of compiled code tools from Artifactory in Dockerfile for api-engine. Fixes issue with missing tools for the api-engine."
    },
    {
        "org_diff": "diff --git a/README.md b/README.md @@ -6,7 +6,7 @@ An easy-to-use library for writing AI Bots for StarCraft II in Python 3. The ult\nDocumentation is in [the Wiki](https://github.com/Dentosal/python-sc2/wiki).\n-For automaticly running multiple matches, check out [Dentosal/sc2-bot-match-runner](https://github.com/Dentosal/sc2-bot-match-runner).\n+For automatically running multiple matches, check out [Dentosal/sc2-bot-match-runner](https://github.com/Dentosal/sc2-bot-match-runner).\n## Installation\n",
        "org_msg": "Fixed a typo\nchanged 'atomaticaly' to 'automatically'",
        "sim_msg": "Forgot to update iNumPlayers",
        "sim_diff": "diff --git a/v3/runner.py b/v3/runner.py @@ -63,6 +63,8 @@ if __name__ == '__main__':\ncallbacks = []\nname_dict = dict()\n+ gameInputPacket.iNumPlayers = num_bots\n+\n# Set configuration values for bots and store name and team\nfor i in range(num_bots):\nbot_config = configparser.RawConfigParser()\n",
        "chatgpt_cot": "Fix typo in README.md for consistency in the phrase \"automatically running multiple matches\"."
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/editor/line_number_widget.py b/node_manager_fkie/src/node_manager_fkie/editor/line_number_widget.py @@ -99,7 +99,7 @@ class LineNumberWidget(QFrame):\nhbox = QHBoxLayout(self)\nhbox.setSpacing(0)\n- hbox.setMargin(0)\n+ # hbox.setMargin(0) # removed: it is not supported by Qt5\nhbox.addWidget(self.number_bar)\nhbox.addWidget(self.edit)\n",
        "org_msg": "node_manager_fkie: removed setMargin since it not suported by Qt5",
        "sim_msg": "move calls to child_widgets_created",
        "sim_diff": "diff --git a/widgets/frame/frame.py b/widgets/frame/frame.py @@ -92,6 +92,8 @@ class EditFrame(BitmapMixin, TopLevelBase, EditStylesMixin):\nself.widget.SetSize((400, 300))\nif wx.Platform == '__WXMSW__':\nself.widget.CenterOnScreen()\n+\n+ def child_widgets_created(self, level):\nif self.check_prop_truth(\"menubar\") and self._menubar.widget: self.widget.SetMenuBar(self._menubar.widget)\nif self.check_prop_truth(\"statusbar\") and self._statusbar.widget: self.widget.SetStatusBar(self._statusbar.widget)\nif self.check_prop_truth(\"toolbar\") and self._toolbar.widget: self.widget.SetToolBar(self._toolbar.widget)\n",
        "chatgpt_cot": "remove unsupported margin setting for LineNumberWidget."
    },
    {
        "org_diff": "diff --git a/fkie_master_discovery/src/fkie_master_discovery/master_discovery.py b/fkie_master_discovery/src/fkie_master_discovery/master_discovery.py @@ -338,18 +338,19 @@ class DiscoveredMaster(object):\ntry:\nrospy.logdebug(\"Get additional connection info from %s\" % self.monitoruri)\nremote_monitor = xmlrpcclient.ServerProxy(self.monitoruri)\n+ socket.setdefaulttimeout(10)\ntimestamp, masteruri, mastername, nodename, monitoruri = remote_monitor.masterContacts()\nself._del_error(self.ERR_SOCKET)\nrospy.logdebug(\"Got [%s, %s, %s, %s] from %s\" % (timestamp, masteruri, mastername, nodename, monitoruri))\nexcept socket.error as errobj:\n- msg = \"socket error [%s]: %s\" % (self.monitoruri, str(errobj))\n+ msg = \"can't retrieve connection information using XMLRPC from [%s], socket error: %s\" % (self.monitoruri, str(errobj))\nrospy.logwarn(msg)\nself._add_error(self.ERR_SOCKET, msg)\nif errobj.errno in [errno.EHOSTUNREACH]:\ntimetosleep = 30\nself.__start_get_info_timer(timetosleep)\nexcept:\n- msg = \"connection error [%s]: %s\" % (self.monitoruri, traceback.format_exc())\n+ msg = \"can't retrieve connection information using XMLRPC from [%s]: %s\" % (self.monitoruri, traceback.format_exc())\nrospy.logwarn(msg)\nself._add_error(self.ERR_SOCKET, msg)\nself.__start_get_info_timer(timetosleep)\n@@ -398,6 +399,8 @@ class DiscoveredMaster(object):\nrospy.logwarn(msg)\nself._add_error(self.ERR_SOCKET, msg)\nself.__start_get_info_timer(timetosleep)\n+ finally:\n+ socket.setdefaulttimeout(None)\nclass Discoverer(object):\n",
        "org_msg": "fkie_master_discovery: reduced timeout for connection requests",
        "sim_msg": "Fixing reconnection to addrindexrs when an error is catched\nNow addrindexrs commands timeouts are caught and retryed",
        "sim_diff": "diff --git a/counterpartylib/lib/backend/addrindexrs.py b/counterpartylib/lib/backend/addrindexrs.py @@ -278,11 +278,19 @@ class AddrIndexRsThread (threading.Thread):\nself.send({\"kill\": True})\ndef connect(self):\n- logging.debug('AddrIndexRs connecting')\nself.lastId = 0\n+ while True:\n+ logging.info('AddrIndexRs connecting...')\nself.sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n- self.sock.connect((self.host, self.port))\nself.sock.settimeout(SOCKET_TIMEOUT)\n+ try:\n+ self.sock.connect((self.host, self.port))\n+ except:\n+ logging.info('Error connecting to AddrIndexRs! Retrying in a few seconds')\n+ time.sleep(5.0)\n+ else:\n+ logging.info('Connected to AddrIndexRs!')\n+ break\ndef run(self):\nself.locker = threading.Condition()\n@@ -301,11 +309,11 @@ class AddrIndexRsThread (threading.Thread):\nself.sock.send(msg)\nhas_sent = True\nexcept Exception as e:\n- try:\n+ #try:\nlogging.debug('AddrIndexRs error:' + e)\nself.connect()\n- except Exception as e2:\n- logging.debug('AddrIndexRs fatal error:' + e2)\n+ #except Exception as e2:\n+ #logging.debug('AddrIndexRs fatal error:' + e2)\nself.message_to_send = None\ndata = b\"\"\n@@ -316,7 +324,18 @@ class AddrIndexRsThread (threading.Thread):\nself.message_result = json.loads(data.decode('utf-8'))\nretry_count = 0\nparsed = True\n+ logging.debug('AddrIndexRs Recv complete!')\n+ except socket.timeout:\n+ logging.debug('AddrIndexRs Recv timeout error sending: '+str(msg))\n+ if retry_count <= 0:\n+ self.connect()\n+ self.message_result = None\n+ retry_count -= -1\n+ except socket.error as e:\n+ logging.debug('AddrIndexRs Recv error:' + str(e)+' with msg '+str(msg))\n+ self.connect()\nexcept Exception as e:\n+ logging.debug('AddrIndexRs Recv error:' + str(e)+' with msg '+str(msg))\nif retry_count <= 0:\nraise e\nself.message_result = None\n",
        "chatgpt_cot": "\"Fix timeout issue in master_discovery.py for retrieving connection information using XMLRPC\""
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/start_handler.py b/node_manager_fkie/src/node_manager_fkie/start_handler.py @@ -668,7 +668,7 @@ class StartHandler(object):\nif ros_hostname:\nnew_env['ROS_HOSTNAME'] = ros_hostname\n# load params to ROS master\n- launcher._load_parameters(masteruri, startcfg.params, startcfg.clear_params, False)\n+ launcher._load_parameters(masteruri, startcfg.params, startcfg.clear_params)\nabs_paths = list() # tuples of (parameter name, old value, new value)\nnot_found_packages = list() # package names\n",
        "org_msg": "node_manager_fkie: fix start nodes on hosts without daemon",
        "sim_msg": "fix launch.",
        "sim_diff": "diff --git a/tools/launch.py b/tools/launch.py @@ -64,9 +64,8 @@ def submit_jobs(args, udf_command):\ntorch_cmd = torch_cmd + ' ' + '--master_addr=' + str(hosts[0][0])\ntorch_cmd = torch_cmd + ' ' + '--master_port=' + str(1234)\n- for i in range(args.num_client):\n- node_id = int(i / client_count_per_machine)\n- ip, _ = hosts[node_id]\n+ for node_id, host in enumerate(hosts):\n+ ip, _ = host\nnew_torch_cmd = torch_cmd.replace('node_rank=0', 'node_rank='+str(node_id))\nnew_udf_command = udf_command.replace('python3', 'python3 ' + new_torch_cmd)\ncmd = client_cmd + ' ' + new_udf_command\n",
        "chatgpt_cot": "Update method call parameters in StartHandler to remove unnecessary argument, improving code readability and efficiency."
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/master_view_proxy.py b/node_manager_fkie/src/node_manager_fkie/master_view_proxy.py @@ -2443,8 +2443,11 @@ class MasterViewProxy(QWidget):\nchoices = dict()\nfor grpc_path, _ in self.__configs.items():\n+ try:\npackage = utf8(package_name(grpc_path)[0])\nchoices['%s [%s]' % (os.path.basename(grpc_path), package)] = grpc_path\n+ except ValueError as val_err:\n+ rospy.logwarn(val_err)\ncfg_items = choices.keys()\ncfg_items.sort()\nres = SelectDialog.getValue('Close/Stop/Shutdown', '',\n",
        "org_msg": "node_manager_fkie: avoid crash on wrong configuration path",
        "sim_msg": "minor imrpvement to Exception reporting",
        "sim_diff": "diff --git a/qualcoder/manage_files.py b/qualcoder/manage_files.py @@ -1091,13 +1091,20 @@ class DialogManageFiles(QtWidgets.QDialog):\nif link_path == \"\":\ntry:\nself.load_file_text(f)\n+ except Exception as e_:\n+ print(e_)\n+ logger.warning(str(e_))\n+ try:\ncopyfile(f, destination)\n- except Exception:\n+ except OSError as e_:\n+ logger.warning(str(e_))\nMessage(self.app, _('Unknown file type'), _(\"Cannot import file\") + \":\\n\" + f, \"warning\")\nelse:\ntry:\nself.load_file_text(f, \"docs:\" + link_path)\n- except Exception:\n+ except Exception as e_:\n+ print(e_)\n+ logger.warning(str(e_))\nMessage(self.app, _('Unknown file type'), _(\"Cannot import file\") + \":\\n\" + f, \"warning\")\nif pdf_msg != \"\":\nself.parent_text_edit.append(pdf_msg)\n",
        "chatgpt_cot": "Add try-except block to handle ValueError in MasterViewProxy.py."
    },
    {
        "org_diff": "diff --git a/node_manager_daemon_fkie/src/node_manager_daemon_fkie/url.py b/node_manager_daemon_fkie/src/node_manager_daemon_fkie/url.py @@ -139,7 +139,7 @@ def join(uri, path):\nreturn '%s%s%s' % (uri, os.path.sep, path)\nreturn path\n-# grpc_split_url\n+\ndef split(grpc_path, with_scheme=False):\n'''\nSplits the gRPC-URI with scheme into URI and file path.\n",
        "org_msg": "node_manager_fkie: fixed wrong launch file paths",
        "sim_msg": "Encode content if not encoded before hashing",
        "sim_diff": "diff --git a/frappe/utils/file_manager.py b/frappe/utils/file_manager.py @@ -301,6 +301,8 @@ def get_file_path(file_name):\nreturn file_path\ndef get_content_hash(content):\n+ if isinstance(content, text_type):\n+ content = content.encode()\nreturn hashlib.md5(content).hexdigest()\ndef get_file_name(fname, optional_suffix):\n",
        "chatgpt_cot": "\"Add split method to the URL module to split the gRPC-URI with scheme into URI and file path.\""
    },
    {
        "org_diff": "diff --git a/master_discovery_fkie/src/master_discovery_fkie/common.py b/master_discovery_fkie/src/master_discovery_fkie/common.py @@ -261,7 +261,7 @@ def create_pattern(param, data, has_interface, default=[], mastername=''):\nelse:\ndef_list.append(rph)\ndef_list = list(set(def_list))\n- return gen_pattern(def_list, param)\n+ return gen_pattern(def_list, param, print_info=True, mastername=mastername)\ndef _parse_value(value, mastername, def_list):\n@@ -287,8 +287,11 @@ def _parse_value(value, mastername, def_list):\ndef_list.append(value)\n-def gen_pattern(filter_list, name, print_info=True):\n+def gen_pattern(filter_list, name, print_info=True, mastername=None):\nif print_info:\n+ if mastername is not None and mastername:\n+ rospy.loginfo(\"[%s] %s: %s\", mastername, name, str(filter_list))\n+ else:\nrospy.loginfo(\"%s: %s\", name, str(filter_list))\ndef_list = [''.join(['\\A', n.strip().replace('*', '.*'), '\\Z']) for n in filter_list]\nif def_list:\n",
        "org_msg": "master_discovery_fkie: improved filter logging",
        "sim_msg": "identifier? is already exported by the expander",
        "sim_diff": "diff --git a/pycket/prims/general.py b/pycket/prims/general.py @@ -359,7 +359,6 @@ for args in [ (\"subprocess?\",),\n(\"readtable?\",),\n(\"link-exists?\",),\n(\"rename-transformer?\",),\n- (\"identifier?\",),\n(\"port?\",),\n(\"sequence?\",),\n(\"namespace-anchor?\",),\n@@ -1212,10 +1211,6 @@ def string_to_symbol(v):\ndef immutable(v):\nreturn values.W_Bool.make(v.immutable())\n-@expose(\"eval-jit-enabled\", [])\n-def jit_enabled():\n- return values.w_true\n-\n@expose(\"make-thread-cell\",\n[values.W_Object, default(values.W_Bool, values.w_false)])\ndef make_thread_cell(v, pres):\n",
        "chatgpt_cot": "Add optional mastername parameter to gen_pattern function for logging, improving readability and flexibility in common.py."
    },
    {
        "org_diff": "diff --git a/src/agent/ansible/vars/os.yml b/src/agent/ansible/vars/os.yml @@ -63,5 +63,6 @@ cluster: {\n# If volume want to be used, specify a size in GB, make volume size 0 if wish\n# not to use volume from your cloud\n- volume_size: 8\n+ volume_size: 0,\n+ block_device_name: \"/dev/vdb\"\n}\n",
        "org_msg": "Block device name should not be removed\nIn previous patch, block device name was removed which\nwas a mistake. This patch will add that parameter back.\nThis problem is only specific for OpenStack cloud.",
        "sim_msg": "tests: teach controller.yml to configure git too",
        "sim_diff": "diff --git a/tests/ansible/gcloud/controller.yml b/tests/ansible/gcloud/controller.yml - hosts: controller\n+ vars:\n+ git_username: '{{ lookup(\"pipe\", \"git config --global user.name\") }}'\n+ git_email: '{{ lookup(\"pipe\", \"git config --global user.email\") }}'\n+\ntasks:\n- lineinfile:\nline: \"net.ipv4.ip_forward=1\"\n- shell: \"rsync -a ~/.ssh {{inventory_hostname}}:\"\nconnection: local\n+ - shell: |\n+ git config --global user.email \"{{git_username}}\"\n+ git config --global user.name \"{{git_email}}\"\n+ name: set_git_config\n+\n- git:\ndest: ~/mitogen\nrepo: https://github.com/dw/mitogen.git\n",
        "chatgpt_cot": "\"Update volume settings in os.yml for Ansible agent, set volume size to 0 and specify block device name as /dev/vdb to avoid cloud volume usage.\""
    },
    {
        "org_diff": "diff --git a/fkie_node_manager_daemon/src/fkie_node_manager_daemon/common.py b/fkie_node_manager_daemon/src/fkie_node_manager_daemon/common.py @@ -359,14 +359,15 @@ def replace_internal_args(content, resolve_args={}, path=None):\nnew_content = new_content.decode('utf-8')\nfor arg_key, args_val in resolve_args.items():\nreplaced = True\n- new_content = new_content.replace('$(arg %s)' % arg_key, args_val).encode('utf-8')\n+ new_content = new_content.replace('$(arg %s)' % arg_key, args_val)\nresolve_args_intern = get_internal_args(content)\nfor arg_key, args_val in resolve_args_intern.items():\n- new_content = new_content.replace('$(arg %s)' % arg_key, args_val).encode('utf-8')\n+ new_content = new_content.replace('$(arg %s)' % arg_key, args_val)\nreplaced = True\nexcept Exception as err:\nprint(\"%s in %s\" % (utf8(err), path))\n- rospy.logdebug(\"%s in %s\" % (utf8(err), path))\n+ import traceback\n+ rospy.logdebug(\"%s in %s\" % (traceback.format_exc(), path))\nreturn replaced, new_content, resolve_args_intern\n",
        "org_msg": "fkie_node_manager: fix error while get mtimes",
        "sim_msg": "fix Utils.encode_bytes\nNo one has encountered this yet, but there was a bug in encode_bytes if\nProcHelper.__init__ is called with an input string (that needs to be\nfixed too.)",
        "sim_diff": "diff --git a/internals/utils.py b/internals/utils.py @@ -12,7 +12,7 @@ def decode_bytes(s):\ndef encode_bytes(s):\n- return s or s.replace('\\n', os.linesep).encode('utf-8') if s is not None else None\n+ return s.replace('\\n', os.linesep).encode('utf-8') if s is not None else None\n# unicode function\n",
        "chatgpt_cot": "\"Fix encoding issue in common.py by removing unnecessary encode('utf-8') and adding traceback for debug log.\""
    },
    {
        "org_diff": "diff --git a/examples/terran/ramp_wall.py b/examples/terran/ramp_wall.py @@ -49,6 +49,9 @@ class RampWallBot(sc2.BotAI):\n# Draw ramp points\nself.draw_ramp_points()\n+ # Draw all detected expansions on the map\n+ self.draw_expansions()\n+\n# # Draw pathing grid\n# self.draw_pathing_grid()\n@@ -128,6 +131,13 @@ class RampWallBot(sc2.BotAI):\n# print(f\"Drawing {p0} to {p1}\")\n# self._client.debug_box_out(p0, p1, color=color)\n+ def draw_expansions(self):\n+ green = Point3((0, 255, 0))\n+ for expansion_pos in self.expansion_locations_list:\n+ height = self.get_terrain_z_height(expansion_pos)\n+ expansion_pos3 = Point3((*expansion_pos, height))\n+ self._client.debug_box2_out(expansion_pos3, half_vertex_length=2.5, color=green)\n+\ndef draw_pathing_grid(self):\nmap_area = self._game_info.playable_area\nfor (b, a), value in np.ndenumerate(self._game_info.pathing_grid.data_numpy):\n@@ -265,7 +275,7 @@ def main():\n\"HonorgroundsLE\", # Has 4 or 9 upper points at the large main base ramp\n]\n)\n- # map = \"ParaSiteLE\"\n+ map = \"GoldenWallLE\"\nsc2.run_game(\nsc2.maps.get(map),\n[Bot(Race.Terran, RampWallBot()), Computer(Race.Zerg, Difficulty.Hard)],\n",
        "org_msg": "Add draw expansion locations for ramp_wall bot",
        "sim_msg": "Clean up a few print statements.",
        "sim_diff": "diff --git a/SimPEG/EM/Utils/CurrentUtils.py b/SimPEG/EM/Utils/CurrentUtils.py @@ -257,7 +257,6 @@ def getSourceTermLineCurrentPolygon_Octree(mesh, px, py, pz):\nt = []\nfor cell in srcCellIds:\n- print('cellInd = ', cell)\n# Find the nodes of current cell\ncellNodeInds = list(mesh[cell].nodes)\n@@ -390,9 +389,10 @@ def getSourceTermLineCurrentPolygon_Octree(mesh, px, py, pz):\n# print('(cell_sx, cell_sy, cell_sz) =', cell_sx, cell_sy, cell_sz)\n+ # Assign integrated src values to the correct edges\n# Deal with paths which follow x edges\nif(len(np.where(cell_sx)[0]) == 1):\n- print('Path follows x edge.')\n+ # print('Path follows x edge.')\nxEdgeLocs = mesh.gridEx\nd_xEdge = np.sqrt((xEdgeLocs[:,0] - cx)**2 + (xEdgeLocs[:,1] - cy)**2 + (xEdgeLocs[:,2] - cz)**2)\nxEdgeInd = np.argmin(d_xEdge)\n@@ -401,7 +401,7 @@ def getSourceTermLineCurrentPolygon_Octree(mesh, px, py, pz):\n# Deal with paths which follow y edges\nelif(len(np.where(cell_sy)[0]) == 1):\n- print('Path follows y edge.')\n+ # print('Path follows y edge.')\nyEdgeLocs = mesh.gridEy\nd_yEdge = np.sqrt((yEdgeLocs[:,0] - cx)**2 + (yEdgeLocs[:,1] - cy)**2 + (yEdgeLocs[:,2] - cz)**2)\nyEdgeInd = np.argmin(d_yEdge)\n@@ -410,7 +410,7 @@ def getSourceTermLineCurrentPolygon_Octree(mesh, px, py, pz):\n# Deal with paths which follow z edges\nelif(len(np.where(cell_sz)[0]) == 1):\n- print('Path follows z edge.')\n+ # print('Path follows z edge.')\nzEdgeLocs = mesh.gridEz\nd_zEdge = np.sqrt((zEdgeLocs[:,0] - cx)**2 + (zEdgeLocs[:,1] - cy)**2 + (zEdgeLocs[:,2] - cz)**2)\nzEdgeInd = np.argmin(d_zEdge)\n@@ -419,7 +419,7 @@ def getSourceTermLineCurrentPolygon_Octree(mesh, px, py, pz):\n# Deal with paths which follow y or z faces\nelif(len(np.where(cell_sx)[0]) == 2):\n- print('Path follows a y or z face.')\n+ # print('Path follows a y or z face.')\nxEdgeLocs = mesh.gridEx\nd_xEdge = np.sqrt((xEdgeLocs[:,0] - cx)**2 + (xEdgeLocs[:,1] - cy)**2 + (xEdgeLocs[:,2] - cz)**2)\nxEdgeInd = np.argsort(d_xEdge)[0:2]\n@@ -430,7 +430,7 @@ def getSourceTermLineCurrentPolygon_Octree(mesh, px, py, pz):\n# Deal with paths which follow x or z faces\nelif(len(np.where(cell_sy)[0]) == 2):\n- print('Path follows a x or z face.')\n+ # print('Path follows a x or z face.')\nyEdgeLocs = mesh.gridEy\nd_yEdge = np.sqrt((yEdgeLocs[:,0] - cx)**2 + (yEdgeLocs[:,1] - cy)**2 + (yEdgeLocs[:,2] - cz)**2)\nyEdgeInd = np.argsort(d_yEdge)[0:2]\n@@ -441,7 +441,7 @@ def getSourceTermLineCurrentPolygon_Octree(mesh, px, py, pz):\n# Deal with paths which follow x or y faces\nelif(len(np.where(cell_sz)[0]) == 2):\n- print('Path follows a x or y face.')\n+ # print('Path follows a x or y face.')\nzEdgeLocs = mesh.gridEz\nd_zEdge = np.sqrt((zEdgeLocs[:,0] - cx)**2 + (zEdgeLocs[:,1] - cy)**2 + (zEdgeLocs[:,2] - cz)**2)\nzEdgeInd = np.argsort(d_zEdge)[0:2]\n",
        "chatgpt_cot": "Add method to draw expansions on map in RampWallBot class to visualize expansion locations, improving map visualization functionality. Update map to \"GoldenWallLE\"."
    },
    {
        "org_diff": "diff --git a/sc2/bot_ai.py b/sc2/bot_ai.py @@ -676,6 +676,7 @@ class BotAI(DistanceCalculation):\nif required_supply > 0:\nself.supply_used += required_supply\nself.supply_left -= required_supply\n+ # TODO: if unit created from larva: reduce larva count by 1\nself.actions.append(action)\nasync def _do_actions(self, actions: List[\"UnitCommand\"], prevent_double=True):\n",
        "org_msg": "Add todo: larva count reduction",
        "sim_msg": "renamed action scheme",
        "sim_diff": "diff --git a/bot_code/modelHelpers/actions/action_factory.py b/bot_code/modelHelpers/actions/action_factory.py @@ -49,7 +49,7 @@ super_split_scheme = ControlScheme(\ncopies=[],\n)\n-super_split_scheme_no_combo = ControlScheme(\n+super_split_scheme_no_combo_7 = ControlScheme(\nranges=[(THROTTLE, (-1, 1.25, .25)), (STEER, (-1, 1.25, .25)), (YAW, (-1, 1.25, .25)), (PITCH, (-1, 1.25, .25)), (ROLL, (-1, 1.25, .25)),(JUMP, (0, 2, 1)), (BOOST, (0, 2, 1)), (HANDBRAKE, (0, 2, 1))],\ncombo_scheme=[],\ncopies=[],\n",
        "chatgpt_cot": "Add functionality to reduce larva count by 1 when unit created from larva."
    },
    {
        "org_diff": "diff --git a/fkie_node_manager/src/fkie_node_manager/editor/editor.py b/fkie_node_manager/src/fkie_node_manager/editor/editor.py @@ -954,7 +954,8 @@ class Editor(QMainWindow):\nself._insert_text('<rosparam param=\"name\"\\n'\n' file=\"$(find pkg-name)/path/foo.yaml\"\\n'\n' command=\"load|dump|delete\"\\n'\n- ' ns=\"namespace\">\\n'\n+ ' ns=\"namespace\"\\n'\n+ ' subst_value=\"true|false\">\\n'\n'</rosparam>', 17, 4)\ndef _on_add_arg_tag_default(self):\n",
        "org_msg": "fkie_node_manager: editor: added 'subst_value' attribute to rosparam tag",
        "sim_msg": "update description strategy for info",
        "sim_diff": "diff --git a/slashtags/objects.py b/slashtags/objects.py @@ -437,8 +437,9 @@ class SlashTag:\ncommand_info = [\nf\"ID: `{c.id}`\",\nf\"Name: {c.name}\",\n- f\"Description: {c.description}\",\n]\n+ if c.description:\n+ command_info.append(f\"Description: {c.description}\")\ne.add_field(name=\"Command\", value=\"\\n\".join(command_info), inline=False)\noption_info = []\n",
        "chatgpt_cot": "Add support for substitution value in rosparam tag in Editor."
    },
    {
        "org_diff": "diff --git a/sc2/unit.py b/sc2/unit.py @@ -223,7 +223,7 @@ class Unit(object):\n@property\ndef order_target(self):\n- \"\"\" Returns the target tag from the first order \"\"\"\n+ \"\"\" Returns the target tag (if it is a Unit) or Point2 (if it is a Position) from the first order \"\"\"\nif len(self.orders) > 0:\nreturn self.orders[0].target\nreturn None\n",
        "org_msg": "Do a minor change to Unit.order_target",
        "sim_msg": "fix for value_and_unit",
        "sim_diff": "diff --git a/apps/projects/models.py b/apps/projects/models.py @@ -261,6 +261,6 @@ class Value(Model):\nvalue = self.value\nif self.attribute.unit:\n- return str(value) + ' ' + self.attribute.unit\n+ return '%s %s' % (value, self.attribute.unit)\nelse:\nreturn value\n",
        "chatgpt_cot": "Improve documentation for order_target method in Unit class to clarify return value based on order type."
    },
    {
        "org_diff": "diff --git a/rasa_core_sdk/__init__.py b/rasa_core_sdk/__init__.py @@ -53,15 +53,10 @@ class Tracker(object):\n# \"text\": text}\nself.latest_message = latest_message if latest_message else {}\n- def current_state(self, should_include_events=False):\n- # type: (bool) -> Dict[Text, Any]\n+ def current_state(self):\n+ # type: () -> Dict[Text, Any]\n\"\"\"Return the current tracker state as an object.\"\"\"\n- if should_include_events:\n- evts = self.events\n- else:\n- evts = None\n-\nif len(self.events) > 0:\nlatest_event_time = self.events[-1].timestamp\nelse:\n@@ -73,7 +68,7 @@ class Tracker(object):\n\"latest_message\": self.latest_message,\n\"latest_event_time\": latest_event_time,\n\"paused\": self.is_paused(),\n- \"events\": evts\n+ \"events\": self.events\n}\ndef current_slot_values(self):\n",
        "org_msg": "removed should include events",
        "sim_msg": "add function for checking my new dog's age in years",
        "sim_diff": "diff --git a/pajbot/bot.py b/pajbot/bot.py @@ -217,6 +217,7 @@ class Bot:\nself.data_cb['stream_status'] = self.c_stream_status\nself.data_cb['bot_uptime'] = self.c_uptime\nself.data_cb['current_time'] = self.c_current_time\n+ self.data_cb['molly_age_in_years'] = self.c_molly_age_in_years\nself.silent = True if args.silent else self.silent\n@@ -477,6 +478,12 @@ class Bot:\ndef c_current_time(self):\nreturn datetime.datetime.now()\n+ def c_molly_age_in_years(self):\n+ molly_birth = datetime.datetime(2018, 10, 29)\n+ now = datetime.datetime.now()\n+ diff = now-molly_birth\n+ return diff.total_seconds()/3600/24/365\n+\n@property\ndef is_online(self):\nreturn self.stream_manager.online\n",
        "chatgpt_cot": "Refactor current_state method to remove should_include_events parameter and fix compilation issues due to the changes in the Tracker class."
    },
    {
        "org_diff": "diff --git a/fkie_node_manager_daemon/src/fkie_node_manager_daemon/common.py b/fkie_node_manager_daemon/src/fkie_node_manager_daemon/common.py @@ -140,7 +140,7 @@ def sizeof_fmt(num, suffix='B'):\nif abs(num) < 1024.0:\nreturn \"%.0f%s%s\" % (num, unit, suffix)\nnum /= 1024.0\n- return \"%.0%s%s\" % (num, 'YiB', suffix)\n+ return \"%.0f%s%s\" % (num, 'YiB', suffix)\ndef formated_ts(stamp, with_date=True, with_nanosecs=True, tz=None):\n",
        "org_msg": "fix for byte formating",
        "sim_msg": "configure where to save peers",
        "sim_diff": "diff --git a/scripts/dht_node.py b/scripts/dht_node.py @@ -12,10 +12,10 @@ logging.basicConfig(level=logging.INFO, format=\"%(asctime)s %(levelname)-4s %(na\nlog = logging.getLogger(__name__)\n-async def main(host: str, port: int):\n+async def main(host: str, port: int, db_file_path):\nloop = asyncio.get_event_loop()\nconf = Config()\n- storage = SQLiteStorage(conf, \":memory:\", loop, loop.time)\n+ storage = SQLiteStorage(conf, db_file_path, loop, loop.time)\nawait storage.open()\nnode = Node(\nloop, PeerManager(loop), generate_id(), port, port, 3333, None,\n@@ -34,5 +34,6 @@ if __name__ == '__main__':\ndescription=\"Starts a single DHT node, which then can be used as a seed node or just a contributing node.\")\nparser.add_argument(\"--host\", default='0.0.0.0', type=str, help=\"Host to listen for requests. Default: 0.0.0.0\")\nparser.add_argument(\"--port\", default=4444, type=int, help=\"Port to listen for requests. Default: 4444\")\n+ parser.add_argument(\"--db_file\", default='/tmp/dht.db', type=str, help=\"DB file to save peers. Default: /tmp/dht.db\")\nargs = parser.parse_args()\n- asyncio.run(main(args.host, args.port))\n+ asyncio.run(main(args.host, args.port, args.db_file))\n",
        "chatgpt_cot": "Fix typo in the common.py file to correctly format the output in the sizeof_fmt function."
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/__init__.py b/node_manager_fkie/src/node_manager_fkie/__init__.py @@ -91,9 +91,9 @@ _QAPP = None\ndef detect_version():\ntry:\nglobal __version__\n- pkg_path, _ = roslib.packages.get_dir_pkg(PKG_NAME)\n+ pkg_path = roslib.packages.get_pkg_dir(PKG_NAME)\nif pkg_path is not None and os.path.isfile(\"%s/VERSION\" % pkg_path):\n- with open(os.path.isfile(\"%s/VERSION\" % pkg_path)) as f:\n+ with open(\"%s/VERSION\" % pkg_path) as f:\nversion = f.read()\n__version__ = version.strip()\nelif os.path.isdir(\"%s/../.git\" % settings().PACKAGE_DIR):\n",
        "org_msg": "node_manager_fkie: fix read version",
        "sim_msg": "Abort deployment if no CNI present\nThis commit makes it so deployment is aborted in case of no CNI plugin\nprovided when selecting specific cni_bin directory.",
        "sim_diff": "diff --git a/kvirt/kind/__init__.py b/kvirt/kind/__init__.py @@ -4,6 +4,8 @@ import os\nimport sys\nimport yaml\n+CNI_DIR = 'cni_bin'\n+\ndef create(config, plandir, cluster, overrides, dnsconfig=None):\nk = config.k\n@@ -31,9 +33,12 @@ def create(config, plandir, cluster, overrides, dnsconfig=None):\ninstallparam['plan'] = plan\ninstallparam['kubetype'] = 'kind'\nyaml.safe_dump(installparam, p, default_flow_style=False, encoding='utf-8', allow_unicode=True)\n- if os.path.exists('cni_bin'):\n- warning(\"Disabling default cni to use yours instead\")\n- data['cni_bin_path'] = f\"{os.getcwd()}/cni_bin\"\n+ if os.path.exists(CNI_DIR) and os.path.isdir(CNI_DIR):\n+ warning(\"Disabling default CNI to use yours instead\")\n+ if not os.listdir(CNI_DIR):\n+ error(\"No CNI plugin provided, aborting...\")\n+ sys.exit(1)\n+ data['cni_bin_path'] = f\"{os.getcwd()}/{CNI_DIR}\"\ndata['disable_default_cni'] = True\nresult = config.plan(plan, inputfile='%s/kcli_plan.yml' % plandir, overrides=data)\nif result['result'] != 'success':\n",
        "chatgpt_cot": "Fix file path and open method in detect_version() function to correctly read the version from the VERSION file in the package directory."
    },
    {
        "org_diff": "diff --git a/fkie_node_manager_daemon/src/fkie_node_manager_daemon/common.py b/fkie_node_manager_daemon/src/fkie_node_manager_daemon/common.py @@ -279,7 +279,6 @@ def get_internal_args(content, path=None, only_default=False):\n:rtype: {str: str}\n'''\nnew_content = content\n- value_types = ['default'] if only_default else ['value', 'default']\ntry:\nresolve_args_intern = {}\nxml_nodes = minidom.parseString(new_content).getElementsByTagName('launch')\n@@ -288,13 +287,17 @@ def get_internal_args(content, path=None, only_default=False):\nif child.localName == 'arg' and child.hasAttributes():\naname = ''\naval = ''\n+ add_arg = True\nfor argi in range(child.attributes.length):\narg_attr = child.attributes.item(argi)\nif arg_attr.localName == 'name':\naname = arg_attr.value\n- elif arg_attr.localName in value_types:\n+ elif arg_attr.localName in ['value', 'default']:\naval = arg_attr.value\n- if aname:\n+ # do not add this argument to the result list if value is set and 'only_default' is True\n+ if only_default and arg_attr.localName == 'value':\n+ add_arg = False\n+ if aname and add_arg:\nresolve_args_intern[aname] = aval\nexcept Exception as err:\nprint(\"%s while get_internal_args %s\" % (utf8(err), path))\n",
        "org_msg": "fkie_node_manager: editor: do not test argument with defined value tag",
        "sim_msg": "Use sentence case for the group names in the parser",
        "sim_diff": "diff --git a/httpie/cli/definition.py b/httpie/cli/definition.py @@ -44,7 +44,7 @@ options = ParserSpec(\n#######################################################################\npositional_arguments = options.add_group(\n- 'Positional Arguments',\n+ 'Positional arguments',\ndescription=\"\"\"\nThese arguments come after any flags and in the order they are listed here.\nOnly URL is required.\n@@ -145,7 +145,7 @@ positional_arguments.add_argument(\n# Content type.\n#######################################################################\n-content_types = options.add_group('Predefined Content Types')\n+content_types = options.add_group('Predefined content types')\ncontent_types.add_argument(\n'--json',\n@@ -219,7 +219,7 @@ content_types.add_argument(\n# Content processing.\n#######################################################################\n-processing_options = options.add_group('Content Processing Options')\n+processing_options = options.add_group('Content processing options')\nprocessing_options.add_argument(\n'--compress',\n@@ -284,7 +284,7 @@ _unsorted_kwargs = {\n'dest': 'format_options',\n}\n-output_processing = options.add_group('Output Processing')\n+output_processing = options.add_group('Output processing')\noutput_processing.add_argument(\n'--pretty',\n@@ -398,7 +398,7 @@ output_processing.add_argument(\n# Output options\n#######################################################################\n-output_options = options.add_group('Output Options')\n+output_options = options.add_group('Output options')\noutput_options.add_argument(\n'--print',\n",
        "chatgpt_cot": "\"Fix compilation issue by adding a new argument to the result list if the value is set and 'only_default' is True\""
    },
    {
        "org_diff": "diff --git a/sc2/units.py b/sc2/units.py @@ -188,7 +188,7 @@ class Units(list):\n@property\ndef gathering(self):\n- return self.filter(lambda unit: not unit.is_gathering)\n+ return self.filter(lambda unit: unit.is_gathering)\n@property\ndef mineral_field(self):\n",
        "org_msg": "Remove accidental \"not\" in the units.gathering property",
        "sim_msg": "fix for value_and_unit",
        "sim_diff": "diff --git a/apps/projects/models.py b/apps/projects/models.py @@ -261,6 +261,6 @@ class Value(Model):\nvalue = self.value\nif self.attribute.unit:\n- return str(value) + ' ' + self.attribute.unit\n+ return '%s %s' % (value, self.attribute.unit)\nelse:\nreturn value\n",
        "chatgpt_cot": "Fix bug in gathering property of Units class. Changed filter condition to correctly identify gathering units."
    },
    {
        "org_diff": "diff --git a/fkie_node_manager/package.xml b/fkie_node_manager/package.xml <exec_depend>rqt_reconfigure</exec_depend>\n<exec_depend>diagnostic_msgs</exec_depend>\n- <exec_depend condition=\"$ROS_PYTHON_VERSION == 2\">python-pycryptodome</exec_depend>\n<exec_depend condition=\"$ROS_PYTHON_VERSION == 2\">python-docutils</exec_depend>\n<exec_depend condition=\"$ROS_PYTHON_VERSION == 2\">python-paramiko</exec_depend>\n+ <exec_depend condition=\"$ROS_PYTHON_VERSION == 2\">python-pycryptodome</exec_depend>\n+ <exec_depend condition=\"$ROS_PYTHON_VERSION == 2\">python-qt5-bindings-webkit</exec_depend>\n<exec_depend condition=\"$ROS_PYTHON_VERSION == 2\">python-ruamel.yaml</exec_depend>\n- <!-- <exec_depend condition=\"$ROS_PYTHON_VERSION == 3\">python3-pycryptodome</exec_depend>\n+ <!--\n<exec_depend condition=\"$ROS_PYTHON_VERSION == 3\">python3-docutils</exec_depend>\n<exec_depend condition=\"$ROS_PYTHON_VERSION == 3\">python3-paramiko</exec_depend>\n- <exec_depend condition=\"$ROS_PYTHON_VERSION == 3\">python3-ruamel.yaml</exec_depend> -->\n+ <exec_depend condition=\"$ROS_PYTHON_VERSION == 3\">python3-pycryptodome</exec_depend>\n+ <exec_depend condition=\"$ROS_PYTHON_VERSION == 3\">python3-qt5-bindings-webkit</exec_depend>\n+ <exec_depend condition=\"$ROS_PYTHON_VERSION == 3\">python3-ruamel.yaml</exec_depend>\n+ -->\n<exec_depend>python_qt_binding</exec_depend>\n<exec_depend>screen</exec_depend>\n",
        "org_msg": "fkie_node_manager: added missing webkit dependecy",
        "sim_msg": "chore: update uvicorn and add testing dependencies\nuvicorn 0.14.0\npytest-asyncio 0.15.1\nasgi-lifespan 1.0.1\nhttpx 0.18.2",
        "sim_diff": "diff --git a/packages/grid/backend/app/pyproject.toml b/packages/grid/backend/app/pyproject.toml @@ -6,7 +6,7 @@ authors = [\"Admin <admin@example.com>\"]\n[tool.poetry.dependencies]\npython = \"^3.7\"\n-uvicorn = \"^0.11.3\"\n+uvicorn = \"^0.14.0\"\nfastapi = \"^0.54.1\"\npython-multipart = \"^0.0.5\"\nemail-validator = \"^1.0.5\"\n@@ -36,6 +36,9 @@ flake8 = \"^3.7.9\"\npytest = \"^5.4.1\"\nsqlalchemy-stubs = \"^0.3\"\npytest-cov = \"^2.8.1\"\n+pytest-asyncio = \"^0.15.1\"\n+asgi-lifespan = \"^1.0.1\"\n+httpx = \"^0.18.2\"\n[tool.isort]\nmulti_line_output = 3\n",
        "chatgpt_cot": "Update package.xml to add dependencies for python-pycryptodome and python-qt5-bindings-webkit based on ROS_PYTHON_VERSION to resolve dependency issues."
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/echo_dialog.py b/node_manager_fkie/src/node_manager_fkie/echo_dialog.py @@ -500,18 +500,22 @@ class EchoDialog(QDialog):\nmessage_window = ''\nmessage_std_dev = ''\nmessage_scrapped = ''\n+ sum_times = sum(self.times)\nif (self.SHOW_BYTES or self.show_only_rate) and self.bytes:\n- avg = sum(self.bytes) / len(self.bytes)\n+ sum_bytes = sum(self.bytes)\n+ avg = sum_bytes / len(self.bytes)\nlast = self.bytes[-1]\nif avg != last:\nmessage_bytes = \"size[ last: %s, avg: %s ]\" % (self._normilize_size_print(last), self._normilize_size_print(avg))\nelse:\nmessage_bytes = \"size: %s\" % (self._normilize_size_print(last))\n+ byte_rate = float(sum_bytes) / float(sum_times)\n+ message_bytes += \" bw: %s\" % (self._normilize_size_print(byte_rate))\n# the code from ROS rostopic\nn = len(self.times)\nif n < 2:\nreturn\n- mean = sum(self.times) / n\n+ mean = sum_times / n\nrate = 1. / mean if mean > 0. else 0\nmessage_rate = \"average rate: %.3f\" % rate\n# min and max\n@@ -540,9 +544,9 @@ class EchoDialog(QDialog):\ndef _normilize_size_print(self, size):\nif size > 999999:\n- return \"%.2fMB\" % (size / 1000000.0)\n+ return \"%.2fMB\" % (size / 1048576.0)\nif size > 999:\n- return \"%.2fKB\" % (size / 1000.0)\n+ return \"%.2fKB\" % (size / 1024.0)\nreturn \"%dB\" % size\ndef _print_status(self):\n",
        "org_msg": "node_manager_fkie: added bandwith calculation",
        "sim_msg": "[ServerStats] This time I introduced another UnboundLocalError whoops",
        "sim_diff": "diff --git a/serverstats/serverstats.py b/serverstats/serverstats.py @@ -1014,8 +1014,8 @@ class ServerStats(commands.Cog):\nif m := guild.get_member(member.id) and guild.get_member(ctx.author.id):\nguild_list.append(m)\nembed_list = []\n- if guild_list != []:\nrobot = \"\\N{ROBOT FACE}\" if member.bot else \"\"\n+ if guild_list != []:\nmsg = f\"**{member}** ({member.id}) {robot}\" + _(\"is on:\\n\\n\")\nembed_msg = \"\"\nfor m in guild_list:\n",
        "chatgpt_cot": "\"Refactor EchoDialog to improve byte and time handling\""
    },
    {
        "org_diff": "diff --git a/rasa_core_sdk/__init__.py b/rasa_core_sdk/__init__.py @@ -190,7 +190,7 @@ class ActionExecutionRejection(Exception):\ndef __init__(self, action_name, message=None):\nself.action_name = action_name\nself.message = (message or\n- \"Custom action '{}' rejected to run\"\n+ \"Custom action '{}' rejected execution of\"\n\"\".format(action_name))\ndef __str__(self):\n",
        "org_msg": "Update rasa_core_sdk/__init__.py",
        "sim_msg": "core: remove unused SecurityError.",
        "sim_diff": "diff --git a/mitogen/core.py b/mitogen/core.py @@ -83,10 +83,6 @@ class Error(Exception):\nException.__init__(self, fmt)\n-class SecurityError(Error):\n- pass\n-\n-\nclass CallError(Error):\ndef __init__(self, e):\ns = '%s.%s: %s' % (type(e).__module__, type(e).__name__, e)\n",
        "chatgpt_cot": "Refactor rejection message in ActionExecutionRejection class in __init__.py to clarify action execution rejection reason."
    },
    {
        "org_diff": "diff --git a/fkie_node_manager/src/fkie_node_manager/node_tree_model.py b/fkie_node_manager/src/fkie_node_manager/node_tree_model.py @@ -349,7 +349,7 @@ class GroupItem(QStandardItem):\nfor _cfg, cap in self._capcabilities.items():\nfor gns, groups in cap.items():\nfor group, _decription in groups.items():\n- if ns.rstrip('/') == gns and group == group_name:\n+ if ns == gns and group == group_name:\nreturn True\nelif self.parent_item is not None:\nreturn self.parent_item.exists_capability_group(ns, group_name)\n@@ -1674,7 +1674,7 @@ class NodeTreeModel(QStandardItemModel):\nself.setHorizontalHeaderLabels([label for label, _ in NodeTreeModel.header])\nself._local_host_address = host_address\nself._local_masteruri = masteruri\n- self._std_capabilities = {'': {'SYSTEM': {'images': [],\n+ self._std_capabilities = {'/': {'SYSTEM': {'images': [],\n'nodes': ['/rosout',\n'/master_discovery',\n'/zeroconf',\n@@ -1704,8 +1704,8 @@ class NodeTreeModel(QStandardItemModel):\nif host_item is not None:\ncap = self._std_capabilities\nmastername = roslib.names.SEP.join(['', host_item.mastername, '*', 'default_cfg'])\n- if mastername not in cap['']['SYSTEM']['nodes']:\n- cap['']['SYSTEM']['nodes'].append(mastername)\n+ if mastername not in cap['/']['SYSTEM']['nodes']:\n+ cap['/']['SYSTEM']['nodes'].append(mastername)\nhost_item.add_capabilities('', cap, host_item.masteruri)\nreturn cap\nreturn dict(self._std_capabilities)\n@@ -1792,7 +1792,7 @@ class NodeTreeModel(QStandardItemModel):\ndef _requestCapabilityGroupParameter(self, host_item):\nif host_item is not None:\nitems = host_item.get_node_items()\n- params = [roslib.names.ns_join(item.name, 'capability_group') for item in items if not item.has_configs() and item.is_running() and not host_item.is_in_cap_group(item.name, '', '', 'SYSTEM')]\n+ params = [roslib.names.ns_join(item.name, 'capability_group') for item in items if not item.has_configs() and item.is_running() and not host_item.is_in_cap_group(item.name, '', '/', 'SYSTEM')]\nif params:\nself.parameterHandler.requestParameterValues(host_item.masteruri, params)\n@@ -1814,7 +1814,7 @@ class NodeTreeModel(QStandardItemModel):\nchanged = False\nif hostItem is not None and code == 1:\ncapabilities = self._set_std_capabilities(hostItem)\n- available_ns = set([''])\n+ available_ns = set(['/'])\navailable_groups = set(['SYSTEM'])\n# assumption: all parameter are 'capability_group' parameter\nfor p, (code_n, _, val) in params.items(): # _:=msg_n\n",
        "org_msg": "fkie_node_manager: fixed capability groups in root namespace",
        "sim_msg": "Dimming item node name's color",
        "sim_diff": "diff --git a/avalon/tools/cbsceneinventory/model.py b/avalon/tools/cbsceneinventory/model.py @@ -73,6 +73,9 @@ class InventoryModel(TreeModel):\nreturn self.GRAYOUT_COLOR\n+ if key == \"name\" and not node.get(\"isGroupNode\"):\n+ return self.GRAYOUT_COLOR\n+\n# Add icons\nif role == QtCore.Qt.DecorationRole:\nif index.column() == 0:\n",
        "chatgpt_cot": "\"Fix capability group parameter issue in NodeTreeModel\""
    },
    {
        "org_diff": "diff --git a/node_manager_daemon_fkie/src/node_manager_daemon_fkie/launcher.py b/node_manager_daemon_fkie/src/node_manager_daemon_fkie/launcher.py @@ -84,7 +84,7 @@ def create_start_config(node, launchcfg, executable='', masteruri=None, loglevel\nresult.respawn = n.respawn\nif n.respawn_delay > 0:\nresult.respawn_delay = n.respawn_delay\n- respawn_params = _get_respawn_params(rospy.names.ns_join(n.namespace, n.name), launchcfg.roscfg.params)\n+ respawn_params = _get_respawn_params(rospy.names.ns_join(n.namespace, n.name), launchcfg.roscfg.params, result.respawn_delay)\nresult.respawn_max = respawn_params['max']\nresult.respawn_min_runtime = respawn_params['min_runtime']\nresult.respawn_delay = respawn_params['delay']\n@@ -270,8 +270,8 @@ def _rosconsole_cfg_file(package, loglevel='INFO'):\nreturn result\n-def _get_respawn_params(node, params):\n- result = {'max': 0, 'min_runtime': 0, 'delay': 0}\n+def _get_respawn_params(node, params, respawn_delay_value=0):\n+ result = {'max': 0, 'min_runtime': 0, 'delay': respawn_delay_value}\nrespawn_max = rospy.names.ns_join(node, 'respawn/max')\nrespawn_min_runtime = rospy.names.ns_join(node, 'respawn/min_runtime')\nrespawn_delay = rospy.names.ns_join(node, 'respawn/delay')\n",
        "org_msg": "node_manager_daemon_fkie: fixed usage of respawn_delay of default launch file tag",
        "sim_msg": "retry startup",
        "sim_diff": "diff --git a/lbrynet/lbrynet_daemon/DaemonControl.py b/lbrynet/lbrynet_daemon/DaemonControl.py @@ -114,7 +114,7 @@ def update_settings_from_args(args):\n@defer.inlineCallbacks\n-def start_server_and_listen(launchui, use_auth, analytics_manager):\n+def start_server_and_listen(launchui, use_auth, analytics_manager, max_tries=5):\n\"\"\"The primary entry point for launching the daemon.\nArgs:\n@@ -124,13 +124,19 @@ def start_server_and_listen(launchui, use_auth, analytics_manager):\n\"\"\"\nanalytics_manager.send_server_startup()\nlog_support.configure_analytics_handler(analytics_manager)\n+ tries = 1\n+ while tries < max_tries:\n+ log.info('Making attempt %s / %s to startup', tries, max_tries)\ntry:\ndaemon_server = DaemonServer(analytics_manager)\nyield daemon_server.start(use_auth, launchui)\nanalytics_manager.send_server_startup_success()\n+ break\nexcept Exception as e:\nlog.exception('Failed to startup')\nanalytics_manager.send_server_startup_error(str(e))\n+ tries += 1\n+ else:\nreactor.callFromThread(reactor.stop)\n",
        "chatgpt_cot": "Add optional parameter to _get_respawn_params method to set respawn_delay_value in launcher.py."
    },
    {
        "org_diff": "diff --git a/sc2/client.py b/sc2/client.py -from s2clientprotocol import sc2api_pb2 as sc_pb, common_pb2 as common_pb, query_pb2 as query_pb\n+from s2clientprotocol import (\n+ sc2api_pb2 as sc_pb,\n+ common_pb2 as common_pb,\n+ query_pb2 as query_pb,\n+ debug_pb2 as debug_pb\n+)\nfrom .cache import method_cache_forever\n@@ -78,3 +83,14 @@ class Client(Protocol):\nignore_resource_requirements=ignore_resources\n))\nreturn [ActionResult(p.result) for p in result.query.placements]\n+\n+ async def debug_text(self, text, position, color=(0, 255, 0)):\n+ await self._execute(debug=sc_pb.RequestDebug(\n+ debug=[debug_pb.DebugCommand(draw=debug_pb.DebugDraw(\n+ text=[debug_pb.DebugText(\n+ text=text,\n+ color=debug_pb.Color(r=color[0], g=color[1], b=color[2]),\n+ world_pos=common_pb.Point(x=position.x, y=position.y, z=position.z)\n+ )]\n+ ))]\n+ ))\n",
        "org_msg": "Add debug text drawing",
        "sim_msg": "Grid Client Small changes\nRemove proxy/unproxy methods\nADD load method\nAdd user_key optional parameter",
        "sim_diff": "diff --git a/src/syft/grid/client/client.py b/src/syft/grid/client/client.py from typing import Any\nfrom typing import Dict\nfrom typing import Optional\n+from typing import Type\nfrom typing import Union\n# third party\n@@ -24,8 +25,10 @@ from ...core.node.device.client import DeviceClient\nfrom ...core.node.domain.client import DomainClient\nfrom ...core.node.network.client import NetworkClient\nfrom ...core.node.vm.client import VirtualMachineClient\n+from ...core.pointer.pointer import Pointer\nfrom ..messages.setup_messages import CreateInitialSetUpMessage\nfrom ..messages.setup_messages import GetSetUpMessage\n+from ..messages.transfer_messages import LoadObjectMessage\nfrom .request_api.association_api import AssociationRequestAPI\nfrom .request_api.group_api import GroupRequestAPI\nfrom .request_api.role_api import RoleRequestAPI\n@@ -38,6 +41,7 @@ def connect(\nconn_type: ClientConnection,\nclient_type: Client,\ncredentials: Dict = {},\n+ user_key: Optional[SigningKey] = None,\n) -> Any:\nclass GridClient(client_type): # type: ignore\ndef __init__(\n@@ -52,11 +56,14 @@ def connect(\nconn = conn_type(url=url) # type: ignore\nif credentials:\n- metadata, user_key = conn.login(credentials=credentials)\n- user_key = SigningKey(user_key.encode(\"utf-8\"), encoder=HexEncoder)\n+ metadata, _user_key = conn.login(credentials=credentials)\n+ _user_key = SigningKey(_user_key.encode(\"utf-8\"), encoder=HexEncoder)\nelse:\nmetadata = conn._get_metadata()\n- user_key = SigningKey.generate()\n+ if not user_key:\n+ _user_key = SigningKey.generate()\n+ else:\n+ _user_key = user_key\n(\nspec_location,\n@@ -81,22 +88,28 @@ def connect(\nvm=location_args[VirtualMachineClient],\nname=name,\nroutes=[route],\n- signing_key=user_key,\n+ signing_key=_user_key,\n)\nself.groups = GroupRequestAPI(send=self.__perform_grid_request)\nself.users = UserRequestAPI(send=self.__perform_grid_request)\nself.roles = RoleRequestAPI(send=self.__perform_grid_request)\n- self.workers = WorkerRequestAPI(send=self.__perform_grid_request)\n+ self.workers = WorkerRequestAPI(\n+ send=self.__perform_grid_request, client=self\n+ )\nself.association_requests = AssociationRequestAPI(\nsend=self.__perform_grid_request\n)\n- def proxy(self, vm_address: Address) -> None:\n- self.proxy_address = vm_address\n-\n- def unproxy(self) -> None:\n- self.proxy_address = None\n+ def load(\n+ self, obj_ptr: Type[Pointer], address: Address, searchable: bool = False\n+ ) -> None:\n+ content = {\n+ \"address\": address.serialize().SerializeToString().decode(\"ISO-8859-1\"), # type: ignore\n+ \"uid\": str(obj_ptr.id_at_location.value),\n+ \"searchable\": searchable,\n+ }\n+ self.__perform_grid_request(grid_msg=LoadObjectMessage, content=content)\ndef initial_setup(self, **kwargs: Any) -> Any:\nreturn self.__perform_grid_request(\n@@ -113,7 +126,6 @@ def connect(\n],\nroute_index: int = 0,\n) -> SyftMessage:\n-\nif self.proxy_address:\nmsg.address = self.proxy_address\n",
        "chatgpt_cot": "Add debug_text method to Client class for debugging purposes."
    },
    {
        "org_diff": "diff --git a/fkie_node_manager_daemon/src/fkie_node_manager_daemon/remote.py b/fkie_node_manager_daemon/src/fkie_node_manager_daemon/remote.py @@ -102,9 +102,9 @@ def get_insecure_channel(url):\nif host.get_port(url):\nrospy.logdebug(\"create insecure channel to %s\" % url)\n# does the storeage cause delays on connection problems?\n- # INSECURE_CHANNEL_CACHE[cn] = grpc.insecure_channel(url)\n- # return INSECURE_CHANNEL_CACHE[cn]\n+ INSECURE_CHANNEL_CACHE[cn] = grpc.insecure_channel(url)\n+ return INSECURE_CHANNEL_CACHE[cn]\n# INSECURE_CHANNEL_CACHE[cn] = grpc.secure_channel(url, CREDENTIALS)\n- return grpc.insecure_channel(url)\n+ # return grpc.insecure_channel(url)\nprint(\"No cached URL for insecure channel: %s\" % url)\nreturn None\n",
        "org_msg": "enable cache for grpc channels again\nno cache causes os_error:\"Too many open files\". Perhaps it is related to\nFurther tests needed.",
        "sim_msg": "Adding additional return to Channel Call",
        "sim_diff": "diff --git a/functions/cachedDbCalls.py b/functions/cachedDbCalls.py @@ -57,7 +57,7 @@ def getChannel(channelID):\nChannel.Channel.chatEnabled, Channel.Channel.chatBG, Channel.Channel.chatTextColor, Channel.Channel.chatAnimation,\nChannel.Channel.imageLocation, Channel.Channel.offlineImageLocation, Channel.Channel.description, Channel.Channel.allowComments,\nChannel.Channel.protected, Channel.Channel.channelMuted, Channel.Channel.showChatJoinLeaveNotification, Channel.Channel.defaultStreamName,\n- Channel.Channel.autoPublish, Channel.Channel.vanityURL, Channel.Channel.private, Channel.Channel.streamKey).filter_by(id=channelID).first()\n+ Channel.Channel.autoPublish, Channel.Channel.vanityURL, Channel.Channel.private, Channel.Channel.streamKey, Channel.Channel.xmppToken).filter_by(id=channelID).first()\nreturn channelQuery\n@cache.memoize(timeout=600)\n@@ -68,7 +68,7 @@ def getChannelByLoc(channelLoc):\nChannel.Channel.chatEnabled, Channel.Channel.chatBG, Channel.Channel.chatTextColor, Channel.Channel.chatAnimation,\nChannel.Channel.imageLocation, Channel.Channel.offlineImageLocation, Channel.Channel.description, Channel.Channel.allowComments,\nChannel.Channel.protected, Channel.Channel.channelMuted, Channel.Channel.showChatJoinLeaveNotification, Channel.Channel.defaultStreamName,\n- Channel.Channel.autoPublish, Channel.Channel.vanityURL, Channel.Channel.private, Channel.Channel.streamKey).filter_by(channelLoc=channelLoc).first()\n+ Channel.Channel.autoPublish, Channel.Channel.vanityURL, Channel.Channel.private, Channel.Channel.streamKey, Channel.Channel.xmppToken).filter_by(channelLoc=channelLoc).first()\nreturn channelQuery\n@cache.memoize(timeout=600)\n@@ -79,7 +79,7 @@ def getChannelByStreamKey(StreamKey):\nChannel.Channel.chatEnabled, Channel.Channel.chatBG, Channel.Channel.chatTextColor, Channel.Channel.chatAnimation,\nChannel.Channel.imageLocation, Channel.Channel.offlineImageLocation, Channel.Channel.description, Channel.Channel.allowComments,\nChannel.Channel.protected, Channel.Channel.channelMuted, Channel.Channel.showChatJoinLeaveNotification, Channel.Channel.defaultStreamName,\n- Channel.Channel.autoPublish, Channel.Channel.vanityURL, Channel.Channel.private, Channel.Channel.streamKey).filter_by(streamKey=StreamKey).first()\n+ Channel.Channel.autoPublish, Channel.Channel.vanityURL, Channel.Channel.private, Channel.Channel.streamKey, Channel.Channel.xmppToken).filter_by(streamKey=StreamKey).first()\nreturn channelQuery\n@cache.memoize(timeout=60)\n",
        "chatgpt_cot": "\"Fix connection delay issue caused by insecure channel cache in remote.py\""
    },
    {
        "org_diff": "diff --git a/README.md b/README.md @@ -6,6 +6,8 @@ An easy-to-use library for writing AI Bots for StarCraft II in Python 3. The ult\nDocumentation is in [the Wiki](https://github.com/Dentosal/python-sc2/wiki).\n+For automaticly running multiple matches, check out [Dentosal/sc2-bot-match-runner](https://github.com/Dentosal/sc2-bot-match-runner).\n+\n## Installation\nYou'll need Python 3.6 or newer.\n",
        "org_msg": "Added a note about sc2-bot-match-runner repository",
        "sim_msg": "Forgot to update iNumPlayers",
        "sim_diff": "diff --git a/v3/runner.py b/v3/runner.py @@ -63,6 +63,8 @@ if __name__ == '__main__':\ncallbacks = []\nname_dict = dict()\n+ gameInputPacket.iNumPlayers = num_bots\n+\n# Set configuration values for bots and store name and team\nfor i in range(num_bots):\nbot_config = configparser.RawConfigParser()\n",
        "chatgpt_cot": "Add link to sc2-bot-match-runner for running multiple matches automatically in README.md."
    },
    {
        "org_diff": "diff --git a/fkie_node_manager_daemon/src/fkie_node_manager_daemon/launcher.py b/fkie_node_manager_daemon/src/fkie_node_manager_daemon/launcher.py @@ -332,7 +332,7 @@ def _load_parameters(masteruri, params, clear_params):\nfor pkey, pval in params.items():\nvalue = pval\n# resolve path elements\n- if isinstance(value, types.StringTypes) and value.startswith('$'):\n+ if isinstance(value, types.StringTypes) and (value.startswith('$') or value.startswith('pkg://') or value.startswith('package://')):\nvalue = interpret_path(value)\nrospy.logdebug(\"interpret parameter '%s' to '%s'\" % (value, pval))\n# add parameter to the multicall\n",
        "org_msg": "fkie_node_manager_daemon: resolve pkg references while launch on remote hosts",
        "sim_msg": "tidying up the read parameters",
        "sim_diff": "diff --git a/pycket/prims/parameter.py b/pycket/prims/parameter.py @@ -81,28 +81,30 @@ expose_val(\"parameterization-key\", values.parameterization_key)\nexpose_val(\"print-mpair-curly-braces\", values_parameter.W_Parameter(values.w_false))\nexpose_val(\"print-pair-curly-braces\", values_parameter.W_Parameter(values.w_false))\nexpose_val(\"error-print-source-location\", values_parameter.W_Parameter(values.w_true))\n-expose_val(\"read-accept-bar-quote\", values_parameter.W_Parameter(values.w_true))\n-expose_val(\"read-accept-compiled\", values_parameter.W_Parameter(values.w_true))\n-expose_val(\"read-accept-lang\", values_parameter.W_Parameter(values.w_true))\n-expose_val(\"read-accept-reader\", values_parameter.W_Parameter(values.w_true))\n-READ_PARAMS = \"\"\"\n+READ_TRUE_PARAMS = \"\"\"\n+read-accept-reader\n+read-accept-lang\n+read-accept-compiled\n+read-accept-bar-quote\nread-square-bracket-as-paren\nread-curly-brace-as-paren\n-read-square-bracket-with-tag\n-read-curly-brace-with-tag\nread-accept-box\n-read-accept-bar-quote\nread-accept-graph\nread-decimal-as-inexact\nread-accept-dot\nread-accept-infix-dot\n-read-cdot\nread-accept-quasiquote\n-read-accept-reader\n-read-accept-lang\n\"\"\"\n-# for name in READ_PARAMS.split():\n-# expose_val(name, values_parameter.W_Parameter(values.w_false))\n+READ_FALSE_PARAMS = \"\"\"\n+read-square-bracket-with-tag\n+read-curly-brace-with-tag\n+read-cdot\n+\"\"\"\n+\n+for name in READ_TRUE_PARAMS.split():\n+ expose_val(name, values_parameter.W_Parameter(values.w_true))\n+for name in READ_FALSE_PARAMS.split():\n+ expose_val(name, values_parameter.W_Parameter(values.w_false))\n",
        "chatgpt_cot": "Add support for interpreting parameters with 'pkg://' and 'package://' prefixes to resolve path elements in launcher.py."
    },
    {
        "org_diff": "diff --git a/fkie_master_discovery/src/fkie_master_discovery/master_discovery.py b/fkie_master_discovery/src/fkie_master_discovery/master_discovery.py @@ -984,8 +984,11 @@ class Discoverer(object):\n(version,) = struct.unpack('B', msg[1:2])\nif (version in [Discoverer.VERSION, 2, 3]):\nif (r == b'R'):\n- if len(msg) == struct.calcsize(Discoverer.HEARTBEAT_FMT):\n+ struct_size = struct.calcsize(Discoverer.HEARTBEAT_FMT)\n+ if len(msg) == struct_size:\nreturn (version, struct.unpack(Discoverer.HEARTBEAT_FMT, msg))\n+ else:\n+ raise Exception(\"wrong message size; expected %d, got %d from %s\" % (struct_size, len(msg), address))\nelse:\nraise Exception(\"wrong initial discovery message char %s received from %s\" % (r, address))\nelif (version > Discoverer.VERSION):\n",
        "org_msg": "fkie_master_discovery: added exception on wrong message size",
        "sim_msg": "encoding= argument is not supported on Python 2.x\nJust omit it on 2.x because it is not needed there anyway.",
        "sim_diff": "diff --git a/setup.py b/setup.py @@ -92,7 +92,9 @@ class sdist(versioneer_sdist):\ncmdclass['build_ext'] = build_ext\ncmdclass['sdist'] = sdist\n-with open('README.rst', encoding='utf-8') as f:\n+\n+encoding_arg = {'encoding': 'utf-8'} if sys.version > '3' else dict()\n+with open('README.rst', **encoding_arg) as f:\nlong_description = f.read()\nsetup(\n",
        "chatgpt_cot": "Fix compilation issue due to the wrong message size in the Discoverer file."
    },
    {
        "org_diff": "diff --git a/README.md b/README.md **Note:** This is a **read-only mirror** of the formal [Gerrit](https://gerrit.hyperledger.org/r/#/admin/projects/cello) repository. Find more details at [Cello Wiki](https://wiki.hyperledger.org/projects/cello).\n-![Cello](docs/images/logo.png)\n+![Cello](docs/images/favicon.png)\nHyperledger Cello is a blockchain provision and operation system, which helps manage blockchain networks in an efficient way.\n",
        "org_msg": "Fix the image file name",
        "sim_msg": "add integrity checks after s3 download as well",
        "sim_diff": "diff --git a/lbrynet/core/Wallet.py b/lbrynet/core/Wallet.py @@ -113,7 +113,8 @@ class Wallet(object):\nelse:\nwith open(os.path.join(self.config.path, \"blockchain_headers\"), \"wb\") as headers_file:\nyield treq.collect(response, headers_file.write)\n- log.info(\"fetched headers from s3 (s3 height: %i)\", s3_height)\n+ log.info(\"fetched headers from s3 (s3 height: %i), now verifying integrity after download.\", s3_height)\n+ self._check_header_file_integrity()\nelse:\nlog.warning(\"s3 is more out of date than we are\")\nelse:\n@@ -143,7 +144,7 @@ class Wallet(object):\nfrom lbrynet import conf\nif conf.settings['blockchain_name'] != \"lbrycrd_main\":\ndefer.returnValue(False)\n- self._check_header_file_integrity(conf)\n+ self._check_header_file_integrity()\ns3_headers_depth = conf.settings['s3_headers_depth']\nif not s3_headers_depth:\ndefer.returnValue(False)\n@@ -159,8 +160,11 @@ class Wallet(object):\nlog.warning(\"error requesting remote height from %s:%i - %s\", server_url, port, err)\ndefer.returnValue(False)\n- def _check_header_file_integrity(self, conf):\n+ def _check_header_file_integrity(self):\n# TODO: temporary workaround for usability. move to txlbryum and check headers instead of file integrity\n+ from lbrynet import conf\n+ if conf.settings['blockchain_name'] != \"lbrycrd_main\":\n+ return\nhashsum = sha256()\nchecksum_height, checksum = conf.settings['HEADERS_FILE_SHA256_CHECKSUM']\nchecksum_length_in_bytes = checksum_height * HEADER_SIZE\n",
        "chatgpt_cot": "\"Update README.md to change the logo image from logo.png to favicon.png for Hyperledger Cello project branding consistency.\""
    },
    {
        "org_diff": "diff --git a/sc2/units.py b/sc2/units.py import random\n-import sys\n-import traceback\nfrom itertools import chain\nfrom typing import Any, Dict, Iterable, List, Optional, Set, Tuple, Union\n-from .data import Alliance\nfrom .ids.unit_typeid import UnitTypeId\n-from .points import Points\nfrom .position import Point2, Point3\nfrom .unit import Unit, UnitGameData\n@@ -21,7 +17,6 @@ class Units(list):\ndef __init__(self, units): # , game_data=None):\nsuper().__init__(units)\n- self.unit_positions: Points = None\ndef __call__(self, *args, **kwargs):\nreturn UnitSelection(self, *args, **kwargs)\n",
        "org_msg": "Fix units.py",
        "sim_msg": "set team to red if joining a team-vs multi",
        "sim_diff": "diff --git a/objects/player.py b/objects/player.py @@ -17,7 +17,7 @@ from constants.gamemodes import GameMode\nfrom constants.mods import Mods\nfrom objects.channel import Channel\n-from objects.match import Match, SlotStatus\n+from objects.match import Match, SlotStatus, MatchTeamTypes, MatchTeams\nfrom objects.beatmap import Beatmap\nfrom objects import glob\n@@ -412,6 +412,11 @@ class Player:\nslot = m.slots[0 if slotID == -1 else slotID]\n+ # if in a teams-vs mode, switch team from neutral to red.\n+ if m.team_type in (MatchTeamTypes.team_vs,\n+ MatchTeamTypes.tag_team_vs):\n+ slot.team = MatchTeams.red\n+\nslot.status = SlotStatus.not_ready\nslot.player = self\nself.match = m\n",
        "chatgpt_cot": "Remove unnecessary imports and attributes, and refactor the Units class constructor in units.py."
    },
    {
        "org_diff": "diff --git a/fkie_master_discovery/src/fkie_master_discovery/interface_finder.py b/fkie_master_discovery/src/fkie_master_discovery/interface_finder.py @@ -124,21 +124,29 @@ def _get_topic(masteruri, ttype, wait=True, check_host=True):\n# read topic types\ncode, msg, val = master.getPublishedTopics(rospy.get_name(), '')\nif code == 1:\n+ own_host = get_hostname(masteruri)\n+ nodes_host = []\n# search for a topic with type MasterState\nfor topic, topic_type in val:\nif topic_type.endswith(ttype):\n# get the name of the publisher node\nfor t, l in state[0]:\nif topic == t:\n+ if check_host:\n# get the URI of the publisher node\nfor n in l:\ncode, msg, val = master.lookupNode(rospy.get_name(), n)\n# only local publisher will be tacked\nif code == 1:\n- if not check_host or get_hostname(val) == get_hostname(masteruri):\n+ hode_host = get_hostname(val)\n+ if hode_host == own_host:\n+ result.append(topic)\n+ else:\n+ nodes_host.append(hode_host)\n+ else:\nresult.append(topic)\nif not result and wait:\n- rospy.logwarn(\"Master_discovery node appear not to running. Wait for topic with type '%s.\" % ttype)\n+ rospy.logwarn(\"master_discovery node appear not to running @%s, only found on %s. Wait for topic with type '%s' @%s.\" % (own_host, nodes_host, ttype, own_host))\ntime.sleep(1)\nelif not result and wait:\nrospy.logwarn(\"Can't get published topics from ROS master: %s, %s. Will keep trying!\" % (code, msg))\n@@ -230,16 +238,24 @@ def _get_service(masteruri, name, wait=True, check_host=True):\ncode, msg, val = master.getSystemState(rospy.get_name())\nif code == 1:\npubs, subs, srvs = val\n+ own_host = get_hostname(masteruri)\n+ nodes_host = []\n# search for a service\nfor srv, providers in srvs:\nif srv.endswith(name):\n# only local service will be tacked\n+ if check_host:\ncode, msg, val = master.lookupService(rospy.get_name(), srv)\nif code == 1:\n- if not check_host or get_hostname(val) == get_hostname(masteruri):\n+ hode_host = get_hostname(val)\n+ if hode_host == own_host:\n+ result.append(srv)\n+ else:\n+ nodes_host.append(hode_host)\n+ else:\nresult.append(srv)\nif not result and wait:\n- rospy.logwarn(\"Master_discovery node appear not to running. Wait for service '%s'.\" % name)\n+ rospy.logwarn(\"master_discovery node appear not to running @%s, only found on %s. Wait for service '%s' @%s.\" % (own_host, nodes_host, name, own_host))\ntime.sleep(1)\nelif not result and wait:\nrospy.logwarn(\"can't get state from ROS master: %s, %s\" % (code, msg))\n",
        "org_msg": "master_discovery: added more output details to find problems on issue\nmore details for \"master_discovery node appear not to running\"",
        "sim_msg": "fixing node startup timing issue in consistency tests",
        "sim_diff": "diff --git a/tests/integration/long/utils.py b/tests/integration/long/utils.py @@ -21,7 +21,7 @@ from ccmlib.node import Node\nfrom cassandra.query import named_tuple_factory\n-from tests.integration import get_node, get_cluster\n+from tests.integration import get_node, get_cluster, wait_for_node_socket\nIP_FORMAT = '127.0.0.%s'\n@@ -132,6 +132,7 @@ def wait_for_up(cluster, node):\nwhile tries < 100:\nhost = cluster.metadata.get_host(addr)\nif host and host.is_up:\n+ wait_for_node_socket(get_node(node), 60)\nlog.debug(\"Done waiting for node %s to be up\", node)\nreturn\nelse:\n",
        "chatgpt_cot": "Add checking host for topic and service, and log warning if master_discovery node is not running."
    },
    {
        "org_diff": "diff --git a/fkie_node_manager/src/fkie_node_manager/parameter_list_model.py b/fkie_node_manager/src/fkie_node_manager/parameter_list_model.py # POSSIBILITY OF SUCH DAMAGE.\n-\nfrom python_qt_binding.QtCore import QSize, Qt\nfrom python_qt_binding.QtGui import QStandardItem, QStandardItemModel\ntry:\n@@ -61,7 +60,8 @@ class ParameterValueItem(QStandardItem):\n@param value: the value of the parameter\n@type value: C{str}\n'''\n- value_str = utf8(value) if not isinstance(value, xmlrpcclient.Binary) else utf8(value)\n+ value_str = utf8(value) if not isinstance(\n+ value, xmlrpcclient.Binary) else utf8(value)\nself.read_only = False\nif len(value_str) > 32000:\nvalue_str = 'value size > 32000; use Ctrl+X to copy'\n@@ -88,6 +88,7 @@ class ParameterValueItem(QStandardItem):\nself._value = value\nif isstring(value) and value.find('\\n') > -1:\nself.setSizeHint(QSize(-1, 45))\n+ self.setText(utf8(value))\ndef type(self):\nreturn ParameterValueItem.ITEM_TYPE\n@@ -214,7 +215,7 @@ class ParameterTypeItem(QStandardItem):\n@param value: the value of the parameter\n@type value: C{str}\n'''\n- QStandardItem.__init__(self, utf8(type(value)).replace(\"<type '\", '').replace(\"'>\", ''))\n+ QStandardItem.__init__(self, utf8(type(value).__name__))\nself._name = name\n'''@ivar: the name of parameter '''\nself._value = value\n@@ -282,7 +283,8 @@ class ParameterModel(QStandardItemModel):\n'''\nQStandardItemModel.__init__(self)\nself.setColumnCount(len(ParameterModel.header))\n- self.setHorizontalHeaderLabels([label for label, _ in ParameterModel.header])\n+ self.setHorizontalHeaderLabels(\n+ [label for label, _ in ParameterModel.header])\ndef flags(self, index):\n'''\n",
        "org_msg": "fkie_node_manager: fixed parameter type visualization and value update",
        "sim_msg": "deeper checking datatypes and subtypes",
        "sim_diff": "diff --git a/py34/bacpypes/object.py b/py34/bacpypes/object.py @@ -201,14 +201,61 @@ class Property:\nif not self.mutable:\nraise ExecutionError(errorClass='property', errorCode='writeAccessDenied')\n+ # if changing the length of the array, the value is unsigned\n+ if arrayIndex == 0:\n+ if not Unsigned.is_valid(value):\n+ raise InvalidParameterDatatype(\"length of %s must be unsigned\" % (\n+ self.identifier,\n+ ))\n+\n# if it's atomic, make sure it's valid\n- if issubclass(self.datatype, Atomic):\n+ elif issubclass(self.datatype, Atomic):\nif _debug: Property._debug(\" - property is atomic, checking value\")\nif not self.datatype.is_valid(value):\nraise InvalidParameterDatatype(\"%s must be of type %s\" % (\nself.identifier, self.datatype.__name__,\n))\n+ # if it's an array, make sure it's valid regarding arrayIndex provided\n+ elif issubclass(self.datatype, Array):\n+ if _debug: Property._debug(\" - property is array, checking subtype and index\")\n+\n+ # changing a single element\n+ if arrayIndex is not None:\n+ # if it's atomic, make sure it's valid\n+ if issubclass(self.datatype.subtype, Atomic):\n+ if _debug: Property._debug(\" - subtype is atomic, checking value\")\n+ if not self.datatype.subtype.is_valid(value):\n+ raise InvalidParameterDatatype(\"%s must be of type %s\" % (\n+ self.identifier, self.datatype.__name__,\n+ ))\n+ # constructed type\n+ elif not isinstance(value, self.datatype.subtype):\n+ raise InvalidParameterDatatype(\"%s must be of type %s\" % (\n+ self.identifier, self.datatype.subtype.__name__\n+ ))\n+\n+ # replacing the array\n+ elif isinstance(value, list):\n+ # check validity regarding subtype\n+ for item in value:\n+ # if it's atomic, make sure it's valid\n+ if issubclass(self.datatype.subtype, Atomic):\n+ if _debug: Property._debug(\" - subtype is atomic, checking value\")\n+ if not self.datatype.subtype.is_valid(item):\n+ raise InvalidParameterDatatype(\"elements of %s must be of type %s\" % (\n+ self.identifier, self.datatype.subtype.__name__,\n+ ))\n+ # constructed type\n+ elif not isinstance(item, self.datatype.subtype):\n+ raise InvalidParameterDatatype(\"elements of %s must be of type %s\" % (\n+ self.identifier, self.datatype.subtype.__name__\n+ ))\n+\n+ # value is mutated into a new array\n+ value = self.datatype(value)\n+\n+ # some kind of constructed data\nelif not isinstance(value, self.datatype):\nif _debug: Property._debug(\" - property is not atomic and wrong type\")\nraise InvalidParameterDatatype(\"%s must be of type %s\" % (\n",
        "chatgpt_cot": "\"Fix indentation and add utf8 conversion for parameter values in Parameter List Model\""
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/editor/editor.py b/node_manager_fkie/src/node_manager_fkie/editor/editor.py @@ -583,6 +583,9 @@ class Editor(QMainWindow):\ncursor.setPosition(index, QTextCursor.MoveAnchor)\ncursor.movePosition(QTextCursor.NextCharacter, QTextCursor.KeepAnchor, len(search_text))\nself.tabWidget.currentWidget().setTextCursor(cursor)\n+ cursor_y = self.tabWidget.currentWidget().cursorRect().top()\n+ vbar = self.tabWidget.currentWidget().verticalScrollBar()\n+ vbar.setValue(vbar.value() + cursor_y * 0.8)\ndef on_search_result_on_open(self, search_text, found, path, index):\n'''\n",
        "org_msg": "node_manager_fkie: move selected text to top",
        "sim_msg": "Make search work in tree view\nNow it's iterating when activated (enter).",
        "sim_diff": "diff --git a/gaphor/ui/treecomponent.py b/gaphor/ui/treecomponent.py from __future__ import annotations\n-from functools import partial\n-\nfrom gi.repository import Gdk, GLib, GObject, Gtk\nfrom gaphor import UML\n@@ -33,6 +31,7 @@ from gaphor.ui.treemodel import (\ntree_item_sort,\nvisible,\n)\n+from gaphor.ui.treesearch import search\nSTART_EDIT_DELAY = 100 # ms\n@@ -43,6 +42,7 @@ class TreeComponent(UIComponent, ActionProvider):\nself.element_factory = element_factory\nself.modeling_language = modeling_language\nself.model = TreeModel()\n+ self.search = None\ndef open(self):\nself.event_manager.subscribe(self.on_element_created)\n@@ -66,7 +66,19 @@ class TreeComponent(UIComponent, ActionProvider):\nsort_model = Gtk.SortListModel.new(tree_model, tree_sorter)\nself.selection = Gtk.SingleSelection.new(sort_model)\n- self.search_bar = create_search_bar(partial(search_next, self.selection))\n+ def search_next(search_text):\n+ try:\n+ if not self.search:\n+ self.search = search(self.model, search_text)\n+ next_item = next(self.search)\n+ else:\n+ next_item = self.search.send(search_text)\n+ if next_item:\n+ self.select_element(next_item.element)\n+ except StopIteration:\n+ self.search = None\n+\n+ self.search_bar = create_search_bar(search_next)\nfactory = Gtk.SignalListItemFactory.new()\nfactory.connect(\n@@ -258,34 +270,25 @@ def create_search_bar(search_next, text_changed=None):\ndef on_search_changed(entry):\nnonlocal search_text\n+ new_text = entry.get_text()\nfilter_change = (\nGtk.FilterChange.MORE_STRICT\n- if search_text in entry.get_text()\n+ if search_text in new_text\nelse Gtk.FilterChange.LESS_STRICT\n- if entry.get_text() in search_text\n+ if new_text in search_text\nelse Gtk.FilterChange.DIFFERENT\n)\n- search_text = entry.get_text()\n- search_filter.changed(filter_change)\n+ search_text = new_text\n+ if text_changed:\n+ text_changed(search_text, filter_change)\ndef on_stop_search(_entry):\nnonlocal search_text\nsearch_text = \"\"\n- search_filter.changed(Gtk.FilterChange.LESS_STRICT)\n-\n- def on_filter_changed(_filter, change):\n- if text_changed:\n- text_changed(search_text, change)\ndef on_search_next(_entry):\nsearch_next(search_text)\n- def name_filter(item):\n- item = item.get_item()\n- return isinstance(item, TreeItem) and search_text.lower() in item.text.lower()\n-\n- search_filter = Gtk.CustomFilter.new(name_filter)\n- search_filter.connect(\"changed\", on_filter_changed)\nsearch_entry = Gtk.SearchEntry.new()\nsearch_entry.connect(\"search-changed\", on_search_changed)\nsearch_entry.connect(\"stop-search\", on_stop_search)\n@@ -298,10 +301,6 @@ def create_search_bar(search_next, text_changed=None):\nreturn search_bar\n-def search_next(selection, search_text):\n- print(\"search\", search_text)\n-\n-\ndef list_item_factory_setup(_factory, list_item, event_manager, modeling_language):\nbuilder = Gtk.Builder()\nbuilder.set_current_object(list_item)\n",
        "chatgpt_cot": "\"Add functionality to automatically scroll to the cursor position in the text editor window when opening search results.\""
    },
    {
        "org_diff": "diff --git a/fkie_node_manager/src/fkie_node_manager/editor/editor.py b/fkie_node_manager/src/fkie_node_manager/editor/editor.py @@ -764,7 +764,8 @@ class Editor(QMainWindow):\n##############################################################################\ndef _show_custom_parameter_dialog(self):\n- methods = {'capability_group': self._on_add_cp_capability_group,\n+ methods = {'associations': self._on_add_cp_associations,\n+ 'capability_group': self._on_add_cp_capability_group,\n'kill_on_stop': self._on_add_cp_kill_on_stop,\n'autostart/delay': self._on_add_cp_as_delay,\n'autostart/exclude': self._on_add_cp_as_exclude,\n@@ -780,7 +781,6 @@ class Editor(QMainWindow):\nstore_geometry='insert_param')\ntags2insert = res[0]\nfor tag in tags2insert:\n- print(\"Insert\", tag)\nmethods[tag]()\ndef _create_tag_button(self, parent=None):\n@@ -853,6 +853,10 @@ class Editor(QMainWindow):\nshow_cp_dialog_action.setShortcuts(QKeySequence(\"Ctrl+Shift+d\"))\nsub_cp_menu.addAction(show_cp_dialog_action)\n+ add_cp_associations_action = QAction(\"associations\", self, statusTip=\"\", triggered=self._on_add_cp_associations)\n+ add_cp_associations_action.setShortcuts(QKeySequence(\"Ctrl+Alt+a\"))\n+ sub_cp_menu.addAction(add_cp_associations_action)\n+\nsub_cp_as_menu = QMenu(\"Autostart\", parent)\nadd_cp_as_delay_action = QAction(\"delay\", self, statusTip=\"\", triggered=self._on_add_cp_as_delay)\nsub_cp_as_menu.addAction(add_cp_as_delay_action)\n@@ -990,6 +994,9 @@ class Editor(QMainWindow):\ndef _on_add_cp_kill_on_stop(self):\nself._insert_text('<param name=\"kill_on_stop\" value=\"100\" hint=\"[ms]\" />', 34, 3)\n+ def _on_add_cp_associations(self):\n+ self._insert_text('<param name=\"associations\" value=\"node1,node2\" hint=\"list of nodes\" />', 34, 11)\n+\ndef _on_add_cp_as_delay(self):\nself._insert_text('<param name=\"autostart/delay\" value=\"1\" hint=\"[seconds]\" />', 37, 1)\n",
        "org_msg": "fkie_node_manager: added associations to custom dialog in editor",
        "sim_msg": "updated tag edits",
        "sim_diff": "diff --git a/modules/plex.py b/modules/plex.py @@ -698,29 +698,24 @@ class Plex:\nupdated = False\nkey = builder.filter_translation[attr] if attr in builder.filter_translation else attr\nif add_tags or remove_tags or sync_tags:\n- _add_tags = [f\"{t[:1].upper()}{t[1:]}\" for t in add_tags] if add_tags else None\n- _remove_tags = [f\"{t[:1].upper()}{t[1:]}\" for t in remove_tags] if remove_tags else None\n- _sync_tags = [t.lower() for t in sync_tags] if sync_tags else None\n- item_tags = [item_tag.tag for item_tag in getattr(obj, key)]\n- input_tags = []\n- if _add_tags:\n- input_tags.extend(_add_tags)\n- if _sync_tags:\n- input_tags.extend(_sync_tags)\n- if _sync_tags or _remove_tags:\n- remove_method = getattr(obj, f\"remove{attr.capitalize()}\")\n- for tag in item_tags:\n- if (_sync_tags and tag.lower() not in _sync_tags) or (_remove_tags and tag in _remove_tags):\n+ _add_tags = add_tags if add_tags else []\n+ _remove = [t.lower() for t in remove_tags] if remove_tags else []\n+ _sync_tags = sync_tags if sync_tags else []\n+ _sync = [t.lower() for t in _sync_tags]\n+ item_tags = [item_tag.tag.lower() for item_tag in getattr(obj, key)]\n+ _add = _add_tags + _sync_tags\n+ if _add:\n+ add = [f\"{t[:1].upper()}{t[1:]}\" for t in _add if t.lower() not in item_tags]\n+ if add:\nupdated = True\n- self.query_data(remove_method, tag)\n- logger.info(f\"Detail: {attr.capitalize()} {tag} removed\")\n- if input_tags:\n- add_method = getattr(obj, f\"add{attr.capitalize()}\")\n- for tag in input_tags:\n- if tag not in item_tags:\n+ self.query_data(getattr(obj, f\"add{attr.capitalize()}\"), add)\n+ logger.info(f\"Detail: {attr.capitalize()} {add} added\")\n+ if _remove or _sync:\n+ remove = [t for t in item_tags if t not in _sync or t in _remove]\n+ if remove:\nupdated = True\n- self.query_data(add_method, tag)\n- logger.info(f\"Detail: {attr.capitalize()} {tag} added\")\n+ self.query_data(getattr(obj, f\"remove{attr.capitalize()}\"), remove)\n+ logger.info(f\"Detail: {attr.capitalize()} {remove} removed\")\nreturn updated\ndef update_item_from_assets(self, item):\n",
        "chatgpt_cot": "Add method to Editor class to handle custom parameter associations, and add action to trigger the method in the GUI."
    },
    {
        "org_diff": "diff --git a/fkie_node_manager/src/fkie_node_manager/node_tree_model.py b/fkie_node_manager/src/fkie_node_manager/node_tree_model.py @@ -1286,6 +1286,9 @@ class NodeItem(QStandardItem):\nif self._node_info.uri != node_info.uri:\nself._node_info.uri = node_info.uri\nrun_changed = True\n+ # delete diagnostics messages on stop or start nodes\n+ if run_changed:\n+ del self.diagnostic_array[:]\n# update the tooltip and icon\nif run_changed and (self.is_running() or self.has_configs) or abbos_changed:\nself.has_screen = True\n",
        "org_msg": "fkie_node_manager: delete diagnostic message of a node on stop/start",
        "sim_msg": "windows: improve visibility of selected tree item when tree does not have the focus",
        "sim_diff": "diff --git a/tree.py b/tree.py @@ -745,9 +745,21 @@ class WidgetTree(wx.TreeCtrl, Tree):\nself.skip_select = True\nself.SelectItem(node.item)\nself.skip_select = False\n- self.cur_widget = node.widget\n+ self._set_cur_widget(node.widget)\nmisc.set_focused_widget(self.cur_widget)\n+ def _set_cur_widget(self, widget):\n+ # set self.cur_widget; adjust label colors and bold if required (on Windows)\n+ if self.cur_widget and wx.Platform == \"__WXMSW__\":\n+ item = self.cur_widget.node.item\n+ self.SetItemTextColour(item, wx.NullColour)\n+ self.SetItemBold( item, False )\n+ self.cur_widget = widget\n+ if wx.Platform == \"__WXMSW__\":\n+ item = widget.node.item\n+ self.SetItemBold(item, True)\n+ self.SetItemTextColour(item, wx.BLUE)\n+\ndef set_current_widget(self, widget):\n# interface from common.set_focused_widget\nif widget is None or widget is self.cur_widget: return\n@@ -758,13 +770,13 @@ class WidgetTree(wx.TreeCtrl, Tree):\nself.skip_select = True\nself.SelectItem(node.item)\nself.skip_select = False\n- self.cur_widget = widget\n+ self._set_cur_widget(widget)\ndef on_change_selection(self, event):\nif self.skip_select: return # triggered by self.SelectItem in self.set_current_widget\nitem = event.GetItem()\nwidget = self._GetItemData(item).widget\n- self.cur_widget = widget\n+ self._set_cur_widget(widget)\nmisc.set_focused_widget(widget)\nif not self.IsExpanded(item):\nself.Expand(item)\n@@ -1075,7 +1087,7 @@ class WidgetTree(wx.TreeCtrl, Tree):\nitemok = item\nif parent is None:\nparent = self._GetItemData(itemok)\n- self.cur_widget = widget\n+ self._set_cur_widget(widget)\nitem, cookie = self._get_first_child(item)\nindex += 1\nelse:\n",
        "chatgpt_cot": "\"Add functionality to delete diagnostic messages on stop or start nodes in NodeItem class in node_tree_model.py\""
    },
    {
        "org_diff": "diff --git a/.github/workflows/docker-ci.yml b/.github/workflows/docker-ci.yml @@ -48,7 +48,7 @@ jobs:\n- name: Build docker image\nrun: |\n- docker build -t burnysc2/python-sc2-docker:py_${{ matrix.python-version }}-sc2_${{ matrix.sc2-version }}-v${{ env.VERSION_NUMBER }} --build-arg PYTHON_VERSION=${{ matrix.python-version }} --build-arg SC2_VERSION=${{ matrix.sc2-version }} .\n+ docker build -f dockerfiles/Dockerfile -t burnysc2/python-sc2-docker:py_${{ matrix.python-version }}-sc2_${{ matrix.sc2-version }}-v${{ env.VERSION_NUMBER }} --build-arg PYTHON_VERSION=${{ matrix.python-version }} --build-arg SC2_VERSION=${{ matrix.sc2-version }} .\n- name: Run test bots\nif: matrix.python-version != '3.7'\n",
        "org_msg": "Fix docker build command",
        "sim_msg": "Do not attempt to build source tarball.",
        "sim_diff": "diff --git a/.github/workflows/build-docker-image.yml b/.github/workflows/build-docker-image.yml @@ -17,10 +17,10 @@ jobs:\nuses: actions/setup-python@v1\nwith:\npython-version: 3.7\n- - name: Install build environment\n- run: python -m pip install build --user\n- - name: Build source tarball\n- run: python -m build --sdist --outdir dist/ .\n+ #- name: Install build environment\n+ # run: python -m pip install build --user\n+ # - name: Build source tarball\n+ # run: python -m build --sdist --outdir dist/ .\n# TODO(rousik): inject tarball into the docker image\n- name: Docker Meta\nid: docker_meta\n",
        "chatgpt_cot": "\"Refactor docker-ci.yml to use separate Dockerfile, improving organization and maintainability of the Docker image build process.\""
    },
    {
        "org_diff": "diff --git a/fkie_node_manager/src/fkie_node_manager/parameter_dialog.py b/fkie_node_manager/src/fkie_node_manager/parameter_dialog.py @@ -808,11 +808,14 @@ class ArrayBox(MainBox):\nremButton.clicked.connect(self._on_rem_dynamic_entry)\nself.options_layout.addWidget(remButton)\n- def _on_add_dynamic_entry(self):\n+ def _on_add_dynamic_entry(self, checked=False, value=None):\nself.setUpdatesEnabled(False)\ntry:\n- if self._dynamic_value is not None:\n- self._create_dynamic_frame(self._dynamic_value)\n+ val = value\n+ if val is None:\n+ val = self._dynamic_value\n+ if val is not None:\n+ self._create_dynamic_frame(val)\nfinally:\nself.setUpdatesEnabled(True)\n@@ -850,10 +853,16 @@ class ArrayBox(MainBox):\ntry:\nif self._is_dynamic:\nself.addDynamicBox()\n+ # Set value used to add dynamic array fields.\n+ # On republish there is an array filled array. So only last enry will be used on add new entry.\n+ if isinstance(value, list):\n+ if value:\n+ self._dynamic_value = value[-1]\n+ else:\nself._dynamic_value = value\nself.set_values(value)\nexcept Exception:\n- print(traceback.format_exc(1))\n+ print(traceback.format_exc())\nfinally:\nself.setUpdatesEnabled(True)\n@@ -894,7 +903,8 @@ class ArrayBox(MainBox):\n# create the list of the elements of the length of values\nif count_entries < len(values):\nfor i in range(len(values) - count_entries):\n- self._on_add_dynamic_entry()\n+ # use array entry\n+ self._on_add_dynamic_entry(value=values[i])\nelif count_entries > len(values):\nfor i in range(count_entries - len(values)):\nself._on_rem_dynamic_entry()\n",
        "org_msg": "fkie_node_manager: fix republish messages with array of included messages",
        "sim_msg": "deeper checking datatypes and subtypes",
        "sim_diff": "diff --git a/py34/bacpypes/object.py b/py34/bacpypes/object.py @@ -201,14 +201,61 @@ class Property:\nif not self.mutable:\nraise ExecutionError(errorClass='property', errorCode='writeAccessDenied')\n+ # if changing the length of the array, the value is unsigned\n+ if arrayIndex == 0:\n+ if not Unsigned.is_valid(value):\n+ raise InvalidParameterDatatype(\"length of %s must be unsigned\" % (\n+ self.identifier,\n+ ))\n+\n# if it's atomic, make sure it's valid\n- if issubclass(self.datatype, Atomic):\n+ elif issubclass(self.datatype, Atomic):\nif _debug: Property._debug(\" - property is atomic, checking value\")\nif not self.datatype.is_valid(value):\nraise InvalidParameterDatatype(\"%s must be of type %s\" % (\nself.identifier, self.datatype.__name__,\n))\n+ # if it's an array, make sure it's valid regarding arrayIndex provided\n+ elif issubclass(self.datatype, Array):\n+ if _debug: Property._debug(\" - property is array, checking subtype and index\")\n+\n+ # changing a single element\n+ if arrayIndex is not None:\n+ # if it's atomic, make sure it's valid\n+ if issubclass(self.datatype.subtype, Atomic):\n+ if _debug: Property._debug(\" - subtype is atomic, checking value\")\n+ if not self.datatype.subtype.is_valid(value):\n+ raise InvalidParameterDatatype(\"%s must be of type %s\" % (\n+ self.identifier, self.datatype.__name__,\n+ ))\n+ # constructed type\n+ elif not isinstance(value, self.datatype.subtype):\n+ raise InvalidParameterDatatype(\"%s must be of type %s\" % (\n+ self.identifier, self.datatype.subtype.__name__\n+ ))\n+\n+ # replacing the array\n+ elif isinstance(value, list):\n+ # check validity regarding subtype\n+ for item in value:\n+ # if it's atomic, make sure it's valid\n+ if issubclass(self.datatype.subtype, Atomic):\n+ if _debug: Property._debug(\" - subtype is atomic, checking value\")\n+ if not self.datatype.subtype.is_valid(item):\n+ raise InvalidParameterDatatype(\"elements of %s must be of type %s\" % (\n+ self.identifier, self.datatype.subtype.__name__,\n+ ))\n+ # constructed type\n+ elif not isinstance(item, self.datatype.subtype):\n+ raise InvalidParameterDatatype(\"elements of %s must be of type %s\" % (\n+ self.identifier, self.datatype.subtype.__name__\n+ ))\n+\n+ # value is mutated into a new array\n+ value = self.datatype(value)\n+\n+ # some kind of constructed data\nelif not isinstance(value, self.datatype):\nif _debug: Property._debug(\" - property is not atomic and wrong type\")\nraise InvalidParameterDatatype(\"%s must be of type %s\" % (\n",
        "chatgpt_cot": "Refactor ArrayBox class in parameter_dialog.py to handle dynamic entries efficiently. Fix dynamic entry creation and removal logic for better functionality."
    },
    {
        "org_diff": "diff --git a/Makefile b/Makefile @@ -208,7 +208,7 @@ logs: ##@Log tail for all service log\nimage-clean: clean ##@Clean all existing images to rebuild\necho \"Clean all cello related images, may need to remove all containers before\"\n- docker images | grep \"hyperledger/cello-\" | awk '{print $3}' | xargs docker rmi -f\n+ docker images | grep \"cello-\" | awk '{print $3}' | xargs docker rmi -f\nstart-docker-compose:\ndocker-compose -f bootup/docker-compose-files/${COMPOSE_FILE} up -d --force-recreate --remove-orphans\n@@ -223,12 +223,17 @@ start: ##@Service Start service\nstop-docker-compose:\necho \"Stop all services with bootup/docker-compose-files/${COMPOSE_FILE}...\"\ndocker-compose -f bootup/docker-compose-files/${COMPOSE_FILE} stop\n+ echo \"Stop all services successfully\"\nremove-docker-compose:\n- echo \"Remove all services with ${COMPOSE_FILE}...\"\n- docker-compose -f bootup/docker-compose-files/${COMPOSE_FILE} down -v\n- rm -rf /opt/cello\n+ make stop-docker-compose\n+ echo \"Remove all services with bootup/docker-compose-files/${COMPOSE_FILE}...\"\n+ if docker ps -a | grep \"cello-\"; then \\\n+ docker ps -a | grep \"cello-\" | awk '{print $1}' | xargs docker rm -f >/dev/null 2>&1; \\\n+ rm -rf /opt/cello; \\\n+ fi\n+ echo \"Remove all services successfully\"\nstart-k8s:\n@$(MAKE) -C bootup/kubernetes init-yaml\n@@ -300,11 +305,12 @@ HELP_FUN = \\\napi-engine: # for debug only now\ndocker build -t hyperledger/cello-api-engine:latest -f build_image/docker/common/api-engine/Dockerfile.in ./\n-dashboard:\n+dashboard: # for debug only now\ndocker build -t hyperledger/cello-dashboard:latest -f build_image/docker/common/dashboard/Dockerfile.in ./\ndocker-rest-agent: # for debug only now\ndocker build -t hyperledger/cello-agent-docker:latest -f build_image/docker/agent/docker-rest-agent/Dockerfile.in ./ --build-arg pip=$(PIP)\n+\nstart-dashboard:\nmake -C src/dashboard start;\n@@ -313,6 +319,7 @@ start-dashboard:\ncheck \\\nclean \\\ndeep-clean \\\n+ dev-build \\\nchangelog \\\ndoc \\\ndocker \\\n",
        "org_msg": "Update makefile commands",
        "sim_msg": "use sudo to install docker-switch",
        "sim_diff": "diff --git a/home.admin/config.scripts/blitz.docker.sh b/home.admin/config.scripts/blitz.docker.sh @@ -86,13 +86,13 @@ if [ \"$1\" = \"1\" ] || [ \"$1\" = \"on\" ]; then\necho \"Docker Compose V2 is not installed\"\nexit 1\nfi\n- curl -fL $COMPOSE_SWITCH_URL -o /usr/local/bin/compose-switch\n- chmod +x /usr/local/bin/compose-switch\n+ sudo curl -fL $COMPOSE_SWITCH_URL -o /usr/local/bin/compose-switch\n+ sudo chmod +x /usr/local/bin/compose-switch\nCOMPOSE=$(command -v docker-compose)\nif [ \"$COMPOSE\" = /usr/local/bin/docker-compose ]; then\n# This is a manual installation of docker-compose\n# so, safe for us to rename binary\n- mv /usr/local/bin/docker-compose /usr/local/bin/docker-compose-v1\n+ sudo mv /usr/local/bin/docker-compose /usr/local/bin/docker-compose-v1\nCOMPOSE=/usr/local/bin/docker-compose-v1\nfi\nALTERNATIVES=\"update-alternatives\"\n@@ -101,9 +101,9 @@ if [ \"$1\" = \"1\" ] || [ \"$1\" = \"on\" ]; then\nfi\necho \"Configuring docker-compose alternatives\"\nif [ -n \"$COMPOSE\" ]; then\n- $ALTERNATIVES --install /usr/local/bin/docker-compose docker-compose $COMPOSE 1\n+ sudo $ALTERNATIVES --install /usr/local/bin/docker-compose docker-compose $COMPOSE 1\nfi\n- $ALTERNATIVES --install /usr/local/bin/docker-compose docker-compose /usr/local/bin/compose-switch 99\n+ sudo $ALTERNATIVES --install /usr/local/bin/docker-compose docker-compose /usr/local/bin/compose-switch 99\necho \"'docker-compose' is now set to run Compose V2\"\necho \"use '$ALTERNATIVES --config docker-compose' if you want to switch back to Compose V1\"\n@@ -113,11 +113,15 @@ if [ \"$1\" = \"1\" ] || [ \"$1\" = \"on\" ]; then\nsudo systemctl stop docker.socket\n# keep the docker dir on the OS drive if the disk is ZFS - needs special config\n- # https://docs.docker.com/storage/storagedriver/zfs-driver/#configure-docker-with-the-zfs-storage-driver\nisZFS=$(zfs list 2>/dev/null | grep -c \"/mnt/hdd\")\nif [ \"${isZFS}\" -eq 0 ]; then\n- sudo mv /var/lib/docker /mnt/hdd/\n- sudo ln -s /var/lib/docker /mnt/hdd/docker\n+ sudo mv -f /var/lib/docker /mnt/hdd/\n+ sudo ln -s /mnt/hdd/docker /var/lib/docker\n+ # move to a different partition or configure docker with ZFS\n+ # https://docs.docker.com/storage/storagedriver/zfs-driver/#configure-docker-with-the-zfs-storage-driver\n+ #else\n+ # sudo mv -f /var/lib/docker /home/admin/\n+ # sudo ln -s /home/admin/docker /var/lib/docker\nfi\nsudo systemctl start docker\nsudo systemctl start docker.socket\n",
        "chatgpt_cot": "Refactor Makefile for image cleanup and service removal. Improve Docker image handling and service cleanup process for better maintenance."
    },
    {
        "org_diff": "diff --git a/sc2/renderer.py b/sc2/renderer.py import datetime\n-from pyglet.text import Label\n-from pyglet.window import Window\nfrom s2clientprotocol import score_pb2 as score_pb\nfrom sc2.position import Point2\n@@ -25,9 +23,6 @@ class Renderer:\nself._text_time = None\nasync def render(self, observation):\n- # pylint: disable=C0415\n- from pyglet.image import ImageData\n-\nrender_data = observation.observation.render_data\nmap_size = render_data.map.size\n@@ -42,6 +37,11 @@ class Renderer:\nminimap_pitch = -minimap_width * 3\nif not self._window:\n+ # pylint: disable=C0415\n+ from pyglet.image import ImageData\n+ from pyglet.text import Label\n+ from pyglet.window import Window\n+\nself._window = Window(width=map_width, height=map_height)\nself._window.on_mouse_press = self._on_mouse_press\nself._window.on_mouse_release = self._on_mouse_release\n",
        "org_msg": "Move more pyglet imports in renderer.py",
        "sim_msg": "add test cleaning",
        "sim_diff": "diff --git a/test/test_render.py b/test/test_render.py @@ -31,6 +31,25 @@ def test_render_rendering():\nassert (np.allclose(np.mean(rgb, axis=(0, 1)), np.array([0.51661223, 0.5035339, 0.4777793, 1.]), rtol=1e-3))\nrenderer.release()\n+def test_render_rendering_cleaning():\n+ renderer = MeshRenderer(width=800, height=600)\n+ renderer.load_object(os.path.join(dir, 'mesh/bed1a77d92d64f5cbbaaae4feed64ec1_new.obj'))\n+ renderer.add_instance(0)\n+ renderer.set_camera([0, 0, 1.2], [0, 1, 1.2], [0, 1, 0])\n+ renderer.set_fov(90)\n+ rgb, _, seg, _ = renderer.render()\n+ plt.imshow(np.concatenate([rgb, seg], axis=1)) # uncomment these two lines to show the rendering results\n+ plt.show()\n+ #assert (np.allclose(np.mean(rgb, axis=(0, 1)), np.array([0.51661223, 0.5035339, 0.4777793, 1.]), rtol=1e-3))\n+\n+ renderer.clean()\n+ rgb, _, seg, _ = renderer.render()\n+ plt.imshow(np.concatenate([rgb, seg], axis=1)) # uncomment these two lines to show the rendering results\n+ plt.show()\n+\n+ renderer.release()\n+#test_render_rendering_cleaning()\n+\n'''\ndef test_tensor_render_rendering():\nw = 800\n",
        "chatgpt_cot": "Add necessary imports for window rendering in Renderer class. Fix compilation issue related to missing imports in the Renderer class."
    },
    {
        "org_diff": "diff --git a/sc2/bot_ai.py b/sc2/bot_ai.py @@ -148,7 +148,7 @@ class BotAI:\n# any resource in a group is closer than 6 to any resource of another group\n# Distance we group resources by\n- RESOURCE_SPREAD_THRESHOLD = 6\n+ RESOURCE_SPREAD_THRESHOLD = 8.5\nminerals = self.state.mineral_field\ngeysers = self.state.vespene_geyser\nall_resources = minerals | geysers\n",
        "org_msg": "Increase resource threshold for automaton middle bases",
        "sim_msg": "[ServerStats] This time I introduced another UnboundLocalError whoops",
        "sim_diff": "diff --git a/serverstats/serverstats.py b/serverstats/serverstats.py @@ -1014,8 +1014,8 @@ class ServerStats(commands.Cog):\nif m := guild.get_member(member.id) and guild.get_member(ctx.author.id):\nguild_list.append(m)\nembed_list = []\n- if guild_list != []:\nrobot = \"\\N{ROBOT FACE}\" if member.bot else \"\"\n+ if guild_list != []:\nmsg = f\"**{member}** ({member.id}) {robot}\" + _(\"is on:\\n\\n\")\nembed_msg = \"\"\nfor m in guild_list:\n",
        "chatgpt_cot": "Increase RESOURCE_SPREAD_THRESHOLD from 6 to 8.5 to ensure resources in a group are not closer than 8.5 units to resources of another group."
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/node_tree_model.py b/node_manager_fkie/src/node_manager_fkie/node_tree_model.py @@ -546,7 +546,7 @@ class GroupItem(QStandardItem):\ndef _remove_group(self, name):\nfor i in reversed(range(self.rowCount())):\nitem = self.child(i)\n- if type(item) == GroupItem and item.rowCount() == 0:\n+ if type(item) == GroupItem and item == name and item.rowCount() == 0:\nself.removeRow(i)\ndef reset_remote_launched_nodes(self):\n",
        "org_msg": "node_manager_fkie: fix crash on clearup",
        "sim_msg": "Avoid Namespace error when shutting down",
        "sim_diff": "diff --git a/gaphor/ui/namespace.py b/gaphor/ui/namespace.py @@ -267,7 +267,7 @@ class NamespaceModel(Gtk.GenericTreeModel):\nself._remove_element(element)\nparent_node = self._nodes.get(element.namespace)\n- if element in parent_node:\n+ if parent_node and element in parent_node:\nparent_node.remove(element)\n# if path and parent_node and len(self._nodes[parent_node]) == 0:\n",
        "chatgpt_cot": "Fix issue with removing group item by name in Node Tree Model. Added condition to check item name before removing."
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/__init__.py b/node_manager_fkie/src/node_manager_fkie/__init__.py @@ -104,12 +104,15 @@ def detect_version():\nprint >> sys.stderr, \"version detection: no version tag in package.xml found!\"\nelse:\nprint >> sys.stderr, \"version detection: package.xml not found!\"\n+ try:\nif os.path.isdir(\"%s/../.git\" % settings().PACKAGE_DIR):\nos.chdir(settings().PACKAGE_DIR)\nps = SupervisedPopen(['git', 'describe', '--tags', '--dirty', '--always'], stdout=subprocess.PIPE)\noutput = ps.stdout.read()\n__version__ = output.strip()\n- except roslib.packages.ROSPkgException as err:\n+ except Exception:\n+ pass\n+ except Exception as err:\nprint >> sys.stderr, \"version detection: %s\" % err\n",
        "org_msg": "node_manager_fkie: error handling while version detection",
        "sim_msg": "Adding readme as long_description in setup.py",
        "sim_diff": "diff --git a/setup.py b/setup.py @@ -13,10 +13,15 @@ def find_version(version_file):\nreturn match_object.group(1)\n+with open('README.rst') as readme_file:\n+ readme = readme_file.read()\n+\n+\nsetup(\nname='brew-view',\nversion=find_version('brew_view/_version.py'),\ndescription='Beergarden Frontend',\n+ long_description=readme,\nurl=' ',\nauthor='The beer-garden Team',\nauthor_email=' ',\n",
        "chatgpt_cot": "fix version detection issue due to exception handling in __init__.py file."
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/echo_dialog.py b/node_manager_fkie/src/node_manager_fkie/echo_dialog.py @@ -354,7 +354,8 @@ class EchoDialog(QDialog):\nself._count_messages(current_time)\n# skip messages, if they are received often then MESSAGE_HZ_LIMIT\nif self._last_received_ts != 0 and self.receiving_hz != 0:\n- if (latched and current_time - self._start_time > 3.0) and current_time - self._last_received_ts < 1.0 / self.receiving_hz:\n+ if current_time - self._last_received_ts < 1.0 / self.receiving_hz:\n+ if (not latched or (latched and current_time - self._start_time > 3.0)):\nself._scrapped_msgs += 1\nself._scrapped_msgs_sl += 1\nreturn\n",
        "org_msg": "node_manager_fkie: fixed rate filter in echo dialog",
        "sim_msg": "correct timing tracking",
        "sim_diff": "diff --git a/GearBot/Bot/TheRealGearBot.py b/GearBot/Bot/TheRealGearBot.py @@ -160,7 +160,7 @@ async def on_message(bot, message:Message):\nf = time.perf_counter_ns if hasattr(time, \"perf_counter_ns\") else time.perf_counter\nstart = f()\nawait bot.invoke(ctx)\n- bot.metrics.bot_command_timing.labels(command_name=ctx.invoked_with).observe((f() - start) / 1000000)\n+ bot.metrics.bot_command_timing.labels(command_name=ctx.command.qualified_name).observe((f() - start) / 1000000)\nasync def on_guild_join(guild):\n",
        "chatgpt_cot": "\"Refactor message skipping logic in EchoDialog file to improve message handling and account for latched messages and message receiving frequency.\""
    },
    {
        "org_diff": "diff --git a/README.md b/README.md @@ -129,4 +129,22 @@ Can you find anyone better at playing chains? :)\n## Incubation Notice\nThis project is a Hyperledger project in _Incubation_. It was proposed to the community and documented [here](https://docs.google.com/document/d/1E2i5GRqWsIag7KTxjQ_jQdDiWcuikv3KqXeuw7NaceM/edit), and was approved by [Hyperledger TSC at 2017-01-07](https://lists.hyperledger.org/pipermail/hyperledger-tsc/2017-January/000535.html). Information on what _Incubation_ entails can be found in the [Hyperledger Project Lifecycle document](https://goo.gl/4edNRc).\n+## Inclusive Language Statement\n+\n+These guiding principles are very important to the maintainers and therefore\n+we respectfully ask all contributors to abide by them as well:\n+\n+- Consider that users who will read the docs are from different backgrounds and\n+cultures and that they have different preferences.\n+- Avoid potential offensive terms and, for instance, prefer \"allow list and\n+deny list\" to \"white list and black list\".\n+- We believe that we all have a role to play to improve our world, and even if\n+writing inclusive documentation might not look like a huge improvement, it's a\n+first step in the right direction.\n+- We suggest to refer to\n+[Microsoft bias free writing guidelines](https://docs.microsoft.com/en-us/style-guide/bias-free-communication)\n+and\n+[Google inclusive doc writing guide](https://developers.google.com/style/inclusive-documentation)\n+as starting points.\n+\n<a rel=\"license\" href=\"http://creativecommons.org/licenses/by/4.0/\"><img alt=\"Creative Commons License\" style=\"border-width:0\" src=\"https://i.creativecommons.org/l/by/4.0/88x31.png\" /></a><br />This work is licensed under a <a rel=\"license\" href=\"http://creativecommons.org/licenses/by/4.0/\">Creative Commons Attribution 4.0 International License</a>.\n",
        "org_msg": "Add inclusive language statement",
        "sim_msg": "updated top-level README",
        "sim_diff": "diff --git a/README.md b/README.md # ACL Anthology\n-(This repo was originally wing-nus/acl and has been transferred over to acl-org\n-as of 5 Jun 2017. Please update accordingly.)\n-\n-These are basic instructions on generating the ACL Anthology website as seen on\n-<https://aclweb.org/anthology/>.\n-\n+These are basic instructions on generating the ACL Anthology website as seen on <https://aclweb.org/anthology/>.\n+The offical home of this repository is <https://github.com/acl-org/acl-anthology>.\n## Generating the Anthology\n@@ -64,21 +60,18 @@ about a minute to start.\n## Contributing\n-If you'd like to contribute to the ACL Anthology, please take a look at our\n-[information on volunteering](https://aclanthology.info/volunteer) and the\n-[detailed README](README_detailed.md) containing more in-depth information about\n-generating and modifying the website.\n+If you'd like to contribute to the ACL Anthology, please take a look at:\n+- our [Github issues page](https://github.com/acl-org/acl-anthology/issues)\n+- our [call for volunteers](https://aclanthology.info/volunteer)\n+- the [detailed README](README_detailed.md) which contains more in-depth information about generating and modifying the website.\n-## License\n+## History\n-Materials prior to 2016 here are licensed under the [Creative Commons\n-Attribution-NonCommercial-ShareAlike 3.0 International\n-License](https://creativecommons.org/licenses/by-nc-sa/3.0/). Permission is\n-granted to make copies for the purposes of teaching and research. Materials\n-published in or after 2016 are licensed on a [Creative Commons Attribution 4.0\n-License](https://creativecommons.org/licenses/by/4.0/).\n+This repo was originally wing-nus/acl and has been transferred over to acl-org as of 5 June 2017.\n-Matt Post (Editor, 2019-) / Min-Yen Kan (Editor, 2008-2018) / Steven Bird (Editor, 2001-2007)\n+## License\n-Developer team: Linh Hien Ng (linhhienng at gmail dot com), Duong Ho Tuan zamakkat at gmail dot com)\n+Materials prior to 2016 here are licensed under the [Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License](https://creativecommons.org/licenses/by-nc-sa/3.0/).\n+Permission is granted to make copies for the purposes of teaching and research.\n+Materials published in or after 2016 are licensed on a [Creative Commons Attribution 4.0 License](https://creativecommons.org/licenses/by/4.0/).\n",
        "chatgpt_cot": "\"Add inclusive language statement to README.md to request contributors to use inclusive language and refer to Microsoft and Google inclusive writing guides.\""
    },
    {
        "org_diff": "diff --git a/master_discovery_fkie/src/master_discovery_fkie/zeroconf.py b/master_discovery_fkie/src/master_discovery_fkie/zeroconf.py @@ -414,7 +414,7 @@ class Zeroconf(threading.Thread):\ndef on_group_failure(self, error):\nrospy.logfatal(\"Template: on_group_failure - %s\", error)\nself.stop()\n- sys.exit(\"ERROR: Template: on_group_failure - EXIT! [%s]\", error)\n+ sys.exit(\"ERROR: Template: on_group_failure - EXIT! [%s]\" % error)\ndef on_group_removed(self, name):\nrospy.loginfo(\"Template: on_group_removed - %s\", name)\n@@ -764,7 +764,7 @@ class Discoverer(Zeroconf):\n# test the host for local entry\nmasterhost, masterport = MasterInfo.MasteruriToAddr(materuri)\nif (masterhost in ['localhost', '127.0.0.1']):\n- sys.exit(\"'%s' is not reachable for other systems. Change the ROS_MASTER_URI!\", masterhost)\n+ sys.exit(\"'%s' is not reachable for other systems. Change the ROS_MASTER_URI!\" % masterhost)\nrpcuri = ''.join(['http://', socket.gethostname(), ':', str(monitor_port), '/'])\ntxtArray = [\"timestamp=%s\" % str(0), \"master_uri=%s\" % materuri, \"zname=%s\" % rospy.get_name(), \"rpcuri=%s\" % rpcuri, \"network_id=%s\" % self.network_id]\n# the Zeroconf class, which contains the QMainLoop to receive the signals from avahi\n",
        "org_msg": "Solve zeroconf sys.exit( ..., ...) issue",
        "sim_msg": "fix(minor): In add_doctype_links, use frappe._dict",
        "sim_diff": "diff --git a/frappe/model/meta.py b/frappe/model/meta.py @@ -460,7 +460,7 @@ class Meta(Document):\nif not link.added:\n# group not found, make a new group\n- data.transactions.append(dict(\n+ data.transactions.append(frappe._dict(\nlabel = link.group,\nitems = [link.link_doctype]\n))\n",
        "chatgpt_cot": "Fix string formatting in Zeroconf.py file to prevent compilation errors due to incorrect usage of %s by replacing it with % to ensure proper string interpolation."
    },
    {
        "org_diff": "diff --git a/.travis.yml b/.travis.yml @@ -47,17 +47,18 @@ jobs:\n- docker exec -i app bash -c \"cd /root/template && pipenv run pytest test/\"\n- docker rm -f app\n- - stage: run autotest bot\n- script:\n- # Debugging\n- - echo Current path\n- - pwd\n- - echo Project dir contents\n- - ls\n- # Build the docker image\n- - docker build -t test_image -f test/Dockerfile .\n- # Run the docker image\n- - docker run -it -d --name app test_image\n- - docker exec -i app bash -c \"python test/travis_test_script.py test/autotest_bot.py\"\n- # Shut down and remove container after finishing\n- - docker rm -f app\n+# Disabled until linux client is at version 4.8.5 or newer - issues with pixelmap that are working on the windows client\n+# - stage: run autotest bot\n+# script:\n+# # Debugging\n+# - echo Current path\n+# - pwd\n+# - echo Project dir contents\n+# - ls\n+# # Build the docker image\n+# - docker build -t test_image -f test/Dockerfile .\n+# # Run the docker image\n+# - docker run -it -d --name app test_image\n+# - docker exec -i app bash -c \"python test/travis_test_script.py test/autotest_bot.py\"\n+# # Shut down and remove container after finishing\n+# - docker rm -f app\n",
        "org_msg": "Dont run autotestbot",
        "sim_msg": "Use --no-deps when building wheels",
        "sim_diff": "diff --git a/buildwheels.sh b/buildwheels.sh #!/bin/bash\n#\n-# Build manylinux1 wheels for cutadapt. Based on the example at\n+# Build manylinux wheels. Based on the example at\n# <https://github.com/pypa/python-manylinux-demo>\n#\n# It is best to run this in a fresh clone of the repository!\n#\n# Run this within the repository root:\n-# docker run --rm -v $(pwd):/io quay.io/pypa/manylinux1_x86_64 /io/buildwheels.sh\n+# ./buildwheels.sh\n#\n# The wheels will be put into the wheelhouse/ subdirectory.\n#\n# For interactive tests:\n-# docker run -it -v $(pwd):/io quay.io/pypa/manylinux1_x86_64 /bin/bash\n+# docker run -it -v $(pwd):/io quay.io/pypa/manylinux2010_x86_64 /bin/bash\nset -xeuo pipefail\n-MANYLINUX=quay.io/pypa/manylinux2010_x86_64\n+manylinux=quay.io/pypa/manylinux2010_x86_64\n# For convenience, if this script is called from outside of a docker container,\n# it starts a container and runs itself inside of it.\nif ! grep -q docker /proc/1/cgroup; then\n# We are not inside a container\n- docker pull ${MANYLINUX}\n- exec docker run --rm -v $(pwd):/io ${MANYLINUX} /io/$0\n+ docker pull ${manylinux}\n+ exec docker run --rm -v $(pwd):/io ${manylinux} /io/$0\nfi\n# Strip binaries (copied from multibuild)\n@@ -37,11 +37,12 @@ PYBINS=\"/opt/python/*/bin\"\nHAS_CYTHON=0\nfor PYBIN in ${PYBINS}; do\n# ${PYBIN}/pip install -r /io/requirements.txt\n- ${PYBIN}/pip wheel /io/ -w wheelhouse/\n+ ${PYBIN}/pip wheel --no-deps /io/ -w wheelhouse/\ndone\n+ls wheelhouse/\n# Bundle external shared libraries into the wheels\n-for whl in wheelhouse/cutadapt-*.whl; do\n+for whl in wheelhouse/*.whl; do\nauditwheel repair \"$whl\" --plat manylinux1_x86_64 -w repaired/\ndone\n",
        "chatgpt_cot": "Disable autotest bot stage until linux client is updated to version 4.8.5 or newer due to pixelmap issues on windows client."
    },
    {
        "org_diff": "diff --git a/fkie_multimaster_msgs/CMakeLists.txt b/fkie_multimaster_msgs/CMakeLists.txt @@ -44,7 +44,7 @@ generate_grpc(PROTO_FILES file launch monitor screen settings version)\ninstall(\nDIRECTORY\n${GRPC_GENERATED_SRC_DIR}\n- DESTINATION ${CATKIN_PACKAGE_LIB_DESTINATION}\n+ DESTINATION ${CATKIN_PACKAGE_PYTHON_DESTINATION}\n)\ninstall(\n",
        "org_msg": "Fix install location for generated gRPC submodule",
        "sim_msg": "Disable sanitizers for cJSON universal.",
        "sim_diff": "diff --git a/package/lib-cjson-master-universal/scripts.linux/install.sh b/package/lib-cjson-master-universal/scripts.linux/install.sh #! /bin/bash\n#\n-# Extra Installation script\n+# Extra installation script\n#\n# See CK LICENSE.txt for licensing details.\n# See CK COPYRIGHT.txt for copyright details.\n@@ -18,7 +18,7 @@ export CK_CMAKE_EXTRA=\"${CK_CMAKE_EXTRA} \\\n-DENABLE_TARGET_EXPORT=On \\\n-DENABLE_CUSTOM_COMPILER_FLAGS=On \\\n-DENABLE_VALGRIND=Off \\\n- -DENABLE_SANITIZERS=On \\\n+ -DENABLE_SANITIZERS=Off \\\n-DBUILD_SHARED_LIBS=On \\\n-DSAMPLES=ON\"\n",
        "chatgpt_cot": "Update destination path in CMakeLists.txt to ${CATKIN_PACKAGE_PYTHON_DESTINATION} for Python files installation."
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/echo_dialog.py b/node_manager_fkie/src/node_manager_fkie/echo_dialog.py @@ -464,7 +464,7 @@ class EchoDialog(QDialog):\nelse:\nmessage_bytes = \"size: %s\" % (self._normilize_size_print(last))\nbyte_rate = float(sum_bytes) / float(sum_times)\n- message_bytes += \" bw: %s\" % (self._normilize_size_print(byte_rate))\n+ message_bytes += \" bw: %s/s\" % (self._normilize_size_print(byte_rate))\n# the code from ROS rostopic\nn = len(self.times)\nif n < 2:\n@@ -499,9 +499,9 @@ class EchoDialog(QDialog):\ndef _normilize_size_print(self, size):\nif size > 999999:\n- return \"%.2fMB\" % (size / 1048576.0)\n+ return \"%.2fMiB\" % (size / 1048576.0)\nif size > 999:\n- return \"%.2fKB\" % (size / 1024.0)\n+ return \"%.2fKiB\" % (size / 1024.0)\nreturn \"%dB\" % size\ndef _print_status(self):\n",
        "org_msg": "node_manager_fkie: size units fixed",
        "sim_msg": "core: assign common expression to a variable.",
        "sim_diff": "diff --git a/mitogen/core.py b/mitogen/core.py @@ -766,14 +766,14 @@ class Stream(BasicStream):\nmsg = Message()\nmsg.router = self._router\n-\n(msg.dst_id, msg.src_id, msg.auth_id,\nmsg.handle, msg.reply_to, msg_len) = struct.unpack(\nself.HEADER_FMT,\nself._input_buf[0][:self.HEADER_LEN],\n)\n- if (self._input_buf_len - self.HEADER_LEN) < msg_len:\n+ total_len = msg_len + self.HEADER_LEN\n+ if self._input_buf_len < total_len:\n_vv and IOLOG.debug(\n'%r: Input too short (want %d, got %d)',\nself, msg_len, self._input_buf_len - self.HEADER_LEN\n@@ -782,7 +782,7 @@ class Stream(BasicStream):\nstart = self.HEADER_LEN\nprev_start = start\n- remain = msg_len + start\n+ remain = total_len\nbits = []\nwhile remain:\nbuf = self._input_buf.popleft()\n@@ -794,7 +794,7 @@ class Stream(BasicStream):\nmsg.data = ''.join(bits)\nself._input_buf.appendleft(buf[prev_start+len(bit):])\n- self._input_buf_len -= self.HEADER_LEN + msg_len\n+ self._input_buf_len -= total_len\nself._router._async_route(msg, self)\nreturn True\n",
        "chatgpt_cot": "Update unit size print format to use MiB and KiB for better clarity and consistency in EchoDialog file."
    },
    {
        "org_diff": "diff --git a/src/api-engine/api/routes/channel/views.py b/src/api-engine/api/routes/channel/views.py #\n# SPDX-License-Identifier: Apache-2.0\n#\n-from distutils.command.config import config\nfrom rest_framework import viewsets, status\nfrom rest_framework.decorators import action\nfrom rest_framework.response import Response\n",
        "org_msg": "Remove unsed dependencies",
        "sim_msg": "Adding forgotten import on api.py",
        "sim_diff": "diff --git a/app/views/api.py b/app/views/api.py @@ -11,7 +11,7 @@ from peewee import JOIN, fn\nfrom .. import misc\nfrom ..socketio import socketio\nfrom ..models import Sub, User, Grant, Token, Client, SubPost, Sub, SubPostComment, APIToken, APITokenSettings\n-from ..models import SiteMetadata, SubPostVote, SubMetadata, SubPostCommentVote\n+from ..models import SiteMetadata, SubPostVote, SubMetadata, SubPostCommentVote, SubMod\napi = Blueprint('api', __name__)\noauth = OAuth2Provider()\n",
        "chatgpt_cot": "Remove unused import and update rest_framework imports in views.py. (#123)"
    },
    {
        "org_diff": "diff --git a/rasa_core_sdk/__init__.py b/rasa_core_sdk/__init__.py @@ -165,7 +165,7 @@ class Action(object):\n:class:`rasa_core_sdk.Tracker` property.\ndomain (Dict[Text, Any]): the bot's domain\nReturns:\n- Dict[Event]: A dictionary of :class:`rasa_core_sdk.events.Event`\n+ List[dict]: A dictionary of :class:`rasa_core_sdk.events.Event`\ninstances that is returned through the endpoint\n\"\"\"\n",
        "org_msg": "Corrects method return's documentation signature",
        "sim_msg": "[EventPoster] Fix for 3.1",
        "sim_diff": "diff --git a/eventposter/event_obj.py b/eventposter/event_obj.py @@ -36,7 +36,12 @@ class Event:\n@classmethod\nasync def from_json(cls, data: dict, guild: discord.Guild):\nchannel = guild.get_channel(data[\"channel\"])\n+ try:\nmessage = await channel.get_message(data[\"message\"])\n+ except AttributeError:\n+ message = await channel.fetch_message(data[\"message\"])\n+ except discord.errors.Forbidden:\n+ message = None\nreturn cls(\nguild.get_member(data[\"hoster\"]),\n[guild.get_member(m) for m in data[\"members\"]],\n",
        "chatgpt_cot": "Update return type in Action class to List[dict] for instances returned through the endpoint in rasa_core_sdk/__init__.py."
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/editor/editor.py b/node_manager_fkie/src/node_manager_fkie/editor/editor.py @@ -566,8 +566,8 @@ class Editor(QMainWindow):\nmov = QTextCursor.NextBlock if curpos < linenr else QTextCursor.PreviousBlock\nself.tabWidget.currentWidget().moveCursor(mov)\ncurpos = self.tabWidget.currentWidget().textCursor().blockNumber() + 1\n- self.tabWidget.currentWidget().moveCursor(QTextCursor.StartOfBlock)\n- self.tabWidget.currentWidget().moveCursor(QTextCursor.EndOfBlock, QTextCursor.KeepAnchor)\n+ self.tabWidget.currentWidget().moveCursor(QTextCursor.EndOfBlock)\n+ self.tabWidget.currentWidget().moveCursor(QTextCursor.StartOfBlock, QTextCursor.KeepAnchor)\n##############################################################################\n# SLOTS for search dialog\n",
        "org_msg": "node_manager_fkie: launch editor: changed line selection behaviour",
        "sim_msg": "improved forward reverse through selected code in code_text",
        "sim_diff": "diff --git a/qualcoder/code_text.py b/qualcoder/code_text.py @@ -254,11 +254,11 @@ class DialogCodeText(QtWidgets.QWidget):\nitem.setToolTip(tt)\nself.ui.listWidget.addItem(item)\n- def closeEvent(self, event):\n+ '''def closeEvent(self, event):\n\"\"\" Save dialog and splitter dimensions. \"\"\"\nself.app.settings['dialogcodetext_w'] = self.size().width()\n- self.app.settings['dialogcodetext_h'] = self.size().height()\n+ self.app.settings['dialogcodetext_h'] = self.size().height()'''\ndef update_sizes(self):\n\"\"\" Called by changed splitter size \"\"\"\n@@ -800,7 +800,7 @@ class DialogCodeText(QtWidgets.QWidget):\nActionMoveCode = None\nif selected is not None and selected.text(1)[0:3] == 'cid':\nActionItemChangeColor = menu.addAction(_(\"Change code color\"))\n- ActionShowCodedMedia = menu.addAction(_(\"Show coded text and media\"))\n+ ActionShowCodedMedia = menu.addAction(_(\"Show coded files\"))\nActionMoveCode = menu.addAction(_(\"Move code to\"))\nActionShowCodesLike = menu.addAction(_(\"Show codes like\"))\n@@ -1014,9 +1014,17 @@ class DialogCodeText(QtWidgets.QWidget):\nend_pos = index['pos1']\nfound_larger = True\nbreak\n+ if not found_larger and indexes == []:\n+ return\n+ # loop around to highest index\n+ if not found_larger and indexes != []:\n+ cur_pos = indexes[0]['pos0']\n+ end_pos = indexes[0]['pos1']\nif not found_larger:\n+ cursor = self.ui.textEdit.textCursor()\n+ cursor.setPosition(0)\n+ self.ui.textEdit.setTextCursor(cursor)\nreturn\n-\nself.unlight()\nself.highlight(cid)\n@@ -1065,9 +1073,12 @@ class DialogCodeText(QtWidgets.QWidget):\nend_pos = index['pos1']\nfound_smaller = True\nbreak\n- if not found_smaller:\n+ if not found_smaller and indexes == []:\nreturn\n-\n+ # loop around to highest index\n+ if not found_smaller and indexes != []:\n+ cur_pos = indexes[0]['pos0']\n+ end_pos = indexes[0]['pos1']\nself.unlight()\nself.highlight(cid)\n@@ -1094,6 +1105,9 @@ class DialogCodeText(QtWidgets.QWidget):\n\"\"\" Opposes show selected code methods.\nHighlights all the codes in the text. \"\"\"\n+ cursor = self.ui.textEdit.textCursor()\n+ cursor.setPosition(0)\n+ self.ui.textEdit.setTextCursor(cursor)\nicon = QtGui.QIcon(QtGui.QPixmap('GUI/2x2_grid_icon_24.png'))\nself.ui.pushButton_show_all_codings.setIcon(icon)\nself.ui.pushButton_show_codings_prev.setStyleSheet(\"\")\n@@ -1108,7 +1122,7 @@ class DialogCodeText(QtWidgets.QWidget):\nparam:\ndata: code dictionary\n\"\"\"\n- ui = DialogInformation(self.app, \"Coded text and media: \" + data['name'], \" \")\n+ ui = DialogInformation(self.app, \"Coded files: \" + data['name'], \" \")\ncur = self.app.conn.cursor()\nCOLOR = 1\nSOURCE_NAME = 2\n",
        "chatgpt_cot": "Refactor cursor movement in Editor class for consistency. Update start and end of block cursor positions to maintain text selection."
    },
    {
        "org_diff": "diff --git a/master_discovery_fkie/src/master_discovery_fkie/udp.py b/master_discovery_fkie/src/master_discovery_fkie/udp.py @@ -42,6 +42,13 @@ import socket\nimport struct\nimport threading\n+try:\n+ import netifaces\n+ _use_netifaces = True\n+except:\n+ _use_netifaces = False\n+\n+\nSEND_ERRORS = {}\n@@ -389,6 +396,17 @@ class DiscoverSocket(socket.socket):\n``(interface name, interface IP)``\n:rtype: list of ``(str, str)``\n'''\n+ if _use_netifaces:\n+ # #addresses on multiple platforms (OS X, Unix, Windows)\n+ local_addrs = []\n+ # see http://alastairs-place.net/netifaces/\n+ for i in netifaces.interfaces():\n+ try:\n+ local_addrs.extend([(i, d['addr']) for d in netifaces.ifaddresses(i)[netifaces.AF_INET]])\n+ except KeyError:\n+ pass\n+ return local_addrs\n+ else:\nSIOCGIFCONF = 0x8912\nMAXBYTES = 8096\narch = platform.architecture()[0]\n",
        "org_msg": "try local interface discovering on iOS",
        "sim_msg": "prevent erroring out when there is no local broadcast tuple",
        "sim_diff": "diff --git a/samples/UDPConsole.py b/samples/UDPConsole.py @@ -126,10 +126,17 @@ class MiddleMan(Client, Server):\n# check the address\nif addr == \"*\":\n+ if not local_broadcast_tuple:\n+ sys.stderr.write(\"err: no local broadcast\\n\")\n+ return\n+\ndest = local_broadcast_tuple\nelif ':' in addr:\naddr, port = addr.split(':')\nif addr == \"*\":\n+ if not local_broadcast_tuple:\n+ sys.stderr.write(\"err: no local broadcast\\n\")\n+ return\ndest = (local_broadcast_tuple[0], int(port))\nelse:\ndest = (addr, int(port))\n@@ -234,6 +241,9 @@ def main():\nif args.noBroadcast:\n_log.debug(\" - skipping broadcast\")\n+ elif not local_broadcast_tuple:\n+ _log.debug(\" - no local broadcast\")\n+\nelif local_unicast_tuple == local_broadcast_tuple:\n_log.debug(\" - identical unicast and broadcast tuples\")\n",
        "chatgpt_cot": "Add the code to discover the local addresses using netifaces and return the list of addresses."
    },
    {
        "org_diff": "diff --git a/master_discovery_fkie/src/master_discovery_fkie/common.py b/master_discovery_fkie/src/master_discovery_fkie/common.py @@ -249,23 +249,10 @@ def create_pattern(param, data, has_interface, default=[], mastername=''):\nif has_interface: # read the parameter from the sync interface data\nif param in data and data[param]:\nfor item in data[param]:\n- if isinstance(item, dict):\n- # this are mastername specific remapings\n- if mastername and mastername in item:\n- if isinstance(item[mastername], list):\n- def_list[len(def_list):] = item[mastername]\n- else:\n- def_list.append(item[mastername])\n- elif isinstance(item, list):\n- def_list[len(def_list):] = item\n- else:\n- def_list.append(item)\n+ _parse_value(item, mastername, def_list)\nelse: # reads the patterns from the ROS parameter server\nrp = rospy.get_param('~%s' % param, [])\n- if isinstance(rp, list):\n- def_list[len(def_list):] = rp\n- else:\n- def_list.append(rp)\n+ _parse_value(rp, mastername, def_list)\n# reads the mastername specific parameters\nif mastername:\nrph = rospy.get_param('~%s' % roslib.names.ns_join(mastername, param), [])\n@@ -277,6 +264,29 @@ def create_pattern(param, data, has_interface, default=[], mastername=''):\nreturn gen_pattern(def_list, param)\n+def _parse_value(value, mastername, def_list):\n+ if isinstance(value, dict):\n+ # this are mastername specific remapings\n+ if mastername and mastername in value:\n+ if isinstance(value[mastername], list):\n+ def_list[len(def_list):] = value[mastername]\n+ else:\n+ def_list.append(value[mastername])\n+ elif isinstance(value, list):\n+ for item in value:\n+ if isinstance(item, dict):\n+ # this are mastername specific remapings\n+ if mastername and mastername in item:\n+ if isinstance(item[mastername], list):\n+ def_list[len(def_list):] = item[mastername]\n+ else:\n+ def_list.append(item[mastername])\n+ else:\n+ def_list.append(item)\n+ else:\n+ def_list.append(value)\n+\n+\ndef gen_pattern(filter_list, name, print_info=True):\nif print_info:\nrospy.loginfo(\"%s: %s\", name, str(filter_list))\n",
        "org_msg": "fixed read parameter with host filter",
        "sim_msg": "fill placehorder dict and list",
        "sim_diff": "diff --git a/qlib/model/trainer.py b/qlib/model/trainer.py @@ -13,6 +13,7 @@ In ``DelayTrainer``, the first step is only to save some necessary info to model\nimport socket\nimport time\n+import re\nfrom typing import Callable, List\nfrom qlib.data.dataset import Dataset\n@@ -62,24 +63,26 @@ def fill_placeholder(config: dict, config_extend: dict):\nthe parameter dict\n\"\"\"\n# check the format of config_extend\n- import re\nfor placeholder in config_extend.keys():\nassert re.match(r\"<[^<>]+>\", placeholder)\n- re.match()\n# bfs\ntop = 0\ntail = 1\n- dict_quene = [config]\n+ item_quene = [config]\nwhile(top < tail):\n- now_dict = dict_quene[top]\n+ now_item = item_quene[top]\ntop += 1\n- for key in now_dict.keys():\n- if(isinstance(now_dict[key], dict)):\n- dict_quene.append(now_dict[key])\n+ if(isinstance(now_item, list)):\n+ item_keys = range(len(now_item))\n+ elif(isinstance(now_item, dict)):\n+ item_keys = now_item.keys()\n+ for key in item_keys:\n+ if(isinstance(now_item[key], list) or isinstance(now_item[key], dict)):\n+ item_quene.append(now_item[key])\ntail += 1\n- elif(now_dict[key] in config_extend.keys()):\n- now_dict[key] = config_extend[now_dict[key]]\n+ elif(now_item[key] in config_extend.keys()):\n+ now_item[key] = config_extend[now_item[key]]\nreturn config\n",
        "chatgpt_cot": "Add method _parse_value to parse the value, solve the issue of reading the parameter from the sync interface data."
    },
    {
        "org_diff": "diff --git a/fkie_master_sync/src/fkie_master_sync/sync_thread.py b/fkie_master_sync/src/fkie_master_sync/sync_thread.py @@ -116,10 +116,10 @@ class SyncThread(object):\nself._filter = FilterInterface()\nself._filter.load(self.name,\n['/rosout', self.discoverer_name, '/node_manager', '/node_manager_daemon', '/zeroconf', '/param_sync'], [],\n- ['/rosout', '/rosout_agg'], ['/'] if sync_on_demand else [],\n+ ['/rosout', '/rosout_agg', '/diagnostics', '/diagnostics_agg'], ['/'] if sync_on_demand else [],\n['/*get_loggers', '/*set_logger_level'], [],\n# do not sync the bond message of the nodelets!!\n- ['bond/Status'],\n+ ['bond/Status', 'fkie_multimaster_msgs/SyncTopicInfo', 'fkie_multimaster_msgs/SyncServiceInfo', 'fkie_multimaster_msgs/SyncMasterInfo', 'fkie_multimaster_msgs/MasterState'],\n[], [],\n[])\n",
        "org_msg": "fkie_master_sync: added diagnostics and master_sync topics to default ignore list",
        "sim_msg": "Fix the variable names used for account_data",
        "sim_diff": "diff --git a/synapse/handlers/sync.py b/synapse/handlers/sync.py @@ -1668,13 +1668,13 @@ class SyncHandler(object):\n\"content\": content,\n})\n- account_data = sync_config.filter_collection.filter_room_account_data(\n+ account_data_events = sync_config.filter_collection.filter_room_account_data(\naccount_data_events\n)\nephemeral = sync_config.filter_collection.filter_room_ephemeral(ephemeral)\n- if not (always_include or batch or account_data or ephemeral or full_state):\n+ if not (always_include or batch or account_data_events or ephemeral or full_state):\nreturn\nstate = yield self.compute_state_delta(\n@@ -1745,7 +1745,7 @@ class SyncHandler(object):\nroom_id=room_id,\ntimeline=batch,\nstate=state,\n- account_data=account_data,\n+ account_data=account_data_events,\n)\nif room_sync or always_include:\nsync_result_builder.archived.append(room_sync)\n",
        "chatgpt_cot": "Update SyncThread filter to include additional topics and message types for synchronization. Fix bond message exclusion and add new message types."
    },
    {
        "org_diff": "diff --git a/rasa_core_sdk/forms.py b/rasa_core_sdk/forms.py @@ -41,8 +41,10 @@ class FormAction(Action):\ndef slot_mapping(self):\n# type: () -> Dict[Text: Union[Text, List[Text], Dict[Text: Any]]]\n- \"\"\"A dictionary to map required slots to extracted entities or\n- to intent:value pairs or free text\"\"\"\n+ \"\"\"A dictionary to map required slots to\n+ - an extracted entity or a list of entities\n+ - a dictionary of intent: value pairs\n+ - a whole message\"\"\"\nreturn dict(zip(self.required_slots(), self.required_slots()))\n",
        "org_msg": "update slot_mapping comment RasaHQ/roadmap#280",
        "sim_msg": "EventForm: conditionally show \"lessons\" field\n...based on \"show_lessons\" kwarg in __init__",
        "sim_diff": "diff --git a/amy/workshops/forms.py b/amy/workshops/forms.py @@ -414,11 +414,28 @@ class EventForm(forms.ModelForm):\nclass Meta:\nmodel = Event\n- fields = ['slug', 'completed', 'start', 'end', 'host', 'administrator',\n- 'assigned_to', 'tags', 'url', 'language', 'reg_key', 'venue',\n- 'manual_attendance', 'contact',\n- 'country', 'address', 'latitude', 'longitude',\n- 'open_TTT_applications', 'curricula',\n+ fields = [\n+ 'slug',\n+ 'completed',\n+ 'start',\n+ 'end',\n+ 'host',\n+ 'administrator',\n+ 'assigned_to',\n+ 'tags',\n+ 'url',\n+ 'language',\n+ 'reg_key',\n+ 'venue',\n+ 'manual_attendance',\n+ 'contact',\n+ 'country',\n+ 'address',\n+ 'latitude',\n+ 'longitude',\n+ 'open_TTT_applications',\n+ 'curricula',\n+ 'lessons',\n'comment',\n]\nwidgets = {\n@@ -430,6 +447,7 @@ class EventForm(forms.ModelForm):\n'size': Tag.ITEMS_VISIBLE_IN_SELECT_WIDGET\n}),\n'curricula': CheckboxSelectMultiple(),\n+ 'lessons': CheckboxSelectMultiple(),\n}\nclass Media:\n@@ -442,6 +460,7 @@ class EventForm(forms.ModelForm):\n)\ndef __init__(self, *args, **kwargs):\n+ show_lessons = kwargs.pop('show_lessons', False)\nsuper().__init__(*args, **kwargs)\nself.helper.layout = Layout(\n@@ -473,6 +492,17 @@ class EventForm(forms.ModelForm):\n'comment',\n)\n+ # if we want to show lessons, we need to alter existing layout\n+ # otherwise we should remove the field so it doesn't break validation\n+ if show_lessons:\n+ self.helper.layout.insert(\n+ # insert AFTER the curricula\n+ self.helper.layout.fields.index('curricula') + 1,\n+ 'lessons',\n+ )\n+ else:\n+ del self.fields['lessons']\n+\ndef clean_slug(self):\n# Ensure slug is in \"YYYY-MM-DD-location\" format\ndata = self.cleaned_data['slug']\n",
        "chatgpt_cot": "Update slot_mapping method in FormAction to provide clearer mapping of required slots to entities, intent:value pairs, and whole message."
    },
    {
        "org_diff": "diff --git a/.github/workflows/codecoverage.yml b/.github/workflows/codecoverage.yml # If you change the name, change the link on the README.md for the badge too\nname: Code coverage and radon\n-# Only run if files in the given path have changed\n-on:\n- push:\n- paths:\n- - sc2/**\n- pull_request:\n- paths:\n- - sc2/**\n+# Always run\n+on: [push, pull_request]\nenv:\n# Docker image version, see https://hub.docker.com/r/burnysc2/python-sc2-docker/tags\n",
        "org_msg": "Make codecoverage always run",
        "sim_msg": "ci(test): test commit to see if report appears",
        "sim_diff": "diff --git a/.github/workflows/ci.yml b/.github/workflows/ci.yml @@ -96,7 +96,6 @@ jobs:\nname: codecoverage-${{ matrix.python-version }}\n- name: Check what is in this folder\nrun: |\n- ls -l\nls -l codecoverage-3.7\ncat codecoverage-3.7/coverage.xml\n- name: Upload coverage to Codecov\n",
        "chatgpt_cot": "\"Update codecoverage.yml to always run on push and pull_request. Also update comments about file path changes and Docker image version.\""
    },
    {
        "org_diff": "diff --git a/fkie_node_manager/scripts/remote_nm.py b/fkie_node_manager/scripts/remote_nm.py @@ -108,7 +108,7 @@ def main(argv=sys.argv):\noptions, args = parse_options(argv)\nif options['show_screen_log']:\nlogfile = screen.get_logfile(node=options['show_screen_log'])\n- if os.path.isfile(logfile):\n+ if not os.path.isfile(logfile):\nraise Exception('screen logfile not found for: %s' % options['show_screen_log'])\ncmd = ' '.join([nm.Settings.LOG_VIEWER, str(logfile)])\nprint(cmd)\n@@ -117,7 +117,7 @@ def main(argv=sys.argv):\nprint_help = False\nif options['tail_screen_log']:\nlogfile = screen.get_logfile(node=options['tail_screen_log'])\n- if os.path.isfile(logfile):\n+ if not os.path.isfile(logfile):\nraise Exception('screen logfile not found for: %s' % options['tail_screen_log'])\ncmd = ' '.join(['tail', '-f', '-n', '25', str(logfile)])\nprint(cmd)\n@@ -126,7 +126,7 @@ def main(argv=sys.argv):\nprint_help = False\nelif options['show_ros_log']:\nlogfile = screen.get_ros_logfile(node=options['show_ros_log'])\n- if os.path.isfile(logfile):\n+ if not os.path.isfile(logfile):\nraise Exception('ros logfile not found for: %s' % options['show_ros_log'])\ncmd = ' '.join([nm.Settings.LOG_VIEWER, str(logfile)])\nprint(cmd)\n",
        "org_msg": "fkie_node_manager: fix remote log view",
        "sim_msg": "Remove outdated util commands",
        "sim_diff": "diff --git a/augur/cli/util.py b/augur/cli/util.py @@ -14,50 +14,6 @@ def cli():\ndef shell(app):\napp.shell()\n-@cli.command('edit-config', short_help='Edit your config file')\n-@pass_application\n-def edit_config(app):\n- \"\"\"\n- Edit your config file\n- \"\"\"\n- click.edit(filename=app._config_file_path)\n-\n-\n-@cli.command('python-location', short_help='Print the location of the interpreter that is running this')\n-def interpreter():\n- \"\"\"\n- Print the location of the interpreter that is running this\n- \"\"\"\n- print(sys.executable)\n-\n-\n-@cli.command('except', short_help='Test logging and raise an exception')\n-@pass_application\n-def excpt(app):\n- \"\"\"\n- Print the location of the interpreter that is running this\n- \"\"\"\n- print('Logging tests... ', file=sys.stderr)\n- app.log.info('Hello')\n- app.log.warn('Things are looking scary')\n- app.log.error('Things are bad!')\n- app.log.fatal('Now I am dying')\n- print('Exception handling...', file=sys.stderr)\n- raise Exception('is dead')\n-\n-\n-@cli.command('upgrade', short_help='Upgrade Augur')\n-@click.option('--from-directory', '-f', type=click.Path(), help='Upgrade from a provided directory rather than git.')\n-@pass_application\n-def upgrade(app, from_directory):\n- \"\"\"\n- Print the location of the interpreter that is running this\n- \"\"\"\n- pass\n- # app.log.info(pyrcss.util.self_upgrade(from_directory=from_directory, dry_run=true))\n- # pyrcss.util.self_upgrade(from_directory=from_directory)\n-\n-\n@cli.command('kill', short_help='Kill Augur')\n@pass_application\ndef kill(app):\n",
        "chatgpt_cot": "Fix file not found exceptions in remote_nm.py for screen and ros log files. Add checks to handle non-existing log files."
    },
    {
        "org_diff": "diff --git a/fkie_node_manager/src/fkie_node_manager/settings.py b/fkie_node_manager/src/fkie_node_manager/settings.py @@ -621,7 +621,7 @@ class Settings(object):\n:rtype: str\n'''\nif self._terminal_emulator is None:\n- self._terminal_emulator = \"\"\n+ self._terminal_emulator = ''\nfor t in ['/usr/bin/x-terminal-emulator', '/usr/bin/xterm', '/opt/x11/bin/xterm']:\nif os.path.isfile(t) and os.access(t, os.X_OK):\n# workaround to support the command parameter in different terminal\n@@ -640,10 +640,13 @@ class Settings(object):\nself._terminal_title = '-T'\nself._terminal_emulator = t\nbreak\n- if self._terminal_emulator == \"\":\n+ if self._terminal_emulator == '':\nraise Exception(\"No Terminal found! Please install one of ['/usr/bin/x-terminal-emulator', '/usr/bin/xterm', '/opt/x11/bin/xterm']\")\n- self._noclose_str = self._noclose_str if noclose else \"\"\n- return '%s %s \"%s\" %s -%s %s' % (self._terminal_emulator, self._terminal_title, title, self._noclose_str, self._terminal_command_arg, ' '.join(cmd))\n+ self._noclose_str = self._noclose_str if noclose else ''\n+ title_opt = ''\n+ if title:\n+ title_opt = '%s \"%s\"' % (self._terminal_title, title)\n+ return '%s %s %s -%s %s' % (self._terminal_emulator, title_opt, self._noclose_str, self._terminal_command_arg, ' '.join(cmd))\ndef qsettings(self, settings_file):\npath = settings_file\n",
        "org_msg": "fkie_node_manager: fixed open terminal",
        "sim_msg": "data sources + backend",
        "sim_diff": "diff --git a/openbb_terminal/settings_controller.py b/openbb_terminal/settings_controller.py @@ -7,7 +7,7 @@ import os.path\nimport argparse\nimport logging\nfrom pathlib import Path\n-from typing import List, Union\n+from typing import List, Optional, Union\nimport pytz\n# IMPORTATION THIRDPARTY\n@@ -138,8 +138,8 @@ class SettingsController(BaseController):\nconsole.print(text=mt.menu_text, menu=\"Settings\")\n@staticmethod\n- def set_cfg_plot(name: str, value: Union[bool, str]):\n- \"\"\"Set cfg_plot attribute\n+ def set_cfg_plot(name: str, value: Optional[Union[bool, str]]):\n+ \"\"\"Set plot config attribute\nParameters\n----------\n@@ -204,7 +204,7 @@ class SettingsController(BaseController):\n\"-v\",\n\"--value\",\ntype=str,\n- default=os.getcwd() + os.path.sep + \"sources.json.default\",\n+ default=str(USER_DATA_DIRECTORY / \"data_sources_default.json\"),\ndest=\"value\",\nhelp=\"value\",\n)\n@@ -214,20 +214,20 @@ class SettingsController(BaseController):\nif ns_parser:\ntry:\n- the_path = os.getcwd() + os.path.sep + ns_parser.value\n- console.print(\"Loading sources from \" + the_path)\n+ the_path = ns_parser.value\n+ console.print(\"Loading sources from \" + str(the_path))\nwith open(the_path):\n# Try to open the file to get an exception if the file doesn't exist\npass\n- except Exception as e:\n- console.print(\"Couldn't open the sources file!\")\n- console.print(e)\n-\nobbff_ctrl.FeatureFlagsController.set_feature_flag(\n\"OPENBB_PREFERRED_DATA_SOURCE_FILE\", ns_parser.value\n)\n+ except Exception as e:\n+ console.print(\"Couldn't open the sources file!\")\n+ console.print(e)\n+\n@log_start_end(log=logger)\ndef call_autoscaling(self, _):\n\"\"\"Process autoscaling command\"\"\"\n@@ -394,11 +394,9 @@ class SettingsController(BaseController):\nother_args.insert(0, \"-v\")\nns_parser = self.parse_simple_args(parser, other_args)\nif ns_parser:\n- set_key(USER_ENV_FILE, \"OPENBB_BACKEND\", str(ns_parser.value))\n- if ns_parser.value == \"None\":\n- cfg_plot.BACKEND = None # type: ignore\n- else:\n- cfg_plot.BACKEND = ns_parser.value\n+ SettingsController.set_cfg_plot(\n+ \"OPENBB_BACKEND\", None if ns_parser.value == \"None\" else ns_parser.value\n+ )\n@log_start_end(log=logger)\ndef call_lang(self, other_args: List[str]):\n",
        "chatgpt_cot": "\"Fix terminal emulator initialization and add title option to terminal command in settings.py\""
    },
    {
        "org_diff": "diff --git a/fkie_node_manager/src/fkie_node_manager/node_tree_model.py b/fkie_node_manager/src/fkie_node_manager/node_tree_model.py @@ -123,7 +123,7 @@ class GroupItem(QStandardItem):\nself._re_cap_nodes = dict()\nself._is_group = is_group\nself._state = NodeItem.STATE_OFF\n- self.diagnostic_array = []\n+ self.diagnostic_level = 0\nself.is_system_group = name == 'SYSTEM'\nself._clearup_mark_delete = False\n@@ -668,7 +668,7 @@ class GroupItem(QStandardItem):\nhas_off = False\nhas_duplicate = False\nhas_ghosts = False\n- diag_level = 0\n+ self.diagnostic_level = 0\nfor i in range(self.rowCount()):\nitem = self.child(i)\nif isinstance(item, (GroupItem, NodeItem)):\n@@ -682,12 +682,8 @@ class GroupItem(QStandardItem):\nhas_off = True\nelif item.state == NodeItem.STATE_RUN:\nhas_running = True\n- if item.diagnostic_array and item.diagnostic_array[-1].level > 0:\n- if diag_level == 0:\n- diag_level = item.diagnostic_array[-1].level\n- elif item.diagnostic_array[-1].level == 2:\n- diag_level = 2\n- self.diagnostic_array = item.diagnostic_array\n+ if item.diagnostic_level > self.diagnostic_level:\n+ self.diagnostic_level = item.diagnostic_level\nelif item.state == NodeItem.STATE_GHOST:\nhas_ghosts = True\nelif item.state == NodeItem.STATE_DUPLICATE:\n@@ -696,8 +692,8 @@ class GroupItem(QStandardItem):\nhas_running = True\nhas_off = True\ndiag_icon = None\n- if diag_level > 0:\n- diag_icon = NodeItem._diagnostic_level2icon(diag_level)\n+ if self.diagnostic_level > 0:\n+ diag_icon = NodeItem._diagnostic_level2icon(self.diagnostic_level)\nif has_duplicate:\nself._state = NodeItem.STATE_DUPLICATE\nself.setIcon(nm.settings().icon('imacadam_stop.png'))\n@@ -1408,6 +1404,12 @@ class NodeItem(QStandardItem):\nelse:\nreturn nm.settings().icon('state_diag_other.png')\n+ @property\n+ def diagnostic_level(self):\n+ if self.diagnostic_array:\n+ return self.diagnostic_array[-1].level\n+ return 0\n+\ndef _on_kill_param_values(self, masteruri, code, msg, params):\nif code == 1:\n# assumption: all parameter are 'kill_on_stop' parameter\n",
        "org_msg": "changed handling of the diagnostics level in group view",
        "sim_msg": "Added basic cleaning\nAdded a basic cleaning routine for the JRO ISR data, based on the Madrigal file comments.",
        "sim_diff": "diff --git a/pysat/instruments/jro_isr.py b/pysat/instruments/jro_isr.py @@ -165,18 +165,36 @@ def clean(self):\nNotes\n--------\nSupports 'clean', 'dusty', 'dirty'\n- 'Clean' is unknown\n- 'Dusty' is unknown\n- 'Dirty' is unknown\n+ 'Clean' is unknown for oblique modes, over 200 km for drifts\n+ 'Dusty' is unknown for oblique modes, over 200 km for drifts\n+ 'Dirty' is unknown for oblique modes, over 200 km for drifts\n'None' None\nRoutine is called by pysat, and not by the end user directly.\n\"\"\"\n+ import numpy as np\n+\n+ idx = list()\n+\n+ if self.tag.find('oblique') == 0:\n+ print('The double pulse, coded pulse, and long pulse modes ' +\n+ 'implemented at Jicamarca have different limitations arising ' +\n+ 'from different degrees of precision and accuracy. Users ' +\n+ 'should consult with the staff to determine which mode is ' +\n+ 'right for their application.')\nif self.clean_level in ['clean', 'dusty', 'dirty']:\nprint('WARNING: this level 2 data has no quality flags')\n- idx = []\n+ else:\n+ if self.clean_level in ['clean', 'dusty', 'dirty']:\n+ if self.clean_level in ['clean', 'dusty']:\n+ print('WARNING: this level 2 data has no quality flags')\n+\n+ idx, = np.where((self['gdalt'] > 200.0))\n+ else:\n+ print(\"WARNING: interpretation of drifts below 200 km should \" +\n+ \"always be done in partnership with the contact people\")\n# downselect data based upon cleaning conditions above\nself.data = self[idx]\n",
        "chatgpt_cot": "\"Fix the diagnostic level attribute and its property in GroupItem and NodeItem classes to solve the compilation issue in the node_tree_model.py file.\""
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/html_delegate.py b/node_manager_fkie/src/node_manager_fkie/html_delegate.py @@ -117,7 +117,7 @@ class HTMLDelegate(QStyledItemDelegate):\nname, sep, host = text.rpartition('@')\nresult = ''\nif sep:\n- result = '%s<span style=\"color:gray;\">%s%s</span>' % (name, sep, host)\n+ result = '%s<span style=\"color:#3c3c3c;\">%s%s</span>' % (name, sep, host)\nelse:\nresult = text\nelif text.find('{') > -1: # handle group names\n@@ -125,9 +125,9 @@ class HTMLDelegate(QStyledItemDelegate):\nns, sep, name = text.rpartition('/')\nresult = ''\nif sep:\n- result = '<b>{</b><span style=\"color:gray;\">%s%s</span><b>%s}</b>' % (ns, sep, name)\n+ result = '{<span style=\"color:#3c3c3c;\">%s%s</span>%s}' % (ns, sep, name)\nelse:\n- result = '<span style=\"color:gray;\">{%s}</span>' % (name)\n+ result = '<span style=\"color:#3c3c3c;\">{%s}</span>' % (name)\n# result = '<b>{</b><span style=\"color:gray;\">%s</span><b>}</b>' % (name)\n# result = '<b>{%s}</b>' % (name)\nelif text.find('[') > -1:\n@@ -152,7 +152,7 @@ class HTMLDelegate(QStyledItemDelegate):\nns, sep, name = text.rpartition('/')\nresult = ''\nif sep:\n- result = '<span style=\"color:gray;\">%s%s</span><b>%s</b>' % (ns, sep, name)\n+ result = '<span style=\"color:#3c3c3c;\">%s%s</span><b>%s</b>' % (ns, sep, name)\nelif is_node:\nresult = '<b>%s</b>' % name\nelse:\n",
        "org_msg": "node_manager_fkie: changed highlighting for namespaces and groups",
        "sim_msg": "Fixed `Make it Happen` button on System View",
        "sim_diff": "diff --git a/src/ui/src/partials/system_view.html b/src/ui/src/partials/system_view.html <td>\n<!-- <a ui-sref=\"base.namespace.system.command(getCommandStateParams(command))\"\nclass=\"btn btn-primary center-block\">Make it Happen!</a> -->\n- <a ui-sref=\"base.namespace.command({systemName: data.name, systemVersion: data.version, commandName: command.name})\"\n+ <a ui-sref=\"base.command({systemName: data.name, systemVersion: data.version, namespace: data.namespace, commandName: command.name})\"\nclass=\"btn btn-primary center-block\">Make it Happen!</a>\n</td>\n</tr>\n",
        "chatgpt_cot": "Update HTMLDelegate styling to use hex color codes for better readability and consistency in formatting."
    },
    {
        "org_diff": "diff --git a/.github/workflows/pythonactions.yml b/.github/workflows/pythonactions.yml @@ -177,14 +177,6 @@ jobs:\ndocker exec -i app4 bash -c \"tree\"\ndocker rm -f app4\n- - name: Run real_time_worker_production.py\n- run: |\n- docker run -it -d --name app5 test_image\n- docker exec -i app5 bash -c \"python test/travis_test_script.py test/real_time_worker_production.py\"\n- docker exec -i app5 bash -c \"tree\"\n- docker rm -f app5\n-\n-\n# https://github.com/JamesIves/github-pages-deploy-action\nrelease_to_github_pages:\nname: GitHub Pages\n",
        "org_msg": "Disable test 'real_time_worker_production.py'",
        "sim_msg": "DOC: Add guidance for configuring gh-pages\n* Add guidance for configuring gh-pages\nAdds instructions to configure GitHub Pages to correctly find and deploy the built files.\n* Update docs/publish/gh-pages.md",
        "sim_diff": "diff --git a/docs/publish/gh-pages.md b/docs/publish/gh-pages.md @@ -184,6 +184,17 @@ jobs:\nIf you want to deploy your site to GitHub Pages at a User and Organization repository (`<username>.github.io`), check another example workflow and available options at the README of [peaceiris/actions-gh-pages](https://github.com/peaceiris/actions-gh-pages).\n+\n+### GitHub Pages Configuration\n+\n+The settings for GitHub Pages must be configured to reflect the method used to build the docs.\n+Access a project's Pages settings at `Settings` -> `Pages`.\n+Set `Source` to `Deploy from a branch` and set `Branch` to `gh-pages`.\n+The build location should be `/ (root)` for each of the methods described here.\n+However, you may choose to place the build files in `/docs` and configure Pages accordingly.\n+\n+![Screen Shot 2022-10-20 at 7 15 30 PM](https://user-images.githubusercontent.com/13797903/197082656-bf5cbea4-1ff4-49dd-9d01-15cfe4aff67e.png)\n+\n## Use a custom domain with GitHub Pages\nBy default, GitHub Pages will host your book at a URL like `githubusername.github.io/yourbookname`.\n",
        "chatgpt_cot": "Remove real_time_worker_production.py from workflow, update docker commands, and add GitHub Pages release action."
    },
    {
        "org_diff": "diff --git a/fkie_node_manager/src/fkie_node_manager/nmd_client/monitor_channel.py b/fkie_node_manager/src/fkie_node_manager/nmd_client/monitor_channel.py @@ -102,6 +102,7 @@ class MonitorChannel(ChannelInterface):\nself.close_channel(channel, uri)\ndef kill_process(self, pid, grpc_url='grpc://localhost:12321'):\n+ if pid is not None:\nrospy.logdebug(\"kill process %d on %s\" % (pid, grpc_url))\nuri, _ = nmdurl.split(grpc_url)\nvm, channel = self.get_monitor_manager(uri)\n",
        "org_msg": "check for pid before execute",
        "sim_msg": "Removing unneeded fstrings for linting",
        "sim_diff": "diff --git a/src/app/beer_garden/local_plugins/runner.py b/src/app/beer_garden/local_plugins/runner.py @@ -94,7 +94,7 @@ class ProcessRunner(Thread):\ndef kill(self):\n\"\"\"Kill the underlying plugin process with SIGKILL\"\"\"\nif self.process and self.process.poll() is None:\n- self.logger.warning(f\"About to kill process\")\n+ self.logger.warning(\"About to kill process\")\nself.process.kill()\ndef run(self):\n@@ -137,7 +137,7 @@ class ProcessRunner(Thread):\nwhile self.process.poll() is None:\nsleep(0.1)\n- self.logger.debug(f\"About to join stream reader threads\")\n+ self.logger.debug(\"About to join stream reader threads\")\nstdout_thread.join()\nstderr_thread.join()\n@@ -156,11 +156,11 @@ class ProcessRunner(Thread):\n# check will happen before we start processing\nsleep(0.1)\n- self.logger.debug(f\"About to stop and join log processing thread\")\n+ self.logger.debug(\"About to stop and join log processing thread\")\nlog_reader.stop()\nlog_reader.join()\n- self.logger.info(f\"Plugin is officially stopped\")\n+ self.logger.info(\"Plugin is officially stopped\")\nexcept Exception as ex:\nself.logger.exception(f\"Plugin died: {ex}\")\n",
        "chatgpt_cot": "Add kill_process method to MonitorChannel to handle killing a process with a given PID and grpc URL. Fixes issue with process termination."
    },
    {
        "org_diff": "diff --git a/sc2/bot_ai.py b/sc2/bot_ai.py @@ -1700,10 +1700,10 @@ class BotAI(DistanceCalculation):\ncontinue\nunit_obj = Unit(unit, self, distance_calculation_index=index)\nindex += 1\n+ self.all_units.append(unit_obj)\nif unit.display_type == IS_PLACEHOLDER:\nself.placeholders.append(unit_obj)\ncontinue\n- self.all_units.append(unit_obj)\nalliance = unit.alliance\n# Alliance.Neutral.value = 3\nif alliance == 3:\n",
        "org_msg": "Add placeholders to self.all_units to enable distance calculation",
        "sim_msg": "added time to the saved files",
        "sim_diff": "diff --git a/bot_manager.py b/bot_manager.py @@ -178,7 +178,7 @@ class BotManager:\ncurrent_time = game_tick_packet.gameInfo.TimeSeconds\nif self.save_data and game_tick_packet.gameInfo.bRoundActive and not old_time == current_time and not current_time == -10:\n- np_input = self.input_converter.create_input_array(game_tick_packet)\n+ np_input = self.input_converter.create_input_array(game_tick_packet, passed_time=time.time() - before2)\nnp_output = np.array(controller_input, dtype=np.float32)\nself.input_array = np.append(self.input_array, np_input)\nself.output_array = np.append(self.output_array, np_output)\n",
        "chatgpt_cot": "\"Add unit_obj to all_units list to include all units in BotAI class\""
    },
    {
        "org_diff": "diff --git a/master_discovery_fkie/src/master_discovery_fkie/master_discovery.py b/master_discovery_fkie/src/master_discovery_fkie/master_discovery.py @@ -134,6 +134,8 @@ class DiscoveredMaster(object):\nself.callback_master_state = callback_master_state\nself.ts_last_request = 0\nself._errors = dict() # ERR_*, msg\n+ self.monitor_hostname = get_hostname(monitoruri)\n+ self.master_hostname = None\nself.masteruriaddr = None\n# create a thread to retrieve additional information about the remote ROS master\nself._get_into_timer = threading.Timer(0.1, self.__retrieve_masterinfo)\n@@ -355,7 +357,8 @@ class DiscoveredMaster(object):\nself.online = True\n# resolve the masteruri. Print an error if not reachable\ntry:\n- self.masteruriaddr = socket.gethostbyname(get_hostname(self.masteruri))\n+ self.master_hostname = get_hostname(self.masteruri)\n+ self.masteruriaddr = socket.gethostbyname(self.master_hostname)\nself._del_error(self.ERR_RESOLVE_NAME)\nexcept socket.gaierror:\nmsg = \"Master discovered with not known hostname ROS_MASTER_URI:='%s'. Fix your network settings!\" % str(self.masteruri)\n@@ -1060,10 +1063,8 @@ class Discoverer(object):\n# test for resolved addr\nif v.mastername is not None and not v.errors and v.masteruri != self.master_monitor.getMasteruri():\ntry:\n- o = get_hostname(v.masteruri)\n- mo = get_hostname(v.monitoruri)\n- if v.masteruriaddr != mo:\n- msg = \"Resolved host of ROS_MASTER_URI %s=%s and origin discovered IP=%s are different. Fix your network settings and restart master_dicovery!\" % (o, v.masteruriaddr, mo)\n+ if v.masteruriaddr != v.monitor_hostname:\n+ msg = \"Resolved host of ROS_MASTER_URI %s=%s and origin discovered IP=%s are different. Fix your network settings and restart master_discovery!\" % (v.master_hostname, v.masteruriaddr, v.monitor_hostname)\nif v.masteruriaddr is None or not v.masteruriaddr.startswith('127.'):\nlocal_addresses = ['localhost'] + roslib.network.get_local_addresses()\n# check 127/8 and local addresses\n",
        "org_msg": "reduced get_hostname calls",
        "sim_msg": "move concurreny control to lower layer",
        "sim_diff": "diff --git a/lbry/torrent/tracker.py b/lbry/torrent/tracker.py @@ -64,14 +64,16 @@ class UDPTrackerClientProtocol(asyncio.DatagramProtocol):\nself.transport = None\nself.data_queue = {}\nself.timeout = timeout\n+ self.semaphore = asyncio.Semaphore(10)\ndef connection_made(self, transport: asyncio.DatagramTransport) -> None:\nself.transport = transport\nasync def request(self, obj, tracker_ip, tracker_port):\nself.data_queue[obj.transaction_id] = asyncio.get_running_loop().create_future()\n- self.transport.sendto(encode(obj), (tracker_ip, tracker_port))\ntry:\n+ async with self.semaphore:\n+ self.transport.sendto(encode(obj), (tracker_ip, tracker_port))\nreturn await asyncio.wait_for(self.data_queue[obj.transaction_id], self.timeout)\nfinally:\nself.data_queue.pop(obj.transaction_id, None)\n@@ -129,7 +131,6 @@ class TrackerClient:\nself.announce_port = announce_port\nself.servers = servers\nself.results = {} # we can't probe the server before the interval, so we keep the result here until it expires\n- self.semaphore = asyncio.Semaphore(10)\nasync def start(self):\nself.transport, _ = await asyncio.get_running_loop().create_datagram_endpoint(\n@@ -163,7 +164,6 @@ class TrackerClient:\nreturn result\ntry:\ntracker_ip = await resolve_host(tracker_host, tracker_port, 'udp')\n- async with self.semaphore:\nresult = await self.client.announce(\ninfo_hash, self.node_id, self.announce_port, tracker_ip, tracker_port, stopped)\nexcept asyncio.TimeoutError:\n",
        "chatgpt_cot": "Add functionality to the DiscoveredMaster class to get and set monitor and master hostnames, and resolve the masteruri."
    },
    {
        "org_diff": "diff --git a/fkie_node_manager/src/fkie_node_manager/parameter_dialog.py b/fkie_node_manager/src/fkie_node_manager/parameter_dialog.py @@ -403,11 +403,11 @@ class ParameterDescription(object):\nelif value:\nif self.isArrayType():\nif 'int' in self.baseType() or 'byte' in self.baseType():\n- rvalue = map(int, value.lstrip('[').rstrip(']').split(','))\n+ rvalue = list(map(int, value.lstrip('[').rstrip(']').split(',')))\nelif 'float' in self.baseType():\n- rvalue = map(float, value.lstrip('[').rstrip(']').split(','))\n+ rvalue = list(map(float, value.lstrip('[').rstrip(']').split(',')))\nelif 'bool' in self.baseType():\n- rvalue = map(str2bool, value.lstrip('[').rstrip(']').split(','))\n+ rvalue = list(map(str2bool, value.lstrip('[').rstrip(']').split(',')))\nelif self.isBinaryType():\nrvalue = value\nelse:\n",
        "org_msg": "fkie_node_manager: fix for publish to topics with array values",
        "sim_msg": "adds extract_request_param to safely extract a typed value from URL parameters in the request",
        "sim_diff": "diff --git a/utils/request.py b/utils/request.py @@ -4,6 +4,7 @@ import re\n# HTK Imports\nfrom htk.utils import htk_setting\nfrom htk.utils.constants import *\n+from htk.utils.general import strtobool_safe\ndef get_current_request():\n@@ -26,6 +27,38 @@ def extract_request_ip(request):\nreturn request.environ['REMOTE_ADDR']\n+def extract_request_param(request, param, as_type=str, allow_none=True):\n+ \"\"\"Extracts a URL parameter from the request (i.e. request.GET.get)\n+\n+ - Performs basic input validation and allows typed retrieval via `as_type`\n+ - Can designate whether `None` is allowed via `allow_none`\n+ \"\"\"\n+ default_value_map = {\n+ str: '',\n+ bool: False,\n+ int: 0,\n+ float: 0,\n+ }\n+ default_value = None if allow_none else default_value_map.get(as_type, '')\n+\n+ raw_value = request.GET.get(param, default_value)\n+\n+ if as_type == str:\n+ value = raw_value\n+ elif as_type == bool:\n+ value = strtobool_safe(raw_value)\n+ elif as_type == int:\n+ m = re.match(r'^(?:\\+|\\-)?(?P<value>\\d+)\\.?$', raw_value) if raw_value else None\n+ value = int(m.group('value')) if m else default_value\n+ elif as_type == float:\n+ m = re.match(r'^(?:\\+|\\-)?(?P<value>\\d*\\.?\\d*)$', raw_value) if raw_value else None\n+ value = float(m.group('value')) if m else default_value\n+ else:\n+ value = raw_value\n+\n+ return value\n+\n+\ndef get_request_metadata(request):\npath = request.path\nurl_name = request.resolver_match.url_name\n",
        "chatgpt_cot": "fix compilation issue due to change in list conversion of array values in ParameterDescription class."
    },
    {
        "org_diff": "diff --git a/scripts/worker_node/download_images.sh b/scripts/worker_node/download_images.sh @@ -13,7 +13,7 @@ else\nfi\n# pull fabric images\n-ARCH=`uname -m | sed 's|i686|x86|' | sed 's|x86_64|x64|'`\n+ARCH=`uname -m | sed 's|i686|x86|' | sed 's|x64|x86_64|'`\nBASEIMAGE_RELEASE=0.3.2\nBASE_VERSION=1.0.5\nPROJECT_VERSION=1.0.5\n",
        "org_msg": "Update download_images.sh\nThis PR updates sed in `cello/scripts/worker_node/download_images.sh`\nand now correctly results x64 as x86_64",
        "sim_msg": "Remove contributor_breadth_worker from worker install",
        "sim_diff": "diff --git a/scripts/install/workers.sh b/scripts/install/workers.sh @@ -14,6 +14,7 @@ do\n&& $WORKER != *\"template_worker\"* \\\n&& $WORKER != *\"metric_status_worker\"* \\\n&& $WORKER != *\"__pycache__\"* \\\n+ && $WORKER != *\"contributor_breadth_worker\"* \\\n]]; then\n# make it pretty for formatting\n",
        "chatgpt_cot": "Fix architecture detection in download_images.sh script. Corrected the sed command to replace architecture names, resolving the issue with pulling fabric images."
    },
    {
        "org_diff": "diff --git a/src/api-engine/api/routes/channel/views.py b/src/api-engine/api/routes/channel/views.py @@ -91,11 +91,9 @@ class ChannelViewSet(viewsets.ViewSet):\nname=name,\nnetwork=org.network\n)\n- channel.organizations.add(org)\nchannel.save()\n+ channel.organizations.add(org)\n- org.chanel = channel\n- org.save()\n# TODO: Interact with the Fabric CLI.\nresponse = ChannelIDSerializer(data=channel.__dict__)\nif response.is_valid(raise_exception=True):\n",
        "org_msg": "Update channel creation endpoint.",
        "sim_msg": "Fixes to new streams endpoint",
        "sim_diff": "diff --git a/blueprints/apis/channel_ns.py b/blueprints/apis/channel_ns.py @@ -228,7 +228,7 @@ class api_1_Streams(Resource):\n'uuid': entry.uuid,\n'topic': entry.topic,\n'streamName': entry.streamName,\n- 'startTimestamp': entry.startTimestamp,\n+ 'startTimestamp': str(entry.startTimestamp),\n'currentViewers': entry.currentViewers,\n'totalViewers': entry.totalViewers,\n'streamURL': streamURL\n",
        "chatgpt_cot": "Fix issue with adding organization to channel in ChannelViewSet"
    },
    {
        "org_diff": "diff --git a/fkie_node_manager/src/fkie_node_manager/start_handler.py b/fkie_node_manager/src/fkie_node_manager/start_handler.py @@ -193,12 +193,18 @@ class StartHandler(object):\n@classmethod\ndef _remove_src_binary(cls, cmdlist):\nresult = []\n+ count = 0\nif len(cmdlist) > 1:\nfor c in cmdlist:\nif c.find('/src/') == -1:\nresult.append(c)\n+ count += 1\nelse:\nresult = cmdlist\n+ if count > 1:\n+ # we have more binaries in src directory\n+ # aks the user\n+ result = cmdlist\nreturn result\n",
        "org_msg": "fkie_node_manager: ask user if more then one binary in src",
        "sim_msg": "syft: revert change of remove obj metadata query in delete",
        "sim_diff": "diff --git a/packages/syft/src/syft/core/node/common/node_manager/bin_obj_manager.py b/packages/syft/src/syft/core/node/common/node_manager/bin_obj_manager.py @@ -153,6 +153,12 @@ class BinObjectManager(ObjectStore):\nobject_to_delete = (\nlocal_session.query(BinObject).filter_by(id=str(key.value)).first()\n)\n+ metadata_to_delete = (\n+ local_session.query(ObjectMetadata)\n+ .filter_by(obj=str(key.value))\n+ .first()\n+ )\n+ local_session.delete(metadata_to_delete)\nlocal_session.delete(object_to_delete)\nlocal_session.commit()\nlocal_session.close()\n",
        "chatgpt_cot": "\"Fix issue with removing src binaries in StartHandler.py by adding count check and user prompt for more binaries in src directory.\""
    },
    {
        "org_diff": "diff --git a/sc2/unit.py b/sc2/unit.py @@ -508,6 +508,7 @@ class Unit:\n:param ignore_armor:\n:param include_overkill_damage:\n\"\"\"\n+ if self.type_id not in {UnitTypeId.BATTLECRUISER, UnitTypeId.BUNKER}:\nif not self.can_attack:\nreturn 0, 0, 0\nif target.type_id != UnitTypeId.COLOSSUS:\n@@ -546,14 +547,10 @@ class Unit:\nif target_has_guardian_shield:\nenemy_armor += 2\nenemy_shield_armor += 2\n- weapon_damage = 8 + self.attack_upgrade_level if not target.is_flying else 5 + self.attack_upgrade_level\n+ weapon_damage = (8 if not target.is_flying else 5) + self.attack_upgrade_level\nweapon_damage = weapon_damage - enemy_shield_armor if target.shield else weapon_damage - enemy_armor\nreturn weapon_damage, 0.224, 6\n- required_target_type: Set[\n- int\n- ] = TARGET_BOTH if target.type_id == UnitTypeId.COLOSSUS else TARGET_GROUND if not target.is_flying else TARGET_AIR\n-\n# Fast return for bunkers, since they don't have a weapon similar to BCs\nif self.type_id == UnitTypeId.BUNKER:\nif self.is_enemy:\n@@ -565,6 +562,9 @@ class Unit:\n# TODO if bunker belongs to us, use passengers and upgrade level to calculate damage\npass\n+ required_target_type: Set[\n+ int\n+ ] = TARGET_BOTH if target.type_id == UnitTypeId.COLOSSUS else TARGET_GROUND if not target.is_flying else TARGET_AIR\n# Contains total damage, attack speed and attack range\ndamages: List[Tuple[float, float, float]] = []\nfor weapon in self._weapons:\n",
        "org_msg": "Fix BC and bunker calculation",
        "sim_msg": "Improve wording and formatting for code formatting\nMessage-Id:\nMessage-Id:",
        "sim_diff": "diff --git a/exercises/concept/ellens-alien-game/.docs/instructions.md b/exercises/concept/ellens-alien-game/.docs/instructions.md # Instructions\nEllen is making a game where the player has to fight aliens.\n-She has just learned about Object Oriented Programming (OOP) and is eager to take advantage of what this paradigm has to offer.\n+She has just learned about Object Oriented Programming (OOP) and is eager to take advantage of what using `classes` could offer her program.\nTo Ellen's delight, you have offered to help and she has given you the task of programming the aliens that the player has to fight.\n@@ -20,19 +20,20 @@ Every alien starts off with a health of 3, so initialize the `health` variable t\n3\n```\n-Now, each alien should be able to keep track of it's own position and health.\n+Now, each alien should be able to internally keep track of it's own position and health.\n## 2. The `hit` Method\nEllen would like the Alien class to have a `hit` method that decrements the health of an alien object when it is called.\n-This way, she can simply call the `hit` method instead of having to manually change an alien's health.\n+This way, she can simply call `<alien>.hit()` instead of having to manually change an alien's health.\n-For example:\n```python\n>>> alien = Alien(0, 0)\n>>> alien.health\n-3 # same as before\n+# Initialized health value.\n+3\n+# Decrements health by 1 point.\n>>> alien.hit()\n>>> alien.health\n2\n@@ -73,7 +74,8 @@ You will need to write a `teleport` function that takes new x and y positions, a\nObviously, if the aliens can be hit by something, then they need to be able to detect when such a collision has occurred.\nHowever, collision detection algorithms can be tricky, and you do not yet know how to implement one.\nEllen has said that she will do it later, but she would still like the method to appear in the class.\n-It will need to take a variable of some kind (probably another object), but that's really all you know:\n+It will need to take a variable of some kind (probably another object), but that's really all you know.\n+You will need to make sure that putting in the `method` definition into the `class` doesn't cause any errors when called:\n```python\n>>> alien.collision_detection(other_object)\n@@ -102,7 +104,7 @@ For example:\n## 7. Object Creation\nEllen loves what you've done so far, but she has a favor to ask.\n-She would like a standalone function that will create a list of alien objects, given a list of positions (as tuples).\n+She would like a standalone function that will create a `list` of alien objects, given a list of positions (as `tuples`).\nFor example:\n",
        "chatgpt_cot": "\"Fix compilation error due to new method in Unit class and update weapon damage calculation logic.\""
    },
    {
        "org_diff": "diff --git a/sc2/main.py b/sc2/main.py @@ -45,7 +45,9 @@ def run_game(map_settings, players, observe=[], realtime=False):\nstate = await client.observation()\nif len(state.observation.player_result) > 0:\n- return Result(min(state.observation.player_result, key=lambda p: p.player_id).result)\n+ result = Result(min(state.observation.player_result, key=lambda p: p.player_id).result)\n+ await client.quit()\n+ return result\ngs = GameState(state.observation, game_data)\n@@ -56,7 +58,5 @@ def run_game(map_settings, players, observe=[], realtime=False):\nawait client.step()\niteration += 1\n- await client.quit()\n-\nresult = asyncio.get_event_loop().run_until_complete(run())\nprint(result)\n",
        "org_msg": "Properly quit from the game",
        "sim_msg": "Use `mode.value` instead enumerate.",
        "sim_diff": "diff --git a/app/objects/player.py b/app/objects/player.py @@ -536,14 +536,14 @@ class Player:\nasync with app.state.services.database.connection() as db_conn:\nawait self.stats_from_sql_full(db_conn)\n- for idx, mode_stat in enumerate(self.stats.values()):\n+ for mode, stats in self.stats.items():\nawait app.state.services.redis.zadd(\n- f\"gulag:leaderboard:{idx}\",\n- {self.id: mode_stat.pp},\n+ f\"gulag:leaderboard:{mode.value}\",\n+ {self.id: stats.pp},\n)\nawait app.state.services.redis.zadd(\n- f\"gulag:leaderboard:{idx}:{self.geoloc['country']['acronym']}\",\n- {self.id: mode_stat.pp},\n+ f\"gulag:leaderboard:{mode.value}:{self.geoloc['country']['acronym']}\",\n+ {self.id: stats.pp},\n)\nif \"restricted\" in self.__dict__:\n",
        "chatgpt_cot": "\"Fix issue with client quitting prematurely in run_game method\""
    },
    {
        "org_diff": "diff --git a/.github/workflows/pythonactions.yml b/.github/workflows/pythonactions.yml @@ -27,6 +27,12 @@ jobs:\nwith:\npython-version: ${{ matrix.python-version }}\n+ - name: Cache poetry\n+ uses: actions/cache@v2\n+ with:\n+ path: ~/.cache/pypoetry/virtualenvs\n+ key: ${{ runner.os }}-${{ matrix.python-version }}-poetry-${{ hashFiles('poetry.lock') }}\n+\n- name: Install dependencies\nrun: |\npython -m pip install poetry\n",
        "org_msg": "Cache poetry packages",
        "sim_msg": "[ReactiveX] Add poetry cache",
        "sim_diff": "diff --git a/.github/workflows/pythonpackage.yml b/.github/workflows/pythonpackage.yml @@ -17,6 +17,15 @@ jobs:\nwith:\npython-version: ${{ matrix.python-version }}\n+ - name: Cache Poetry\n+ uses: actions/cache@v2\n+ with:\n+ path: |\n+ ~/.cache/pypoetry\n+ ~/Library/Caches/pypoetry\n+ C:\\Users\\*\\AppData\\Local\\pypoetry\\Cache\n+ key: poetry-cache-${{ runner.os }}-${{ env.PYTHON_VERSION }}-${{ env.POETRY_VERSION }}\n+\n- name: Install dependencies\nrun: |\npip install poetry\n",
        "chatgpt_cot": "Add caching of poetry virtual environments to improve workflow performance."
    },
    {
        "org_diff": "diff --git a/src/api-engine/api/routes/channel/views.py b/src/api-engine/api/routes/channel/views.py @@ -25,12 +25,12 @@ from api.lib.peer.channel import Channel as PeerChannel\nfrom api.lib.configtxlator.configtxlator import ConfigTxLator\nfrom api.exceptions import (\nResourceNotFound,\n+ NoResource\n)\nfrom api.models import (\nChannel,\nNode,\nOrganization,\n- Network,\n)\nfrom api.routes.channel.serializers import (\nChannelCreateBody,\n@@ -127,6 +127,16 @@ class ChannelViewSet(viewsets.ViewSet):\ntry:\norg = request.user.organization\n+ # Check if nodes are running\n+ for i in range(len(orderers)):\n+ o = Node.objects.get(id=orderers[i])\n+ if o.status != \"running\":\n+ raise NoResource\n+ for i in range(len(peers)):\n+ p = Node.objects.get(id=peers[i])\n+ if p.status != \"running\":\n+ raise NoResource\n+\nConfigTX(org.network.name).createChannel(name, [org.name])\nConfigTxGen(org.network.name).channeltx(\nprofile=name, channelid=name, outputCreateChannelTx=\"{}.tx\".format(name))\n",
        "org_msg": "Check node status before creating channels",
        "sim_msg": "Adding forgotten import on api.py",
        "sim_diff": "diff --git a/app/views/api.py b/app/views/api.py @@ -11,7 +11,7 @@ from peewee import JOIN, fn\nfrom .. import misc\nfrom ..socketio import socketio\nfrom ..models import Sub, User, Grant, Token, Client, SubPost, Sub, SubPostComment, APIToken, APITokenSettings\n-from ..models import SiteMetadata, SubPostVote, SubMetadata, SubPostCommentVote\n+from ..models import SiteMetadata, SubPostVote, SubMetadata, SubPostCommentVote, SubMod\napi = Blueprint('api', __name__)\noauth = OAuth2Provider()\n",
        "chatgpt_cot": "Add error handling for non-running nodes in ChannelViewSet to raise NoResource exception, ensuring nodes are running before creating a channel."
    },
    {
        "org_diff": "diff --git a/fkie_node_manager/src/fkie_node_manager/editor/xmlformatter.py b/fkie_node_manager/src/fkie_node_manager/editor/xmlformatter.py @@ -185,8 +185,16 @@ class Formatter():\nfor tk in iter(self):\ngetattr(tk, step)()\nresult = \"\"\n+ prev_comment = False\nfor tk in iter(self):\n- result += str(tk)\n+ tk_str = str(tk)\n+ # remove newline for wrapped items if we had comment before\n+ if prev_comment:\n+ if tk.arg[0] in self.formatter.wraped:\n+ tk_str = tk_str.replace('\\n\\n', '\\n', 1)\n+ result += tk_str\n+ if not isinstance(tk, Formatter.CharacterData):\n+ prev_comment = isinstance(tk, Formatter.Comment)\nreturn result\ndef append(self, tk):\n",
        "org_msg": "fkie_node_manager: editor: remove newline after comments",
        "sim_msg": "Preserve node id on re-edit",
        "sim_diff": "diff --git a/textext/base.py b/textext/base.py @@ -469,8 +469,10 @@ class TexText(inkex.EffectExtension):\nReplace an XML node old_node with new_node\n\"\"\"\nparent = old_node.getparent()\n+ old_id = old_node.get_id()\nparent.remove(old_node)\nparent.append(new_node)\n+ new_node.set_id(old_id)\nself.copy_style(old_node, new_node)\n@staticmethod\n",
        "chatgpt_cot": "Fix newline formatting issue in XMLFormatter by removing extra newline for wrapped items when preceded by a comment in the Formatter class."
    },
    {
        "org_diff": "diff --git a/docs/setup_worker_docker.md b/docs/setup_worker_docker.md @@ -25,6 +25,14 @@ Edit systemd service config file `/lib/systemd/system/docker.service`, update th\nExecStart=/usr/bin/dockerd -H fd:// -H unix:///var/run/docker.sock -H tcp://0.0.0.0:2375 --default-ulimit=nofile=8192:16384 --default-ulimit=nproc=8192:16384\n```\n+#### Ubuntu 16.04\n+Edit systemd service config file `usr/lib/systemd/system/docker.service`, update the `ExecStart` line under section `[Service]`, as the following:\n+\n+```\n+[Service]\n+ExecStart=/usr/bin/dockerd -H fd:// -H unix:///var/run/docker.sock -H tcp://0.0.0.0:2375 --default-ulimit=nofile=8192:16384 --default-ulimit=nproc=8192:16384\n+```\n+\nRegenerate the docker service script and restart the docker engine:\n```bash\n",
        "org_msg": "updata how set docker on ubuntu16.04\nthe old method \"Alternatively\" is invaild on ubuntu16.04,but the\nnew method is vaild.\n#done",
        "sim_msg": "Isolating the part of the docker build that fails",
        "sim_diff": "diff --git a/util/docker/backend/Dockerfile b/util/docker/backend/Dockerfile @@ -34,9 +34,10 @@ COPY ./util/docker/backend/backend.docker.config.json .\n#Might want to set these up in differant RUN statements.\nRUN set -x \\\n- && pip install . \\\n- && ./scripts/install/workers.sh \\\n- && augur config init --rc-config-file /augur/backend.docker.config.json \\\n+ && pip install .\n+\n+RUN ./scripts/install/workers.sh\n+RUN augur config init --rc-config-file /augur/backend.docker.config.json \\\n&& mkdir -p repos/ logs/\nCOPY ./util/docker/backend/entrypoint.sh /\n",
        "chatgpt_cot": "Fix docker service config file for Ubuntu 16.04 to update the `ExecStart` line under section `[Service]` to regenerate the docker service script."
    },
    {
        "org_diff": "diff --git a/fkie_node_manager_daemon/src/fkie_node_manager_daemon/launcher.py b/fkie_node_manager_daemon/src/fkie_node_manager_daemon/launcher.py @@ -433,6 +433,8 @@ def get_global_params(roscfg):\nnodesparam = False\nfor n in nodes:\nif name.startswith(n):\n+ # load global parameter which has names equal to node names\n+ if name != n:\nnodesparam = True\nbreak\nif not nodesparam:\n",
        "org_msg": "fkie_node_manager_daemon: load global parameter which has names equal to node names",
        "sim_msg": "Always walk the chain for the ambassador_id, whether we're using the superpod or not.",
        "sim_diff": "diff --git a/kat/kat/harness.py b/kat/kat/harness.py @@ -851,17 +851,28 @@ class Runner:\nsuperpods: Dict[str, Superpod] = {}\nfor n in (n for n in self.nodes if n in selected):\n- # What namespace is this node in?\n+ manifest = None\nnsp = None\n+ ambassador_id = None\n+\n+ print('manifesting for {n.path}')\n+\n+ # Walk up the parent chain to find our namespace and ambassador_id.\ncur = n\n- manifest = None\nwhile cur:\n+ if not nsp:\nnsp = getattr(cur, 'namespace', None)\n+ print(f'... {cur.name} has namespace {nsp}')\n- if nsp:\n+ if not ambassador_id:\n+ ambassador_id = getattr(cur, 'ambassador_id', None)\n+ print(f'... {cur.name} has ambassador_id {ambassador_id}')\n+\n+ if nsp and ambassador_id:\n+ print(f'... good for namespace and ambassador_id')\nbreak\n- else:\n+\ncur = cur.parent\n# OK. Does this node want to use a superpod?\n@@ -876,19 +887,6 @@ class Runner:\nprint(f'superpodifying {n.name}')\n- cur = n\n- kat_ambassador_id = None\n-\n- while cur:\n- kat_ambassador_id = getattr(cur, 'ambassador_id', None)\n-\n- if kat_ambassador_id:\n- print(f'... found ambassador_id in {cur.name}')\n- break\n- else:\n- print(f'... no ambassador_id in {cur.name}')\n- cur = cur.parent\n-\n# Next up: use the BACKEND_SERVICE manifest as a template...\nyaml = n.format(BACKEND_SERVICE)\nmanifest = load(n.path, yaml, Tag.MAPPING)\n@@ -901,8 +899,8 @@ class Runner:\nm['spec']['selector']['backend'] = superpod.name\n# ...and labels if needed...\n- if kat_ambassador_id:\n- m['metadata']['labels'] = { 'kat-ambassador-id': kat_ambassador_id }\n+ if ambassador_id:\n+ m['metadata']['labels'] = { 'kat-ambassador-id': ambassador_id }\n# ...and target ports.\nsuperpod_ports = superpod.allocate(n.path.k8s)\n@@ -929,9 +927,6 @@ class Runner:\nif 'labels' not in metadata:\nmetadata['labels'] = {}\n- # Does it have an ambassador_id?\n- ambassador_id = getattr(n, 'ambassador_id', None)\n-\nif ambassador_id:\nmetadata['labels']['kat-ambassador-id'] = ambassador_id\n",
        "chatgpt_cot": "Add logic to load global parameters for node names different from the node name itself in get_global_params function."
    },
    {
        "org_diff": "diff --git a/fkie_node_manager/src/fkie_node_manager/master_view_proxy.py b/fkie_node_manager/src/fkie_node_manager/master_view_proxy.py @@ -2437,11 +2437,12 @@ class MasterViewProxy(QWidget):\nfinally:\nsocket.setdefaulttimeout(None)\n# wait kill_on_stop is an integer\n+ if node.pid is not None:\nif hasattr(node, 'kill_on_stop') and isinstance(node.kill_on_stop, (int, float)):\ntime.sleep(float(node.kill_on_stop) / 1000.0)\nnm.nmd().monitor.kill_process(node.pid, nmdurl.nmduri(node.masteruri))\nelif not success:\n- if node.pid and node.name != '/node_manager_daemon':\n+ if node.name != '/node_manager_daemon':\nrospy.loginfo(\"Try to kill process %d of the node: %s\", node.pid, utf8(node.name))\nnm.nmd().monitor.kill_process(node.pid, nmdurl.nmduri(node.masteruri))\nelif isinstance(node, NodeItem) and node.is_ghost:\n",
        "org_msg": "fkie_node_manager: fix error on stop nodes",
        "sim_msg": "handle early lbrycrd exit in tests",
        "sim_diff": "diff --git a/lbry/wallet/orchstr8/node.py b/lbry/wallet/orchstr8/node.py @@ -228,6 +228,7 @@ class BlockchainProcess(asyncio.SubprocessProtocol):\ndef process_exited(self):\nself.stopped.set()\n+ self.ready.set()\nclass BlockchainNode:\n@@ -315,6 +316,7 @@ class BlockchainNode:\nBlockchainProcess, *command\n)\nawait self.protocol.ready.wait()\n+ assert not self.protocol.stopped.is_set()\nasync def stop(self, cleanup=True):\ntry:\n",
        "chatgpt_cot": "\"Fix issue with kill_on_stop integer check and node name comparison for process kill in MasterViewProxy file\""
    },
    {
        "org_diff": "diff --git a/sc2/unit.py b/sc2/unit.py @@ -525,13 +525,13 @@ class Unit(PassengerUnit):\n@property_immutable_cache\ndef is_attacking(self) -> bool:\n\"\"\" Checks if the unit is attacking. \"\"\"\n- return self.orders and self.orders[0].ability.id in {\n+ return self.is_using_ability({\nAbilityId.ATTACK,\nAbilityId.ATTACK_ATTACK,\nAbilityId.ATTACK_ATTACKTOWARDS,\nAbilityId.ATTACK_ATTACKBARRAGE,\nAbilityId.SCAN_MOVE,\n- }\n+ })\n@property_immutable_cache\ndef is_patrolling(self) -> bool:\n@@ -551,12 +551,12 @@ class Unit(PassengerUnit):\n@property_immutable_cache\ndef is_collecting(self) -> bool:\n\"\"\" Checks if a unit is gathering or returning. \"\"\"\n- return self.orders and self.orders[0].ability.id in {AbilityId.HARVEST_GATHER, AbilityId.HARVEST_RETURN}\n+ return self.is_using_ability({AbilityId.HARVEST_GATHER, AbilityId.HARVEST_RETURN})\n@property_immutable_cache\ndef is_constructing_scv(self) -> bool:\n\"\"\" Checks if the unit is an SCV that is currently building. \"\"\"\n- return self.orders and self.orders[0].ability.id in {\n+ return self.is_using_ability({\nAbilityId.TERRANBUILD_ARMORY,\nAbilityId.TERRANBUILD_BARRACKS,\nAbilityId.TERRANBUILD_BUNKER,\n@@ -570,16 +570,16 @@ class Unit(PassengerUnit):\nAbilityId.TERRANBUILD_SENSORTOWER,\nAbilityId.TERRANBUILD_STARPORT,\nAbilityId.TERRANBUILD_SUPPLYDEPOT,\n- }\n+ })\n@property_immutable_cache\ndef is_repairing(self) -> bool:\n\"\"\" Checks if the unit is an SCV or MULE that is currently repairing. \"\"\"\n- return self.orders and self.orders[0].ability.id in {\n+ return self.is_using_ability({\nAbilityId.EFFECT_REPAIR,\nAbilityId.EFFECT_REPAIR_MULE,\nAbilityId.EFFECT_REPAIR_SCV,\n- }\n+ })\n@property_immutable_cache\ndef add_on_tag(self) -> int:\n",
        "org_msg": "Use is_using_ability for more things",
        "sim_msg": "Use using instead of ._state.db everywhere",
        "sim_diff": "diff --git a/cacheops/query.py b/cacheops/query.py @@ -427,11 +427,11 @@ class ManagerMixin(object):\nif cls.__module__ != '__fake__' and family_has_profile(cls):\nself._install_cacheops(cls)\n- def _pre_save(self, sender, instance, **kwargs):\n+ def _pre_save(self, sender, instance, using, **kwargs):\nif not (instance.pk is None or instance._state.adding or no_invalidation.active):\ntry:\n- _old_objs.__dict__[sender, instance.pk] = sender.objects. \\\n- using(instance._state.db).get(pk=instance.pk)\n+ _old_objs.__dict__[sender, instance.pk] \\\n+ = sender.objects.using(using).get(pk=instance.pk)\nexcept sender.DoesNotExist:\npass\n@@ -446,7 +446,7 @@ class ManagerMixin(object):\ninvalidate_obj(instance, using=using)\n# We run invalidations but skip caching if we are dirty\n- if transaction_states[instance._state.db].is_dirty():\n+ if transaction_states[using].is_dirty():\nreturn\n# NOTE: it's possible for this to be a subclass, e.g. proxy, without cacheprofile,\n",
        "chatgpt_cot": "Refactor is_attacking, is_patrolling, is_collecting, is_constructing_scv, is_repairing methods to use is_using_ability and AbilityId enum for better code readability."
    },
    {
        "org_diff": "diff --git a/sc2/client.py b/sc2/client.py @@ -74,6 +74,7 @@ class Client(Protocol):\nreturn result.join_game.player_id\nasync def leave(self):\n+ \"\"\" You can use 'await self._client.leave()' to surrender midst game. \"\"\"\nis_resign = self._game_result is None\nif is_resign:\n",
        "org_msg": "Add surrender hint",
        "sim_msg": "don't enqueue match start packet to lobby",
        "sim_diff": "diff --git a/app/objects/match.py b/app/objects/match.py @@ -443,7 +443,7 @@ class Match:\nno_map.append(s.player.id)\nself.in_progress = True\n- self.enqueue(packets.match_start(self), immune=no_map)\n+ self.enqueue(packets.match_start(self), immune=no_map, lobby=False)\nself.enqueue_state()\ndef reset_scrim(self) -> None:\n",
        "chatgpt_cot": "Add docstring to leave method in Client class. The docstring provides information on how to surrender midst game using the leave method."
    },
    {
        "org_diff": "diff --git a/examples/simulate_fight_scenario.py b/examples/simulate_fight_scenario.py @@ -39,8 +39,6 @@ class FightBot(BotAI):\nif not self.fight_started and self.enemy_location and not self.enemy_units(UnitTypeId.SCV) and not self.units(UnitTypeId.SCV):\nfor u in self.enemy_units:\nu.attack(self.start_location)\n- for u in self.units:\n- u.attack(self.enemy_location)\nself.fight_started = True\n# in case of no units left - do not wait for game to finish\n@@ -49,12 +47,12 @@ class FightBot(BotAI):\nawait self._client.quit() # or reset level\nfor u in self.units(UnitTypeId.MARINE):\n- u.attack(self.enemy_structures.first.position)\n+ u.attack(self.enemy_location)\n# TODO: implement your fight logic here\n# if u.weapon_cooldown:\n- # u.move(u.position.towards(self.structures.first.position))\n+ # u.move(u.position.towards(self.start_location))\n# else:\n- # u.attack(self.enemy_structures.first.position)\n+ # u.attack(self.enemy_location)\n# pass\n",
        "org_msg": "unwanted buildings replaced with start locations",
        "sim_msg": "[baron] leave reason, optional args",
        "sim_diff": "diff --git a/baron/baron.py b/baron/baron.py import asyncio\n-from typing import Literal\n+from typing import Literal, Optional\nimport discord\nfrom redbot.core import commands\n+from redbot.core.commands import GuildConverter\nfrom redbot.core.bot import Red\nfrom redbot.core.config import Config\nfrom redbot.core.utils.chat_formatting import box, humanize_list, pagify\n@@ -145,7 +146,7 @@ class Baron(commands.Cog):\nawait ctx.tick()\n@baron.command()\n- async def minmembers(self, ctx: commands.Context, limit: int = 0):\n+ async def minmembers(self, ctx: commands.Context, limit: Optional[int] = 0):\n\"\"\"Set the minimum number of members a server should have for the bot to stay in it.\nPass 0 to disable.\"\"\"\n@@ -157,7 +158,7 @@ class Baron(commands.Cog):\n)\n@baron.command()\n- async def botratio(self, ctx: commands.Context, ratio: int = 0):\n+ async def botratio(self, ctx: commands.Context, ratio: Optional[int] = 0):\n\"\"\"Set the bot ratio for servers for the bot to leave.\nPass 0 to disable.\"\"\"\n@@ -171,7 +172,7 @@ class Baron(commands.Cog):\n)\n@baron.command()\n- async def botfarms(self, ctx: commands.Context, rate: int = 75, page_limit: int = 500):\n+ async def botfarms(self, ctx: commands.Context, rate: Optional[int] = 75, page_limit: Optional[int] = 500):\n\"\"\"View servers that have a bot to member ratio with the given rate.\"\"\"\nif rate not in range(1, 100):\nraise commands.BadArgument\n@@ -221,7 +222,7 @@ class Baron(commands.Cog):\n@baron.command()\nasync def members(\n- self, ctx: commands.Context, members: int, less_than: bool = True, page_limit: int = 500\n+ self, ctx: commands.Context, members: int, less_than: Optional[bool] = True, page_limit: Optional[int] = 500\n):\n\"\"\"View servers that have a member count less than the specified number.\n@@ -278,8 +279,8 @@ class Baron(commands.Cog):\nself,\nctx: commands.Context,\ncommands: int,\n- highest_first: bool = False,\n- page_limit: int = 500,\n+ highest_first: Optional[bool] = False,\n+ page_limit: Optional[int] = 500,\n):\n\"\"\"View servers that have command usage less than the specified number.\n@@ -347,11 +348,11 @@ class Baron(commands.Cog):\n\"\"\"Manage leaving servers.\"\"\"\n@leave.command()\n- async def mass(self, ctx: commands.Context, guilds: commands.Greedy[commands.GuildConverter]):\n+ async def mass(self, ctx: commands.Context, guilds: commands.Greedy[GuildConverter], *, reason: Optional[str] = \"I have left this server at the request of my owner.\"):\n\"\"\"Leave servers from a list of IDs.\"\"\"\nif not guilds:\nraise commands.BadArgument\n- await self.leave_guilds(ctx, guilds, \"I have left this server at the request of my owner.\")\n+ await self.leave_guilds(ctx, guilds, reason)\n@leave.command(name=\"botfarms\")\nasync def leave_botfarms(self, ctx: commands.Context, rate: int = 75):\n",
        "chatgpt_cot": "Refactor fight logic in FightBot for better targeting and movement. Removed redundant attack commands and adjusted movement logic based on unit cooldown."
    },
    {
        "org_diff": "diff --git a/node_manager_daemon_fkie/src/node_manager_daemon_fkie/file_servicer.py b/node_manager_daemon_fkie/src/node_manager_daemon_fkie/file_servicer.py @@ -274,8 +274,18 @@ class FileServicer(fms_grpc.FileServiceServicer):\nif not request.path:\n# list ROS root items\nfor p in os.getenv('ROS_PACKAGE_PATH').split(':'):\n+ try:\npath = os.path.normpath(p)\n- path_list.append(fms.PathObj(path=path, mtime=os.path.getmtime(path), size=os.path.getsize(path), type=PATH_DIR, ))\n+ fileList = os.listdir(path)\n+ file_type = None\n+ if is_package(fileList):\n+ file_type = PATH_PACKAGE\n+ else:\n+ file_type = PATH_DIR\n+ self.DIR_CACHE[path] = file_type\n+ path_list.append(fms.PathObj(path=path, mtime=os.path.getmtime(path), size=os.path.getsize(path), type=file_type))\n+ except Exception as _:\n+ pass\nelse:\ntry:\n# list the path\n",
        "org_msg": "node_manager_daemon_fkie: fixed package detection in the ROOT package pach",
        "sim_msg": "use path cache",
        "sim_diff": "diff --git a/source_shared/vpk/vpk_file.py b/source_shared/vpk/vpk_file.py @@ -17,7 +17,7 @@ class VPKFile:\nself.entries: Dict[str, List[Entry]] = {}\nself.archive_md5_entries: List[ArchiveMD5Entry] = []\n- self.path_cache = []\n+ self.path_cache = {}\nself.tree_hash = b''\nself.archive_md5_hash = b''\n@@ -67,7 +67,7 @@ class VPKFile:\nfull_path = Path(f'{directory_name}/{file_name}.{type_name}')\nentry = Entry(full_path)\nentry.read(reader)\n- self.path_cache.append(full_path)\n+ self.path_cache[full_path] = entry\nif reader.read_uint16() != 0xFFFF:\nraise NotImplementedError('Invalid terminator')\n@@ -95,21 +95,27 @@ class VPKFile:\nfull_path = Path(full_path)\nif full_path.is_absolute():\nfull_path = full_path.relative_to(self.filepath.parent)\n- ext = Path(full_path).suffix.strip('./\\\\')\n- for entry in self.entries.get(ext.lower(), []):\n- if entry.file_name == full_path:\n- return entry\n- return None\n+\n+ # ext = Path(full_path).suffix.strip('./\\\\')\n+ # for entry in self.entries.get(ext.lower(), []):\n+ # if entry.file_name == full_path:\n+ # return entry\n+ # return None\nelif file_type and directory and file_name:\nfile_type = file_type.strip('./\\\\')\ndirectory = directory.strip('./\\\\')\nfile_name = Path(file_name.strip('./\\\\')).stem\n- for entry in self.entries.get(file_type, []):\n- if entry.directory_name == directory and entry.file_name == file_name:\n- return entry\n- return None\n+ full_path = Path(f'{directory}/{file_name}.{file_type}')\nelse:\nraise Exception(\"No valid parameters were given\")\n+ # for entry in self.entries.get(file_type, []):\n+ # if entry.directory_name == directory and entry.file_name == file_name:\n+ # return entry\n+ # return None\n+ entry = self.path_cache.get(full_path,None)\n+ if entry:\n+ return entry\n+\ndef read_file(self, entry: Entry) -> BytesIO:\nif entry.archive_id == 0x7FFF:\n",
        "chatgpt_cot": "\"Add caching for directory types and package types to improve file service performance.\""
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/CMakeLists.txt b/node_manager_fkie/CMakeLists.txt @@ -55,7 +55,12 @@ install(\n)\n# On Ubuntu, create and install a desktop launcher for node_manager.\n-if (${CMAKE_SYSTEM_NAME} STREQUAL Linux)\n+find_program(DFI desktop-file-install)\n+if (NOT DFI)\n+ message(STATUS \"Skip installing Unity desktop launcher: desktop-file-install not found!\")\n+endif()\n+\n+if ((${CMAKE_SYSTEM_NAME} STREQUAL Linux) AND (EXISTS ${DFI}))\n# Define where to create the launcher file.\nset(NODE_MANAGER_LAUNCHER ${CMAKE_CURRENT_BINARY_DIR}/node_manager.desktop)\n@@ -74,4 +79,4 @@ Categories=Utility;Development;\"\n# Install the launcher file.\ninstall(CODE \"set(NODE_MANAGER_LAUNCHER \\\"${NODE_MANAGER_LAUNCHER}\\\")\")\ninstall(SCRIPT InstallLauncher.cmake)\n-endif(${CMAKE_SYSTEM_NAME} STREQUAL Linux)\n+endif()\n",
        "org_msg": "node_manager_fkie: removed install author warning",
        "sim_msg": "Add basic test for CLion integration",
        "sim_diff": "diff --git a/tests/commands/test_init.py b/tests/commands/test_init.py @@ -16,6 +16,10 @@ import json\nfrom os import getcwd, makedirs\nfrom os.path import getsize, isdir, isfile, join\n+import pytest\n+\n+from platformio import proc\n+from platformio.commands import platform as cli_platform\nfrom platformio.commands.boards import cli as cmd_boards\nfrom platformio.commands.project import project_init as cmd_init\nfrom platformio.project.config import ProjectConfig\n@@ -177,3 +181,83 @@ def test_init_incorrect_board(clirunner):\nassert result.exit_code == 2\nassert \"Error: Invalid value for\" in result.output\nassert isinstance(result.exception, SystemExit)\n+\n+\n+@pytest.mark.skipif(not proc.is_ci(), reason=\"runs on CI\")\n+def test_init_ide_clion(clirunner, isolated_pio_core, validate_cliresult, tmpdir):\n+ result = clirunner.invoke(\n+ cli_platform.platform_install,\n+ [\n+ \"ststm32\",\n+ \"--skip-default-package\",\n+ \"--with-package\",\n+ \"tool-cmake\",\n+ \"--with-package\",\n+ \"tool-ninja\",\n+ ],\n+ )\n+\n+ # Add extra libraries to cover cases with possible unwanted backslashes\n+ lib_extra_dirs = isolated_pio_core.join(\"extra_libs\").mkdir()\n+ extra_lib = lib_extra_dirs.join(\"extra_lib\").mkdir()\n+ extra_lib.join(\"extra_lib.h\").write(\" \")\n+ extra_lib.join(\"extra_lib.cpp\").write(\" \")\n+\n+ with tmpdir.as_cwd():\n+ result = clirunner.invoke(\n+ cmd_init,\n+ [\n+ \"-b\",\n+ \"nucleo_f401re\",\n+ \"--ide\",\n+ \"clion\",\n+ \"--project-option\",\n+ \"framework=arduino\",\n+ \"--project-option\",\n+ \"lib_extra_dirs=%s\" % str(lib_extra_dirs),\n+ ],\n+ )\n+\n+ validate_cliresult(result)\n+ assert all(isfile(f) for f in (\"CMakeLists.txt\", \"CMakeListsPrivate.txt\"))\n+\n+ tmpdir.join(\"src\").join(\"main.cpp\").write(\n+ \"\"\"#include <Arduino.h>\n+#include \"extra_lib.h\"\n+void setup(){}\n+void loop(){}\n+\"\"\"\n+ )\n+ cmake_path = str(\n+ isolated_pio_core.join(\"packages\")\n+ .join(\"tool-cmake\")\n+ .join(\"bin\")\n+ .join(\"cmake\")\n+ )\n+ tmpdir.join(\"build_dir\").mkdir()\n+ result = proc.exec_command(\n+ [\n+ cmake_path,\n+ \"-DCMAKE_BUILD_TYPE=nucleo_f401re\",\n+ \"-DCMAKE_MAKE_PROGRAM=%s\"\n+ % str(\n+ isolated_pio_core.join(\"packages\").join(\"tool-ninja\").join(\"ninja\")\n+ ),\n+ \"-G\",\n+ \"Ninja\",\n+ \"-S\",\n+ str(tmpdir),\n+ \"-B\",\n+ \"build_dir\",\n+ ]\n+ )\n+\n+ # Check if CMake was able to generate a native project for Ninja\n+ assert result[\"returncode\"] == 0, result[\"out\"]\n+\n+ result = proc.exec_command(\n+ [cmake_path, \"--build\", \"build_dir\", \"--target\", \"Debug\"]\n+ )\n+\n+ assert result[\"returncode\"] == 0\n+ assert \"[SUCCESS]\" in str(result[\"out\"])\n",
        "chatgpt_cot": "Add check for desktop-file-install presence and skip installation if not found to prevent errors on Linux systems."
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/echo_dialog.py b/node_manager_fkie/src/node_manager_fkie/echo_dialog.py @@ -287,6 +287,7 @@ class EchoDialog(QDialog):\nexcept ValueError:\nself.maxLenStringComboBox.setEditText(str(self.line_limit))\nself.display.clear()\n+ with self.lock:\nfor msg, current_time in self._msgs:\nself._append_message(msg, self._latched, current_time, False)\n@@ -297,6 +298,7 @@ class EchoDialog(QDialog):\nself.digits_after_in_array = None\nself.maxDigitsComboBox.setEditText('')\nself.display.clear()\n+ with self.lock:\nfor msg, current_time in self._msgs:\nself._append_message(msg, self._latched, current_time, False)\n@@ -311,6 +313,7 @@ class EchoDialog(QDialog):\nself.chars_limit = 0\nself.receiving_hz = 0\nself.display.clear()\n+ with self.lock:\nfor msg, current_time in self._msgs:\nself._append_message(msg, self._latched, current_time, False)\n@@ -326,6 +329,7 @@ class EchoDialog(QDialog):\nself.maxLenComboBox.setEditText(str(self.chars_limit))\nif update_display:\nself.display.clear()\n+ with self.lock:\nfor msg, current_time in self._msgs:\nself._append_message(msg, self._latched, current_time, False)\n@@ -341,6 +345,7 @@ class EchoDialog(QDialog):\nself.maxHzComboBox.setEditText(str(self.receiving_hz))\nif update_display:\nself.display.clear()\n+ with self.lock:\nfor msg, current_time in self._msgs:\nself._append_message(msg, self._latched, current_time, False)\n@@ -354,6 +359,7 @@ class EchoDialog(QDialog):\ndef on_clear_btn_clicked(self):\nself.display.clear()\nwith self.lock:\n+ del self._msgs[:]\nself.message_count = 0\nself._scrapped_msgs = 0\ndel self.times[:]\n@@ -393,6 +399,7 @@ class EchoDialog(QDialog):\ncurrent_time = time.time()\nself._latched = latched\nif store:\n+ with self.lock:\nself._msgs.append((msg, current_time))\nif len(self._msgs) > 25:\nself._msgs.pop()\n",
        "org_msg": "node_manager_fkie: fixed clear in echo dialog",
        "sim_msg": "checkbox to scroll transcript when video plays\nwhen checked textEdit_transcription scrolls to timestamps, and is read only.",
        "sim_diff": "diff --git a/qualcoder/view_av.py b/qualcoder/view_av.py @@ -1588,7 +1588,7 @@ class DialogViewAV(QtWidgets.QDialog):\nself.setFont(newfont)\nself.setWindowTitle(self.media_data['mediapath'])\n- # Get the transcribed text and fill textedit\n+ # Get the transcription text and fill textedit\ncur = self.settings['conn'].cursor()\ncur.execute(\"select id, fulltext from source where name = ?\", [media_data['name'] + \".transcribed\"])\nself.transcription = cur.fetchone()\n@@ -1662,8 +1662,20 @@ class DialogViewAV(QtWidgets.QDialog):\nself.timer = QtCore.QTimer(self)\nself.timer.setInterval(100)\nself.timer.timeout.connect(self.update_ui)\n+\n+ self.ui.checkBox_scroll_transcript.stateChanged.connect(self.scroll_transcribed_checkbox_changed)\n#self.play_pause()\n+ def scroll_transcribed_checkbox_changed(self):\n+ \"\"\" If checked, then cannot edit the textEdit_transcribed. \"\"\"\n+\n+ if self.ui.checkBox_scroll_transcript.isChecked():\n+ self.ui.textEdit_transcription.setReadOnly(True)\n+ else:\n+ # redo timestamps as text may have been changed by user\n+ self.get_timestamps_from_transcription()\n+ self.ui.textEdit_transcription.setReadOnly(False)\n+\ndef get_timestamps_from_transcription(self):\n\"\"\" Get a list of starting/ending characterpositions and time in milliseconds\nfrom transcribed text file.\n@@ -1825,7 +1837,7 @@ class DialogViewAV(QtWidgets.QDialog):\nvideo's current position.\ntime_postion list itme: [text_pos0, text_pos1, milliseconds]\n\"\"\"\n- if self.transcription is not None or self.ui.textEdit_transcription.toPlainText() != \"\":\n+ if self.ui.checkBox_scroll_transcript.isChecked() and self.transcription is not None and self.ui.textEdit_transcription.toPlainText() != \"\":\ntext_pos = 0\nfor i in range(1, len(self.time_positions)):\nif msecs > self.time_positions[i - 1][2] and msecs < self.time_positions[i][2]:\n",
        "chatgpt_cot": "Add lock to protect the data access in EchoDialog class."
    },
    {
        "org_diff": "diff --git a/test/test_pickled_data.py b/test/test_pickled_data.py @@ -110,7 +110,8 @@ class TestClass:\nbot._game_info.map_ramps, bot._game_info.vision_blockers = bot._game_info._find_ramps_and_vision_blockers()\nassert bot.main_base_ramp # Test if any ramp was found\n# TODO: Cache all expansion positions for a map and check if it is the same\n- assert len(bot.expansion_locations) >= 10\n+ assert len(bot.expansion_locations) >= 10, f\"Too few expansions found: {len(bot.expansion_locations)}\"\n+ assert len(bot.expansion_locations) <= 20, f\"Too many expansions found: {len(bot.expansion_locations)}\"\n# On N player maps, it is expected that there are N*X bases because of symmetry, at least for 1vs1 maps\nassert (\nlen(bot.expansion_locations) % (len(bot.enemy_start_locations) + 1) == 0\n",
        "org_msg": "Change tests to test expansion amount",
        "sim_msg": "Remove TileMap from bulk Testing, needs an individual test written.",
        "sim_diff": "diff --git a/tests/base/test_maps.py b/tests/base/test_maps.py @@ -18,7 +18,7 @@ MAPS_TO_EXCLUDE_2D = [\n\"ParametricCasingAndLayer\",\n\"ParametricLayer\", \"ParametricBlockInLayer\",\n\"Projection\", \"SelfConsistentEffectiveMedium\",\n- \"SumMap\", \"SurjectUnits\"\n+ \"SumMap\", \"SurjectUnits\", \"TileMap\"\n]\nMAPS_TO_EXCLUDE_3D = [\n\"ComboMap\", \"ActiveCells\", \"InjectActiveCells\",\n@@ -29,7 +29,7 @@ MAPS_TO_EXCLUDE_3D = [\n\"SplineMap\", \"ParametricCasingAndLayer\",\n\"ParametricLayer\", \"ParametricBlockInLayer\",\n\"Projection\", \"SelfConsistentEffectiveMedium\",\n- \"SumMap\", \"SurjectUnits\"\n+ \"SumMap\", \"SurjectUnits\", \"TileMap\"\n]\n",
        "chatgpt_cot": "Add assertions for expansion locations in TestClass to ensure a minimum and maximum number of expansions are found."
    },
    {
        "org_diff": "diff --git a/scripts/worker_node_setup/download_images.sh b/scripts/worker_node_setup/download_images.sh @@ -17,7 +17,7 @@ BASEIMAGE_RELEASE=0.3.1\nBASE_VERSION=1.0.0\nPROJECT_VERSION=1.0.0-rc1\n-IMG_VERSION=1.0.0-rc1\n+IMG_VERSION=v1.0.0-rc1\n# latest is only For testing latest images\necho_b \"Downloading images from DockerHub... need a while\"\n",
        "org_msg": "Fix fabric images tag\nChange IMG_version from 1.0.0.rc1 to v1.0.0.rc1",
        "sim_msg": "Simplifies and fix docker images tests on release",
        "sim_diff": "diff --git a/.github/workflows/docker_release.yml b/.github/workflows/docker_release.yml @@ -50,14 +50,16 @@ jobs:\n- name: Test base images\nrun: |\nEXPECTED_VERSION=$(cat VERSION.txt)\n- VERSION=$(docker run --rm deepset/haystack:base-cpu-${{ steps.meta.outputs.version }} --platform linux/amd64 python -c\"import haystack; print(haystack.__version__)\")\n- [[ \"$VERSION\" = \"$EXPECTED_VERSION\" ]]\n- VERSION=$(docker run --rm deepset/haystack:base-gpu-${{ steps.meta.outputs.version }} --platform linux/amd64 python -c\"import haystack; print(haystack.__version__)\")\n- [[ \"$VERSION\" = \"$EXPECTED_VERSION\" ]]\n- VERSION=$(docker run --rm deepset/haystack:base-cpu-${{ steps.meta.outputs.version }} --platform linux/arm64 python -c\"import haystack; print(haystack.__version__)\")\n- [[ \"$VERSION\" = \"$EXPECTED_VERSION\" ]]\n- VERSION=$(docker run --rm deepset/haystack:base-gpu-${{ steps.meta.outputs.version }} --platform linux/arm64 python -c\"import haystack; print(haystack.__version__)\")\n- [[ \"$VERSION\" = \"$EXPECTED_VERSION\" ]]\n+ function test_image {\n+ local TAG=$1\n+ local PLATFORM=$2\n+ local VERSION=$(docker run --platform $PLATFORM --rm deepset/haystack:$TAG python -c\"import haystack; print(haystack.__version__)\")\n+ [[ \"$VERSION\" = \"$EXPECTED_VERSION\" ]] || echo \"::error 'Haystack version in deepset/haystack:$TAG image for $PLATFORM is different from expected'\"\n+ }\n+ test_image base-cpu-${{ steps.meta.outputs.version }} linux/amd64\n+ test_image base-gpu-${{ steps.meta.outputs.version }} linux/amd64\n+ test_image base-cpu-${{ steps.meta.outputs.version }} linux/arm64\n+ test_image base-gpu-${{ steps.meta.outputs.version }} linux/arm64\n- name: Build api images\nuses: docker/bake-action@v2\n@@ -110,4 +112,4 @@ jobs:\nsleep 15s\nEXPECTED_VERSION=$(cat VERSION.txt)\nVERSION=$(curl http://localhost:8000/hs_version | jq .hs_version)\n- [[ \"$VERSION\" = \"$EXPECTED_VERSION\" ]]\n+ [[ \"$VERSION\" = \"$EXPECTED_VERSION\" ]] || echo \"::error 'Haystack version in REST API image is different from expected'\"\n",
        "chatgpt_cot": "Update IMG_VERSION to v1.0.0-rc1 to match the versioning convention and fix compilation issue in download_images.sh."
    },
    {
        "org_diff": "diff --git a/rasa_core_sdk/forms.py b/rasa_core_sdk/forms.py @@ -6,7 +6,7 @@ from __future__ import unicode_literals\nimport logging\nimport typing\n-from typing import Dict, Text, Any, List\n+from typing import Dict, Text, Any, List, Union\nfrom rasa_core_sdk import Action, ActionExecutionError\nfrom rasa_core_sdk.events import SlotSet, Form\n@@ -37,23 +37,32 @@ class FormAction(Action):\nraise NotImplementedError(\"A form must implement required slots \"\n\"that it has to fill\")\n+ def slot_mapping(self):\n+ # type: () -> Dict[Text: Union[Text, List[Text]]]\n+ \"\"\"A dictionary to map required slots to extracted entities\"\"\"\n+\n+ return dict(zip(self.required_slots(), self.required_slots()))\n+\n# noinspection PyUnusedLocal\ndef validate(self, dispatcher, tracker, domain):\n# type: (CollectingDispatcher, Tracker, Dict[Text, Any]) -> List[Dict]\n\"\"\"\"Validate the user input else return an error\"\"\"\n+ slot_to_fill = tracker.slots[REQUESTED_SLOT]\n+\n+ # map requested_slot to entity\n+ required_entities = self.slot_mapping().get(slot_to_fill)\n+\n+ if required_entities:\n+ if isinstance(required_entities, str):\n+ required_entities = [required_entities]\n- events = []\nfor e in tracker.latest_message[\"entities\"]:\n- if e.get(\"entity\") == tracker.slots[REQUESTED_SLOT]:\n- events.append(SlotSet(e['entity'], e['value']))\n+ if e.get(\"entity\") in required_entities:\n+ return [SlotSet(slot_to_fill, e['value'])]\n- if events:\n- return events\n- else:\nraise ActionExecutionError(\"Failed to validate slot {0} \"\n\"with action {1}\"\n- \"\".format(tracker.slots[REQUESTED_SLOT],\n- self.name()),\n+ \"\".format(slot_to_fill, self.name()),\nself.name())\ndef submit(self, dispatcher, tracker, domain):\n",
        "org_msg": "refactor forms RasaHQ/roadmap#263",
        "sim_msg": "fix ret_dict.setdefault()",
        "sim_diff": "diff --git a/src/genie/libs/parser/iosxe/show_platform.py b/src/genie/libs/parser/iosxe/show_platform.py @@ -3339,12 +3339,11 @@ class ShowPlatformPower(ShowPlatformPowerSchema):\nslot = m.groupdict()['slot']\nt = m.groupdict()['type']\nstate = m.groupdict()['state']\n- allocation = m.groupdict()['allocation']\n- ret_dict.setdefault('slot', {})\n- ret_dict['slot'].setdefault(slot, {})\n- ret_dict['slot'][slot]['type'] = t\n- ret_dict['slot'][slot]['state'] = state\n- ret_dict['slot'][slot]['allocation'] = float(allocation)\n+ allocation = float(m.groupdict()['allocation'])\n+ slot_dict = ret_dict.setdefault('slot', {}).setdefault(slot,{})\n+ slot_dict.update({\"type\": t})\n+ slot_dict.update({\"state\": state})\n+ slot_dict.update({\"allocation\": allocation})\ncontinue\nm = p5.match(line)\n@@ -3352,14 +3351,13 @@ class ShowPlatformPower(ShowPlatformPowerSchema):\nslot = m.groupdict()['slot']\nt = m.groupdict()['type']\nstate = m.groupdict()['state']\n- capacity = m.groupdict()['capacity']\n- load = m.groupdict()['load']\n- ret_dict.setdefault('slot', {})\n- ret_dict['slot'].setdefault(slot, {})\n- ret_dict['slot'][slot]['type'] = t\n- ret_dict['slot'][slot]['state'] = state\n- ret_dict['slot'][slot]['capacity'] = int(capacity)\n- ret_dict['slot'][slot]['load'] = int(load)\n+ capacity = int(m.groupdict()['capacity'])\n+ load = int(m.groupdict()['load'])\n+ slot_dict = ret_dict.setdefault('slot', {}).setdefault(slot,{})\n+ slot_dict.update({\"type\": t})\n+ slot_dict.update({\"state\": state})\n+ slot_dict.update({\"capacity\": capacity})\n+ slot_dict.update({\"load\": load})\ncontinue\nm = p6.match(line)\n",
        "chatgpt_cot": "Add Union type to typing import to support multiple types, and add slot_mapping method for mapping required slots to extracted entities in FormAction."
    },
    {
        "org_diff": "diff --git a/fkie_node_manager_daemon/src/fkie_node_manager_daemon/screen.py b/fkie_node_manager_daemon/src/fkie_node_manager_daemon/screen.py @@ -246,7 +246,11 @@ def get_cmd(node, env=[], keys=[]):\nshell = '-/bin/bash'\nif 'SHELL' in os.environ:\nshell = '-%s' % os.environ['SHELL']\n- return '%s -c %s/screen.cfg -O -L -Logfile %s -s %s -dmS %s' % (SCREEN, SETTINGS_PATH, get_logfile(node=node, for_new_screen=True), shell, create_session_name(node=node))\n+ cfg_file = '%s/screen.cfg' % SETTINGS_PATH\n+ cfg_opt = ''\n+ if os.path.exists(cfg_file):\n+ cfg_opt = '-c %s' % cfg_file\n+ return '%s %s -O -L -Logfile %s -s %s -dmS %s' % (SCREEN, cfg_opt, get_logfile(node=node, for_new_screen=True), shell, create_session_name(node=node))\ndef rosclean():\n",
        "org_msg": "check if screen configuration file exists",
        "sim_msg": "Removing unnecessary CLI argument from app.sh",
        "sim_diff": "diff --git a/src/app/bin/app.sh b/src/app/bin/app.sh SCRIPT_DIRECTORY=\"$( cd \"$( dirname \"${BASH_SOURCE[0]}\" )\" && pwd )\"\nAPP_ROOT=\"$(dirname \"$SCRIPT_DIRECTORY\")\"\n-\nCONFIG_FILE=\"$APP_ROOT/example_configs/config.yaml\"\n-LOG_CONFIG_FILE=\"$APP_ROOT/example_configs/logging-config.yaml\"\n-CMD=\"beer_garden -c $CONFIG_FILE -l $LOG_CONFIG_FILE\"\n-python -m $CMD\n+python -m beer_garden -c \"$CONFIG_FILE\"\n",
        "chatgpt_cot": "Refactor get_cmd method in screen.py to handle screen.cfg file, improving flexibility and robustness."
    },
    {
        "org_diff": "diff --git a/fkie_node_manager_daemon/src/fkie_node_manager_daemon/screen.py b/fkie_node_manager_daemon/src/fkie_node_manager_daemon/screen.py @@ -53,6 +53,7 @@ SCREEN = \"/usr/bin/screen\"\n''':var SCREEN: Defines the path to screen binary.'''\nSLASH_SEP = '_'\n''':var SLASH_SEP: this character is used to replace the slashes in ROS-Names.'''\n+SCREEN_NAME_MAX_CHARS = 74\ndef create_session_name(node=''):\n@@ -68,6 +69,8 @@ def create_session_name(node=''):\nreturn ''\nresult = rospy.names.ns_join('/', node).replace(SLASH_SEP, '%s%s' % (SLASH_SEP, SLASH_SEP))\nresult = result.replace('/', SLASH_SEP)\n+ if len(result) > SCREEN_NAME_MAX_CHARS:\n+ result = '_~%s' % result[len(result)-SCREEN_NAME_MAX_CHARS-2:]\nreturn result\n@@ -82,6 +85,8 @@ def session_name2node_name(session):\nnode_name = session.replace('%s%s' % (SLASH_SEP, SLASH_SEP), '//')\nnode_name = node_name.replace(SLASH_SEP, '/')\nnode_name = node_name.replace('//', SLASH_SEP)\n+ if node_name.startswith('/~'):\n+ node_name = node_name[2:]\nreturn node_name\n@@ -135,7 +140,7 @@ def get_active_screens(nodename=''):\nif nodename:\n# put all sessions which starts with '_'\nif nodepart.startswith('_'):\n- if nodename == session_name2node_name(nodepart):\n+ if nodepart == create_session_name(nodename):\nresult[screen_name] = nodename\nelse:\n# only sessions for given node\n",
        "org_msg": "fkie_node_manager: limits the length of the generated screen name",
        "sim_msg": "don't just completely remove @ from names",
        "sim_diff": "diff --git a/GearBot/Cogs/ModLog.py b/GearBot/Cogs/ModLog.py @@ -162,7 +162,7 @@ class ModLog:\nf\":rotating_light: {user.name}#{user.discriminator} (`{user.id}`) has been unbanned from the server.\")\ndef Clean_Name(self, text):\n- return text.replace(\"@\",\"\").replace(\"`\",\"\")\n+ return text.replace(\"@\",\"@\\u200b\").replace(\"`\",\"\")\nasync def on_member_update(self, before, after):\nwhile not self.bot.STARTUP_COMPLETE:\n@@ -175,7 +175,6 @@ class ModLog:\nafter.nick != before.nick):\nafter_clean_name = self.Clean_Name(after.name)\nafter_clean_display_name = self.Clean_Name(after.display_name)\n- before_clean_name = self.Clean_Name(after.name)\nbefore_clean_display_name = self.Clean_Name(before.display_name)\nawait logChannel.send(\nf':name_badge: {after_clean_name}#{after.discriminator} (`{after.id}`) has changed nickname from **``\\u200b{before_clean_display_name}``** to **``\\u200b{after_clean_display_name}``**.'\n@@ -183,11 +182,9 @@ class ModLog:\nelif (before.name != after.name and\nafter.name != before.name):\nafter_clean_name = self.Clean_Name(after.name)\n- after_clean_display_name = self.Clean_Name(after.display_name)\nbefore_clean_name = self.Clean_Name(before.name)\n- before_clean_display_name = self.Clean_Name(before.display_name)\nawait logChannel.send(\n- f':name_badge: {before_clean_name}#{before.discriminator} (`{before.id}`) has changed username from **``\\u200b{before_clean_name}``** to **``\\u200b{after_clean_name}``**.'\n+ f':name_badge: {after_clean_name}#{after.discriminator} (`{after.id}`) has changed username from **``\\u200b{before_clean_name}#{after.discriminator}``** to **``\\u200b{after_clean_name}#{after.discriminator}``**.'\n)\n",
        "chatgpt_cot": "Refactor screen.py, add SCREEN_NAME_MAX_CHARS, and optimize create_session_name and session_name2node_name functions for better screen name handling."
    },
    {
        "org_diff": "diff --git a/node_manager_daemon_fkie/src/node_manager_daemon_fkie/screen.py b/node_manager_daemon_fkie/src/node_manager_daemon_fkie/screen.py @@ -209,6 +209,8 @@ def _append_env(cfgfile, arg, env):\nvalue = env[arg]\nif value:\ncfgfile.write('setenv %s %s\\n' % (arg, value))\n+ return True\n+ return False\ndef get_cmd(node, env=[], keys=[]):\n@@ -230,7 +232,6 @@ def get_cmd(node, env=[], keys=[]):\nf.write(\"logfile %s\\n\" % get_logfile(node=node))\nf.write(\"logfile flush 0\\n\")\nf.write(\"defscrollback 10000\\n\")\n- use_env = env if env else os.environ\naddkeys = list(keys)\naddkeys.append('LD_LIBRARY_PATH')\naddkeys.append('ROS_ETC_DIR')\n@@ -243,6 +244,7 @@ def get_cmd(node, env=[], keys=[]):\naddkeys.append('RESPAWN_MAX')\naddkeys.append('RESPAWN_MIN_RUNTIME')\nfor key in keys:\n- _append_env(f, key, use_env)\n+ if not _append_env(f, key, env):\n+ _append_env(f, key, os.environ):\nf.close()\nreturn \"%s -c %s -L -dmS %s\" % (SCREEN, filename, create_session_name(node=node))\n",
        "org_msg": "node_manager_daemon_fkie: fixed set ENV in screen",
        "sim_msg": "Config: add the load_from_file method\nThis allows loading the configuration passing a filename directly,\nwithout the need to go through env vars. This will make it easier to\nuse the config from parts of the code that aren't run inside the\nrestservice.",
        "sim_diff": "diff --git a/rest-service/manager_rest/config.py b/rest-service/manager_rest/config.py @@ -61,14 +61,15 @@ class Config(object):\nself.warnings = []\ndef load_configuration(self):\n- self._load_config('MANAGER_REST_CONFIG_PATH')\n- self._load_config('MANAGER_REST_SECURITY_CONFIG_PATH', 'security')\n- self._load_config('MANAGER_REST_AUTHORIZATION_CONFIG_PATH',\n- 'authorization')\n-\n- def _load_config(self, env_var_name, namespace=''):\n+ for env_var_name, namespace in [\n+ ('MANAGER_REST_CONFIG_PATH', ''),\n+ ('MANAGER_REST_SECURITY_CONFIG_PATH', 'security'),\n+ ('MANAGER_REST_AUTHORIZATION_CONFIG_PATH', 'authorization')]:\nif env_var_name in os.environ:\n- with open(os.environ[env_var_name]) as f:\n+ self.load_from_file(os.environ[env_var_name], namespace)\n+\n+ def load_from_file(self, filename, namespace=''):\n+ with open(filename) as f:\nyaml_conf = yaml.safe_load(f.read())\nfor key, value in yaml_conf.iteritems():\nconfig_key = '{0}_{1}'.format(namespace, key) if namespace \\\n@@ -78,7 +79,7 @@ class Config(object):\nelse:\nself.warnings.append(\n\"Ignoring unknown key '{0}' in configuration file \"\n- \"'{1}'\".format(key, os.environ[env_var_name]))\n+ \"'{1}'\".format(key, filename))\ninstance = Config()\n",
        "chatgpt_cot": "\"Fix issue with _append_env function and add new return statement to resolve compilation problem in screen.py file.\""
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/launch_list_model.py b/node_manager_fkie/src/node_manager_fkie/launch_list_model.py @@ -253,7 +253,7 @@ class LaunchListModel(QStandardItemModel):\nitem = self.itemFromIndex(index)\nprev = '%s\\n' % text if text else ''\ntext = '%sfile://%s' % (prev, item.path)\n- mimeData.setData('text/plain', text)\n+ mimeData.setData('text/plain', text.encode('utf-8'))\nreturn mimeData\n# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n@@ -374,7 +374,7 @@ class LaunchListModel(QStandardItemModel):\nitem = self.itemFromIndex(index)\nprev = '%s\\n' % text if text else ''\ntext = '%sfile://%s' % (prev, item.path)\n- mimeData.setData('text/plain', text)\n+ mimeData.setData('text/plain', text.encode('utf-8'))\nQApplication.clipboard().setMimeData(mimeData)\n# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
        "org_msg": "node_manager_fkie: fixed copy function in launch file browser",
        "sim_msg": "Removed redundant internalPointer query",
        "sim_diff": "diff --git a/avalon/tools/cbsceneinventory/model.py b/avalon/tools/cbsceneinventory/model.py @@ -50,7 +50,6 @@ class InventoryModel(TreeModel):\nif role == QtCore.Qt.DecorationRole:\nif index.column() == 0:\n# Override color\n- node = index.internalPointer()\ncolor = node.get(\"color\", style.colors.default)\nif not index.parent().isValid(): # group-item\nreturn qta.icon(\"fa.folder\", color=color)\n@@ -62,7 +61,6 @@ class InventoryModel(TreeModel):\nreturn node.get(\"familyIcon\", None)\nif role == self.UniqueRole:\n- node = index.internalPointer()\nreturn node['representation'] + node.get(\"objectName\", \"<none>\")\nreturn super(InventoryModel, self).data(index, role)\n",
        "chatgpt_cot": "Fix encoding issue in LaunchListModel file by encoding text to 'utf-8' before setting it as data in mimeData to handle special characters."
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/InstallLauncher.cmake b/node_manager_fkie/InstallLauncher.cmake # Install and register the given launcher file.\n+message(STATUS \"Installing Unity desktop launcher\")\nexecute_process(COMMAND\ndesktop-file-install --dir=$ENV{HOME}/.local/share/applications ${NODE_MANAGER_LAUNCHER}\nRESULT_VARIABLE\nLAUNCHER_INSTALLATION_RESULT\n)\n-# Print the result.\n-if (${LAUNCHER_INSTALLATION_RESULT} EQUAL 0)\n- set(LAUNCHER_INSTALLATION_RESULT success)\n-endif (${LAUNCHER_INSTALLATION_RESULT} EQUAL 0)\n-\n-if (${LAUNCHER_INSTALLATION_RESULT} EQUAL 1)\n- set(LAUNCHER_INSTALLATION_RESULT failure)\n-endif (${LAUNCHER_INSTALLATION_RESULT} EQUAL 1)\n-\n-message(STATUS \"Installing Unity desktop launcher: ${LAUNCHER_INSTALLATION_RESULT}.\")\n+# If an error occurred, print it.\n+if (NOT ${LAUNCHER_INSTALLATION_RESULT} EQUAL 0)\n+ message(AUTHOR_WARNING \"Installing Unity desktop launcher failed\")\n+endif (NOT ${LAUNCHER_INSTALLATION_RESULT} EQUAL 0)\n",
        "org_msg": "Improve messages during launcher installation.",
        "sim_msg": "better timeout for aea install",
        "sim_diff": "diff --git a/aea/cli/install.py b/aea/cli/install.py @@ -61,42 +61,46 @@ def _install_dependency(dependency_name: str, dependency: Dependency):\n)\n-def _try_install(install_command: List[str]) -> int:\n+def _try_install(install_command: List[str], install_timeout: float = 300) -> int:\n\"\"\"\nTry executing install command.\n- :param return_code: the return code of the subprocess\n+ :param install_command: list strings of the command\n+ :param install_timeout: timeout to wait pip to install\n+ :return: the return code of the subprocess\n\"\"\"\ntry:\nsubp = subprocess.Popen(install_command) # nosec\n- subp.wait(120.0)\n+ subp.wait(install_timeout)\nreturn_code = subp.returncode\nfinally:\npoll = subp.poll()\nif poll is None: # pragma: no cover\nsubp.terminate()\n- subp.wait(2)\n+ subp.wait(30)\nreturn return_code\n-def _install_from_requirement(file: str):\n+def _install_from_requirement(file: str, install_timeout: float = 300) -> None:\n+ \"\"\"\n+ Install from requirements.\n+\n+ :param file: requirement.txt file path\n+ :param install_timeout: timeout to wait pip to install\n+\n+ :return: None\n+ \"\"\"\ntry:\n- subp = subprocess.Popen( # nosec\n- [sys.executable, \"-m\", \"pip\", \"install\", \"-r\", file]\n- ) # nosec\n- subp.wait(30.0)\n- assert subp.returncode == 0, \"Return code != 0.\"\n+ returncode = _try_install(\n+ [sys.executable, \"-m\", \"pip\", \"install\", \"-r\", file], install_timeout\n+ )\n+ assert returncode == 0, \"Return code != 0.\"\nexcept Exception:\nraise AEAException(\n\"An error occurred while installing requirement file {}. Stopping...\".format(\nfile\n)\n)\n- finally:\n- poll = subp.poll()\n- if poll is None: # pragma: no cover\n- subp.terminate()\n- subp.wait(2)\n@click.command()\n",
        "chatgpt_cot": "\"Refactor InstallLauncher.cmake to handle Unity desktop launcher installation and error handling.\""
    },
    {
        "org_diff": "diff --git a/setup.py b/setup.py @@ -3,12 +3,13 @@ from setuptools import setup\nsetup(\nname = \"sc2\",\npackages = [\"sc2\"],\n- version = \"0.1.0\",\n+ version = \"0.1.0alpha0\",\ndescription = \"A StarCraft II bot api library\",\nlicense='MIT',\nauthor = \"Hannes Karppila\",\nauthor_email = \"hannes.karppila@gmail.com\",\nurl = \"https://github.com/Dentosal/python-sc2\",\n+ download_url = \"https://github.com/Dentosal/python-sc2/archive/v0.1.0-alpha.tar.gz\",\nkeywords = [\"StarCraft\", \"StarCraft 2\", \"StarCraft II\", \"AI\", \"Bot\"],\ninstall_requires=[\"s2clientprotocol\", \"websockets\", \"portpicker\", \"vectors\"],\nclassifiers = [\n",
        "org_msg": "Use github releases",
        "sim_msg": "automatically find matchms package in setup.py",
        "sim_diff": "diff --git a/setup.py b/setup.py import os\nfrom setuptools import setup\n+from setuptools import find_packages\nhere = os.path.abspath(os.path.dirname(__file__))\n@@ -22,9 +23,7 @@ setup(\nauthor=\"Netherlands eScience Center\",\nauthor_email='generalization@esciencecenter.nl',\nurl='https://github.com/matchms/matchms',\n- packages=[\n- 'matchms',\n- ],\n+ packages=find_packages(),\ninclude_package_data=True,\nlicense=\"Apache Software License 2.0\",\nzip_safe=False,\n",
        "chatgpt_cot": "Update version to 0.1.0-alpha, add download URL\n- The scope of changes includes modifying the version number and adding a download URL\n- The file \"setup.py\" is used for setting up the project, and the modifications are related to versioning and distribution\n- The purpose of the modifications is to update the version number and provide a download URL for the project."
    },
    {
        "org_diff": "diff --git a/fkie_node_manager/src/fkie_node_manager/screen_handler.py b/fkie_node_manager/src/fkie_node_manager/screen_handler.py @@ -94,7 +94,7 @@ class ScreenHandler(object):\n'''\n# create a title of the terminal\nif use_log_widget:\n- nm._MAIN_FORM.screen_dock.connect(host, screen_name, nodename, user)\n+ nm._MAIN_FORM.screen_widget.connect(host, screen_name, nodename, user)\nreturn\ntitle_opt = 'SCREEN %s on %s' % (nodename, host)\nif nm.is_local(host):\n",
        "org_msg": "fkie_node_manager: fix",
        "sim_msg": "Window title is set correctly\nFixes",
        "sim_diff": "diff --git a/gaphor/ui/mainwindow.py b/gaphor/ui/mainwindow.py @@ -255,6 +255,7 @@ class MainWindow(Service, ActionProvider):\ntitle += \" [\" + gettext(\"edited\") + \"]\"\nself.title.set_text(title)\nself.subtitle.set_text(subtitle)\n+ self.window.set_title(title)\n# Signal callbacks:\n",
        "chatgpt_cot": "Update method call in ScreenHandler to use screen_widget instead of screen_dock for better functionality and consistency with naming conventions."
    },
    {
        "org_diff": "diff --git a/node_manager_daemon_fkie/src/node_manager_daemon_fkie/server.py b/node_manager_daemon_fkie/src/node_manager_daemon_fkie/server.py from concurrent import futures\nimport grpc\nimport rospy\n+import time\nfrom .file_servicer import FileServicer\nfrom .launch_servicer import LaunchServicer\n@@ -64,11 +65,15 @@ class GrpcServer:\n# server_credentials = grpc.ssl_server_credentials(((private_key, certificate_chain,),))\n# print(\"port: \", self.server.add_secure_port(url, server_credentials))\ninsecure_port = self.server.add_insecure_port(url)\n- if insecure_port == 0:\n- raise Exception(\"Can not add insecure channel to '%s'!\" % url)\n+ while insecure_port == 0 and not rospy.is_shutdown():\n+ rospy.logwarn(\"can not add insecure channel to '%s', try again...\" % url)\n+ time.sleep(2.)\n+ insecure_port = self.server.add_insecure_port(url)\n+ if insecure_port > 0:\nfgrpc.add_FileServiceServicer_to_server(FileServicer(), self.server)\nlgrpc.add_LaunchServiceServicer_to_server(self.launch_servicer, self.server)\nself.server.start()\n+ rospy.loginfo(\"Server at '%s' started!\" % url)\ndef shutdown(self):\nself.launch_servicer.stop()\n",
        "org_msg": "node_manager_daemon_fkie: retry creat of channel on error",
        "sim_msg": "Changed default port for grpc server wrapper class to also allow ipv6 interfaces.",
        "sim_diff": "diff --git a/fedn/fedn/common/net/grpc/server.py b/fedn/fedn/common/net/grpc/server.py @@ -29,10 +29,10 @@ class Server:\nserver_credentials = grpc.ssl_server_credentials(\n((config['key'], config['certificate'],),))\n- self.server.add_secure_port('0.0.0.0:' + str(config['port']), server_credentials)\n+ self.server.add_secure_port('[::]:' + str(config['port']), server_credentials)\nelse:\n- self.server.add_insecure_port('0.0.0.0:' + str(config['port']))\n+ self.server.add_insecure_port('[::]:' + str(config['port']))\ndef start(self):\nself.server.start()\n",
        "chatgpt_cot": "Fix server insecure port addition issue with retry mechanism and log messages in server.py."
    },
    {
        "org_diff": "diff --git a/MAINTAINERS.md b/MAINTAINERS.md |---|---|---|---|---|\n| Baohua Yang | baohua | yeasy | baohua | yangbaohua@gmail.com |\n| Haitao Yue | hightall | hightall | hightall | hightallyht@gmail.com |\n+| Tong Li | tongli | tongli | tongli | litong01@us.ibm.com |\n<a rel=\"license\" href=\"http://creativecommons.org/licenses/by/4.0/\"><img alt=\"Creative Commons License\" style=\"border-width:0\" src=\"https://i.creativecommons.org/l/by/4.0/88x31.png\" /></a><br />This work is licensed under a <a rel=\"license\" href=\"http://creativecommons.org/licenses/by/4.0/\">Creative Commons Attribution 4.0 International License</a>.\n",
        "org_msg": "Nominate Tong Li as maintainer\nTong Li has been contributing to Hyperledger\nCello for several months, in terms of code, answering questions and\nreviewing pathsets.\nWould like to nominate him as new maintainer.",
        "sim_msg": "updated top-level README",
        "sim_diff": "diff --git a/README.md b/README.md # ACL Anthology\n-(This repo was originally wing-nus/acl and has been transferred over to acl-org\n-as of 5 Jun 2017. Please update accordingly.)\n-\n-These are basic instructions on generating the ACL Anthology website as seen on\n-<https://aclweb.org/anthology/>.\n-\n+These are basic instructions on generating the ACL Anthology website as seen on <https://aclweb.org/anthology/>.\n+The offical home of this repository is <https://github.com/acl-org/acl-anthology>.\n## Generating the Anthology\n@@ -64,21 +60,18 @@ about a minute to start.\n## Contributing\n-If you'd like to contribute to the ACL Anthology, please take a look at our\n-[information on volunteering](https://aclanthology.info/volunteer) and the\n-[detailed README](README_detailed.md) containing more in-depth information about\n-generating and modifying the website.\n+If you'd like to contribute to the ACL Anthology, please take a look at:\n+- our [Github issues page](https://github.com/acl-org/acl-anthology/issues)\n+- our [call for volunteers](https://aclanthology.info/volunteer)\n+- the [detailed README](README_detailed.md) which contains more in-depth information about generating and modifying the website.\n-## License\n+## History\n-Materials prior to 2016 here are licensed under the [Creative Commons\n-Attribution-NonCommercial-ShareAlike 3.0 International\n-License](https://creativecommons.org/licenses/by-nc-sa/3.0/). Permission is\n-granted to make copies for the purposes of teaching and research. Materials\n-published in or after 2016 are licensed on a [Creative Commons Attribution 4.0\n-License](https://creativecommons.org/licenses/by/4.0/).\n+This repo was originally wing-nus/acl and has been transferred over to acl-org as of 5 June 2017.\n-Matt Post (Editor, 2019-) / Min-Yen Kan (Editor, 2008-2018) / Steven Bird (Editor, 2001-2007)\n+## License\n-Developer team: Linh Hien Ng (linhhienng at gmail dot com), Duong Ho Tuan zamakkat at gmail dot com)\n+Materials prior to 2016 here are licensed under the [Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License](https://creativecommons.org/licenses/by-nc-sa/3.0/).\n+Permission is granted to make copies for the purposes of teaching and research.\n+Materials published in or after 2016 are licensed on a [Creative Commons Attribution 4.0 License](https://creativecommons.org/licenses/by/4.0/).\n",
        "chatgpt_cot": "Add Tong Li as a maintainer in the MAINTAINERS.md file."
    },
    {
        "org_diff": "diff --git a/fkie_node_manager/src/fkie_node_manager/logscreen/screen_widget.py b/fkie_node_manager/src/fkie_node_manager/logscreen/screen_widget.py @@ -359,7 +359,7 @@ class ScreenWidget(QWidget):\nif line_size > 120:\ncount += 1\nline_size = 0\n- if ch == '\\n':\n+ if ch == b'\\n':\ncount += 1\nline_size = 0\nif count >= lines:\n",
        "org_msg": "fkie_node_manager: fixed python3 compatibility in logscreens",
        "sim_msg": "dark stylesheet update",
        "sim_diff": "diff --git a/qualcoder/__main__.py b/qualcoder/__main__.py @@ -544,10 +544,8 @@ class App(object):\nQListWidget::item:selected {border-left: 3px solid red; color: #eeeeee;}\\n\\\nQHeaderView::section {background-color: #505050; color: #ffce42;}\\n\\\nQTreeWidget {font-size: 12px;}\\n\\\n- QTreeWidget::branch:selected {border-left: 2px solid red; color: #eeeeee;}\\n\\\n- QSlider::groove:horizontal {background-color: #777777; border: 0px solid #777777; height: 10px; border-radius: 4px;}\\n\\\n- QSlider::handle:horizontal { background-color: #ffaa00; border: 2px solid #ffaa00; width: 16px; height: 16px; \\\n- line-height: 16px; margin-top: -4px; margin-bottom: -4px; border-radius: 8px;}\"\n+ QTreeView {background-color: #484848}\\n\\\n+ QTreeView::branch:selected {border-left: 2px solid red; color: #eeeeee;}\"\nstyle_dark = style_dark.replace(\"* {font-size: 12\", \"* {font-size:\" + str(settings.get('fontsize')))\nstyle_dark = style_dark.replace(\"QTreeWidget {font-size: 12\",\n\"QTreeWidget {font-size: \" + str(settings.get('treefontsize')))\n",
        "chatgpt_cot": "fix issue with counting lines in ScreenWidget due to handling of newline character."
    },
    {
        "org_diff": "diff --git a/sc2/constants.py b/sc2/constants.py @@ -445,7 +445,12 @@ ZERG_TECH_REQUIREMENT: Dict[UnitTypeId, UnitTypeId] = defaultdict(\n)\n# Required in 'tech_requirement_progress' bot_ai.py function\nEQUIVALENTS_FOR_TECH_PROGRESS: Dict[UnitTypeId, Set[UnitTypeId]] = {\n- UnitTypeId.SUPPLYDEPOT: {UnitTypeId.SUPPLYDEPOTLOWERED},\n+ # Protoss\n+ UnitTypeId.GATEWAY: {UnitTypeId.WARPGATE},\n+ UnitTypeId.WARPPRISM: {UnitTypeId.WARPPRISMPHASING},\n+ UnitTypeId.OBSERVER: {UnitTypeId.OBSERVERSIEGEMODE},\n+ # Terran\n+ UnitTypeId.SUPPLYDEPOT: {UnitTypeId.SUPPLYDEPOTLOWERED, UnitTypeId.SUPPLYDEPOTDROP},\nUnitTypeId.BARRACKS: {UnitTypeId.BARRACKSFLYING},\nUnitTypeId.FACTORY: {UnitTypeId.FACTORYFLYING},\nUnitTypeId.STARPORT: {UnitTypeId.STARPORTFLYING},\n@@ -455,9 +460,31 @@ EQUIVALENTS_FOR_TECH_PROGRESS: Dict[UnitTypeId, Set[UnitTypeId]] = {\nUnitTypeId.ORBITALCOMMAND,\nUnitTypeId.ORBITALCOMMANDFLYING,\n},\n+ UnitTypeId.ORBITALCOMMAND: {UnitTypeId.ORBITALCOMMANDFLYING},\n+ UnitTypeId.HELLION: {UnitTypeId.HELLIONTANK},\n+ UnitTypeId.WIDOWMINE: {UnitTypeId.WIDOWMINEBURROWED},\n+ UnitTypeId.SIEGETANK: {UnitTypeId.SIEGETANKSIEGED},\n+ UnitTypeId.THOR: {UnitTypeId.THORAP},\n+ UnitTypeId.VIKINGFIGHTER: {UnitTypeId.VIKINGASSAULT},\n+ UnitTypeId.LIBERATOR: {UnitTypeId.LIBERATORAG},\n+ # Zerg\nUnitTypeId.LAIR: {UnitTypeId.HIVE},\nUnitTypeId.HATCHERY: {UnitTypeId.LAIR, UnitTypeId.HIVE},\nUnitTypeId.SPIRE: {UnitTypeId.GREATERSPIRE},\n+ UnitTypeId.SPINECRAWLER: {UnitTypeId.SPINECRAWLERUPROOTED},\n+ UnitTypeId.SPORECRAWLER: {UnitTypeId.SPORECRAWLERUPROOTED},\n+ UnitTypeId.OVERLORD: {UnitTypeId.OVERLORDTRANSPORT},\n+ UnitTypeId.OVERSEER: {UnitTypeId.OVERSEERSIEGEMODE},\n+ UnitTypeId.DRONE: {UnitTypeId.DRONEBURROWED},\n+ UnitTypeId.ZERGLING: {UnitTypeId.ZERGLINGBURROWED},\n+ UnitTypeId.ROACH: {UnitTypeId.ROACHBURROWED},\n+ UnitTypeId.RAVAGER: {UnitTypeId.RAVAGERBURROWED},\n+ UnitTypeId.HYDRALISK: {UnitTypeId.HYDRALISKBURROWED},\n+ UnitTypeId.LURKERMP: {UnitTypeId.LURKERMPBURROWED},\n+ UnitTypeId.SWARMHOSTMP: {UnitTypeId.SWARMHOSTBURROWEDMP},\n+ UnitTypeId.INFESTOR: {UnitTypeId.INFESTORBURROWED},\n+ UnitTypeId.ULTRALISK: {UnitTypeId.ULTRALISKBURROWED},\n+ # TODO What about morphing untis? E.g. roach to ravager, overlord to drop-overlord or overseer\n}\nALL_GAS: Set[UnitTypeId] = {\nUnitTypeId.ASSIMILATOR,\n",
        "org_msg": "Update dict of units and their equivalent types",
        "sim_msg": "Add new infrastructure-type-ov entries",
        "sim_diff": "diff --git a/stix2/v21/vocab.py b/stix2/v21/vocab.py @@ -285,12 +285,16 @@ INFRASTRUCTURE_TYPE_AMPLIFICATION = \"amplification\"\nINFRASTRUCTURE_TYPE_ANONYMIZATION = \"anonymization\"\nINFRASTRUCTURE_TYPE_BOTNET = \"botnet\"\nINFRASTRUCTURE_TYPE_COMMAND_AND_CONTROL = \"command-and-control\"\n+INFRASTRUCTURE_TYPE_CONTROL_SYSTEM = \"control-system\"\nINFRASTRUCTURE_TYPE_EXFILTRATION = \"exfiltration\"\n+INFRASTRUCTURE_TYPE_FIREWALL = \"firewall\"\nINFRASTRUCTURE_TYPE_HOSTING_MALWARE = \"hosting-malware\"\nINFRASTRUCTURE_TYPE_HOSTING_TARGET_LISTS = \"hosting-target-lists\"\nINFRASTRUCTURE_TYPE_PHISHING = \"phishing\"\nINFRASTRUCTURE_TYPE_RECONNAISSANCE = \"reconnaissance\"\n+INFRASTRUCTURE_TYPE_ROUTERS_SWITCHES = \"routers-switches\"\nINFRASTRUCTURE_TYPE_STAGING = \"staging\"\n+INFRASTRUCTURE_TYPE_WORKSTATION = \"workstation\"\nINFRASTRUCTURE_TYPE_UNKNOWN = \"unknown\"\n@@ -299,12 +303,16 @@ INFRASTRUCTURE_TYPE = [\nINFRASTRUCTURE_TYPE_ANONYMIZATION,\nINFRASTRUCTURE_TYPE_BOTNET,\nINFRASTRUCTURE_TYPE_COMMAND_AND_CONTROL,\n+ INFRASTRUCTURE_TYPE_CONTROL_SYSTEM,\nINFRASTRUCTURE_TYPE_EXFILTRATION,\n+ INFRASTRUCTURE_TYPE_FIREWALL,\nINFRASTRUCTURE_TYPE_HOSTING_MALWARE,\nINFRASTRUCTURE_TYPE_HOSTING_TARGET_LISTS,\nINFRASTRUCTURE_TYPE_PHISHING,\nINFRASTRUCTURE_TYPE_RECONNAISSANCE,\n+ INFRASTRUCTURE_TYPE_ROUTERS_SWITCHES,\nINFRASTRUCTURE_TYPE_STAGING,\n+ INFRASTRUCTURE_TYPE_WORKSTATION,\nINFRASTRUCTURE_TYPE_UNKNOWN,\n]\n",
        "chatgpt_cot": "\"Add equivalent tech progress for Protoss, Terran, and Zerg units, and support for morphing units in 'tech_requirement_progress' bot_ai.py function.\""
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/master_view_proxy.py b/node_manager_fkie/src/node_manager_fkie/master_view_proxy.py @@ -355,12 +355,12 @@ class MasterViewProxy(QWidget):\nself._shortcut_stop = QShortcut(QKeySequence(self.tr(\"Alt+S\", \"stop selected nodes\")), self)\nself._shortcut_stop.activated.connect(self.on_stop_clicked)\n- self.message_frame = MessageFrame(self)\n+ self.message_frame = MessageFrame()\nself.masterTab.questionFrameLayout.addWidget(self.message_frame.frameui)\nself.message_frame.accept_signal.connect(self._on_question_ok)\nself.message_frame.cancel_signal.connect(self._on_question_cancel)\n- self.info_frame = MessageFrame(self, info=True)\n+ self.info_frame = MessageFrame(info=True)\nself.masterTab.infoFrameLayout.addWidget(self.info_frame.frameui)\nself.info_frame.accept_signal.connect(self._on_info_ok)\n# self._shortcut_copy = QShortcut(QKeySequence(self.tr(\"Ctrl+C\", \"copy selected values to clipboard\")), self)\n",
        "org_msg": "node_manager_fkie: fixed blocked filter on left side",
        "sim_msg": "tree: improve popup menu handling",
        "sim_diff": "diff --git a/tree.py b/tree.py @@ -390,7 +390,8 @@ class WidgetTree(wx.TreeCtrl, Tree):\nself.Bind(wx.EVT_RIGHT_DOWN, self.popup_menu)\nself.Bind(wx.EVT_LEFT_DCLICK, self.on_left_dclick)\nself.Bind(wx.EVT_LEFT_DOWN, self.on_left_click) # allow direct placement of widgets\n- self.Bind(wx.EVT_MENU, self.show_toplevel)\n+ self.Bind(wx.EVT_MENU, self.on_menu) # for handling the selection of the first item\n+ self._popup_menu_widget = None # the widget for the popup menu\nself.Bind(wx.EVT_TREE_BEGIN_DRAG, self.begin_drag)\nself.Bind(wx.EVT_LEAVE_WINDOW, self.on_leave_window)\nself.Bind(wx.EVT_MOUSE_EVENTS, self.on_mouse_events)\n@@ -707,6 +708,12 @@ class WidgetTree(wx.TreeCtrl, Tree):\nself.SetCursor(wx.STANDARD_CURSOR)\nevent.Skip()\n+ def on_menu(self, event):\n+ # the first entry in the popup menu, i.e. the name was selected\n+ if self._popup_menu_widget is None: return\n+ if not getattr(self._popup_menu_widget, \"_is_toplevel_window\", False): return\n+ self.show_toplevel( None, self._popup_menu_widget )\n+\ndef on_mouse_events(self, event):\nif not self._drag_ongoing and not event.IsButton():\n# set cursor to indicate a possible drop\n@@ -730,8 +737,9 @@ class WidgetTree(wx.TreeCtrl, Tree):\nif not node:\nreturn\nself.select_item(node)\n- item = node.widget\n- item.popup_menu(event, pos)\n+ self._popup_menu_widget = node.widget\n+ node.widget.popup_menu(event, pos)\n+ self._popup_menu_widget = None\ndef expand(self, node=None, yes=True):\n\"expands or collapses the given node\"\n",
        "chatgpt_cot": "\"Refactor MessageFrame instantiation in MasterViewProxy to improve code readability and maintainability\""
    },
    {
        "org_diff": "diff --git a/node_manager_daemon_fkie/src/node_manager_daemon_fkie/launch_servicer.py b/node_manager_daemon_fkie/src/node_manager_daemon_fkie/launch_servicer.py @@ -293,8 +293,7 @@ class LaunchServicer(lgrpc.LaunchServiceServicer):\nlaunch_config = LaunchConfig(launchfile, masteruri=request.masteruri, host=request.host)\n# get the list with needed launch args\nreq_args = launch_config.get_args()\n- if request.request_args:\n- if req_args:\n+ if request.request_args and req_args:\narg_dict = launch_config.argv2dict(req_args)\nfor arg, value in arg_dict.items():\nif arg not in provided_args:\n",
        "org_msg": "node_manager_daemon_fkie: changed request args on load launch file",
        "sim_msg": "retry startup",
        "sim_diff": "diff --git a/lbrynet/lbrynet_daemon/DaemonControl.py b/lbrynet/lbrynet_daemon/DaemonControl.py @@ -114,7 +114,7 @@ def update_settings_from_args(args):\n@defer.inlineCallbacks\n-def start_server_and_listen(launchui, use_auth, analytics_manager):\n+def start_server_and_listen(launchui, use_auth, analytics_manager, max_tries=5):\n\"\"\"The primary entry point for launching the daemon.\nArgs:\n@@ -124,13 +124,19 @@ def start_server_and_listen(launchui, use_auth, analytics_manager):\n\"\"\"\nanalytics_manager.send_server_startup()\nlog_support.configure_analytics_handler(analytics_manager)\n+ tries = 1\n+ while tries < max_tries:\n+ log.info('Making attempt %s / %s to startup', tries, max_tries)\ntry:\ndaemon_server = DaemonServer(analytics_manager)\nyield daemon_server.start(use_auth, launchui)\nanalytics_manager.send_server_startup_success()\n+ break\nexcept Exception as e:\nlog.exception('Failed to startup')\nanalytics_manager.send_server_startup_error(str(e))\n+ tries += 1\n+ else:\nreactor.callFromThread(reactor.stop)\n",
        "chatgpt_cot": "\"Refactor launch_servicer.py to improve request_args handling\""
    },
    {
        "org_diff": "diff --git a/fkie_node_manager/CMakeLists.txt b/fkie_node_manager/CMakeLists.txt @@ -48,6 +48,12 @@ install(\nDESTINATION ${CATKIN_PACKAGE_SHARE_DESTINATION}\n)\n+install(\n+ DIRECTORY\n+ doc\n+ DESTINATION ${CATKIN_PACKAGE_SHARE_DESTINATION}\n+)\n+\ninstall(\nFILES\nsrc/${PROJECT_NAME}/EchoDialog.ui\n",
        "org_msg": "fkie_node_manager: install doc directory",
        "sim_msg": "Disable sanitizers for cJSON universal.",
        "sim_diff": "diff --git a/package/lib-cjson-master-universal/scripts.linux/install.sh b/package/lib-cjson-master-universal/scripts.linux/install.sh #! /bin/bash\n#\n-# Extra Installation script\n+# Extra installation script\n#\n# See CK LICENSE.txt for licensing details.\n# See CK COPYRIGHT.txt for copyright details.\n@@ -18,7 +18,7 @@ export CK_CMAKE_EXTRA=\"${CK_CMAKE_EXTRA} \\\n-DENABLE_TARGET_EXPORT=On \\\n-DENABLE_CUSTOM_COMPILER_FLAGS=On \\\n-DENABLE_VALGRIND=Off \\\n- -DENABLE_SANITIZERS=On \\\n+ -DENABLE_SANITIZERS=Off \\\n-DBUILD_SHARED_LIBS=On \\\n-DSAMPLES=ON\"\n",
        "chatgpt_cot": "Add installation of the 'doc' directory to CMakeLists.txt. This change ensures that the 'doc' directory is installed to the correct destination."
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/parameter_dialog.py b/node_manager_fkie/src/node_manager_fkie/parameter_dialog.py @@ -618,7 +618,7 @@ class ArrayBox(MainBox):\nprint traceback.format_exc(1)\nself.count_label.setText(utf8(self._dynamic_items_count))\n- def createFieldFromValue(self, value):\n+ def createFieldFromValue(self, value, clear_origin_value=False):\nself.setUpdatesEnabled(False)\ntry:\nif isinstance(value, list):\n",
        "org_msg": "node_manager_fkie: fixed topic publish dialog for messages with arrays",
        "sim_msg": "[fix] Project setup order of operations",
        "sim_diff": "diff --git a/labelbox/schema/project.py b/labelbox/schema/project.py @@ -199,6 +199,8 @@ class Project(DbObject, Updateable, Deletable):\nif not isinstance(labeling_frontend_options, str):\nlabeling_frontend_options = json.dumps(labeling_frontend_options)\n+ self.labeling_frontend.connect(labeling_frontend)\n+\nLFO = Entity.LabelingFrontendOptions\nlabeling_frontend_options = self.client._create(\nLFO, {LFO.project: self, LFO.labeling_frontend: labeling_frontend,\n@@ -206,7 +208,6 @@ class Project(DbObject, Updateable, Deletable):\nLFO.organization: organization\n})\n- self.labeling_frontend.connect(labeling_frontend)\ntimestamp = datetime.now(timezone.utc).strftime(\"%Y-%m-%dT%H:%M:%SZ\")\nself.update(setup_complete=timestamp)\n",
        "chatgpt_cot": "\"Add parameter to createFieldFromValue method in ArrayBox for clearing origin value\""
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/master_view_proxy.py b/node_manager_fkie/src/node_manager_fkie/master_view_proxy.py @@ -456,7 +456,7 @@ class MasterViewProxy(QWidget):\nreturn\nnmd_node = master_info.getNode('/node_manager_daemon')\nif nmd_node is None or nmd_node.pid is None:\n- # if not self.is_local:\n+ if not self.is_local:\nself.message_frame.show_question(MessageFrame.TYPE_NMD, \"node_manager_daemon not found for '%s'.\\nShould it be started?\" % self.masteruri, MessageData(self.masteruri))\ntry:\nif (master_info.masteruri == self.masteruri):\n",
        "org_msg": "node_manager_fkie: do not ask to start nmd on localhost",
        "sim_msg": "ADD get_req_info / FIX get_user_info",
        "sim_diff": "diff --git a/packages/syft/src/syft/core/node/common/node_manager/request_manager.py b/packages/syft/src/syft/core/node/common/node_manager/request_manager.py @@ -45,17 +45,35 @@ class RequestManager(DatabaseManager):\ndef set(self, request_id: int, status: RequestStatus) -> None:\nself.modify({\"id\": request_id}, {\"status\": status})\n- def get_user_info(request_id: int) -> Dict:\n+ def get_user_info(self, request_id: int) -> Dict:\nrequest = super().first(id=request_id)\nreturn {\n\"name\": request.user_name,\n\"email\": request.user_email,\n\"role\": request.user_role,\n- \"budget\": request.user_budget,\n+ \"current_budget\": request.user_budget,\n\"institution\": request.institution,\n\"website\": request.website,\n}\n+ def get_req_info(self, request_id: int) -> Dict:\n+ request = super().first(id=request_id)\n+ return {\n+ \"id\": request.id,\n+ \"date\": str(request.date),\n+ \"status\": request.status,\n+ \"reason\": request.reason,\n+ \"request_type\": request.request_type,\n+ \"current_budget\": request.current_budget,\n+ \"requested_budget\": request.requested_budget,\n+ \"review\": {\n+ \"name\": request.reviewer_name,\n+ \"role\": request.reviewer_role,\n+ \"updated_on\": str(request.updated_on),\n+ \"comment\": request.reviewer_comment,\n+ },\n+ }\n+\ndef clear(self) -> None:\nlocal_session = sessionmaker(bind=self.db)()\nlocal_session.query(self.schema).delete()\n",
        "chatgpt_cot": "Fix conditional statement in MasterViewProxy class to show question when node_manager_daemon is not found for the given masteruri."
    },
    {
        "org_diff": "diff --git a/sc2/unit.py b/sc2/unit.py @@ -511,10 +511,14 @@ class Unit(PassengerUnit):\n\"\"\" Checks if unit is idle. \"\"\"\nreturn not self.orders\n+ def is_using_ability(self, ability: AbilityId) -> bool:\n+ \"\"\" Check if the unit is using the given ability. \"\"\"\n+ return bool(self.orders) and self.orders[0].ability.id is ability\n+\n@property_immutable_cache\ndef is_moving(self) -> bool:\n\"\"\" Checks if the unit is moving. \"\"\"\n- return self.orders and self.orders[0].ability.id is AbilityId.MOVE\n+ return self.is_using_ability(AbilityId.MOVE)\n@property_immutable_cache\ndef is_attacking(self) -> bool:\n@@ -530,17 +534,17 @@ class Unit(PassengerUnit):\n@property_immutable_cache\ndef is_patrolling(self) -> bool:\n\"\"\" Checks if a unit is patrolling. \"\"\"\n- return self.orders and self.orders[0].ability.id is AbilityId.PATROL\n+ return self.is_using_ability(AbilityId.PATROL)\n@property_immutable_cache\ndef is_gathering(self) -> bool:\n\"\"\" Checks if a unit is on its way to a mineral field or vespene geyser to mine. \"\"\"\n- return self.orders and self.orders[0].ability.id is AbilityId.HARVEST_GATHER\n+ return self.is_using_ability(AbilityId.HARVEST_GATHER)\n@property_immutable_cache\ndef is_returning(self) -> bool:\n\"\"\" Checks if a unit is returning from mineral field or vespene geyser to deliver resources to townhall. \"\"\"\n- return self.orders and self.orders[0].ability.id is AbilityId.HARVEST_RETURN\n+ return self.is_using_ability(AbilityId.HARVEST_RETURN)\n@property_immutable_cache\ndef is_collecting(self) -> bool:\n",
        "org_msg": "Add Unit.is_using_ability",
        "sim_msg": "Not allowing deleted users to stay logged in",
        "sim_diff": "diff --git a/app/misc.py b/app/misc.py @@ -81,13 +81,10 @@ class SiteUser(object):\nself.is_active = False\nelse:\nself.is_active = True\n- if self.user:\n- self.is_authenticated = True\n- self.is_anonymous = False\n+ self.is_active = True if self.user['status'] == 0 else False\n+ self.is_authenticated = True if self.user['status'] == 0 else False\n+ self.is_anonymous = True if self.user['status'] != 0 else False\nself.admin = 'admin' in self.prefs\n- else:\n- self.is_authenticated = False\n- self.is_anonymous = True\nself.canupload = True if ('canupload' in self.prefs) or (self.admin) else False\n",
        "chatgpt_cot": "Add method is_using_ability to check if the unit is using a specific ability, refactor is_moving, is_patrolling, is_gathering, is_returning methods to use is_using_ability for code consistency."
    },
    {
        "org_diff": "diff --git a/fkie_master_discovery/src/fkie_master_discovery/master_discovery.py b/fkie_master_discovery/src/fkie_master_discovery/master_discovery.py @@ -893,9 +893,6 @@ class Discoverer(object):\nif firstc != b'R':\n# ignore the message. it does not start with 'R'\nreturn\n- # map local addresses to locahost\n- if address[0] in get_local_addresses():\n- address = ('localhost', address[1])\nmaster_key = (address, monitor_port)\nif version >= 3 and secs == 0 and nsecs == 0:\n# is it a request to update the state\n",
        "org_msg": "fkie_master_discovery: removed map of local addresses to localhost\nThis caused problems if ROS_IP of ROS_HOSTNAME was used",
        "sim_msg": "S4048 SSH autodetect support",
        "sim_diff": "diff --git a/netmiko/ssh_autodetect.py b/netmiko/ssh_autodetect.py @@ -106,6 +106,12 @@ SSH_MAPPER_BASE = {\n\"priority\": 99,\n\"dispatch\": \"_autodetect_std\",\n},\n+ 'dell_force10': {\n+ \"cmd\": \"show version | grep Type\",\n+ \"search_patterns\": [\"S4048-ON\"],\n+ \"priority\": 99,\n+ \"dispatch\": \"_autodetect_std\",\n+ },\n}\n",
        "chatgpt_cot": "Remove unnecessary code to map local addresses to localhost in Discoverer class. Fixes issue with message not starting with 'R'."
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/master_view_proxy.py b/node_manager_fkie/src/node_manager_fkie/master_view_proxy.py @@ -2596,7 +2596,7 @@ class MasterViewProxy(QWidget):\ninputDia = MasterParameterDialog(node.masteruri if node.masteruri is not None else self.masteruri, ''.join([node.name, roslib.names.SEP]), parent=self, store_geometry=\"edit_param_dialog\")\ninputDia.setWindowTitle('%s - %s' % (os.path.basename(node.name), \"parameter\"))\nif node.has_launch_cfgs(node.cfgs):\n- inputDia.add_warning(\"The changes may not have any effect, because the launch file was also loaded as not 'default' and the parameter in the launch file will be reloaded on start of the ROS node.\")\n+ inputDia.add_warning(\"The changes may not have any effect, because the launch file was also loaded and the parameter in the launch file will be reloaded on restart of the ROS node.\")\ninputDia.show()\nexcept Exception:\nrospy.logwarn(\"Error on retrieve parameter for %s: %s\", utf8(node.name), traceback.format_exc(1))\n",
        "org_msg": "node_manager_fkie: warn message updated",
        "sim_msg": "added label for file count",
        "sim_diff": "diff --git a/GUI_UIs/ui_dialog_manage_files.ui b/GUI_UIs/ui_dialog_manage_files.ui <string>Files</string>\n</property>\n<layout class=\"QGridLayout\" name=\"gridLayout\">\n- <item row=\"2\" column=\"0\">\n+ <item row=\"3\" column=\"0\">\n<widget class=\"QTableWidget\" name=\"tableWidget\"/>\n</item>\n<item row=\"1\" column=\"0\">\n</widget>\n</widget>\n</item>\n+ <item row=\"2\" column=\"0\">\n+ <widget class=\"QLabel\" name=\"label_fcount\">\n+ <property name=\"text\">\n+ <string>Files:</string>\n+ </property>\n+ </widget>\n+ </item>\n</layout>\n</widget>\n<resources/>\n",
        "chatgpt_cot": "\"Update warning message in MasterViewProxy to clarify the effect of changes in the launch file on parameter reloading.\""
    },
    {
        "org_diff": "diff --git a/user-dashboard/src/package.json b/user-dashboard/src/package.json \"eslint-plugin-compat\": \"^2.1.0\",\n\"eslint-plugin-import\": \"^2.8.0\",\n\"eslint-plugin-jsx-a11y\": \"^6.0.3\",\n- \"eslint-plugin-markdown\": \"^1.0.0-beta.6\",\n\"eslint-plugin-react\": \"^7.0.1\",\n\"gh-pages\": \"^1.0.0\",\n\"husky\": \"^0.14.3\",\n",
        "org_msg": "Fix user dashboard dockerhub build failed\nFix user dashboard dockerhub build failed.",
        "sim_msg": ".exact isn't supported until v3.0.0",
        "sim_diff": "diff --git a/package.json b/package.json \"rc-slider\": \"^8.3.1\",\n\"react-addons-shallow-compare\": \"^15.6.0\",\n\"react-dates\": \"^20.1.0\",\n- \"react-docgen\": \"^2.21.0\",\n+ \"react-docgen\": \"^3.0.0\",\n\"react-dropzone\": \"^4.1.2\",\n\"react-markdown\": \"^4.0.6\",\n\"react-select-fast-filter-options\": \"^0.2.3\",\n",
        "chatgpt_cot": "\"Remove markdown eslint plugin to resolve compatibility issues and optimize the dependencies in the package.json file.\""
    },
    {
        "org_diff": "diff --git a/README.md b/README.md @@ -12,6 +12,8 @@ You'll need Python 3.6 or newer.\npip3 install --user --upgrade sc2\n```\n+Please note that not all commits are not released to PyPI. Releases are tagged with version number. You can see latest released versions from [tags page](https://github.com/Dentosal/python-sc2/tags).\n+\nYou'll also need an StarCraft II executable. If you are running Windows or macOS, just install the normal SC2 from blizzard app. [The free starter edition works too.](https://us.battle.net/account/sc2/starter-edition/). Linux users must use the [Linux binary](https://github.com/Blizzard/s2client-proto#downloads).\nYou probably want some maps too. Offical map downloads are available from [Blizzard/s2client-proto](https://github.com/Blizzard/s2client-proto#downloads),\n",
        "org_msg": "Add mention about releases and tags",
        "sim_msg": "highlighted code in readme",
        "sim_diff": "diff --git a/README.rst b/README.rst @@ -15,12 +15,12 @@ Installation\nThe package is currently not available directly via PyPI. Instead, follow these steps\nto install the development version:\n-1. Download the repository if you have not done so already: `git clone https://github.com/mloning/python_utils.git`\n-2. Move into the root directory: `cd sktime`\n-3. Make sure your local version is up-to-date: `git pull`\n-4. Switch onto the development branch: `git checkout dev`\n-5. Optionally, activate environment, e.g. with conda: `conda activate <env>`\n-6. Install package: `pip install .`\n+1. Download the repository if you have not done so already: :code:`git clone https://github.com/mloning/python_utils.git`\n+2. Move into the root directory: :code:`cd sktime`\n+3. Make sure your local version is up-to-date: :code:`git pull`\n+4. Switch onto the development branch: :code:`git checkout dev`\n+5. Optionally, activate environment, e.g. with conda: :code:`conda activate <env>`\n+6. Install package: :code:`pip install .`\nProject development\n",
        "chatgpt_cot": "Add note about releases and link to latest versions in README."
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/main_window.py b/node_manager_fkie/src/node_manager_fkie/main_window.py @@ -1982,11 +1982,10 @@ class MainWindow(QMainWindow):\ndef _url_path(self, url):\n'''Helper class for Qt5 compatibility'''\n- return url.toString()\n- # if hasattr(url, 'encodedPath'):\n- # return str(url.encodedPath())\n- # else:\n- # return str(url.path())\n+ if hasattr(url, 'encodedPath'):\n+ return str(url.encodedPath())\n+ else:\n+ return str(url.path())\ndef _url_host(self, url):\n'''Helper class for Qt5 compatibility'''\n",
        "org_msg": "node_manager_fkie: reverted url changes",
        "sim_msg": "open projet now recognises default directory",
        "sim_diff": "diff --git a/qualcoder/qualcoder.py b/qualcoder/qualcoder.py @@ -833,9 +833,11 @@ class MainWindow(QtWidgets.QMainWindow):\nself.close_project()\nself.setWindowTitle(\"QualCoder\" + _(\"Open Project\"))\nif path == \"\" or path is False:\n- #print(\"appsettings dir \", self.app.settings['directory'], os.path.expanduser('~') ) # tmp\n+ default_directory = self.app.settings['directory']\n+ if default_directory == \"\":\n+ default_directory = os.path.expanduser('~')\npath = QtWidgets.QFileDialog.getExistingDirectory(self,\n- _('Open project directory'), os.path.expanduser('~') )\n+ _('Open project directory'), default_directory)\nif path == \"\" or path is False:\nreturn\nmsg = \"\"\n",
        "chatgpt_cot": "Refactor _url_path method for Qt5 compatibility in MainWindow class. Fix return logic to handle encodedPath attribute."
    },
    {
        "org_diff": "diff --git a/fkie_node_manager/src/fkie_node_manager/parameter_list_model.py b/fkie_node_manager/src/fkie_node_manager/parameter_list_model.py @@ -61,7 +61,13 @@ class ParameterValueItem(QStandardItem):\n@param value: the value of the parameter\n@type value: C{str}\n'''\n- QStandardItem.__init__(self, utf8(value) if not isinstance(value, xmlrpcclient.Binary) else utf8(value))\n+ value_str = utf8(value) if not isinstance(value, xmlrpcclient.Binary) else utf8(value)\n+ self.read_only = False\n+ if len(value_str) > 32000:\n+ value_str = 'value size > 32000; use Ctrl+X to copy'\n+ self.read_only = True\n+ QStandardItem.__init__(self, value_str)\n+ self.setEditable(not self.read_only)\nself._name = name\n'''@ivar: the name of parameter '''\nself._value = value\n@@ -289,6 +295,9 @@ class ParameterModel(QStandardItemModel):\nif not index.isValid():\nreturn Qt.NoItemFlags\nif index.column() == 2:\n+ item = self.itemFromIndex(index)\n+ if not item.isEditable():\n+ return Qt.ItemIsEnabled | Qt.ItemIsSelectable\nreturn Qt.ItemIsEnabled | Qt.ItemIsSelectable | Qt.ItemIsEditable\nreturn Qt.ItemIsEnabled | Qt.ItemIsSelectable\n@@ -343,6 +352,5 @@ class ParameterModel(QStandardItemModel):\nitem.setEditable(False)\nitems.append(item)\nitemValue = ParameterValueItem(name, value)\n- itemValue.setEditable(True)\nitems.append(itemValue)\nreturn items\n",
        "org_msg": "fkie_node_manager: do not edit parameter with size > 32000",
        "sim_msg": "disable drag-enabled tree widget items",
        "sim_diff": "diff --git a/qualcoder/reports.py b/qualcoder/reports.py @@ -972,7 +972,7 @@ class DialogReportCodes(QtWidgets.QDialog):\nmemo = \"Memo\"\ntop_item = QtWidgets.QTreeWidgetItem([c['name'], 'cid:' + str(c['cid']), memo])\ntop_item.setBackground(0, QBrush(QtGui.QColor(c['color']), Qt.SolidPattern))\n- top_item.setFlags(Qt.ItemIsSelectable | Qt.ItemIsUserCheckable | Qt.ItemIsEnabled | Qt.ItemIsDragEnabled)\n+ top_item.setFlags(Qt.ItemIsSelectable | Qt.ItemIsUserCheckable | Qt.ItemIsEnabled) # | Qt.ItemIsDragEnabled)\ntop_item.setToolTip(2, c['memo'])\nself.ui.treeWidget.addTopLevelItem(top_item)\nremove_items.append(c)\n@@ -992,7 +992,7 @@ class DialogReportCodes(QtWidgets.QDialog):\nmemo = _(\"Memo\")\nchild = QtWidgets.QTreeWidgetItem([c['name'], 'cid:' + str(c['cid']), memo])\nchild.setBackground(0, QBrush(QtGui.QColor(c['color']), Qt.SolidPattern))\n- child.setFlags(Qt.ItemIsSelectable | Qt.ItemIsUserCheckable | Qt.ItemIsEnabled | Qt.ItemIsDragEnabled)\n+ child.setFlags(Qt.ItemIsSelectable | Qt.ItemIsUserCheckable | Qt.ItemIsEnabled) # | Qt.ItemIsDragEnabled)\nchild.setToolTip(2, c['memo'])\nitem.addChild(child)\nc['catid'] = -1 # make unmatchable\n",
        "chatgpt_cot": "\"Add read-only functionality for long parameter values and fix editability of items in the ParameterModel in fkie_node_manager.\""
    },
    {
        "org_diff": "diff --git a/node_manager_daemon_fkie/src/node_manager_daemon_fkie/version.py b/node_manager_daemon_fkie/src/node_manager_daemon_fkie/version.py @@ -29,7 +29,7 @@ def detect_version(package):\nelif os.path.isdir(\"%s/../.git\" % pkg_path):\ntry:\nos.chdir(pkg_path)\n- ps = SupervisedPopen(['git', 'describe', '--tags', '--dirty', '--always'], stdout=subprocess.PIPE)\n+ ps = SupervisedPopen(['git', 'describe', '--tags', '--dirty', '--always', '--abbrev=8'], stdout=subprocess.PIPE)\noutput = ps.stdout.read()\nversion = output.strip()\nps = SupervisedPopen(['git', 'show', '-s', '--format=%ci'], stdout=subprocess.PIPE)\n",
        "org_msg": "fixed version check by using 8 digits to display SHA-1s",
        "sim_msg": "add copyright to package version check script",
        "sim_diff": "diff --git a/scripts/check_package_versions_in_docs.py b/scripts/check_package_versions_in_docs.py -#!/usr/bin/env python\n+#!/usr/bin/env python3\n+# -*- coding: utf-8 -*-\n+# ------------------------------------------------------------------------------\n+#\n+# Copyright 2018-2019 Fetch.AI Limited\n+#\n+# Licensed under the Apache License, Version 2.0 (the \"License\");\n+# you may not use this file except in compliance with the License.\n+# You may obtain a copy of the License at\n+#\n+# http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+# ------------------------------------------------------------------------------\n\"\"\"\nCheck that package ids are in sync with the current packages.\n",
        "chatgpt_cot": "Update git describe command in version.py to include abbreviated commit hash for better version identification."
    },
    {
        "org_diff": "diff --git a/fkie_node_manager_daemon/src/fkie_node_manager_daemon/screen.py b/fkie_node_manager_daemon/src/fkie_node_manager_daemon/screen.py @@ -177,7 +177,7 @@ def get_logfile(session=None, node=None, for_new_screen=False):\nreturn path\nif node is not None:\npath = \"%s%s.log\" % (LOG_PATH, create_session_name(node))\n- print('RETURN PATH', path)\n+ if os.path.exists(path) or for_new_screen:\nreturn path\nreturn get_ros_logfile(node)\n",
        "org_msg": "fkie_node_manager: hotfix",
        "sim_msg": "make git log call simpler",
        "sim_diff": "diff --git a/InvenTree/plugin/helpers.py b/InvenTree/plugin/helpers.py @@ -98,14 +98,16 @@ def get_git_log(path):\n\"\"\"\npath = path.replace(os.path.dirname(settings.BASE_DIR), '')[1:]\ncommand = ['git', 'log', '-n', '1', \"--pretty=format:'%H%n%aN%n%aE%n%aI%n%f%n%G?%n%GK'\", '--follow', '--', path]\n+ output = None\ntry:\noutput = str(subprocess.check_output(command, cwd=os.path.dirname(settings.BASE_DIR)), 'utf-8')[1:-1]\nif output:\noutput = output.split('\\n')\n- else:\n- output = 7 * ['']\n- except subprocess.CalledProcessError:\n- output = 7 * ['']\n+ except subprocess.CalledProcessError: # pragma: no cover\n+ pass\n+\n+ if not output:\n+ output = 7 * [''] # pragma: no cover\nreturn {'hash': output[0], 'author': output[1], 'mail': output[2], 'date': output[3], 'message': output[4], 'verified': output[5], 'key': output[6]}\n",
        "chatgpt_cot": "Remove debug print statement and add condition to check if the path exists or for new screen in get_logfile function in screen.py."
    },
    {
        "org_diff": "diff --git a/docs_generate/text_files/introduction.rst b/docs_generate/text_files/introduction.rst @@ -49,7 +49,6 @@ Information about your bot::\nself.supply_left: int # 2 for zerg, 3 for T and P at game start\n# Units\n- self.larva_count: int # 3 at game start (only zerg)\nself.warp_gate_count: Units # Your warp gate count (only protoss)\nself.idle_worker_count: int # Workers that are doing nothing\nself.army_count: int # Amount of army units\n",
        "org_msg": "Update documentation text file",
        "sim_msg": "[ServerStats] 1.6.8 Fix getguild in DM's with no guild ID for bot owner.",
        "sim_diff": "diff --git a/serverstats/serverstats.py b/serverstats/serverstats.py @@ -45,7 +45,7 @@ class ServerStats(commands.Cog):\n\"\"\"\n__author__ = [\"TrustyJAID\", \"Preda\"]\n- __version__ = \"1.6.7\"\n+ __version__ = \"1.6.8\"\ndef __init__(self, bot):\nself.bot: Red = bot\n@@ -1442,6 +1442,7 @@ class ServerStats(commands.Cog):\nguilds = [ctx.guild]\npage = 0\nif await ctx.bot.is_owner(ctx.author):\n+ if ctx.guild:\npage = ctx.bot.guilds.index(ctx.guild)\nguilds = ctx.bot.guilds\nif guild:\n",
        "chatgpt_cot": "Remove unnecessary attribute larva_count in introduction.rst."
    },
    {
        "org_diff": "diff --git a/sc2/game_state.py b/sc2/game_state.py @@ -5,6 +5,7 @@ from .ids.upgrade_id import UpgradeId\nfrom .ids.effect_id import EffectId\nfrom .position import Point2\n+\nclass Common(object):\nATTRIBUTES = [\n\"player_id\",\n@@ -14,6 +15,7 @@ class Common(object):\n\"idle_worker_count\", \"army_count\",\n\"warp_gate_count\", \"larva_count\"\n]\n+\ndef __init__(self, proto):\nself._proto = proto\n@@ -34,13 +36,16 @@ class EffectData(object):\nreturn [Point2.from_proto(p) for p in self._proto.pos]\nclass GameState(object):\n- def __init__(self, observation, game_data):\n- self.common = Common(observation.observation.player_common)\n- self.psionic_matrix = PsionicMatrix.from_proto(observation.observation.raw_data.player.power_sources)\n- self.game_loop = observation.observation.game_loop\n- self.chat = observation.chat\n- self.responseObservation = observation\n- self.actions = observation.actions\n+ def __init__(self, response_observation, game_data):\n+ self.actions = response_observation.actions\n+ self.action_errors = response_observation.action_errors\n+ self.observation = response_observation.observation\n+ self.player_result = response_observation.player_result\n+ self.chat = response_observation.chat\n+ self.common = Common(self.observation.player_common)\n+ self.units = Units.from_proto(self.observation.raw_data.units, game_data)\n+ self.psionic_matrix = PsionicMatrix.from_proto(self.observation.raw_data.player.power_sources)\n+ self.game_loop = self.observation.game_loop\ndestructables = [x for x in observation.observation.raw_data.units if x.alliance == 3 and x.radius > 1.5] # all destructable rocks except the one below the main base ramps\nself.destructables = Units.from_proto(destructables, game_data)\n",
        "org_msg": "Add missing properties of ResponseObservarion to game_state.py",
        "sim_msg": "tests for sub and mul",
        "sim_diff": "diff --git a/test/torch/tensors/test_chinese_remainder.py b/test/torch/tensors/test_chinese_remainder.py @@ -50,13 +50,9 @@ def test_eq():\nexp_ab = torch.tensor([1, 1]).fix_prec(field=21, precision_fractional=0)\nexp_ac = torch.tensor([0, 1]).fix_prec(field=21, precision_fractional=0)\n- print(eq_ab)\n- print(exp_ab)\n-\nassert ((eq_ab == exp_ab).all())\nassert ((eq_ac == exp_ac).all())\n-\"\"\"\ndef test_add():\nres_3 = torch.tensor([[1, 2], [0, 1]]).fix_prec(field=3, precision_fractional=0)\n@@ -73,15 +69,48 @@ def test_add():\nexp_res = {3: exp_3, 7: exp_7}\nexp = syft.CRTTensor(exp_res).wrap()\n- assert result == exp\n+ assert (result.child.solve_system() == exp.child.solve_system()).all()\n+\n+\n+def test_sub():\n+ res_a3 = torch.tensor([[1, 2], [0, 1]]).fix_prec(field=3, precision_fractional=0)\n+ res_a7 = torch.tensor([[3, 4], [5, 6]]).fix_prec(field=7, precision_fractional=0)\n+ residues_a = {3: res_a3, 7: res_a7}\n+\n+ res_b3 = torch.tensor([[1, 1], [0, 2]]).fix_prec(field=3, precision_fractional=0)\n+ res_b7 = torch.tensor([[5, 1], [5, 2]]).fix_prec(field=7, precision_fractional=0)\n+ residues_b = {3: res_b3, 7: res_b7}\n+\n+ crt_a = syft.CRTTensor(residues_a).wrap()\n+ crt_b = syft.CRTTensor(residues_b).wrap()\n+\n+ result = crt_a - crt_b\n+\n+ exp_3 = torch.tensor([[0, 1], [0, 2]]).fix_prec(field=3, precision_fractional=0)\n+ exp_7 = torch.tensor([[5, 3], [0, 4]]).fix_prec(field=7, precision_fractional=0)\n+ exp_res = {3: exp_3, 7: exp_7}\n+ exp = syft.CRTTensor(exp_res).wrap()\n+\n+ assert (result.child.solve_system() == exp.child.solve_system()).all()\n-def test_sub(workers):\n- bob, alice, james = (workers[\"bob\"], workers[\"alice\"], workers[\"james\"])\n+def test_mul():\n+ res_3 = torch.tensor([[1, 2], [0, 1]]).fix_prec(field=3, precision_fractional=0)\n+ res_7 = torch.tensor([[3, 4], [5, 6]]).fix_prec(field=7, precision_fractional=0)\n+ residues = {3: res_3, 7: res_7}\n-def test_mul(workers):\n- bob, alice, james = (workers[\"bob\"], workers[\"alice\"], workers[\"james\"])\n+ crt1 = syft.CRTTensor(residues).wrap()\n+ crt2 = syft.CRTTensor(residues).wrap()\n+ result = crt1 * crt2\n+\n+ exp_3 = torch.tensor([[1, 1], [0, 1]]).fix_prec(field=3, precision_fractional=0)\n+ exp_7 = torch.tensor([[2, 2], [4, 1]]).fix_prec(field=7, precision_fractional=0)\n+ exp_res = {3: exp_3, 7: exp_7}\n+ exp = syft.CRTTensor(exp_res).wrap()\n+\n+ assert (result.child.solve_system() == exp.child.solve_system()).all()\n+\"\"\"\ndef test_torch_sum(workers):\nalice, bob, james = workers[\"alice\"], workers[\"bob\"], workers[\"james\"]\n",
        "chatgpt_cot": "Refactor GameState constructor to accept response_observation and game_data. Also, refactor the common attribute initialization."
    },
    {
        "org_diff": "diff --git a/sc2/units.py b/sc2/units.py @@ -133,6 +133,15 @@ class Units(list):\nother = [other]\nreturn self.filter(lambda unit: unit.type_id not in other)\n+ @property\n+ def center(self):\n+ \"\"\" Returns the central point of all units in this list \"\"\"\n+ assert self.exists\n+ pos = self.random.position\n+ pos.x = sum([unit.position.x for unit in self]) / self.amount\n+ pos.y = sum([unit.position.y for unit in self]) / self.amount\n+ return pos\n+\n@property\ndef tags(self):\nreturn {unit.tag for unit in self}\n@@ -177,6 +186,10 @@ class Units(list):\ndef not_structure(self):\nreturn self.filter(lambda unit: not unit.is_structure)\n+ @property\n+ def gathering(self):\n+ return self.filter(lambda unit: not unit.is_gathering)\n+\n@property\ndef mineral_field(self):\nreturn self.filter(lambda unit: unit.is_mineral_field)\n",
        "org_msg": "Add gathering and center of units",
        "sim_msg": "datacube.model.Measurements attr access",
        "sim_diff": "diff --git a/datacube/model/__init__.py b/datacube/model/__init__.py @@ -331,6 +331,10 @@ class Measurement(dict):\nsuper().__init__(measurement_data)\n+ def __getattr__(self, key):\n+ \"\"\" Allow access to items as attributes. \"\"\"\n+ return self[key]\n+\ndef __repr__(self):\nreturn \"Measurement({})\".format(super(Measurement, self).__repr__())\n",
        "chatgpt_cot": "Add new properties for center and gathering in Units class to calculate the central point and filter units accordingly."
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/launch_list_model.py b/node_manager_fkie/src/node_manager_fkie/launch_list_model.py @@ -554,15 +554,15 @@ class LaunchListModel(QStandardItemModel):\n'''\nif path_id in [PathItem.NOTHING]:\nreturn None\n- has_alt_mod = Qt.AltModifier & QApplication.keyboardModifiers()\n+ has_shift_mod = Qt.ShiftModifier & QApplication.keyboardModifiers()\nif path_id in [PathItem.LAUNCH_FILE, PathItem.CFG_FILE, PathItem.PROFILE, PathItem.FILE, PathItem.RECENT_FILE, PathItem.LAUNCH_FILE]:\n- if not has_alt_mod:\n+ if not has_shift_mod:\nreturn path\nroot = self.invisibleRootItem()\nwhile root.rowCount():\nroot.removeRow(0)\nself.pyqt_workaround.clear()\n- if has_alt_mod:\n+ if has_shift_mod:\nif path_id in [PathItem.LAUNCH_FILE, PathItem.CFG_FILE, PathItem.PROFILE, PathItem.FILE, PathItem.RECENT_FILE, PathItem.LAUNCH_FILE]:\nself._current_path = os.path.dirname(path)\nelse:\n",
        "org_msg": "node_manager_fkie: changed 'goto root or package' from alt to shift modifire",
        "sim_msg": "Don't try to kill docker containers if none are running.",
        "sim_diff": "diff --git a/ambassador/tests/abstract_tests.py b/ambassador/tests/abstract_tests.py @@ -134,11 +134,21 @@ class AmbassadorTest(Test):\nif not AmbassadorTest.IMAGE_BUILT:\nAmbassadorTest.IMAGE_BUILT = True\n+ cmd = ShellCommand('docker', 'ps', '-a', '-f', 'label=kat-family=ambassador', '--format', '{{.ID}}')\n+\n+ if cmd.check('find old docker container IDs'):\n+ ids = cmd.stdout.split('\\n')\n+\n+ while ids:\n+ if ids[-1]:\n+ break\n+\n+ ids.pop()\n+\n+ if ids:\nprint(\"Killing old containers...\")\n- ShellCommand.run(\"kill old containers\",\n- \"bash\", \"-c\", 'docker kill $(docker ps -a -f \\'label=kat-family=ambassador\\' --format \\'{{.ID}}\\')')\n- ShellCommand.run(\"rm old containers\",\n- \"bash\", \"-c\", 'docker rm $(docker ps -a -f \\'label=kat-family=ambassador\\' --format \\'{{.ID}}\\')')\n+ ShellCommand.run('kill old containers', 'docker', 'kill', *ids, verbose=True)\n+ ShellCommand.run('rm old containers', 'docker', 'rm', *ids, verbose=True)\ncontext = os.path.dirname(os.path.dirname(os.path.dirname(__file__)))\n",
        "chatgpt_cot": "\"Fix keyboard modifier issue in LaunchListModel\""
    },
    {
        "org_diff": "diff --git a/fkie_node_manager_daemon/src/fkie_node_manager_daemon/__init__.py b/fkie_node_manager_daemon/src/fkie_node_manager_daemon/__init__.py @@ -78,8 +78,11 @@ def set_process_name(name):\ndef init_arg_parser():\nparser = argparse.ArgumentParser()\nparser.add_argument(\"-l\", \"--load\", nargs=1, help=\"loads given file on start;\"\n+ \" statements like pkg://PACKAGE/subfolder/LAUNCH are resolved to absolute path;\"\n\" comma separated for multiple files\")\nparser.add_argument(\"-a\", \"--autostart\", nargs=1, help=\"loads given file on start and launch nodes after load launch file;\"\n+\n+ \" statements like pkg://PACKAGE/subfolder/LAUNCH are resolved to absolute path;\"\n\" comma separated for multiple files\")\nreturn parser\n",
        "org_msg": "fkie_node_manager_daemon: updated arguments help",
        "sim_msg": "retry startup",
        "sim_diff": "diff --git a/lbrynet/lbrynet_daemon/DaemonControl.py b/lbrynet/lbrynet_daemon/DaemonControl.py @@ -114,7 +114,7 @@ def update_settings_from_args(args):\n@defer.inlineCallbacks\n-def start_server_and_listen(launchui, use_auth, analytics_manager):\n+def start_server_and_listen(launchui, use_auth, analytics_manager, max_tries=5):\n\"\"\"The primary entry point for launching the daemon.\nArgs:\n@@ -124,13 +124,19 @@ def start_server_and_listen(launchui, use_auth, analytics_manager):\n\"\"\"\nanalytics_manager.send_server_startup()\nlog_support.configure_analytics_handler(analytics_manager)\n+ tries = 1\n+ while tries < max_tries:\n+ log.info('Making attempt %s / %s to startup', tries, max_tries)\ntry:\ndaemon_server = DaemonServer(analytics_manager)\nyield daemon_server.start(use_auth, launchui)\nanalytics_manager.send_server_startup_success()\n+ break\nexcept Exception as e:\nlog.exception('Failed to startup')\nanalytics_manager.send_server_startup_error(str(e))\n+ tries += 1\n+ else:\nreactor.callFromThread(reactor.stop)\n",
        "chatgpt_cot": "\"Add autostart argument to init_arg_parser function to load and launch nodes after loading launch file in fkie_node_manager_daemon\""
    },
    {
        "org_diff": "diff --git a/master_sync_fkie/src/master_sync_fkie/sync_thread.py b/master_sync_fkie/src/master_sync_fkie/sync_thread.py @@ -104,7 +104,7 @@ class SyncThread(object):\n# setup the filter\nself._filter = FilterInterface()\nself._filter.load(self.name,\n- ['/rosout', rospy.get_name(), self.discoverer_name, '/node_manager', '/zeroconf'], [],\n+ ['/rosout', rospy.get_name(), self.discoverer_name, '/node_manager', '/node_manager_daemon', '/zeroconf'], [],\n['/rosout', '/rosout_agg'], ['/'] if sync_on_demand else [],\n['/*get_loggers', '/*set_logger_level'], [],\n# do not sync the bond message of the nodelets!!\n",
        "org_msg": "master_sync_fkie: added node manager daemon to defaul ignore list",
        "sim_msg": "Add Eurus mainnet and testnet contract addresses and initial block",
        "sim_diff": "diff --git a/safe_transaction_service/history/management/commands/setup_service.py b/safe_transaction_service/history/management/commands/setup_service.py @@ -270,6 +270,14 @@ MASTER_COPIES: Dict[EthereumNetwork, List[Tuple[str, int, str]]] = {\nEthereumNetwork.METER_TESTNET: [\n(\"0xfb1bffC9d739B8D520DaF37dF666da4C687191EA\", 15035438, \"1.3.0+L2\") # v1.3.0\n],\n+ EthereumNetwork.EURUS_MAINNET: [\n+ (\"0x3E5c63644E683549055b9Be8653de26E0B4CD36E\", 7127163, \"1.3.0+L2\"),\n+ (\"0xd9Db270c1B5E3Bd161E8c8503c55cEABeE709552\", 7127166, \"1.3.0\"),\n+ ],\n+ EthereumNetwork.EURUS_TESTNET: [\n+ (\"0x3E5c63644E683549055b9Be8653de26E0B4CD36E\", 12845441, \"1.3.0+L2\"),\n+ (\"0xd9Db270c1B5E3Bd161E8c8503c55cEABeE709552\", 12845443, \"1.3.0\"),\n+ ],\n}\nPROXY_FACTORIES: Dict[EthereumNetwork, List[Tuple[str, int]]] = {\n@@ -382,6 +390,12 @@ PROXY_FACTORIES: Dict[EthereumNetwork, List[Tuple[str, int]]] = {\nEthereumNetwork.METER_TESTNET: [\n(\"0xC22834581EbC8527d974F8a1c97E1bEA4EF910BC\", 15035363), # v1.3.0\n],\n+ EthereumNetwork.EURUS_MAINNET: [\n+ (\"0xa6B71E26C5e0845f74c812102Ca7114b6a896AB2\", 7127155), # v1.3.0\n+ ],\n+ EthereumNetwork.EURUS_TESTNET: [\n+ (\"0xa6B71E26C5e0845f74c812102Ca7114b6a896AB2\", 12845425), # v1.3.0\n+ ],\n}\n",
        "chatgpt_cot": "\"Add node_manager_daemon to the filter list to fix the sync issue.\""
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/launch_config.py b/node_manager_fkie/src/node_manager_fkie/launch_config.py @@ -198,7 +198,9 @@ class LaunchConfig(QObject):\nreturn path\n@classmethod\n- def included_files(cls, text_or_path, regexp_list=[QRegExp(\"\\\\btextfile\\\\b\"),\n+ def included_files(cls, text_or_path,\n+ regexp_retruns=[],\n+ regexp_filelist=[QRegExp(\"\\\\btextfile\\\\b\"),\nQRegExp(\"\\\\bfile\\\\b\"),\nQRegExp(\"\\\\bdefault\\\\b\"),\nQRegExp(\"\\\\bvalue=.*pkg:\\/\\/\\\\b\"),\n@@ -206,6 +208,10 @@ class LaunchConfig(QObject):\nQRegExp(\"\\\\bvalue=.*\\$\\(find\\\\b\"),\nQRegExp(\"\\\\bargs=.*\\$\\(find\\\\b\")],\nrecursive=True, unique=True):\n+ '''\n+ :param regexp_retruns: the list with patterns which are returned as result. If empy it's the same as 'regexp_filelist'\n+ :param regexp_filelist: the list with all patterns to find include files\n+ '''\nresult = []\nlines = []\npwd = '.'\n@@ -225,7 +231,7 @@ class LaunchConfig(QObject):\nlines = [text_or_path]\nline_index = 0\nfor line in lines:\n- index = cls._index(line, regexp_list)\n+ index = cls._index(line, regexp_filelist)\nif index > -1:\nstartIndex = line.find('\"', index)\nif startIndex > -1:\n@@ -235,13 +241,14 @@ class LaunchConfig(QObject):\ntry:\npath = cls.interpretPath(fileName, pwd)\nif os.path.isfile(path):\n+ if not regexp_retruns or cls._index(line, regexp_retruns) > -1:\nif not unique:\nresult.append((line_index, path))\nelse:\nresult.append(path)\next = os.path.splitext(path)\nif recursive and ext[1] in nm.settings().SEARCH_IN_EXT:\n- result += cls.included_files(path, regexp_list)\n+ result += cls.included_files(path, regexp_filelist)\nexcept Exception:\nimport traceback\nprint traceback.format_exc()\n@@ -267,11 +274,12 @@ class LaunchConfig(QObject):\nself.__roscfg = roscfg\nnm.filewatcher().add_launch(self.__masteruri, self.__launchFile, self.__launch_id, self.included_files(self.Filename))\nif not nm.is_local(get_hostname(self.__masteruri)):\n- files = self.included_files(self.Filename)\n-# regexp_list=[QRegExp(\"\\\\bdefault\\\\b\"),\n-# QRegExp(\"\\\\bvalue=.*pkg:\\/\\/\\\\b\"),\n-# QRegExp(\"\\\\bvalue=.*package:\\/\\/\\\\b\"),\n-# QRegExp(\"\\\\bvalue=.*\\$\\(find\\\\b\")])\n+ files = self.included_files(self.Filename,\n+ regexp_retruns=[QRegExp(\"\\\\bdefault\\\\b\"),\n+ QRegExp(\"\\\\bvalue=.*pkg:\\/\\/\\\\b\"),\n+ QRegExp(\"\\\\bvalue=.*package:\\/\\/\\\\b\"),\n+ QRegExp(\"\\\\bvalue=.*\\$\\(find\\\\b\"),\n+ QRegExp(\"\\\\bargs=.*\\$\\(find\\\\b\")])\nnm.file_watcher_param().add_launch(self.__masteruri,\nself.__launchFile,\nself.__launch_id,\n",
        "org_msg": "node_manager_fkie: file_watcher: fixed wrong detection for paths in parameter values",
        "sim_msg": "simply the logic",
        "sim_diff": "diff --git a/qlib/config.py b/qlib/config.py @@ -211,13 +211,10 @@ class QlibConfig(Config):\nself[\"provider_uri\"] = str(Path(self[\"provider_uri\"]).expanduser().resolve())\ndef get_uri_type(self):\n- win_rm = re.match(\"^[a-zA-Z]:.*\", self[\"provider_uri\"])\n- nfs_or_win_rm = re.match(\"^[^/]+:.+\", self[\"provider_uri\"])\n- # Windows path is \"C:\\\\\"\n- if win_rm is None:\n- if nfs_or_win_rm is None:\n- return QlibConfig.LOCAL_URI\n- else:\n+ is_win = re.match(\"^[a-zA-Z]:.*\", self[\"provider_uri\"]) is not None # such as 'C:\\\\data', 'D:'\n+ is_nfs_or_win = re.match(\"^[^/]+:.+\", self[\"provider_uri\"]) is not None # such as 'host:/data/' (User may define short hostname by themselves or use localhost)\n+\n+ if is_nfs_or_win and not is_win:\nreturn QlibConfig.NFS_URI\nelse:\nreturn QlibConfig.LOCAL_URI\n",
        "chatgpt_cot": "\"Add a method to the LaunchConfig class to find included files with regular expressions, fix compilation issue, and improve the file watcher.\""
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/__init__.py b/node_manager_fkie/src/node_manager_fkie/__init__.py @@ -391,6 +391,7 @@ def main(name):\ntry:\nrospy.on_shutdown(finish)\nexit_code = _QAPP.exec_()\n+ if nmd() is not None:\nnmd().stop()\nexcept Exception:\nif not rospy.is_shutdown():\n",
        "org_msg": "fixed warning on close echo dialog",
        "sim_msg": "extend timeout to kill oef",
        "sim_diff": "diff --git a/aea/cli_gui/__init__.py b/aea/cli_gui/__init__.py @@ -587,7 +587,7 @@ def _kill_running_oef_nodes():\n)\nstdout = b\"\"\ntry:\n- process.wait(5.0)\n+ process.wait(10.0)\n(stdout, stderr) = process.communicate()\nimage_ids.update(stdout.decode(\"utf-8\").splitlines())\nfinally:\n",
        "chatgpt_cot": "Add stop method call to nmd if not None to ensure proper shutdown in main function."
    },
    {
        "org_diff": "diff --git a/fkie_node_manager/src/fkie_node_manager/launch_list_model.py b/fkie_node_manager/src/fkie_node_manager/launch_list_model.py @@ -497,7 +497,7 @@ class LaunchListModel(QStandardItemModel):\ndetail_msg = utf8(error)\nif hasattr(error, 'details'):\ndetail_msg = utf8(error.details())\n- path_item = PathItem.create_row_items(utf8(error), PathItem.NOTHING, 0, 0, utf8(\"%s, please start node manager daemon\" % detail_msg))\n+ path_item = PathItem.create_row_items(utf8(\"%s, please start node manager daemon\" % detail_msg), PathItem.NOTHING, 0, 0, 'connecting to daemon...')\nroot.appendRow(path_item)\nself.pyqt_workaround[path_item[0].name] = path_item[0]\nself.error_on_path.emit(nmdurl.join(url, path), error)\n",
        "org_msg": "fkie_node_manager: changed error message in launch file browser while connecting to deamon",
        "sim_msg": "Do not catch AttributeError on 'executor' method",
        "sim_diff": "diff --git a/resources/lib/run_addon.py b/resources/lib/run_addon.py @@ -151,6 +151,8 @@ def _execute(executor_type, pathitems, params, root_handler):\n\"\"\"Execute an action as specified by the path\"\"\"\ntry:\nexecutor = executor_type(params).__getattribute__(pathitems[0] if pathitems else 'root')\n+ except AttributeError as exc:\n+ raise InvalidPathError('Unknown action {}'.format('/'.join(pathitems))) from exc\nLOG.debug('Invoking action: {}', executor.__name__)\nexecutor(pathitems=pathitems)\nif root_handler == G.MODE_DIRECTORY and not G.IS_ADDON_EXTERNAL_CALL:\n@@ -158,8 +160,6 @@ def _execute(executor_type, pathitems, params, root_handler):\nWndHomeProps[WndHomeProps.CURRENT_DIRECTORY] = executor.__name__\nWndHomeProps[WndHomeProps.CURRENT_DIRECTORY_MENU_ID] = pathitems[1] if len(pathitems) > 1 else ''\nWndHomeProps[WndHomeProps.IS_CONTAINER_REFRESHED] = None\n- except AttributeError as exc:\n- raise InvalidPathError('Unknown action {}'.format('/'.join(pathitems))) from exc\ndef _get_service_status():\n",
        "chatgpt_cot": "Fix error message creation in LaunchListModel. Modified the creation of the error message to ensure it includes the correct details and prompts to start the node manager daemon."
    },
    {
        "org_diff": "diff --git a/docs/setup_master.md b/docs/setup_master.md ## Master Node Setup\n-The [Master Node](./terminology.md) includes several services:\n+The [Master Node](terminology.md) includes several services:\n* `operator dashboard`: Provide Web UI for operators.\n* `user dashboard`: Provide Web UI for users.\n@@ -11,10 +11,11 @@ The [Master Node](./terminology.md) includes several services:\n### System Requirement\n* Hardware: 8c16g100g\n+* Linux Kernel >= 3.0.0\n* Docker engine: 1.10.0~1.13.0 (Docker 17.0+ support is experimental)\n* docker-compose: 1.8.0~1.12.0\n-The [Master Node](./terminology.md) can be deployed by in 2 steps.\n+The [Master Node](terminology.md) can be deployed by in 2 steps:\n* Clone code\n* Run setup script\n@@ -115,11 +116,22 @@ Please keep it safe by backups or using more high-available solutions.\n### Work with MacOS\n+#### Local Path Mount\nIn MacOS, Docker cannot mount local path from host by default. Hence for mongo container data volume, users need to:\n* Make sure the `/opt/cello` path exists locally, and it is writable for the current user account. Simply just run `make setup-master`.\n* Add the path to `File Sharing` list in the preference of [Docker for MacOS](https://docs.docker.com/docker-for-mac/install/), to make it mountable by container.\n+#### Install envsubst\n+macOS does not have envsubst command. In order to install it, need to use the [Homebrew](https://brew.sh) tool.\n+\n+```bash\n+$ brew install gettext\n+$ brew link gettext\n+$ export PATH=\"/usr/local/opt/gettext/bin:$PATH\"\n+$ echo 'export PATH=\"/usr/local/opt/gettext/bin:$PATH\"' >> ~/.bash_profile\n+```\n+\n## More Commands using make\nTo know more what the following make commands does please refer [make_support](./make_support.md) page.\n",
        "org_msg": "Add envsubst install to doc\nWhen starting master service, it requires the envsubst command.\nHowever, macOS does not have that tool, add into doc how to install\nit.",
        "sim_msg": "Update DOCKER_README.md\n* Update DOCKER_README.md\nFix typo in the docker name\n* Update DOCKER_README.md",
        "sim_diff": "diff --git a/openbb_terminal/DOCKER_README.md b/openbb_terminal/DOCKER_README.md @@ -85,9 +85,9 @@ If you don't have `Docker Compose` you can also use `Docker` directly to run the\nHere is the commands to run:\n```bash\n-docker pull ghcr.io/openbb-finance/openbbterminal/poetry:X.Y.Z\n+docker pull ghcr.io/openbb-finance/openbbterminal-poetry:X.Y.Z\n-docker run -v ~/.openbb_terminal/:/home/python/.openbb_terminal -v ~/OpenBBUserData:/home/python/OpenBBUserData -it --rm ghcr.io/openbb-finance/openbbterminal/poetry:X.Y.Z\n+docker run -v ~/.openbb_terminal/:/home/python/.openbb_terminal -v ~/OpenBBUserData:/home/python/OpenBBUserData -it --rm ghcr.io/openbb-finance/openbbterminal-poetry:X.Y.Z\n```\nBe sure to replace `X.Y.Z` with the version you want to pull and run.\n@@ -122,7 +122,7 @@ docker compose run poetry\nOr run `Docker` directly:\n```bash\n-docker run -v ~/.openbb_terminal:/home/python/.openbb_terminal -v ~/OpenBBUserData:/home/python/OpenBBUserData -it --rm --env DISPLAY=host.docker.internal:0.0 ghcr.io/openbb-finance/openbbterminal/poetry:X.Y.Z\n+docker run -v ~/.openbb_terminal:/home/python/.openbb_terminal -v ~/OpenBBUserData:/home/python/OpenBBUserData -it --rm --env DISPLAY=host.docker.internal:0.0 ghcr.io/openbb-finance/openbbterminal-poetry:X.Y.Z\n```\n### X-Server on macOS\n@@ -150,8 +150,8 @@ xhost + $IP\nNow we can run the docker container, adding the display to the environment:\n-```bach\n-docker run -v ~/.openbb_terminal/:/home/python/.openbb_terminal -v ~/OpenBBUserData:/home/python/OpenBBUserData -it --rm --env-file=path/to/setenv --env DISPLAY=$IP:0 ghcr.io/openbb-finance/openbbterminal/poetry:X.Y.Z\n+```bash\n+docker run -v ~/.openbb_terminal/:/home/python/.openbb_terminal -v ~/OpenBBUserData:/home/python/OpenBBUserData -it --rm --env-file=path/to/setenv --env DISPLAY=$IP:0 ghcr.io/openbb-finance/openbbterminal-poetry:X.Y.Z\n```\nThis container will be able to display all the same plots as the terminal interface.\n@@ -174,7 +174,7 @@ And run the following commands.\n```bash\nxhost +local:\n-docker run -it --rm --name openbb --env-file=./.env -e DISPLAY=$DISPLAY -v /tmp/.X11-unix:/tmp/.X11-unix ghcr.io/openbb-finance/openbbterminal/poetry:X.Y.Z\n+docker run -it --rm --name openbb --env-file=./.env -e DISPLAY=$DISPLAY -v /tmp/.X11-unix:/tmp/.X11-unix ghcr.io/openbb-finance/openbbterminal-poetry:X.Y.Z\nxhost -local:\n```\n",
        "chatgpt_cot": "\"Fix file paths, add Linux Kernel requirement, and provide instructions for MacOS. Also, update make commands for clarity.\""
    },
    {
        "org_diff": "diff --git a/sc2/bot_ai.py b/sc2/bot_ai.py @@ -124,7 +124,14 @@ class BotAI(object):\nreturn closest\nasync def distribute_workers(self):\n- \"\"\"Distributes workers across all the bases taken.\"\"\"\n+ \"\"\"\n+ Distributes workers across all the bases taken.\n+ WARNING: This is quite slow when there are lots of workers or multiple bases.\n+ \"\"\"\n+\n+ # TODO:\n+ # OPTIMIZE: Assign idle workers smarter\n+ # OPTIMIZE: Never use same worker mutltiple times\nexpansion_locations = self.expansion_locations\nowned_expansions = self.owned_expansions\n",
        "org_msg": "Add warning about BotAI.distribute_workers slowness",
        "sim_msg": "/8 cpu count threads on multithread method worker base",
        "sim_diff": "diff --git a/workers/worker_base.py b/workers/worker_base.py @@ -966,7 +966,7 @@ class Worker():\nvalid_url_count = len(urls)\nwhile len(urls) > 0 and attempts < max_attempts:\n- with concurrent.futures.ThreadPoolExecutor(max_workers=multiprocessing.cpu_count()/4) as executor:\n+ with concurrent.futures.ThreadPoolExecutor(max_workers=max(multiprocessing.cpu_count()/8, 1)) as executor:\n# Start the load operations and mark each future with its URL\nfuture_to_url = {executor.submit(load_url, *url): url for url in urls}\nself.logger.info(\"Multithreaded urls and returned status codes:\\n\")\n",
        "chatgpt_cot": "\"Optimize worker assignment and usage in distribute_workers method in BotAI file to improve performance and avoid using the same worker multiple times.\""
    },
    {
        "org_diff": "diff --git a/src/api-engine/api/routes/channel/views.py b/src/api-engine/api/routes/channel/views.py @@ -105,7 +105,7 @@ class ChannelViewSet(viewsets.ViewSet):\nchannel.organizations.add(org)\nordering_node = Node.objects.filter(\n- type=\"orderer\").filter(organization=org).get()\n+ type=\"orderer\").filter(organization=org).first()\norg_name = org.name\norg_domain = org_name.split(\".\", 1)[1]\nmsp_id = org_name.split(\".\")[0].capitalize()\n",
        "org_msg": "get the first node of ordering nodes.",
        "sim_msg": "Fixing cases where channel image may be blank",
        "sim_diff": "diff --git a/classes/Channel.py b/classes/Channel.py @@ -61,7 +61,7 @@ class Channel(db.Model):\n'owningUser': self.owningUser,\n'channelName': self.channelName,\n'description': self.description,\n- 'channelImage': \"/images/\" + self.imageLocation,\n+ 'channelImage': \"/images/\" + str(self.imageLocation),\n'offlineImageLocation': \"/images/\" + str(self.offlineImageLocation),\n'topic': self.topic,\n'views': self.views,\n",
        "chatgpt_cot": "Fix issue with Node filter in ChannelViewSet\nThe code changes modify the Node filter from .get() to .first() to fix an issue with filtering in the ChannelViewSet class."
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/node_tree_model.py b/node_manager_fkie/src/node_manager_fkie/node_tree_model.py @@ -115,6 +115,7 @@ class GroupItem(QStandardItem):\nself._is_group = is_group\nself._state = NodeItem.STATE_OFF\nself.diagnostic_array = []\n+ self.is_system_group = name == 'SYSTEM'\n@property\ndef name(self):\n@@ -147,16 +148,24 @@ class GroupItem(QStandardItem):\n'''\nreturn self._state\n+ @property\n+ def is_group(self):\n+ return self._is_group\n+\n+ @property\n+ def cfgs(self):\n+ return self.get_configs()\n+\ndef get_namespace(self):\nname = self._name\nif type(self) == HostItem:\nname = rospy.names.SEP\n- elif type(self) == GroupItem:\n- name = namespace(name)\n+ elif type(self) == GroupItem and self._is_group:\n+ name = namespace(self._name)\nresult = name\nif self.parent_item is not None:\n- result = normns(self.parent_item.get_namespace() + result)\n- return result\n+ result = self.parent_item.get_namespace() + rospy.names.SEP + result\n+ return normns(result)\ndef count_nodes(self):\n'''\n@@ -416,22 +425,6 @@ class GroupItem(QStandardItem):\nself.appendRow(row)\nrow[0].parent_item = self\n-\n- def get_group_items(self):\n- '''\n- Returns all group items this group\n-\n- :return: The list with group items.\n- :rtype: list(:class:`GroupItem`)\n- '''\n- result = []\n- for i in range(self.rowCount()):\n- item = self.child(i)\n- if isinstance(item, GroupItem):\n- result.append(item)\n- result[len(result):] = item.get_group_items()\n- return result\n-\ndef clearup(self, fixed_node_names=None):\n'''\nRemoves not running and not configured nodes.\n@@ -753,6 +746,10 @@ class GroupItem(QStandardItem):\nCompares the name of the group.\n'''\nif isinstance(item, str) or isinstance(item, unicode):\n+ # put the group with SYSTEM nodes at the end\n+ if self.is_system_group:\n+ if self.name.lower() != item.lower():\n+ return True\nreturn self.name.lower() > item.lower()\nelif not (item is None):\nreturn self.name.lower() > item.name.lower()\n@@ -1026,7 +1023,7 @@ class NodeItem(QStandardItem):\nif parent_item is None:\nself.setText(self._node_info.name)\nelse:\n- self.setText(self._node_info.name.replace(parent_item.get_namespace(), ''))\n+ self.setText(self._node_info.name.replace(parent_item.get_namespace(), '', 1))\n@property\ndef node_info(self):\n",
        "org_msg": "node_manager_fkie: fix crash and sort of namespaces",
        "sim_msg": "Backwards compatibility for old manager",
        "sim_diff": "diff --git a/avalon/tools/manager/app.py b/avalon/tools/manager/app.py @@ -173,7 +173,19 @@ class Window(QtWidgets.QDialog):\nfor container in api.registered_host().ls():\nhas[\"containers\"] = True\n+ if container[\"schema\"] == \"avalon-core:container-1.0\":\n+ name = container[\"objectName\"]\n+ container[\"representation\"] = str(io.locate([\n+ api.session[\"project\"],\n+ container[\"asset\"],\n+ container[\"subset\"],\n+ container[\"version\"],\n+ container[\"representation\"].strip(\".\"),\n+ ]))\n+\n+ else:\nname = \"{namespace}{name}\".format(**container)\n+\nitem = QtWidgets.QListWidgetItem(name)\nitem.setData(QtCore.Qt.ItemIsEnabled, True)\nitem.setData(ContainerRole, container)\n",
        "chatgpt_cot": "\"Add property to determine system group. Fix compilation issue due to new method. Remove get_group_items to improve code readability.\""
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/parameter_dialog.py b/node_manager_fkie/src/node_manager_fkie/parameter_dialog.py @@ -1015,21 +1015,21 @@ class MasterParameterDialog(ParameterDialog):\ngiven namespace.\n'''\n- def __init__(self, masteruri, ns='/', parent=None):\n+ def __init__(self, masteruri, ns='/', parent=None, store_geometry=''):\n'''\n@param masteruri: if the master uri is not None, the parameter are retrieved from ROS parameter server.\n@type masteruri: C{str}\n@param ns: namespace of the parameter retrieved from the ROS parameter server.\n@type ns: C{str}\n'''\n- ParameterDialog.__init__(self, dict(), parent=parent)\n+ ParameterDialog.__init__(self, dict(), parent=parent, store_geometry=store_geometry)\nself.masteruri = masteruri\nself.ns = ns\nself.is_delivered = False\nself.is_send = False\nself.mIcon = QIcon(\":/icons/default_cfg.png\")\nself.setWindowIcon(self.mIcon)\n- self.resize(450, 300)\n+ # self.resize(450, 300)\nself.add_new_button = QPushButton()\nself.add_new_button.setIcon(QIcon(':/icons/crystal_clear_add.png'))\nself.add_new_button.clicked.connect(self._on_add_parameter)\n",
        "org_msg": "node_manager_fkie: fixed open parameter dialog",
        "sim_msg": "Fix bug in Creator, on editing the name",
        "sim_diff": "diff --git a/mindbender/tools/creator/app.py b/mindbender/tools/creator/app.py @@ -81,15 +81,25 @@ class Window(QtWidgets.QDialog):\ncreate_btn.clicked.connect(self.on_create)\nname.returnPressed.connect(self.on_create)\n- name.textChanged.connect(self.on_data_changed)\n- listing.currentItemChanged.connect(self.on_data_changed)\n+ name.textChanged.connect(self.on_name_changed)\n+ listing.currentItemChanged.connect(self.on_selection_changed)\n# Defaults\nself.resize(220, 250)\nname.setFocus()\ncreate_btn.setEnabled(False)\n- def on_data_changed(self, *args):\n+ def on_name_changed(self, *args):\n+ button = self.findChild(QtWidgets.QPushButton, \"Create Button\")\n+ name = self.findChild(QtWidgets.QWidget, \"Name\")\n+ item = self.findChild(QtWidgets.QWidget, \"Listing\").currentItem()\n+\n+ button.setEnabled(\n+ name.text().strip() != \"\" and\n+ item.data(QtCore.Qt.ItemIsEnabled)\n+ )\n+\n+ def on_selection_changed(self, *args):\nbutton = self.findChild(QtWidgets.QPushButton, \"Create Button\")\nname = self.findChild(QtWidgets.QWidget, \"Name\")\nitem = self.findChild(QtWidgets.QWidget, \"Listing\").currentItem()\n",
        "chatgpt_cot": "\"Fix parameter_dialog.py to include store_geometry in __init__ method for MasterParameterDialog to handle geometry storage for ROS parameter server.\""
    },
    {
        "org_diff": "diff --git a/fkie_node_manager/scripts/remote_nm.py b/fkie_node_manager/scripts/remote_nm.py @@ -184,6 +184,23 @@ def rosconsole_cfg_file(package, loglevel='INFO'):\nreturn result\n+def remove_src_binary(cmdlist):\n+ result = []\n+ count = 0\n+ if len(cmdlist) > 1:\n+ for c in cmdlist:\n+ if c.find('/src/') == -1:\n+ result.append(c)\n+ count += 1\n+ else:\n+ result = cmdlist\n+ if count > 1:\n+ # we have more binaries in src directory\n+ # aks the user\n+ result = cmdlist\n+ return result\n+\n+\ndef runNode(package, executable, name, args, prefix='', repawn=False, masteruri=None, loglevel=''):\n'''\nRuns a ROS node. Starts a roscore if needed.\n@@ -204,6 +221,7 @@ def runNode(package, executable, name, args, prefix='', repawn=False, masteruri=\nif cmd is None or len(cmd) == 0:\nraise StartException(' '.join([executable, 'in package [', package, '] not found!\\n\\nThe package was created?\\nIs the binary executable?\\n']))\n# create string for node parameter. Set arguments with spaces into \"'\".\n+ cmd = remove_src_binary(cmd)\nnode_params = ' '.join(''.join([\"'\", a, \"'\"]) if a.find(' ') > -1 else a for a in args[1:])\ncmd_args = [screen.get_cmd(name), RESPAWN_SCRIPT if repawn else '', prefix, cmd[0], node_params]\nprint('run on remote host:', ' '.join(cmd_args))\n",
        "org_msg": "fkie_node_manager: remove binaries in src path if multiple executables are found",
        "sim_msg": "Add basic tests for P2PLibp2pConnection",
        "sim_diff": "diff --git a/packages/fetchai/connections/p2p_libp2p/connection.py b/packages/fetchai/connections/p2p_libp2p/connection.py @@ -44,6 +44,8 @@ WORK_DIR = os.getcwd()\nLIBP2P_NODE_MODULE = str(os.path.abspath(os.path.dirname(__file__)))\n+LIBP2P_NODE_MODULE_NAME = \"libp2p_node\"\n+\nLIBP2P_NODE_LOG_FILE = \"libp2p_node.log\"\nLIBP2P_NODE_ENV_FILE = \".env.libp2p\"\n@@ -112,12 +114,12 @@ def _golang_module_build(path: str, log_file_desc: IO[str]) -> subprocess.Popen:\ndef _golang_module_run(\n- path: str, args: Sequence[str], log_file_desc: IO[str]\n+ path: str, name: str, args: Sequence[str], log_file_desc: IO[str]\n) -> subprocess.Popen:\n\"\"\"\nRuns a built module located at `path`\n\"\"\"\n- cmd = [\"go\", \"run\", \".\"]\n+ cmd = [os.path.join(path, name)]\ncmd.extend(args)\n@@ -218,7 +220,7 @@ class Libp2pNode:\nself.entry_peers = entry_peers if entry_peers is not None else []\n# node startup\n- self.source = module_path\n+ self.source = os.path.abspath(module_path)\nself.clargs = clargs if clargs is not None else []\n# log file\n@@ -287,7 +289,7 @@ class Libp2pNode:\n# run node\nlogger.info(\"Starting libp2p node...\")\n- self.proc = _golang_module_run(self.source, self.clargs, self._log_file_desc)\n+ self.proc = _golang_module_run(self.source, LIBP2P_NODE_MODULE_NAME, self.clargs, self._log_file_desc)\nlogger.info(\"Connecting to libp2p node...\")\nawait self._connect()\n@@ -368,7 +370,9 @@ class Libp2pNode:\ndef stop(self) -> None:\n# TOFIX(LR) wait is blocking and proc can ignore terminate\nif self.proc is not None:\n+ logger.debug(\"Terminating node process {}...\".format(self.proc.pid))\nself.proc.terminate()\n+ logger.debug(\"Waiting for node process {} to terminate...\".format(self.proc.pid))\nself.proc.wait()\nelse:\nlogger.debug(\"Called stop when process not set!\")\n",
        "chatgpt_cot": "\"Add function to remove source binaries and update node parameters to avoid issues with spaces in arguments in remote_nm.py\""
    },
    {
        "org_diff": "diff --git a/src/operator-dashboard/agent/ansible/roles/deploy_k8s/pubconn/tasks/apply.yml b/src/operator-dashboard/agent/ansible/roles/deploy_k8s/pubconn/tasks/apply.yml - name: Query service ports\nshell: >-\n- kubectl --kubeconfig kubeconfig get services\n+ ./kubectl --kubeconfig kubeconfig get services\n| grep NodePort | awk '{print $1, $5}'\nregister: ports\nargs:\n",
        "org_msg": "Fix kubectl not in default location issue",
        "sim_msg": "tests: ansible_test shouldn't have a default become password",
        "sim_diff": "diff --git a/.travis/ansible_tests.sh b/.travis/ansible_tests.sh @@ -45,7 +45,6 @@ echo \\\nansible_port=2201 \\\nansible_python_interpreter=/usr/bin/python2.7 \\\nansible_user=mitogen__has_sudo_pubkey \\\n- ansible_become_pass=has_sudo_pubkey_password \\\nansible_ssh_private_key_file=${TRAVIS_BUILD_DIR}/tests/data/docker/mitogen__has_sudo_pubkey.key \\\n>> ${TMPDIR}/hosts\necho travis_fold:end:job_setup\n",
        "chatgpt_cot": "Fix shell command to use local kubectl binary in apply.yml. This ensures correct service port querying in the Kubernetes deployment process."
    },
    {
        "org_diff": "diff --git a/src/api-engine/api/lib/peer/chaincode.py b/src/api-engine/api/lib/peer/chaincode.py import os\n+import json\nfrom api.lib.peer.basicEnv import BasicEnv\n-from api.config import FABRIC_TOOL\n+from api.config import FABRIC_TOOL, FABRIC_CFG\nclass ChainCode(BasicEnv):\n@@ -39,3 +40,49 @@ class ChainCode(BasicEnv):\nerr_msg = \"install chaincode failed for {}!\".format(e)\nraise Exception(err_msg)\nreturn res\n+\n+ def lifecycle_query_installed(self, timeout):\n+ \"\"\"\n+ get the chaincode info installed in peer.\n+ :param timeout:\n+ :return: res 0 means success\n+ installed_chaincodes: the json format of installed_chaincodes info\n+ \"\"\"\n+\n+ try:\n+ res = os.system(\"{} lifecycle chaincode queryinstalled --output json --connTimeout {}\"\n+ \" > ./queryInstalled.txt\".format(self.peer, timeout))\n+ with open('./queryInstalled.txt', 'r', encoding='utf-8') as f:\n+ content = f.read()\n+ os.system(\"rm ./queryInstalled.txt\")\n+ installed_chaincodes = json.loads(content)\n+ except Exception as e:\n+ err_msg = \"query_installed chaincode info failed for {}!\".format(e)\n+ raise Exception(err_msg)\n+ return res, installed_chaincodes\n+\n+ def lifecycle_get_installed_package(self, timeout):\n+ \"\"\"\n+ lifecycle_query_installed will return a list installed in peer.\n+ then execute cmd to get all chaincode with tar.gz format installed in peer.\n+ :param timeout:\n+ :return: res_return: 0 means success get all chaincode in peers.\n+ \"\"\"\n+ try:\n+ res, installed = self.lifecycle_query_installed(\"3s\")\n+ res_return = 0\n+ if res == 0:\n+ for item in installed['installed_chaincodes']:\n+ res_get = os.system(\"{} lifecycle chaincode getinstalledpackage --package-id {} \"\n+ \"--output-directory {} --connTimeout {}\".format(self.peer,\n+ item['package_id'], FABRIC_CFG, timeout))\n+ res_get = res_get >> 8\n+ res_return = res_return or res_get\n+ else:\n+ print(\"package_id get failed.\")\n+ return 1, {}\n+ except Exception as e:\n+ err_msg = \"get_installed_package failed for {}!\".format(e)\n+ raise Exception(err_msg)\n+ return res_return\n+\n",
        "org_msg": "[#issue-320] lifecycle_query_installed&lifecycle_get_installed_package\nlifecycle_query_installed will get all chaincode information installed in peer. lifecycle_get_installed_package will get all chaincode files installed in peer,\nit's input is packid_id.\nClose #issue-320",
        "sim_msg": "make peer search asynchronous",
        "sim_diff": "diff --git a/lbrynet/dht/peerfinder.py b/lbrynet/dht/peerfinder.py @@ -27,8 +27,8 @@ class DHTPeerFinder(DummyPeerFinder):\nself.dht_node = dht_node\nself.peer_manager = peer_manager\nself.peers = {}\n+ self._ongoing_searchs = {}\n- @defer.inlineCallbacks\ndef find_peers_for_blob(self, blob_hash, timeout=None, filter_self=True):\n\"\"\"\nFind peers for blob in the DHT\n@@ -40,25 +40,27 @@ class DHTPeerFinder(DummyPeerFinder):\nReturns:\nlist of peers for the blob\n\"\"\"\n- if blob_hash not in self.peers:\n- self.peers[blob_hash] = [(self.dht_node.externalIP, self.dht_node.peerPort)]\n+ self.peers.setdefault(blob_hash, {(self.dht_node.externalIP, self.dht_node.peerPort,)})\n+ if not blob_hash in self._ongoing_searchs:\n+ self._ongoing_searchs[blob_hash] = self._execute_peer_search(blob_hash, timeout)\n+ peers = set(self._filter_self(blob_hash) if filter_self else self.peers[blob_hash])\n+ return defer.succeed([self.peer_manager.get_peer(*peer) for peer in peers])\n+\n+ @defer.inlineCallbacks\n+ def _execute_peer_search(self, blob_hash, timeout):\n+ try:\nbin_hash = binascii.unhexlify(blob_hash)\nfinished_deferred = self.dht_node.iterativeFindValue(bin_hash, exclude=self.peers[blob_hash])\ntimeout = timeout or conf.settings['peer_search_timeout']\nif timeout:\nfinished_deferred.addTimeout(timeout, self.dht_node.clock)\n- try:\npeer_list = yield finished_deferred\n+ self.peers[blob_hash].update(set((host, port) for _, host, port in peer_list))\nexcept defer.TimeoutError:\n- log.debug(\"DHT timed out while looking peers for blob %s after %s seconds\",\n- blob_hash, timeout)\n- peer_list = []\n+ log.debug(\"DHT timed out while looking peers for blob %s after %s seconds\", blob_hash, timeout)\n+ finally:\n+ del self._ongoing_searchs[blob_hash]\n- peers = set(peer_list)\n- results = []\n- for node_id, host, port in peers:\n- if filter_self and (host, port) == (self.dht_node.externalIP, self.dht_node.peerPort):\n- continue\n- results.append(self.peer_manager.get_peer(host, port))\n- self.peers[blob_hash].append((host, port))\n- defer.returnValue(results)\n+ def _filter_self(self, blob_hash):\n+ my_host, my_port = self.dht_node.externalIP, self.dht_node.peerPort\n+ return set((host, port) for host, port in self.peers[blob_hash] if (host, port) != (my_host, my_port))\n",
        "chatgpt_cot": "Add lifecycle_query_installed and lifecycle_get_installed_package methods to ChainCode class for querying and getting installed chaincode info."
    },
    {
        "org_diff": "diff --git a/rasa_core_sdk/endpoint.py b/rasa_core_sdk/endpoint.py @@ -73,8 +73,7 @@ def endpoint_app(cors_origins=None,\nresponse = executor.run(action_call)\nexcept ActionExecutionError as e:\nlogger.error(str(e))\n- result = {\"error\": str(e),\n- \"action\": action_call.get(\"next_action\")}\n+ result = {\"error\": str(e)}\nresponse = jsonify(result)\nresponse.status_code = 400\nreturn response\n",
        "org_msg": "remove action name from error response",
        "sim_msg": "refacto: black formatting applied",
        "sim_diff": "diff --git a/addok/http/base.py b/addok/http/base.py @@ -194,7 +194,11 @@ class Reverse(View):\nclass Health(View):\ndef on_get(self, req, resp):\n- return self.json(req, resp, {\"status\": \"HEALTHY\", \"redis_version\": DB.info().get(\"redis_version\")})\n+ return self.json(\n+ req,\n+ resp,\n+ {\"status\": \"HEALTHY\", \"redis_version\": DB.info().get(\"redis_version\")},\n+ )\ndef register_http_endpoint(api):\n",
        "chatgpt_cot": "Refactor endpoint_app function in endpoint.py to handle ActionExecutionError, removing unnecessary \"action\" key from result dictionary."
    },
    {
        "org_diff": "diff --git a/sc2/bot_ai.py b/sc2/bot_ai.py @@ -428,7 +428,7 @@ class BotAI(object):\nself.on_building_construction_complete(unit)\ndef _issue_unit_dead_events(self):\n- event = self.state.responseObservation.observation.raw_data.event\n+ event = self.state.observation.raw_data.event\nif event is not None:\nfor tag in event.dead_units:\nself.on_unit_destroyed(tag)\n",
        "org_msg": "Fix error occured after removing resonseObservation from GameState",
        "sim_msg": "add function for checking my new dog's age in years",
        "sim_diff": "diff --git a/pajbot/bot.py b/pajbot/bot.py @@ -217,6 +217,7 @@ class Bot:\nself.data_cb['stream_status'] = self.c_stream_status\nself.data_cb['bot_uptime'] = self.c_uptime\nself.data_cb['current_time'] = self.c_current_time\n+ self.data_cb['molly_age_in_years'] = self.c_molly_age_in_years\nself.silent = True if args.silent else self.silent\n@@ -477,6 +478,12 @@ class Bot:\ndef c_current_time(self):\nreturn datetime.datetime.now()\n+ def c_molly_age_in_years(self):\n+ molly_birth = datetime.datetime(2018, 10, 29)\n+ now = datetime.datetime.now()\n+ diff = now-molly_birth\n+ return diff.total_seconds()/3600/24/365\n+\n@property\ndef is_online(self):\nreturn self.stream_manager.online\n",
        "chatgpt_cot": "Fix observation attribute in BotAI class. The modification updates the attribute \"responseObservation\" to \"observation\" to resolve the issue with observation data access."
    },
    {
        "org_diff": "diff --git a/fkie_node_manager/src/fkie_node_manager/editor/editor.py b/fkie_node_manager/src/fkie_node_manager/editor/editor.py @@ -121,6 +121,7 @@ class Editor(QMainWindow):\nself.setWindowTitle(window_title)\nself.init_filenames = filenames\nself._search_thread = None\n+ self._last_search_request = None\n# list with all open files\nself.files = []\n# create tabs for files\n@@ -409,6 +410,7 @@ class Editor(QMainWindow):\nself._search_thread = TextSearchThread(search_text, filename, path_text={filename: self.tabWidget.widget(0).document().toPlainText()}, recursive=True, only_launch=only_launch)\nself._search_thread.search_result_signal.connect(self.on_search_result_on_open)\nself._search_thread.warning_signal.connect(self.on_search_result_warning)\n+ self._last_search_request = (filename, search_text, insert_index, goto_line, only_launch)\nif not self.graph_view.is_loading():\nself.on_graph_info(\"search thread: start search for '%s'\" % self._search_thread._search_text)\nself._search_thread.start()\n@@ -464,10 +466,12 @@ class Editor(QMainWindow):\ndef on_text_changed(self, value=\"\"):\nif self.tabWidget.currentWidget().hasFocus():\nself.find_dialog.file_changed(self.tabWidget.currentWidget().filename)\n+ self._last_search_request = None\ndef on_tab_changed(self, index):\nif index > -1:\nself.graph_view.set_file(self.tabWidget.widget(index).filename, self.tabWidget.widget(0).filename)\n+ self._last_search_request = None\ndef on_close_tab(self, tab_index):\n'''\n@@ -495,6 +499,7 @@ class Editor(QMainWindow):\n# close editor, if no tabs are open\nif not self.tabWidget.count():\nself.close()\n+ self._last_search_request = None\nexcept Exception:\nimport traceback\nrospy.logwarn(\"Error while close tab %s: %s\", str(tab_index), traceback.format_exc(1))\n@@ -512,6 +517,8 @@ class Editor(QMainWindow):\nif self.tabWidget.widget(i).filename == grpc_path:\nself.tabWidget.widget(i).file_changed(mtime)\nbreak\n+ if self._last_search_request is not None:\n+ self.on_load_request(*self._last_search_request)\ndef closeEvent(self, event):\n'''\n",
        "org_msg": "fkie_node_manager: editor: fix goto node after reload on changed file",
        "sim_msg": "Make search work in tree view\nNow it's iterating when activated (enter).",
        "sim_diff": "diff --git a/gaphor/ui/treecomponent.py b/gaphor/ui/treecomponent.py from __future__ import annotations\n-from functools import partial\n-\nfrom gi.repository import Gdk, GLib, GObject, Gtk\nfrom gaphor import UML\n@@ -33,6 +31,7 @@ from gaphor.ui.treemodel import (\ntree_item_sort,\nvisible,\n)\n+from gaphor.ui.treesearch import search\nSTART_EDIT_DELAY = 100 # ms\n@@ -43,6 +42,7 @@ class TreeComponent(UIComponent, ActionProvider):\nself.element_factory = element_factory\nself.modeling_language = modeling_language\nself.model = TreeModel()\n+ self.search = None\ndef open(self):\nself.event_manager.subscribe(self.on_element_created)\n@@ -66,7 +66,19 @@ class TreeComponent(UIComponent, ActionProvider):\nsort_model = Gtk.SortListModel.new(tree_model, tree_sorter)\nself.selection = Gtk.SingleSelection.new(sort_model)\n- self.search_bar = create_search_bar(partial(search_next, self.selection))\n+ def search_next(search_text):\n+ try:\n+ if not self.search:\n+ self.search = search(self.model, search_text)\n+ next_item = next(self.search)\n+ else:\n+ next_item = self.search.send(search_text)\n+ if next_item:\n+ self.select_element(next_item.element)\n+ except StopIteration:\n+ self.search = None\n+\n+ self.search_bar = create_search_bar(search_next)\nfactory = Gtk.SignalListItemFactory.new()\nfactory.connect(\n@@ -258,34 +270,25 @@ def create_search_bar(search_next, text_changed=None):\ndef on_search_changed(entry):\nnonlocal search_text\n+ new_text = entry.get_text()\nfilter_change = (\nGtk.FilterChange.MORE_STRICT\n- if search_text in entry.get_text()\n+ if search_text in new_text\nelse Gtk.FilterChange.LESS_STRICT\n- if entry.get_text() in search_text\n+ if new_text in search_text\nelse Gtk.FilterChange.DIFFERENT\n)\n- search_text = entry.get_text()\n- search_filter.changed(filter_change)\n+ search_text = new_text\n+ if text_changed:\n+ text_changed(search_text, filter_change)\ndef on_stop_search(_entry):\nnonlocal search_text\nsearch_text = \"\"\n- search_filter.changed(Gtk.FilterChange.LESS_STRICT)\n-\n- def on_filter_changed(_filter, change):\n- if text_changed:\n- text_changed(search_text, change)\ndef on_search_next(_entry):\nsearch_next(search_text)\n- def name_filter(item):\n- item = item.get_item()\n- return isinstance(item, TreeItem) and search_text.lower() in item.text.lower()\n-\n- search_filter = Gtk.CustomFilter.new(name_filter)\n- search_filter.connect(\"changed\", on_filter_changed)\nsearch_entry = Gtk.SearchEntry.new()\nsearch_entry.connect(\"search-changed\", on_search_changed)\nsearch_entry.connect(\"stop-search\", on_stop_search)\n@@ -298,10 +301,6 @@ def create_search_bar(search_next, text_changed=None):\nreturn search_bar\n-def search_next(selection, search_text):\n- print(\"search\", search_text)\n-\n-\ndef list_item_factory_setup(_factory, list_item, event_manager, modeling_language):\nbuilder = Gtk.Builder()\nbuilder.set_current_object(list_item)\n",
        "chatgpt_cot": "\"Fix search functionality in Editor class by adding last search request attribute and updating it on various events.\""
    },
    {
        "org_diff": "diff --git a/sc2/bot_ai.py b/sc2/bot_ai.py @@ -94,7 +94,6 @@ class BotAI(DistanceCalculation):\nself.idle_worker_count: int = None\nself.army_count: int = None\nself.warp_gate_count: int = None\n- self.larva_count: int = None\nself.actions: List[UnitCommand] = []\nself.blips: Set[Blip] = set()\nself._units_created: Counter = Counter()\n@@ -158,6 +157,11 @@ class BotAI(DistanceCalculation):\n\"\"\" See client.py \"\"\"\nreturn self._client\n+ @property\n+ def larva_count(self):\n+ \"\"\" Replacement for self.state.common.larva_count https://github.com/Blizzard/s2client-proto/blob/d3d18392f9d7c646067d447df0c936a8ca57d587/s2clientprotocol/sc2api.proto#L614 \"\"\"\n+ return len(self.larva)\n+\ndef alert(self, alert_code: Alert) -> bool:\n\"\"\"\nCheck if alert is triggered in the current step.\n@@ -1346,12 +1350,6 @@ class BotAI(DistanceCalculation):\nif required_supply > 0:\nself.supply_used += required_supply\nself.supply_left -= required_supply\n- if (\n- self.race == Race.Zerg\n- and unit_type in UNIT_TRAINED_FROM\n- and UNIT_TRAINED_FROM[unit_type] == {UnitTypeId.LARVA}\n- ):\n- self.larva_count -= 1\nself.actions.append(action)\nself.unit_tags_received_action.add(action.unit.tag)\nreturn True\n@@ -1555,8 +1553,6 @@ class BotAI(DistanceCalculation):\nself.supply_left: int = self.supply_cap - self.supply_used\nif self.race == Race.Zerg:\n- # Larva count does not seem to be reliable at all\n- self.larva_count: int = state.common.larva_count\n# Workaround Zerg supply rounding bug\nself._correct_zerg_supply()\nelif self.race == Race.Protoss:\n",
        "org_msg": "Replace bot.larva_count with property instead of data from proto",
        "sim_msg": "added time to the saved files",
        "sim_diff": "diff --git a/bot_manager.py b/bot_manager.py @@ -178,7 +178,7 @@ class BotManager:\ncurrent_time = game_tick_packet.gameInfo.TimeSeconds\nif self.save_data and game_tick_packet.gameInfo.bRoundActive and not old_time == current_time and not current_time == -10:\n- np_input = self.input_converter.create_input_array(game_tick_packet)\n+ np_input = self.input_converter.create_input_array(game_tick_packet, passed_time=time.time() - before2)\nnp_output = np.array(controller_input, dtype=np.float32)\nself.input_array = np.append(self.input_array, np_input)\nself.output_array = np.append(self.output_array, np_output)\n",
        "chatgpt_cot": "Remove larva count attribute and add a new method for larva count. Fix Zerg supply rounding bug."
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/settings.py b/node_manager_fkie/src/node_manager_fkie/settings.py @@ -476,7 +476,7 @@ class Settings(object):\nnoclose_str = '-hold'\nif self._terminal_emulator is None:\nself._terminal_emulator = \"\"\n- for t in ['/usr/bin/x-terminal-emulator', '/usr/bin/xterm']:\n+ for t in ['/usr/bin/x-terminal-emulator', '/usr/bin/xterm', '/opt/x11/bin/xterm']:\nif os.path.isfile(t) and os.access(t, os.X_OK):\n# workaround to support the command parameter in different terminal\nif os.path.basename(os.path.realpath(t)) in ['terminator', 'gnome-terminal', 'xfce4-terminal']:\n",
        "org_msg": "added xterm path for macOS",
        "sim_msg": "Changes default theme to Defaultv2 - Newer UI",
        "sim_diff": "diff --git a/classes/settings.py b/classes/settings.py @@ -39,7 +39,7 @@ class settings(db.Model):\nself.showEmptyTables = showEmptyTables\nself.allowComments = allowComments\nself.background = \"Ash\"\n- self.systemTheme = \"Default\"\n+ self.systemTheme = \"Defaultv2\"\nself.version = version\nself.systemLogo = \"/static/img/logo.png\"\n",
        "chatgpt_cot": "\"Add support for new xterm location in terminal emulator settings\""
    },
    {
        "org_diff": "diff --git a/fkie_node_manager/src/fkie_node_manager/logscreen/logger_handler.py b/fkie_node_manager/src/fkie_node_manager/logscreen/logger_handler.py @@ -95,7 +95,6 @@ class LoggerHandler(QObject):\ndef _handle_loggers(self, loggers):\nwhile self.layout.count() > 1:\nitem = self.layout.takeAt(0)\n- print(\"remove\", item.widget())\nitem.widget().setParent(None)\nself._logger_items.clear()\nall_item = LoggerItem(self.nodename, 'all', '')\n",
        "org_msg": "fkie_node_manager: logscreen: removed debug output",
        "sim_msg": "Modify set_global_logger_level use of contextmanager",
        "sim_diff": "diff --git a/qlib/log.py b/qlib/log.py @@ -165,8 +165,16 @@ class LogFilter(logging.Filter):\nreturn allow\n+@contextmanager\ndef set_global_logger_level(level: int):\n+ _handler_level_map = {}\nqlib_logger = logging.root.manager.loggerDict.get(\"qlib\", None)\nif qlib_logger is not None:\nfor _handler in qlib_logger.handlers:\n+ _handler_level_map[_handler] = _handler.level\n_handler.level = level\n+ try:\n+ yield\n+ finally:\n+ for _handler, _level in _handler_level_map.items():\n+ _handler.level = _level\n",
        "chatgpt_cot": "Remove unnecessary print statement in LoggerHandler class. Clean up code by removing debug output for better readability and maintenance."
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/nmd_client.py b/node_manager_fkie/src/node_manager_fkie/nmd_client.py @@ -544,8 +544,13 @@ class NmdClient(QObject):\nuri, _ = nmdurl.split(grpc_path)\nrospy.logdebug(\"get nodes from %s\" % uri)\nlm = self.get_launch_manager(uri)\n+ try:\nlaunch_descriptions = lm.get_nodes(True, masteruri=masteruri)\nreturn launch_descriptions\n+ except grpc.RpcError as gerr:\n+ rospy.logdebug(\"remove connection\", uri)\n+ remote.remove_insecure_channel(uri)\n+ raise gerr\ndef get_nodes_threaded(self, grpc_path='grpc://localhost:12321', masteruri=''):\nself._threads.start_thread(\"gn_%s_%s\" % (grpc_path, masteruri), target=self._get_nodes_threaded, args=(grpc_path, masteruri))\n@@ -561,7 +566,6 @@ class NmdClient(QObject):\nld.path = nmdurl.join(clean_url, ld.path)\nself.launch_nodes.emit(clean_url, launch_descriptions)\nexcept Exception as err:\n- remote.remove_insecure_channel(uri)\nself.error.emit(\"_get_nodes\", grpc_path, masteruri, err)\nif hasattr(self, '_threads'):\nself._threads.finished(\"gn_%s_%s\" % (grpc_path, masteruri))\n@@ -600,7 +604,7 @@ class NmdClient(QObject):\ntry:\nreturn lm.start_node(name, loglevel=loglevel, logformat=logformat, masteruri=masteruri, reload_global_param=reload_global_param)\nexcept grpc.RpcError as gerr:\n- print(\"remove connection\", uri)\n+ rospy.logdebug(\"remove connection\", uri)\nremote.remove_insecure_channel(uri)\nraise gerr\nexcept Exception as err:\n@@ -631,7 +635,8 @@ class NmdClient(QObject):\nstartcfg.respawn_max = 0\nstartcfg.respawn_min_runtime = 0\nreturn lm.start_standalone_node(startcfg)\n- except Exception as err:\n+ except grpc.RpcError as err:\n+ rospy.logdebug(\"remove connection\", uri)\nremote.remove_insecure_channel(uri)\nraise err\n",
        "org_msg": "node_manager_fkie: remove grpc connection on rennection errors",
        "sim_msg": "tests: fix more DisconnectTest raciness.",
        "sim_diff": "diff --git a/tests/parent_test.py b/tests/parent_test.py @@ -31,8 +31,25 @@ def wait_for_child(pid, timeout=1.0):\n@mitogen.core.takes_econtext\n-def call_func_in_sibling(ctx, econtext):\n- ctx.call(time.sleep, 99999)\n+def call_func_in_sibling(ctx, econtext, sync_sender):\n+ recv = ctx.call_async(time.sleep, 99999)\n+ sync_sender.send(None)\n+ recv.get().unpickle()\n+\n+\n+def wait_for_empty_output_queue(sync_recv, context):\n+ # wait for sender to submit their RPC. Since the RPC is sent first, the\n+ # message sent to this sender cannot arrive until we've routed the RPC.\n+ sync_recv.get()\n+\n+ router = context.router\n+ broker = router.broker\n+ while True:\n+ # Now wait for the RPC to exit the output queue.\n+ stream = router.stream_by_id(context.context_id)\n+ if broker.defer_sync(lambda: stream.pending_bytes()) == 0:\n+ return\n+ time.sleep(0.1)\nclass GetDefaultRemoteNameTest(testlib.TestCase):\n@@ -353,12 +370,17 @@ class DisconnectTest(testlib.RouterMixin, testlib.TestCase):\nself.router.stream_by_id(c1.context_id).auth_id = mitogen.context_id\nc1.call(mitogen.parent.upgrade_router)\n- recv = c1.call_async(call_func_in_sibling, c2)\n+ sync_recv = mitogen.core.Receiver(self.router)\n+ recv = c1.call_async(call_func_in_sibling, c2,\n+ sync_sender=sync_recv.to_sender())\n+\n+ wait_for_empty_output_queue(sync_recv, c2)\nc2.shutdown(wait=True)\n+\ne = self.assertRaises(mitogen.core.CallError,\nlambda: recv.get().unpickle())\ns = 'mitogen.core.ChannelError: ' + self.router.respondent_disconnect_msg\n- self.assertTrue(e.args[0].startswith(s))\n+ self.assertTrue(e.args[0].startswith(s), str(e))\ndef test_far_sibling_disconnected(self):\n# God mode: child of child notices child of child of parent has\n@@ -373,8 +395,13 @@ class DisconnectTest(testlib.RouterMixin, testlib.TestCase):\nself.router.stream_by_id(c1.context_id).auth_id = mitogen.context_id\nc11.call(mitogen.parent.upgrade_router)\n- recv = c11.call_async(call_func_in_sibling, c22)\n+ sync_recv = mitogen.core.Receiver(self.router)\n+ recv = c11.call_async(call_func_in_sibling, c22,\n+ sync_sender=sync_recv.to_sender())\n+\n+ wait_for_empty_output_queue(sync_recv, c22)\nc22.shutdown(wait=True)\n+\ne = self.assertRaises(mitogen.core.CallError,\nlambda: recv.get().unpickle())\ns = 'mitogen.core.ChannelError: ' + self.router.respondent_disconnect_msg\n",
        "chatgpt_cot": "Fix compilation issue due to new exception handling in NmdClient for removing insecure channel connections."
    },
    {
        "org_diff": "diff --git a/src/modules/host.py b/src/modules/host.py @@ -231,7 +231,7 @@ class HostHandler(object):\nlogger.warning(\"No host found with id=\" + id)\nreturn {}\n- if h_old.get(\"status\") == \"pending\":\n+ if h_old.status == \"pending\":\nreturn {}\nif \"worker_api\" in d and not d[\"worker_api\"].startswith(\"tcp://\"):\n@@ -246,6 +246,10 @@ class HostHandler(object):\nd[\"log_server\"] = \"udp://\" + d[\"log_server\"]\nif \"log_type\" in d and d[\"log_type\"] == CLUSTER_LOG_TYPES[0]:\nd[\"log_server\"] = \"\"\n+ if \"autofill\" in d:\n+ d[\"autofill\"] = d[\"autofill\"] == \"true\"\n+ if \"schedulable\" in d:\n+ d[\"schedulable\"] = d[\"schedulable\"] == \"true\"\nself.db_set_by_id(id, **d)\nh_new = self.get_by_id(id)\nreturn self._schema(h_new)\n",
        "org_msg": "Fix edit host fail in admin",
        "sim_msg": "results are indexed by ip, setdefault after resolve",
        "sim_diff": "diff --git a/lbry/torrent/tracker.py b/lbry/torrent/tracker.py @@ -197,12 +197,12 @@ class TrackerClient:\nasync def _probe_server(self, info_hash, tracker_host, tracker_port, stopped=False):\nresult = None\n- self.results.setdefault(tracker_host, {})\ntry:\ntracker_host = await resolve_host(tracker_host, tracker_port, 'udp')\nexcept socket.error:\nlog.warning(\"DNS failure while resolving tracker host: %s, skipping.\", tracker_host)\nreturn\n+ self.results.setdefault(tracker_host, {})\nif info_hash in self.results[tracker_host]:\nnext_announcement, result = self.results[tracker_host][info_hash]\nif time.time() < next_announcement:\n",
        "chatgpt_cot": "Refactor HostHandler in host.py to handle boolean values for \"autofill\" and \"schedulable\" fields, improving data processing and schema consistency."
    },
    {
        "org_diff": "diff --git a/sc2/unit.py b/sc2/unit.py @@ -53,6 +53,12 @@ class Unit(object):\n@property\ndef position(self):\n+ \"\"\"2d position of the unit.\"\"\"\n+ return self.position3d.to2\n+\n+ @property\n+ def position3d(self):\n+ \"\"\"3d position of the unit.\"\"\"\nreturn Point3.from_proto(self._proto.pos)\ndef distance_to(self, p):\n",
        "org_msg": "Use 2d positions by default",
        "sim_msg": "fix for value_and_unit",
        "sim_diff": "diff --git a/apps/projects/models.py b/apps/projects/models.py @@ -261,6 +261,6 @@ class Value(Model):\nvalue = self.value\nif self.attribute.unit:\n- return str(value) + ' ' + self.attribute.unit\n+ return '%s %s' % (value, self.attribute.unit)\nelse:\nreturn value\n",
        "chatgpt_cot": "Add properties for 2D and 3D positions in Unit class."
    },
    {
        "org_diff": "diff --git a/fkie_node_manager/src/fkie_node_manager/master_view_proxy.py b/fkie_node_manager/src/fkie_node_manager/master_view_proxy.py @@ -175,6 +175,7 @@ class MasterViewProxy(QWidget):\nself.__current_parameter_robot_icon = ''\nself.__republish_params = {} # { topic : params, created by dialog}\nself.__last_selection = 0\n+ self.__last_node_activation = 0\nself.__last_question_start_nmd = 0\nself._on_stop_kill_roscore = False\nself._on_stop_poweroff = False\n@@ -1286,6 +1287,7 @@ class MasterViewProxy(QWidget):\n:param index: The index of the activated node\n:type index: :class:`QtCore.QModelIndex` <https://srinikom.github.io/pyside-docs/PySide/QtCore/QModelIndex.html>\n'''\n+ self.__last_node_activation = time.time()\nselectedNodes = []\nif index.column() == 0:\nselectedNodes = self.nodesFromIndexes(self.ui.nodeTreeView.selectionModel().selectedIndexes(), False)\n@@ -1309,6 +1311,7 @@ class MasterViewProxy(QWidget):\nself.on_log_clicked()\ndef on_node_clicked(self, index):\n+ if time.time() - self.__last_node_activation > 1.:\nself.message_frame.hide_question([MessageFrame.TYPE_NODELET])\nself.info_frame.hide_question([MessageFrame.TYPE_NOSCREEN])\nif time.time() - self.__last_selection > 1.:\n",
        "org_msg": "fkie_node_manager: fixed fast hide of screen info",
        "sim_msg": "improve tree behaviour",
        "sim_diff": "diff --git a/tree.py b/tree.py @@ -755,11 +755,15 @@ class WidgetTree(wx.TreeCtrl, Tree):\nself.SetItemTextColour(item, wx.NullColour)\nself.SetItemBold( item, False )\nself.cur_widget = widget\n- if wx.Platform == \"__WXMSW__\":\nitem = widget.node.item\n+ self.EnsureVisible(item)\n+ # ensure that the icon is visible\n+ text_rect = self.GetBoundingRect(item, True)\n+ if text_rect.x<22:\n+ self.SetScrollPos(wx.HORIZONTAL, self.GetScrollPos(wx.HORIZONTAL) - 22 + text_rect.x)\n+ if wx.Platform == \"__WXMSW__\":\nself.SetItemBold(item, True)\nself.SetItemTextColour(item, wx.BLUE)\n-\ndef set_current_widget(self, widget):\n# interface from common.set_focused_widget\nif widget is None or widget is self.cur_widget: return\n@@ -904,8 +908,7 @@ class WidgetTree(wx.TreeCtrl, Tree):\nelse:\nnode.widget.widget.GetParent().Show()\n- misc.set_focused_widget(node.widget)\n-\n+ #misc.set_focused_widget(node.widget)\nnode.widget.widget.Raise()\n# set the best size for the widget (if no one is given)\nprops = node.widget.properties\n@@ -957,8 +960,8 @@ class WidgetTree(wx.TreeCtrl, Tree):\ntoplevel_widget.GetTopLevelParent().Hide()\n# added by rlawson to collapse only the toplevel node, not collapse back to root node\n- self.select_item(node)\n- misc.set_focused_widget(node.widget)\n+ #self.select_item(node)\n+ #misc.set_focused_widget(node.widget)\nif event: event.Skip()\nif \"design\" in node.widget.properties: node.widget.design.update_label()\n@@ -1096,6 +1099,7 @@ class WidgetTree(wx.TreeCtrl, Tree):\nnode = self._GetItemData(itemok)\nif parent is not None:\nself._show_widget_toplevel(parent)\n+ common.app_tree.expand(parent)\nif pos is not None:\nmisc.get_toplevel_parent(parent.widget).SetPosition(pos)\nself.select_item(node)\n",
        "chatgpt_cot": "Add a method to handle node activation time. The modification helps to manage the time of node activation in the MasterViewProxy file."
    },
    {
        "org_diff": "diff --git a/src/modules/host.py b/src/modules/host.py @@ -291,7 +291,7 @@ class HostHandler(object):\nlogger.warning(\"Cannot delete non-existed host\")\nreturn False\n- host_type = h.host.type\n+ host_type = h.type\nif ClusterModel.objects(host=h).count():\nlogger.warning(\"Host type not found.\")\n",
        "org_msg": "Fix host can not delete in admin dashboard\nDirectly get host type through host model object",
        "sim_msg": "Decr log level.",
        "sim_diff": "diff --git a/dpark/hostatus.py b/dpark/hostatus.py @@ -132,7 +132,7 @@ class TaskHostManager:\nif task_id in self.task_host_failed_dict:\nfor host in self.task_host_failed_dict[task_id]:\nself.host_dict[host].erase_failed_task(task_id)\n- logger.info('the failed hosts %s for task %s',\n+ logger.debug('the failed hosts %s for task %s',\nstr(self.task_host_failed_dict[task_id]), task_id)\ndel self.task_host_failed_dict[task_id]\n",
        "chatgpt_cot": "\"Fix issue with host type assignment in HostHandler class\""
    },
    {
        "org_diff": "diff --git a/README.md b/README.md @@ -87,6 +87,12 @@ SC2CLIENTHOST=<your windows IP>\nSC2SERVERHOST=0.0.0.0\n```\n+If you are adding these to your .bashrc, you may need to export your environment variables by adding:\n+```sh\n+export SC2CLIENTHOST\n+export SC2SERVERHOST\n+```\n+\nYou can find your Windows IP using `ipconfig /all` from `PowerShell.exe` or `CMD.exe`.\n## Example\n",
        "org_msg": "Update README to recommend exporting environment variables",
        "sim_msg": "check if IPs are valid",
        "sim_diff": "diff --git a/home.admin/config.scripts/internet.sh b/home.admin/config.scripts/internet.sh @@ -7,18 +7,45 @@ if [ $# -eq 0 ] || [ \"$1\" = \"-h\" ] || [ \"$1\" = \"-help\" ]; then\nexit 1\nfi\n-# load local config\n-source /mnt/hdd/raspiblitz.conf\n+# FUNCTIONS\n-# get local IP\n+isValidIP() {\n+ if [ \"$1\" != \"${1#*[0-9].[0-9]}\" ]; then\n+ # IPv4\n+ echo 1\n+ elif [ \"$1\" != \"${1#*:[0-9a-fA-F]}\" ]; then\n+ # IPv6\n+ echo 1\n+ else\n+ # unkown\n+ echo 0\n+ fi\n+}\n+\n+# load local config (but should also work if not available)\n+source /mnt/hdd/raspiblitz.conf 2>/dev/null\n+\n+# get local IP (from different sources)\nlocalip_ALL=$(ip addr | grep 'state UP' -A2 | egrep -v 'docker0' | egrep -i '(*[eth|ens|enp|eno|wlan|wlp][0-9]$)' | tail -n1 | awk '{print $2}' | cut -f1 -d'/')\n+if [ $(isValidIP ${localip_ALL}) -eq 0 ] then\n+ localip_ALL=\"\"\n+fi\nlocalip_LAN=$(ip addr | grep 'state UP' -A2 | egrep -v 'docker0' | egrep -i '(*[eth][0-9]$)' | tail -n1 | awk '{print $2}' | cut -f1 -d'/')\n+if [ $(isValidIP ${localip_LAN}) -eq 0 ] then\n+ localip_LAN=\"\"\n+fi\nlocalip=\"${localip_ALL}\"\nif [ ${#localip_LAN} -gt 0 ]; then\n# prefer local IP over LAN over all other if available\nlocalip=\"${localip_LAN}\"\nfi\n+# check DHCP\n+dhcp=1\n+if [ \"${localip:0:4}\" = \"169.\" ]; then\n+ dhcp=0\n+fi\n+\n# check for internet connection\nonline=0\nif [ ${#dnsServer} -gt 0 ]; then\n@@ -45,6 +72,7 @@ fi\nif [ \"$1\" == \"status\" ]; then\necho \"localip=${localip}\"\n+ echo \"dhcp=${dhcp}\"\necho \"online=${online}\"\nexit 0\n",
        "chatgpt_cot": "Add instructions for exporting environment variables in .bashrc to README.md."
    },
    {
        "org_diff": "diff --git a/.github/workflows/docker-ci.yml b/.github/workflows/docker-ci.yml @@ -46,15 +46,15 @@ jobs:\nname: Build docker image\nruns-on: ${{ matrix.os }}\ntimeout-minutes: 30\n+ env:\n+ IMAGE_NAME: burnysc2/python-sc2-docker:py_${{ matrix.python-version }}-sc2_${{ matrix.sc2-version }}-v${{ env.VERSION_NUMBER }}\n+ BUILD_ARGS: --build-arg PYTHON_VERSION=${{ matrix.python-version }} --build-arg SC2_VERSION=${{ matrix.sc2-version }}\nstrategy:\nfail-fast: false\nmatrix:\nos: [ubuntu-latest]\npython-version: ['3.7', '3.8', '3.9', '3.10']\nsc2-version: ['4.10']\n- env:\n- IMAGE_NAME: burnysc2/python-sc2-docker:py_${{ matrix.python-version }}-sc2_${{ matrix.sc2-version }}-v${{ env.VERSION_NUMBER }}\n- BUILD_ARGS: --build-arg PYTHON_VERSION=${{ matrix.python-version }} --build-arg SC2_VERSION=${{ matrix.sc2-version }}\nsteps:\n- uses: actions/checkout@v1\n",
        "org_msg": "Move env argument",
        "sim_msg": "Test with slim images",
        "sim_diff": "diff --git a/.circleci/config.yml b/.circleci/config.yml @@ -246,7 +246,7 @@ jobs:\ntype: string\ndocker:\n- - image: python:<< parameters.python-version >>\n+ - image: python:<< parameters.python-version >>-slim\nsteps:\n- checkout\n@@ -308,7 +308,7 @@ workflows:\n- build-linux: &build\nmatrix:\nparameters:\n- python-version: [3.7.9, 3.8.9, 3.9.4, 3.10.0, 3.11.0]\n+ python-version: &python-versions [3.7.9, 3.8.9, 3.9.4, 3.10.0, 3.11.0]\n- build-linux-aarch64: *build\n- build-sdist\n- build-osx: *build\n@@ -324,7 +324,7 @@ workflows:\nparameters:\n# test the lowest supported numpy and the latest\ndependencies: [oldest-supported-numpy, numpy]\n- python-version: [3.7.9, 3.8.9, 3.9.4, 3.10.0, 3.11.0rc1]\n+ python-version: *python-versions\nexclude:\n# we don't support 1.14.5, the oldest version for Python 3.7.9\n- python-version: 3.7.9\n",
        "chatgpt_cot": "Update docker-ci.yml to include environment variables for image name and build arguments based on python and sc2 versions in the matrix."
    },
    {
        "org_diff": "diff --git a/node_manager_daemon_fkie/src/node_manager_daemon_fkie/monitor/cpu_load.py b/node_manager_daemon_fkie/src/node_manager_daemon_fkie/monitor/cpu_load.py @@ -69,7 +69,19 @@ class CpuLoad(SensorInterface):\nif count_warn_cpu > 1:\ndiag_level = DiagnosticStatus.WARN\ndiag_msg = 'CPU load of %d cores is >%.0f%%)' % (count_warn_cpu, self._cpu_load_warn * 100)\n-\n+ try:\n+ # determine processes with high load\n+ processes = {}\n+ for pi in sorted(psutil.process_iter(attrs=['name', 'cpu_percent']), key=lambda pi: pi.info['cpu_percent'], reverse=True):\n+ if pi.info['cpu_percent'] / 100.0 >= warn_level:\n+ phlmsg = '%.2f%% %s[%d] %s' % (pi.info['cpu_percent'], pi.info['name'], pi.pid, ' '.join(pi.cmdline()[:1]))\n+ processes[pi.info['cpu_percent']] = phlmsg\n+ else:\n+ break\n+ for _pp, msg in processes.items():\n+ diag_vals.append(KeyValue(key='Process high load', value=msg))\n+ except Exception:\n+ pass\n# Update status\nwith self.mutex:\nself._ts_last = time.time()\n",
        "org_msg": "node_manager_fkie: determine processes with high load",
        "sim_msg": "updating `augur util kill` cli_kill_processes and kill_processes to send SIGKILL after waiting 15 seconds and checking what is still running again.",
        "sim_diff": "diff --git a/augur/cli/util.py b/augur/cli/util.py @@ -7,6 +7,7 @@ import os\nimport signal\nimport logging\nfrom subprocess import call, run\n+import time\nimport psutil\nimport click\n@@ -52,9 +53,28 @@ def cli_kill_processes():\nif processes != []:\nfor process in processes:\nif process.pid != os.getpid():\n- logger.info(f\"Killing process {process.pid}\")\n+ logger.info(f\"Terminating process {process.pid}\")\ntry:\nprocess.send_signal(signal.SIGTERM)\n+ logger.info(f\"sending SIGTERM Signal to {process.pid}\")\n+ except psutil.NoSuchProcess as e:\n+ pass\n+\n+ logger.info(f\"Waiting to check if processes terminated.\")\n+\n+ time.sleep(15)\n+ logger.info(f\"Checking on process termination.\")\n+\n+ processes = get_augur_processes()\n+\n+ if processes != []:\n+ for process in processes:\n+\n+ if process.pid != os.getpid():\n+ logger.info(f\"Killing process {process.pid}\")\n+ try:\n+ process.send_signal(signal.SIGKILL)\n+ logger.info(f\"sending SIGKILL Signal to {process.pid}\")\nexcept psutil.NoSuchProcess as e:\npass\n@@ -64,11 +84,29 @@ def kill_processes():\nif processes != []:\nfor process in processes:\nif process.pid != os.getpid():\n- logger.info(f\"Killing process {process.pid}\")\n+ logger.info(f\"Terminating process {process.pid}\")\ntry:\nprocess.send_signal(signal.SIGTERM)\n+ logger.info(f\"sending SIGTERM Signal to {process.pid}\")\nexcept psutil.NoSuchProcess as e:\nlogger.warning(e)\n+ logger.info(f\"Waiting to check if processes terminated.\")\n+\n+ time.sleep(15)\n+ logger.info(f\"Checking on process termination.\")\n+\n+ processes = get_augur_processes()\n+\n+ if processes != []:\n+ for process in processes:\n+ if process.pid != os.getpid():\n+ logger.info(f\"Killing process {process.pid}\")\n+ logger.info(f\"Killing process {process.pid}\")\n+ try:\n+ process.send_signal(signal.SIGKILL)\n+ logger.info(f\"sending SIGKILL Signal to {process.pid}\")\n+ except psutil.NoSuchProcess as e:\n+ pass\n@cli.command('list',)\n@initialize_logging\n",
        "chatgpt_cot": "Add process monitoring to CPU load monitor in node manager daemon, to track processes with high load and update status accordingly."
    },
    {
        "org_diff": "diff --git a/sc2/score.py b/sc2/score.py @@ -2,6 +2,7 @@ class ScoreDetails:\n\"\"\" Accessable in self.state.score during step function\nFor more information, see https://github.com/Blizzard/s2client-proto/blob/master/s2clientprotocol/score.proto\n\"\"\"\n+\ndef __init__(self, proto):\nself._data = proto\nself._proto = proto.score_details\n@@ -17,7 +18,8 @@ class ScoreDetails:\nfor stat in self.state.score.summary:\nfile.write(f\"{stat[0]:<35} {float(stat[1]):>35.3f}\\n\")\n\"\"\"\n- values = [\"score_type\",\n+ values = [\n+ \"score_type\",\n\"score\",\n\"idle_production_time\",\n\"idle_worker_time\",\n@@ -95,6 +97,8 @@ class ScoreDetails:\n\"total_healed_life\",\n\"total_healed_shields\",\n\"total_healed_energy\",\n+ \"current_apm\",\n+ \"current_effective_apm\",\n]\nreturn [[value, getattr(self, value)] for value in values]\n@@ -409,3 +413,11 @@ class ScoreDetails:\n@property\ndef total_healed_energy(self):\nreturn self._proto.total_healed.energy\n+\n+ @property\n+ def current_apm(self):\n+ return self._proto.current_apm\n+\n+ @property\n+ def current_effective_apm(self):\n+ return self._proto.current_effective_apm\n",
        "org_msg": "Add apm to score.py",
        "sim_msg": "fix gamemode in Score.from_sql",
        "sim_diff": "diff --git a/app/objects/score.py b/app/objects/score.py @@ -230,7 +230,7 @@ class Score:\ns.grade,\ns.perfect,\ns.status,\n- mode_vn,\n+ mode,\ns.play_time,\ns.time_elapsed,\ns.client_flags,\n@@ -242,7 +242,7 @@ class Score:\ns.status = SubmissionStatus(s.status)\ns.grade = Grade.from_str(s.grade)\ns.mods = Mods(s.mods)\n- s.mode = GameMode.from_params(mode_vn, s.mods)\n+ s.mode = GameMode(mode)\ns.client_flags = ClientFlags(s.client_flags)\nif s.bmap:\n",
        "chatgpt_cot": "Add new properties to ScoreDetails class for total healed energy, current APM, and current effective APM."
    },
    {
        "org_diff": "diff --git a/src/agent/fabric-operator/deploy/crds/fabric_v1alpha1_ca_cr.yaml b/src/agent/fabric-operator/deploy/crds/fabric_v1alpha1_ca_cr.yaml @@ -35,14 +35,16 @@ spec:\n# memory: \"1024mi\"\n# cpu: \"250\"\n- # To specify more environment variables for Fabric CA, use the\n+ # To specify more environment variables for Fabric CA.\n# following parameters:\n- # configParams:\n- # FABRIC_CA_SERVER_PORT: 7054\n- # FABRIC_CA_SERVER_DEBUG: false\n- # FABRIC_CA_SERVER_CSR_HOSTS: []\n+ # FABRIC_CA_SERVER_CSR_HOSTS: \"[]\"\n# FABRIC_CA_SERVER_CSR_NAMES_0_C: US\n# FABRIC_CA_SERVER_CSR_NAMES_0_ST: \"North Carolina\"\n# FABRIC_CA_SERVER_CSR_NAMES_0_L: \"Cary\"\n# FABRIC_CA_SERVER_CSR_NAMES_0_O: \"Sample Org\"\n# FABRIC_CA_SERVER_CSR_NAMES_0_OU: \"Sample Org Unit\"\n+ configParams:\n+ - name: FABRIC_CA_SERVER_PORT\n+ value: \"7054\"\n+ - name: FABRIC_CA_SERVER_DEBUG\n+ value: false\n",
        "org_msg": "[#61]Fixed operation CA example cr yaml file",
        "sim_msg": "update ci deployment",
        "sim_diff": "diff --git a/ci/deployment.yaml b/ci/deployment.yaml @@ -14,7 +14,7 @@ spec:\nspec:\ncontainers:\n- name: hail-ci\n- image: gcr.io/broad-ctsa/hail-ci:0d5db5aa44cb934a08ce06c789cf389bd10d5d6b57a7239d60606e95b7fbb71b\n+ image: gcr.io/broad-ctsa/hail-ci:102b3c13a57d1eefd5f91558b72b8cabc9d01cef89aa6f38a5bcd7fba834672c\nenv:\n- name: SELF_HOSTNAME\nvalue: http://hail-ci\n",
        "chatgpt_cot": "\"Add environment variables for Fabric CA server and update configParams for Fabric CA in fabric_v1alpha1_ca_cr.yaml file.\""
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/settings.py b/node_manager_fkie/src/node_manager_fkie/settings.py # ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE\n# POSSIBILITY OF SUCH DAMAGE.\n+from __future__ import division, absolute_import, print_function, unicode_literals\n+\nfrom python_qt_binding.QtGui import QColor\nimport os\nimport roslib\n@@ -112,8 +114,8 @@ class Settings(object):\nPACKAGE_DIR = \"%s/../../share/node_manager_fkie\" % PACKAGE_DIR\nprint(\"PACKAGE_DIR: %s\" % PACKAGE_DIR)\nROBOTS_DIR = os.path.join(PACKAGE_DIR, 'images')\n- CFG_PATH = os.path.join('.node_manager', os.sep)\n- ''':ivar CFG_PATH: configuration path to store the history.'''\n+ CFG_PATH = os.path.expanduser('~/.config/ros.fkie/node_manager/')\n+ ''':ivar CFG_PATH: configuration path to store the settings and history'''\nHELP_FILE = os.path.join(PACKAGE_DIR, 'README.rst')\nCURRENT_DIALOG_PATH = os.path.expanduser('~')\nLOG_PATH = screen.LOG_PATH\n@@ -172,7 +174,8 @@ class Settings(object):\nself._noclose_str = '-hold'\nself._terminal_title = '--title'\nself._masteruri = masteruri_from_ros()\n- self.CFG_PATH = os.path.join(get_ros_home(), 'node_manager')\n+ # self.CFG_PATH = os.path.join(get_ros_home(), 'node_manager')\n+ self.CFG_PATH = os.path.expanduser('~/.config/ros.fkie/node_manager/')\n# loads the current configuration path. If the path was changed, a redirection\n# file exists with new configuration folder\nif not os.path.isdir(self.CFG_PATH):\n@@ -181,6 +184,18 @@ class Settings(object):\nelse:\nsettings = self.qsettings(os.path.join(self.CFG_PATH, self.CFG_REDIRECT_FILE))\nself._cfg_path = settings.value('cfg_path', self.CFG_PATH)\n+ # move all stuff from old location to new\n+ try:\n+ import shutil\n+ old_cfg_path = os.path.join(get_ros_home(), 'node_manager')\n+ if os.path.exists(old_cfg_path):\n+ print(\"move configuration to new destination: %s\" % self.CFG_PATH)\n+ for filename in os.listdir(old_cfg_path):\n+ shutil.move(os.path.join(old_cfg_path, filename), os.path.join(self.CFG_PATH, filename))\n+ shutil.rmtree(old_cfg_path)\n+ except Exception:\n+ pass\n+ print(\"Configuration path: %s\" % self.CFG_PATH)\n# after the settings path was loaded, load other settings\nself._robots_path = self.ROBOTS_DIR\nsettings = self.qsettings(self.CFG_FILE)\n",
        "org_msg": "node_manager_fkie: moved settings destination to .config/ros.fkie/",
        "sim_msg": "Print warnings to stderr not stdout",
        "sim_diff": "diff --git a/InvenTree/InvenTree/settings.py b/InvenTree/InvenTree/settings.py @@ -11,11 +11,16 @@ database setup in this file.\n\"\"\"\n+import sys\nimport os\nimport logging\nimport tempfile\nimport yaml\n+def eprint(*args, **kwargs):\n+ \"\"\" Print a warning message to stderr \"\"\"\n+ print(*args, file=sys.stderr, **kwargs)\n+\n# Build paths inside the project like this: os.path.join(BASE_DIR, ...)\nBASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))\n@@ -23,7 +28,7 @@ cfg_filename = os.path.join(BASE_DIR, 'config.yaml')\nif not os.path.exists(cfg_filename):\nCONFIG = {}\n- print(\"Warning: config.yaml not found - using default settings\")\n+ eprint(\"Warning: config.yaml not found - using default settings\")\nelse:\nwith open(cfg_filename, 'r') as cfg:\nCONFIG = yaml.safe_load(cfg)\n@@ -52,7 +57,7 @@ if cors_opt:\nCORS_ORIGIN_ALLOW_ALL = cors_opt.get('allow_all', False)\nif CORS_ORIGIN_ALLOW_ALL:\n- print(\"Warning: CORS requests are allowed for any domain!\")\n+ eprint(\"Warning: CORS requests are allowed for any domain!\")\nelse:\nCORS_ORIGIN_WHITELIST = cors_opt.get('whitelist', [])\n@@ -156,7 +161,7 @@ DATABASES = {}\nif 'database' in CONFIG:\nDATABASES['default'] = CONFIG['database']\nelse:\n- print(\"Warning: Database backend not specified - using default (sqlite)\")\n+ eprint(\"Warning: Database backend not specified - using default (sqlite)\")\nDATABASES['default'] = {\n'ENGINE': 'django.db.backends.sqlite3',\n'NAME': os.path.join(BASE_DIR, 'inventree_db.sqlite3'),\n",
        "chatgpt_cot": "\"Update CFG_PATH to store settings and history, move configuration to new destination, and load other settings after the settings path was loaded.\""
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/settings.py b/node_manager_fkie/src/node_manager_fkie/settings.py @@ -156,7 +156,7 @@ class Settings(object):\nSHOW_DOMAIN_SUFFIX = False\nTRANSPOSE_PUB_SUB_DESCR = True\n- TIMEOUT_CLOSE_DIALOG = 5.0\n+ TIMEOUT_CLOSE_DIALOG = 30.0\nGROUP_BY_NAMESPACE = True\nTIMEOUT_GRPC = nmd_settings.GRPC_TIMEOUT\nSYSMON_DEFAULT_INTERVAL = 10\n",
        "org_msg": "node_manager_fkie: changed timeout for close dialog to 30 sec",
        "sim_msg": "Add missing entry in DB Class",
        "sim_diff": "diff --git a/classes/settings.py b/classes/settings.py @@ -28,6 +28,7 @@ class settings(db.Model):\nserverMessageTitle = db.Column(db.String(256))\nserverMessage = db.Column(db.String(8192))\nmaxClipLength = db.Column(db.Integer)\n+ limitMaxChannels = db.Column(db.Integer)\nproxyFQDN = db.Column(db.String(2048))\nmaintenanceMode = db.Column(db.Boolean)\nbuildEdgeOnRestart = db.Column(db.Boolean)\n",
        "chatgpt_cot": "Increase timeout for close dialog in settings to 30.0 seconds to improve user experience and prevent premature closing of dialogs."
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/master_view_proxy.py b/node_manager_fkie/src/node_manager_fkie/master_view_proxy.py @@ -165,6 +165,7 @@ class MasterViewProxy(QWidget):\nself._on_stop_kill_roscore = False\nself._on_stop_poweroff = False\nself._start_nodes_after_load_cfg = dict()\n+ self._cfg_changed_nodes = dict()\n# store the running_nodes to update to duplicates after load a launch file\nself.__running_nodes = dict() # dict (node name : masteruri)\nself._nodelets = dict() # dict(launchfile: dict(nodelet manager: list(nodes))\n@@ -675,13 +676,9 @@ class MasterViewProxy(QWidget):\ndef _apply_launch_config(self, launchcfg, changed_nodes):\nfilename = launchcfg.launchfile\n- # restart nodes\n+ # store changed nodes for restart\nif changed_nodes:\n- restart, ok = SelectDialog.getValue('Restart nodes?', \"Select nodes to restart <b>@%s</b>:\" % self.mastername, changed_nodes, False, True, '', self)\n- if ok:\n- self.stop_nodes_by_name(restart)\n- self.start_nodes_after_load_cfg(filename, restart, force=True)\n- # self.start_nodes_by_name(restart, filename, force=True)\n+ self._cfg_changed_nodes[filename] = changed_nodes\nif filename in self.__configs:\n# store expanded items\nself.__expanded_items[filename] = self._get_expanded_groups()\n@@ -987,6 +984,14 @@ class MasterViewProxy(QWidget):\nprint (\"skip remove config\", url, cfg)\npass\nself.updateButtons()\n+ for cfg in new_configs:\n+ if cfg in self._cfg_changed_nodes:\n+ changed_nodes = self._cfg_changed_nodes[cfg]\n+ del self._cfg_changed_nodes[cfg]\n+ restart, ok = SelectDialog.getValue('Restart nodes?', \"Select nodes to restart <b>@%s</b>:\" % self.mastername, changed_nodes, False, True, '', self)\n+ if ok:\n+ self.stop_nodes_by_name(restart)\n+ self.start_nodes_by_name(restart, cfg, force=True)\ndef on_launch_description_err(self, url, error):\n'''\n",
        "org_msg": "node_manager_fkie: fixed delayed restart nodes after reload config",
        "sim_msg": "Simplified grammar",
        "sim_diff": "diff --git a/packages/hagrid/hagrid/cli.py b/packages/hagrid/hagrid/cli.py @@ -21,13 +21,13 @@ def cli():\n@click.command(help=\"Start a new PyGrid domain/network node!\")\n-@click.argument(\"type\", type=click.Choice([\"domain\", \"network\"]))\n+@click.argument(\"name\", type=str)\n@click.option(\n- \"--name\",\n- default=\"\",\n+ \"--type\",\n+ default=\"domain\",\nrequired=False,\n- type=str,\n- help=\"The name of your new domain/network node. (Default: <randomly generated>)\",\n+ type=click.Choice([\"domain\", \"network\"]),\n+ help=\"The type of node you would like to deploy.\",\n)\n@click.option(\n\"--port\",\n@@ -50,7 +50,7 @@ def cli():\ntype=bool,\nhelp=\"\"\"If restarting a node that already existed, don't/do reset the database (Default: deletes the db)\"\"\",\n)\n-def launch(type, name, port, tag, keep_db, host=\"localhost\"):\n+def launch(name, type, port, tag, keep_db, host=\"localhost\"):\nif name == \"\":\nname = names.get_full_name() + \"'s \" + type.capitalize()\n@@ -110,13 +110,13 @@ def launch(type, name, port, tag, keep_db, host=\"localhost\"):\n@click.command(help=\"Stop a running PyGrid domain/network node.\")\n-@click.argument(\"type\", type=click.Choice([\"domain\", \"network\"]))\n+@click.argument(\"name\", type=str)\n@click.option(\n- \"--name\",\n- default=\"\",\n+ \"--type\",\n+ default=\"domain\",\nrequired=False,\n- type=str,\n- help=\"The name of your new domain/network node. (Default: <randomly generated>)\",\n+ type=click.Choice([\"domain\", \"network\"]),\n+ help=\"The type of node you would like to terminate.\",\n)\n@click.option(\n\"--port\",\n@@ -153,7 +153,7 @@ def land(type, name, port, tag):\nversion = check_docker()\n- motorcycle()\n+ # motorcycle()\nprint(\"Launching a \" + str(type) + \" PyGrid node on port \" + str(port) + \"!\\n\")\nprint(\" - TYPE: \" + str(type))\n",
        "chatgpt_cot": "\"Add functionality to store changed nodes for restart, and implement restart nodes based on changed nodes in the Master View Proxy file.\""
    },
    {
        "org_diff": "diff --git a/sc2/unit.py b/sc2/unit.py @@ -138,6 +138,10 @@ class Unit(object):\ndef is_massive(self) -> bool:\nreturn Attribute.Massive.value in self._type_data.attributes\n+ @property\n+ def is_psionic(self) -> bool:\n+ return Attribute.Psionic.value in self._type_data.attributes\n+\n@property\ndef is_mineral_field(self) -> bool:\nreturn self._type_data.has_minerals\n",
        "org_msg": "Add \"is_psionic\" property\nUpdate unit.py",
        "sim_msg": "fix for value_and_unit",
        "sim_diff": "diff --git a/apps/projects/models.py b/apps/projects/models.py @@ -261,6 +261,6 @@ class Value(Model):\nvalue = self.value\nif self.attribute.unit:\n- return str(value) + ' ' + self.attribute.unit\n+ return '%s %s' % (value, self.attribute.unit)\nelse:\nreturn value\n",
        "chatgpt_cot": "Add new property \"is_psionic\" to Unit class to check if unit is psionic."
    },
    {
        "org_diff": "diff --git a/sc2/unit.py b/sc2/unit.py @@ -1110,14 +1110,26 @@ class Unit:\n@property_immutable_cache\ndef add_on_land_position(self) -> Point2:\n- \"\"\" If this unit is an addon (techlab, reactor), returns the position\n- where a terran building (BARRACKS, FACTORY, STARPORT) has to land to connect to this addon. \"\"\"\n+ \"\"\"\n+ If this unit is an addon (techlab, reactor), returns the position\n+ where a terran building (BARRACKS, FACTORY, STARPORT) has to land to connect to this addon.\n+\n+ Why offset (-2.5, 0.5)? See description in 'add_on_position'\n+ \"\"\"\nreturn self.position.offset(Point2((-2.5, 0.5)))\n@property_immutable_cache\ndef add_on_position(self) -> Point2:\n- \"\"\" If this unit is a terran production building (BARRACKS, FACTORY, STARPORT),\n- this property returns the position of where the addon should be, if it should build one or has one attached. \"\"\"\n+ \"\"\"\n+ If this unit is a terran production building (BARRACKS, FACTORY, STARPORT),\n+ this property returns the position of where the addon should be, if it should build one or has one attached.\n+\n+ Why offset (2.5, -0.5)?\n+ A barracks is of size 3x3. The distance from the center to the edge is 1.5.\n+ An addon is 2x2 and the distance from the edge to center is 1.\n+ The total distance from center to center on the x-axis is 2.5.\n+ The distance from center to center on the y-axis is -0.5.\n+ \"\"\"\nreturn self.position.offset(Point2((2.5, -0.5)))\n@property_mutable_cache\n",
        "org_msg": "Improve description on 'add_on_position'",
        "sim_msg": "Fix regression in simulator function.",
        "sim_diff": "diff --git a/gibson2/simulator.py b/gibson2/simulator.py @@ -1397,7 +1397,10 @@ class Simulator:\n\"\"\"\nif not hasattr(self.scene, 'objects_by_id'):\nreturn []\n- return [body_id for body_id in self.objects if body_id in self.scene.objects_by_id.keys() and self.scene.objects_by_id[body_id].category == category_name]\n+ return [body_id for body_id in self.objects\n+ if (body_id in self.scene.objects_by_id.keys() and\n+ hasattr(self.scene.objects_by_id[body_id], \"category\") and\n+ self.scene.objects_by_id[body_id].category == category_name)]\ndef update_position(self, instance):\n\"\"\"\n",
        "chatgpt_cot": "\"Add detailed comments for add_on_land_position and add_on_position methods to explain the offset calculation for terran building connection and addon positioning.\""
    },
    {
        "org_diff": "diff --git a/fkie_node_manager/src/fkie_node_manager/ssh_handler.py b/fkie_node_manager/src/fkie_node_manager/ssh_handler.py @@ -96,7 +96,8 @@ class SSHhandler(object):\nCloses all open SSH sessions. Used on the closing the node manager.\n'''\n# close all ssh sessions\n- for ssh in SSHhandler.SSH_SESSIONS.keys():\n+ keys = list(SSHhandler.SSH_SESSIONS.keys())\n+ for ssh in keys:\ns = SSHhandler.SSH_SESSIONS.pop(ssh)\nif s._transport is not None:\ns.close()\n",
        "org_msg": "fixed close ssh sessions",
        "sim_msg": "Fixing F5 TMSH disconnect process",
        "sim_diff": "diff --git a/netmiko/f5/f5_tmsh_ssh.py b/netmiko/f5/f5_tmsh_ssh.py @@ -27,6 +27,22 @@ class F5TmshSSH(BaseConnection):\nself.clear_buffer()\nreturn None\n+ def exit_tmsh(self):\n+ output = self.send_command(\"quit\", expect_string=r\"#\")\n+ self.set_base_prompt()\n+ return output\n+\n+ def cleanup(self, command=\"exit\"):\n+ \"\"\"Gracefully exit the SSH session.\"\"\"\n+ try:\n+ self.exit_tmsh()\n+ except Exception:\n+ pass\n+\n+ # Always try to send final 'exit' (command)\n+ self._session_log_fin = True\n+ self.write_channel(command + self.RETURN)\n+\ndef check_config_mode(self, check_string=\"\", pattern=\"\"):\n\"\"\"Checks if the device is in configuration mode or not.\"\"\"\nreturn True\n",
        "chatgpt_cot": "Fix SSH session closure in SSHhandler to prevent dictionary size change during iteration."
    },
    {
        "org_diff": "diff --git a/pyproject.toml b/pyproject.toml [tool.poetry]\nname = \"burnysc2\"\n-version = \"5.0.13\"\n+version = \"5.0.14\"\ndescription = \"A StarCraft II API Client for Python 3\"\nauthors = [\"BurnySc2 <gamingburny@gmail.com>\"]\nlicense = \"MIT\"\n@@ -27,7 +27,7 @@ classifiers=[\n\"Programming Language :: Python :: 3.10\",\n]\npackages = [\n- { include = \"sc2/*.py\" },\n+ { include = \"sc2/**/*.py\" },\n]\n[tool.poetry.dependencies]\n",
        "org_msg": "Fix build include files and bump version",
        "sim_msg": "Added doc and test source to sdist",
        "sim_diff": "diff --git a/pyproject.toml b/pyproject.toml @@ -14,7 +14,9 @@ classifiers = [\n\"Programming Language :: Python :: 3.7\",\n]\npackages = [\n- { include = \"astral\", from = \"src\"}\n+ { include = \"astral\", from = \"src\"},\n+ { include = \"doc\", from = \"src\", format = \"sdist\"},\n+ { include = \"test\", from = \"src\", format = \"sdist\"},\n]\n[tool.poetry.dependencies]\n",
        "chatgpt_cot": "Update version to 5.0.14 and include all subdirectories in the sc2 package to ensure compatibility with Python 3.10."
    },
    {
        "org_diff": "diff --git a/test/test_examples.py b/test/test_examples.py @@ -11,35 +11,40 @@ from examples.protoss.warpgate_push import WarpGateBot\nfrom examples.zerg.zerg_rush import ZergRushBot\nfrom examples.zerg.onebase_broodlord import BroodlordBot\n-def run_example(race, bot):\n+def run_example(caplog, race, bot):\nresult = sc2.run_game(sc2.maps.get(\"Sequencer LE\"), [\nBot(race, bot),\nComputer(Race.Terran, Difficulty.Easy)\n], realtime=False)\n+ for rec in caplog.records:\n+ if \"AI step threw an error\" in rec.msg:\n+ raise RuntimeError(\"Erroneous behavior logged in a\")\n+\n+ print(f\"result = {result !r}\")\nassert result in [sc2.Result.Victory, sc2.Result.Defeat, sc2.Result.Tie]\n@pytest.mark.slow\n-def test_proxy_rax_example():\n- run_example(Race.Terran, ProxyRaxBot())\n+def test_proxy_rax_example(caplog):\n+ run_example(caplog, Race.Terran, ProxyRaxBot())\n@pytest.mark.slow\n-def test_ramp_wall_example():\n- run_example(Race.Terran, RampWallBot())\n+def test_ramp_wall_example(caplog):\n+ run_example(caplog, Race.Terran, RampWallBot())\n@pytest.mark.slow\n-def test_cannon_rush_example():\n- run_example(Race.Protoss, CannonRushBot())\n+def test_cannon_rush_example(caplog):\n+ run_example(caplog, Race.Protoss, CannonRushBot())\n@pytest.mark.slow\n-def test_warpgate_example():\n- run_example(Race.Protoss, WarpGateBot())\n+def test_warpgate_example(caplog):\n+ run_example(caplog, Race.Protoss, WarpGateBot())\n@pytest.mark.slow\n-def test_zerg_rush_example():\n- run_example(Race.Zerg, ZergRushBot())\n+def test_zerg_rush_example(caplog):\n+ run_example(caplog, Race.Zerg, ZergRushBot())\n@pytest.mark.slow\n-def test_broodlord_example():\n- run_example(Race.Zerg, BroodlordBot())\n+def test_broodlord_example(caplog):\n+ run_example(caplog, Race.Zerg, BroodlordBot())\n",
        "org_msg": "Fix e2e slow test suite",
        "sim_msg": "unbreak tests that refer to removed rpc method",
        "sim_diff": "diff --git a/test/test_rpc.py b/test/test_rpc.py @@ -82,6 +82,10 @@ class ExampleService(object):\ndef async_task(self):\npass # pragma: no cover\n+ @rpc\n+ def raises(self):\n+ raise ExampleError(\"error\")\n+\n@pytest.yield_fixture\ndef get_rpc_exchange():\n@@ -452,14 +456,14 @@ def test_handle_message_raise_other_exception(\nproxy.task_a()\n-def test_rpc_broken_method(container_factory, rabbit_config):\n+def test_rpc_method_that_raises(container_factory, rabbit_config):\ncontainer = container_factory(ExampleService, rabbit_config)\ncontainer.start()\nwith ServiceRpcProxy(\"exampleservice\", rabbit_config) as proxy:\nwith pytest.raises(RemoteError) as exc_info:\n- proxy.broken()\n+ proxy.raises()\nassert exc_info.value.exc_type == \"ExampleError\"\n",
        "chatgpt_cot": "Add caplog parameter to run_example function to capture logs during test execution for better debugging and error handling in test_examples.py."
    },
    {
        "org_diff": "diff --git a/README.md b/README.md @@ -122,7 +122,9 @@ The API supports a number of options for configuring how it operates.\n### `unit_command_uses_self_do`\nSet this to 'True' if your bot is issueing commands using `self.do(Unit(Ability, Target))` instead of `Unit(Ability, Target)`.\n```python\n-class MyBot(sc2.BotAI):\n+from sc2.bot_ai import BotAI\n+\n+class MyBot(BotAI):\ndef __init__(self):\nself.unit_command_uses_self_do = True\n```\n@@ -130,7 +132,9 @@ class MyBot(sc2.BotAI):\n### `raw_affects_selection`\nSetting this to true improves bot performance by a little bit.\n```python\n-class MyBot(sc2.BotAI):\n+from sc2.bot_ai import BotAI\n+\n+class MyBot(BotAI):\ndef __init__(self):\nself.raw_affects_selection = True\n```\n@@ -141,7 +145,9 @@ The distance calculation method:\n- 1 for scipy pdist\n- 2 for scipy cdist\n```python\n-class MyBot(sc2.BotAI):\n+from sc2.bot_ai import BotAI\n+\n+class MyBot(BotAI):\ndef __init__(self):\nself.distance_calculation_method: int = 2\n```\n@@ -150,7 +156,9 @@ class MyBot(sc2.BotAI):\nOn game start or in any frame actually, you can set the game step. This controls how often your bot's `step` method is called.\n__Do not set this in the \\_\\_init\\_\\_ function as the client will not have been initialized yet!__\n```python\n-class MyBot(sc2.BotAI):\n+from sc2.bot_ai import BotAI\n+\n+class MyBot(BotAI):\ndef __init__(self):\npass # don't set it here!\n",
        "org_msg": "Updated all README examples, fixed imports\nAll of the README examples that were previously using ```sc2.BotAI``` had to be updated to include the following:\n```from sc2.bot_ai import BotAI```",
        "sim_msg": "statistics now allows non-bot output",
        "sim_diff": "diff --git a/trainer/utils/controller_statistics.py b/trainer/utils/controller_statistics.py @@ -10,32 +10,34 @@ class OutputChecks:\ngame_tick_packet = None\naccuracy_over_time = None\nbot_data_over_time = None\n+ requires_output = False\ndef __init__(self, packets, model_output, game_tick_packet, input_array, tf_session, action_handler,\n- tutorial_bot=None):\n+ bot=None):\nself.sess = tf_session\nself.packets = packets\nself.game_tick_packet = game_tick_packet\nself.input_array = input_array\nself.packet_generator = random_packet_creator.TensorflowPacketGenerator(packets)\n- self.tutorial_bot = tutorial_bot\n+ self.tutorial_bot = bot\nself.model_output = model_output\nself.actionHandler = action_handler\nif self.tutorial_bot is None:\n- self.tutorial_bot = tutorial_bot_output.TutorialBotOutput(packets)\n+ self.requires_output = True\ndef create_model(self):\n# clear history\nself.accuracy_over_time = []\nself.bot_data_over_time = []\n- def get_amounts(self):\n+ def get_amounts(self, bot_output=None):\ncontrols = tf.transpose(\nself.actionHandler.create_tensorflow_controller_from_selection(self.model_output, self.packets))\n- expected = self.tutorial_bot.get_output_vector(self.game_tick_packet)\n+ if not self.requires_output:\n+ bot_output = self.tutorial_bot.get_output_vector(self.game_tick_packet)\n- output, bot_output = self.sess.run([controls, expected])\n+ output = self.sess.run(controls)\naccuracy = np.sum(np.isclose(output, bot_output, 0.01), 1) / np.size(output[1])\nself.accuracy_over_time.append(accuracy)\n@@ -63,14 +65,13 @@ class OutputChecks:\nnumber_prints = len(self.accuracy_over_time)\naccuracy = np.transpose(self.accuracy_over_time)\nnp.set_printoptions(formatter={'float': '{: 0.2f}'.format})\n- ten = number_prints * .1\n- twfive = number_prints * .25\n- fifty = number_prints * .5\n+ percentages = [10, 25, 50]\nnames = [\"Throttle\", \"Steer\", \"Pitch\", \"Yaw\", \"Roll\", \"Jump\", \"Boost\", \"Handbrake\"]\n- print(\"Every action is printed four times, once all values and then averages over 10%, 25% and 50%\")\n+ print(\"Every action is printed multiple times, once all values and then averages over percentages\")\nfor n in range(8):\nprint(names[n] + \":\")\nprint(\"All: \", accuracy[n])\n- print(\"Averages every 10%\", np.array([average(accuracy[n][int(i * ten):int(i * ten + ten) if not int(i * ten + ten) is int(i * ten) else int(i * ten) + 1]) for i in range(10)]))\n- print(\" 25%\", np.array([average(accuracy[n][int(i * twfive):int(i * twfive + twfive) if not int(i * twfive + twfive) is int(i * twfive) else int(i * twfive) + 1]) for i in range(4)]))\n- print(\" 50%\", np.array([average(accuracy[n][int(i * fifty):int(i * fifty + fifty) if not int(i * fifty + fifty) is int(i * fifty) else int(i * fifty) + 1]) for i in range(2)]))\n+ for p in percentages:\n+ r = int(100 / p)\n+ step = int(number_prints * p / 100)\n+ print(str(p) + \"%:\", np.array([average(accuracy[n][int(i * step):int(i * step + step) if not int(i * step + step) is int(i * step) else int(i * step) + 1]) for i in range(r)]))\n",
        "chatgpt_cot": "\"Refactor MyBot class to import BotAI from sc2.bot_ai, and modify the __init__ method to set attributes.\""
    },
    {
        "org_diff": "diff --git a/fkie_node_manager_daemon/src/fkie_node_manager_daemon/launch_config.py b/fkie_node_manager_daemon/src/fkie_node_manager_daemon/launch_config.py @@ -182,6 +182,7 @@ class LaunchConfig(object):\nroscfg = roslaunch.ROSLaunchConfig()\nloader = roslaunch.XmlLoader()\nself.argv = self.resolve_args(argv)\n+ loader.ignore_unset_args = False\nloader.load(self.filename, roscfg, verbose=False, argv=self.argv)\nself.__roscfg = roscfg\nif 'arg' in loader.root_context.resolve_dict:\n",
        "org_msg": "fkie_node_manager: fixed error message with ignore_unset_args",
        "sim_msg": "retry startup",
        "sim_diff": "diff --git a/lbrynet/lbrynet_daemon/DaemonControl.py b/lbrynet/lbrynet_daemon/DaemonControl.py @@ -114,7 +114,7 @@ def update_settings_from_args(args):\n@defer.inlineCallbacks\n-def start_server_and_listen(launchui, use_auth, analytics_manager):\n+def start_server_and_listen(launchui, use_auth, analytics_manager, max_tries=5):\n\"\"\"The primary entry point for launching the daemon.\nArgs:\n@@ -124,13 +124,19 @@ def start_server_and_listen(launchui, use_auth, analytics_manager):\n\"\"\"\nanalytics_manager.send_server_startup()\nlog_support.configure_analytics_handler(analytics_manager)\n+ tries = 1\n+ while tries < max_tries:\n+ log.info('Making attempt %s / %s to startup', tries, max_tries)\ntry:\ndaemon_server = DaemonServer(analytics_manager)\nyield daemon_server.start(use_auth, launchui)\nanalytics_manager.send_server_startup_success()\n+ break\nexcept Exception as e:\nlog.exception('Failed to startup')\nanalytics_manager.send_server_startup_error(str(e))\n+ tries += 1\n+ else:\nreactor.callFromThread(reactor.stop)\n",
        "chatgpt_cot": "\"Enable loader to consider unset arguments in launch configuration\""
    },
    {
        "org_diff": "diff --git a/fkie_node_manager/scripts/reduced_nm.py b/fkie_node_manager/scripts/reduced_nm.py @@ -136,6 +136,7 @@ class StartHandler(object):\nmaster.getUri(rospy.get_name())\nexcept Exception:\n# run a roscore\n+ screen.test_screen()\nmaster_host = get_hostname(masteruri)\nif cls.is_local(master_host, True):\nprint(\"Start ROS-Master with %s ...\" % masteruri)\n",
        "org_msg": "fixed remote start of roscore",
        "sim_msg": "master: send_await() always unpickles now.",
        "sim_diff": "diff --git a/mitogen/master.py b/mitogen/master.py @@ -744,10 +744,9 @@ class ChildIdAllocator(object):\ndef allocate(self):\nmaster = Context(self.router, 0)\n- reply = master.send_await(\n+ return master.send_await(\nmitogen.core.Message(dst_id=0, handle=mitogen.core.ALLOCATE_ID)\n)\n- return reply.unpickle()\nclass Router(mitogen.core.Router):\n",
        "chatgpt_cot": "\"Add screen test in case of exception when getting master URI in StartHandler class\""
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/main_window.py b/node_manager_fkie/src/node_manager_fkie/main_window.py @@ -483,6 +483,8 @@ class MainWindow(QMainWindow):\nself._finished = True\nprint \"Mainwindow finish...\"\nself._stop_updating()\n+ for _, editor in self.editor_dialogs.items():\n+ editor.close()\nfor _, master in self.masters.iteritems():\nmaster.stop()\nprint \"Mainwindow finished!\"\n@@ -1655,7 +1657,7 @@ class MainWindow(QMainWindow):\ndel self.editor_dialogs[path]\nself.on_launch_edit(files, search_text, 2)\nelse:\n- editor = Editor(files, search_text, self)\n+ editor = Editor(files, search_text)\nself.editor_dialogs[path] = editor\neditor.finished_signal.connect(self._editor_dialog_closed)\neditor.show()\n",
        "org_msg": "node_manager_fkie: fixed problem with editor in foreground",
        "sim_msg": "add Duplicate menu item for toplevel windows",
        "sim_diff": "diff --git a/edit_windows.py b/edit_windows.py @@ -244,6 +244,10 @@ class EditBase(EventsMixin, np.PropertyOwner):\nself._dont_destroy = False # always destroy when explicitly asked\ncommon.app_tree.remove(self.node)\n+ def duplicate(self, *args):\n+ clipboard.copy(self)\n+ clipboard.paste(common.app_tree.root.widget)\n+\ndef on_set_focus(self, event):\n\"\"\"Event handler called when a window receives the focus: this in fact is\nconnected to a EVT_LEFT_DOWN and not to an EVT_FOCUS, but the effect is the same\"\"\"\n@@ -746,6 +750,9 @@ class TopLevelBase(WindowBase, PreviewMixin):\ni = misc.append_menu_item(menu, -1, _('Remove %s\\tDel')%widgetclass, wx.ART_DELETE)\nmisc.bind_menu_item_after(widget, i, self.remove)\n+ i = misc.append_menu_item(menu, -1, _('Duplicate %s')%widgetclass, wx.ART_COPY)\n+ misc.bind_menu_item_after(widget, i, self.duplicate)\n+\n# paste\ni = misc.append_menu_item(menu, -1, _('Paste Sizer\\tCtrl+V'), wx.ART_PASTE)\nmisc.bind_menu_item_after(widget, i, self.clipboard_paste)\n",
        "chatgpt_cot": "\"Close editor dialog when main window is finished and update Editor constructor call in main window for consistency.\""
    },
    {
        "org_diff": "diff --git a/setup.py b/setup.py @@ -10,7 +10,7 @@ test_requirements = convert_deps_to_pip(pfile[\"dev-packages\"], r=False)\nsetup(\nname=\"burnysc2\",\npackages=find_packages(exclude=[\"examples*\", \"examples\"]),\n- version=\"4.11.16\",\n+ version=\"5.0.0\",\ndescription=\"A StarCraft II API Client for Python 3\",\nlicense=\"MIT\",\nauthor=\"BurnySc2\",\n",
        "org_msg": "Bump version to 5.0.0 to push a new pypi package",
        "sim_msg": "Bumping dependency versions in setup.py",
        "sim_diff": "diff --git a/setup.py b/setup.py @@ -24,9 +24,9 @@ setup(\npackages=(find_packages(exclude=['test', 'test.*'])),\ninclude_package_data=True,\ninstall_requires=[\n- \"apispec==0.25.4\",\n+ \"apispec==0.38.0\",\n\"bg-utils>=2.3.4\",\n- \"tornado==4.5.2\",\n+ \"tornado==5.0.2\",\n],\nextras_require={\n':python_version==\"2.7\"': [\n",
        "chatgpt_cot": "Update version to 5.0.0 in setup.py for burnysc2 package."
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/launch_list_model.py b/node_manager_fkie/src/node_manager_fkie/launch_list_model.py @@ -204,7 +204,7 @@ class PathItem(QStandardItem):\n# return the tooltip of the item\nresult = \"%s\" % self.path\nif self.id == PathItem.RECENT_FILE or self.id == PathItem.RECENT_PROFILE:\n- result = \"%s\\nPress 'Delete' to remove the entry from the history list\" % self.path\n+ result = \"%s\\nPress 'Delete' to remove the entry from the history list\\nShift+'double click' goes to the file location\" % self.path\nreturn result\nelif role == Qt.EditRole:\nreturn \"%s\" % self.name\n",
        "org_msg": "node_manager_fkie: added hint for history files",
        "sim_msg": "improved file management context menu",
        "sim_diff": "diff --git a/qualcoder/manage_files.py b/qualcoder/manage_files.py @@ -135,15 +135,35 @@ class DialogManageFiles(QtWidgets.QDialog):\ntext = None\ntry:\ntext = str(self.ui.tableWidget.item(row, col).text())\n+ # some blanks cells contain None and some contain blank strings\n+ if text == \"\":\n+ text = None\nexcept:\npass\n#print(self.row, self.col, self.cellValue)\n- if col < 4:\n+ # action cannot be None otherwise may default to one of the actionsbelow depending on column clicked\nmenu = QtWidgets.QMenu()\n+ action_view = menu.addAction(_(\"View\"))\n+ action_alphabetic = 1\n+ action_date = 1\n+ action_type = 1\n+ action_by_value = 1\n+ if col < 4:\naction_alphabetic = menu.addAction(_(\"Alphabetic order\"))\naction_date = menu.addAction(_(\"Date order\"))\naction_type = menu.addAction(_(\"File type order\"))\n+ if col > 3:\n+ action_by_value = menu.addAction(_(\"Show this value\"))\n+ action_export = menu.addAction(_(\"Export\"))\n+ action_delete = menu.addAction(_(\"Delete\"))\naction = menu.exec_(self.ui.tableWidget.mapToGlobal(position))\n+\n+ if action == action_view:\n+ self.view()\n+ if action == action_export:\n+ self.export()\n+ if action== action_delete:\n+ self.delete()\nif action == action_alphabetic:\nself.order_by = \"\"\nself.load_file_data()\n@@ -154,17 +174,16 @@ class DialogManageFiles(QtWidgets.QDialog):\nif action == action_type:\nself.order_by = \"filetype\"\nself.load_file_data()\n- #TODO\n- '''\n- # Hide rows that do not match this value\n- if col > 3:\n- print(row, col, text)\n+ if action == action_by_value:\n+ # Hide rows that do not match this value, text can be None type\n+ # Cell items can be None or exist with ''\nfor r in range(0, self.ui.tableWidget.rowCount()):\n- try:\n- if self.ui.tableWidget.item(row, col).text().find(text) == -1:\n+ item = self.ui.tableWidget.item(r, col)\n+ # items can be None or appear to be None when item text == ''\n+ if text is None and (item is not None and len(item.text()) > 0):\n+ self.ui.tableWidget.setRowHidden(r, True)\n+ if text is not None and (item is None or item.text().find(text) == -1):\nself.ui.tableWidget.setRowHidden(r, True)\n- except: # None type\n- pass'''\ndef load_file_data(self):\n\"\"\" Documents images and audio contain the filetype suffix.\n@@ -1067,7 +1086,7 @@ class DialogManageFiles(QtWidgets.QDialog):\niditem = QtWidgets.QTableWidgetItem(str(fid))\niditem.setFlags(iditem.flags() ^ QtCore.Qt.ItemIsEditable)\nself.ui.tableWidget.setItem(row, self.ID_COLUMN, iditem)\n- # add the attribute values\n+ # Add the attribute values\nfor a in self.attributes:\nfor col, header in enumerate(self.header_labels):\n#print(fid, a[2], a[0], header)\n",
        "chatgpt_cot": "Update tooltip message in PathItem class to include information about removing entry and navigating to file location."
    },
    {
        "org_diff": "diff --git a/sc2/bot_ai.py b/sc2/bot_ai.py @@ -31,7 +31,7 @@ class BotAI(object):\ndef _prepare_step(self, state):\nself.units = state.units.owned\nself.minerals = state.common.minerals\n- self.vespnene = state.common.vespene\n+ self.vespene = state.common.vespene\ndef on_start(self):\npass\n",
        "org_msg": "Prepare with vespenen gas count too",
        "sim_msg": "renamed action scheme",
        "sim_diff": "diff --git a/bot_code/modelHelpers/actions/action_factory.py b/bot_code/modelHelpers/actions/action_factory.py @@ -49,7 +49,7 @@ super_split_scheme = ControlScheme(\ncopies=[],\n)\n-super_split_scheme_no_combo = ControlScheme(\n+super_split_scheme_no_combo_7 = ControlScheme(\nranges=[(THROTTLE, (-1, 1.25, .25)), (STEER, (-1, 1.25, .25)), (YAW, (-1, 1.25, .25)), (PITCH, (-1, 1.25, .25)), (ROLL, (-1, 1.25, .25)),(JUMP, (0, 2, 1)), (BOOST, (0, 2, 1)), (HANDBRAKE, (0, 2, 1))],\ncombo_scheme=[],\ncopies=[],\n",
        "chatgpt_cot": "Fix typo in variable name 'vespnene' to 'vespene' in BotAI class to maintain consistency and avoid potential errors related to resource tracking."
    },
    {
        "org_diff": "diff --git a/sc2/unit.py b/sc2/unit.py @@ -334,7 +334,7 @@ class Unit(object):\nunit_attack_range = self.air_range\nelse:\nunit_attack_range = -1\n- return self.distance_to(target) + bonus_distance <= target.radius + unit_attack_range\n+ return self.distance_to(target) + bonus_distance <= self.radius + target.radius + unit_attack_range\n@property\ndef armor(self) -> Union[int, float]:\n",
        "org_msg": "Include unit radius in target_in_range function",
        "sim_msg": "fix for value_and_unit",
        "sim_diff": "diff --git a/apps/projects/models.py b/apps/projects/models.py @@ -261,6 +261,6 @@ class Value(Model):\nvalue = self.value\nif self.attribute.unit:\n- return str(value) + ' ' + self.attribute.unit\n+ return '%s %s' % (value, self.attribute.unit)\nelse:\nreturn value\n",
        "chatgpt_cot": "Fix calculation of attack range and distance in Unit class. Update the condition expression to correctly calculate the attack range and distance."
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/html_delegate.py b/node_manager_fkie/src/node_manager_fkie/html_delegate.py @@ -59,7 +59,7 @@ class HTMLDelegate(QStyledItemDelegate):\ndoc = QTextDocument()\ndoc.setHtml(self.toHTML(options.text))\n- doc.setTextWidth(option.rect.width())\n+ # doc.setTextWidth(option.rect.width())\noptions.text = ''\nstyle.drawControl(QStyle.CE_ItemViewItem, options, painter)\n",
        "org_msg": "node_manager_fkie: fixed display not complete node/topic/service name",
        "sim_msg": "Fix rendering of multiple stereotype params/attributes/operations",
        "sim_diff": "diff --git a/gaphor/diagram/classes/klass.py b/gaphor/diagram/classes/klass.py @@ -117,7 +117,12 @@ class ClassItem(ElementPresentation, Classified):\nstyle={\"min-width\": 0, \"min-height\": 0},\n),\nEditableText(\n- text=lambda: self.subject.name or \"\", style={\"font\": \"sans bold 10\"}\n+ text=lambda: self.subject.name or \"\",\n+ style={\n+ \"font\": \"sans bold italic 10\"\n+ if self.subject and self.subject.isAbstract\n+ else \"sans bold 10\"\n+ },\n),\nstyle={\"padding\": (12, 4, 12, 4)},\n),\n@@ -166,11 +171,14 @@ class ClassItem(ElementPresentation, Classified):\ndef attributes_compartment(subject):\n+ # We need to fix the attribute value, since the for loop changes it.\n+ def lazy_format(attribute):\n+ # str(), so we never ever get an error on a property part of an association\n+ return lambda: (UML.format(attribute))\n+\nreturn Box(\n*(\n- Text(\n- text=lambda: UML.format(attribute), style={\"text-align\": TextAlign.LEFT}\n- )\n+ Text(text=lazy_format(attribute), style={\"text-align\": TextAlign.LEFT})\nfor attribute in subject.ownedAttribute\nif not attribute.association\n),\n@@ -180,17 +188,19 @@ def attributes_compartment(subject):\ndef operations_compartment(subject):\n+ def lazy_format(operation):\n+ return lambda: UML.format(\n+ operation, visibility=True, type=True, multiplicity=True, default=True\n+ )\n+\nreturn Box(\n*(\nText(\n- text=lambda: UML.format(\n- operation,\n- visibility=True,\n- type=True,\n- multiplicity=True,\n- default=True,\n- ),\n- style={\"text-align\": TextAlign.LEFT},\n+ text=lazy_format(operation),\n+ style={\n+ \"text-align\": TextAlign.LEFT,\n+ \"font\": \"sans italic 10\" if operation.isAbstract else \"sans 10\",\n+ },\n)\nfor operation in subject.ownedOperation\n),\n",
        "chatgpt_cot": "Comment out doc.setTextWidth to prevent text wrapping in HTMLDelegate. Fixes display issue with item width in QStyledItemDelegate."
    },
    {
        "org_diff": "diff --git a/sc2/game_info.py b/sc2/game_info.py from typing import Tuple, Set, FrozenSet, Sequence, Generator\n+from collections import deque\nfrom copy import deepcopy\nimport itertools\n@@ -169,33 +170,53 @@ class GameInfo(object):\ndef _find_groups(self, points: Set[Point2], minimum_points_per_group: int=8, max_distance_between_points: int=2) -> List[Set[Point2]]:\n\"\"\" From a set/list of points, this function will try to group points together \"\"\"\n- foundGroups = []\n- currentGroup = set()\n- newlyAdded = set()\n- pointsPool = set(points)\n-\n- while pointsPool or currentGroup:\n- if not currentGroup:\n- randomPoint = pointsPool.pop()\n- currentGroup.add(randomPoint)\n- newlyAdded.add(randomPoint)\n-\n- newlyAddedOld = newlyAdded\n- newlyAdded = set()\n- for p1 in newlyAddedOld:\n- # create copy as we change set size during iteration\n- for p2 in pointsPool.copy():\n- if abs(p1.x - p2.x) + abs(p1.y - p2.y) <= max_distance_between_points:\n- currentGroup.add(p2)\n- newlyAdded.add(p2)\n- pointsPool.discard(p2)\n-\n- # Check if all connected points were found\n- if not newlyAdded:\n- # Add to group if number of points reached threshold - discard group if not enough points\n+ \"\"\" Paint clusters of points in rectangular map using flood fill algorithm. \"\"\"\n+ NOT_INTERESTED = -2\n+ NOT_COLORED_YET = -1\n+ currentColor: int = NOT_COLORED_YET\n+ picture: List[List[int]] = [[NOT_INTERESTED\n+ for j in range (self.pathing_grid.width)]\n+ for i in range (self.pathing_grid.height)]\n+\n+ def paint (pt: Point2) -> None:\n+ picture[pt.y][pt.x] = currentColor\n+\n+ nearby: Set[Point2] = set ()\n+ for dx in range (-max_distance_between_points, max_distance_between_points + 1):\n+ for dy in range (-max_distance_between_points, max_distance_between_points + 1):\n+ if abs (dx) + abs (dy) <= max_distance_between_points:\n+ nearby.add (Point2 ((dx, dy)))\n+\n+ for point in points:\n+ paint (point)\n+\n+ remaining: Set[Point2] = set (points)\n+ queue: Deque[Point2] = deque ()\n+ foundGroups: List[Set[Point2]] = []\n+ while remaining:\n+ currentGroup: Set[Point2] = set ()\n+ if not queue:\n+ currentColor += 1\n+ start = remaining.pop ()\n+ paint (start)\n+ queue.append (start)\n+ currentGroup.add (start)\n+ while queue:\n+ base: Point2 = queue.popleft ()\n+ for offset in nearby:\n+ px, py = base.x + offset.x, base.y + offset.y\n+ if px < 0 or py < 0 or px >= self.pathing_grid.width or py >= self.pathing_grid.height:\n+ continue\n+ if picture[py][px] != NOT_COLORED_YET:\n+ continue\n+ point: Point2 = Point2 ((px, py))\n+ remaining.remove (point)\n+ paint (point)\n+ queue.append (point)\n+ currentGroup.add (point)\nif len (currentGroup) >= minimum_points_per_group:\nfoundGroups.append (currentGroup)\n- currentGroup = set()\n+\n\"\"\" Returns groups of points as list\n[{p1, p2, p3}, {p4, p5, p6, p7, p8}]\n\"\"\"\n",
        "org_msg": "Find point clusters during ramp search faster\nUse flood fill algorithm to only compare nearby points",
        "sim_msg": "Handle a degenerate case better",
        "sim_diff": "diff --git a/histomicstk/segmentation/label/trace_object_boundaries.py b/histomicstk/segmentation/label/trace_object_boundaries.py @@ -131,7 +131,7 @@ def trace_object_boundaries(im_label,\nreturn X, Y\n-def _remove_thin_colinear_spurs(px, py, eps_colinear_area=1.0):\n+def _remove_thin_colinear_spurs(px, py, eps_colinear_area=0.0):\n\"\"\"Simplifies the given list of points by removing colinear spurs\n\"\"\"\n@@ -143,7 +143,14 @@ def _remove_thin_colinear_spurs(px, py, eps_colinear_area=1.0):\nwhile testpos < len(px):\n# get coords of next triplet of points to test\n- ind = [anchor, testpos, (testpos + 1) % len(px)]\n+ if testpos == len(px) - 1:\n+ if not len(keep):\n+ break\n+ nextpos = keep[0]\n+ else:\n+ nextpos = testpos + 1\n+\n+ ind = [anchor, testpos, nextpos]\nx1, x2, x3 = px[ind]\ny1, y2, y3 = py[ind]\n@@ -162,9 +169,6 @@ def _remove_thin_colinear_spurs(px, py, eps_colinear_area=1.0):\nelse:\ntestpos += 1\n- if len(keep) < 2: # degenerate case\n- keep = [0, -1]\n-\npx = px[keep]\npy = py[keep]\n",
        "chatgpt_cot": "Add flood fill algorithm to paint clusters of points in rectangular map using flood fill algorithm. Fix compilation issue due to new method in GameInfo."
    },
    {
        "org_diff": "diff --git a/master_sync_fkie/src/master_sync_fkie/sync_thread.py b/master_sync_fkie/src/master_sync_fkie/sync_thread.py @@ -104,7 +104,7 @@ class SyncThread(object):\n# setup the filter\nself._filter = FilterInterface()\nself._filter.load(self.name,\n- ['/rosout', rospy.get_name().replace('/', '/*') + '*', self.discoverer_name.replace('/', '/*') + '*', '/*node_manager', '/*zeroconf'], [],\n+ ['/rosout', rospy.get_name(), self.discoverer_name, '/node_manager', '/zeroconf'], [],\n['/rosout', '/rosout_agg'], ['/'] if sync_on_demand else [],\n['/*get_loggers', '/*set_logger_level'], [],\n# do not sync the bond message of the nodelets!!\n",
        "org_msg": "master_sync_fkie: changed default filter for sync nodes, see issue",
        "sim_msg": "[sync.py] only restart running pods",
        "sim_diff": "diff --git a/devbin/sync.py b/devbin/sync.py @@ -64,7 +64,8 @@ class Sync:\nk8s.list_namespaced_pod,\nnamespace,\nlabel_selector=f'app in ({\",\".join(apps)})')\n- updated_pods = {(pod.metadata.name, namespace) for pod in updated_pods.items}\n+ updated_pods = [x for x in updated_pods.items if x.status.phase == 'Running']\n+ updated_pods = {(pod.metadata.name, namespace) for pod in updated_pods}\nfresh_pods = updated_pods - self.pods\ndead_pods = self.pods - updated_pods\nlog.info(f'monitor_pods: fresh_pods: {fresh_pods}')\n",
        "chatgpt_cot": "\"Modify filter interface load method in sync thread to fix sync on demand issue\""
    },
    {
        "org_diff": "diff --git a/Makefile b/Makefile @@ -136,7 +136,7 @@ build/docker/%/.push: build/docker/%/$(DUMMY)\ndocker: $(patsubst %,build/docker/%/$(DUMMY),$(DOCKER_IMAGES)) ##@Generate docker images locally\n-docker-operator-dashboard: build/docker/operator-dashboard/$(DUMMY)\n+docker-operator-dashboard: build/docker/dashboard/$(DUMMY)\ndocker-clean: stop image-clean ##@Clean all existing images\n",
        "org_msg": "[CE-652]Fix the path error in the Makefile\nThe makefile contains the old path to the dashboard Dockerfile.\nThis patch fixed that error.",
        "sim_msg": "UI now has a latest docker tag",
        "sim_diff": "diff --git a/src/ui/Makefile b/src/ui/Makefile @@ -72,8 +72,9 @@ package: clean ## builds distribution\n# Docker\ndocker-build: package ## build docker image\n- docker build -t $(DOCKER_NAME):$(VERSION) .\n- docker tag $(DOCKER_NAME):$(VERSION) $(DOCKER_NAME):$(SHORT_VERSION)\n+ docker build -t $(DOCKER_NAME):latest .\n+ docker tag $(DOCKER_NAME):latest $(DOCKER_NAME):$(VERSION)\n+ docker tag $(DOCKER_NAME):latest $(DOCKER_NAME):$(SHORT_VERSION)\ndocker-build-unstable: package ## build nightly docker image\ndocker build -t $(DOCKER_NAME):unstable .\n@@ -81,6 +82,7 @@ docker-build-unstable: package ## build nightly docker image\n# Publishing\npublish-docker: docker-build ## push the docker image\n+ docker push $(DOCKER_NAME):latest\ndocker push $(DOCKER_NAME):$(VERSION)\ndocker push $(DOCKER_NAME):$(SHORT_VERSION)\n",
        "chatgpt_cot": "\"Update Makefile to correct docker image build target for operator-dashboard\""
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/master_view_proxy.py b/node_manager_fkie/src/node_manager_fkie/master_view_proxy.py @@ -80,6 +80,13 @@ try:\nexcept Exception:\nfrom python_qt_binding.QtCore import QItemSelection, QItemSelectionModel, QItemSelectionRange, QSortFilterProxyModel\n+# from python_qt_binding import QtUiTools\n+try:\n+ from diagnostic_msgs.msg import DiagnosticStatus\n+ DIAGNOSTICS_AVAILABLE = True\n+except Exception:\n+ DIAGNOSTICS_AVAILABLE = False\n+\nclass MasterViewProxy(QWidget):\n'''\n@@ -1027,7 +1034,16 @@ class MasterViewProxy(QWidget):\ndef on_nmd_version_retrieved(self, nmd_url, version, date):\n# rospy.logdebug(\"%s %s %s\" % (version, date, nmd_url))\n+ if DIAGNOSTICS_AVAILABLE:\n+ diagnostic_status = DiagnosticStatus()\n+ diagnostic_status.name = '/node_manager_daemon'\nif version != self._nmd_version:\n+ diagnostic_status.level = DiagnosticStatus.WARN\n+ diagnostic_status.message = \"node_manager_daemon has on<br>%s different version<br>'%s', own:<br>'%s'.<br>Please update and restart!\" % (self.masteruri, version, self._nmd_version)\n+ else:\n+ diagnostic_status.level = DiagnosticStatus.OK\n+ self.append_diagnostic(diagnostic_status)\n+ elif version != self._nmd_version:\nself.message_frame.show_question(MessageFrame.TYPE_NMD, \"node_manager_daemon has on %s different version '%s', own '%s'.\\nShould it be started?\" % (self.masteruri, version, self._nmd_version), MessageData(self.masteruri))\n@property\n",
        "org_msg": "node_manager_fkie: set warning state of the daemon if different version detected",
        "sim_msg": "remove update url",
        "sim_diff": "diff --git a/lbrynet/lbrynet_daemon/Daemon.py b/lbrynet/lbrynet_daemon/Daemon.py @@ -125,10 +125,8 @@ class CheckInternetConnection(object):\nclass CheckRemoteVersion(object):\n- URL = 'https://api.github.com/repos/lbryio/lbry-electron/releases/latest'\ndef __init__(self):\nself.version = None\n- self.update_url = None\ndef __call__(self):\nd = threads.deferToThread(self._get_lbry_electron_client_version)\n@@ -157,7 +155,6 @@ class CheckRemoteVersion(object):\nif release['prerelease']:\nraise Exception('Release {} is a pre-release'.format(tag))\nself.version = self._get_version_from_release(release)\n- self.update_url = self._get_update_url_from_release(release)\ndef _get_release_data(self):\nresponse = requests.get(self.URL, timeout=20)\n@@ -169,31 +166,6 @@ class CheckRemoteVersion(object):\ntag = release['tag_name']\nreturn self._get_version_from_tag(tag)\n- def _get_update_url_from_release(self, release):\n- # go through the assets and pick the one that looks like it\n- # best matches the system we're on\n- target_ext = self._extension_for_platform()\n- print\n- print target_ext\n- print\n- for asset in release['assets']:\n- url = asset['browser_download_url']\n- print\n- print url\n- print\n- if os.path.splitext(url)[1] == target_ext:\n- return url\n- return None\n-\n- def _extension_for_platform(self):\n- system = platform.system()\n- if system == 'Darwin':\n- return \".dmg\"\n- elif system == 'Linux':\n- return \".deb\"\n- else:\n- return \".zip\"\n-\ndef _get_version_from_tag(self, tag):\nmatch = re.match('v([\\d.]+)', tag)\nif match:\n@@ -1290,7 +1262,6 @@ class Daemon(AuthJSONRPCServer):\n'ui_version': platform_info['ui_version'],\n'remote_lbrynet': self._remote_version.version,\n'lbrynet_update_available': self._remote_version.is_update_available(),\n- 'lbrynet_update_url': self._remote_version.update_url\n}\nlog.info(\"Get version info: \" + json.dumps(msg))\n",
        "chatgpt_cot": "\"Add diagnostic status for node_manager_daemon version retrieval in MasterViewProxy\""
    },
    {
        "org_diff": "diff --git a/src/agent/fabric-operator/deploy/crds/fabric_v1alpha1_ca_cr.yaml b/src/agent/fabric-operator/deploy/crds/fabric_v1alpha1_ca_cr.yaml @@ -35,14 +35,8 @@ spec:\n# memory: \"1024mi\"\n# cpu: \"250\"\n- # To specify more environment variables for Fabric CA.\n- # following parameters:\n- # FABRIC_CA_SERVER_CSR_HOSTS: \"[]\"\n- # FABRIC_CA_SERVER_CSR_NAMES_0_C: US\n- # FABRIC_CA_SERVER_CSR_NAMES_0_ST: \"North Carolina\"\n- # FABRIC_CA_SERVER_CSR_NAMES_0_L: \"Cary\"\n- # FABRIC_CA_SERVER_CSR_NAMES_0_O: \"Sample Org\"\n- # FABRIC_CA_SERVER_CSR_NAMES_0_OU: \"Sample Org Unit\"\n+ # To specify more environment variables for Fabric CA, use any Fabric CA\n+ # configurable parameters\nconfigParams:\n- name: FABRIC_CA_SERVER_PORT\nvalue: \"7054\"\n",
        "org_msg": "[#63]Removed the few extra spaces from the example yaml",
        "sim_msg": "update ci deployment",
        "sim_diff": "diff --git a/ci/deployment.yaml b/ci/deployment.yaml @@ -14,7 +14,7 @@ spec:\nspec:\ncontainers:\n- name: hail-ci\n- image: gcr.io/broad-ctsa/hail-ci:0d5db5aa44cb934a08ce06c789cf389bd10d5d6b57a7239d60606e95b7fbb71b\n+ image: gcr.io/broad-ctsa/hail-ci:102b3c13a57d1eefd5f91558b72b8cabc9d01cef89aa6f38a5bcd7fba834672c\nenv:\n- name: SELF_HOSTNAME\nvalue: http://hail-ci\n",
        "chatgpt_cot": "Refactor environment variable configuration in fabric_v1alpha1_ca_cr.yaml to use any Fabric CA configurable parameters, improving flexibility and maintainability."
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/main_window.py b/node_manager_fkie/src/node_manager_fkie/main_window.py @@ -260,6 +260,8 @@ class MainWindow(QMainWindow):\nself.startRobotButton.setEnabled(False)\nself._sync_dialog = SyncDialog()\n+ self._shortcut_focus = QShortcut(QKeySequence(self.tr(\"Ctrl+Shift+F\", \"switch to next focus area\")), self)\n+ self._shortcut_focus.activated.connect(self._show_section_menu)\nself.editor_dialogs = dict() # [file] = Editor\n'''@ivar: stores the open Editor '''\n@@ -342,7 +344,6 @@ class MainWindow(QMainWindow):\nif DIAGNOSTICS_AVAILABLE:\nself._sub_extended_log = rospy.Subscriber('/diagnostics_agg', DiagnosticArray, self._callback_diagnostics)\nself.launch_dock.launchlist_model.reloadPackages()\n- self._timer_alt = None\nself._select_index = 0\ndef _dock_widget_in(self, area=Qt.LeftDockWidgetArea, only_visible=False):\n@@ -2079,18 +2080,10 @@ class MainWindow(QMainWindow):\ndef keyPressEvent(self, event):\n'''\n- Track long hold Alt-Key\n'''\n- if event.modifiers() == Qt.AltModifier and event.key() == Qt.Key_Alt:\n- self._select_index = 0\n- self._timer_alt = rospy.Timer(rospy.Duration(1.1), self._show_section_menu) # , oneshot=True)\n- else:\n- if self._timer_alt is not None:\n- self._timer_alt.shutdown()\n- self._timer_alt = None\nQMainWindow.keyPressEvent(self, event)\n- def _show_section_menu(self, event):\n+ def _show_section_menu(self, event=None):\n# self._timer_alt = None\nif self._select_index == 0:\nif self.currentMaster is not None:\n@@ -2127,9 +2120,6 @@ class MainWindow(QMainWindow):\nDefines some of shortcuts for navigation/management in launch\nlist view or topics view.\n'''\n- if self._timer_alt is not None:\n- self._timer_alt.shutdown()\n- self._timer_alt = None\nkey_mod = QApplication.keyboardModifiers()\nif self.currentMaster is not None and self.currentMaster.masterTab.nodeTreeView.hasFocus():\nif event.key() == Qt.Key_F4 and not key_mod:\n",
        "org_msg": "node_manager_fkie: replaced long hold Alt by Ctrl+Shift+F",
        "sim_msg": "additional cleanup and bugfix for Viv-specific docks.",
        "sim_diff": "diff --git a/vivisect/qt/main.py b/vivisect/qt/main.py @@ -231,8 +231,8 @@ class VQVivMainWindow(viv_base.VivEventDist, vq_app.VQMainCmdWindow):\ndwcls = settings.value('%s/DockClasses' % guid)\nstate = settings.value('%s/DockState' % guid)\ngeom = settings.value('%s/DockGeometry' % guid)\n+ basename = '%s/VQDockWidget%%d' % guid\n- # PyQt4 is very different here\nif compat_isNone(dwcls):\nnames = self.vw.filemeta.keys()\nnames.sort()\n@@ -240,17 +240,18 @@ class VQVivMainWindow(viv_base.VivEventDist, vq_app.VQMainCmdWindow):\ndwcls = settings.value('%s/DockClasses' % name)\nstate = settings.value('%s/DockState' % name)\ngeom = settings.value('%s/DockGeometry' % name)\n+ basename = '%s/VQDockWidget%%d' % name\nif compat_isNone(dwcls):\ndwcls = settings.value('DockClasses')\nstate = settings.value('DockState')\ngeom = settings.value('DockGeometry')\n+ basename = 'VQDockWidget%d'\nif not compat_isNone(dwcls):\n- print repr(dwcls)\nfor i, clsname in enumerate(compat_strList(dwcls)):\n- name = 'VQDockWidget%d' % i\n+ name = basename % i\ntry:\ntup = self.vqBuildDockWidget(str(clsname), floating=False)\nif tup != None:\n@@ -275,49 +276,6 @@ class VQVivMainWindow(viv_base.VivEventDist, vq_app.VQMainCmdWindow):\nreturn True\n- # or it's Qt5\n- if dwcls == None or not len(dwcls):\n- names = self.vw.filemeta.keys()\n- names.sort()\n- name = '+'.join(names)\n- dwcls = settings.value('%s/DockClasses' % name)\n- state = settings.value('%s/DockState' % name)\n- geom = settings.value('%s/DockGeometry' % name)\n-\n- if dwcls == None or not len(dwcls):\n- dwcls = settings.value('DockClasses')\n- state = settings.value('DockState')\n- geom = settings.value('DockGeometry')\n-\n-\n- if dwcls != None and len(dwcls):\n- for i, clsname in enumerate(dwcls):\n- name = 'VQDockWidget%d' % i\n- try:\n- #tup = self.vqBuildDockWidget(str(clsname)) # FIXME:, floating=True)\n- tup = self.vqBuildDockWidget(str(clsname), floating=True)\n- if tup != None:\n- d, obj = tup\n- d.setObjectName(name)\n- d.vqRestoreState(settings,name)\n- d.show()\n- except Exception, e:\n- print('Error Building: %s: %s' % (clsname,e))\n-\n- # Once dock widgets are loaded, we can restoreState\n- if not state == None:\n- self.restoreState(state)\n-\n- if not geom == None:\n- self.restoreGeometry(geom)\n-\n- # Just get all the resize activities done...\n- vq_main.eatevents()\n- for w in self.vqGetDockWidgets():\n- w.show()\n-\n- return True\n-\ndef vqSaveGuiSettings(self, settings):\ndock_classes = []\n",
        "chatgpt_cot": "Add a new method to MainWindow, and connect it to a shortcut. Remove a timer and modify a method."
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/master_view_proxy.py b/node_manager_fkie/src/node_manager_fkie/master_view_proxy.py @@ -2624,8 +2624,10 @@ class MasterViewProxy(QWidget):\nimport shlex\nenv = dict(os.environ)\nenv[\"ROS_MASTER_URI\"] = str(self.masteruri)\n- nodename = 'echo_%s%s%s%s' % ('hz_' if show_hz_only else '', 'ssh_' if use_ssh else '', str(get_hostname(self.masteruri)), topic.name)\n- cmd = 'rosrun node_manager_fkie node_manager --echo %s %s %s %s __name:=%s' % (topic.name, topic.type, '--hz' if show_hz_only else '', '--ssh' if use_ssh else '', nodename)\n+ namespace = rospy.names.namespace(topic.name)\n+ nodename = os.path.basename(topic.name)\n+ namespace = 'echo_%s%s%s%s' % ('hz_' if show_hz_only else '', 'ssh_' if use_ssh else '', str(get_hostname(self.masteruri)), namespace)\n+ cmd = 'rosrun node_manager_fkie node_manager --echo %s %s %s %s __name:=%s __ns:=%s' % (topic.name, topic.type, '--hz' if show_hz_only else '', '--ssh' if use_ssh else '', nodename, namespace)\nrospy.loginfo(\"Echo topic: %s\" % cmd)\nps = SupervisedPopen(shlex.split(cmd), env=env, stderr=None, close_fds=True, object_id=topic.name, description='Echo topic: %s' % topic.name)\nps.finished.connect(self._topic_dialog_closed)\n",
        "org_msg": "node_manager_fkie: fixed the warning about illegal ROS name on open echo dialog",
        "sim_msg": "finish create new bidge",
        "sim_diff": "diff --git a/home.admin/config.scripts/blitz.subscriptions.py b/home.admin/config.scripts/blitz.subscriptions.py @@ -192,7 +192,7 @@ your RaspiBlitz behind TOR.\n# ask user for which RaspiBlitz service the bridge should be used\nchoices = []\nchoices.append( (\"REST\",\"LND REST API {0}\".format(\"--> ALREADY BRIDGED\" if lnd_rest_api else \"\")) )\n- choices.append( (\"GRPC\",\"LND GRPC API {0}\".format(\"--> ALREADY BRIDGED\" if lnd_grpc_api else \"\")) )\n+ choices.append( (\"GRPC\",\"LND gRPC API {0}\".format(\"--> ALREADY BRIDGED\" if lnd_grpc_api else \"\")) )\nchoices.append( (\"SELF\",\"Create a custom IP2TOR Bridge\") )\nd = Dialog(dialog=\"dialog\",autowidgetsize=True)\n@@ -246,10 +246,6 @@ your RaspiBlitz behind TOR.\ntime.sleep(3)\nsys.exit(1)\n- print(torAddress)\n- print(torPort)\n- sys.exit()\n-\n# run creating a new IP2TOR subscription\nos.system(\"clear\")\ncmd=\"python /home/admin/config.scripts/blitz.subscriptions.ip2tor.py create-ssh-dialog {0} {1} {2}\".format(\"RTL\",\"s7foqiwcstnxmlesfsjt7nlhwb2o6w44hc7glv474n7sbyckf76wn6id.onion\",\"80\")\n",
        "chatgpt_cot": "Refactor topic name handling in MasterViewProxy to improve readability and maintainability."
    },
    {
        "org_diff": "diff --git a/sc2/units.py b/sc2/units.py @@ -255,7 +255,8 @@ class Units(list):\n:param distance:\n:param position:\n\"\"\"\n- assert self, \"Units object is empty\"\n+ if not self:\n+ return self\nif isinstance(position, Unit):\ndistance_squared = distance ** 2\nreturn self.subgroup(\n@@ -281,7 +282,8 @@ class Units(list):\n:param distance:\n:param position:\n\"\"\"\n- assert self, \"Units object is empty\"\n+ if not self:\n+ return self\nif isinstance(position, Unit):\ndistance_squared = distance ** 2\nreturn self.subgroup(\n@@ -310,7 +312,8 @@ class Units(list):\n:param distance1:\n:param distance2:\n\"\"\"\n- assert self, \"Units object is empty\"\n+ if not self:\n+ return self\nif isinstance(position, Unit):\ndistance1_squared = distance1 ** 2\ndistance2_squared = distance2 ** 2\n@@ -339,7 +342,8 @@ class Units(list):\n:param position:\n:param n:\n\"\"\"\n- assert self, \"Units object is empty\"\n+ if not self:\n+ return self\nreturn self.subgroup(self._list_sorted_by_distance_to(position)[:n])\ndef furthest_n_units(self, position: Union[Unit, Point2, np.ndarray], n: int) -> Units:\n@@ -357,7 +361,8 @@ class Units(list):\n:param position:\n:param n:\n\"\"\"\n- assert self, \"Units object is empty\"\n+ if not self:\n+ return self\nreturn self.subgroup(self._list_sorted_by_distance_to(position)[-n:])\ndef in_distance_of_group(self, other_units: Units, distance: float) -> Units:\n",
        "org_msg": "Removing asserts for some Units filter functions",
        "sim_msg": "Added distances_indices_groups function.",
        "sim_diff": "diff --git a/pymatgen/analysis/chemenv/utils/coordination_geometry_utils.py b/pymatgen/analysis/chemenv/utils/coordination_geometry_utils.py @@ -700,7 +700,8 @@ class Plane(object):\ndef distances_indices_sorted(self, points):\n\"\"\"\nComputes the distances from the plane to each of the points. Positive distances are on the side of the\n- normal of the plane while negative distances are on the other side\n+ normal of the plane while negative distances are on the other side. Indices sorting the points from closest\n+ to furthest is also computed.\n:param points: Points for which distances are computed\n:return: Distances from the plane to the points (positive values on the side of the normal to the plane,\nnegative values on the other side), as well as indices of the points from closest to furthest.\n@@ -708,6 +709,31 @@ class Plane(object):\ndistances = [np.dot(self.normal_vector, pp) + self.d for pp in points]\nreturn distances, sorted(range(len(distances)), key=lambda k: np.abs(distances[k]))\n+ def distances_indices_groups(self, points, delta=None, delta_factor=0.05):\n+ \"\"\"\n+ Computes the distances from the plane to each of the points. Positive distances are on the side of the\n+ normal of the plane while negative distances are on the other side. Indices sorting the points from closest\n+ to furthest is also computed. Grouped indices are also given, for which indices of the distances that are\n+ separated by less than delta are grouped together. The delta parameter is either set explictly or taken as\n+ a fraction (using the delta_factor parameter) of the maximal point distance.\n+ :param points: Points for which distances are computed\n+ :param delta: Distance interval for which two points are considered in the same group.\n+ :param delta_factor: If delta is None, the distance interval is taken as delta_factor times the maximal\n+ point distance.\n+ :return: Distances from the plane to the points (positive values on the side of the normal to the plane,\n+ negative values on the other side), as well as indices of the points from closest to furthest and\n+ grouped indices of distances separated by less than delta.\n+ \"\"\"\n+ distances, indices = self.distances_indices_sorted(points=points)\n+ if delta is None:\n+ delta = delta_factor*np.abs(distances[indices[-1]])\n+ iends = [ii for ii, idist in enumerate(indices, start=1)\n+ if ii == len(distances) or (np.abs(distances[indices[ii]])-np.abs(distances[idist])>delta)]\n+ grouped_indices = [indices[iends[ii-1]:iend]\n+ if ii>0 else indices[:iend]\n+ for ii, iend in enumerate(iends)]\n+ return distances, indices, grouped_indices\n+\ndef projectionpoints(self, pps):\n\"\"\"\nProjects each points in the point list pps on plane and returns the list of projected points\n",
        "chatgpt_cot": "Fix compilation issue in sc2/units.py by adding a return statement in case of empty Units object."
    },
    {
        "org_diff": "diff --git a/docs_generate/text_files/introduction.rst b/docs_generate/text_files/introduction.rst @@ -22,12 +22,16 @@ A basic bot can be made by creating a new file `my_bot.py` and filling it with t\nimport sc2\nfrom sc2.bot_ai import BotAI\n+ from sc2.player import Bot, Computer\n+\nclass MyBot(BotAI):\nasync def on_step(self, iteration: int):\n- print(f\"This is my bot in iteration {iteration}!\"\n+ print(f\"This is my bot in iteration {iteration}!\")\nsc2.run_game(\n- sc2.maps.get(map), [Bot(Race.Zerg, MyBot()), Computer(Race.Zerg, Difficulty.Hard)], realtime=False\n+ sc2.maps.get(\"AcropolisLE\"),\n+ [Bot(sc2.Race.Zerg, MyBot()), Computer(sc2.Race.Zerg, sc2.Difficulty.Hard)],\n+ realtime=False,\n)\nYou can now run the file using command ``python my_bot.py`` or double clicking the file.\n",
        "org_msg": "Fix introduction example",
        "sim_msg": "deleted an oopsie",
        "sim_diff": "diff --git a/bot_manager.py b/bot_manager.py @@ -251,4 +251,4 @@ class BotManager:\ncompressor.write_is_eval(self.game_file, self.is_eval)\ndef create_file_name(self):\n- return os.path.join(self.game_name, + self.name + '-' + str(self.file_number) + '.bin')\n+ return os.path.join(self.game_name, self.name + '-' + str(self.file_number) + '.bin')\n",
        "chatgpt_cot": "\"Add new player and map in MyBot class, and fix print statement to resolve compilation issue in introduction.rst file.\""
    },
    {
        "org_diff": "diff --git a/sc2/game_info.py b/sc2/game_info.py @@ -65,10 +65,8 @@ class Ramp:\nreturn set() # HACK: makes this work for now\n# FIXME: please do\n- upper2 = sorted(list(self.upper), key=lambda x: x.distance_to_point2(self.bottom_center), reverse=True)\n- while len(upper2) > 2:\n- upper2.pop()\n- return set(upper2)\n+\n+ return set(sorted(list(self.upper), key=lambda x: x.distance_to_point2(self.bottom_center), reverse=True)[:2])\n@property_immutable_cache\ndef top_center(self) -> Point2:\n",
        "org_msg": "optimize upper2_for_ramp_wall\nusing slicing instead of a while loop",
        "sim_msg": "Fixed an oopsie I made",
        "sim_diff": "diff --git a/game_data_struct.py b/game_data_struct.py @@ -227,10 +227,10 @@ def rotate_game_tick_packet_boost_omitted(game_tick_packet):\ngame_tick_packet.gameball.Acceleration.Y = -1 * game_tick_packet.gameball.Acceleration.Y\n# ball touch data\n- game_tick_packet.gameball.Touch.sHitLocation.X = -1 * game_tick_packet.gameball.Touch.sHitLocation.X\n- game_tick_packet.gameball.Touch.sHitLocation.Y = -1 * game_tick_packet.gameball.Touch.sHitLocation.Y\n- game_tick_packet.gameball.Touch.sHitNormal.X = -1 * game_tick_packet.gameball.Touch.sHitNormal.X\n- game_tick_packet.gameball.Touch.sHitNormal.Y = -1 * game_tick_packet.gameball.Touch.sHitNormal.Y\n+ game_tick_packet.gameball.LatestTouch.sHitLocation.X = -1 * game_tick_packet.gameball.LatestTouch.sHitLocation.X\n+ game_tick_packet.gameball.LatestTouch.sHitLocation.Y = -1 * game_tick_packet.gameball.LatestTouch.sHitLocation.Y\n+ game_tick_packet.gameball.LatestTouch.sHitNormal.X = -1 * game_tick_packet.gameball.LatestTouch.sHitNormal.X\n+ game_tick_packet.gameball.LatestTouch.sHitNormal.Y = -1 * game_tick_packet.gameball.LatestTouch.sHitNormal.Y\n# Rotate Yaw 180 degrees is all that is necessary.\nball_yaw = game_tick_packet.gameball.Rotation.Yaw\n",
        "chatgpt_cot": "\"Refactor Ramp class to fix sorting issue in game_info.py\""
    },
    {
        "org_diff": "diff --git a/test/test_pickled_data.py b/test/test_pickled_data.py @@ -404,8 +404,8 @@ def test_bot_ai():\nassert_cost(AbilityId.MORPHTOBROODLORD_BROODLORD, Cost(300, 250))\nassert_cost(AbilityId.MORPHZERGLINGTOBANELING_BANELING, Cost(50, 25))\n- assert Cost(100, 50, 2 * Cost(50, 25))\n- assert Cost(100, 50, Cost(50, 25) * 2)\n+ assert Cost(100, 50) == 2 * Cost(50, 25)\n+ assert Cost(100, 50) == Cost(50, 25) * 2\nassert bot.calculate_supply_cost(UnitTypeId.BARRACKS) == 0\nassert bot.calculate_supply_cost(UnitTypeId.HATCHERY) == 0\n",
        "org_msg": "Fix cost test",
        "sim_msg": "[batch] remove check_cost loop\n* [batch] remove check_cost loop\nCan't use this anymore after we added local SSDs\n* delint",
        "sim_diff": "diff --git a/batch/batch/driver/main.py b/batch/batch/driver/main.py @@ -29,7 +29,6 @@ from ..batch_configuration import REFRESH_INTERVAL_IN_SECONDS, \\\nDEFAULT_NAMESPACE, BATCH_BUCKET_NAME, HAIL_SHA, HAIL_SHOULD_PROFILE, \\\nWORKER_LOGS_BUCKET_NAME, PROJECT\nfrom ..globals import HTTP_CLIENT_MAX_SIZE\n-from ..utils import cost_from_msec_mcpu\nfrom .instance_pool import InstancePool\nfrom .scheduler import Scheduler\n@@ -606,58 +605,6 @@ LOCK IN SHARE MODE;\nawait asyncio.sleep(10)\n-async def check_cost(db):\n- @transaction(db, read_only=True)\n- async def check(tx):\n- agg_job_resources = tx.execute_and_fetchall('''\n-SELECT *\n-FROM jobs\n-LEFT JOIN (\n- SELECT batch_id, job_id, SUM(`usage` * rate) AS cost\n- FROM aggregated_job_resources\n- INNER JOIN resources ON aggregated_job_resources.resource = resources.resource\n- GROUP BY batch_id, job_id\n- LOCK IN SHARE MODE) AS t\n-ON jobs.batch_id = t.batch_id AND jobs.job_id = t.job_id\n-LOCK IN SHARE MODE;\n-''')\n-\n- agg_batch_resources = tx.execute_and_fetchall('''\n-SELECT *\n-FROM batches\n-LEFT JOIN (\n- SELECT batch_id, SUM(`usage` * rate) AS cost\n- FROM aggregated_batch_resources\n- INNER JOIN resources ON aggregated_batch_resources.resource = resources.resource\n- GROUP BY batch_id\n- LOCK IN SHARE MODE) AS t\n-ON batches.id = t.batch_id\n-LOCK IN SHARE MODE;\n-''')\n-\n- def assert_cost_same(id, msec_mcpu, cost_resources):\n- cost_msec_mcpu = cost_from_msec_mcpu(msec_mcpu)\n- if cost_msec_mcpu is not None and cost_resources is not None:\n- if cost_msec_mcpu != 0:\n- assert abs(cost_resources - cost_msec_mcpu) / cost_msec_mcpu <= 0.001, \\\n- (id, cost_msec_mcpu, cost_resources)\n- else:\n- assert cost_resources == 0, (id, cost_msec_mcpu, cost_resources)\n-\n- async for record in agg_job_resources:\n- assert_cost_same((record['batch_id'], record['job_id']), record['msec_mcpu'], record['cost'])\n-\n- async for record in agg_batch_resources:\n- assert_cost_same(record['batch_id'], record['msec_mcpu'], record['cost'])\n-\n- while True:\n- try:\n- await check() # pylint: disable=no-value-for-parameter\n- except Exception:\n- log.exception('while checking cost')\n- await asyncio.sleep(10)\n-\n-\nasync def on_startup(app):\npool = concurrent.futures.ThreadPoolExecutor()\napp['blocking_pool'] = pool\n@@ -734,7 +681,6 @@ SELECT worker_type, worker_cores, worker_disk_size_gb,\n# asyncio.ensure_future(check_incremental_loop(db))\n# asyncio.ensure_future(check_resource_aggregation(db))\n- # asyncio.ensure_future(check_cost(db))\nasync def on_cleanup(app):\n",
        "chatgpt_cot": "Fix assertion errors and update test cases for bot AI. Updated cost calculations to ensure accurate supply cost calculations for different unit types."
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/launch_list_model.py b/node_manager_fkie/src/node_manager_fkie/launch_list_model.py @@ -589,7 +589,7 @@ class LaunchListModel(QStandardItemModel):\nself._current_path = grpc_join(surl, dir_path)\nelif self._current_path != path:\nself._current_path = path\n- self._add_path(self._current_path, PathItem.ROOT, 0, 0, '')\n+ self._add_path(self._current_path, PathItem.ROOT, 0, 0, 'loading...')\nnm.nmd().list_path_threaded(self._current_path, clear_cache)\nprint \"current_path_end\", self._current_path\n# else:\n",
        "org_msg": "node_manager_fkie: added 'loading...' text to root",
        "sim_msg": "add deserialize and serialize to ContentManager",
        "sim_diff": "diff --git a/source1/content_manager.py b/source1/content_manager.py @@ -54,6 +54,25 @@ class ContentManager(metaclass=SingletonMeta):\nself.sub_managers[root_path.stem] = sub_manager\nprint(f'Registered sub manager for {source_game_path.stem}')\n+ def deserialize(self, data: Dict[str, str]):\n+ for name, path in data.items():\n+ if path.endswith('.vpk'):\n+ sub_manager = VPKSubManager(Path(path))\n+ self.sub_managers[name] = sub_manager\n+ elif path.endswith('.txt'):\n+ sub_manager = Gameinfo(Path(path))\n+ self.sub_managers[name] = sub_manager\n+ elif path.endswith('.bps'):\n+ from .bsp.bsp_file import BSPFile, LumpTypes\n+ bsp = BSPFile(path)\n+ bsp.parse()\n+ pak_lump = bsp.get_lump(LumpTypes.LUMP_PAK)\n+ if pak_lump:\n+ self.sub_managers[name] = pak_lump\n+ else:\n+ sub_manager = NonSourceSubManager(Path(path))\n+ self.sub_managers[name] = sub_manager\n+\n@staticmethod\ndef is_source_mod(path: Path, second=False):\nif path.name == 'gameinfo.txt':\n@@ -88,3 +107,6 @@ class ContentManager(metaclass=SingletonMeta):\ndef find_material(self, filepath):\nreturn self.find_file(filepath, 'materials', extension='.vmt')\n+\n+ def serialize(self):\n+ return {name: str(sub_manager.filepath) for name, sub_manager in self.sub_managers.items()}\n",
        "chatgpt_cot": "Update LaunchListModel to display loading message when adding current path."
    },
    {
        "org_diff": "diff --git a/sc2/main.py b/sc2/main.py @@ -13,6 +13,7 @@ async def _play_game_human(client, realtime):\nif len(state.observation.player_result) > 0:\nresult = Result(min(state.observation.player_result, key=lambda p: p.player_id).result)\n+ await client.leave()\nawait client.quit()\nreturn result\n@@ -29,9 +30,10 @@ async def _play_game_ai(client, player_id, ai, realtime):\niteration = 0\nwhile True:\nstate = await client.observation()\n-\nif len(state.observation.player_result) > 0:\n+ print(\"OBSR\", state.observation.player_result)\nresult = Result(min(state.observation.player_result, key=lambda p: p.player_id).result)\n+ await client.leave()\nawait client.quit()\nreturn result\n@@ -44,7 +46,7 @@ async def _play_game_ai(client, player_id, ai, realtime):\nawait client.step()\niteration += 1\n-async def _get_run_game_fn(map_settings, players, realtime=False, observer=False, portconfig=None):\n+async def _host_game(map_settings, players, realtime=False, observer=False, portconfig=None):\nassert len(players) > 0, \"Can't create a game without players\"\nif observer:\n@@ -71,7 +73,7 @@ async def _get_run_game_fn(map_settings, players, realtime=False, observer=False\nelse:\nreturn await _play_game_ai(client, player_id, players[0].ai, realtime)\n-async def _get_join_game_fn(map_settings, players, realtime, portconfig):\n+async def _join_game(map_settings, players, realtime, portconfig):\nasync with SC2Process() as server:\nawait server.ping()\nclient = Client(server._ws)\n@@ -83,12 +85,12 @@ async def _get_join_game_fn(map_settings, players, realtime, portconfig):\nreturn await _play_game_ai(client, player_id, players[1].ai, realtime)\ndef run_game(*args, **kwargs):\n- if any(isinstance(p, (Human, Bot)) for p in args[1]):\n+ if sum(isinstance(p, (Human, Bot)) for p in args[1]) > 1:\nportconfig = Portconfig()\nresult = asyncio.get_event_loop().run_until_complete(asyncio.gather(\n- _get_run_game_fn(*args, **kwargs, portconfig=portconfig),\n- _get_join_game_fn(*args, kwargs.get(\"realtime\", False), portconfig)\n+ _host_game(*args, **kwargs, portconfig=portconfig),\n+ _join_game(*args, kwargs.get(\"realtime\", False), portconfig)\n))\nelse:\n- result = asyncio.get_event_loop().run_until_complete(_get_run_game_fn(*args))\n+ result = asyncio.get_event_loop().run_until_complete(_host_game(*args, **kwargs))\nprint(result)\n",
        "org_msg": "Fix singleplayer",
        "sim_msg": "CS fixes and minor changes from comments",
        "sim_diff": "diff --git a/mpf/modes/game/code/game.py b/mpf/modes/game/code/game.py -\"\"\"Contains the Game class which is the Machine Mode that actually runs and manages an the game in a pinball machine.\n+\"\"\"Contains the Game class which is the Machine Mode that actually runs and manages\n+the game in a pinball machine.\nNote that in the Mission Pinball Framework, a distinction is made between a\n*game* and a *machine*. A *game* refers to a game in progress, whereas a\n@@ -71,13 +72,12 @@ class Game(AsyncMode):\nwhile True:\n# Wait for end ball event to be set\nyield from self._end_ball_event.wait()\n- if self._end_ball_event.is_set():\nyield from self._end_ball()\nself._end_ball_event.clear()\n@asyncio.coroutine\ndef _start_game(self):\n- \"\"\"Start a new game\"\"\"\n+ \"\"\"Start a new game.\"\"\"\nself.debug_log(\"Game start\")\n@@ -185,8 +185,8 @@ class Game(AsyncMode):\nyield from self._award_extra_ball()\nreturn\n- if (self.player.ball == self.machine.config['game']['balls_per_game'] and\n- self.player.number == self.num_players):\n+ if (self.player.ball == self.machine.config['game'][\n+ 'balls_per_game'] and self.player.number == self.num_players):\nyield from self._end_game()\nelse:\nyield from self._end_player_turn()\n@@ -256,9 +256,12 @@ class Game(AsyncMode):\ndef mode_stop(self, **kwargs):\n\"\"\"Stop mode.\"\"\"\n+ del kwargs\n+\nfor mode in self.machine.modes:\nif mode.active and mode.is_game_mode:\n- raise AssertionError(\"Mode {} is not supposed to run outside of game.\".format(mode.name))\n+ raise AssertionError(\"Mode {} is not supposed to run outside of game.\"\n+ .format(mode.name))\nself.machine.game = None\n@asyncio.coroutine\n@@ -275,9 +278,10 @@ class Game(AsyncMode):\nself.debug_log(\"***************************************************\")\nself.debug_log(\"****************** BALL STARTING ******************\")\nself.debug_log(\"** **\")\n- self.debug_log(\"** Player: {} Ball: {} Score: {}\".format(\n- self.player.number, self.player.ball,\n- self.player.score).ljust(49) + '**')\n+ self.debug_log(\"** Player: {} Ball: {} Score: {}\".format(self.player.number,\n+ self.player.ball,\n+ self.player.score\n+ ).ljust(49) + '**')\nself.debug_log(\"** **\")\nself.debug_log(\"***************************************************\")\nself.debug_log(\"***************************************************\")\n@@ -480,7 +484,8 @@ class Game(AsyncMode):\nself.machine.events.post_queue('player_adding',\nplayer=player,\nnumber=player.number,\n- callback=partial(self._player_adding_complete, player=player))\n+ callback=partial(self._player_adding_complete,\n+ player=player))\n'''event: player_adding\ndesc: A new player is in the process of being added to this game. This is a queue\nevent, and the player won't actually be finished adding until the queue is cleared.\n@@ -548,7 +553,6 @@ class Game(AsyncMode):\nThese machine variables are updated at the end of each player's\nturn, and they persist on disk so they are restored the next time\nMPF starts up.\n-\n'''\nreturn True\n",
        "chatgpt_cot": "Refactor game functions, rename and add host/join game methods, improve readability and maintainability of the code in main.py."
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/scripts/remote_nm.py b/node_manager_fkie/scripts/remote_nm.py @@ -10,7 +10,7 @@ import roslib\nimport rospy\nfrom node_manager_daemon_fkie import screen\n-from node_manager_daemon_fkie.launcher import RESPAWN_SCRIPT\n+from node_manager_daemon_fkie.settings import RESPAWN_SCRIPT\ntry:\nimport node_manager_fkie as nm\nexcept:\n",
        "org_msg": "node_manager_fkie: fixed respawn script dependency",
        "sim_msg": "added option to jump from scr to po.  Just pass stocks spaced apart",
        "sim_diff": "diff --git a/gamestonk_terminal/screener/screener_controller.py b/gamestonk_terminal/screener/screener_controller.py @@ -14,6 +14,7 @@ from gamestonk_terminal.helper_funcs import (\n)\nfrom gamestonk_terminal.screener import finviz_view\nfrom gamestonk_terminal.screener import yahoo_finance_view\n+from gamestonk_terminal.portfolio_optimization import po_controller\nclass ScreenerController:\n@@ -34,6 +35,7 @@ class ScreenerController:\n\"performance\",\n\"technical\",\n\"signals\",\n+ \"po\",\n]\ndef __init__(self):\n@@ -69,6 +71,8 @@ class ScreenerController:\nprint(\"\")\nprint(\" signals view filter signals (e.g. -s top_gainers)\")\nprint(\"\")\n+ print(\" > po go to the portfolio optimization menu\")\n+ print(\"\")\n@staticmethod\ndef view_available_presets(other_args: List[str]):\n@@ -217,6 +221,9 @@ class ScreenerController:\n\"\"\"Process signals command\"\"\"\nfinviz_view.view_signals(other_args)\n+ def call_po(self, other_args: List[str]):\n+ return po_controller.menu(other_args)\n+\ndef menu():\n\"\"\"Screener Menu\"\"\"\n",
        "chatgpt_cot": "Update import statement in remote_nm.py to use RESPAWN_SCRIPT from settings instead of launcher for consistency and clarity."
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/launch_files_widget.py b/node_manager_fkie/src/node_manager_fkie/launch_files_widget.py @@ -190,6 +190,12 @@ class LaunchFilesWidget(QDockWidget):\nself.loadXmlButton.setEnabled(False)\nself.transferButton.setEnabled(False)\nself.loadXmlAsDefaultButton.setEnabled(False)\n+ try:\n+ from roslaunch import substitution_args\n+ import rospkg\n+ substitution_args._rospack = rospkg.RosPack()\n+ except Exception as err:\n+ rospy.logwarn(\"Cannot reset package cache: %s\" % utf8(err))\ndef on_edit_xml_clicked(self):\n'''\n",
        "org_msg": "node_manager_fkie: reset package cache on reload in lauch widget\nso you don't need to restart node_manager if new packages are added at\nruntime",
        "sim_msg": "Minor improvement on cbloader, pass representation['data']",
        "sim_diff": "diff --git a/avalon/tools/cbloader/widgets.py b/avalon/tools/cbloader/widgets.py @@ -197,8 +197,11 @@ class SubsetWidget(QtWidgets.QWidget):\n))\ncontinue\n+ data = representation.get(\"data\", None)\ntry:\n- api.load(Loader=loader, representation=representation)\n+ api.load(Loader=loader,\n+ representation=representation,\n+ data=data)\nexcept pipeline.IncompatibleLoaderError as exc:\nself.echo(exc)\ncontinue\n",
        "chatgpt_cot": "Add try-except block to handle package cache reset failure in LaunchFilesWidget. This modification ensures robustness in handling exceptions during package cache reset."
    },
    {
        "org_diff": "diff --git a/node_manager_daemon_fkie/src/node_manager_daemon_fkie/settings.py b/node_manager_daemon_fkie/src/node_manager_daemon_fkie/settings.py @@ -148,6 +148,7 @@ class Settings:\npath = os.path.dirname(param_name).split('/')\nval_tag = tag if tag else ':value'\ncfg_item = self._cfg\n+ changed = False\nfor item in path:\nif item:\nif item in cfg_item:\n@@ -155,18 +156,23 @@ class Settings:\nelse:\ncfg_item[item] = {}\ncfg_item = cfg_item[item]\n+ changed = True\npname = os.path.basename(param_name)\nif pname in cfg_item:\nif isinstance(cfg_item[pname], dict):\nif self._is_writable(cfg_item[pname]):\n+ changed = cfg_item[pname][val_tag] != value\ncfg_item[pname][val_tag] = value\nelse:\nraise Exception('%s is a read only parameter!' % param_name)\nelse:\n+ changed = cfg_item[pname] != value\ncfg_item[pname] = value\nelse:\n# create new parameter entry\ncfg_item[pname] = {val_tag: value}\n+ changed = True\n+ if changed:\nself.save()\nexcept Exception as exc:\nrospy.logdebug(\"Cant't set parameter '%s', full parameter path: '%s'\" % (utf8(exc), param_name))\n",
        "org_msg": "node_manager_daemon_fkie: save parameter only if something was changed",
        "sim_msg": "make parameter values use fuzzy dict error",
        "sim_diff": "diff --git a/pybamm/parameters/parameter_values.py b/pybamm/parameters/parameter_values.py @@ -165,15 +165,17 @@ class ParameterValues:\n)\n)\n# check parameter already exists (for updating parameters)\n- if check_already_exists is True and name not in self.items.keys():\n+ if check_already_exists is True:\n+ try:\n+ self.items[name]\n+ except KeyError as err:\nraise KeyError(\n- \"\"\"cannot update parameter '{}' as it does not have a default value\n- \"\"\".format(\n- name\n+ \"cannot update parameter '{}' \".format(name)\n+ + \"as it does not have a default value. ({})\".format(\n+ err.args[0]\n)\n)\n# if no conflicts, update, loading functions and data if they are specified\n- else:\n# Functions are flagged with the string \"[function]\"\nif isinstance(value, str):\nif value.startswith(\"[function]\"):\n@@ -183,9 +185,7 @@ class ParameterValues:\nself.items[name] = loaded_value\nvalues[name] = loaded_value\n# Data is flagged with the string \"[data]\" or \"[current data]\"\n- elif value.startswith(\"[current data]\") or value.startswith(\n- \"[data]\"\n- ):\n+ elif value.startswith(\"[current data]\") or value.startswith(\"[data]\"):\nif value.startswith(\"[current data]\"):\ndata_path = os.path.join(\npybamm.root_dir(), \"input\", \"drive_cycles\"\n",
        "chatgpt_cot": "\"Add logic to track changes in settings to fix saving issue.\""
    },
    {
        "org_diff": "diff --git a/src/dashboard/src/pages/Operator/Channel/Channel.js b/src/dashboard/src/pages/Operator/Channel/Channel.js @@ -542,10 +542,6 @@ class Channel extends PureComponent {\n<a onClick={() => this.handleDownloadConfig(record)}>\n{intl.formatMessage({ id: 'form.menu.item.download', defaultMessage: 'Download' })}\n</a>\n- <Divider type=\"vertical\" />\n- <a className={styles.danger}>\n- {intl.formatMessage({ id: 'form.menu.item.delete', defaultMessage: 'Delete' })}\n- </a>\n</Fragment>\n),\n},\n",
        "org_msg": "Remove Delete Btn on Channel Page\nChannel page has a button to delete one channel. But we are going\nto implement this feature in the next release. So remove the frontend\nbutton for now.",
        "sim_msg": "Add Edit Channel Panel Logic fix",
        "sim_diff": "diff --git a/static/js/userchannelsv2.js b/static/js/userchannelsv2.js @@ -997,7 +997,7 @@ function editChannelPanel(panelId, channelId) {\ndocument.getElementById('panel_modal_header').value = document.getElementById('channelPanel-header-' + panelId).innerHTML;\ndocument.getElementById('panel_modal_type').value = document.getElementById('channelPanel-typeId-' + panelId).innerHTML;\ndocument.getElementById('panel_modal_order').value = document.getElementById('channelPanel-orderId-' + panelId).innerHTML;\n- document.getElementById('panel_modal_content').value = document.getElementById('bannelPanel-content-' + panelId).innerHTML;\n+ document.getElementById('panel_modal_content').value = document.getElementById('channelPanel-content-' + panelId).innerHTML;\neasymde_panel_editor.value = document.getElementById('channelPanel-content-' + panelId).innerHTML;\nvar doc = easymde_panel_editor.codemirror.getDoc();\ndoc.setValue(easymde_panel_editor.value);\n",
        "chatgpt_cot": "\"Remove delete button from Channel page to prevent accidental deletion\""
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/main_window.py b/node_manager_fkie/src/node_manager_fkie/main_window.py @@ -1279,13 +1279,13 @@ class MainWindow(QMainWindow):\nif self.__current_master_label_name != name:\nself.__current_master_label_name = name\nshow_name = name if nm.settings().show_domain_suffix else subdomain(name)\n- self.masternameLabel.setText('<span style=\" font-size:14pt; font-weight:600;\">%s</span>' % show_name)\n+ self.masternameLabel.setText('<span style=\" font-size:14pt; font-weight:600; color:black\">%s</span>' % show_name)\ncolor = QColor.fromRgb(nm.settings().host_color(self.__current_master_label_name, self._default_color.rgb()))\nself._new_color(color)\nts = 'updated: %s' % utf8(timestamp) if timestamp is not None else ''\nif not nm.settings().autoupdate:\nts = '%s<span style=\" color:orange;\"> AU off</span>' % ts\n- self.masterInfoLabel.setText('<span style=\" font-size:8pt;\">%s%s</span>' % (con_err, ts))\n+ self.masterInfoLabel.setText('<span style=\" font-size:8pt; color:black\">%s%s</span>' % (con_err, ts))\n# load the robot image, if one exists\nif self.masternameLabel.isEnabled():\n",
        "org_msg": "node_manager_fkie: set fixed title color",
        "sim_msg": "store whole parent document instead of just id and name in project manager",
        "sim_diff": "diff --git a/avalon/tools/projectmanager/dialogs.py b/avalon/tools/projectmanager/dialogs.py @@ -62,8 +62,7 @@ class AssetCreateDialog(QtWidgets.QDialog):\nself.setWindowTitle(\"Add asset\")\nself.is_silo_required = is_silo_required\n- self.parent_id = None\n- self.parent_name = \"\"\n+ self.parent_doc = None\n# Label\nlabel_label = QtWidgets.QLabel(\"Label:\")\n@@ -136,18 +135,16 @@ class AssetCreateDialog(QtWidgets.QDialog):\ndef set_parent(self, parent_id):\n# Get the parent asset (if any provided)\n- parent_name = \"\"\nif parent_id:\n- parent_asset = io.find_one({\"_id\": parent_id, \"type\": \"asset\"})\n- assert parent_asset, \"Parent asset does not exist.\"\n- parent_name = parent_asset[\"name\"]\n+ parent_doc = io.find_one({\"_id\": parent_id, \"type\": \"asset\"})\n+ assert parent_doc, \"Parent asset does not exist.\"\n+ parent_name = parent_doc[\"name\"]\n- self.parent_name = parent_name\n- self.parent_id = parent_id\n+ self.parent_doc = parent_doc\nelse:\n# Clear the parent\n- self.parent_name = \"\"\n- self.parent_id = None\n+ parent_name = \"\"\n+ self.parent_doc = None\nself.data[\"label\"][\"parent\"].setText(parent_name)\n@@ -163,14 +160,18 @@ class AssetCreateDialog(QtWidgets.QDialog):\nname = label\n# Prefix with parent name (if parent)\n- if self.parent_name:\n- name = self.parent_name + \"_\" + name\n+ if self.parent_doc:\n+ name = \"_\".join((self.parent_doc[\"name\"], name))\nself.data[\"label\"][\"name\"].setText(name)\ndef on_add_asset(self):\n- parent_id = self.parent_id\n+ if self.parent_doc:\n+ parent_id = self.parent_doc[\"_id\"]\n+ else:\n+ parent_id = None\n+\nname = self.data[\"label\"][\"name\"].text()\nlabel = self.data[\"label\"][\"label\"].text()\n",
        "chatgpt_cot": "Fix color and font size for masternameLabel and masterInfoLabel in MainWindow to improve readability and user experience."
    },
    {
        "org_diff": "diff --git a/sc2/client.py b/sc2/client.py from __future__ import annotations\n-from typing import Any, Dict, Iterable, List, Optional, Set, Tuple, Union, TYPE_CHECKING\n+from typing import Dict, Iterable, List, Optional, Set, Tuple, Union\nfrom s2clientprotocol import debug_pb2 as debug_pb\nfrom s2clientprotocol import query_pb2 as query_pb\n@@ -474,7 +474,9 @@ class Client(Protocol):\nTo grab a unit's 3d position, use unit.position3d\nUsually the Z value of a Point3 is between 8 and 14 (except for flying units). Use self.get_terrain_z_height() from bot_ai.py to get the Z value (height) of the terrain at a 2D position.\n\"\"\"\n- if isinstance(pos, Point2) and not isinstance(pos, Point3): # a Point3 is also a Point2\n+ if isinstance(pos, Unit):\n+ pos = pos.position3d\n+ elif not isinstance(pos, Point3):\npos = Point3((pos.x, pos.y, 0))\nself._debug_texts.append(DrawItemWorldText(text=text, color=color, start_point=pos, font_size=size))\n@@ -486,6 +488,14 @@ class Client(Protocol):\ndef debug_line_out(\nself, p0: Union[Unit, Point2, Point3], p1: Union[Unit, Point2, Point3], color: Union[tuple, list, Point3] = None\n):\n+ if isinstance(p0, Unit):\n+ p0 = p0.position3d\n+ elif not isinstance(p0, Point3):\n+ p0 = Point3((p0.x, p0.y, 0))\n+ if isinstance(p1, Unit):\n+ p1 = p1.position3d\n+ elif not isinstance(p1, Point3):\n+ p1 = Point3((p1.x, p1.y, 0))\n\"\"\" Draws a line from p0 to p1. \"\"\"\nself._debug_lines.append(DrawItemLine(color=color, start_point=p0, end_point=p1))\n@@ -496,6 +506,14 @@ class Client(Protocol):\ncolor: Union[tuple, list, Point3] = None,\n):\n\"\"\" Draws a box with p_min and p_max as corners of the box. \"\"\"\n+ if isinstance(p_min, Unit):\n+ p_min = p_min.position3d\n+ elif not isinstance(p_min, Point3):\n+ p_min = Point3((p_min.x, p_min.y, 0))\n+ if isinstance(p_max, Unit):\n+ p_max = p_max.position3d\n+ elif not isinstance(p_max, Point3):\n+ p_max = Point3((p_max.x, p_max.y, 0))\nself._debug_boxes.append(DrawItemBox(start_point=p_min, end_point=p_max, color=color))\ndef debug_box2_out(\n@@ -517,6 +535,10 @@ class Client(Protocol):\nself, p: Union[Unit, Point2, Point3], r: Union[int, float], color: Union[tuple, list, Point3] = None\n):\n\"\"\" Draws a sphere at point p with radius r. \"\"\"\n+ if isinstance(p, Unit):\n+ p = p.position3d\n+ elif not isinstance(p, Point3):\n+ p = Point3((p.x, p.y, 0))\nself._debug_spheres.append(DrawItemSphere(start_point=p, radius=r, color=color))\nasync def _send_debug(self):\n",
        "org_msg": "Fix and other debug draw functions that accept Unit or Point2 as argument",
        "sim_msg": "Provide draw function access to box properties",
        "sim_diff": "diff --git a/gaphor/diagram/actions/action.py b/gaphor/diagram/actions/action.py @@ -34,7 +34,7 @@ class Box:\ndef draw(self, cr, bounding_box):\nif self._draw:\n- self._draw(cr, bounding_box)\n+ self._draw(self, cr, bounding_box)\nfor c in self.children:\nc.draw(cr, bounding_box)\n@@ -66,16 +66,20 @@ class ActionItem(ElementPresentation):\nCreate action item.\n\"\"\"\nsuper().__init__(id, model)\n- self._name = Name(self)\nself.layout = Box(\n- self._name,\n- style={\"min-width\": 50, \"min-height\": 30, \"padding\": (5, 10, 5, 10)},\n+ Name(self),\n+ style={\n+ \"min-width\": 50,\n+ \"min-height\": 30,\n+ \"padding\": (5, 10, 5, 10),\n+ \"border-radius\": 15,\n+ },\ndraw=self.draw_border,\n)\n- def draw_border(self, cr, bounding_box):\n- d = 15\n+ def draw_border(self, box, cr, bounding_box):\n+ d = box.style(\"border-radius\")\nx, y, width, height = bounding_box\nwidth += x\nheight += y\n@@ -99,15 +103,14 @@ class SendSignalActionItem(ElementPresentation):\nCreate action item.\n\"\"\"\nsuper().__init__(id, model)\n- self._name = Name(self)\nself.layout = Box(\n- self._name,\n+ Name(self),\nstyle={\"min-width\": 50, \"min-height\": 30, \"padding\": (5, 25, 5, 10)},\ndraw=self.draw_border,\n)\n- def draw_border(self, cr, bounding_box):\n+ def draw_border(self, box, cr, bounding_box):\nd = 15\nx, y, width, height = bounding_box\ncr.move_to(0, 0)\n@@ -127,15 +130,14 @@ class AcceptEventActionItem(ElementPresentation):\nCreate action item.\n\"\"\"\nsuper().__init__(id, model)\n- self._name = Name(self)\nself.layout = Box(\n- self._name,\n+ Name(self),\nstyle={\"min-width\": 50, \"min-height\": 30, \"padding\": (5, 10, 5, 25)},\ndraw=self.draw_border,\n)\n- def draw_border(self, cr, bounding_box):\n+ def draw_border(self, box, cr, bounding_box):\nd = 15\nx, y, width, height = bounding_box\ncr.move_to(0, 0)\n",
        "chatgpt_cot": "\"Fix compilation issue due to missing import and type mismatch in client.py.\""
    },
    {
        "org_diff": "diff --git a/src/agent/fabric-operator/README.md b/src/agent/fabric-operator/README.md @@ -9,6 +9,7 @@ fabric CA, Orderer and Peer node using kubectl\n- [kubectl][kubectl_tool] v1.11.3+\n- Access to a Kubernetes v1.11.3+ cluster\n+- A PersistentVolume storage location for each ca, peer, and orderer.\n## Getting Started\n",
        "org_msg": "Update README.md\nFixes Added documentation of PersistentVolume",
        "sim_msg": "generate docs [e2e-skip]",
        "sim_diff": "diff --git a/docs/api.rst b/docs/api.rst @@ -84,13 +84,13 @@ MesosNode\n=========\n.. code-block::\n- MesosNode(mesos_agent_endpoint:<function Url at 0x7f607afcf8c8>='https://127.0.0.1:5051', timeout:wca.config.Numeric=5.0, ssl:Union[wca.security.SSL, NoneType]=None)\n+ MesosNode(mesos_agent_endpoint:<function Url at 0x7fedd0f7d8c8>='https://127.0.0.1:5051', timeout:wca.config.Numeric=5.0, ssl:Union[wca.security.SSL, NoneType]=None)\nKubernetesNode\n==============\n.. code-block::\n- KubernetesNode(cgroup_driver:wca.kubernetes.CgroupDriverType=<CgroupDriverType.CGROUPFS: 'cgroupfs'>, ssl:Union[wca.security.SSL, NoneType]=None, client_token_path:Union[wca.config.Path, NoneType]='/var/run/secrets/kubernetes.io/serviceaccount/token', server_cert_ca_path:Union[wca.config.Path, NoneType]='/var/run/secrets/kubernetes.io/serviceaccount/ca.crt', kubelet_enabled:bool=False, kubelet_endpoint:<function Url at 0x7f607afcf8c8>='https://127.0.0.1:10250', kubeapi_host:<function Str at 0x7f607afcf6a8>=None, kubeapi_port:<function Str at 0x7f607afcf6a8>=None, node_ip:<function Str at 0x7f607afcf6a8>=None, timeout:wca.config.Numeric=5, monitored_namespaces:List[Str]=<factory>)\n+ KubernetesNode(cgroup_driver:wca.kubernetes.CgroupDriverType=<CgroupDriverType.CGROUPFS: 'cgroupfs'>, ssl:Union[wca.security.SSL, NoneType]=None, client_token_path:Union[wca.config.Path, NoneType]='/var/run/secrets/kubernetes.io/serviceaccount/token', server_cert_ca_path:Union[wca.config.Path, NoneType]='/var/run/secrets/kubernetes.io/serviceaccount/ca.crt', kubelet_enabled:bool=False, kubelet_endpoint:<function Url at 0x7fedd0f7d8c8>='https://127.0.0.1:10250', kubeapi_host:<function Str at 0x7fedd0f7d6a8>=None, kubeapi_port:<function Str at 0x7fedd0f7d6a8>=None, node_ip:<function Str at 0x7fedd0f7d6a8>=None, timeout:wca.config.Numeric=5, monitored_namespaces:List[Str]=<factory>)\nLogStorage\n==========\n@@ -139,7 +139,7 @@ AllocationConfiguration\n=======================\n.. code-block::\n- AllocationConfiguration(cpu_quota_period:wca.config.Numeric=1000, cpu_shares_unit:wca.config.Numeric=1000, default_rdt_l3:<function Str at 0x7f607afcf6a8>=None, default_rdt_mb:<function Str at 0x7f607afcf6a8>=None)\n+ AllocationConfiguration(cpu_quota_period:wca.config.Numeric=1000, cpu_shares_unit:wca.config.Numeric=1000, default_rdt_l3:<function Str at 0x7fedd0f7d6a8>=None, default_rdt_mb:<function Str at 0x7fedd0f7d6a8>=None)\nCgroupDriverType\n================\n",
        "chatgpt_cot": "Add PersistentVolume storage location requirement for fabric CA, Orderer, and Peer nodes using kubectl."
    },
    {
        "org_diff": "diff --git a/sc2/pixel_map.py b/sc2/pixel_map.py from typing import Callable, FrozenSet, List, Set\n+import numpy as np\n+\nfrom .position import Point2\n@@ -8,7 +10,9 @@ class PixelMap:\nself._proto = proto\nassert self.bits_per_pixel % 8 == 0, \"Unsupported pixel density\"\nassert self.width * self.height * self.bits_per_pixel / 8 == len(self._proto.data)\n- self.data = bytearray(self._proto.data)\n+ self.data_numpy = np.array(np.frombuffer(proto.data, dtype=np.uint8)).reshape(proto.size.y, proto.size.x)[\n+ ::-1, :\n+ ]\n@property\ndef width(self):\n@@ -27,27 +31,16 @@ class PixelMap:\nreturn self._proto.bits_per_pixel // 8\ndef __getitem__(self, pos):\n- x, y = pos\n-\n- assert 0 <= x <= self.width, f\"x is {x}, self.width is {self.width}\"\n- assert 0 <= y <= self.height, f\"y is {y}, self.height is {self.height}\"\n-\n- index = -self.width * y + x\n- # print(f\"INDEX IS {index} FOR {pos}\")\n- start = index * self.bytes_per_pixel\n- data = self.data[start : start + self.bytes_per_pixel]\n- return int.from_bytes(data, byteorder=\"little\", signed=False)\n-\n- def __setitem__(self, pos, val):\n- \"\"\" Example usage: self._game_info.pathing_grid[Point2((20, 20))] = [255] \"\"\"\n- x, y = pos\n-\n- assert 0 <= x <= self.width, f\"x is {x}, self.width is {self.width}\"\n- assert 0 <= y <= self.height, f\"y is {y}, self.height is {self.height}\"\n-\n- index = -self.width * y + x\n- start = index * self.bytes_per_pixel\n- self.data[start : start + self.bytes_per_pixel] = val\n+ assert 0 <= pos[0] < self.width, f\"x is {pos[0]}, self.width is {self.width}\"\n+ assert 0 <= pos[1] < self.height, f\"y is {pos[1]}, self.height is {self.height}\"\n+ return int(self.data_numpy[pos[1] - 1, pos[0]])\n+\n+ def __setitem__(self, pos, value):\n+ assert 0 <= pos[0] < self.width, f\"x is {pos[0]}, self.width is {self.width}\"\n+ assert 0 <= pos[1] < self.height, f\"y is {pos[1]}, self.height is {self.height}\"\n+ assert 0 <= value < 256, f\"value is {value}, it should be between 0 and 255\"\n+ assert isinstance(value, int), f\"value is of type {type(value)}, it should be an integer\"\n+ self.data_numpy[pos[1] - 1, pos[0]] = value\ndef is_set(self, p):\nreturn self[p] != 0\n",
        "org_msg": "Numpy entered the room.",
        "sim_msg": "fixes not finding 4 in a row in last column\n* fixes not finding 4 in a row in last column\nit was checking only 6 wide (height) not 7 wide (width) when looking for a 4 in a row from top-left to bottom-right\n* refactor diagonals code",
        "sim_diff": "diff --git a/connect4/core.py b/connect4/core.py @@ -15,10 +15,10 @@ class Board(list):\ndef __getitem__(self, pos: Union[int, tuple]):\nif isinstance(pos, int):\n- return list(self)[pos]\n+ return super().__getitem__(pos)\nelif isinstance(pos, tuple):\nx, y = pos\n- return list(self)[x][y]\n+ return super().__getitem__(x)[y]\nelse:\nraise TypeError(\"pos must be an int or tuple\")\n@@ -49,28 +49,21 @@ class Board(list):\nreturn y\nraise ValueError(\"that column is full\")\n+ def _position_check(self, x: int, y: int) -> bool:\n+ \"\"\"Checks if the given position is in the board\"\"\"\n+ return x >= 0 and y >= 0 and x < self.width and y < self.height\n+\ndef _pos_diagonals(self):\n\"\"\"Get positive diagonals, going from bottom-left to top-right.\"\"\"\n- for di in (\n- [(j, i - j) for j in range(self.width)] for i in range(self.width + self.height - 1)\n- ):\n- yield [\n- self[i, j]\n- for i, j in di\n- if i >= 0 and j >= 0 and i < self.width and j < self.height\n- ]\n+ for y in range(self.width + self.height - 1):\n+ diagonal = [(x, y - x) for x in range(self.width)]\n+ yield [self[i, j] for i, j in diagonal if self._position_check(i, j)]\ndef _neg_diagonals(self):\n\"\"\"Get negative diagonals, going from top-left to bottom-right.\"\"\"\n- for di in (\n- [(j, i - self.width + j + 1) for j in range(self.height)]\n- for i in range(self.width + self.height - 1)\n- ):\n- yield [\n- self[i, j]\n- for i, j in di\n- if i >= 0 and j >= 0 and i < self.width and j < self.height\n- ]\n+ for y in range(self.width + self.height - 1):\n+ diagonal = [(x, y - self.width + x + 1) for x in range(self.width)]\n+ yield [self[i, j] for i, j in diagonal if self._position_check(i, j)]\ndef _full(self):\n\"\"\"is there a move in every position?\"\"\"\n",
        "chatgpt_cot": "Add numpy library to PixelMap.py to optimize array manipulation and add array slicing to improve read and write operations."
    },
    {
        "org_diff": "diff --git a/sc2/bot_ai.py b/sc2/bot_ai.py @@ -628,7 +628,7 @@ class BotAI(DistanceCalculation):\n:param check_supply_cost: \"\"\"\nenough_supply = True\ncost = self.calculate_cost(item_id)\n- if not cost.minerals > self.minerals or cost.vespene > self.vespene:\n+ if cost.minerals > self.minerals or cost.vespene > self.vespene:\nreturn False\nif (\ncheck_supply_cost\n",
        "org_msg": "Remove wrong not",
        "sim_msg": "Ensure that a StockItem is not already allocated to a Build",
        "sim_diff": "diff --git a/InvenTree/build/models.py b/InvenTree/build/models.py @@ -137,6 +137,12 @@ class Build(models.Model):\nif len(stock) == 1:\nstock_item = stock[0]\n+ # Check that we have not already allocated this stock-item against this build\n+ build_items = BuildItem.objects.filter(build=self, stock_item=stock_item)\n+\n+ if len(build_items) > 0:\n+ continue\n+\n# Are there any parts available?\nif stock_item.quantity > 0:\n# Only take as many as are available\n",
        "chatgpt_cot": "Fix condition logic in BotAI class to check if there is enough supply cost before proceeding."
    },
    {
        "org_diff": "diff --git a/fkie_node_manager/src/fkie_node_manager/master_view_proxy.py b/fkie_node_manager/src/fkie_node_manager/master_view_proxy.py @@ -1131,7 +1131,7 @@ class MasterViewProxy(QWidget):\nself.host_description_updated.emit(masteruri, robot_addr, tooltip)\nnode_cfgs = dict()\nfor n in ld.nodes:\n- if n not in alredy_added_nodes:\n+ # if n not in alredy_added_nodes:\nnode_cfgs[n] = ld.path\nself.node_tree_model.append_config(masteruri, host_addr, node_cfgs)\n# set the robot_icon\n",
        "org_msg": "fkie_node_manager: fix for visualization of nodes with and without capability groups",
        "sim_msg": "do not require perf_event cgroup enabled for StaticNode",
        "sim_diff": "diff --git a/wca/extra/static_node.py b/wca/extra/static_node.py @@ -45,7 +45,8 @@ class StaticNode(Node):\ntasks_labels: Optional[Dict[str, Dict[str, str]]] = None\n_BASE_CGROUP_PATH = '/sys/fs/cgroup'\n- _REQUIRED_CONTROLLERS = ('cpu', 'cpuacct', 'perf_event')\n+ _REQUIRED_CONTROLLERS = ('cpu', 'cpuacct')\n+ #, 'perf_event')\ndef get_tasks(self) -> List[Task]:\ntasks = []\n",
        "chatgpt_cot": "\"Comment out unnecessary if condition to fix logic error in MasterViewProxy\""
    },
    {
        "org_diff": "diff --git a/examples/worker_rush.py b/examples/worker_rush.py @@ -5,12 +5,12 @@ from sc2.player import Bot, Computer\nclass WorkerRushBot(sc2.BotAI):\nasync def on_step(self, state, iteration):\nif iteration == 0:\n- for probe in self.workers:\n- await self.do(probe.attack(self.enemy_start_locations[0]))\n+ for worker in self.workers:\n+ await self.do(worker.attack(self.enemy_start_locations[0]))\ndef main():\nrun_game(maps.get(\"Abyssal Reef LE\"), [\n- Bot(Race.Protoss, WorkerRushBot()),\n+ Bot(Race.Zerg, WorkerRushBot()),\nComputer(Race.Protoss, Difficulty.Medium)\n], realtime=True)\n",
        "org_msg": "Use generic names in the worker rush example",
        "sim_msg": "fix raid actions",
        "sim_diff": "diff --git a/GearBot/Util/RaidHandling/RaidActions.py b/GearBot/Util/RaidHandling/RaidActions.py @@ -106,7 +106,7 @@ class Mute(RaidAction):\nclass Kick(RaidAction):\nasync def execute(self, bot, member, data, raid_id, raider_ids, shield):\n- await self.bot.redis_pool.psetex(f\"forced_exits:{member.guild.id}-{member.id}\", 8000, 1)\n+ await bot.redis_pool.psetex(f\"forced_exits:{member.guild.id}-{member.id}\", 8000, 1)\nreason = f\"Raider kicked by raid shield {shield['name']} in raid {raid_id}\"\ntry:\nawait member.kick(reason=reason)\n@@ -137,7 +137,7 @@ class Kick(RaidAction):\nclass Ban(RaidAction):\nasync def execute(self, bot, member, data, raid_id, raider_ids, shield):\n- await self.bot.redis_pool.psetex(f\"forced_exits:{member.guild.id}-{member.id}\", 8000, 1)\n+ await bot.redis_pool.psetex(f\"forced_exits:{member.guild.id}-{member.id}\", 8000, 1)\nreason = f\"Raider banned by raid shield {shield['name']} in raid {raid_id}\"\ntry:\nawait member.ban(reason=reason,\n@@ -200,7 +200,6 @@ class LowerShield(RaidAction):\nclass SendDash(RaidAction):\nasync def execute(self, bot, guild, data, raid_id, raider_ids, shield):\n- cog = bot.get_cog(\"AntiRaid\")\npass\n@property\n",
        "chatgpt_cot": "Fix worker attack method and change player race to Zerg in WorkerRushBot file."
    },
    {
        "org_diff": "diff --git a/sc2/unit.py b/sc2/unit.py @@ -511,9 +511,11 @@ class Unit(PassengerUnit):\n\"\"\" Checks if unit is idle. \"\"\"\nreturn not self.orders\n- def is_using_ability(self, ability: AbilityId) -> bool:\n- \"\"\" Check if the unit is using the given ability. \"\"\"\n- return bool(self.orders) and self.orders[0].ability.id is ability\n+ def is_using_ability(self, abilities: Union[AbilityId, Set[AbilityId]]) -> bool:\n+ \"\"\" Check if the unit is using one of the given abilities. \"\"\"\n+ if isinstance(abilities, AbilityId):\n+ abilities = {abilities}\n+ return bool(self.orders) and self.orders[0].ability.id in abilities\n@property_immutable_cache\ndef is_moving(self) -> bool:\n",
        "org_msg": "Allow passing a set of abilities to is_using_ability",
        "sim_msg": "Everything seems to be working now",
        "sim_diff": "diff --git a/syft/syft.py b/syft/syft.py @@ -132,7 +132,9 @@ class FloatTensor():\nreturn []\ndef dataOnGpu(self):\n- return self.get(\"dataOnGpu\")\n+ if(self.get(\"dataOnGpu\") == \"1\"):\n+ return True\n+ return False\ndef __truediv__(self, x):\nreturn self.arithmetic_operation(x, \"div\", False)\n",
        "chatgpt_cot": "\"Modify is_using_ability method to accept multiple abilities for checking, fixing the issue with checking multiple abilities.\""
    },
    {
        "org_diff": "diff --git a/fkie_node_manager/src/fkie_node_manager/name_resolution.py b/fkie_node_manager/src/fkie_node_manager/name_resolution.py @@ -123,7 +123,7 @@ class MasterEntry(object):\nfor addr in ipaddrlist:\nif not self.has_address(addr):\nself._addresses.append(addr)\n- except socket.gaierror:\n+ except Exception:\n# no suitable address found\npass\n@@ -137,7 +137,7 @@ class MasterEntry(object):\nself._addresses.insert(0, hostname)\nif not self.has_address(name_splitted[0]):\nself._addresses.insert(0, name_splitted[0])\n- except socket.gaierror:\n+ except Exception:\n# no suitable address found\npass\n",
        "org_msg": "fkie_node_manager: changed exception handling in name resolution",
        "sim_msg": "remove unneeded if statement in getPeersForBlob",
        "sim_diff": "diff --git a/lbrynet/dht/node.py b/lbrynet/dht/node.py @@ -220,9 +220,6 @@ class Node(object):\nif blob_hash in result:\nfor peer in result[blob_hash]:\nhost = \".\".join([str(ord(d)) for d in peer[:4]])\n- if host == \"127.0.0.1\" and \"from_peer\" in result \\\n- and result[\"from_peer\"] != \"self\":\n- host = result[\"from_peer\"]\nport, = struct.unpack('>H', peer[4:6])\nif (host, port) not in expanded_peers:\nexpanded_peers.append((host, port))\n",
        "chatgpt_cot": "Fix exception handling in name_resolution.py to handle all exceptions when adding addresses to the MasterEntry object, improving robustness and error handling."
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/master_view_proxy.py b/node_manager_fkie/src/node_manager_fkie/master_view_proxy.py @@ -444,6 +444,10 @@ class MasterViewProxy(QWidget):\nupdate_result[6].update(self.__master_info.service_names)\nnmd_node = self.__master_info.getNode('/node_manager_daemon')\nif nmd_node is None or nmd_node.pid is None:\n+ ret = MessageBox.Yes\n+ if not self.is_local:\n+ ret = MessageBox.question(self, 'Question', \"node_manager_daemon not found for '%s'.\\nShould it be started?\" % self.masteruri, buttons=MessageBox.Yes | MessageBox.No)\n+ if ret == MessageBox.Yes:\n# start node manager daemon if not already running\nhost_addr = nm.nameres().address(self.masteruri)\nrospy.loginfo(\"start node manager daemon for %s\", self.masteruri)\n@@ -2167,7 +2171,7 @@ class MasterViewProxy(QWidget):\ndef _getCfgChoises(self, node, ignore_defaults=False):\nresult = {}\nfor c in node.cfgs:\n- if c:\n+ if c and not isinstance(c, tuple):\n# TODO: create name\nprint \"_getCfgChoises\", c, type(c)\nresult[c] = c\n",
        "org_msg": "node_manager_fkie: fixed configuration selection",
        "sim_msg": "refactor broadcast start",
        "sim_diff": "diff --git a/dpark/broadcast.py b/dpark/broadcast.py @@ -42,12 +42,9 @@ class GuideManager(object):\nself.guides = {}\nself.host = socket.gethostname()\nself.guide_thread = None\n+ self.guide_addr = None\nself.register_addr = {}\nself.ctx = zmq.Context()\n- self.sock = self.ctx.socket(zmq.REP)\n- port = self.sock.bind_to_random_port('tcp://0.0.0.0')\n- self.guide_addr = 'tcp://%s:%d' % (self.host, port)\n-\ndef start(self):\nif self._started:\n@@ -58,10 +55,12 @@ class GuideManager(object):\nenv.register(GUIDE_ADDR, self.guide_addr)\ndef start_guide(self):\n+ sock = self.ctx.socket(zmq.REP)\n+ port = sock.bind_to_random_port('tcp://0.0.0.0')\n+ self.guide_addr = 'tcp://%s:%d' % (self.host, port)\n+\ndef run():\nlogger.debug(\"guide start at %s\", self.guide_addr)\n-\n- sock = self.sock\nwhile True:\ntype, msg = sock.recv_pyobj()\nif type == GUIDE_STOP:\n@@ -99,7 +98,6 @@ class GuideManager(object):\nelse:\nlogger.error('Unknown guide message: %s %s', type, msg)\nsock.send_pyobj(None)\n- sock.close()\nreturn spawn(run)\n@@ -117,6 +115,8 @@ class GuideManager(object):\nsock.recv_pyobj()\nsock.close()\nself.guide_thread.join()\n+ self.guide_addr = None\n+\ndownload_cond = None\nshared_uuid_fn_dict = None\n@@ -186,6 +186,9 @@ class DownloadManager(object):\nglobal shared_uuid_fn_dict, shared_uuid_map_dict, shared_master_blocks\nself.ctx = zmq.Context()\nself.host = socket.gethostname()\n+ if GUIDE_ADDR not in env.environ:\n+ start_guide_manager()\n+\nself.guide_addr = env.get(GUIDE_ADDR)\nself.random_inst = random.SystemRandom()\nself.server_addr, self.server_thread = self.start_server()\n@@ -466,6 +469,7 @@ class BroadcastManager(object):\nself._started = True\nglobal shared_uuid_fn_dict, shared_uuid_map_dict\n+ start_download_manager()\nself.guide_addr = env.get(GUIDE_ADDR)\nself.download_addr = env.get(DOWNLOAD_ADDR)\nself.cache = Cache()\n@@ -474,8 +478,6 @@ class BroadcastManager(object):\nself.shared_uuid_map_dict = shared_uuid_map_dict\ndef register(self, uuid, value):\n- _guide_manager.start()\n- _download_manager.start()\nself.start()\nif uuid in self.shared_uuid_fn_dict:\n@@ -507,7 +509,7 @@ class BroadcastManager(object):\nsock.close()\ndef fetch(self, uuid, compressed_size):\n- _download_manager.start()\n+ start_download_manager()\nself.start()\nvalue = self.cache.get(uuid)\nif value is not None:\n@@ -614,6 +616,8 @@ def stop_manager():\n_manager.shutdown()\n_download_manager.shutdown()\n_guide_manager.shutdown()\n+ env.environ.pop(GUIDE_ADDR, None)\n+ env.environ.pop(DOWNLOAD_ADDR, None)\nclass Broadcast(object):\n",
        "chatgpt_cot": "Add confirmation dialog for starting node_manager_daemon if not found, handle non-tuple config choices in _getCfgChoises method."
    },
    {
        "org_diff": "diff --git a/sc2/position.py b/sc2/position.py @@ -285,7 +285,9 @@ class Point2(Pointlike):\nreturn math.hypot(self.x, self.y)\ndef __bool__(self) -> bool:\n- return self.x != 0 or self.y != 0\n+ if self.x != 0 or self.y != 0:\n+ return True\n+ return False\ndef __mul__(self, other: Union[int, float, Point2]) -> Point2:\ntry:\n",
        "org_msg": "Fix by explicitly returning python bool",
        "sim_msg": "feat: add exp() to syft.py",
        "sim_diff": "diff --git a/syft/syft.py b/syft/syft.py @@ -140,6 +140,9 @@ class FloatTensor():\nreturn True\nreturn False\n+ def exp(self):\n+ return self.no_params_func(\"exp\", return_response=True)\n+\ndef __truediv__(self, x):\nreturn self.arithmetic_operation(x, \"div\", False)\n",
        "chatgpt_cot": "Refactor Point2 class bool method to improve readability and maintainability."
    },
    {
        "org_diff": "diff --git a/src/api-engine/api/utils/common.py b/src/api-engine/api/utils/common.py @@ -147,4 +147,4 @@ def to_dict(data, org_name):\nres = groups.get(org_name, None)\nif res != None:\nreturn res\n- return {\"error\": \"can't find org's config\"}\n+ return {\"error\": \"can't find channel config\"}\n",
        "org_msg": "Update error logs",
        "sim_msg": "Split session JSON serialization and writing to file\nTo avoid writing invalid JSON in case of presence of unserializable data due to an internal bug.",
        "sim_diff": "diff --git a/httpie/config.py b/httpie/config.py @@ -108,16 +108,14 @@ class BaseConfigDict(dict):\nself.ensure_directory()\n- try:\n- with self.path.open('w') as f:\n- json.dump(\n+ json_string = json.dumps(\nobj=self,\n- fp=f,\nindent=4,\nsort_keys=True,\nensure_ascii=True,\n)\n- f.write('\\n')\n+ try:\n+ self.path.write_text(json_string + '\\n')\nexcept IOError:\nif not fail_silently:\nraise\n",
        "chatgpt_cot": "Update error message in to_dict function to specify \"channel\" instead of \"org's\" config in common.py."
    },
    {
        "org_diff": "diff --git a/node_manager_daemon_fkie/src/node_manager_daemon_fkie/common.py b/node_manager_daemon_fkie/src/node_manager_daemon_fkie/common.py @@ -212,7 +212,7 @@ def included_files(string,\npwd = '.'\ncontent = string\n# read file content if file exists\n- if os.path.exists(string):\n+ if os.path.exists(string) and not os.path.isdir(string):\npwd = os.path.dirname(string)\nwith open(string, 'r') as f:\ncontent = f.read()\n",
        "org_msg": "node_manager_daemon_fkie: fixed error on open directory while search for include files",
        "sim_msg": "stupid backslashes in file paths",
        "sim_diff": "diff --git a/source1/content_manager.py b/source1/content_manager.py @@ -58,7 +58,8 @@ class ContentManager(metaclass=SingletonMeta):\nreturn False, path\ndef find_file(self, filepath: str, additional_dir=None, extension=None):\n- new_filepath = Path(filepath)\n+\n+ new_filepath = Path(str(filepath).strip('/\\\\').rstrip('/\\\\'))\nif additional_dir:\nnew_filepath = Path(additional_dir, new_filepath)\nif extension:\n",
        "chatgpt_cot": "\"Fix issue with reading file content in common.py\""
    },
    {
        "org_diff": "diff --git a/src/api-engine/api/routes/node/views.py b/src/api-engine/api/routes/node/views.py @@ -472,14 +472,12 @@ class NodeViewSet(viewsets.ViewSet):\nraise ResourceNotFound\nelse:\n# Set file url of node\n- server_host = request.META[\"HTTP_HOST\"]\n- server_host = server_host.split(\":\")[0]\nnode.file = request.build_absolute_uri(node.file.url)\nports = Port.objects.filter(node=node)\nnode.links = [\n{\n\"internal_port\": port.internal,\n- \"url\": \"%s:%s\" % (server_host, port.external),\n+ \"url\": \"%s:%s\" % (node.agent.ip, port.external),\n}\nfor port in ports\n]\n",
        "org_msg": "Fix links of node info not correct\nLinks of node info should use agent ip, not master\nserver address.",
        "sim_msg": "outputting info on request",
        "sim_diff": "diff --git a/xcube/webapi/viewer/viewer.py b/xcube/webapi/viewer/viewer.py @@ -77,7 +77,6 @@ class Viewer:\nserver_url = _get_server_url(port)\nself._server_url = server_url\nself._viewer_url = f\"{server_url}/viewer/?serverUrl={server_url}\"\n- self.info()\n@property\ndef server_config(self) -> Mapping[str, Any]:\n@@ -133,12 +132,16 @@ class Viewer:\nf' height=\"{height}\"'\nf'/>'\n)\n- except ImportError:\n+ except ImportError as e:\n+ print(f\"Error: {e}; Trying to open Viewer in web browser...\")\n+ try:\nimport webbrowser\nwebbrowser.open_new_tab(self.viewer_url)\n+ except:\n+ print(\"Failed too.\")\ndef info(self):\n- # Consider outputting this as HTML\n+ # Consider outputting this as HTML if in Notebook\nprint(f\"Server: {self.server_url}\")\nprint(f\"Viewer: {self.viewer_url}\")\n",
        "chatgpt_cot": "Update file URL to use node agent IP instead of server host"
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/echo_dialog.py b/node_manager_fkie/src/node_manager_fkie/echo_dialog.py @@ -422,6 +422,12 @@ class EchoDialog(QDialog):\nif rospy.is_shutdown():\nself.close()\nreturn\n+ if not self.show_only_rate and time.time() - self._last_received_ts > 1:\n+ # create a notification about scrapped messages\n+ if self._scrapped_msgs_sl > 0:\n+ txt = '<pre style=\"color:red; font-family:Fixedsys,Courier,monospace; padding:10px;\">scrapped %s message because of Hz-settings</pre>' % self._scrapped_msgs_sl\n+ self._scrapped_msgs_sl = 0\n+ self.display.append(txt)\nif self.message_count == self.last_printed_count:\nreturn\nwith self.lock:\n",
        "org_msg": "node_manager_fkie: fixed warning about echo of last scrapped message",
        "sim_msg": "text code statistics in report",
        "sim_diff": "diff --git a/qualcoder/report_codes.py b/qualcoder/report_codes.py @@ -1357,9 +1357,13 @@ class DialogReportCodes(QtWidgets.QDialog):\nfinal_stats.append(st)\nprint(\"stats results:\")\n+ msg = _(\"Text code statistics:\")\nfor st in final_stats:\n- print(\"stats\", st)\n-\n+ msg += \"\\n\" + st['codename'] + \" | \" + st['filename'] + \" | \" + _(\"Count: \") + str(st['codecount']) + \" | \"\n+ msg += _(\"Percent of file: \") + str(st['percent']) + \"%\"\n+ msg += \"\\n========\"\n+ if len(final_stats) > 0:\n+ self.ui.textEdit.append(msg)\ndef fill_text_edit_with_search_results(self):\n\"\"\" The textEdit.document is filled with the search results.\n",
        "chatgpt_cot": "Fix display issue in EchoDialog due to scrapped messages exceeding Hz-settings by adding notification to show scrapped message count."
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/screen_handler.py b/node_manager_fkie/src/node_manager_fkie/screen_handler.py @@ -181,4 +181,4 @@ class ScreenHandler(object):\nelse:\nnm.ssh().ssh_exec(host, [screen.SCREEN, '-wipe'], close_stdin=True, close_stdout=True, close_stderr=True)\nexcept nm.AuthenticationRequest as e:\n- raise nm.InteractionNeededError(e, cls.kill_screens, (node, host, auto_ok_request))\n+ raise nm.InteractionNeededError(e, cls.kill_screens, (grpc_url, host, auto_ok_request))\n",
        "org_msg": "node_manager_fkie: fixed error on kill screen on remote hosts",
        "sim_msg": "Typo when kcli console VM in opening remote-viewer\nIt seems the'e a typo when kcli console VM in opening remote-viewer",
        "sim_diff": "diff --git a/kvirt/kvm/__init__.py b/kvirt/kvm/__init__.py @@ -938,7 +938,7 @@ class Kvirt(object):\nurl = \"%s://%s:%s\" % (protocol, host, localport)\nif self.debug:\nprint(url)\n- consolecommand += \"; remote-viewer %s &\" % url\n+ consolecommand += \"remote-viewer %s &\" % url\n# os.popen(\"remote-viewer %s &\" % url)\nos.popen(consolecommand)\n",
        "chatgpt_cot": "\"Fix InteractionNeededError parameters in ScreenHandler\""
    },
    {
        "org_diff": "diff --git a/fkie_master_discovery/src/fkie_master_discovery/master_discovery.py b/fkie_master_discovery/src/fkie_master_discovery/master_discovery.py @@ -1047,6 +1047,7 @@ class Discoverer(object):\n:type stats: `fkie_master_discovery.msg.LinkStatesStamped <http://www.ros.org/doc/api/fkie_master_discovery/html/msg/LinkStatesStamped.html>`_\n'''\n+ if not rospy.is_shutdown():\nwith self.__lock:\ntry:\nself.pubstats.publish(stats)\n",
        "org_msg": "fkie_master_discovery: do not publish statistics after shutdown",
        "sim_msg": "[ServerStats] 1.6.1 Improve performance of `[p]whois` and fix IndexError in channelstats and serverstats commands",
        "sim_diff": "diff --git a/serverstats/serverstats.py b/serverstats/serverstats.py @@ -44,7 +44,7 @@ class ServerStats(commands.Cog):\n\"\"\"\n__author__ = [\"TrustyJAID\", \"Preda\"]\n- __version__ = \"1.6.0\"\n+ __version__ = \"1.6.1\"\ndef __init__(self, bot):\nself.bot: Red = bot\n@@ -1013,17 +1013,15 @@ class ServerStats(commands.Cog):\nembed.colour = await ctx.embed_colour()\nembed.set_author(name=f\"{member} ({member.id})\", icon_url=member.avatar_url)\nif await self.bot.is_owner(ctx.author):\n- guild_list = [\n- m\n- async for m in AsyncIter(self.bot.get_all_members(), steps=500)\n- if m.id == member.id\n- ]\n+ guild_list = []\n+ async for guild in AsyncIter(self.bot.guilds, steps=100):\n+ if m := guild.get_member(member.id):\n+ guild_list.append(m)\nelse:\n- guild_list = [\n- m\n- async for m in AsyncIter(self.bot.get_all_members(), steps=500)\n- if m.id == member.id and ctx.author in m.guild.members\n- ]\n+ guild_list = []\n+ async for guild in AsyncIter(self.bot.guilds, steps=100):\n+ if m:= guild.get_member(member.id) and guild.get_member(ctx.author.id):\n+ guild_list.append(m)\nif guild_list != []:\nmsg = f\"**{member}** ({member.id}) \" + _(\"is on:\\n\\n\")\n@@ -1649,8 +1647,14 @@ class ServerStats(commands.Cog):\nfor member_id, value in sorted_members[:5]:\nmember_messages.append(f\"<@!{member_id}>: {bold(humanize_number(value))}\\n\")\n+ try:\nmost_messages_user_id = sorted_members[0][0]\n+ except IndexError:\n+ most_messages_user_id = None\n+ try:\nmost_messages_user_num = sorted_members[0][1]\n+ except IndexError:\n+ most_messages_user_num = 0\nnew_msg = (\n_(\"**Most posts on the server**\\nTotal Messages: \")\n+ bold(humanize_number(guild_data[\"total\"]))\n@@ -1722,8 +1726,14 @@ class ServerStats(commands.Cog):\nlog.info(channel_data)\nfor member_id, value in sorted_members[:5]:\nmember_messages.append(f\"<@!{member_id}>: {bold(humanize_number(value))}\\n\")\n+ try:\nmost_messages_user_id = sorted_members[0][0]\n+ except IndexError:\n+ most_messages_user_id = None\n+ try:\nmost_messages_user_num = sorted_members[0][1]\n+ except IndexError:\n+ most_messages_user_num = 0\nmaybe_guild = f\"<@!{most_messages_user_id}>: {bold(humanize_number(int(most_messages_user_num)))}\\n\"\nnew_msg = (\n_(\"**Most posts in <#{}>**\\nTotal Messages: \").format(channel.id)\n",
        "chatgpt_cot": "Add check for rospy shutdown before publishing stats to prevent potential issues with rospy shutdown in Discoverer class."
    },
    {
        "org_diff": "diff --git a/test/test_pickled_data.py b/test/test_pickled_data.py @@ -112,7 +112,7 @@ class TestClass:\nbot._game_info.map_ramps, bot._game_info.vision_blockers = bot._game_info._find_ramps_and_vision_blockers()\nassert bot.main_base_ramp # Test if any ramp was found\n# TODO: Cache all expansion positions for a map and check if it is the same\n- assert len(bot.expansion_locations) >= 12\n+ assert len(bot.expansion_locations) >= 10\n# On N player maps, it is expected that there are N*X bases because of symmetry, at least for 1vs1 maps\nassert (\nlen(bot.expansion_locations) % (len(bot.enemy_start_locations) + 1) == 0\n",
        "org_msg": "Reduce minimum amount of expansions to 10 (fix for bel'shir vestige)",
        "sim_msg": "Remove TileMap from bulk Testing, needs an individual test written.",
        "sim_diff": "diff --git a/tests/base/test_maps.py b/tests/base/test_maps.py @@ -18,7 +18,7 @@ MAPS_TO_EXCLUDE_2D = [\n\"ParametricCasingAndLayer\",\n\"ParametricLayer\", \"ParametricBlockInLayer\",\n\"Projection\", \"SelfConsistentEffectiveMedium\",\n- \"SumMap\", \"SurjectUnits\"\n+ \"SumMap\", \"SurjectUnits\", \"TileMap\"\n]\nMAPS_TO_EXCLUDE_3D = [\n\"ComboMap\", \"ActiveCells\", \"InjectActiveCells\",\n@@ -29,7 +29,7 @@ MAPS_TO_EXCLUDE_3D = [\n\"SplineMap\", \"ParametricCasingAndLayer\",\n\"ParametricLayer\", \"ParametricBlockInLayer\",\n\"Projection\", \"SelfConsistentEffectiveMedium\",\n- \"SumMap\", \"SurjectUnits\"\n+ \"SumMap\", \"SurjectUnits\", \"TileMap\"\n]\n",
        "chatgpt_cot": "Adjust expansion location assertion to accommodate map symmetry, ensuring accurate base count calculation."
    },
    {
        "org_diff": "diff --git a/sc2/client.py b/sc2/client.py @@ -230,8 +230,8 @@ class Client(Protocol):\n))\nasync def debug_create_unit(self, unit_spawn_commands):\n- \"\"\" Usage example (will spawn 1 marine in the center of the map for player ID 1):\n- await self._client.debug_create_unit([[UnitTypeId.MARINE, 1, self._game_info.map_center, 1]]) \"\"\"\n+ \"\"\" Usage example (will spawn 5 marines in the center of the map for player ID 1):\n+ await self._client.debug_create_unit([[UnitTypeId.MARINE, 5, self._game_info.map_center, 1]]) \"\"\"\nassert isinstance(unit_spawn_commands, list)\nassert len(unit_spawn_commands) > 0\nassert isinstance(unit_spawn_commands[0], list)\n@@ -247,7 +247,7 @@ class Client(Protocol):\nowner=owner_id,\npos=common_pb.Point2D(x=position.x, y=position.y),\nquantity=amount_of_units\n- )) for unit_type, owner_id, position, amount_of_units in unit_spawn_commands]\n+ )) for unit_type, amount_of_units, position, owner_id in unit_spawn_commands]\n))\nasync def move_camera(self, position: Union[Unit, Point2, Point3]):\n",
        "org_msg": "Fix debug_create_unit",
        "sim_msg": "set team to red if joining a team-vs multi",
        "sim_diff": "diff --git a/objects/player.py b/objects/player.py @@ -17,7 +17,7 @@ from constants.gamemodes import GameMode\nfrom constants.mods import Mods\nfrom objects.channel import Channel\n-from objects.match import Match, SlotStatus\n+from objects.match import Match, SlotStatus, MatchTeamTypes, MatchTeams\nfrom objects.beatmap import Beatmap\nfrom objects import glob\n@@ -412,6 +412,11 @@ class Player:\nslot = m.slots[0 if slotID == -1 else slotID]\n+ # if in a teams-vs mode, switch team from neutral to red.\n+ if m.team_type in (MatchTeamTypes.team_vs,\n+ MatchTeamTypes.tag_team_vs):\n+ slot.team = MatchTeams.red\n+\nslot.status = SlotStatus.not_ready\nslot.player = self\nself.match = m\n",
        "chatgpt_cot": "Fix method documentation in Client class for debug_create_unit. Updated usage example to spawn 5 marines instead of 1. Changed parameter order in list comprehension."
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/supervised_popen.py b/node_manager_fkie/src/node_manager_fkie/supervised_popen.py @@ -73,9 +73,13 @@ class SupervisedPopen(QObject, subprocess.Popen):\nshell=shell, cwd=cwd, env=env, universal_newlines=universal_newlines,\nstartupinfo=startupinfo, creationflags=creationflags)\nexcept:\n- subprocess.Popen.__init__(self, args, bufsize, executable, stdin, stdout,\n- stderr, preexec_fn, close_fds, shell, cwd, env,\n- universal_newlines, startupinfo, creationflags)\n+ try:\n+ subprocess.Popen.__init__(self, args=args, bufsize=bufsize, executable=executable, stdin=stdin, stdout=stdout,\n+ stderr=stderr, preexec_fn=preexec_fn, close_fds=close_fds, shell=shell, cwd=cwd, env=env,\n+ universal_newlines=universal_newlines, startupinfo=startupinfo, creationflags=creationflags)\n+ except:\n+ import traceback\n+ print traceback.format_exc()\nQObject.__init__(self)\nself._args = args\nself._object_id = object_id\n",
        "org_msg": "fix popen init on IOS",
        "sim_msg": "Typo when kcli console VM in opening remote-viewer\nIt seems the'e a typo when kcli console VM in opening remote-viewer",
        "sim_diff": "diff --git a/kvirt/kvm/__init__.py b/kvirt/kvm/__init__.py @@ -938,7 +938,7 @@ class Kvirt(object):\nurl = \"%s://%s:%s\" % (protocol, host, localport)\nif self.debug:\nprint(url)\n- consolecommand += \"; remote-viewer %s &\" % url\n+ consolecommand += \"remote-viewer %s &\" % url\n# os.popen(\"remote-viewer %s &\" % url)\nos.popen(consolecommand)\n",
        "chatgpt_cot": "Fix compilation issue by adding exception handling and print traceback in supervised_popen."
    },
    {
        "org_diff": "diff --git a/sc2/units.py b/sc2/units.py @@ -3,7 +3,7 @@ import random\nimport warnings\nimport math\nfrom itertools import chain\n-from typing import Any, Dict, Iterable, List, Optional, Set, Tuple, Union, TYPE_CHECKING\n+from typing import Any, Dict, Iterable, List, Optional, Set, Tuple, Union, Generator, TYPE_CHECKING\nfrom .ids.unit_typeid import UnitTypeId\nfrom .position import Point2, Point3\n@@ -34,6 +34,9 @@ class Units(list):\ndef __call__(self, *args, **kwargs):\nreturn UnitSelection(self, *args, **kwargs)\n+ def __iter__(self) -> Generator[Unit, None, None]:\n+ return (item for item in super().__iter__())\n+\ndef select(self, *args, **kwargs):\nreturn UnitSelection(self, *args, **kwargs)\n",
        "org_msg": "Add __iter__ function to generate suggestions (IDE) when looping over Units",
        "sim_msg": "After formatting.",
        "sim_diff": "diff --git a/syft/grid.py b/syft/grid.py @@ -2,11 +2,14 @@ from collections import Counter\nfrom typing import Tuple\nfrom typing import Dict\n+\nclass VirtualGrid:\ndef __init__(self, *workers):\nself.workers = workers\n- def search(self, *query, verbose: bool =True, return_counter: bool=True) -> Tuple[Dict,Counter] :\n+ def search(\n+ self, *query, verbose: bool = True, return_counter: bool = True\n+ ) -> Tuple[Dict, Counter]:\n\"\"\"Searches over a collection of workers, returning pointers to the results\ngrouped by worker.\"\"\"\n",
        "chatgpt_cot": "Add generator to Units class for iteration efficiency. Update typing import to include Generator for improved code readability."
    },
    {
        "org_diff": "diff --git a/fkie_node_manager/src/fkie_node_manager/editor/editor.py b/fkie_node_manager/src/fkie_node_manager/editor/editor.py @@ -937,7 +937,11 @@ class Editor(QMainWindow):\nself._insert_text('<env name=\"variable\" value=\"value\"/>', 11, 8)\ndef _on_add_param_clipboard_tag(self):\n- self._insert_text('<param name=\"%s\" value=\"value\" />' % QApplication.clipboard().mimeData().text(), 13, 4)\n+ lines = QApplication.clipboard().mimeData().text().splitlines()\n+ name = \"\"\n+ if len(lines) == 1:\n+ name = lines[0]\n+ self._insert_text('<param name=\"%s\" value=\"value\" />' % name, 13, len(name))\ndef _on_add_param_tag(self):\nself._insert_text('<param name=\"name\" value=\"value\" />', 13, 4)\n",
        "org_msg": "node_manager: editor: do not add text with end of line chars as name for parameter on Ctrl+Shift+P",
        "sim_msg": "load text file encoding error handler using backslashreplace",
        "sim_diff": "diff --git a/qualcoder/manage_files.py b/qualcoder/manage_files.py @@ -1009,6 +1009,10 @@ class DialogManageFiles(QtWidgets.QDialog):\nfor lt_obj in layout:\nif isinstance(lt_obj, LTTextBox) or isinstance(lt_obj, LTTextLine):\ntext += lt_obj.get_text() + \"\\n\" # add line to paragraph spacing for visual format\n+ # remove excess line endings, include those with one blank space on a line\n+ text = text.replace('\\n \\n', '\\n')\n+ text = text.replace('\\n\\n\\n', '\\n\\n')\n+\n# import from html\nif import_file[-5:].lower() == \".html\" or import_file[-4:].lower() == \".htm\":\nimportErrors = 0\n@@ -1028,7 +1032,8 @@ class DialogManageFiles(QtWidgets.QDialog):\nif text == \"\":\nimport_errors = 0\ntry:\n- with open(import_file, \"r\") as sourcefile:\n+ # can get UnicodeDecode Error on Windows so using error handler\n+ with open(import_file, \"r\", encoding=\"utf-8\", errors=\"backslashreplace\") as sourcefile:\nwhile 1:\nline = sourcefile.readline()\nif not line:\n",
        "chatgpt_cot": "Add logic to handle multiple lines in clipboard for adding param tag in Editor. Fixes issue with single line clipboard content."
    },
    {
        "org_diff": "diff --git a/src/dashboard/package.json b/src/dashboard/package.json \"resize-observer-polyfill\": \"^1.5.1\",\n\"umi\": \"^3.1.4\",\n\"umi-request\": \"^1.2.19\",\n- \"validator\": \"^11.0.0\"\n+ \"validator\": \"^13.7.0\"\n},\n\"devDependencies\": {\n\"@types/history\": \"^4.7.2\",\n",
        "org_msg": "Fix security vulnerabilities in package.json file of dashboard module.\nUpgrade validator library to v13.7.0",
        "sim_msg": "Bump version of express",
        "sim_diff": "diff --git a/modules/app-layer/src/main/resources/dashboard/package.json b/modules/app-layer/src/main/resources/dashboard/package.json \"dependencies\": {\n\"atob\": \"^2.1.2\",\n\"cookie-parser\": \"^1.4.5\",\n- \"express\": \"^4.17.3\",\n+ \"express\": \"^4.18.2\",\n\"jsonwebtoken\": \"^8.5.1\",\n\"jwks-rsa\": \"^2.0.2\"\n}\n",
        "chatgpt_cot": "Update validator version from 11.0.0 to 13.7.0 in package.json"
    },
    {
        "org_diff": "diff --git a/sc2/game_data.py b/sc2/game_data.py @@ -114,6 +114,12 @@ class AbilityData:\nclass UnitTypeData:\ndef __init__(self, game_data, proto):\n+ # The ability_id for lurkers is\n+ # LURKERASPECTMPFROMHYDRALISKBURROWED_LURKERMPFROMHYDRALISKBURROWED\n+ # instead of the correct MORPH_LURKER.\n+ if proto.unit_id == UnitTypeId.LURKERMP.value:\n+ proto.ability_id = AbilityId.MORPH_LURKER.value\n+\nself._game_data = game_data\nself._proto = proto\n",
        "org_msg": "Workaround for incorrectly set lurker morph ability",
        "sim_msg": "Use `mode.value` instead enumerate.",
        "sim_diff": "diff --git a/app/objects/player.py b/app/objects/player.py @@ -536,14 +536,14 @@ class Player:\nasync with app.state.services.database.connection() as db_conn:\nawait self.stats_from_sql_full(db_conn)\n- for idx, mode_stat in enumerate(self.stats.values()):\n+ for mode, stats in self.stats.items():\nawait app.state.services.redis.zadd(\n- f\"gulag:leaderboard:{idx}\",\n- {self.id: mode_stat.pp},\n+ f\"gulag:leaderboard:{mode.value}\",\n+ {self.id: stats.pp},\n)\nawait app.state.services.redis.zadd(\n- f\"gulag:leaderboard:{idx}:{self.geoloc['country']['acronym']}\",\n- {self.id: mode_stat.pp},\n+ f\"gulag:leaderboard:{mode.value}:{self.geoloc['country']['acronym']}\",\n+ {self.id: stats.pp},\n)\nif \"restricted\" in self.__dict__:\n",
        "chatgpt_cot": "Fix incorrect ability_id for lurkers in UnitTypeData class. Update ability_id to MORPH_LURKER when unit_id is LURKERMP."
    },
    {
        "org_diff": "diff --git a/sc2/bot_ai.py b/sc2/bot_ai.py @@ -386,13 +386,12 @@ class BotAI:\nreturn False\ndef select_build_worker(self, pos: Union[Unit, Point2, Point3], force: bool=False) -> Optional[Unit]:\n- \"\"\"Select a worker to build a bulding with.\"\"\"\n-\n- workers = self.workers.closer_than(20, pos) or self.workers\n+ \"\"\"Select a worker to build a building with.\"\"\"\n+ workers = self.workers.filter(lambda w: (w.is_gathering or w.is_idle) and w.distance_to(pos) < 20) or self.workers\n+ if workers:\nfor worker in workers.sorted_by_distance_to(pos).prefer_idle:\nif not worker.orders or len(worker.orders) == 1 and worker.orders[0].ability.id in {AbilityId.MOVE,\n- AbilityId.HARVEST_GATHER,\n- AbilityId.HARVEST_RETURN}:\n+ AbilityId.HARVEST_GATHER}:\nreturn worker\nreturn workers.random if force else None\n",
        "org_msg": "improve select_build_worker",
        "sim_msg": "added unit test test_clear_object_for_worker_created_with_pre_existing_id for change in clear_objects()",
        "sim_diff": "diff --git a/test/workers/test_base.py b/test/workers/test_base.py @@ -27,6 +27,31 @@ def test_create_already_existing_worker(hook):\n_ = x + y * z\n+def test_clear_object_for_worker_created_with_pre_existing_id(hook):\n+\n+ worker = sy.VirtualWorker(hook, id=\"worker\")\n+ worker.clear_objects()\n+\n+ ptr = th.tensor([1, 2, 3]).send(worker)\n+ print(worker._objects)\n+\n+ assert len(worker._known_workers[worker.id]._objects) == len(worker._objects)\n+ assert len(worker._objects) == 1\n+\n+ # create worker with pre-existing id\n+ worker = sy.VirtualWorker(hook, id=\"worker\")\n+ worker.clear_objects()\n+\n+ assert len(worker._known_workers[worker.id]._objects) == len(worker._objects)\n+ assert len(worker._objects) == 0\n+\n+ ptr = th.tensor([1, 2, 3]).send(worker)\n+ print(worker._objects)\n+\n+ assert len(worker._known_workers[worker.id]._objects) == len(worker._objects)\n+ assert len(worker._objects) == 1\n+\n+\ndef test_create_already_existing_worker_with_different_type(hook, start_proc):\n# Shares tensor with bob\nbob = sy.VirtualWorker(hook, \"bob\")\n",
        "chatgpt_cot": "Refactor worker selection logic in BotAI to prioritize idle workers closer to the build location, fixing selection criteria for building."
    },
    {
        "org_diff": "diff --git a/Makefile b/Makefile @@ -133,7 +133,7 @@ docker-operator-dashboard: build/docker/operator-dashboard/$(DUMMY)\ndocker-clean: image-clean ##@Clean all existing images\n-DOCKERHUB_IMAGES = baseimage engine mongo nginx operator-dashboard user-dashboard watchdog\n+DOCKERHUB_IMAGES = baseimage engine mongo nginx operator-dashboard user-dashboard watchdog ansible-agent\ndockerhub: $(patsubst %,dockerhub-%,$(DOCKERHUB_IMAGES)) ##@Building latest images with dockerhub materials, to valid them\n",
        "org_msg": "[CE-351]Add ansible agent image onto docker hub",
        "sim_msg": "install a released watt instead of checking in a random build",
        "sim_diff": "diff --git a/Makefile b/Makefile @@ -264,7 +264,7 @@ docker-push-base-images:\ndocker-update-base: docker-base-images docker-push-base-images\n-ambassador-docker-image: version\n+ambassador-docker-image: version $(WATT)\ndocker build --build-arg AMBASSADOR_BASE_IMAGE=$(AMBASSADOR_BASE_IMAGE) --build-arg CACHED_CONTAINER_IMAGE=$(AMBASSADOR_DOCKER_IMAGE_CACHED) $(DOCKER_OPTS) -t $(AMBASSADOR_DOCKER_IMAGE) .\ndocker-login:\n@@ -341,6 +341,14 @@ $(TELEPROXY):\nsudo chown root $(TELEPROXY)\nsudo chmod go-w,a+sx $(TELEPROXY)\n+WATT=watt\n+WATT_VERSION=0.4.1\n+\n+# This is for the docker image, so we don't use the current arch, we hardcode to linux/amd64\n+$(WATT):\n+ curl -o $(WATT) https://s3.amazonaws.com/datawire-static-files/watt/$(WATT_VERSION)/linux/amd64/watt\n+ chmod go-w,a+x $(WATT)\n+\nCLAIM_FILE=kubernaut-claim.txt\nCLAIM_NAME=$(shell cat $(CLAIM_FILE))\n@@ -369,7 +377,7 @@ $(KAT_CLIENT):\nmv kat-backend-$(KAT_BACKEND_RELEASE)/client/bin/client_$(GOOS)_$(GOARCH) $(PWD)/$(KAT_CLIENT)\nrm -rf v$(KAT_BACKEND_RELEASE).tar.gz kat-backend-$(KAT_BACKEND_RELEASE)/\n-setup-develop: venv $(KAT_CLIENT) $(TELEPROXY) $(KUBERNAUT) version\n+setup-develop: venv $(KAT_CLIENT) $(TELEPROXY) $(KUBERNAUT) $(WATT) version\nkill_teleproxy = $(shell kill -INT $$(/bin/ps -ef | fgrep venv/bin/teleproxy | fgrep -v grep | awk '{ print $$2 }') 2>/dev/null)\n",
        "chatgpt_cot": "\"Add ansible-agent to dockerhub images for validation\""
    },
    {
        "org_diff": "diff --git a/sc2/bot_ai.py b/sc2/bot_ai.py @@ -346,7 +346,7 @@ class BotAI:\nif len(worker_pool) > len(deficit_mining_places):\nall_minerals_near_base = [\nmineral\n- for mineral in self.mineral_fields\n+ for mineral in self.state.mineral_field\nif any(mineral.distance_to(base) <= 8 for base in self.townhalls.ready)\n]\n# distribute every worker in the pool\n@@ -376,7 +376,7 @@ class BotAI:\nmineral for mineral in self.state.mineral_field if mineral.distance_to(current_place) <= 8\n]\ntarget_mineral = max(local_minerals, key=lambda mineral: mineral.mineral_contents)\n- self.actions.append(worker.gather(target_mineral))\n+ actions.append(worker.gather(target_mineral))\n# more workers to distribute than free mining spots\n# send to closest if worker is doing nothing\nelif worker.is_idle and all_minerals_near_base:\n",
        "org_msg": "fix last typos",
        "sim_msg": "fix assign tuple action existing_tuple logic",
        "sim_diff": "diff --git a/workers/worker_base.py b/workers/worker_base.py @@ -354,9 +354,15 @@ class Worker():\ncontinue\nobj['flag'] = 'none' # default of no action needed\n+ existing_tuple = None\nfor db_dupe_key in list(duplicate_col_map.keys()):\nif table_values.isin([obj[duplicate_col_map[db_dupe_key]]]).any().any():\n+ if table_values[table_values[db_dupe_key].isin(\n+ [obj[duplicate_col_map[db_dupe_key]]])].to_dict('records'):\n+\n+ existing_tuple = table_values[table_values[db_dupe_key].isin(\n+ [obj[duplicate_col_map[db_dupe_key]]])].to_dict('records')[0]\ncontinue\nself.logger.info('Found a tuple that needs insertion based on dupe key: {}\\n'.format(db_dupe_key))\n@@ -369,15 +375,6 @@ class Worker():\n'Moving to next tuple.\\n')\ncontinue\n- try:\n- existing_tuple = table_values[table_values[db_dupe_key].isin(\n- [obj[duplicate_col_map[db_dupe_key]]])].to_dict('records')[0]\n- except Exception as e:\n- self.logger.info('Special case assign_tuple_action error')\n- self.logger.info(f'Error: {e}')\n- self.logger.info(f'Related vars: {table_values}, ' +\n- f'{table_values[db_dupe_key].isin([obj[duplicate_col_map[db_dupe_key]]])}')\n-\n# If we need to check the values of the existing tuple to determine if an update is needed\nfor augur_col, value_check in value_update_col_map.items():\nnot_nan_check = not (math.isnan(value_check) and math.isnan(existing_tuple[augur_col])) if value_check is not None else True\n",
        "chatgpt_cot": "\"Fix worker gathering and action append in BotAI to resolve compilation issue and improve worker distribution logic based on mining spots.\""
    },
    {
        "org_diff": "diff --git a/sc2/main.py b/sc2/main.py @@ -196,7 +196,8 @@ async def _play_game(player, client, realtime, portconfig, step_time_limit=None,\nelse:\nresult = await _play_game_ai(client, player_id, player.ai, realtime, step_time_limit, game_time_limit)\n- logging.info(f\"Result for player {player_id} ({player.ai.__class__.__name__}): {result._name_}\")\n+ logging.info(f\"Result for player {player_id} ({str(player)}: {result._name_}\")\n+\nreturn result\nasync def _setup_host_game(server, map_settings, players, realtime, random_seed=None):\n",
        "org_msg": "FIx Human string issue",
        "sim_msg": "disable host latency option",
        "sim_diff": "diff --git a/customping/customping.py b/customping/customping.py @@ -32,7 +32,7 @@ import time\nimport discord\nimport speedtest\n-from redbot.core import checks, commands\n+from redbot.core import commands, Config\nold_ping = None\n@@ -42,6 +42,17 @@ class CustomPing(commands.Cog):\ndef __init__(self, bot):\nself.bot = bot\n+ self.config = Config.get_conf(\n+ self,\n+ identifier=325236743863625234572,\n+ force_registration=True,\n+ )\n+ default_global = {\"host_latency\": True}\n+ self.config.register_global(**default_global)\n+ self.settings = {}\n+\n+ async def initialize(self):\n+ self.settings = await self.config.all()\nasync def red_delete_data_for_user(self, **kwargs):\nreturn\n@@ -55,7 +66,7 @@ class CustomPing(commands.Cog):\npass\nself.bot.add_command(old_ping)\n- @checks.bot_has_permissions(embed_links=True)\n+ @commands.bot_has_permissions(embed_links=True)\n@commands.cooldown(2, 5, commands.BucketType.user)\n@commands.group(invoke_without_command=True)\nasync def ping(self, ctx):\n@@ -83,11 +94,16 @@ class CustomPing(commands.Cog):\nelse:\ncolor = discord.Colour.green()\n+ if not self.settings[\"host_latency\"]:\n+ e.title = \"Pong!\"\n+\ne.color = color\ntry:\nawait message.edit(embed=e)\nexcept discord.NotFound:\nreturn\n+ if not self.settings[\"host_latency\"]:\n+ return\nexecutor = concurrent.futures.ThreadPoolExecutor(max_workers=1)\nloop = asyncio.get_event_loop()\n@@ -170,14 +186,34 @@ class CustomPing(commands.Cog):\nelse:\ncolor = discord.Colour.green()\ne = discord.Embed(color=color, title=\"Shard Pings\", description=\"\\n\".join(description))\n- e.set_footer(text=f\"Average: {average_ping}ms\")\n+ e.set_footer(text=f\"Average: {round(average_ping, 2)}ms\")\nawait ctx.send(embed=e)\n+ @commands.is_owner()\n+ @commands.group()\n+ async def pingset(self, ctx: commands.Context):\n+ \"\"\"Manage CustomPing settings.\"\"\"\n+\n+ @pingset.command(name=\"hostlatency\")\n+ async def pingset_hostlatency(self, ctx: commands.Context, true_or_false: bool = None):\n+ \"\"\"Toggle displaying host latency on the ping command.\"\"\"\n+ target_state = (\n+ true_or_false\n+ if true_or_false is not None\n+ else not (await self.config.host_latency())\n+ )\n+ await self.config.host_latency.set(target_state)\n+ self.settings[\"host_latency\"] = target_state\n+ word = \" \" if target_state else \" not \"\n+ await ctx.send(f\"Host latency will{word}be displayed on the `{ctx.clean_prefix}ping` command.\")\n+\n-def setup(bot):\n- ping = CustomPing(bot)\n+async def setup(bot):\nglobal old_ping\nold_ping = bot.get_command(\"ping\")\nif old_ping:\nbot.remove_command(old_ping.name)\n- bot.add_cog(ping)\n+\n+ cog = CustomPing(bot)\n+ await cog.initialize()\n+ bot.add_cog(cog)\n",
        "chatgpt_cot": "Fix logging format for player result in main.py. Add missing closing parenthesis and convert player object to string for logging."
    },
    {
        "org_diff": "diff --git a/.github/workflows/ci.yml b/.github/workflows/ci.yml @@ -109,7 +109,7 @@ jobs:\nfail-fast: false\nmatrix:\nos: [ubuntu-latest]\n- python-version: ['3.8', '3.9', '3.10', '3.11.0b1']\n+ python-version: ['3.8', '3.9', '3.10']\nsc2-version: ['4.10']\nenv:\nIMAGE_NAME: burnysc2/python-sc2:local\n",
        "org_msg": "Remove python beta release client",
        "sim_msg": "Temporarily pause Python 3.10 CI tests due to scikit-learn issues with Windows\nScikit-learn is planning to add Python 3.10 support in the middle of December 2021, according to scikit-learn/scikit-learn#21882",
        "sim_diff": "diff --git a/.github/workflows/ci.yaml b/.github/workflows/ci.yaml @@ -76,7 +76,7 @@ jobs:\nneeds: [cache_nltk_data, cache_third_party]\nstrategy:\nmatrix:\n- python-version: ['3.7', '3.8', '3.9', '3.10']\n+ python-version: ['3.7', '3.8', '3.9']\nos: [ubuntu-latest, macos-latest, windows-latest]\nfail-fast: false\nruns-on: ${{ matrix.os }}\n",
        "chatgpt_cot": "Update Python versions in CI workflow to include 3.10 and remove 3.11.0b1 to match current supported versions and ensure compatibility."
    },
    {
        "org_diff": "diff --git a/rasa_core_sdk/forms.py b/rasa_core_sdk/forms.py @@ -102,7 +102,7 @@ class FormAction(Action):\nself.name())\n# noinspection PyUnusedLocal\n- def next_slot_to_request(self,\n+ def request_next_slot(self,\ndispatcher, # type: CollectingDispatcher\ntracker, # type: Tracker\ndomain # type: Dict[Text, Any]\n@@ -184,7 +184,7 @@ class FormAction(Action):\nif e['event'] == 'slot':\ntemp_tracker.slots[e[\"name\"]] = e[\"value\"]\n- next_slot_events = self.next_slot_to_request(dispatcher, temp_tracker,\n+ next_slot_events = self.request_next_slot(dispatcher, temp_tracker,\ndomain)\nif next_slot_events is not None:\n# request next slot\n",
        "org_msg": "request slot in different methodrequest_next_slot RasaHQ/roadmap#280",
        "sim_msg": "Removed fetching of loco data\nBy testing seems the website now is able to auto update the category menu continue watching",
        "sim_diff": "diff --git a/resources/lib/services/nfsession/msl/events_handler.py b/resources/lib/services/nfsession/msl/events_handler.py @@ -67,9 +67,9 @@ class EventsHandler(threading.Thread):\ndef _process_event_request(self, event_type, event_data, player_state):\n\"\"\"Build and make the event post request\"\"\"\n- if event_type == EVENT_START:\n- # We get at every new video playback a fresh LoCo data\n- self.loco_data = self.nfsession.get_loco_data()\n+ # if event_type == EVENT_START:\n+ # # We get at every new video playback a fresh LoCo data\n+ # self.loco_data = self.nfsession.get_loco_data()\nurl = event_data['manifest']['links']['events']['href']\nfrom resources.lib.services.nfsession.msl.msl_request_builder import MSLRequestBuilder\nrequest_data = MSLRequestBuilder.build_request_data(url,\n@@ -85,8 +85,8 @@ class EventsHandler(threading.Thread):\nresponse = self.chunked_request(endpoint_url, request_data, get_esn())\n# Malformed/wrong content in requests are ignored without returning any error in the response or exception\nLOG.debug('EVENT [{}] - Request response: {}', event_type, response)\n- if event_type == EVENT_STOP:\n- # 15/01/2023 update_loco_context looks like not more used on website when playback stop\n+ # if event_type == EVENT_STOP:\n+ # # 15/01/2023 update_loco_context looks like not more used on website when playback stop\n# if event_data['allow_request_update_loco']:\n# if 'list_context_name' in self.loco_data:\n# self.nfsession.update_loco_context(\n@@ -96,7 +96,7 @@ class EventsHandler(threading.Thread):\n# self.loco_data['list_index'])\n# else:\n# LOG.debug('EventsHandler: LoCo list not updated no list context data provided')\n- self.loco_data = None\n+ # self.loco_data = None\nexcept Exception as exc: # pylint: disable=broad-except\nLOG.error('EVENT [{}] - The request has failed: {}', event_type, exc)\n# Ban future event requests from this event xid\n@@ -182,7 +182,7 @@ class EventsHandler(threading.Thread):\n'uiplaycontext': {\n# 'list_id': list_id, # not mandatory\n# lolomo_id: use loco root id value\n- 'lolomo_id': loco_data['root_id'],\n+ 'lolomo_id': 'unknown', # loco_data['root_id'],\n'location': play_ctx_location,\n'rank': 0, # Perhaps this is a reference of cdn rank used in the manifest? (we use always 0)\n'request_id': event_data['request_id'],\n",
        "chatgpt_cot": "Refactor method name in FormAction class for clarity and consistency. Update method name from next_slot_to_request to request_next_slot for better readability and understanding."
    },
    {
        "org_diff": "diff --git a/sc2/game_info.py b/sc2/game_info.py @@ -51,7 +51,7 @@ class Ramp:\n@property\ndef upper2_for_ramp_wall(self) -> Set[Point2]:\n\"\"\" Returns the 2 upper ramp points of the main base ramp required for the supply depot and barracks placement properties used in this file. \"\"\"\n- if len(self.upper) > 2:\n+ if len(self.upper) > 5:\n# NOTE: this was way too slow on large ramps\nreturn set() # HACK: makes this work for now\n# FIXME: please do\n",
        "org_msg": "Fix Para Site ramp crash",
        "sim_msg": "fixed barrier bug",
        "sim_diff": "diff --git a/holoclean/holoclean.py b/holoclean/holoclean.py @@ -111,16 +111,15 @@ class _Barrier:\nself.mutex.acquire()\nself.count = self.count + 1\nstring_name = str(threading.currentThread().getName())\n- if self.count == self.n:\n+ count = self.count\nself.mutex.release()\n+ if count == self.n:\nself.barrier.acquire()\nself.barrier.notifyAll()\nself.barrier.release()\nelse:\nself.barrier.acquire()\n- self.mutex.release()\nself.barrier.wait()\n- self.mutex.acquire()\nself.barrier.release()\nclass HoloClean:\n",
        "chatgpt_cot": "Increase upper ramp points to 5 in game_info.py\nIncreased the upper ramp points from 2 to 5 in the Ramp class of game_info.py to improve supply depot and barracks placement properties."
    },
    {
        "org_diff": "diff --git a/sc2/unit.py b/sc2/unit.py @@ -79,6 +79,25 @@ class PassengerUnit:\ndef is_psionic(self) -> bool:\nreturn Attribute.Psionic.value in self._type_data.attributes\n+ @property_immutable_cache\n+ def is_detector(self) -> bool:\n+ \"\"\" Checks if the unit is a detector.\n+ Has to be ready to detect and Photoncannons also need to be powered. \"\"\"\n+ return self.is_ready and (\n+ self.type_id\n+ in {\n+ UnitTypeId.OBSERVER,\n+ UnitTypeId.OBSERVERSIEGEMODE,\n+ UnitTypeId.RAVEN,\n+ UnitTypeId.MISSILETURRET,\n+ UnitTypeId.OVERSEER,\n+ UnitTypeId.OVERSEERSIEGEMODE,\n+ UnitTypeId.SPORECRAWLER,\n+ }\n+ or self.type_id == UnitTypeId.PHOTONCANNON\n+ and self.is_powered\n+ )\n+\n@property_immutable_cache\ndef cargo_size(self) -> Union[float, int]:\n\"\"\" How much cargo this unit uses up in cargo_space \"\"\"\n@@ -578,7 +597,7 @@ class Unit(PassengerUnit):\nreturn self(self._game_data.upgrades[upgrade.value].research_ability.id, *args, **kwargs)\ndef has_buff(self, buff):\n- assert isinstance(buff, BuffId)\n+ assert isinstance(buff, BuffId), f\"{buff} is no BuffId\"\nreturn buff.value in self._proto.buff_ids\ndef warp_in(self, unit, placement, *args, **kwargs):\n",
        "org_msg": "Add is_detector property",
        "sim_msg": "pytest refactoring of expval test",
        "sim_diff": "diff --git a/tests/test_expval.py b/tests/test_expval.py Unit tests for the :mod:`pennylane.plugin.DefaultGaussian` device.\n\"\"\"\n# pylint: disable=protected-access,cell-var-from-loop\n-import unittest\n-import inspect\n-import logging as log\n-\n-import pennylane as qml\n-\nfrom pennylane import numpy as np\nfrom scipy.linalg import block_diag\n-from defaults import pennylane as qml, BaseTest\n+from defaults import pennylane as qml\nfrom pennylane.expval import Identity\nfrom pennylane.qnode import QuantumFunctionError\n-log.getLogger('defaults')\n+import pytest\n-class TestExpval(BaseTest):\n- \"\"\"Tests that the Expectations in expval work propperly.\"\"\"\n- def test_identiy_raises_exception_if_outside_qnode(self):\n- \"\"\"Tests that proper exceptions are raised if we try to call Idenity\n- outside a QNode.\"\"\"\n- self.logTestName()\n-\n- with self.assertRaisesRegex(QuantumFunctionError, 'can only be used inside a qfunc'):\n+def test_identiy_raises_exception_if_outside_qnode():\n+ \"\"\"expval: Tests that proper exceptions are raised if we try to call\n+ Idenity outside a QNode.\"\"\"\n+ with pytest.raises(QuantumFunctionError, match=\"can only be used inside a qfunc\"):\nIdentity(wires=0)\n- def test_identiy_raises_exception_if_cannot_guess_device_type(self):\n- \"\"\"Tests that proper exceptions are raised if Identity fails to guess\n- whether on a device is CV or qubit.\"\"\"\n- self.logTestName()\n- dev = qml.device('default.qubit', wires=1)\n+def test_identiy_raises_exception_if_cannot_guess_device_type():\n+ \"\"\"expval: Tests that proper exceptions are raised if Identity fails to guess\n+ whether on a device is CV or qubit.\"\"\"\n+ dev = qml.device(\"default.qubit\", wires=1)\ndev._expectation_map = {}\n@qml.qnode(dev)\ndef circuit():\nreturn qml.expval.Identity(wires=0)\n- with self.assertRaisesRegex(QuantumFunctionError, 'Unable to determine whether this device supports CV or qubit'):\n+ with pytest.raises(\n+ QuantumFunctionError,\n+ match=\"Unable to determine whether this device supports CV or qubit\",\n+ ):\ncircuit()\n-\n-\n-if __name__ == '__main__':\n- print('Testing PennyLane version ' + qml.version() + ', expval.')\n- # run the tests in this file\n- suite = unittest.TestSuite()\n- for t in (TestExpval):\n- ttt = unittest.TestLoader().loadTestsFromTestCase(t)\n- suite.addTests(ttt)\n- unittest.TextTestRunner().run(suite)\n",
        "chatgpt_cot": "Add methods to check if unit is a detector and cargo size, and fix assert statement to include assertion message for non-BuffId."
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/editor/text_edit.py b/node_manager_fkie/src/node_manager_fkie/editor/text_edit.py @@ -407,7 +407,7 @@ class TextEdit(QTextEdit):\nlast_pos = res.rfind(\"- ->\")\nif last_pos > -1:\nres = \"%s-->\" % res[0:last_pos]\n- cursor.insertText(res)\n+ cursor.insertText(res.replace(\"- - \", \"--\"))\nelse: # other comments\nhash_re = re.compile(r\"# ?\")\nif do_comment:\n",
        "org_msg": "node_manager_fkie: editor: fixed uncomment of -- statements",
        "sim_msg": "Escaping markdown on mentions. Fixes T458",
        "sim_diff": "diff --git a/app/misc.py b/app/misc.py @@ -449,7 +449,11 @@ def our_markdown(text):\nln = '/u/' + match.group(4)\nelse:\nln = match.group(2)\n- return '[{0}]({1})'.format(match.group(2), ln)\n+ text = match.group(2)\n+ text = text.replace('_', '\\_')\n+ text = text.replace('*', '\\*')\n+ text = text.replace('~', '\\~')\n+ return '[{0}]({1})'.format(text, ln)\ntext = RE_AMENTION.sub(repl, text)\ntry:\nreturn md(text)\n",
        "chatgpt_cot": "\"Fix issue with comment formatting in TextEdit class by replacing '- -' with '--' in insertText method\""
    },
    {
        "org_diff": "diff --git a/sc2/player.py b/sc2/player.py @@ -26,6 +26,7 @@ class AbstractPlayer:\nif p_type == PlayerType.Computer:\nself.difficulty = difficulty\n+\nclass Human(AbstractPlayer):\ndef __init__(self, race, name=None):\nsuper().__init__(PlayerType.Participant, race, name=name)\n@@ -36,6 +37,7 @@ class Human(AbstractPlayer):\nelse:\nreturn f\"Human({self.race._name_})\"\n+\nclass Bot(AbstractPlayer):\ndef __init__(self, race, ai, name=None):\n\"\"\"\n@@ -52,9 +54,10 @@ class Bot(AbstractPlayer):\nelse:\nreturn f\"Bot {self.ai.__class__.__name__}({self.race._name_})\"\n+\nclass Computer(AbstractPlayer):\ndef __init__(self, race, difficulty=Difficulty.Easy):\n- super().__init__(PlayerType.Computer, race, difficulty)\n+ super().__init__(PlayerType.Computer, race, difficulty=difficulty)\ndef __str__(self):\nreturn f\"Computer {self.difficulty._name_}({self.race._name_})\"\n",
        "org_msg": "Fix difficulty",
        "sim_msg": "set team to red if joining a team-vs multi",
        "sim_diff": "diff --git a/objects/player.py b/objects/player.py @@ -17,7 +17,7 @@ from constants.gamemodes import GameMode\nfrom constants.mods import Mods\nfrom objects.channel import Channel\n-from objects.match import Match, SlotStatus\n+from objects.match import Match, SlotStatus, MatchTeamTypes, MatchTeams\nfrom objects.beatmap import Beatmap\nfrom objects import glob\n@@ -412,6 +412,11 @@ class Player:\nslot = m.slots[0 if slotID == -1 else slotID]\n+ # if in a teams-vs mode, switch team from neutral to red.\n+ if m.team_type in (MatchTeamTypes.team_vs,\n+ MatchTeamTypes.tag_team_vs):\n+ slot.team = MatchTeams.red\n+\nslot.status = SlotStatus.not_ready\nslot.player = self\nself.match = m\n",
        "chatgpt_cot": "Add new method and modify method parameters in AbstractPlayer and its subclasses to enhance functionality and improve code readability."
    },
    {
        "org_diff": "diff --git a/src/api-engine/api/routes/channel/views.py b/src/api-engine/api/routes/channel/views.py @@ -52,9 +52,8 @@ class ChannelViewSet(viewsets.ViewSet):\ntry:\norg_id = request.user.organization.id\norg = Organization.objects.get(pk=org_id)\n- channels = Channel.objects.filter(network=org.network)\n- p = Paginator(channels, per_page)\n- channels = p.page(page)\n+ channels = Paginator(org.channel, per_page)\n+ channels = channels.page(page)\nresponse = ChannelListResponse(\ndata={\"data\": channels, \"total\": channels.count}\n)\n",
        "org_msg": "Update the way for filtering out channels",
        "sim_msg": "Testing Order Change in Swagger Def",
        "sim_diff": "diff --git a/flask-nginx-rtmp-mgmt/apiv1.py b/flask-nginx-rtmp-mgmt/apiv1.py @@ -35,12 +35,6 @@ channelParserPost.add_argument('topicID', type=int, required=True)\n@api.route('/channels/')\nclass api_1_ListChannels(Resource):\n- def get(self):\n- \"\"\"\n- Gets a List of all Public Channels\n- \"\"\"\n- channelList = Channel.Channel.query.all()\n- return {'results': [ob.serialize() for ob in channelList]}\n# Channel - Create Channel\n@api.expect(channelParserPost)\n@api.doc(security='apikey')\n@@ -50,16 +44,17 @@ class api_1_ListChannels(Resource):\nCreates a New Channel\n\"\"\"\nreturn {'results': {'message':'Channel Created'}}, 200\n+ # Channel - Get all Channels\n+ def get(self):\n+ \"\"\"\n+ Gets a List of all Public Channels\n+ \"\"\"\n+ channelList = Channel.Channel.query.all()\n+ return {'results': [ob.serialize() for ob in channelList]}\n@api.route('/channels/<string:channelEndpointID>')\n@api.doc(params={'channelEndpointID': 'Channel Endpoint Descriptor, Expressed in a UUID Value(ex:db0fe456-7823-40e2-b40e-31147882138e)'})\nclass api_1_ListChannel(Resource):\n- def get(self, channelEndpointID):\n- \"\"\"\n- Get Info for One Channel\n- \"\"\"\n- channelList = Channel.Channel.query.filter_by(channelLoc=channelEndpointID).all()\n- return json.dumps({'results': [ob.serialize() for ob in channelList]})\n# Channel - Change Channel Name or Topic ID\n@api.expect(channelParserPut)\n@api.doc(security='apikey')\n@@ -76,7 +71,13 @@ class api_1_ListChannel(Resource):\npass\nreturn {'results': {'message':'Channel Updated'}}, 200\nelse:\n- return {'results': {'message':'Request Error'}}, 400\n+ return {'results': {'message':'Request Error'}},\n+ def get(self, channelEndpointID):\n+ \"\"\"\n+ Get Info for One Channel\n+ \"\"\"\n+ channelList = Channel.Channel.query.filter_by(channelLoc=channelEndpointID).all()\n+ return json.dumps({'results': [ob.serialize() for ob in channelList]})\n@api.route('/streams/')\nclass api_1_ListStreams(Resource):\n",
        "chatgpt_cot": "Refactor channel view pagination logic for organization channels in ChannelViewSet to improve efficiency."
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/__init__.py b/node_manager_fkie/src/node_manager_fkie/__init__.py @@ -58,8 +58,8 @@ PKG_NAME = 'node_manager_fkie'\n__author__ = \"Alexander Tiderko (Alexander.Tiderko@fkie.fraunhofer.de)\"\n__copyright__ = \"Copyright (c) 2012 Alexander Tiderko, Fraunhofer FKIE/US\"\n__license__ = \"BSD\"\n-__version__ = \"0.7.8\" # git describe --tags --dirty --always\n-__date__ = \"2018-03-24\" # git log -1 --date=iso\n+__version__ = \"0.7.8-30\" # git describe --tags --dirty --always\n+__date__ = \"2018-07-04\" # git log -1 --date=iso\n# PYTHONVER = (2, 7, 1)\n# if sys.version_info < PYTHONVER:\n",
        "org_msg": "node_manager_fkie: update version info",
        "sim_msg": "MAINT: fix release version in docs conf.py",
        "sim_diff": "diff --git a/docs/conf.py b/docs/conf.py @@ -22,7 +22,7 @@ copyright = '2020, Projeto Jupiter'\nauthor = 'Giovani Hdalgo Ceotto'\n# The full version, including alpha/beta/rc tags\n-release = '0.9.7'\n+release = '0.9.8'\n# -- General configuration ---------------------------------------------------\n",
        "chatgpt_cot": "Update version and date in __init__.py to reflect the latest changes made on 2018-07-04 and version 0.7.8-30."
    },
    {
        "org_diff": "diff --git a/docs/CONTRIBUTING.md b/docs/CONTRIBUTING.md @@ -69,15 +69,15 @@ $ make check\n$ git commit -s -a\n```\n-Example commit msg may look like:\n+Example commit msg may look like (take CE-1234 for example):\n```sh\n-[CE-26] A short description of your change with no period at the end\n+[CE-1234] A short description of your change with no period at the end\nYou can add more details here in several paragraphs, but please keep each line\nwidth less than 80 characters. A bug fix should include the issue number.\n-Fix https://jira.hyperledger.org/browse/CE-26.\n+CE-1234 #done.\nChange-Id: If2e142ea1a21bc4b42f702f9a27d70d31edff20d\nSigned-off-by: Your Name <committer@email.address>\n",
        "org_msg": "Update the contribution doc\nDeveloper can add `CE-1234 #done` at commit msg, to trigger the\njira issue to close automatically after the commit is merged.\n#done.",
        "sim_msg": "Update pre-commit checks section in CONTRIBUTING.md with more tox commands",
        "sim_diff": "diff --git a/CONTRIBUTING.md b/CONTRIBUTING.md @@ -9,12 +9,8 @@ If you're already familiar with our workflow, maybe have a quick look at the [pr\nBefore you commit any code, please perform the following checks:\n- [No style issues](#coding-style-guidelines): `$ flake8`\n-- [All tests pass](#testing): `$ python run-tests.py --unit`\n-- [The documentation builds](#building-the-documentation): `$ cd docs` and then `$ make clean; make html`\n-\n-You can even run all three at once, using `$ tox`. This will run the above checks in two separate environments\n-for python 3.6 and 3.7. To check for only your current python version, use `$ tox -e py`.\n-\n+- [All tests pass](#testing): `$ tox -e quick` (GNU/Linux and MacOS), `$ python -m tox -e windows-quick` (Windows)\n+- [The documentation builds](#building-the-documentation): `$ python -m tox -e docs`\n## Workflow\n",
        "chatgpt_cot": "Fix compilation issue due to new method in CONTRIBUTING.md file."
    },
    {
        "org_diff": "diff --git a/.github/workflows/docker-ci.yml b/.github/workflows/docker-ci.yml @@ -46,15 +46,15 @@ jobs:\nname: Build docker image\nruns-on: ${{ matrix.os }}\ntimeout-minutes: 30\n- env:\n- IMAGE_NAME: burnysc2/python-sc2-docker:py_${{ matrix.python-version }}-sc2_${{ matrix.sc2-version }}-v${{ env.VERSION_NUMBER }}\n- BUILD_ARGS: --build-arg PYTHON_VERSION=${{ matrix.python-version }} --build-arg SC2_VERSION=${{ matrix.sc2-version }}\nstrategy:\nfail-fast: false\nmatrix:\nos: [ubuntu-latest]\npython-version: ['3.7', '3.8', '3.9', '3.10']\nsc2-version: ['4.10']\n+ env:\n+ IMAGE_NAME: burnysc2/python-sc2-docker:py_${{ matrix.python-version }}-sc2_${{ matrix.sc2-version }}-v${{ VERSION_NUMBER }}\n+ BUILD_ARGS: --build-arg PYTHON_VERSION=${{ matrix.python-version }} --build-arg SC2_VERSION=${{ matrix.sc2-version }}\nsteps:\n- uses: actions/checkout@v1\n",
        "org_msg": "Remove env. prefix",
        "sim_msg": "Test with slim images",
        "sim_diff": "diff --git a/.circleci/config.yml b/.circleci/config.yml @@ -246,7 +246,7 @@ jobs:\ntype: string\ndocker:\n- - image: python:<< parameters.python-version >>\n+ - image: python:<< parameters.python-version >>-slim\nsteps:\n- checkout\n@@ -308,7 +308,7 @@ workflows:\n- build-linux: &build\nmatrix:\nparameters:\n- python-version: [3.7.9, 3.8.9, 3.9.4, 3.10.0, 3.11.0]\n+ python-version: &python-versions [3.7.9, 3.8.9, 3.9.4, 3.10.0, 3.11.0]\n- build-linux-aarch64: *build\n- build-sdist\n- build-osx: *build\n@@ -324,7 +324,7 @@ workflows:\nparameters:\n# test the lowest supported numpy and the latest\ndependencies: [oldest-supported-numpy, numpy]\n- python-version: [3.7.9, 3.8.9, 3.9.4, 3.10.0, 3.11.0rc1]\n+ python-version: *python-versions\nexclude:\n# we don't support 1.14.5, the oldest version for Python 3.7.9\n- python-version: 3.7.9\n",
        "chatgpt_cot": "\"Update docker-ci.yml to fix environment variable reference issue and update matrix python and sc2 versions for docker image build.\""
    },
    {
        "org_diff": "diff --git a/rasa_core_sdk/forms.py b/rasa_core_sdk/forms.py @@ -123,7 +123,11 @@ class FormAction(Action):\ndef validate(self, dispatcher, tracker, domain):\n# type: (CollectingDispatcher, Tracker, Dict[Text, Any]) -> List[Dict]\n- \"\"\"\"Validate extracted requested slot else raise an error\"\"\"\n+ \"\"\"\"Validate extracted value of requested slot else raise an error\n+\n+ Add custom validation and rejection logic\n+ by subclassing this method\n+ \"\"\"\nslot_to_fill = tracker.get_slot(REQUESTED_SLOT)\nextracted_value = self.extract(dispatcher, tracker, domain)\n@@ -136,8 +140,6 @@ class FormAction(Action):\n\"\".format(slot_to_fill,\nself.name()))\n- # add custom validation logic by subclassing this method\n-\n# validation succeed, set requested slot to extracted value\nreturn [SlotSet(slot_to_fill, extracted_value)]\n",
        "org_msg": "change validate description RasaHQ/roadmap#280",
        "sim_msg": "EventForm: conditionally show \"lessons\" field\n...based on \"show_lessons\" kwarg in __init__",
        "sim_diff": "diff --git a/amy/workshops/forms.py b/amy/workshops/forms.py @@ -414,11 +414,28 @@ class EventForm(forms.ModelForm):\nclass Meta:\nmodel = Event\n- fields = ['slug', 'completed', 'start', 'end', 'host', 'administrator',\n- 'assigned_to', 'tags', 'url', 'language', 'reg_key', 'venue',\n- 'manual_attendance', 'contact',\n- 'country', 'address', 'latitude', 'longitude',\n- 'open_TTT_applications', 'curricula',\n+ fields = [\n+ 'slug',\n+ 'completed',\n+ 'start',\n+ 'end',\n+ 'host',\n+ 'administrator',\n+ 'assigned_to',\n+ 'tags',\n+ 'url',\n+ 'language',\n+ 'reg_key',\n+ 'venue',\n+ 'manual_attendance',\n+ 'contact',\n+ 'country',\n+ 'address',\n+ 'latitude',\n+ 'longitude',\n+ 'open_TTT_applications',\n+ 'curricula',\n+ 'lessons',\n'comment',\n]\nwidgets = {\n@@ -430,6 +447,7 @@ class EventForm(forms.ModelForm):\n'size': Tag.ITEMS_VISIBLE_IN_SELECT_WIDGET\n}),\n'curricula': CheckboxSelectMultiple(),\n+ 'lessons': CheckboxSelectMultiple(),\n}\nclass Media:\n@@ -442,6 +460,7 @@ class EventForm(forms.ModelForm):\n)\ndef __init__(self, *args, **kwargs):\n+ show_lessons = kwargs.pop('show_lessons', False)\nsuper().__init__(*args, **kwargs)\nself.helper.layout = Layout(\n@@ -473,6 +492,17 @@ class EventForm(forms.ModelForm):\n'comment',\n)\n+ # if we want to show lessons, we need to alter existing layout\n+ # otherwise we should remove the field so it doesn't break validation\n+ if show_lessons:\n+ self.helper.layout.insert(\n+ # insert AFTER the curricula\n+ self.helper.layout.fields.index('curricula') + 1,\n+ 'lessons',\n+ )\n+ else:\n+ del self.fields['lessons']\n+\ndef clean_slug(self):\n# Ensure slug is in \"YYYY-MM-DD-location\" format\ndata = self.cleaned_data['slug']\n",
        "chatgpt_cot": "Enhance custom validation logic in FormAction class by adding instructions for subclassing the method and improving slot extraction and error handling."
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/master_view_proxy.py b/node_manager_fkie/src/node_manager_fkie/master_view_proxy.py @@ -1794,6 +1794,24 @@ class MasterViewProxy(QWidget):\n'Error while parse parameter',\nutf8(e))\nif not diag_canceled:\n+ # check for nodelets\n+ nodenames = [n.name for n in nodes]\n+ for node in nodes:\n+ try:\n+ if node.name in cfg_nodes:\n+ n = node.launched_cfg.getNode(node.name)\n+ if n is None:\n+ raise nm.StartException(\"Node '%s' not found!\" % node.name)\n+ args = n.args.split(' ')\n+ if len(args) == 3 and args[0] == 'load':\n+ nodelet = roslib.names.ns_join(n.namespace, args[2])\n+ if nodelet not in nodenames:\n+ ret = MessageBox.question(self, 'Question', \"Nodelet manager '%s' not in current list. (Re)Start nodelet manager?\" % nodelet, buttons=MessageBox.Yes | MessageBox.No)\n+ nodenames.append(nodelet)\n+ if ret == MessageBox.Yes:\n+ self.start_nodes_by_name([nodelet], node.launched_cfg)\n+ except Exception as err:\n+ rospy.logwarn(\"Error while test for nodelets: %s\" % utf8(err))\n# put into the queue and start\nfor node in nodes:\nif node.name in cfg_nodes:\n",
        "org_msg": "node_manager_fkie: added check for restart of nodelet manager",
        "sim_msg": "Simplified grammar",
        "sim_diff": "diff --git a/packages/hagrid/hagrid/cli.py b/packages/hagrid/hagrid/cli.py @@ -21,13 +21,13 @@ def cli():\n@click.command(help=\"Start a new PyGrid domain/network node!\")\n-@click.argument(\"type\", type=click.Choice([\"domain\", \"network\"]))\n+@click.argument(\"name\", type=str)\n@click.option(\n- \"--name\",\n- default=\"\",\n+ \"--type\",\n+ default=\"domain\",\nrequired=False,\n- type=str,\n- help=\"The name of your new domain/network node. (Default: <randomly generated>)\",\n+ type=click.Choice([\"domain\", \"network\"]),\n+ help=\"The type of node you would like to deploy.\",\n)\n@click.option(\n\"--port\",\n@@ -50,7 +50,7 @@ def cli():\ntype=bool,\nhelp=\"\"\"If restarting a node that already existed, don't/do reset the database (Default: deletes the db)\"\"\",\n)\n-def launch(type, name, port, tag, keep_db, host=\"localhost\"):\n+def launch(name, type, port, tag, keep_db, host=\"localhost\"):\nif name == \"\":\nname = names.get_full_name() + \"'s \" + type.capitalize()\n@@ -110,13 +110,13 @@ def launch(type, name, port, tag, keep_db, host=\"localhost\"):\n@click.command(help=\"Stop a running PyGrid domain/network node.\")\n-@click.argument(\"type\", type=click.Choice([\"domain\", \"network\"]))\n+@click.argument(\"name\", type=str)\n@click.option(\n- \"--name\",\n- default=\"\",\n+ \"--type\",\n+ default=\"domain\",\nrequired=False,\n- type=str,\n- help=\"The name of your new domain/network node. (Default: <randomly generated>)\",\n+ type=click.Choice([\"domain\", \"network\"]),\n+ help=\"The type of node you would like to terminate.\",\n)\n@click.option(\n\"--port\",\n@@ -153,7 +153,7 @@ def land(type, name, port, tag):\nversion = check_docker()\n- motorcycle()\n+ # motorcycle()\nprint(\"Launching a \" + str(type) + \" PyGrid node on port \" + str(port) + \"!\\n\")\nprint(\" - TYPE: \" + str(type))\n",
        "chatgpt_cot": "Add functionality to check for and start nodelets, log errors if encountered, and handle missing nodelet manager in the MasterViewProxy class."
    },
    {
        "org_diff": "diff --git a/fkie_node_manager/src/fkie_node_manager/master_view_proxy.py b/fkie_node_manager/src/fkie_node_manager/master_view_proxy.py @@ -2436,13 +2436,14 @@ class MasterViewProxy(QWidget):\nrospy.logwarn(\"Error while stop node '%s': %s\", utf8(node.name), utf8(e))\nfinally:\nsocket.setdefaulttimeout(None)\n- if not success:\n- if node.pid and node.name != '/node_manager_daemon':\n- rospy.loginfo(\"Try to kill process %d of the node: %s\", node.pid, utf8(node.name))\n# wait kill_on_stop is an integer\nif hasattr(node, 'kill_on_stop') and isinstance(node.kill_on_stop, (int, float)):\ntime.sleep(float(node.kill_on_stop) / 1000.0)\nnm.nmd().monitor.kill_process(node.pid, nmdurl.nmduri(node.masteruri))\n+ elif not success:\n+ if node.pid and node.name != '/node_manager_daemon':\n+ rospy.loginfo(\"Try to kill process %d of the node: %s\", node.pid, utf8(node.name))\n+ nm.nmd().monitor.kill_process(node.pid, nmdurl.nmduri(node.masteruri))\nelif isinstance(node, NodeItem) and node.is_ghost:\n# since for ghost nodes no info is available, emit a signal to handle the\n# stop message in other master_view_proxy\n",
        "org_msg": "fkie_node_manager: force kill if kill_on_stop is defined",
        "sim_msg": "handle early lbrycrd exit in tests",
        "sim_diff": "diff --git a/lbry/wallet/orchstr8/node.py b/lbry/wallet/orchstr8/node.py @@ -228,6 +228,7 @@ class BlockchainProcess(asyncio.SubprocessProtocol):\ndef process_exited(self):\nself.stopped.set()\n+ self.ready.set()\nclass BlockchainNode:\n@@ -315,6 +316,7 @@ class BlockchainNode:\nBlockchainProcess, *command\n)\nawait self.protocol.ready.wait()\n+ assert not self.protocol.stopped.is_set()\nasync def stop(self, cleanup=True):\ntry:\n",
        "chatgpt_cot": "\"Fix the issue with killing the process of the node and update the log message in the file 'master_view_proxy.py'.\""
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/main_window.py b/node_manager_fkie/src/node_manager_fkie/main_window.py @@ -841,6 +841,8 @@ class MainWindow(QMainWindow):\nif minfo.masteruri in self.masters:\nfor _, master in self.masters.items(): # _:=uri\ntry:\n+ if not master.online and master.masteruri != minfo.masteruri:\n+ continue\n# check for running discovery service\nnew_info = master.master_info is None or master.master_info.timestamp < minfo.timestamp\n# cputimes = os.times()\n",
        "org_msg": "node_manager_fkie: skip update of offline hosts",
        "sim_msg": "SERVICES menu: fix chantools/CLN switch",
        "sim_diff": "diff --git a/home.admin/00settingsMenuServices.sh b/home.admin/00settingsMenuServices.sh @@ -43,7 +43,7 @@ OPTIONS+=(j 'JoinMarket' ${joinmarket})\nOPTIONS+=(o 'Balance of Satoshis' ${bos})\nOPTIONS+=(x 'Sphinx-Relay' ${sphinxrelay})\nOPTIONS+=(y 'PyBLOCK' ${pyblock})\n-OPTIONS+=(c 'ChannelTools (Fund Rescue)' ${chantools})\n+OPTIONS+=(h 'ChannelTools (Fund Rescue)' ${chantools})\nOPTIONS+=(w 'Download Bitcoin Whitepaper' ${whitepaper})\nOPTIONS+=(n 'Parallel Testnet services' ${testnet})\nOPTIONS+=(c 'C-lightning' ${cln})\n@@ -247,7 +247,7 @@ else\nfi\n# CHANTOOLS process choice\n-choice=\"off\"; check=$(echo \"${CHOICES}\" | grep -c \"c\")\n+choice=\"off\"; check=$(echo \"${CHOICES}\" | grep -c \"h\")\nif [ ${check} -eq 1 ]; then choice=\"on\"; fi\nif [ \"${chantools}\" != \"${choice}\" ]; then\necho \"chantools Setting changed ..\"\n",
        "chatgpt_cot": "\"Add condition to check for online status of master before continuing, to prevent unnecessary processing and improve efficiency in MainWindow class.\""
    },
    {
        "org_diff": "diff --git a/fkie_node_manager_daemon/src/fkie_node_manager_daemon/common.py b/fkie_node_manager_daemon/src/fkie_node_manager_daemon/common.py @@ -242,9 +242,11 @@ def interpret_path(path, pwd='.'):\npkg_name = groups.groups()[index]\nif pkg_name:\npkg = get_pkg_path(pkg_name)\n+ rospy.logdebug(\"rospkg.RosPack.get_path for '%s': %s\" % (pkg_name, pkg))\npath_suffix = path[groups.end():].rstrip(\"'\")\nif path_suffix.startswith('/'):\n- paths = roslib.packages.find_resource(pkg_name, path_suffix.strip(os.path.sep))\n+ paths = roslib.packages._find_resource(pkg, path_suffix.strip(os.path.sep))\n+ rospy.logdebug(\" search for resource with roslib.packages._find_resource, suffix '%s': %s\" % (path_suffix.strip(os.path.sep), paths))\nif len(paths) > 0:\n# if more then one launch file is found, take the first one\nreturn paths[0]\n",
        "org_msg": "fkie_node_manager_daemon: added debug output in searching for package and resource names",
        "sim_msg": "Prevent filename glob expansion in _msg_opts in rosbash\nThe `find` argument glob is not properly quoted resulting in bash filename\nexpansion. This leads to incorrect `find` calls.\nThis fixes issue",
        "sim_diff": "diff --git a/tools/rosbash/rosbash b/tools/rosbash/rosbash @@ -369,7 +369,7 @@ function _msg_opts {\nelse\npath=$(rospack find ${pkgname})\nif [ -d ${path}/msg ]; then\n- echo $(find -L ${path}/msg -maxdepth 1 -mindepth 1 -name *.msg ! -regex \".*/[.][^./].*\" -print0 | tr '\\000' '\\n' | sed -e \"s/.*\\/\\(.*\\)\\.msg/${pkgname}\\/\\1/g\")\n+ echo $(find -L ${path}/msg -maxdepth 1 -mindepth 1 -name '*.msg' ! -regex \".*/[.][^./].*\" -print0 | tr '\\000' '\\n' | sed -e \"s/.*\\/\\(.*\\)\\.msg/${pkgname}\\/\\1/g\")\nfi\nfi\n}\n@@ -883,7 +883,7 @@ function _msg_opts {\npath=$(rospack find ${pkgname} 2> /dev/null)\nif [ $? -eq 0 ] && [ -d ${path}/msg ]; then\n- echo $(find -L ${path}/msg -maxdepth 1 -mindepth 1 -name *.msg ! -regex \".*/[.][^./].*\" -print0 | tr '\\000' '\\n' | sed -e \"s/.*\\/\\(.*\\)\\.msg/${pkgname}\\/\\1/g\")\n+ echo $(find -L ${path}/msg -maxdepth 1 -mindepth 1 -name '*.msg' ! -regex \".*/[.][^./].*\" -print0 | tr '\\000' '\\n' | sed -e \"s/.*\\/\\(.*\\)\\.msg/${pkgname}\\/\\1/g\")\nfi\n}\n",
        "chatgpt_cot": "Fix compilation issue by using roslib.packages._find_resource instead of roslib.packages.find_resource to search for a resource in common.py file."
    },
    {
        "org_diff": "diff --git a/setup.py b/setup.py @@ -10,7 +10,7 @@ setup(\nauthor_email = \"hannes.karppila@gmail.com\",\nurl = \"https://github.com/Dentosal/python-sc2\",\nkeywords = [\"StarCraft\", \"StarCraft 2\", \"StarCraft II\", \"AI\", \"Bot\"],\n- install_requires=[\"s2clientprotocol\", \"websockets\", \"portpicker\", \"vectors\"],\n+ install_requires=[\"s2clientprotocol\", \"websockets\", \"portpicker\"],\nclassifiers = [\n\"Development Status :: 3 - Alpha\",\n",
        "org_msg": "Remove dependency \"vectors\"",
        "sim_msg": "Add minimum Python version to setup.py",
        "sim_diff": "diff --git a/setup.py b/setup.py @@ -89,6 +89,7 @@ setup(\nversion=\"2019.7.2\",\ncmdclass={'build_ext': build_ext},\nsetup_requires=['numpy>=1.14.3', 'setuptools>=18.0'],\n+ python_requires='>=3.6',\ninstall_requires=[\"numpy>=1.14.3\", \"requests\", \"ruamel.yaml>=0.15.6\",\n\"monty>=1.0.6\", \"scipy>=1.0.1\", \"pydispatcher>=2.0.5\",\n\"tabulate\", \"spglib>=1.9.9.44\", \"networkx>=2.2\",\n",
        "chatgpt_cot": "\"Remove 'vectors' from install_requires in setup.py\""
    },
    {
        "org_diff": "diff --git a/fkie_node_manager/src/fkie_node_manager/main_window.py b/fkie_node_manager/src/fkie_node_manager/main_window.py @@ -272,6 +272,12 @@ class MainWindow(QMainWindow):\nself.ui_help_home.clicked.connect(self._on_help_go_home)\nself.ui_help_back.clicked.connect(self._on_help_go_back)\nself.ui_help_forward.clicked.connect(self._on_help_go_forward)\n+ if self.ui_help_home.icon().isNull():\n+ self.ui_help_home.setText(\"Home\")\n+ if self.ui_help_back.icon().isNull():\n+ self.ui_help_back.setText(\"Back\")\n+ if self.ui_help_forward.icon().isNull():\n+ self.ui_help_forward.setText(\"Forward\")\ntry:\nscreen.test_screen()\n",
        "org_msg": "fkie_node_manager: set button text if no icons available",
        "sim_msg": "subscriptions only work with lnd",
        "sim_diff": "diff --git a/home.admin/00mainMenu.sh b/home.admin/00mainMenu.sh @@ -162,7 +162,9 @@ OPTIONS+=(SETTINGS \"Node Settings & Options\")\nOPTIONS+=(SERVICES \"Additional Apps & Services\")\nOPTIONS+=(SYSTEM \"Monitoring & Configuration\")\nOPTIONS+=(CONNECT \"Connect Apps & Show Credentials\")\n+if [ \"${lightning}\" == \"lnd\" ] || [ \"${lnd}\" == \"on\" ]; then\nOPTIONS+=(SUBSCRIBE \"Manage Subscriptions\")\n+fi\nOPTIONS+=(PASSWORD \"Change Passwords\")\nif [ \"${touchscreen}\" == \"1\" ]; then\n",
        "chatgpt_cot": "Add text to buttons if icons are null in the main window class."
    },
    {
        "org_diff": "diff --git a/Makefile b/Makefile +GREEN := $(shell tput -Txterm setaf 2)\n+WHITE := $(shell tput -Txterm setaf 7)\n+YELLOW := $(shell tput -Txterm setaf 3)\n+RESET := $(shell tput -Txterm sgr0)\n+\n.PHONY: \\\nall \\\ncheck \\\nall: check\n-check:\n+check: ##@Code Check code format\ntox\n-clean:\n+clean: ##@Code Clean tox result\nrm -rf .tox\n# Use like \"make log service=dashboard\"\n-log:\n+log: ##@Log tail special service log, Use like \"make log service=dashboard\"\ndocker-compose logs -f ${service} --tail=100\nlogs:\ndocker-compose logs -f --tail=100\n# Use like \"make redeploy service=dashboard\"\n-redeploy:\n+redeploy: ##@Service Redeploy single service, Use like \"make redeploy service=dashboard\"\nbash scripts/redeploy.sh ${service}\n-start:\n+start: ##@Service Start service\nbash scripts/start.sh\n-stop:\n+stop: ##@Service Stop service\nbash scripts/stop.sh\n-restart: stop start\n+restart: ##@Service Restart service\n+ stop start\n-setup:\n+setup: ##@Environment Setup dependency for service environment\nbash scripts/setup.sh\n+\n+HELP_FUN = \\\n+ %help; \\\n+ while(<>) { push @{$$help{$$2 // 'options'}}, [$$1, $$3] if /^([a-zA-Z\\-]+)\\s*:.*\\#\\#(?:@([a-zA-Z\\-]+))?\\s(.*)$$/ }; \\\n+ print \"usage: make [target]\\n\\n\"; \\\n+ for (sort keys %help) { \\\n+ print \"${WHITE}$$_:${RESET}\\n\"; \\\n+ for (@{$$help{$$_}}) { \\\n+ $$sep = \" \" x (32 - length $$_->[0]); \\\n+ print \" ${YELLOW}$$_->[0]${RESET}$$sep${GREEN}$$_->[1]${RESET}\\n\"; \\\n+ }; \\\n+ print \"\\n\"; }\n+\n+help: ##@other Show this help.\n+ @perl -e '$(HELP_FUN)' $(MAKEFILE_LIST)\n",
        "org_msg": "Add make help for Makefile\nAdd Help information for user in make command line.",
        "sim_msg": "Ditch vestigial Helm stuff from the Makefile.",
        "sim_diff": "diff --git a/Makefile b/Makefile @@ -21,7 +21,7 @@ SHELL = bash\n.FORCE:\n.PHONY: \\\n.FORCE clean version setup-develop print-vars \\\n- docker-login docker-push docker-images publish-website helm \\\n+ docker-login docker-push docker-images publish-website \\\nteleproxy-restart teleproxy-stop\n# MAIN_BRANCH\n@@ -271,21 +271,6 @@ website-yaml:\nwebsite: website-yaml\nVERSION=$(VERSION) bash docs/build-website.sh\n-helm:\n- echo \"Helm version $(VERSION)\"\n- cd helm && helm package --app-version \"$(VERSION)\" --version \"$(VERSION)\" ambassador/\n- curl -o tmp.yaml -k -L https://getambassador.io/helm/index.yaml\n- helm repo index helm --url https://www.getambassador.io/helm --merge tmp.yaml\n-\n-helm-update: helm\n- aws s3api put-object --bucket datawire-static-files \\\n- --key ambassador/ambassador-$(VERSION).tgz \\\n- --body helm/ambassador-$(VERSION).tgz\n- aws s3api put-object --bucket datawire-static-files \\\n- --key ambassador/index.yaml \\\n- --body helm/index.yaml\n- rm tmp.yaml helm/index.yaml helm/ambassador-$(VERSION).tgz\n-\ne2e: E2E_TEST_NAME=all\ne2e: e2e-versioned-manifests\nsource venv/bin/activate; \\\n@@ -416,7 +401,6 @@ release:\ndocker push $(AMBASSADOR_DOCKER_REPO):$(VERSION); \\\nDOC_RELEASE_TYPE=stable make website; \\\nmake SCOUT_APP_KEY=app.json STABLE_TXT_KEY=stable.txt update-aws; \\\n- make helm-update; \\\nset +x; \\\nelse \\\nprintf \"'make release' can only be run for a GA commit when VERSION is not the same as GIT_COMMIT!\\n\"; \\\n",
        "chatgpt_cot": "\"Add color variables and help target to Makefile\""
    },
    {
        "org_diff": "diff --git a/src/agent/fabric-operator/README.md b/src/agent/fabric-operator/README.md @@ -9,7 +9,7 @@ fabric CA, Orderer and Peer node using kubectl\n- [kubectl][kubectl_tool] v1.11.3+\n- Access to a Kubernetes v1.11.3+ cluster\n-- A PersistentVolume storage location for each ca, peer, and orderer.\n+- A PersistentVolume storage location with AccessMode of ReadWriteOnce for each ca, peer, and orderer.\n## Getting Started\n",
        "org_msg": "Update README.md\nAdded AccessMode",
        "sim_msg": "Added a link to the edgectl docs.",
        "sim_diff": "diff --git a/README.md b/README.md @@ -7,6 +7,7 @@ Kubernetes-based cloud native applications.\nCommands:\n+- [edgectl](docs/edgectl.md) - CLI for controlling the traffic into, out of, or within a Kubernetes cluster\n- [teleproxy](docs/teleproxy.md) - connect locally running code to a remote Kubernetes cluster\n- [watt](docs/watt.md) - trigger actions when Kubernetes and/or consul resources are updated\n- [kubeapply](docs/kubeapply.md) - apply Kubernetes manifests with templating, docker builds, and feedback\n",
        "chatgpt_cot": "Update storage location requirements for fabric CA, Orderer, and Peer nodes in README to specify AccessMode of ReadWriteOnce."
    },
    {
        "org_diff": "diff --git a/rasa_core_sdk/__init__.py b/rasa_core_sdk/__init__.py @@ -151,7 +151,20 @@ class Action(object):\ndef run(self, dispatcher, tracker, domain):\n# type: (CollectingDispatcher, Tracker, Dict[Text, Any]) -> List[dict]\n- \"\"\"Execute the side effects of this action.\"\"\"\n+ \"\"\"\n+ Execute the side effects of this action.\n+ Args:\n+ dispatcher (CollectingDispatcher): the dispatcher which is used to send\n+ messages back to the user. Use ``dipatcher.utter_message()``\n+ or any other :class:`rasa_core_sdk.executor.CollectingDispatcher` method.\n+ tracker (Tracker): the state tracker for the current\n+ user. You can access slot values using\n+ ``tracker.get_slot(slot_name)``, the most recent user\n+ message is ``tracker.latest_message.text`` and any other :class:`rasa_core_sdk.Tracker` property.\n+ domain (Dict[Text, Any]): the bot's domain\n+ Returns:\n+ List[Event]: A list of :class:`rasa_core_sdk.events.Event` instances that is returned through the endpoint\n+ \"\"\"\nraise NotImplementedError\n",
        "org_msg": "Includes run() documentation",
        "sim_msg": "core: remove unused SecurityError.",
        "sim_diff": "diff --git a/mitogen/core.py b/mitogen/core.py @@ -83,10 +83,6 @@ class Error(Exception):\nException.__init__(self, fmt)\n-class SecurityError(Error):\n- pass\n-\n-\nclass CallError(Error):\ndef __init__(self, e):\ns = '%s.%s: %s' % (type(e).__module__, type(e).__name__, e)\n",
        "chatgpt_cot": "\"Add detailed comments and documentation for the run method in the Action class to improve code readability and understanding of function parameters.\""
    },
    {
        "org_diff": "diff --git a/fkie_node_manager/src/fkie_node_manager/logscreen/screen_dock.py b/fkie_node_manager/src/fkie_node_manager/logscreen/screen_dock.py @@ -72,29 +72,44 @@ class ScreenDock(DetachableTabDock):\nself.connect_signal.connect(self._on_connect)\nself.tab_widget.close_tab_request_signal.connect(self.close_tab_requested)\nself.tab_widget.tab_removed_signal.connect(self.tab_removed)\n- self._nodes = [] # tuple of (host, nodename)\n+ self._nodes = {} # tuple of (host, nodename) : ScreenWidget\ndef connect(self, host, screen_name, nodename, user=''):\nself.connect_signal.emit(host, screen_name, nodename, user)\ndef _on_connect(self, host, screen_name, nodename, user=''):\nif (host, nodename) not in self._nodes:\n- self._nodes.append((host, nodename))\nsw = ScreenWidget(host, screen_name, nodename, str(user))\ntab_index = self.tab_widget.addTab(sw, nodename)\nself.tab_widget.setCurrentIndex(tab_index)\n+ self._nodes[(host, nodename)] = sw\n+ else:\n+ index = self.tab_widget.indexOf(self._nodes[(host, nodename)])\n+ if index >= 0:\n+ self.tab_widget.setCurrentIndex(index)\n+ else:\n+ for dia in self._open_dialogs:\n+ index = dia.tab_widget.indexOf(self._nodes[(host, nodename)])\n+ if index >= 0:\n+ dia.tab_widget.setCurrentIndex(index)\n+ dia.raise_()\n+ dia.activateWindow()\n+ break\nself.show()\ndef close_tab_requested(self, tab_widget, index):\ntab_widget.removeTab(index)\ndef tab_removed(self, widget):\n- self._nodes.remove((widget.host(), widget.name()))\n+ try:\n+ del self._nodes[(widget.host(), widget.name())]\n+ except Exception:\n+ pass\nwidget.close()\ndef finish(self):\nself.tab_widget.clear()\n- del self._nodes[:]\n+ self._nodes.clear()\ndef closeEvent(self, event):\n# close tabs on hide\n",
        "org_msg": "fkie_node_manager: select screen log tab on activate",
        "sim_msg": "bring journals/manage files/cases to fron if behind other windows",
        "sim_diff": "diff --git a/qualcoder/qualcoder.py b/qualcoder/qualcoder.py @@ -468,6 +468,9 @@ class MainWindow(QtWidgets.QMainWindow):\nself.init_ui()\nself.show()\n+ self.whichone = 0\n+\n+\ndef init_ui(self):\n\"\"\" Set up menu triggers \"\"\"\n@@ -527,6 +530,7 @@ class MainWindow(QtWidgets.QMainWindow):\nself.ui.actionContents.triggered.connect(self.help)\nself.ui.actionContents.setShortcut('Ctrl+H')\nself.ui.actionAbout.triggered.connect(self.about)\n+\nfont = 'font: ' + str(self.app.settings['fontsize']) + 'pt '\nfont += '\"' + self.app.settings['font'] + '\";'\nself.setStyleSheet(font)\n@@ -775,6 +779,7 @@ class MainWindow(QtWidgets.QMainWindow):\nfor d in self.dialogList:\nif type(d).__name__ == \"DialogCases\":\nd.show()\n+ d.activateWindow()\nreturn\nui = DialogCases(self.app, self.ui.textEdit)\nself.dialogList.append(ui)\n@@ -789,6 +794,7 @@ class MainWindow(QtWidgets.QMainWindow):\nfor d in self.dialogList:\nif type(d).__name__ == \"DialogManageFiles\":\nd.show()\n+ d.activateWindow()\nreturn\nui = DialogManageFiles(self.app, self.ui.textEdit)\nself.dialogList.append(ui)\n@@ -804,6 +810,7 @@ class MainWindow(QtWidgets.QMainWindow):\nif type(d).__name__ == \"DialogJournals\":\ntry:\nd.show()\n+ d.activateWindow()\nreturn\nexcept Exception as e:\nlogger.debug(str(e))\n",
        "chatgpt_cot": "Refactor ScreenDock class in logscreen/screen_dock.py, change _nodes from list to dictionary for efficient lookup and handling tab indexes."
    },
    {
        "org_diff": "diff --git a/docs/CONTRIBUTING.md b/docs/CONTRIBUTING.md @@ -9,7 +9,7 @@ Before taking actions, we highly recommend reading the [docs](../README.md).\nWe now have two channels for bug and questions:\n* [Jira](https://jira.hyperledger.org/secure/RapidBoard.jspa?rapidView=111): report bug issues, create to-do tasks.\n-* [Slack](https://hyperledgerproject.slack.com/archives/cello): technical discussions and questions.\n+* [Chat](https://chat.hyperledger.org/channel/cello): technical discussions and questions.\nJira tasks with `To Do` status are available for picking. If you want to handle one, assign it to yourself, and update the status to `In Progress`. Remember to mark it to `Done` when the patch is merged.\n",
        "org_msg": "Update docs slack->chat",
        "sim_msg": "Fix \"ugly\" link\nFix \"ugly\" link (\"https://www.getambassador.io/contact/\" -> \"/contact/\").",
        "sim_diff": "diff --git a/docs/docs/latest/index.md b/docs/docs/latest/index.md @@ -15,7 +15,7 @@ We're happy to help!\n* The [FAQ](about/faq) has answers to many common questions\n* Join our open source [Slack channel](https://d6e.co/slack)\n* Report bugs in [GitHub](https://github.com/datawire/ambassador)\n-* Need commercial support? [Contact us](https://www.getambassador.io/contact/)\n+* Need commercial support? [Contact us](/contact/)\n## How the Documentation is Organized\n",
        "chatgpt_cot": "Update bug and questions channels in CONTRIBUTING.md\n\nChange the Slack link to Chat link for technical discussions and questions to align with the current communication platform."
    },
    {
        "org_diff": "diff --git a/src/dashboard/src/pages/Operator/Node/index.js b/src/dashboard/src/pages/Operator/Node/index.js @@ -566,39 +566,11 @@ class Index extends PureComponent {\n</a>\n</Menu.Item>\n)}\n- {\n- record.status === 'stopped' &&\n- <Menu.Item>\n- <a onClick={() => this.operationForNode('start', record)}>\n- {intl.formatMessage({\n- id: 'app.operator.node.table.operation.start',\n- defaultMessage: 'Start',\n- })}\n- </a>\n- </Menu.Item>\n- }\n- {\n- record.status === 'running' &&\n- <Menu.Item>\n- <a onClick={() => this.operationForNode('stop', record)}>\n- {intl.formatMessage({\n- id: 'app.operator.node.table.operation.stop',\n- defaultMessage: 'Stop',\n- })}\n- </a>\n- </Menu.Item>\n- }\n- {\n- record.status === 'stopped' &&\n<Menu.Item>\n- <a onClick={() => this.operationForNode('restart', record)}>\n- {intl.formatMessage({\n- id: 'app.operator.node.table.operation.restart',\n- defaultMessage: 'Restart',\n- })}\n+ <a onClick={() => this.handleDeleteNode(record)}>\n+ {intl.formatMessage({ id: 'form.menu.item.delete', defaultMessage: 'Delete' })}\n</a>\n</Menu.Item>\n- }\n</Menu>\n);\n@@ -652,9 +624,26 @@ class Index extends PureComponent {\n}),\nrender: (text, record) => (\n<Fragment>\n- <a className={styles.danger} onClick={() => this.handleDeleteNode(record)}>\n- {intl.formatMessage({ id: 'form.menu.item.delete', defaultMessage: 'Delete' })}\n+ {\n+ record.status === 'running' &&\n+ <a onClick={() => this.operationForNode('stop', record)}>\n+ {intl.formatMessage({\n+ id: 'app.operator.node.table.operation.stop',\n+ defaultMessage: 'Stop',\n+ })}\n</a>\n+ }\n+ {\n+ record.status === 'stopped' &&\n+ <Menu.Item>\n+ <a onClick={() => this.operationForNode('start', record)}>\n+ {intl.formatMessage({\n+ id: 'app.operator.node.table.operation.start',\n+ defaultMessage: 'Start',\n+ })}\n+ </a>\n+ </Menu.Item>\n+ }\n<Divider type=\"vertical\" />\n<MoreBtn {...record} />\n</Fragment>\n",
        "org_msg": "[#issue-457]Modify node operation list\nModify node operation list, operation type",
        "sim_msg": "Make info icon a bit more subtle",
        "sim_diff": "diff --git a/gaphor/UML/classes/propertypages.glade b/gaphor/UML/classes/propertypages.glade @@ -91,14 +91,11 @@ renderers and such.</property>\n<child>\n<object class=\"GtkEventBox\" id=\"head-info-icon\">\n<property name=\"visible\">1</property>\n- <property name=\"can_focus\">1</property>\n- <property name=\"receives_default\">1</property>\n+ <property name=\"valign\">start</property>\n<signal name=\"button-release-event\" handler=\"head-info-clicked\" swapped=\"no\"/>\n<child>\n<object class=\"GtkImage\">\n<property name=\"visible\">1</property>\n- <property name=\"margin-start\">6</property>\n- <property name=\"margin-end\">6</property>\n<property name=\"icon-name\">info-symbolic</property>\n</object>\n</child>\n@@ -237,14 +234,11 @@ renderers and such.</property>\n<child>\n<object class=\"GtkEventBox\" id=\"tail-info-icon\">\n<property name=\"visible\">1</property>\n- <property name=\"can_focus\">1</property>\n- <property name=\"receives_default\">1</property>\n+ <property name=\"valign\">start</property>\n<signal name=\"button-release-event\" handler=\"tail-info-clicked\" swapped=\"no\"/>\n<child>\n<object class=\"GtkImage\">\n<property name=\"visible\">1</property>\n- <property name=\"margin-start\">6</property>\n- <property name=\"margin-end\">6</property>\n<property name=\"icon-name\">info-symbolic</property>\n</object>\n</child>\n@@ -403,12 +397,11 @@ Use &lt;b&gt;-&lt;/b&gt;/&lt;b&gt;=&lt;/b&gt; to move items up or down.</propert\n<child>\n<object class=\"GtkEventBox\" id=\"attributes-info-icon\">\n<property name=\"visible\">1</property>\n+ <property name=\"valign\">start</property>\n<signal name=\"button-release-event\" handler=\"attributes-info-clicked\" swapped=\"no\"/>\n<child>\n<object class=\"GtkImage\">\n<property name=\"visible\">1</property>\n- <property name=\"margin-start\">6</property>\n- <property name=\"margin-end\">6</property>\n<property name=\"icon-name\">info-symbolic</property>\n</object>\n</child>\n@@ -685,12 +678,11 @@ Use &lt;b&gt;-&lt;/b&gt;/&lt;b&gt;=&lt;/b&gt; to move items up or down.</propert\n<child>\n<object class=\"GtkEventBox\" id=\"operations-info-icon\">\n<property name=\"visible\">1</property>\n+ <property name=\"valign\">start</property>\n<signal name=\"button-release-event\" handler=\"operations-info-clicked\" swapped=\"no\"/>\n<child>\n<object class=\"GtkImage\">\n<property name=\"visible\">1</property>\n- <property name=\"margin-start\">6</property>\n- <property name=\"margin-end\">6</property>\n<property name=\"icon-name\">info-symbolic</property>\n</object>\n</child>\n@@ -838,12 +830,11 @@ Use &lt;b&gt;-&lt;/b&gt;/&lt;b&gt;=&lt;/b&gt; to move items up or down.</propert\n<child>\n<object class=\"GtkEventBox\" id=\"enumerations-info-icon\">\n<property name=\"visible\">1</property>\n+ <property name=\"valign\">start</property>\n<signal name=\"button-release-event\" handler=\"enumerations-info-clicked\" swapped=\"no\"/>\n<child>\n<object class=\"GtkImage\">\n<property name=\"visible\">1</property>\n- <property name=\"margin-start\">6</property>\n- <property name=\"margin-end\">6</property>\n<property name=\"icon-name\">info-symbolic</property>\n</object>\n</child>\n",
        "chatgpt_cot": "\"Refactor Node index.js to improve code readability and remove redundant conditional rendering for start and stop operations.\""
    },
    {
        "org_diff": "diff --git a/sc2/sc2process.py b/sc2/sc2process.py @@ -71,14 +71,14 @@ class SC2Process(object):\ndef _launch(self):\nreturn subprocess.Popen([\n- Paths.EXECUTABLE,\n+ str(Paths.EXECUTABLE),\n\"-listen\", self._host,\n\"-port\", str(self._port),\n\"-displayMode\", \"1\" if self._fullscreen else \"0\",\n- \"-dataDir\", Paths.BASE,\n+ \"-dataDir\", str(Paths.BASE),\n\"-tempDir\", self._tmp_dir\n],\n- cwd=Paths.CWD,\n+ cwd=str(Paths.CWD),\n#, env=run_config.env\n)\n",
        "org_msg": "Invoke str() on paths during _launch()\nThis is because the paths become WindowsPath type when executing in Windows 7 Professional",
        "sim_msg": "Fix mypy incompatible types in assignment errors",
        "sim_diff": "diff --git a/win-installer/misc/create-launcher.py b/win-installer/misc/create-launcher.py @@ -48,8 +48,8 @@ def get_build_args():\nos.path.dirname(sys.executable), python_name + \"-config\"\n)\n- cflags = subprocess.check_output([\"sh\", python_config, \"--cflags\"]).strip()\n- libs = subprocess.check_output([\"sh\", python_config, \"--libs\"]).strip()\n+ cflags = subprocess.check_output([\"sh\", python_config, \"--cflags\"], universal_newlines=True).strip()\n+ libs = subprocess.check_output([\"sh\", python_config, \"--libs\"], universal_newlines=True).strip()\ncflags = os.fsdecode(cflags)\nlibs = os.fsdecode(libs)\n",
        "chatgpt_cot": "Fix string conversion issue in SC2Process launch method. Update Paths variables to strings for subprocess.Popen parameters."
    },
    {
        "org_diff": "diff --git a/sc2/game_data.py b/sc2/game_data.py @@ -69,10 +69,19 @@ class GameData(object):\nreturn Cost(0, 0)\nclass AbilityData(object):\n- @staticmethod\n- def id_exists(ability_id: int) -> bool:\n+ ability_ids: List[int] = [] # sorted list\n+ for ability_id in AbilityId: # 1000 items Enum is slow\n+ ability_ids.append(ability_id.value)\n+ ability_ids.remove(0)\n+ ability_ids.sort()\n+\n+ @classmethod\n+ def id_exists(cls, ability_id):\nassert isinstance(ability_id, int), f\"Wrong type: {ability_id} is not int\"\n- return ability_id != 0 and ability_id in (a.value for a in AbilityId)\n+ if ability_id == 0:\n+ return False\n+ i = bisect_left(cls.ability_ids, ability_id) # quick binary search\n+ return i != len(cls.ability_ids) and cls.ability_ids[i] == ability_id\ndef __init__(self, game_data, proto):\nself._game_data = game_data\n",
        "org_msg": "Load abilities faster\nEliminated bottleneck of loading abilities data at startup time",
        "sim_msg": "Stub to future tests which don't pass yet",
        "sim_diff": "diff --git a/tests/syft/core/common/object_test.py b/tests/syft/core/common/object_test.py @@ -27,6 +27,28 @@ def test_basic_init():\nobj = ObjectWithID()\nassert isinstance(obj.id, UID)\n+#\n+# def test_immutability_of_id():\n+# \"\"\"We shouldn't allow people to modify the id of an\n+# ObjectWithID because this can create all sorts of errors.\n+#\n+# Put the other way around - blocking people from modifying\n+# the ID of an object means we can build a codebase which more\n+# firmly relies on the id being truthful. It also will avoid\n+# people initialising objects in weird ways (setting ids later).\n+# \"\"\"\n+#\n+#\n+# def test_compare():\n+#\n+# obj = ObjectWithID()\n+# obj2 = ObjectWithID()\n+#\n+# assert obj != obj2\n+#\n+# obj.id = obj2.id\n+#\n+# assert obj == obj2\n################## CLASS METHODS #######################\n###################### SERDE ##########################\n\\ No newline at end of file\n",
        "chatgpt_cot": "\"Optimize AbilityData class for faster ability ID search and fix type check assertion in id_exists method\""
    },
    {
        "org_diff": "diff --git a/sc2/sc2process.py b/sc2/sc2process.py @@ -157,9 +157,11 @@ class SC2Process:\nawait asyncio.sleep(1)\ntry:\nself._session = aiohttp.ClientSession()\n- ws = await self._session.ws_connect(\n- self.ws_url, timeout=aiohttp.client_ws.ClientWSTimeout(ws_close=120)\n- )\n+ ws = await self._session.ws_connect(self.ws_url, timeout=120)\n+ # FIXME fix deprecation warning in for future aiohttp version\n+ # ws = await self._session.ws_connect(\n+ # self.ws_url, timeout=aiohttp.client_ws.ClientWSTimeout(ws_close=120)\n+ # )\nlogger.debug(\"Websocket connection ready\")\nreturn ws\nexcept aiohttp.client_exceptions.ClientConnectorError:\n",
        "org_msg": "Roll back deprecation fix, add note for future",
        "sim_msg": "Committing final fix, replacing None with 999999 to avoid timeout and overriding the default timeout settings in any setting",
        "sim_diff": "diff --git a/syft/workers/websocket_client.py b/syft/workers/websocket_client.py @@ -38,8 +38,8 @@ class WebsocketClientWorker(BaseWorker):\n# creates the connection with the server which gets held open until the\n# WebsocketClientWorker is garbage collected.\n- # Daniele Gadler: Fix timeout issues on the server-side\n- self.ws = websocket.create_connection(self.uri, max_size=None, timeout=None)\n+ # Daniele Gadler: Also avoid the server from timing out on the server-side\n+ self.ws = websocket.create_connection(self.uri, max_size=None, timeout=9999999)\nsuper().__init__(hook, id, data, is_client_worker, log_msgs, verbose)\n@@ -52,6 +52,7 @@ class WebsocketClientWorker(BaseWorker):\nreturn sy.serde.deserialize(response)\ndef _send_msg(self, message: bin, location) -> bin:\n+ self.ws.settimeout(9999999)\nraise RuntimeError(\n\"_send_msg should never get called on a \",\n\"WebsocketClientWorker. Did you accidentally \"\n@@ -72,7 +73,7 @@ class WebsocketClientWorker(BaseWorker):\nself.ws.shutdown()\ntime.sleep(1)\n# Daniele Gadler: also avoid timing out on the server-side\n- self.ws = websocket.create_connection(self.uri, max_size=None, timeout=None)\n+ self.ws = websocket.create_connection(self.uri, max_size=None, timeout=9999999)\nlogger.warning(\"Created new websocket connection\")\ntime.sleep(0.1)\nresponse = self._receive_action(message)\n",
        "chatgpt_cot": "Fix deprecation warning in websocket connection method in SC2Process file. Updated timeout parameter to resolve future aiohttp version compatibility."
    },
    {
        "org_diff": "diff --git a/fkie_node_manager/src/fkie_node_manager/message_frame.py b/fkie_node_manager/src/fkie_node_manager/message_frame.py @@ -158,7 +158,8 @@ class MessageFrame(QFrame):\n7: nm.settings().pixmap('crystal_clear_binary.png').scaled(self.ICON_SIZE, self.ICON_SIZE, Qt.IgnoreAspectRatio, Qt.SmoothTransformation),\n8: nm.settings().pixmap('crystal_clear_no_io.png').scaled(self.ICON_SIZE, self.ICON_SIZE, Qt.IgnoreAspectRatio, Qt.SmoothTransformation),\n9: nm.settings().pixmap('crystal_clear_run_zeroconf.png').scaled(self.ICON_SIZE, self.ICON_SIZE, Qt.IgnoreAspectRatio, Qt.SmoothTransformation),\n- 10: nm.settings().pixmap('sekkyumu_restart.png').scaled(self.ICON_SIZE, self.ICON_SIZE, Qt.IgnoreAspectRatio, Qt.SmoothTransformation)\n+ 10: nm.settings().pixmap('crystal_clear_run_zeroconf.png').scaled(self.ICON_SIZE, self.ICON_SIZE, Qt.IgnoreAspectRatio, Qt.SmoothTransformation),\n+ 11: nm.settings().pixmap('sekkyumu_restart.png').scaled(self.ICON_SIZE, self.ICON_SIZE, Qt.IgnoreAspectRatio, Qt.SmoothTransformation)\n}\nself._new_request = False\nself._in_resp_process = False\n",
        "org_msg": "fkie_node_manager: fixed crash after change of configuration",
        "sim_msg": "Added waveform - usses ffmpeg\nffmpeg must be installed to create a waveform image",
        "sim_diff": "diff --git a/qualcoder/view_av.py b/qualcoder/view_av.py @@ -34,6 +34,7 @@ import os\nimport platform\nfrom random import randint\nimport re\n+import subprocess\nimport sys\nimport time\nimport traceback\n@@ -3452,6 +3453,9 @@ class DialogViewAV(QtWidgets.QDialog):\nself.ui.textEdit.installEventFilter(self)\nself.installEventFilter(self) # for rewind, play/stop\n+ # Get waveform\n+ self.get_waveform()\n+\n# Get the transcription text and fill textedit\nself.transcription = None\ncur = self.app.conn.cursor()\n@@ -3661,6 +3665,28 @@ class DialogViewAV(QtWidgets.QDialog):\nelse:\nself.ui.pushButton_speechtotext.setToolTip(_(\"Speech to text disabled.\\nTranscript contains text.\"))\n+ def get_waveform(self):\n+ \"\"\" Create waveform image in the audio folder. Apply image to label_waveform.\n+ Requires installed ffmpeg \"\"\"\n+\n+ img_path = self.app.project_path + \"/audio/waveform.png\"\n+ if os.path.exists(img_path):\n+ os.remove(img_path)\n+ command = 'ffmpeg -i \"' + self.abs_path + '\"'\n+ command += ' -filter_complex'\n+ command += ' \"aformat=channel_layouts=mono,compand,showwavespic=s=640x120'\n+ if self.app.settings['stylesheet'] == \"dark\":\n+ command += ':colors=#f89407\"'\n+ else:\n+ command += ':colors=#0A0A0A\"'\n+ command += ' -frames:v 1 '\n+ command += '\"' + self.app.project_path + '/audio/waveform.png\"'\n+ subprocess.run(command, shell=True)\n+ #print(subprocess.run(command, shell=True))\n+ pm = QtGui.QPixmap()\n+ pm.load(img_path)\n+ self.ui.label_waveform.setPixmap(QtGui.QPixmap(pm).scaled(1020, 60))\n+\ndef get_cases_codings_annotations(self):\n\"\"\" Get all linked cases, coded text and annotations for this file \"\"\"\n",
        "chatgpt_cot": "Update image scaling in MessageFrame to use correct icon and fix display issue."
    },
    {
        "org_diff": "diff --git a/test/autotest_bot.py b/test/autotest_bot.py @@ -219,7 +219,7 @@ class TestBot(sc2.BotAI):\nPointlike((2, 2)),\nPointlike((-2, -2))\n]) == Pointlike((-2, -2))\n- assert p1.offset(Pointlike((-1, -1))) == Pointlike((1.3, 1.7))\n+ assert p1.offset(Pointlike((-1, -1))) == Pointlike((1.3, 1.7)), f\"{p1.offset(Pointlike((-1, -1)))} is not equal to {Pointlike((1.3, 1.7))}\"\nassert p1.offset(Pointlike((-1, 1))) == Pointlike((1.3, 3.7))\nassert p1.towards(Pointlike((2.3, 50)), 5) == Pointlike((2.3, 7.7))\n# testing backwards aswell\n",
        "org_msg": "Add assert string message",
        "sim_msg": "Added test comment for np.array simplification",
        "sim_diff": "diff --git a/test/test_serde.py b/test/test_serde.py @@ -128,6 +128,10 @@ class TestSimplify(object):\n# make sure outer type is correct\nassert type(output) == tuple\n+ # make sure the object type ID is correct\n+ # (0 for torch.Tensor)\n+ assert output[0] == 0\n+\n# make sure inner type is correct\nassert type(output[1]) == tuple\n@@ -138,8 +142,20 @@ class TestSimplify(object):\nassert type(output[1][1]) == bytes\ndef test_ndarray_simplify(self):\n+ \"\"\"This tests our ability to simplify numpy.array objects\n+\n+ At the time of writing, arrays simplify to an object inside\n+ of a tuple which specifies the ID for the np.array type (6) so\n+ that the detailer knows to turn the simplifed form to a np.array\n+ \"\"\"\n+\ninput = numpy.random.random((100, 100))\noutput = _simplify(input)\n+\n+ # make sure simplified type ID is correct\n+ assert output[0] == 6\n+\n+ # make sure serialized form is correct\nassert type(output[1][0]) == bytes\nassert output[1][1] == input.shape\nassert output[1][2] == input.dtype.name\n",
        "chatgpt_cot": "Add assertion message for offset method in TestBot to improve readability and debugging of the code."
    },
    {
        "org_diff": "diff --git a/master_discovery_fkie/src/master_discovery_fkie/common.py b/master_discovery_fkie/src/master_discovery_fkie/common.py @@ -40,6 +40,7 @@ import rospy\nEMPTY_PATTERN = re.compile('\\b', re.I)\n+IP4_PATTERN = re.compile(r\"^\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}$\")\nMASTERURI = None\n@@ -90,6 +91,8 @@ def subdomain(hostname):\n'''\nif hostname is None:\nreturn None\n+ if IP4_PATTERN.match(hostname):\n+ return hostname\nreturn hostname.split('.')[0]\n",
        "org_msg": "do not remove domain names by IP addresses",
        "sim_msg": "Adding soft hyphen to the whitespace-like character list",
        "sim_diff": "diff --git a/app/misc.py b/app/misc.py @@ -52,7 +52,7 @@ redis = Redis(host=config.CACHE_REDIS_HOST,\n# Regex that matches VALID user and sub names\nallowedNames = re.compile(\"^[a-zA-Z0-9_-]+$\")\n-WHITESPACE = \"\\u0009\\u000A\\u000B\\u000C\\u000D\\u0020\\u0085\\u00A0\\u1680\\u2000\\u2001\\u2002\\u2003\\u2004\\u2005\\u2006\\u2007\\u2008\\u2009\\u200a\\u200b2029\\u202f\\u205f\\u3000\\u180e\\u200b\\u200c\\u200d\\u2060\\ufeff\"\n+WHITESPACE = \"\\u0009\\u000A\\u000B\\u000C\\u000D\\u0020\\u0085\\u00A0\\u1680\\u2000\\u2001\\u2002\\u2003\\u2004\\u2005\\u2006\\u2007\\u2008\\u2009\\u200a\\u200b\\u2029\\u202f\\u205f\\u3000\\u180e\\u200b\\u200c\\u200d\\u2060\\ufeff\\u00AD\"\nclass SiteUser(object):\n",
        "chatgpt_cot": "Add an IP4_PATTERN regular expression to match IP addresses in subdomain function."
    },
    {
        "org_diff": "diff --git a/fkie_node_manager/src/fkie_node_manager/master_view_proxy.py b/fkie_node_manager/src/fkie_node_manager/master_view_proxy.py @@ -1616,7 +1616,7 @@ class MasterViewProxy(QWidget):\nif len(selectedNodes) > 1 or len(selectedGroups) > 0:\nrestartable_nodes = [sn for sn in selectedNodes if len(sn.cfgs) > 0 and not self._is_in_ignore_list(sn.name)]\nrestartable_nodes_with_launchfiles = [sn for sn in selectedNodes if sn.has_launch_cfgs(sn.cfgs) > 0 and not self._is_in_ignore_list(sn.name)]\n- killable_nodes = [sn for sn in selectedNodes if sn.node_info.pid is not None and not self._is_in_ignore_list(sn.name)]\n+ killable_nodes = [sn for sn in selectedNodes if not self._is_in_ignore_list(sn.name)]\nunregisterble_nodes = [sn for sn in selectedNodes if sn.node_info.pid is None and sn.node_info.uri is not None and sn.node_info.isLocal and not self._is_in_ignore_list(sn.name)]\n# add description for multiple selected nodes\nif restartable_nodes or killable_nodes or unregisterble_nodes:\n",
        "org_msg": "fkie_node_manager: show kill button for nodes without valid PID, too",
        "sim_msg": "do not require perf_event cgroup enabled for StaticNode",
        "sim_diff": "diff --git a/wca/extra/static_node.py b/wca/extra/static_node.py @@ -45,7 +45,8 @@ class StaticNode(Node):\ntasks_labels: Optional[Dict[str, Dict[str, str]]] = None\n_BASE_CGROUP_PATH = '/sys/fs/cgroup'\n- _REQUIRED_CONTROLLERS = ('cpu', 'cpuacct', 'perf_event')\n+ _REQUIRED_CONTROLLERS = ('cpu', 'cpuacct')\n+ #, 'perf_event')\ndef get_tasks(self) -> List[Task]:\ntasks = []\n",
        "chatgpt_cot": "Refactor killable_nodes condition in MasterViewProxy to simplify logic and improve readability."
    },
    {
        "org_diff": "diff --git a/docker-compose.yml b/docker-compose.yml version: '3.2'\nservices:\n- # nginx as front end for the operator dashboard\n- nginx:\n- image: hyperledger/cello-nginx\n- hostname: cello-nginx\n- container_name: cello-nginx\n- restart: always\n- deploy:\n- resources:\n- limits:\n- cpus: '0.50'\n- memory: 2048M\n- reservations:\n- cpus: '0.10'\n- memory: 256M\n- ports:\n- - \"80:80\"\n- - \"8080:8080\"\n- environment:\n- - BACKEND=cello-operator-dashboard\n- - PORT=8080\n- - USERNAME=admin\n- - PASSWORD=pass\n+ # nginx as front end for the services, disable now\n+ #nginx:\n+ # image: hyperledger/cello-nginx\n+ # hostname: cello-nginx\n+ # container_name: cello-nginx\n+ # restart: always\n+ # deploy:\n+ # resources:\n+ # limits:\n+ # cpus: '0.50'\n+ # memory: 2048M\n+ # reservations:\n+ # cpus: '0.10'\n+ # memory: 256M\n+ # ports:\n+ # - \"80:80\"\n+ # - \"8080:8080\"\n+ # environment:\n+ # - BACKEND=cello-operator-dashboard\n+ # - PORT=8080\n+ # - USERNAME=admin\n+ # - PASSWORD=pass\n# cello dashboard service for network operator\noperator-dashboard:\n@@ -51,8 +51,8 @@ services:\n- STATIC_FOLDER=$STATIC_FOLDER\n- TEMPLATE_FOLDER=$TEMPLATE_FOLDER\n- ENABLE_EMAIL_ACTIVE=$ENABLE_EMAIL_ACTIVE\n- expose:\n- - \"8080\"\n+ ports:\n+ - \"8080:8080\"\n#TODO: need to follow other images to put at dockerhub\nuser-dashboard:\n@@ -94,8 +94,8 @@ services:\n- MONGO_DB=dev\n- DEBUG=True # in debug mode, service will auto-restart\n- LOG_LEVEL=DEBUG # what level log will be output\n- expose:\n- - \"80\"\n+ ports:\n+ - \"80:80\"\n# cello watchdog service\nwatchdog:\n",
        "org_msg": "Disable nginx frontend\nThe existing nginx config has bugs to block dashboard access.\nThe nginx way is not perfect for authentication.\nWe will implement membership management inside the flask framework.\nHence will disable nginx but allow users to adopt it manually.",
        "sim_msg": "Clean up compose file",
        "sim_diff": "diff --git a/docker-compose.yaml b/docker-compose.yaml @@ -2,32 +2,6 @@ version: '3.7'\nservices:\n-\n-# discovery:\n-# image: \"scaleoutsystems/discovery:latest\"\n-# build:\n-# context: .\n-# dockerfile: components/discovery/Dockerfile\n-# environment:\n-# - GET_HOSTS_FROM=dns\n-# - ALLIANCE_UID=${ALLIANCE_UID}\n-# - CONTROLLER_HOST=${FEDN_CONTROLLER_HOST}\n-# - CONTROLLER_PORT=${FEDN_CONTROLLER_PORT}\n-# - MONGO_HOST=${FEDN_MONGO_HOST}\n-# - MONGO_PORT=${FEDN_MONGO_PORT}\n-# - MDBUSR=${MDBUSR}\n-# - MDBPWD=${MDBPWD}\n-# - DASHBOARD_HOST=${FEDN_DASHBOARD_HOST}\n-# - DASHBOARD_PORT=${FEDN_DASHBOARD_PORT}\n-# command: sh -c \"scripts/run_web.sh\"\n-# volumes:\n-# - ./components/discovery/:/app/\n-# - ./sdk:/app/sdk\n-# - ./cli:/app/cli\n-# ports:\n-# - \"${FEDN_CONTROLLER_PORT}:${FEDN_CONTROLLER_PORT}\"\n-\n-\nminio:\nimage: minio/minio:latest\nhostname: minio\n",
        "chatgpt_cot": "\"Disable nginx service, update port mapping for operator-dashboard and user-dashboard, and add comments for future reference in docker-compose.yml\""
    },
    {
        "org_diff": "diff --git a/sc2/bot_ai.py b/sc2/bot_ai.py @@ -590,7 +590,7 @@ class BotAI(DistanceCalculation):\ndef owned_expansions(self) -> Dict[Point2, Unit]:\n\"\"\"List of expansions owned by the player.\"\"\"\nowned = {}\n- for el in self.expansion_locations:\n+ for el in self.expansion_locations_list:\ndef is_near_to_expansion(t):\nreturn t.distance_to(el) < self.EXPANSION_GAP_THRESHOLD\n@@ -882,8 +882,8 @@ class BotAI(DistanceCalculation):\nasync def find_placement(\nself,\n- building: UnitTypeId,\n- near: Union[Unit, Point2],\n+ building: Union[UnitTypeId, AbilityId],\n+ near: Point2,\nmax_distance: int = 20,\nrandom_alternative: bool = True,\nplacement_step: int = 2,\n@@ -893,7 +893,7 @@ class BotAI(DistanceCalculation):\nExample::\n- if self.townahlls:\n+ if self.townhalls:\ncc = self.townhalls[0]\ndepot_position = await self.find_placement(UnitTypeId.SUPPLYDEPOT, near=cc)\n@@ -901,17 +901,16 @@ class BotAI(DistanceCalculation):\n:param near:\n:param max_distance:\n:param random_alternative:\n- :param placement_step: \"\"\"\n+ :param placement_step:\n+ :param addon_place: \"\"\"\nassert isinstance(building, (AbilityId, UnitTypeId))\nassert isinstance(near, Point2), f\"{near} is no Point2 object\"\nif isinstance(building, UnitTypeId):\n- building = self._game_data.units[building.value].creation_ability\n- else: # AbilityId\n- building = self._game_data.abilities[building.value]\n+ building = self._game_data.units[building.value].creation_ability.id\n- if await self.can_place(building, near) and (\n+ if await self.can_place_single(building, near) and (\nnot addon_place or await self.can_place_single(UnitTypeId.SUPPLYDEPOT, near.offset((2.5, -0.5)))\n):\nreturn near\n@@ -929,15 +928,16 @@ class BotAI(DistanceCalculation):\n+ [(distance, dy) for dy in range(-distance, distance + 1, placement_step)]\n)\n]\n- res = await self._client.query_building_placement(building, possible_positions)\n- possible = [p for r, p in zip(res, possible_positions) if r == ActionResult.Success]\n+ res = await self._client._query_building_placement_fast(building, possible_positions)\n+ # Filter all positions if building can be placed\n+ possible = [p for r, p in zip(res, possible_positions) if r]\nif addon_place:\n- res = await self._client.query_building_placement(\n- self._game_data.units[UnitTypeId.SUPPLYDEPOT.value].creation_ability,\n- [p.offset((2.5, -0.5)) for p in possible],\n+ # Filter remaining positions if addon can be placed\n+ res = await self._client._query_building_placement_fast(\n+ AbilityId.TERRANBUILDDROP_SUPPLYDEPOTDROP, [p.offset((2.5, -0.5)) for p in possible],\n)\n- possible = [p for r, p in zip(res, possible) if r == ActionResult.Success]\n+ possible = [p for r, p in zip(res, possible) if r]\nif not possible:\ncontinue\n",
        "org_msg": "Fix find_placement",
        "sim_msg": "[pyclustering.tsp.antcolony] Improve unit-tests stability.",
        "sim_diff": "diff --git a/pyclustering/tsp/tests/integration/it_antcolony.py b/pyclustering/tsp/tests/integration/it_antcolony.py @@ -33,7 +33,6 @@ from pyclustering.utils import euclidean_distance;\nclass Test(unittest.TestCase):\n-\ndef getCityDistance(self, result, object_locations, citiesDistRepresent):\nvisited_objects = [False] * len(result.object_sequence)\ncurrent_distance = 0.0\n@@ -51,9 +50,13 @@ class Test(unittest.TestCase):\nreturn current_distance\n+\ndef templateTspSolving(self, parameters, object_locations, expected_length,\ncitiesDistRepresent=wrapper.CITIES_DISTANCE_SET_BY_LIST_OF_COORDINATES):\n+ testing_result = False;\n+ testing_attempts = 5;\n+ for _ in range(testing_attempts):\nif parameters is None:\n# default parameters\nparameters = antcolony_parameters()\n@@ -65,18 +68,31 @@ class Test(unittest.TestCase):\nelse:\nresult = algorithm.process(object_locations)\n- assert result.shortest_length == expected_length\n- assert len(result.object_sequence) == len(object_locations)\n+ if (result.shortest_length != expected_length):\n+ continue;\n+\n+ if (len(result.object_sequence) != len(object_locations)):\n+ continue;\ncurrent_distance = self.getCityDistance(result, object_locations, citiesDistRepresent)\n- assert current_distance == expected_length\n+\n+ if (current_distance != expected_length):\n+ continue;\n+\n+ testing_result = True;\n+ break;\n+\n+ assert testing_result == True;\n+\ndef testSixObjects(self):\nself.templateTspSolving(None, [[0.0, 1.0], [1.0, 1.0], [2.0, 1.0], [0.0, 0.0], [1.0, 0.0], [2.0, 0.0]], 6.0)\n+\ndef testSimpleSixObjectsSequence(self):\nself.templateTspSolving(None, [[0.0, 0.0], [0.0, 1.0], [0.0, 2.0], [0.0, 3.0], [0.0, 4.0], [0.0, 5.0]], 10.0)\n+\ndef testSmallestPathFourCitiesByMatrix(self):\nmatrix = [[0.0, 1.0, 30.0, 99.0],\n[1.0, 0.0, 1.0, 30.0],\n",
        "chatgpt_cot": "Refactor BotAI class in bot_ai.py, change method name, update method parameters, improve building placement logic, and enhance addon placement functionality."
    },
    {
        "org_diff": "diff --git a/fkie_node_manager/src/fkie_node_manager/nmd_client/monitor_channel.py b/fkie_node_manager/src/fkie_node_manager/nmd_client/monitor_channel.py @@ -113,7 +113,7 @@ class MonitorChannel(ChannelInterface):\nself.close_channel(channel, uri)\ndef get_user_threaded(self, grpc_url='grpc://localhost:12321'):\n- self._threads.start_thread(\"gut_%s\" % grpc_url, target=self.get_user, args=(grpc_url, True))\n+ self._threads.start_thread(\"gut_%s\" % grpc_url, target=self.get_user, args=(grpc_url,))\ndef get_user(self, grpc_url='grpc://localhost:12321'):\nrospy.logdebug(\"get user from %s\" % (grpc_url))\n",
        "org_msg": "fkie_node_manager: fixed threaded call to get remote user",
        "sim_msg": "Remove consensus member\n- Left out ChannelService.__consensus to be remove in",
        "sim_diff": "diff --git a/loopchain/channel/channel_service.py b/loopchain/channel/channel_service.py @@ -48,7 +48,6 @@ class ChannelService:\nself.__peer_auth: Signer = None\nself.__broadcast_scheduler: BroadcastScheduler = None\nself.__rs_client: RestClient = None\n- self.__consensus = None\nself.__timer_service = TimerService()\nself.__node_subscriber: NodeSubscriber = None\n",
        "chatgpt_cot": "Fix thread start method argument in MonitorChannel file. Updated get_user_threaded to pass correct arguments to get_user method, resolving potential runtime issues."
    },
    {
        "org_diff": "diff --git a/src/agent/ansible/roles/deploy_compose/fabricsetup/templates/peer-compose.j2 b/src/agent/ansible/roles/deploy_compose/fabricsetup/templates/peer-compose.j2 @@ -15,6 +15,8 @@ services:\n{{ peer.name }}:\ncontainer_name: {{ peer.name }}\nimage: {{ fabric.repo.url }}fabric-peer:{{ fabric.baseimage_tag }}\n+ expose:\n+ - \"7051\"\nnetwork_mode: bridge\nhostname: {{ peer.name }}\nenvironment:\n",
        "org_msg": "Enable access to peer via docker network\nIt does this by exposing a\nsingle port on the internal\nnetwork so that proxies and\netc can access the peer via\nthe docker network.",
        "sim_msg": "One more missing bracket",
        "sim_diff": "diff --git a/Jenkinsfile b/Jenkinsfile @@ -152,12 +152,13 @@ pipeline {\ndir('./ansible') {\nwithCredentials([file(credentialsId: 'ansible-bbop-local-slave', variable: 'DEPLOY_LOCAL_IDENTITY')]) {\n-\necho 'Push master out to public Blazegraph'\nretry(3){\nsh 'ansible-playbook update-kg-hub-endpoint.yaml --inventory=hosts.local-rdf-endpoint --private-key=\"$DEPLOY_LOCAL_IDENTITY\" -e target_user=bbop --extra-vars=\"endpoint=internal\"'\n}\n}\n+\n+ }\n}\n}\n",
        "chatgpt_cot": "Add port 7051 to peer-compose.j2 template for fabric peer container to expose the port."
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/ssh_handler.py b/node_manager_fkie/src/node_manager_fkie/ssh_handler.py # POSSIBILITY OF SUCH DAMAGE.\nimport os\n+import paramiko\nimport shlex\nimport sys\nimport threading\n@@ -41,13 +42,6 @@ from supervised_popen import SupervisedPopen\nimport node_manager_fkie as nm\n-try:\n- import paramiko\n-except Exception, e:\n- print >> sys.stderr, e\n- sys.exit(1)\n-\n-\nclass AuthenticationRequest(Exception):\n''' '''\n",
        "org_msg": "raise an error now if paramiko is not available",
        "sim_msg": "added ruckus first beta",
        "sim_diff": "diff --git a/netmiko/ssh_dispatcher.py b/netmiko/ssh_dispatcher.py @@ -45,6 +45,7 @@ from netmiko.ovs import OvsLinuxSSH\nfrom netmiko.paloalto import PaloAltoPanosSSH\nfrom netmiko.pluribus import PluribusSSH\nfrom netmiko.quanta import QuantaMeshSSH\n+from netmiko.ruckus import RuckusFastironSSH\nfrom netmiko.terminal_server import TerminalServerSSH\nfrom netmiko.terminal_server import TerminalServerTelnet\nfrom netmiko.ubiquiti import UbiquitiEdgeSSH\n@@ -100,6 +101,7 @@ CLASS_MAPPER_BASE = {\n'paloalto_panos': PaloAltoPanosSSH,\n'pluribus': PluribusSSH,\n'quanta_mesh': QuantaMeshSSH,\n+ 'ruckus_fastiron':RuckusFastironSSH,\n'ubiquiti_edge': UbiquitiEdgeSSH,\n'vyatta_vyos': VyOSSSH,\n'vyos': VyOSSSH,\n",
        "chatgpt_cot": "Add paramiko import, remove try-except block, and clean up unnecessary code in ssh_handler.py."
    },
    {
        "org_diff": "diff --git a/sc2/bot_ai.py b/sc2/bot_ai.py @@ -919,6 +919,9 @@ class BotAI(DistanceCalculation):\n# If you want to save up money for mutalisks, you can now save up once the spire is nearly completed:\nspire_almost_completed: bool = self.structure_type_build_progress(UnitTypeId.SPIRE) > 0.75\n+ # If you have a Hive completed but no lair, this function returns 1.0 for the following:\n+ self.structure_type_build_progress(UnitTypeId.LAIR)\n+\n# Assume you have 2 command centers in production, one has 0.5 build_progress and the other 0.2, the following returns 0.5\nhighest_progress_of_command_center: float = self.structure_type_build_progress(UnitTypeId.COMMANDCENTER)\n@@ -929,16 +932,18 @@ class BotAI(DistanceCalculation):\n), f\"Needs to be int or UnitTypeId, but was: {type(structure_type)}\"\nif isinstance(structure_type, int):\nstructure_type_value: int = structure_type\n+ structure_type = UnitTypeId(structure_type_value)\nelse:\nstructure_type_value = structure_type.value\nassert structure_type_value, f\"structure_type can not be 0 or NOTAUNIT, but was: {structure_type_value}\"\n+ equiv_values: Set[int] = {structure_type_value} | {\n+ s_type.value for s_type in EQUIVALENTS_FOR_TECH_PROGRESS.get(structure_type, set())\n+ }\n+ creation_ability: AbilityData = self._game_data.units[structure_type_value].creation_ability\nmax_value = max(\n- (s for s in self.structures if s._proto.unit_type == structure_type_value),\n- key=lambda structure: structure.build_progress,\n- default=0,\n+ [s.build_progress for s in self.structures if s._proto.unit_type in equiv_values]\n+ + [self._abilities_all_units[1].get(creation_ability, 0)]\n)\n- if isinstance(max_value, Unit):\n- return max_value.build_progress\nreturn max_value\ndef tech_requirement_progress(self, structure_type: UnitTypeId) -> float:\n",
        "org_msg": "Attempt to fix structure_type_build_progress once more",
        "sim_msg": "try longer timeout and loop iteration to actually ge them all killed",
        "sim_diff": "diff --git a/GearBot/Bot/TheRealGearBot.py b/GearBot/Bot/TheRealGearBot.py @@ -140,7 +140,7 @@ async def fill_cache(bot):\nwhile len(bot.missing_guilds) > 0:\ntry:\ntasks = [asyncio.create_task(cache_guild(bot, guild_id)) for guild_id in bot.missing_guilds]\n- await asyncio.wait_for(asyncio.gather(*tasks), 90)\n+ await asyncio.wait_for(asyncio.gather(*tasks), 600)\nexcept (CancelledError, concurrent.futures._base.CancelledError):\npass\nexcept concurrent.futures._base.TimeoutError:\n@@ -148,6 +148,7 @@ async def fill_cache(bot):\nawait GearbotLogging.bot_log(f\"{Emoji.get_chat_emoji('NO')} Cluster {bot.cluster} timed out fetching member chunks canceling all pending fetches to try again!\")\nfor task in tasks:\ntask.cancel()\n+ await asyncio.sleep(1)\ncontinue\nexcept Exception as e:\nawait handle_exception(\"Fetching member info\", bot, e)\n",
        "chatgpt_cot": "\"Add functionality to return build progress for equivalent structure types in BotAI\""
    },
    {
        "org_diff": "diff --git a/node_manager_daemon_fkie/src/node_manager_daemon_fkie/launcher.py b/node_manager_daemon_fkie/src/node_manager_daemon_fkie/launcher.py @@ -111,7 +111,7 @@ def create_start_config(node, launchcfg, executable='', masteruri=None, loglevel\nglobal_params = get_global_params(launchcfg.roscfg)\nresult.params.update(global_params)\nrospy.loginfo(\"add global parameter for '%s'\" % launchcfg.filename)\n- rospy.logdebug(\"add global parameter:\\n %s\", '\\n '.join(\"%s%s\" % (utf8(v)[:80], '...' if len(utf8(v)) > 80 else'') for v in global_params.values()))\n+ rospy.logdebug(\"add global parameter:\\n %s\", '\\n '.join(\"%s: %s%s\" % (key, utf8(val)[:80], '...' if len(utf8(val)) > 80 else'') for key, val in global_params.items()))\nlaunchcfg.global_param_done.append(result.masteruri)\n# add params and clear_params\nnodens = \"%s%s%s\" % (n.namespace, n.name, rospy.names.SEP)\n@@ -122,7 +122,7 @@ def create_start_config(node, launchcfg, executable='', masteruri=None, loglevel\nif cparam.startswith(nodens):\nresult.clear_params.append(cparam)\nrospy.logdebug(\"set delete parameter:\\n %s\", '\\n '.join(result.clear_params))\n- rospy.logdebug(\"add parameter:\\n %s\", '\\n '.join(\"%s%s\" % (utf8(v)[:80], '...' if len(utf8(v)) > 80 else'') for v in result.params.values()))\n+ rospy.logdebug(\"add parameter:\\n %s\", '\\n '.join(\"%s: %s%s\" % (key, utf8(val)[:80], '...' if len(utf8(val)) > 80 else '') for key, val in result.params.items()))\nreturn result\n",
        "org_msg": "fix debug output while launch node",
        "sim_msg": "retry startup",
        "sim_diff": "diff --git a/lbrynet/lbrynet_daemon/DaemonControl.py b/lbrynet/lbrynet_daemon/DaemonControl.py @@ -114,7 +114,7 @@ def update_settings_from_args(args):\n@defer.inlineCallbacks\n-def start_server_and_listen(launchui, use_auth, analytics_manager):\n+def start_server_and_listen(launchui, use_auth, analytics_manager, max_tries=5):\n\"\"\"The primary entry point for launching the daemon.\nArgs:\n@@ -124,13 +124,19 @@ def start_server_and_listen(launchui, use_auth, analytics_manager):\n\"\"\"\nanalytics_manager.send_server_startup()\nlog_support.configure_analytics_handler(analytics_manager)\n+ tries = 1\n+ while tries < max_tries:\n+ log.info('Making attempt %s / %s to startup', tries, max_tries)\ntry:\ndaemon_server = DaemonServer(analytics_manager)\nyield daemon_server.start(use_auth, launchui)\nanalytics_manager.send_server_startup_success()\n+ break\nexcept Exception as e:\nlog.exception('Failed to startup')\nanalytics_manager.send_server_startup_error(str(e))\n+ tries += 1\n+ else:\nreactor.callFromThread(reactor.stop)\n",
        "chatgpt_cot": "\"Update debug log format to include parameter keys and values for start configuration in launcher.py\""
    },
    {
        "org_diff": "diff --git a/fkie_master_sync/src/fkie_master_sync/sync_thread.py b/fkie_master_sync/src/fkie_master_sync/sync_thread.py @@ -279,6 +279,7 @@ class SyncThread(object):\ndef _apply_remote_state(self, remote_state):\nrospy.loginfo(\"SyncThread[%s] Applying remote state...\", self.name)\ntry:\n+ rospy.logdebug(\"SyncThread[%s]: remote state: %s\" % (self.name, remote_state))\nstamp = float(remote_state[0])\nstamp_local = float(remote_state[1])\nremote_masteruri = remote_state[2]\n",
        "org_msg": "master_sync: added debug output for remote state",
        "sim_msg": "Remove locks from state",
        "sim_diff": "diff --git a/batchflow/batch.py b/batchflow/batch.py @@ -333,9 +333,14 @@ class Batch:\ndef __getstate__(self):\nstate = self.__dict__.copy()\nstate.pop('_data_named')\n+ state['_local'] = state['_local'] is not None\n+ state['_preloaded_lock'] = True\nreturn state\ndef __setstate__(self, state):\n+ state['_preloaded_lock'] = threading.Lock() if state['_preloaded_lock'] else None\n+ state['_local'] = threading.Lock() if state['_local'] else None\n+\nfor k, v in state.items():\n# this warrants that all hidden objects are reconstructed upon unpickling\nsetattr(self, k, v)\n",
        "chatgpt_cot": "Add debug log for remote state in SyncThread for better monitoring and troubleshooting of synchronization process."
    },
    {
        "org_diff": "diff --git a/examples/worker_rush.py b/examples/worker_rush.py -import sc2\n-from sc2 import run_game, maps, Race, Difficulty\n+from sc2 import run_game, maps, Race, Difficulty, BotAI\nfrom sc2.player import Bot, Computer\n-class WorkerRushBot(sc2.BotAI):\n+class WorkerRushBot(BotAI):\n+ def __init__(self):\n+ super().__init__()\n+ self.actions = []\n+\nasync def on_step(self, iteration):\n+ self.actions = []\n+\nif iteration == 0:\n+ target = self.enemy_start_locations[0]\n+\nfor worker in self.workers:\n- await self.do(worker.attack(self.enemy_start_locations[0]))\n+ self.actions.append(worker.attack(target))\n+\n+ await self.do_actions(self.actions)\ndef main():\nrun_game(maps.get(\"Abyssal Reef LE\"), [\n",
        "org_msg": "Use do_actions() instead of do() in WorkerRushBot",
        "sim_msg": "Trying to use Dask.",
        "sim_diff": "diff --git a/workers/worker_base.py b/workers/worker_base.py import requests, datetime, time, traceback, json, os, sys, math, logging, numpy, copy, concurrent, multiprocessing\nfrom logging import FileHandler, Formatter, StreamHandler\n-from multiprocessing import Process, Queue\n+from multiprocessing import Process, Queue, Pool\n+import dask.dataframe as dd\n+from os import getpid\nimport sqlalchemy as s\nimport pandas as pd\nfrom pathlib import Path\n@@ -365,11 +367,11 @@ class Worker():\nif len(new_data) == 0:\nreturn [], []\n- need_insertion = pd.DataFrame()\n- need_updates = pd.DataFrame()\n+ need_insertion = dd.DataFrame()\n+ need_updates = dd.DataFrame()\n- table_values_df = pd.DataFrame(table_values, columns=table_values[0].keys())\n- new_data_df = pd.DataFrame(new_data).dropna(subset=action_map['insert']['source'])\n+ table_values_df = dd.DataFrame(table_values, columns=table_values[0].keys())\n+ new_data_df = dd.DataFrame(new_data).dropna(subset=action_map['insert']['source'])\nnew_data_df, table_values_df = self.sync_df_types(new_data_df, table_values_df,\naction_map['insert']['source'], action_map['insert']['augur'])\n",
        "chatgpt_cot": "\"Add new method and fix compilation issue in WorkerRushBot class\""
    },
    {
        "org_diff": "diff --git a/sc2/unit.py b/sc2/unit.py @@ -876,7 +876,7 @@ class Unit:\n\"\"\"\nreturn self(AbilityId.HARVEST_RETURN, target=target, queue=queue)\n- def move(self, position: Union[Point2, Point3], queue: bool = False) -> UnitCommand:\n+ def move(self, position: Union[Unit, Point2, Point3], queue: bool = False) -> UnitCommand:\n\"\"\" Orders the unit to move to 'position'.\nTarget can be a Unit (to follow that unit) or Point2.\n",
        "org_msg": "Add \"Unit\" as possible target to the move command",
        "sim_msg": "add FloatTensor ceil function",
        "sim_diff": "diff --git a/syft/syft.py b/syft/syft.py @@ -35,6 +35,9 @@ class FloatTensor():\ndef scalar_multiply(self, scalar):\nreturn self.params_func(\"scalar_multiply\",[scalar])\n+ def ceil(self):\n+ return self.no_params_func(\"ceil\")\n+\ndef params_func(self, name, params, return_response=False):\n# send the command\n",
        "chatgpt_cot": "Refactor move method in Unit class to accept Unit as position parameter."
    },
    {
        "org_diff": "diff --git a/sc2/bot_ai.py b/sc2/bot_ai.py @@ -142,6 +142,7 @@ class BotAI:\nif not location:\nlocation = await self.get_next_expansion()\n+ if location:\nawait self.build(building, near=location, max_distance=max_distance, random_alternative=False, placement_step=1)\nasync def get_next_expansion(self) -> Optional[Point2]:\n@@ -413,6 +414,8 @@ class BotAI:\nnear = near.position.to2\nelif near is not None:\nnear = near.to2\n+ else:\n+ return\np = await self.find_placement(building, near.rounded, max_distance, random_alternative, placement_step)\nif p is None:\n",
        "org_msg": "Stop expand if no more places for expanding\nIt complained \"AttributeError: 'NoneType' object has no attribute 'rounded'\" when my bot take every available places to build  main bases.  In that case, the location got from `get_next_expansion` will be None and cause the error.",
        "sim_msg": "added get_slab_regions",
        "sim_diff": "diff --git a/pymatgen/core/surface.py b/pymatgen/core/surface.py @@ -1734,6 +1734,68 @@ def generate_all_slabs(structure, max_index, min_slab_size, min_vacuum_size,\nreturn all_slabs\n+def get_slab_regions(slab, blength=3):\n+ \"\"\"\n+ Function to get the ranges of the slab regions. Useful for discerning where\n+ the slab ends and vacuum begins if the slab is not fully within the cell\n+\n+ Args:\n+ slab (Structure): Structure object modelling the surface\n+ blength (float, Ang): The bondlength between atoms.\n+ \"\"\"\n+\n+ fcoords, indices, all_indices = [], [], []\n+ for site in slab:\n+ # find sites with c < 0 (noncontiguous)\n+ neighbors = slab.get_neighbors(site, blength, include_index=True,\n+ include_image=True)\n+ for nn in neighbors:\n+ if nn[0].frac_coords[2] < 0:\n+ # sites are noncontiguous within cell\n+ fcoords.append(nn[0].frac_coords[2])\n+ indices.append(nn[-2])\n+ if nn[-2] not in all_indices:\n+ all_indices.append(nn[-2])\n+\n+ if fcoords:\n+ # If slab is noncontiguous, locate the lowest\n+ # site within the upper region of the slab\n+ while fcoords:\n+ last_fcoords = copy.copy(fcoords)\n+ last_indices = copy.copy(indices)\n+ site = slab[indices[fcoords.index(min(fcoords))]]\n+ neighbors = slab.get_neighbors(site, blength, include_index=True,\n+ include_image=True)\n+ fcoords, indices = [], []\n+ for nn in neighbors:\n+ if 1 > nn[0].frac_coords[2] > 0 and \\\n+ nn[0].frac_coords[2] < site.frac_coords[2]:\n+ # sites are noncontiguous within cell\n+ fcoords.append(nn[0].frac_coords[2])\n+ indices.append(nn[-2])\n+ if nn[-2] not in all_indices:\n+ all_indices.append(nn[-2])\n+\n+ # Now locate the highest site within the lower region of the slab\n+ upper_fcoords = []\n+ for site in slab:\n+ if all([nn[-1] not in all_indices for nn in\n+ slab.get_neighbors(site, blength,\n+ include_index=True)]):\n+ upper_fcoords.append(site.frac_coords[2])\n+ coords = copy.copy(last_fcoords) if not fcoords else copy.copy(fcoords)\n+ min_top = slab[last_indices[coords.index(min(coords))]].frac_coords[2]\n+ ranges = [[0, max(upper_fcoords)], [min_top, 1]]\n+ else:\n+ # If the entire slab region is within the slab cell, just\n+ # set the range as the highest and lowest site in the slab\n+ sorted_sites = sorted(slab, key=lambda site: site.frac_coords[2])\n+ ranges = [[sorted_sites[0].frac_coords[2],\n+ sorted_sites[-1].frac_coords[2]]]\n+\n+ return ranges\n+\n+\ndef miller_index_from_sites(lattice, coords, coords_are_cartesian=True,\nround_dp=4, verbose=True):\n\"\"\"\n",
        "chatgpt_cot": "Ensure building location before building to prevent errors in BotAI. Fix potential issue with building placement near location in BotAI."
    },
    {
        "org_diff": "diff --git a/rasa_core_sdk/executor.py b/rasa_core_sdk/executor.py @@ -53,7 +53,7 @@ class CollectingDispatcher(object):\n# type: (Text) -> None\n\"\"\"Send a message to the client with attachments.\"\"\"\n- message = {\"text\": None, \"attachement\": attachment}\n+ message = {\"text\": None, \"attachment\": attachment}\nself.messages.append(message)\n",
        "org_msg": "fixed misspelled attachment",
        "sim_msg": "docs: add explain on return",
        "sim_diff": "diff --git a/docs/fundamentals/executor/executor-api.md b/docs/fundamentals/executor/executor-api.md @@ -147,7 +147,7 @@ class MyExecutor(Executor):\n@requests\nasync def foo(\nself, docs: DocumentArray, parameters: Dict, docs_matrix: List[DocumentArray]\n- ) -> Optional[Union[DocumentArray, Dict]]:\n+ ) -> Union[DocumentArray, Dict, None]:\npass\n```\n@@ -161,7 +161,6 @@ any other `list`-like object in a Python function.\n- `docs_matrix`: This is the least common parameter to be used for an `Executor`. This argument is needed when an `Executor` is used inside a `Flow` to merge or reduce the output of more than one other `Executor`.\nAs a user, you will rarely touch this parameter.\n-- `return`: Every Executor method can process data in 3 ways: Update `docs` on the fly, return a `DocumentArray` object, or return a `Dict` object.\n````{admonition} Hint\n@@ -193,6 +192,17 @@ class MyExecutor(Executor):\n```\n````\n+### Method return\n+\n+Every Executor method can `return` in 3 ways:\n+\n+- If you return a `DocumentArray` object, then it will be sent over to the next Executor.\n+- If you return `None` or if you don't have a `return` in your method, then the original `doc` object (potentially mutated by your function) will be sent over to the next Executor.\n+- If you return a `dict` object, then it will be considered as a result and passed on behind `parameters['__results__']`. The original `doc` object (potentially mutated by your function) will be sent over to the next Executor.\n+\n+\n+### Example\n+\nLet's understand how `Executor`s processes `DocumentArray`s inside a Flow, and how the changes are chained and applied, affecting downstream `Executors` in the Flow.\n```python\n@@ -246,8 +256,11 @@ with f:\nPrintExecutor: received document with text: \"I returned a different Document\"\n```\n+## Other usages\n+\n+Beside running Executor inside the Flow, we list two other usages that may help you debug.\n-## Use Executor out of Flow\n+### Use Executor out of Flow\n`Executor` objects can be used directly, just like a regular Python object. For example:\n@@ -274,7 +287,7 @@ Text: hello world\n```\n-## Using Executors in an AsyncIO runner\n+### Use Executors in an AsyncIO runner\n```python\n",
        "chatgpt_cot": "Fix typo in attachment key in CollectingDispatcher class."
    },
    {
        "org_diff": "diff --git a/fkie_node_manager/src/fkie_node_manager/main_window.py b/fkie_node_manager/src/fkie_node_manager/main_window.py @@ -1592,6 +1592,8 @@ class MainWindow(QMainWindow):\nelse:\nnm.settings().set_host_user(hostname, usr)\nmuri = None if masteruri == 'ROS_MASTER_URI' else utf8(masteruri)\n+ # stop if master_discovery already running\n+ self._append_stop_for('/%s' % utf8(discovery_type), hostname, muri, self._progress_queue)\nself._progress_queue.add2queue(utf8(uuid.uuid4()),\n'start discovering on %s' % hostname,\nnm.starter().runNodeWithoutConfig,\n@@ -1607,6 +1609,7 @@ class MainWindow(QMainWindow):\n'_ignore_topics:=[]', '_sync_topics:=[]',\n'_ignore_services:=[]', '_sync_services:=[]',\n'_sync_remote_nodes:=False']\n+ self._append_stop_for('/master_sync', hostname, muri, self._progress_queue_sync)\nself._progress_queue_sync.add2queue(utf8(uuid.uuid4()),\n'start sync on %s' % hostname,\nnm.starter().runNodeWithoutConfig,\n@@ -1628,6 +1631,25 @@ class MainWindow(QMainWindow):\n'Error while parse parameter',\nutf8(e))\n+ def _append_stop_for(self, nodename, hostname, muri, queue):\n+ '''\n+ Appends stop command to given queue for given node\n+ '''\n+ cmuri = muri\n+ if hostname == 'localhost':\n+ lmuri = self.getMasteruri()\n+ if cmuri is None:\n+ cmuri = lmuri\n+ else:\n+ cmuri = cmuri.replace('localhost', get_hostname(lmuri))\n+ elif cmuri is None:\n+ cmuri = nm.nameres().masteruri(utf8(hostname))\n+ master = self.getMaster(cmuri.rstrip('/') + '/', create_new=False)\n+ if master is not None:\n+ found_nodes = master._get_nodes_by_name([nodename])\n+ for node in found_nodes:\n+ queue.add2queue(utf8(uuid.uuid4()), 'stop %s' % node.name, master.stop_node, (node, True))\n+\ndef _join_network(self, network):\ntry:\nhostname = 'localhost'\n",
        "org_msg": "fkie_node_manger: prepend stop while start master_discovery from node_manager\nit is a workaround because all nodes with same are stopped by roscore.\nAlso the new one.",
        "sim_msg": "DELETE thread_function method",
        "sim_diff": "diff --git a/packages/grid/backend/grid/core/node.py b/packages/grid/backend/grid/core/node.py # stdlib\nimport logging\n-import threading\nfrom typing import Optional\n# third party\n@@ -23,52 +22,6 @@ from grid.db.session import get_db_session\nfrom grid.core.celery_app import celery_app\n-def thread_function(*args, **kwargs) -> None: # type: ignore\n- # TODO: call this after the Network node is deployed instead of using a timer.\n-\n- # third party\n- from requests import get\n-\n- ip = get(\"https://api.ipify.org\").content.decode(\"utf8\")\n- print(f\"My public IP address is: {ip}\")\n- NETWORK_PUBLIC_HOST = \"http://\" + ip + \":80\"\n- # third party\n- import requests\n-\n- # syft absolute\n- import syft as sy\n-\n- if (\n- requests.get(\"http://localhost:80/api/v1/exam/asdf\", timeout=1).status_code\n- != 502\n- ):\n- NETWORK_PUBLIC_HOST = \"http://localhost:80\"\n-\n- network_root = sy.login(\n- email=\"info@openmined.org\",\n- password=\"changethis\",\n- url=\"http://localhost\",\n- port=80,\n- )\n- elif (\n- requests.get(NETWORK_PUBLIC_HOST + \"/api/v1/exam/asdf\", timeout=1).status_code\n- != 502\n- ):\n-\n- network_root = sy.login(\n- email=\"info@openmined.org\",\n- password=\"changethis\",\n- url=\"http://\" + ip,\n- port=80,\n- )\n-\n- vpn_s = network_root.vpn_status()\n-\n- # if the VPN is empty then it's ready for the network node to join it (first)\n- if len(vpn_s[\"host\"]) == 0 and len(vpn_s[\"peers\"]) == 0:\n- network_root.join_network(host_or_ip=NETWORK_PUBLIC_HOST)\n-\n-\ndef create_s3_bucket(bucket_name: str, settings: Settings) -> None:\nlogging.info(\"Trying to connect with SeaweedFS ... \")\ns3_client = get_s3_client(settings=settings)\n",
        "chatgpt_cot": "\"Add stop command for discovery and sync, and append stop command to the queue for the given node to fix the network join issue.\""
    },
    {
        "org_diff": "diff --git a/fkie_node_manager/package.xml b/fkie_node_manager/package.xml <exec_depend>rqt_reconfigure</exec_depend>\n<exec_depend>diagnostic_msgs</exec_depend>\n- <exec_depend condition=\"$ROS_PYTHON_VERSION == 2\">python-crypto</exec_depend>\n+ <exec_depend condition=\"$ROS_PYTHON_VERSION == 2\">python-pycryptodome</exec_depend>\n<exec_depend condition=\"$ROS_PYTHON_VERSION == 2\">python-docutils</exec_depend>\n<exec_depend condition=\"$ROS_PYTHON_VERSION == 2\">python-paramiko</exec_depend>\n<exec_depend condition=\"$ROS_PYTHON_VERSION == 2\">python-ruamel.yaml</exec_depend>\n- <!-- <exec_depend condition=\"$ROS_PYTHON_VERSION == 3\">python3-crypto</exec_depend>\n+ <!-- <exec_depend condition=\"$ROS_PYTHON_VERSION == 3\">python3-pycryptodome</exec_depend>\n<exec_depend condition=\"$ROS_PYTHON_VERSION == 3\">python3-docutils</exec_depend>\n<exec_depend condition=\"$ROS_PYTHON_VERSION == 3\">python3-paramiko</exec_depend>\n<exec_depend condition=\"$ROS_PYTHON_VERSION == 3\">python3-ruamel.yaml</exec_depend> -->\n",
        "org_msg": "fkie_node_manager: changed dependency from Crypto to pycryptodome",
        "sim_msg": "Add comments showing most recent versions of augur depencies",
        "sim_diff": "diff --git a/setup.py b/setup.py @@ -34,60 +34,59 @@ setup(\n],\ninstall_requires=[\n\"wheel\",\n- \"alembic==1.8.1\",\n- \"coloredlogs==15.0\",\n- \"Beaker==1.11.0\",\n- \"SQLAlchemy==1.3.23\",\n- \"itsdangerous==2.0.1\",\n- \"Jinja2==3.0.2\",\n- \"Flask==2.0.2\",\n+ \"alembic==1.8.1\", # 1.8.1\n+ \"coloredlogs==15.0\", # 15.0.1\n+ \"Beaker==1.11.0\", # 1.11.0\n+ \"SQLAlchemy==1.3.23\", # 1.4.40\n+ \"itsdangerous==2.0.1\", # 2.1.2\n+ \"Jinja2==3.0.2\", # 3.1.2\n+ \"Flask==2.0.2\", # 2.2.2\n\"Flask-Cors==3.0.10\",\n\"Flask-Login==0.5.0\",\n\"Flask-WTF==1.0.0\",\n- \"pandas==1.3.5\",\n- \"numpy==1.21\",\n- \"requests==2.28.0\",\n- \"psycopg2-binary==2.9.3\",\n- \"click==8.0.3\",\n- \"psutil==5.8.0\",\n- \"gunicorn==20.1.0\",\n- \"six==1.15.0\",\n- \"bokeh==2.0.2\",\n- \"selenium==3.141.0\",\n- \"dask>=2021.6.2\",\n- \"cloudpickle >= 0.2.2\",\n- \"fsspec >= 0.6.0\",\n- \"toolz >= 0.8.2\",\n- \"partd >= 0.3.10\",\n- \"distributed >= 2021.03.0\",\n- \"tornado < 6.2\",\n- \"nltk==3.6.6\",\n- \"h5py~=3.6.0\",\n- \"scipy==1.7.3\",\n- \"blinker==1.4\",\n- \"protobuf > 3.6.0\",\n- \"slack==0.0.2\",\n- \"boto3==1.17.57\",\n- \"toml\",\n- \"mistune==0.8.4\",\n- \"pyYaml\",\n- \"redis==4.3.3\",\n- \"XlsxWriter==1.3.7\",\n- \"celery==5.2.7\",\n- \"httpx==0.23.0\",\n+ \"pandas==1.3.5\", # 1.4.3\n+ \"numpy==1.21\", # 1.23.2\n+ \"requests==2.28.0\", # 2.28.1\n+ \"psycopg2-binary==2.9.3\", #2.9.3 what is pscopg-binary 3.0.16\n+ \"click==8.0.3\", # 8.1.3\n+ \"psutil==5.8.0\", # 5.9.1\n+ \"gunicorn==20.1.0\", # 20.1.0\n+ \"six==1.15.0\", # 1.16.0\n+ \"bokeh==2.0.2\", # 2.4.3\n+ \"selenium==3.141.0\",# 4.4.3\n+ \"dask>=2021.6.2\", # 2022.8.1\n+ \"cloudpickle >= 0.2.2\", # 2.1.0\n+ \"fsspec >= 0.6.0\", # 2022.7.1\n+ \"toolz >= 0.8.2\", # 0.12.0\n+ \"partd >= 0.3.10\", # 1.3.0\n+ \"distributed >= 2021.03.0\", # 2022.8.1\n+ \"nltk==3.6.6\", # 3.7\n+ \"h5py~=3.6.0\", # 3.7\n+ \"scipy==1.7.3\", # 1.9.0\n+ \"blinker==1.4\", # 1.5\n+ \"protobuf > 3.6.0\", # 4.21.5\n+ \"slack==0.0.2\", # 0.0.2\n+ \"boto3==1.17.57\", # 1.24.56\n+ \"toml\", # 0.10.2\n+ \"mistune==0.8.4\", # 2.0.4\n+ \"pyYaml\", # 6.0\n+ \"redis==4.3.3\", # 4.3.4\n+ \"XlsxWriter==1.3.7\", # 3.0.3\n+ \"celery==5.2.7\", # 5.2.7\n+ \"httpx==0.23.0\", # 0.23.0\n\"tornado==6.1\" # added because it sometimes errors when tornado is not 6.1 even though nothing we install depends on it\n],\nextras_require={\n\"dev\": [\n- \"tox==3.24.4\",\n- \"pytest==6.2.5\",\n- \"toml >= 0.10.2\",\n- \"ipdb==0.13.9\",\n- \"sphinx==4.2.0\",\n- \"sphinx_rtd_theme==1.0.0\",\n- \"sphinxcontrib-openapi==0.7.0\",\n- \"sphinxcontrib-redoc==1.6.0\",\n- \"docutils==0.17.1\"\n+ \"tox==3.24.4\", # 3.25.1\n+ \"pytest==6.2.5\", # 7.1.2\n+ \"toml >= 0.10.2\", # 0.10.2\n+ \"ipdb==0.13.9\", # 0.13.9\n+ \"sphinx==4.2.0\", # 5.1.1\n+ \"sphinx_rtd_theme==1.0.0\", # 1.0.0\n+ \"sphinxcontrib-openapi==0.7.0\", # 0.7.0\n+ \"sphinxcontrib-redoc==1.6.0\", # 1.6.0\n+ \"docutils==0.17.1\" # 0.19\n]\n},\nentry_points={\n",
        "chatgpt_cot": "Update python-crypto to python-pycryptodome for ROS_PYTHON_VERSION == 2 to resolve dependency issue. Comment out python3-crypto and use python3-pycryptodome for ROS_PYTHON_VERSION == 3."
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/node_tree_model.py b/node_manager_fkie/src/node_manager_fkie/node_tree_model.py @@ -1029,9 +1029,9 @@ class HostItem(GroupItem):\nothers.append((val.key, val.value))\ntooltip += '\\n<b>%s:</b> <font color=grey>%s</font>' % (diag.name, stamp)\nif diag.level > 0:\n- tooltip += '\\n<dt><font color=\"#CC0000\">%s</font></dt>' % (diag.message.replace('>', '&gt;').replace('<', '&lt;'))\n+ tooltip += '\\n<dt><font color=\"red\">%s</font></dt>' % (diag.message.replace('>', '&gt;').replace('<', '&lt;'))\nif free is not None:\n- tooltip += '\\n<dt>%s: %s (%s%%)</dt>' % ('Free', free, free_percent)\n+ tooltip += '\\n<dt><em>%s:</em> %s (%s%%)</dt>' % ('Free', free, free_percent)\nfor key, value in others:\nkey_fmt = key\nval_fmt = value\n@@ -1044,7 +1044,10 @@ class HostItem(GroupItem):\nelif '[degree]' in key:\nval_fmt = '%s&deg;C' % value\nkey_fmt = key_fmt.replace(' [degree]', '')\n- tooltip += '\\n<dt>%s: %s</dt>' % (key_fmt, val_fmt)\n+ if key == 'Process high load':\n+ tooltip += '\\n<dt><font color=\"red\">%s</font></dt>' % (key_fmt, val_fmt)\n+ else:\n+ tooltip += '\\n<dt><em>%s:</em> %s</dt>' % (key_fmt, val_fmt)\nexcept Exception as err:\ntooltip += '\\n<dt><font color=\"red\">%s</font></dt>' % (utf8(err))\ntooltip += '<br>'\n",
        "org_msg": "node_manager_fkie: visualize processes with high load",
        "sim_msg": "text tooltip update",
        "sim_diff": "diff --git a/qualcoder/view_av.py b/qualcoder/view_av.py @@ -2189,19 +2189,19 @@ class DialogCodeAV(QtWidgets.QDialog):\naction_play_text = menu.addAction(_(\"Play text\"))\nplay_text_avid = item['avid']\naction_unmark = menu.addAction(_(\"Unmark\"))\n- action_code_memo = menu.addAction(_(\"Memo coded text\"))\n- action_start_pos = menu.addAction(_(\"Change start position\"))\n- action_end_pos = menu.addAction(_(\"Change end position\"))\n+ action_code_memo = menu.addAction(_(\"Memo coded text M\"))\n+ action_start_pos = menu.addAction(_(\"Change start position (SHIFT LEFT/ALT RIGHT)\"))\n+ action_end_pos = menu.addAction(_(\"Change end position (SHIFT RIGHT/ALT LEFT)\"))\nbreak\nif selectedText != \"\":\nif self.ui.treeWidget.currentItem() is not None:\n- action_mark = menu.addAction(_(\"Mark\"))\n+ action_mark = menu.addAction(_(\"Mark (Q)\"))\n# Use up to 5 recent codes\nif len(self.recent_codes) > 0:\n- submenu = menu.addMenu(_(\"Mark with recent code\"))\n+ submenu = menu.addMenu(_(\"Mark with recent code (R)\"))\nfor item in self.recent_codes:\nsubmenu.addAction(item['name'])\n- action_annotate = menu.addAction(_(\"Annotate\"))\n+ action_annotate = menu.addAction(_(\"Annotate (A)\"))\naction_copy = menu.addAction(_(\"Copy to clipboard\"))\nif self.segment_for_text is None:\naction_link_text_to_segment = menu.addAction(_(\"Prepare text_link to segment\"))\n@@ -2628,6 +2628,7 @@ class ToolTip_EventFilter(QtCore.QObject):\nfor c in self.codes:\nif item['cid'] == c['cid']:\nitem['name'] = c['name']\n+ item['color'] = c['color']\ndef eventFilter(self, receiver, event):\n# QtGui.QToolTip.showText(QtGui.QCursor.pos(), tip)\n@@ -2644,16 +2645,14 @@ class ToolTip_EventFilter(QtCore.QObject):\nreturn super(ToolTip_EventFilter, self).eventFilter(receiver, event)\nfor item in self.code_text:\nif item['pos0'] <= pos and item['pos1'] >= pos:\n- # print(item)\ntry:\n- if text != \"\":\n- text = text + \"\\n\"\n- text += item['name'] # += as can have multiple codes on same position\n+ text += '<p style=\"background-color:' + item['color'] + '\">' + item['name']\nif item['avid'] is not None:\ntext += \" [\" + msecs_to_mins_and_secs(item['av_pos0'])\ntext += \" - \" + msecs_to_mins_and_secs(item['av_pos1']) + \"]\"\nif item['memo'] is not None and item['memo'] != \"\":\ntext += \"<br /><em>\" + _(\"Memo: \") + item['memo'] + \"</em>\"\n+ text += \"</p>\"\nexcept Exception as e:\nmsg = \"Codes ToolTipEventFilter \" + str(e) + \". Possible key error: \"\nmsg += str(item) + \"\\n\" + str(self.code_text)\n",
        "chatgpt_cot": "\"Update tooltip formatting in HostItem class to improve readability and highlight specific diagnostic messages for better user experience.\""
    },
    {
        "org_diff": "diff --git a/fkie_node_manager/src/fkie_node_manager/name_resolution.py b/fkie_node_manager/src/fkie_node_manager/name_resolution.py @@ -312,9 +312,10 @@ class NameResolution(object):\nelse:\nbreak\ntry:\n- if MasterEntry.is_legal_ip(address):\n- (hostname, _, _) = socket.gethostbyaddr(address)\n- return hostname\n+ self.add_address(address)\n+ # if MasterEntry.is_legal_ip(address):\n+ # (hostname, _, _) = socket.gethostbyaddr(address)\n+ # return hostname\nexcept Exception:\nimport traceback\nprint(traceback.format_exc())\n",
        "org_msg": "try to fix block while name resolution",
        "sim_msg": "Add to MSL support to IPC data/error callback",
        "sim_diff": "diff --git a/resources/lib/services/msl/http_server.py b/resources/lib/services/msl/http_server.py See LICENSES/MIT.md for more information.\n\"\"\"\nimport base64\n+import json\nfrom http.server import BaseHTTPRequestHandler\nfrom socketserver import TCPServer\nfrom urllib.parse import parse_qs, urlparse\n+from resources.lib import common\nfrom resources.lib.common.exceptions import MSLError\nfrom resources.lib.utils.logging import LOG\nfrom .msl_handler import MSLHandler\n@@ -29,10 +31,7 @@ class MSLHttpRequestHandler(BaseHTTPRequestHandler):\ntry:\nurl_parse = urlparse(self.path)\nLOG.debug('Handling HTTP POST IPC call to {}', url_parse.path)\n- if '/license' not in url_parse:\n- self.send_response(404)\n- self.end_headers()\n- return\n+ if '/license' in url_parse:\nlength = int(self.headers.get('content-length', 0))\ndata = self.rfile.read(length).decode('utf-8').split('!')\nb64license = self.server.msl_handler.get_license(\n@@ -40,6 +39,25 @@ class MSLHttpRequestHandler(BaseHTTPRequestHandler):\nself.send_response(200)\nself.end_headers()\nself.wfile.write(base64.standard_b64decode(b64license))\n+ else:\n+ func_name = self.path[1:]\n+ length = int(self.headers.get('content-length', 0))\n+ data = json.loads(self.rfile.read(length)) or None\n+ try:\n+ result = self.server.msl_handler.http_ipc_slots[func_name](data)\n+ if isinstance(result, dict) and common.IPC_EXCEPTION_PLACEHOLDER in result:\n+ self.send_response(500, json.dumps(result))\n+ self.end_headers()\n+ return\n+ self.send_response(200)\n+ self.end_headers()\n+ self.wfile.write(json.dumps(result).encode('utf-8'))\n+ except KeyError:\n+ self.send_response(500, json.dumps(\n+ common.ipc_convert_exc_to_json(class_name='SlotNotImplemented',\n+ message='The specified slot {} does not exist'.format(func_name))\n+ ))\n+ self.end_headers()\nexcept Exception as exc:\nimport traceback\nLOG.error(traceback.format_exc())\n",
        "chatgpt_cot": "\"Add address to name resolution and comment out unused code for legal IP and hostname resolution\""
    },
    {
        "org_diff": "diff --git a/.travis.yml b/.travis.yml @@ -42,6 +42,7 @@ jobs:\n# Shut down and remove container\n- docker rm -f app\n+\n- stage: test python 3.8\nscript:\n# TODO: Change to normal python 3.8 version once 3.8 is released\n@@ -53,6 +54,18 @@ jobs:\n- docker exec -i app bash -c \"cd /root/template && pipenv run pytest test/\"\n- docker rm -f app\n+\n+ - stage: run code coverage\n+ python:\n+ - 3.7\n+ script:\n+ - pip install pipenv\n+ - pipenv install --dev\n+ - pipenv run pytest --cov=./\n+ after_success:\n+ - codecov\n+\n+\n- stage: run autotest bot\nscript:\n# Debugging\n@@ -69,6 +82,7 @@ jobs:\n# Shut down and remove container after finishing\n- docker rm -f app\n+\n- stage: release to pypi\nscript:\n# Necessary random output in this stage\n@@ -82,11 +96,3 @@ jobs:\npassword: \"$PYPI_PASSWORD\"\non:\nbranch: pypi-release\n-\n- - stage: run code coverage\n- script:\n- - pip install pipenv\n- - pipenv install --dev\n- - pipenv run pytest --cov=./\n- after_success:\n- - codecov\n",
        "org_msg": "Specify python version 3.7",
        "sim_msg": "Clear test cache",
        "sim_diff": "diff --git a/.travis.yml b/.travis.yml @@ -20,7 +20,7 @@ install:\n# command to run the dependencies\nscript:\n- - 'if [[ \"$TEST_SUITE\" == \"install\" ]]; then rm -fr ~/.cache/pip; fi'\n+ - 'if [[ \"$TEST_SUITE\" == \"install\" ]]; then export PYTEST_ADDOPTS=\"--cache-clear\"; fi'\n- \"pipenv run bash ./run-tests.sh\"\njobs:\n",
        "chatgpt_cot": "Add code coverage and run autotest bot stages, update python version, and remove redundant code coverage stage."
    },
    {
        "org_diff": "diff --git a/Makefile b/Makefile # - dockerhub-pull: Pulling service images from dockerhub\n# - license: Checks sourrce files for Apache license header\n# - help: Output the help instructions for each command\n-# - log: Check the recent log output of all services\n+# - log: Check the recent log output of given service\n+# - logs: Check the recent log output of all services\n# - restart: Stop the cello service and then start\n# - setup-master: Setup the host as a master node, install pkg and download docker images\n# - setup-worker: Setup the host as a worker node, install pkg and download docker images\n@@ -215,6 +216,9 @@ initial-env: ##@Configuration Initial Configuration for dashboard\nstart: ##@Service Start service\n@$(MAKE) $(START_OPTIONS)\necho \"Start all services with ${COMPOSE_FILE}... docker images must exist local now, otherwise, run 'make setup-master first' !\"\n+ if [ \"$(MODE)\" = \"dev\" ]; then \\\n+ make build-admin-js; \\\n+ fi\ndocker-compose -f ${COMPOSE_FILE} up -d --no-recreate\necho \"Now you can visit operator-dashboard at localhost:8080, or user-dashboard at localhost:8081\"\n",
        "org_msg": "Add make build-admin-js cmd in dev mode\nIn dev mode, when run make start, need to trigger\n`make build-admin-js` to update the local js files if necessary.\n#done.",
        "sim_msg": "[Chore] Fix systemd service generation instructions\nProblem: We provide a way to generate systemd services for running Octez\nbinaries in the background separately from Ubuntu/Fedora packages. But\ncurrently, these instructions are a bit outdated.\nSolution: Update them to reflect the actual 'gen_systemd_service_file.py' behaviour.",
        "sim_diff": "diff --git a/docs/systemd.md b/docs/systemd.md @@ -39,19 +39,18 @@ from scratch.\nFor this you'll need a `.service` file to define each systemd service.\nThe easiest way to get one is to run [`gen_systemd_service_file.py`](../gen_systemd_service_file.py).\n-You should specify the service name as an argument. Note that there are two\n-predefined services for `tezos-node`: `tezos-node-{mainnet, hangzhounet}`.\n+You should specify the binary name as an argument.\nE.g.:\n```\n-./gen_systemd_service_file.py tezos-node-mainnet\n+./gen_systemd_service_file.py tezos-node\n# or\n./gen_systemd_service_file.py tezos-baker-011-PtHangz2\n```\n-After that you'll have a `.service` file in the current directory.\n+After that you'll have `.service` files in the current directory.\n-Apart from the `.service` file you'll need the service startup script and default\n-configuration file, they can be found in the [`scripts`](../docker/package/scripts) and\n+Apart from these `.service` files you'll need the services' startup scripts and default\n+configuration files, they can be found in the [`scripts`](../docker/package/scripts) and\n[`defaults`](../docker/package/defaults) folders respectively.\n## Systemd units on WSL\n",
        "chatgpt_cot": "Add conditional build step for admin JS in start command to improve development workflow."
    },
    {
        "org_diff": "diff --git a/fkie_node_manager/src/fkie_node_manager/logscreen/logger_item.py b/fkie_node_manager/src/fkie_node_manager/logscreen/logger_item.py @@ -114,17 +114,17 @@ class LoggerItem(QFrame):\nself.set_level('FATAL')\ndef set_level(self, level):\n- if level == 'DEBUG':\n+ if level.upper() == 'DEBUG':\nself.debug.setChecked(True)\n- elif level == 'INFO':\n+ elif level.upper() == 'INFO':\nself.info.setChecked(True)\n- elif level == 'WARN':\n+ elif level.upper() == 'WARN':\nself.warn.setChecked(True)\n- elif level == 'ERROR':\n+ elif level.upper() == 'ERROR':\nself.error.setChecked(True)\n- elif level == 'FATAL':\n+ elif level.upper() == 'FATAL':\nself.fatal.setChecked(True)\n- else:\n+ elif level:\nrospy.logwarn(\"loglevel not found '%s'\" % (level))\nif self._current_level is not None:\nif self._callback is not None:\n",
        "org_msg": "fkie_node_manager: fixed loglevel compare",
        "sim_msg": "default to debug",
        "sim_diff": "diff --git a/shutit_global.py b/shutit_global.py @@ -220,7 +220,7 @@ class ShutItGlobal(object):\nelif self.loglevel == 'INFO':\nlogging.basicConfig(format=logformat,level=logging.INFO)\nelse:\n- logging.basicConfig(format=logformat,level=logging.INFO)\n+ logging.basicConfig(format=logformat,level=logging.DEBUG)\nelse:\nself.loglevel = self.loglevel.upper()\nif self.loglevel == 'DEBUG':\n@@ -234,7 +234,7 @@ class ShutItGlobal(object):\nelif self.loglevel == 'INFO':\nlogging.basicConfig(format=logformat,filename=self.logfile,level=logging.INFO)\nelse:\n- logging.basicConfig(format=logformat,filename=self.logfile,level=logging.INFO)\n+ logging.basicConfig(format=logformat,filename=self.logfile,level=logging.DEBUG)\nself.loglevel = logging.getLogger().getEffectiveLevel()\n",
        "chatgpt_cot": "\"Fix compilation issue due to case sensitivity in log level comparison in LoggerItem.py\""
    },
    {
        "org_diff": "diff --git a/.github/workflows/check-code.yml b/.github/workflows/check-code.yml @@ -7,9 +7,7 @@ on:\nbranches: [\"main\"]\njobs:\n-\ncheck:\n-\nruns-on: ubuntu-latest\nsteps:\n@@ -17,7 +15,7 @@ jobs:\n- name: Set up Python\nuses: actions/setup-python@v4\nwith:\n- python-version: '3.5'\n+ python-version: \"3.8\"\n- name: Install dependencies\nrun: |\npython -m pip install --upgrade pip\n",
        "org_msg": "Bump up github workflow python version to 3.8",
        "sim_msg": "add install isort\nisort is not auto installed by pre-commit",
        "sim_diff": "diff --git a/.github/workflows/check.yml b/.github/workflows/check.yml @@ -21,7 +21,7 @@ jobs:\npython-version: \"3.6\"\n- name: Install dependencies\nrun: |\n- pip install pre-commit\n+ pip install pre-commit isort\npre-commit install\n- name: Run pre-commit checks including linting\nrun: |\n",
        "chatgpt_cot": "Update python version to 3.8 in check-code.yml workflow to ensure compatibility with dependencies and resolve potential issues with outdated version."
    },
    {
        "org_diff": "diff --git a/rasa_core_sdk/forms.py b/rasa_core_sdk/forms.py @@ -53,7 +53,8 @@ class FormAction(Action):\nraise ActionExecutionError(\"Failed to validate slot {0} \"\n\"with action {1}\"\n\"\".format(tracker.slots[REQUESTED_SLOT],\n- self.name()), self.name())\n+ self.name()),\n+ self.name())\ndef submit(self, dispatcher, tracker, domain):\n# type: (CollectingDispatcher, Tracker, Dict[Text, Any]) -> List[Dict]\n",
        "org_msg": "code style RasaHQ/roadmap#263",
        "sim_msg": "error checking fix.",
        "sim_diff": "diff --git a/workers/pull_request_worker/pull_request_worker.py b/workers/pull_request_worker/pull_request_worker.py @@ -439,7 +439,7 @@ class GitHubPullRequestWorker(WorkerGitInterfaceable):\nstacker = traceback.format_exc()\nself.logger.debug(f\"{stacker}\")\n-\n+ prs_insert = []\ntry:\nprs_insert = [\n{\n",
        "chatgpt_cot": "Fix formatting issue in FormAction class in forms.py. Removed extra parentheses in raise statement to ensure proper error message display."
    },
    {
        "org_diff": "diff --git a/test/queries_test_bot.py b/test/queries_test_bot.py @@ -79,25 +79,31 @@ class TestBot(sc2.BotAI):\nawait self._advance_steps(10)\nasync def spawn_unit(self, unit_type: Union[UnitTypeId, List[UnitTypeId]]):\n+ await self._advance_steps(10)\nif not isinstance(unit_type, List):\nunit_type = [unit_type]\nfor i in unit_type:\nawait self.client.debug_create_unit([[i, 1, self.game_info.map_center, 1]])\nasync def spawn_unit_enemy(self, unit_type: Union[UnitTypeId, List[UnitTypeId]]):\n+ await self._advance_steps(10)\nif not isinstance(unit_type, List):\nunit_type = [unit_type]\nfor i in unit_type:\n+ if i == UnitTypeId.CREEPTUMOR:\n+ await self.client.debug_create_unit([[i, 1, self.game_info.map_center + Point2((5, 5)), 2]])\n+ else:\nawait self.client.debug_create_unit([[i, 1, self.game_info.map_center, 2]])\nasync def run_can_place(self) -> bool:\n- await self._advance_steps(20)\n+ await self._advance_steps(1000)\nresult = await self.can_place(AbilityId.TERRANBUILD_COMMANDCENTER, [self.game_info.map_center])\nreturn result[0]\nasync def test_can_place_expect_true(self):\ntest_cases = [\n[UnitTypeId.OVERLORD, UnitTypeId.DARKTEMPLAR],\n+ [UnitTypeId.OVERLORD, UnitTypeId.ROACHBURROWED],\n[UnitTypeId.ZEALOT, None],\n[None, UnitTypeId.ZEALOT],\n[None, UnitTypeId.SUPPLYDEPOT],\n@@ -106,10 +112,10 @@ class TestBot(sc2.BotAI):\n]\nfor i, (own_unit_type, enemy_unit_type) in enumerate(test_cases):\n- if own_unit_type:\n- await self.spawn_unit(own_unit_type)\nif enemy_unit_type:\nawait self.spawn_unit_enemy(enemy_unit_type)\n+ if own_unit_type:\n+ await self.spawn_unit(own_unit_type)\nresult = await self.run_can_place()\nif result:\nlogger.info(f\"Test case successful: {i}, own unit: {own_unit_type}, enemy unit: {enemy_unit_type}\")\n@@ -127,13 +133,12 @@ class TestBot(sc2.BotAI):\n[UnitTypeId.OVERLORD, UnitTypeId.CREEPTUMOR],\n[UnitTypeId.OBSERVER, UnitTypeId.CREEPTUMOR],\n[UnitTypeId.OBSERVER, UnitTypeId.DARKTEMPLAR],\n- [UnitTypeId.OVERLORD, UnitTypeId.ROACHBURROWED],\n[UnitTypeId.OBSERVER, UnitTypeId.ROACHBURROWED],\n- [UnitTypeId.OVERLORD, UnitTypeId.MINERALFIELD450],\n[UnitTypeId.OVERLORD, UnitTypeId.CHANGELING],\n[UnitTypeId.OBSERVER, UnitTypeId.CHANGELING],\n[UnitTypeId.COMMANDCENTER, None],\n- # True for linux client:\n+ # True for linux client, False for windows client:\n+ # [UnitTypeId.OVERLORD, UnitTypeId.MINERALFIELD450],\n# [None, UnitTypeId.MINERALFIELD450],\n]\n",
        "org_msg": "Add more time in between tests, add offset to creep tumors",
        "sim_msg": "kind-of standardize on _socks_config=",
        "sim_diff": "diff --git a/test/test_controller.py b/test/test_controller.py @@ -979,7 +979,7 @@ class WebAgentTests(unittest.TestCase):\ncfg = Mock()\ntor = Tor(reactor, cfg)\n- agent = tor.web_agent(\"9151\", pool=self.pool)\n+ agent = tor.web_agent(pool=self.pool, _socks_config=\"9151\")\nresp = yield agent.request('GET', b'meejah.ca')\nself.assertEqual(self.expected_response, resp)\n@@ -991,7 +991,7 @@ class WebAgentTests(unittest.TestCase):\ncfg = Mock()\ntor = Tor(reactor, cfg)\n- agent = tor.web_agent(socks_d, pool=self.pool)\n+ agent = tor.web_agent(pool=self.pool, _socks_config=socks_d)\nresp = yield agent.request('GET', b'meejah.ca')\nself.assertEqual(self.expected_response, resp)\n@@ -1002,7 +1002,7 @@ class WebAgentTests(unittest.TestCase):\ncfg = Mock()\ntor = Tor(reactor, cfg)\n- agent = tor.web_agent(u\"9151\", pool=self.pool)\n+ agent = tor.web_agent(pool=self.pool, _socks_config=u\"9151\")\nresp = yield agent.request('GET', b'meejah.ca')\nself.assertEqual(self.expected_response, resp)\n@@ -1015,7 +1015,7 @@ class WebAgentTests(unittest.TestCase):\ncfg = Mock()\ntor = Tor(reactor, cfg)\n- agent = tor.web_agent(socks, pool=self.pool)\n+ agent = tor.web_agent(pool=self.pool, _socks_config=socks)\nresp = yield agent.request('GET', b'meejah.ca')\nself.assertEqual(self.expected_response, resp)\n@@ -1027,7 +1027,7 @@ class WebAgentTests(unittest.TestCase):\ntor = Tor(reactor, cfg)\nwith self.assertRaises(ValueError) as ctx:\n- agent = tor.web_agent(object(), pool=self.pool)\n+ agent = tor.web_agent(pool=self.pool, _socks_config=object())\nyield agent.request('GET', b'meejah.ca')\nself.assertTrue('socks_config' in str(ctx.exception))\n@@ -1087,7 +1087,7 @@ class TorStreamTests(unittest.TestCase):\nself.assertTrue(\"isn't going to work over Tor\", str(ctx.exception))\ndef test_stream_via_custom_socks(self):\n- self.tor.stream_via('meejah.ca', '1234', socks_port='localhost:9050')\n+ self.tor.stream_via('meejah.ca', '1234', _socks_config='localhost:9050')\nself.assertEqual(1, len(self.cfg.mock_calls))\ncall = self.cfg.mock_calls[0]\nself.assertEqual(\"create_socks_endpoint\", call[0])\n",
        "chatgpt_cot": "\"Fix compilation issue in TestBot file by adding missing await keywords and modifying the method run_can_place to improve test coverage.\""
    },
    {
        "org_diff": "diff --git a/src/api-engine/api_engine/urls.py b/src/api-engine/api_engine/urls.py @@ -56,13 +56,13 @@ SchemaView = get_schema_view(\n# define and register routers of api\nrouter = DefaultRouter(trailing_slash=False)\n-router.register(\"networks\", NetworkViewSet, base_name=\"network\")\n-router.register(\"agents\", AgentViewSet, base_name=\"agent\")\n-router.register(\"nodes\", NodeViewSet, base_name=\"node\")\n-router.register(\"organizations\", OrganizationViewSet, base_name=\"organization\")\n-router.register(\"users\", UserViewSet, base_name=\"user\")\n-router.register(\"files\", FileViewSet, base_name=\"file\")\n-# router.register(\"clusters\", ClusterViewSet, base_name=\"cluster\")\n+router.register(\"networks\", NetworkViewSet, basename=\"network\")\n+router.register(\"agents\", AgentViewSet, basename=\"agent\")\n+router.register(\"nodes\", NodeViewSet, basename=\"node\")\n+router.register(\"organizations\", OrganizationViewSet, basename=\"organization\")\n+router.register(\"users\", UserViewSet, basename=\"user\")\n+router.register(\"files\", FileViewSet, basename=\"file\")\n+# router.register(\"clusters\", ClusterViewSet, basename=\"cluster\")\nurlpatterns = router.urls\n",
        "org_msg": "modified base_name to basename",
        "sim_msg": "fix: include request routes in the api",
        "sim_diff": "diff --git a/packages/grid/backend/grid/api/router.py b/packages/grid/backend/grid/api/router.py @@ -10,12 +10,12 @@ from grid.api.roles import roles\nfrom grid.api.setup import setup\nfrom grid.api.syft import syft\nfrom grid.api.users.routes import router as user_router\n+from grid.api.requests.routes import router as requests_router\napi_router = APIRouter()\napi_router.include_router(login.router, tags=[\"login\"])\napi_router.include_router(user_router, prefix=\"/users\", tags=[\"users\"])\n-# comment out in merge\n-# api_router.include_router(requests_router, prefix=\"/requests\", tags=[\"requests\"])\n+api_router.include_router(requests_router, prefix=\"/requests\", tags=[\"requests\"])\napi_router.include_router(roles.router, prefix=\"/roles\", tags=[\"roles\"])\napi_router.include_router(syft.router, prefix=\"/syft\", tags=[\"syft\"])\napi_router.include_router(datasets.router, prefix=\"/datasets\", tags=[\"datasets\"])\n",
        "chatgpt_cot": "\"Correct router registration naming in urls.py for Network, Agent, Node, Organization, User, and File ViewSets to resolve naming inconsistency.\""
    },
    {
        "org_diff": "diff --git a/rasa_core_sdk/__init__.py b/rasa_core_sdk/__init__.py @@ -155,8 +155,9 @@ class Action(object):\nExecute the side effects of this action.\nArgs:\ndispatcher (CollectingDispatcher): the dispatcher which is used to\n- send messages back to the user. Use ``dipatcher.utter_message()``\n- or any other :class:`rasa_core_sdk.executor.CollectingDispatcher`\n+ send messages back to the user. Use\n+ ``dipatcher.utter_message()`` or any other\n+ :class:`rasa_core_sdk.executor.CollectingDispatcher`\nmethod.\ntracker (Tracker): the state tracker for the current\nuser. You can access slot values using\n",
        "org_msg": "Fixes max line lenghts",
        "sim_msg": "Better !remindme",
        "sim_diff": "diff --git a/pajbot/dispatch.py b/pajbot/dispatch.py @@ -633,13 +633,15 @@ class Dispatch:\nreturn False\nparts = message.split(' ')\n- if len(parts) < 2:\n+ if len(parts) < 1:\n# Not enough arguments\nreturn False\ndelay = int(parts[0])\n- extra_message = '{0} {1}'.format(source.username, ' '.join(parts[1:]).strip())\n+ reminder_text = ' '.join(parts[1:]).strip()\n+ extra_message = '{0}, your reminder from {1} seconds ago is over: {2}'.format(source.username_raw, delay, reminder_text)\n+ bot.say('{0}, I will remind you of \\'{2}\\' in {1} seconds. SeemsGood'.format(source.username_raw, delay, reminder_text))\nbot.execute_delayed(delay, bot.say, (extra_message, ))\ndef ord(bot, source, message, event, args):\n",
        "chatgpt_cot": "\"Fix typo in __init__.py file by correcting the spelling of dispatcher in the comment and update the dispatcher method call.\""
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/editor/text_edit.py b/node_manager_fkie/src/node_manager_fkie/editor/text_edit.py @@ -443,8 +443,17 @@ class TextEdit(QTextEdit):\ncursor.movePosition(QTextCursor.StartOfLine)\nelse:\n# shift one line two spaces to the right\n+ indent_prev = self.getIndentOfPreviewsBlock()\n+ if self.textCursor().positionInBlock() >= indent_prev:\ncursor.movePosition(QTextCursor.NextCharacter, QTextCursor.KeepAnchor, end - start)\ncursor.insertText(' ')\n+ else:\n+ # move to the position of previous indent\n+ cursor.movePosition(QTextCursor.StartOfLine)\n+ pose_of_line = cursor.position()\n+ cursor.movePosition(QTextCursor.EndOfLine, QTextCursor.KeepAnchor)\n+ cursor.insertText(\"%s%s\" % (' ' * indent_prev, cursor.selectedText().lstrip()))\n+ cursor.setPosition(pose_of_line + indent_prev, QTextCursor.MoveAnchor)\nelse:\n# shift the selected block two spaces to the left\nif back:\n@@ -523,6 +532,15 @@ class TextEdit(QTextEdit):\nreturn len(line) - len(line.lstrip(' '))\nreturn 0\n+ def getIndentOfPreviewsBlock(self):\n+ cursor = self.textCursor()\n+ if not cursor.isNull():\n+ cursor.movePosition(QTextCursor.PreviousBlock)\n+ cursor.movePosition(QTextCursor.EndOfLine, QTextCursor.KeepAnchor)\n+ line = cursor.selectedText()\n+ return len(line) - len(line.lstrip(' '))\n+ return 0\n+\n#############################################################################\n########## Drag&Drop ######\n#############################################################################\n",
        "org_msg": "node_manager_fkie: editor: adapt indent to previous line on tab",
        "sim_msg": "when forward search, term term not always at bottom of screen.",
        "sim_diff": "diff --git a/qualcoder/code_text.py b/qualcoder/code_text.py @@ -837,6 +837,13 @@ class DialogCodeText(QtWidgets.QWidget):\nif self.file_ is None or self.file_['id'] != next_result[0]['id']:\nself.load_file(next_result[0])\nself.ui.lineEdit_search.setText(self.search_term)\n+ # Adjust scroll bar so that the term term is not at the very bottom of screen.\n+ try:\n+ cursor.setPosition(cursor.position() + next_result[2] + 300)\n+ self.ui.textEdit.setTextCursor(cursor)\n+ except:\n+ pass\n+ # Highlight selected text\ncursor.setPosition(next_result[1])\ncursor.setPosition(cursor.position() + next_result[2], QtGui.QTextCursor.KeepAnchor)\nself.ui.textEdit.setTextCursor(cursor)\n",
        "chatgpt_cot": "Add method getIndentOfPreviewsBlock to get the indent of the previous block to the TextEdit class to handle indentation in the TextEdit class."
    },
    {
        "org_diff": "diff --git a/src/dashboard/src/layouts/Header.js b/src/dashboard/src/layouts/Header.js import React, { Component } from 'react';\nimport { Layout, message } from 'antd';\nimport Animate from 'rc-animate';\n-import router from 'umi/router';\n-import { connect, formatMessage } from 'umi';\n+import { connect, formatMessage, history } from 'umi';\nimport GlobalHeader from '@/components/GlobalHeader';\nimport TopNavHeader from '@/components/TopNavHeader';\nimport styles from './Header.less';\n@@ -56,15 +55,15 @@ class HeaderView extends Component {\nhandleMenuClick = ({ key }) => {\nconst { dispatch } = this.props;\nif (key === 'userCenter') {\n- router.push('/account/center');\n+ history.push('/account/center');\nreturn;\n}\nif (key === 'triggerError') {\n- router.push('/exception/trigger');\n+ history.push('/exception/trigger');\nreturn;\n}\nif (key === 'userinfo') {\n- router.push('/account/settings/base');\n+ history.push('/account/settings/base');\nreturn;\n}\nif (key === 'logout') {\n",
        "org_msg": "[fix-code-format] Fix umi Router Import Error\nUmi3 deprecated router, switch to umi history for the router feature.",
        "sim_msg": "remove stuff from requests/data",
        "sim_diff": "diff --git a/packages/grid/frontend/src/pages/_domain/requests/data.tsx b/packages/grid/frontend/src/pages/_domain/requests/data.tsx import {createContext, useContext, useMemo, useState} from 'react'\nimport Link from 'next/link'\nimport {Badge, Button, Divider, H2, H4, H5, Tabs, Tag, Text} from '@/omui'\n-import {SearchInput, TopContent, Tooltip, Accordion} from '@/components/lib'\n+import {SearchInput, TopContent, Tooltip} from '@/components/lib'\nimport {Alert} from '@/components/Alert'\nimport {FontAwesomeIcon} from '@fortawesome/react-fontawesome'\n-import {faCalendar, faCheck, faDownload, faExpandAlt, faLink, faTimes} from '@fortawesome/free-solid-svg-icons'\n+import {faCalendar, faCheck, faDownload, faLink, faTimes} from '@fortawesome/free-solid-svg-icons'\nimport cloneDeep from 'lodash.clonedeep'\n-import dayjs from 'dayjs'\nimport {TableItem, useOMUITable} from '@/components/Table'\nimport Modal from '@/components/Modal'\nimport {Base} from '@/components/Layouts'\n",
        "chatgpt_cot": "Update router to use history for navigation in HeaderView component. Fix navigation issue and improve code consistency."
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/editor/editor.py b/node_manager_fkie/src/node_manager_fkie/editor/editor.py @@ -616,6 +616,9 @@ class Editor(QMainWindow):\ncursor.setPosition(index, QTextCursor.MoveAnchor)\ncursor.movePosition(QTextCursor.NextCharacter, QTextCursor.KeepAnchor, len(search_text))\nself.tabWidget.currentWidget().setTextCursor(cursor)\n+ cursor_y = self.tabWidget.currentWidget().cursorRect().top()\n+ vbar = self.tabWidget.currentWidget().verticalScrollBar()\n+ vbar.setValue(vbar.value() + cursor_y * 0.8)\ndef on_search_result_on_open(self, search_text, found, path, index):\n'''\n",
        "org_msg": "node_manager_fkie: move selected text to top of the editor",
        "sim_msg": "Make search work in tree view\nNow it's iterating when activated (enter).",
        "sim_diff": "diff --git a/gaphor/ui/treecomponent.py b/gaphor/ui/treecomponent.py from __future__ import annotations\n-from functools import partial\n-\nfrom gi.repository import Gdk, GLib, GObject, Gtk\nfrom gaphor import UML\n@@ -33,6 +31,7 @@ from gaphor.ui.treemodel import (\ntree_item_sort,\nvisible,\n)\n+from gaphor.ui.treesearch import search\nSTART_EDIT_DELAY = 100 # ms\n@@ -43,6 +42,7 @@ class TreeComponent(UIComponent, ActionProvider):\nself.element_factory = element_factory\nself.modeling_language = modeling_language\nself.model = TreeModel()\n+ self.search = None\ndef open(self):\nself.event_manager.subscribe(self.on_element_created)\n@@ -66,7 +66,19 @@ class TreeComponent(UIComponent, ActionProvider):\nsort_model = Gtk.SortListModel.new(tree_model, tree_sorter)\nself.selection = Gtk.SingleSelection.new(sort_model)\n- self.search_bar = create_search_bar(partial(search_next, self.selection))\n+ def search_next(search_text):\n+ try:\n+ if not self.search:\n+ self.search = search(self.model, search_text)\n+ next_item = next(self.search)\n+ else:\n+ next_item = self.search.send(search_text)\n+ if next_item:\n+ self.select_element(next_item.element)\n+ except StopIteration:\n+ self.search = None\n+\n+ self.search_bar = create_search_bar(search_next)\nfactory = Gtk.SignalListItemFactory.new()\nfactory.connect(\n@@ -258,34 +270,25 @@ def create_search_bar(search_next, text_changed=None):\ndef on_search_changed(entry):\nnonlocal search_text\n+ new_text = entry.get_text()\nfilter_change = (\nGtk.FilterChange.MORE_STRICT\n- if search_text in entry.get_text()\n+ if search_text in new_text\nelse Gtk.FilterChange.LESS_STRICT\n- if entry.get_text() in search_text\n+ if new_text in search_text\nelse Gtk.FilterChange.DIFFERENT\n)\n- search_text = entry.get_text()\n- search_filter.changed(filter_change)\n+ search_text = new_text\n+ if text_changed:\n+ text_changed(search_text, filter_change)\ndef on_stop_search(_entry):\nnonlocal search_text\nsearch_text = \"\"\n- search_filter.changed(Gtk.FilterChange.LESS_STRICT)\n-\n- def on_filter_changed(_filter, change):\n- if text_changed:\n- text_changed(search_text, change)\ndef on_search_next(_entry):\nsearch_next(search_text)\n- def name_filter(item):\n- item = item.get_item()\n- return isinstance(item, TreeItem) and search_text.lower() in item.text.lower()\n-\n- search_filter = Gtk.CustomFilter.new(name_filter)\n- search_filter.connect(\"changed\", on_filter_changed)\nsearch_entry = Gtk.SearchEntry.new()\nsearch_entry.connect(\"search-changed\", on_search_changed)\nsearch_entry.connect(\"stop-search\", on_stop_search)\n@@ -298,10 +301,6 @@ def create_search_bar(search_next, text_changed=None):\nreturn search_bar\n-def search_next(selection, search_text):\n- print(\"search\", search_text)\n-\n-\ndef list_item_factory_setup(_factory, list_item, event_manager, modeling_language):\nbuilder = Gtk.Builder()\nbuilder.set_current_object(list_item)\n",
        "chatgpt_cot": "Add functionality to automatically scroll to the cursor position when opening search results in the Editor class."
    },
    {
        "org_diff": "diff --git a/sc2/game_state.py b/sc2/game_state.py from .units import Units\nfrom .power_source import PsionicMatrix\n+from .pixel_map import PixelMap\nclass Common(object):\nATTRIBUTES = [\n@@ -20,10 +21,19 @@ class Common(object):\nclass GameState(object):\ndef __init__(self, observation, game_data):\nself.common = Common(observation.observation.player_common)\n- self.units = Units.from_proto(observation.observation.raw_data.units, game_data)\nself.psionic_matrix = PsionicMatrix.from_proto(observation.observation.raw_data.player.power_sources)\nself.game_loop = observation.observation.game_loop\n+ destructables = [x for x in observation.observation.raw_data.units if x.alliance == 3 and x.radius > 1.5] # all destructable rocks except the one below the main base ramps\n+ self.destructables = Units.from_proto(destructables, game_data)\n+\n+ # fix for enemy units detected by sensor tower\n+ visibleUnits, hiddenUnits = [], []\n+ for u in observation.observation.raw_data.units:\n+ hiddenUnits.append(u) if u.is_blip else visibleUnits.append(u)\n+ self.units = Units.from_proto(visibleUnits, game_data)\n+ # self.blips = Units.from_proto(hiddenUnits, game_data) # TODO: fix me\n+\n@property\ndef mineral_field(self):\nreturn self.units.mineral_field\n",
        "org_msg": "Fix crash when enemy in sensor tower range + support destructible rocksu",
        "sim_msg": "Change to using scipy constants.",
        "sim_diff": "diff --git a/SimPEG/FLOW/Richards/Empirical.py b/SimPEG/FLOW/Richards/Empirical.py @@ -5,6 +5,7 @@ from __future__ import unicode_literals\nimport numpy as np\nimport scipy.sparse as sp\n+from scipy import constants\nfrom SimPEG import Utils, Props\n@@ -575,77 +576,77 @@ class VanGenuchtenParams(object):\ndef sand(self):\nreturn {\n\"theta_r\": 0.020, \"theta_s\": 0.417, \"alpha\": 0.138*100.,\n- \"n\": 1.592, \"Ks\": 504.0/100./24./60./60.\n+ \"n\": 1.592, \"Ks\": 504.0*constants.centi/constants.day\n}\n@property\ndef loamy_sand(self):\nreturn {\n\"theta_r\": 0.035, \"theta_s\": 0.401, \"alpha\": 0.115*100.,\n- \"n\": 1.474, \"Ks\": 146.6/100./24./60./60.\n+ \"n\": 1.474, \"Ks\": 146.6*constants.centi/constants.day\n}\n@property\ndef sandy_loam(self):\nreturn {\n\"theta_r\": 0.041, \"theta_s\": 0.412, \"alpha\": 0.068*100.,\n- \"n\": 1.322, \"Ks\": 62.16/100./24./60./60.\n+ \"n\": 1.322, \"Ks\": 62.16*constants.centi/constants.day\n}\n@property\ndef loam(self):\nreturn {\n\"theta_r\": 0.027, \"theta_s\": 0.434, \"alpha\": 0.090*100.,\n- \"n\": 1.220, \"Ks\": 16.32/100./24./60./60.\n+ \"n\": 1.220, \"Ks\": 16.32*constants.centi/constants.day\n}\n@property\ndef silt_loam(self):\nreturn {\n\"theta_r\": 0.015, \"theta_s\": 0.486, \"alpha\": 0.048*100.,\n- \"n\": 1.211, \"Ks\": 31.68/100./24./60./60.\n+ \"n\": 1.211, \"Ks\": 31.68*constants.centi/constants.day\n}\n@property\ndef sandy_clay_loam(self):\nreturn {\n\"theta_r\": 0.068, \"theta_s\": 0.330, \"alpha\": 0.036*100.,\n- \"n\": 1.250, \"Ks\": 10.32/100./24./60./60.\n+ \"n\": 1.250, \"Ks\": 10.32*constants.centi/constants.day\n}\n@property\ndef clay_loam(self):\nreturn {\n\"theta_r\": 0.075, \"theta_s\": 0.390, \"alpha\": 0.039*100.,\n- \"n\": 1.194, \"Ks\": 5.52/100./24./60./60.\n+ \"n\": 1.194, \"Ks\": 5.52*constants.centi/constants.day\n}\n@property\ndef silty_clay_loam(self):\nreturn {\n\"theta_r\": 0.040, \"theta_s\": 0.432, \"alpha\": 0.031*100.,\n- \"n\": 1.151, \"Ks\": 3.60/100./24./60./60.\n+ \"n\": 1.151, \"Ks\": 3.60*constants.centi/constants.day\n}\n@property\ndef sandy_clay(self):\nreturn {\n\"theta_r\": 0.109, \"theta_s\": 0.321, \"alpha\": 0.034*100.,\n- \"n\": 1.168, \"Ks\": 2.88/100./24./60./60.\n+ \"n\": 1.168, \"Ks\": 2.88*constants.centi/constants.day\n}\n@property\ndef silty_clay(self):\nreturn {\n\"theta_r\": 0.056, \"theta_s\": 0.423, \"alpha\": 0.029*100.,\n- \"n\": 1.127, \"Ks\": 2.16/100./24./60./60.\n+ \"n\": 1.127, \"Ks\": 2.16*constants.centi/constants.day\n}\n@property\ndef clay(self):\nreturn {\n\"theta_r\": 0.090, \"theta_s\": 0.385, \"alpha\": 0.027*100.,\n- \"n\": 1.131, \"Ks\": 1.44/100./24./60./60.\n+ \"n\": 1.131, \"Ks\": 1.44*constants.centi/constants.day\n}\n# From:\n",
        "chatgpt_cot": "Add destructables and fix enemy units detection in game state for improved gameplay and functionality."
    },
    {
        "org_diff": "diff --git a/sc2/bot_ai.py b/sc2/bot_ai.py @@ -164,18 +164,14 @@ class BotAI:\nand friends return the wrong value when there are an odd number of zerglings\nand banelings. This function corrects the bad values. \"\"\"\n# TODO: remove when Blizzard/sc2client-proto#123 gets fixed.\n- correction = (\n- self.units(\n- {\n+ half_supply_units = {\nUnitTypeId.ZERGLING,\nUnitTypeId.ZERGLINGBURROWED,\nUnitTypeId.BANELING,\nUnitTypeId.BANELINGBURROWED,\nUnitTypeId.BANELINGCOCOON,\n}\n- ).amount\n- % 2\n- )\n+ correction = self.units(half_supply_units).amount % 2\nself.supply_used += correction\nself.supply_army += correction\nself.supply_left -= correction\n",
        "org_msg": "Format zerg supply correction",
        "sim_msg": "Fix translated string\nStockItem -> stock item",
        "sim_diff": "diff --git a/InvenTree/order/models.py b/InvenTree/order/models.py @@ -1376,7 +1376,7 @@ class SalesOrderAllocation(models.Model):\n# TODO: The logic here needs improving. Do we need to subtract our own amount, or something?\nif self.item.quantity - self.item.allocation_count() + self.quantity < self.quantity:\n- errors['quantity'] = _('StockItem is over-allocated')\n+ errors['quantity'] = _('Stock item is over-allocated')\nif self.quantity <= 0:\nerrors['quantity'] = _('Allocation quantity must be greater than zero')\n",
        "chatgpt_cot": "\"Correct calculation of supply units for odd number of zerglings and banelings, fixing value return issue. Removed redundant code and simplified correction calculation.\""
    },
    {
        "org_diff": "diff --git a/src/api-engine/api/routes/chaincode/views.py b/src/api-engine/api/routes/chaincode/views.py @@ -368,9 +368,8 @@ class ChainCodeViewSet(viewsets.ViewSet):\npeer_root_certs.append(peer_tls_cert)\npeer_channel_cli = PeerChainCode(\"v2.2.0\", **envs)\n- policy1 = \"\\\"OR ('Org1.cello.comMSP.member')\\\"\"\ncode = peer_channel_cli.lifecycle_commit(orderer_url, orderer_tls_root_cert, channel_name,\n- chaincode_name, chaincode_version, policy1,\n+ chaincode_name, chaincode_version, policy,\npeer_address_list, peer_root_certs, sequence)\nif code != 0:\nreturn Response(err(\"commit failed.\"), status=status.HTTP_400_BAD_REQUEST)\n",
        "org_msg": "[#issue-402] implement commit function and modify channel config policy\nimplement commit function and modify channel config policy\nClose",
        "sim_msg": "Remove unused lines at PeerService",
        "sim_diff": "diff --git a/loopchain/peer/peer_service.py b/loopchain/peer/peer_service.py @@ -89,9 +89,6 @@ class PeerService:\nself.__outer_service: PeerOuterService = None\nself.__channel_services = {}\n- self.__reset_voter_in_progress = False\n- self.__json_conf_path = None\n-\nself.__node_keys: dict = {}\nObjectManager().peer_service = self\n@@ -112,10 +109,6 @@ class PeerService:\ndef rest_target(self):\nreturn self.__rest_target\n- @property\n- def json_conf_path(self):\n- return self.__json_conf_path\n-\n@property\ndef channel_infos(self):\nreturn self.__channel_infos\n",
        "chatgpt_cot": "\"Update policy variable name and remove unnecessary quotes in chaincode views for lifecycle_commit method.\""
    },
    {
        "org_diff": "diff --git a/sc2/protocol.py b/sc2/protocol.py @@ -36,16 +36,14 @@ class Protocol:\ntry:\nawait self._ws.send_bytes(request.SerializeToString())\nexcept TypeError:\n- logger.exception(\"Cannot send: Connection already closed.\")\n- raise ConnectionAlreadyClosed(\"Connection already closed.\")\n+ raise ConnectionAlreadyClosed(\"Cannot send: Connection already closed.\")\nlogger.debug(f\"Request sent\")\nresponse = sc_pb.Response()\ntry:\nresponse_bytes = await self._ws.receive_bytes()\nexcept TypeError:\n- logger.exception(\"Cannot receive: Connection already closed.\")\n- raise ConnectionAlreadyClosed(\"Connection already closed.\")\n+ raise ConnectionAlreadyClosed(\"Cannot receive: Connection already closed.\")\nexcept asyncio.CancelledError:\n# If request is sent, the response must be received before reraising cancel\ntry:\n@@ -82,4 +80,7 @@ class Protocol:\nreturn result\nasync def quit(self):\n+ try:\nawait self._execute(quit=sc_pb.RequestQuit())\n+ except ConnectionAlreadyClosed:\n+ pass\n",
        "org_msg": "Ignore closed connections in response to quit requests",
        "sim_msg": "close protocol if transport reuse brings responses before requests",
        "sim_diff": "diff --git a/lbrynet/blob_exchange/client.py b/lbrynet/blob_exchange/client.py @@ -35,6 +35,9 @@ class BlobExchangeClientProtocol(asyncio.Protocol):\nif self._response_fut and not self._response_fut.done():\nself._response_fut.cancel()\nreturn\n+ if not self._response_fut:\n+ log.warning(\"Protocol received data before expected, probable race on keep alive. Closing transport.\")\n+ return self.close()\nif self._blob_bytes_received and not self.writer.closed():\nreturn self._write(data)\n",
        "chatgpt_cot": "Fix exception handling in Protocol class for sending and receiving data to prevent connection closure errors. Added try-except block for quit method to handle ConnectionAlreadyClosed exception."
    },
    {
        "org_diff": "diff --git a/sc2/bot_ai.py b/sc2/bot_ai.py @@ -600,13 +600,13 @@ class BotAI:\nreturn await self._client.actions(actions)\ndef prevent_double_actions(self, action):\n+ # always add actions if queued\n+ if action.queue:\n+ return True\nif action.unit.orders:\n# action: UnitCommand\n# current_action: UnitOrder\ncurrent_action = action.unit.orders[0]\n- # always add actions if queued\n- if action.queue:\n- return True\n# different action\nif current_action.ability.id != action.ability:\nreturn True\n@@ -624,9 +624,6 @@ class BotAI:\n):\n# remove action if same target position\nreturn False\n- else:\n- return True\n- else:\nreturn True\nasync def chat_send(self, message: str):\n",
        "org_msg": "Improve double actions",
        "sim_msg": "if model hash does not exist the error messages are more obvious",
        "sim_diff": "diff --git a/bot_manager.py b/bot_manager.py @@ -238,7 +238,12 @@ class BotManager:\ndef maybe_compress_and_upload(self, filename):\nif not os.path.isfile(filename + '.gz'):\ncompressed = self.compress(filename)\n- self.server_manager.maybe_upload_replay(compressed, self.bot_parameters['model_hash'])\n+ model_hash = \"NO_HASH\"\n+ if self.bot_parameters is None:\n+ print('BOT PARAMETERS DO NOT EXIST', file=sys.stderr)\n+ else:\n+ model_hash = self.bot_parameters['model_hash']\n+ self.server_manager.maybe_upload_replay(compressed, model_hash)\ndef compress(self, filename):\noutput = filename + '.gz'\n",
        "chatgpt_cot": "\"Add condition to prevent double actions in BotAI class, fix potential issue with queued actions, and improve code readability.\""
    },
    {
        "org_diff": "diff --git a/sc2/sc2process.py b/sc2/sc2process.py @@ -34,7 +34,6 @@ class SC2Process(object):\nself._ws = None\nasync def __aenter__(self):\n- print(\"E>\", self._port)\nkill_switch.add(self)\ndef signal_handler(signal, frame):\n@@ -50,14 +49,11 @@ class SC2Process(object):\nself._clean()\nraise\n- print(\"E<\")\nreturn Controller(self._ws)\nasync def __aexit__(self, *args):\n- print(\"X>\")\nkill_switch.kill_all()\nsignal.signal(signal.SIGINT, signal.SIG_DFL)\n- print(\"X<\")\n@property\ndef ws_url(self):\n",
        "org_msg": "Remove redundant debug prints",
        "sim_msg": "[NotSoBot] Maybe fix transport error and other minor fixes",
        "sim_diff": "diff --git a/notsobot/notsobot.py b/notsobot/notsobot.py @@ -229,6 +229,7 @@ class NotSoBot(commands.Cog):\nasync def run_process(self, code, response=False):\ntry:\n+ transport = None\nloop = self.bot.loop\nexit_future = asyncio.Future(loop=loop)\ncreate = loop.subprocess_exec(\n@@ -246,6 +247,7 @@ class NotSoBot(commands.Cog):\nprint(e)\nreturn False\nfinally:\n+ if transport:\ntransport.close()\nasync def gist(self, ctx, idk, content: str):\n@@ -626,8 +628,8 @@ class NotSoBot(commands.Cog):\nawait ctx.send(file=file)\nos.remove(path)\nos.remove(path2)\n- except Exception as e:\n- await ctx.send(e)\n+ except Exception:\n+ log.error(\"Error triggering image\", exc_info=True)\ntry:\nos.remove(path)\nos.remove(path2)\n@@ -1603,6 +1605,8 @@ class NotSoBot(commands.Cog):\nurls = await ImageFinder().search_for_images(ctx)\nurl = urls[0]\nb = await self.bytes_download(url)\n+ if not b:\n+ return await ctx.send(\"That's not a valid image to rotate.\")\ndef rotate_img(b, degrees):\nimg = PIL.Image.open(b).convert(\"RGBA\")\n",
        "chatgpt_cot": "\"Remove print statements and add signal handling in SC2Process class\""
    },
    {
        "org_diff": "diff --git a/Makefile b/Makefile @@ -180,15 +180,11 @@ test-case: ##@Code Run test case for flask server\n@$(MAKE) -C src/operator-dashboard/test/ all\nclean:\n- make stop-docker-compose\n- rm -rf .tox .cache *.egg-info build/\n- find . -name \"*.pyc\" -o -name \"__pycache__\" | xargs rm -rf\n- rm -rf /opt/cello/\n+ make remove-docker-compose\ndeep-clean:\n- make stop\n+ make clean\nmake image-clean\n- rm -rf /opt/cello/\n# TODO (david_dornseier): As long as there are no release versions, always rewrite\n@@ -226,10 +222,14 @@ start: ##@Service Start service\nstop-docker-compose:\necho \"Stop all services with bootup/docker-compose-files/${COMPOSE_FILE}...\"\ndocker-compose -f bootup/docker-compose-files/${COMPOSE_FILE} stop\n+ echo \"Stop all hyperledger-fabric nodes ...\"\n+ docker ps | grep \"hyperledger-fabric\" | awk '{print $1}' | xargs docker stop\nremove-docker-compose:\necho \"Remove all services with ${COMPOSE_FILE}...\"\n- docker-compose -f bootup/docker-compose-files/${COMPOSE_FILE} rm -f -a\n+ docker-compose -f bootup/docker-compose-files/${COMPOSE_FILE} down -v\n+ echo \"Stop all hyperledger-fabric nodes ...\"\n+ docker ps -a | grep \"hyperledger-fabric\" | awk '{print $1}' | xargs docker rm -f\nstart-k8s:\n@$(MAKE) -C bootup/kubernetes init-yaml\n",
        "org_msg": "Use appropriate docker commands to run the actions.",
        "sim_msg": "Separate grabbing the Kubernaut cluster from starting teleproxy.",
        "sim_diff": "diff --git a/Makefile b/Makefile @@ -186,6 +186,7 @@ print-vars:\n@echo \"AMBASSADOR_DOCKER_TAG = $(AMBASSADOR_DOCKER_TAG)\"\n@echo \"AMBASSADOR_DOCKER_IMAGE = $(AMBASSADOR_DOCKER_IMAGE)\"\n@echo \"KAT_BACKEND_RELEASE = $(KAT_BACKEND_RELEASE)\"\n+ @echo \"KUBECONFIG = = $(KUBECONFIG)\"\nexport-vars:\n@echo \"export MAIN_BRANCH='$(MAIN_BRANCH)'\"\n@@ -207,6 +208,7 @@ export-vars:\n@echo \"export AMBASSADOR_DOCKER_TAG='$(AMBASSADOR_DOCKER_TAG)'\"\n@echo \"export AMBASSADOR_DOCKER_IMAGE='$(AMBASSADOR_DOCKER_IMAGE)'\"\n@echo \"export KAT_BACKEND_RELEASE='$(KAT_BACKEND_RELEASE)'\"\n+ @echo \"export KUBECONFIG='$(KUBECONFIG)'\"\n# All of this will likely fail horribly outside of CI, for the record.\ndocker-registry:\n@@ -215,6 +217,10 @@ ifneq ($(DOCKER_LOCAL_REGISTRY),)\necho \"make docker-registry is only for CI\" >&2 ;\\\nexit 1 ;\\\nfi\n+ @if [ -z \"$(KUBECONFIG)\" ]; then \\\n+ echo \"No KUBECONFIG\" >&2 ;\\\n+ exit 1 ;\\\n+ fi\n@if [ ! -r .docker_port_forward ]; then \\\necho \"Starting local Docker registry in Kubernetes\" ;\\\nkubectl apply -f releng/docker-registry.yaml ;\\\n@@ -355,6 +361,8 @@ ifeq ($(USE_KUBERNAUT), true)\n$(KUBERNAUT_CLAIM)\ncp ~/.kube/$(CLAIM_NAME).yaml cluster.yaml\nendif\n+\n+cluster-and-teleproxy: cluster.yaml\nrm -rf /tmp/k8s-*.yaml\n@echo \"Killing teleproxy\"\n$(call kill_teleproxy)\n@@ -362,7 +370,7 @@ endif\n@echo \"Sleeping for Teleproxy cluster\"\nsleep 10\n-setup-test: cluster.yaml\n+setup-test: cluster-and-teleproxy\nteleproxy-restart:\n@echo \"Killing teleproxy\"\n@@ -382,7 +390,7 @@ teleproxy-stop:\necho \"teleproxy stopped\" >&2; \\\nfi\n-shell: setup-develop cluster.yaml\n+shell: setup-develop cluster-and-teleproxy\nAMBASSADOR_DOCKER_IMAGE=\"$(AMBASSADOR_DOCKER_IMAGE)\" \\\nAMBASSADOR_DOCKER_IMAGE_CACHED=\"$(AMBASSADOR_DOCKER_IMAGE_CACHED)\" \\\nAMBASSADOR_BASE_IMAGE=\"$(AMBASSADOR_BASE_IMAGE)\" \\\n@@ -391,12 +399,12 @@ shell: setup-develop cluster.yaml\nbash --init-file releng/init.sh -i\nclean-test:\n- rm -f cluster.yaml\n+ rm -f cluster-and-teleproxy\ntest -x $(KUBERNAUT) && $(KUBERNAUT_DISCARD) || true\nrm -f $(CLAIM_FILE)\n$(call kill_teleproxy)\n-test: setup-develop cluster.yaml\n+test: setup-develop cluster-and-teleproxy\ncd ambassador && \\\nAMBASSADOR_DOCKER_IMAGE=\"$(AMBASSADOR_DOCKER_IMAGE)\" \\\nAMBASSADOR_DOCKER_IMAGE_CACHED=\"$(AMBASSADOR_DOCKER_IMAGE_CACHED)\" \\\n",
        "chatgpt_cot": "Refactor Makefile for better Docker management and service control. Improve start, stop, and clean operations for increased efficiency and clarity."
    },
    {
        "org_diff": "diff --git a/sc2/position.py b/sc2/position.py @@ -2,6 +2,9 @@ from math import sqrt, pi, sin, cos, atan2\nimport random\nimport itertools\n+FLOAT_DIGITS = 8\n+EPSILON = 10**(-FLOAT_DIGITS)\n+\ndef _sign(num):\nif num == 0:\nreturn 0\n@@ -21,7 +24,7 @@ class Pointlike(tuple):\nassert isinstance(p, Pointlike)\nif self == p:\nreturn 0\n- return sqrt(sum(self.__class__((b-a)**2 for a, b in itertools.zip_longest(self, p[:len(self)], fillvalue=0))))\n+ return sqrt(sum(self.__class__((b-a)**2 for a, b in itertools.zip_longest(self, p, fillvalue=0))))\ndef sort_by_distance(self, ps):\nreturn sorted(ps, key=lambda p: self.distance_to(p))\n@@ -36,11 +39,19 @@ class Pointlike(tuple):\nreturn self.__class__(_sign(b - a) for a, b in itertools.zip_longest(self, p[:len(self)], fillvalue=0))\ndef towards(self, p, distance=1, limit=False):\n+ assert self != p\nd = self.distance_to(p)\nif limit:\ndistance = min(d, distance)\nreturn self.__class__(a + (b - a) / d * distance for a, b in itertools.zip_longest(self, p[:len(self)], fillvalue=0))\n+ def __eq__(self, other):\n+ assert isinstance(other, tuple)\n+ return all(abs(a - b) < EPSILON for a, b in itertools.zip_longest(self, other, fillvalue=0))\n+\n+ def __hash__(self):\n+ return hash(tuple(int(c * FLOAT_DIGITS) for c in self))\n+\nclass Point2(Pointlike):\n@classmethod\n@@ -63,24 +74,21 @@ class Point2(Pointlike):\ndef to3(self):\nreturn Point3((*self, 0))\n- def random_on_distance(self, distance, angle=None):\n- if isinstance(distance, tuple):\n+ def random_on_distance(self, distance):\n+ if isinstance(distance, (tuple, list)): # interval\ndistance = distance[0] + random.random() * (distance[1] - distance[0])\nassert distance > 0\n-\n- if angle is None:\nangle = random.random() * 2 * pi\ndx, dy = cos(angle), sin(angle)\nreturn Point2((self.x + dx * distance, self.y + dy * distance))\n- def towards_random_angle(self, p, max_difference=(pi/4), distance=1):\n- dx, dy = self.to2.towards(p.to2, 1)\n- angle = atan2(dy, dx)\n+ def towards_with_random_angle(self, p, distance=1, max_difference=(pi/4)):\n+ tx, ty = self.to2.towards(p.to2, 1)\n+ angle = atan2(ty - self.y, tx - self.x)\nangle = (angle - max_difference) + max_difference * 2 * random.random()\n- return self.random_on_distance(distance, angle)\n-\n+ return Point2((self.x + cos(angle) * distance, self.y + sin(angle) * distance))\nclass Point3(Point2):\n@classmethod\n",
        "org_msg": "Rename and fix towards_with_random_angle",
        "sim_msg": "only use the largest connected component as trav_map",
        "sim_diff": "diff --git a/gibson2/core/physics/scene.py b/gibson2/core/physics/scene.py @@ -82,7 +82,7 @@ class BuildingScene(Scene):\nself.trav_map_resolution = trav_map_resolution\nself.trav_map_original_size = None\nself.trav_map_size = None\n- self.trav_map_erosion = 3\n+ self.trav_map_erosion = 2\nself.build_graph = build_graph\nself.num_waypoints = num_waypoints\nself.waypoint_interval = int(waypoint_resolution / trav_map_resolution)\n@@ -137,7 +137,6 @@ class BuildingScene(Scene):\nobstacle_map = np.array(obstacle_map.resize((self.trav_map_size, self.trav_map_size)))\ntrav_map[obstacle_map == 0] = 0\ntrav_map = cv2.erode(trav_map, np.ones((self.trav_map_erosion, self.trav_map_erosion)))\n- self.floor_map.append(trav_map)\nif self.build_graph:\ng = nx.Graph()\n@@ -151,8 +150,19 @@ class BuildingScene(Scene):\nif 0 <= n[0] < self.trav_map_size and 0 <= n[1] < self.trav_map_size and \\\ntrav_map[n[0], n[1]] > 0:\ng.add_edge(n, (i, j), weight=self.l2_distance(n, (i, j)))\n+\n+ # only take the largest connected component\n+ largest_cc = max(nx.connected_components(g), key=len)\n+ g = nx.subgraph(g, largest_cc)\nself.floor_graph.append(g)\n+ # update trav_map accordingly\n+ trav_map[:, :] = 0\n+ for node in largest_cc:\n+ trav_map[node[0], node[1]] = 255\n+\n+ self.floor_map.append(trav_map)\n+\nreturn [boundaryUid] + [item for item in self.ground_plane_mjcf]\ndef get_random_point(self):\n",
        "chatgpt_cot": "Add FLOAT_DIGITS and EPSILON to improve precision and add new methods towards_with_random_angle and __eq__ and __hash__ to Pointlike."
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/cmake/version.cmake b/node_manager_fkie/cmake/version.cmake @@ -2,6 +2,10 @@ include(CMakeParseArguments)\nmacro(generate_version)\nfind_program(GIT git)\n+ if (NOT GIT)\n+ message(STATUS \"git not found, VERSION and DATE files are not created\")\n+ return()\n+ endif()\n# install a file with version tag\nset(VERSION_DIR \"${CATKIN_DEVEL_PREFIX}/${CATKIN_PACKAGE_SHARE_DESTINATION}\")\nset(VERSION_FILES \"\")\n",
        "org_msg": "node_manager_fkie: fix version detection if no git is available",
        "sim_msg": "set policy for ROOT variables",
        "sim_diff": "diff --git a/CMakeLists.txt b/CMakeLists.txt -cmake_minimum_required(VERSION 3.10)\n+cmake_minimum_required(VERSION 3.13)\n+cmake_policy(SET CMP0074 NEW)\nif(DEFINED ENV{VCPKG_ROOT_DIR} AND NOT DEFINED VCPKG_ROOT_DIR)\nset(VCPKG_ROOT_DIR \"$ENV{VCPKG_ROOT_DIR}\"\n@@ -50,8 +51,6 @@ if(NOT CASADI_DIR)\nOUTPUT_STRIP_TRAILING_WHITESPACE)\nfile(TO_CMAKE_PATH ${CASADI_DIR} CASADI_DIR)\nmessage(\"Found casadi path: ${CASADI_DIR}\")\n- FILE(GLOB children RELATIVE ${CASADI_DIR} ${CASADI_DIR}/*)\n- message(\"Contents of casadi path: ${children}\")\nendif()\nfind_package(casadi CONFIG PATHS ${CASADI_DIR} REQUIRED)\n",
        "chatgpt_cot": "Add check for git executable in generate_version macro to prevent creation of VERSION and DATE files if git is not found."
    },
    {
        "org_diff": "diff --git a/sc2/game_data.py b/sc2/game_data.py @@ -19,7 +19,7 @@ FREE_ABILITIES = {\"Lower\", \"Raise\", \"Land\", \"Lift\", \"Hold\", \"Harvest\"}\nclass GameData:\ndef __init__(self, data):\nids = set(a.value for a in AbilityId if a.value != 0)\n- self.abilities = {a.ability_id: AbilityData(self, a) for a in data.abilities if a.ability_id in ids}\n+ self.abilities = {a.ability_id: AbilityData(self, a) for a in data.abilities if a.ability_id in ids and a.available}\nself.units = {u.unit_id: UnitTypeData(self, u) for u in data.units if u.available}\nself.upgrades = {u.upgrade_id: UpgradeData(self, u) for u in data.upgrades}\nself.unit_types: Dict[int, UnitTypeId] = {}\n",
        "org_msg": "Filter out unavailable abilities",
        "sim_msg": "Fixes based on the PR comments",
        "sim_diff": "diff --git a/packages/fetchai/skills/tac_control_contract/game.py b/packages/fetchai/skills/tac_control_contract/game.py @@ -889,7 +889,7 @@ class Game(Model):\n+ \"\\n\"\n)\nfor good_id, quantity in agent_state.quantities_by_good_id.items():\n- result += \" \" + str(good_id) + \": \" + str(quantity) + \"\\n\"\n+ result += \" \" + good_id + \": \" + str(quantity) + \"\\n\"\nfor currency_id, amount in agent_state.amount_by_currency_id.items():\nresult += \" \" + currency_id + \": \" + str(amount) + \"\\n\"\nresult += \" score: \" + str(round(agent_state.get_score(), 2)) + \"\\n\"\n@@ -901,7 +901,7 @@ class Game(Model):\n\"\"\"Get equilibrium summary.\"\"\"\nresult = \"\\n\" + \"Equilibrium prices: \\n\"\nfor good_id, eq_price in self.initialization.good_id_to_eq_prices.items():\n- result = result + str(good_id) + \" \" + str(eq_price) + \"\\n\"\n+ result = result + good_id + \" \" + str(eq_price) + \"\\n\"\nresult = result + \"\\n\"\nresult = result + \"Equilibrium good allocation: \\n\"\nfor (\n@@ -915,7 +915,7 @@ class Game(Model):\n+ \":\\n\"\n)\nfor good_id, quantity in eq_allocations.items():\n- result = result + \" \" + str(good_id) + \": \" + str(quantity) + \"\\n\"\n+ result = result + \" \" + good_id + \": \" + str(quantity) + \"\\n\"\nresult = result + \"\\n\"\nresult = result + \"Equilibrium money allocation: \\n\"\nfor (\n",
        "chatgpt_cot": "\"Fix filtering of available abilities in GameData class constructor\""
    },
    {
        "org_diff": "diff --git a/build_image/docker/common/api-engine/Dockerfile.in b/build_image/docker/common/api-engine/Dockerfile.in @@ -15,7 +15,7 @@ COPY src/api-engine ./\nCOPY template/node /opt/node\n# Install compiled code tools from Artifactory and copy it to opt folder.\n-RUN curl -X GET \"https://hyperledger.jfrog.io/artifactory/fabric-binaries/hyperledger-fabric-linux-amd64-2.2-stable.tar.gz?archiveType=gzip\" > bin.tar.gz \\\n+RUN curl \"https://hyperledger.jfrog.io/artifactory/fabric-binaries/hyperledger-fabric-linux-amd64-2.2-stable.tar.gz?archiveType=gzip\" > bin.tar.gz \\\n&& tar -xzvf bin.tar.gz -C /opt/\n# Install python dependencies\n",
        "org_msg": "Removed unnecessary flags for downloading compiled code tools.",
        "sim_msg": "Working out changed augurface stuff.",
        "sim_diff": "diff --git a/docker/augurface/Dockerfile b/docker/augurface/Dockerfile @@ -8,7 +8,7 @@ WORKDIR /augur/frontend/\nCOPY ./docker/frontend/docker.config.json frontend.config.json\nFROM build-stage as augurface\n-WORKDIR /augur/augurface/\n+WORKDIR /augur/augur/augurface/\nCOPY augur/augurface/package.json .\nCOPY augur/augurface/package-lock.json .\nRUN npm install\n",
        "chatgpt_cot": "Fix download link in Dockerfile for API Engine to avoid redirection issues during build process."
    },
    {
        "org_diff": "diff --git a/master_discovery_fkie/src/master_discovery_fkie/udp.py b/master_discovery_fkie/src/master_discovery_fkie/udp.py @@ -371,6 +371,7 @@ class DiscoverSocket(socket.socket):\n:rtype: bool\n'''\n+ if platform.system() in ['Linux', 'FreeBSD']:\nSIOCGIFFLAGS = 0x8913\nIFF_MULTICAST = 0x1000 # Supports multicast.\nIFF_UP = 0x1 # Interface is up.\n@@ -384,6 +385,8 @@ class DiscoverSocket(socket.socket):\nif ((flags & IFF_MULTICAST) != 0) & ((flags & IFF_UP) != 0):\nreturn True\nreturn False\n+ else:\n+ return True\n@staticmethod\ndef localifs():\n",
        "org_msg": "perform  test for multicast interfaces only on Linux and FreeBSD",
        "sim_msg": "Additional Refactoring of DeleteUser",
        "sim_diff": "diff --git a/functions/securityFunc.py b/functions/securityFunc.py @@ -9,10 +9,11 @@ from classes import Channel\nfrom classes import Sec\nfrom classes import invites\nfrom classes import views\n+from classes import comments\nfrom globals import globalvars\n-from functions import cache\n+from functions import cache, system\nlog = logging.getLogger('app.functions.securityFunctions')\n@@ -80,6 +81,20 @@ def delete_user(userID):\nif userQuery != None:\nchannelQuery = Channel.Channel.query.filter_by(owningUser=userQuery.id).all()\nusername = userQuery.username\n+\n+ # Delete any existing Invites\n+ inviteQuery = invites.invitedViewer.query.filter_by(userID=int(userID)).all()\n+ for invite in inviteQuery:\n+ db.session.delete(invite)\n+ db.session.commit()\n+\n+ # Delete any existing User Comments\n+ commentQuery = comments.videoComments.query.filter_by(userID=int(userID)).all()\n+ for comment in commentQuery:\n+ db.session.delete(comment)\n+ db.session.commit()\n+\n+ # Delete Channels and all Channel Data\nfor channel in channelQuery:\nvideoQuery = channel.recordedVideo\nfor video in videoQuery:\n@@ -101,6 +116,10 @@ def delete_user(userID):\ndb.session.delete(userQuery)\ndb.session.commit()\nlog.warning({\"level\": \"warning\", \"message\": \"User Deleted - \" + username})\n+ system.newLog(1, \"User \" + current_user.username + \" deleted User \" + username)\n+ return True\n+ else:\n+ return False\ndef uia_username_mapper(identity):\n# we allow pretty much anything - but we bleach it.\n",
        "chatgpt_cot": "Add platform check for Linux and FreeBSD to set IFF_MULTICAST and IFF_UP flags in DiscoverSocket class in udp.py."
    },
    {
        "org_diff": "diff --git a/examples/zerg/zerg_rush.py b/examples/zerg/zerg_rush.py @@ -111,7 +111,7 @@ class ZergRushBot(sc2.BotAI):\n# If we have no queen, try to build a queen if we have a spawning pool compelted\nelif (\n- self.units(UnitTypeId.QUEEN).amount + self.already_pending(UnitTypeId.QUEEN) == 0\n+ self.units(UnitTypeId.QUEEN).amount + self.already_pending(UnitTypeId.QUEEN) < self.townhalls.amount\nand self.structures(UnitTypeId.SPAWNINGPOOL).ready\n):\nif self.can_afford(UnitTypeId.QUEEN):\n",
        "org_msg": "Add more queens to zerg rush bot",
        "sim_msg": "add missing  padding arguments to class construcrots for dowmsample blocks",
        "sim_diff": "diff --git a/batchflow/models/torch/layers/core.py b/batchflow/models/torch/layers/core.py @@ -341,7 +341,7 @@ class _Pool(nn.Module):\nself.pool = _fn[get_num_dims(inputs)](**kwargs)\nelse:\n- self.pool = _fn(inputs=inputs, **kwargs)\n+ self.pool = _fn(inputs=inputs, padding=padding, **kwargs)\ndef forward(self, x):\nif self.padding:\n@@ -358,7 +358,7 @@ MAXPOOL = {\nclass MaxPool(_Pool):\n\"\"\" Multi-dimensional max pooling layer \"\"\"\ndef __init__(self, padding='same', **kwargs):\n- super().__init__(_fn=MAXPOOL, **kwargs)\n+ super().__init__(_fn=MAXPOOL, padding=padding, **kwargs)\nAVGPOOL = {\n1: nn.AvgPool1d,\n@@ -369,7 +369,7 @@ AVGPOOL = {\nclass AvgPool(_Pool):\n\"\"\" Multi-dimensional average pooling layer \"\"\"\ndef __init__(self, padding='same', **kwargs):\n- super().__init__(_fn=AVGPOOL, **kwargs)\n+ super().__init__(_fn=AVGPOOL, padding=padding, **kwargs)\nclass Pool(_Pool):\n",
        "chatgpt_cot": "\"Add condition to build queen if no queen and spawning pool is ready, to improve ZergRushBot strategy.\""
    },
    {
        "org_diff": "diff --git a/fkie_node_manager/src/fkie_node_manager/main_window.py b/fkie_node_manager/src/fkie_node_manager/main_window.py @@ -2331,7 +2331,10 @@ class MainWindow(QMainWindow):\ndef _throttle_nmd_errrors(self, reason, url, error, delay=60):\nnow = time.time()\ndoprint = False\n+ try:\nkey = (reason, url, error.details())\n+ except Exception:\n+ key = (reason, url, utf8(error))\nif key not in self._nmd_last_errors.keys():\ndoprint = True\nelif now - self._nmd_last_errors[key] > delay:\n",
        "org_msg": "fkie_node_manager: fixed crash on daemon exception",
        "sim_msg": "let scanLND handle bitcoin",
        "sim_diff": "diff --git a/home.admin/00infoLCD.sh b/home.admin/00infoLCD.sh @@ -198,22 +198,22 @@ while :\nfi\n# check if bitcoin is ready\n- sudo -u bitcoin ${network}-cli -datadir=/home/bitcoin/.${network} getblockchaininfo 1>/dev/null 2>error.tmp\n- clienterror=`cat error.tmp`\n- rm error.tmp\n- if [ ${#clienterror} -gt 0 ]; then\n- boxwidth=40\n- l1=\"Waiting for ${network}d to get ready.\\n\"\n- l2=\"---> ${clienterror/error*:/}\\n\"\n- l3=\"Can take longer if device was off.\"\n- uptimeSeconds=\"$(cat /proc/uptime | grep -o '^[0-9]\\+')\"\n- if [ ${uptimeSeconds} -gt 600 ]; then\n- l3=\"!!Please login for more details!!\"\n- fi\n- dialog --backtitle \"RaspiBlitz ${codeVersion} (${localip}) - Welcome Back\" --infobox \"$l1$l2$l3\" 5 ${boxwidth}\n- sleep 5\n- continue\n- fi\n+ #sudo -u bitcoin ${network}-cli -datadir=/home/bitcoin/.${network} getblockchaininfo 1>/dev/null 2>error.tmp\n+ #clienterror=`cat error.tmp`\n+ #rm error.tmp\n+ #if [ ${#clienterror} -gt 0 ]; then\n+ # boxwidth=40\n+ # l1=\"Waiting for ${network}d to get ready.\\n\"\n+ # l2=\"---> ${clienterror/error*:/}\\n\"\n+ # l3=\"Can take longer if device was off.\"\n+ # uptimeSeconds=\"$(cat /proc/uptime | grep -o '^[0-9]\\+')\"\n+ # if [ ${uptimeSeconds} -gt 600 ]; then\n+ # l3=\"!!Please login for more details!!\"\n+ # fi\n+ # dialog --backtitle \"RaspiBlitz ${codeVersion} (${localip}) - Welcome Back\" --infobox \"$l1$l2$l3\" 5 ${boxwidth}\n+ # sleep 5\n+ # continue\n+ #fi\n# check if locked\nlocked=$(sudo -u bitcoin lncli --chain=${network} --network=${chain}net getinfo 2>&1 | grep -c unlock)\n",
        "chatgpt_cot": "Add try-except block to handle exception in _throttle_nmd_errors method in main_window.py."
    },
    {
        "org_diff": "diff --git a/docs/node_manager.html b/docs/node_manager.html @@ -51,7 +51,7 @@ Usage\n<a href=\"chapter_usage/launch_editor.html\">Launch Editor</a><br/>\n<a href=\"chapter_usage/description_dock.html\">Description Dock</a><br/>\n<a href=\"chapter_usage/capabilities_and_additional_description.html\">Capabilities and additional description</a><br/>\n-<a href=\"chapter_usage/node_manager_daemon.html\">Node Manager Daemon</a><br/>\n+<a href=\"node_manager_daemon.html\">Node Manager Daemon</a><br/>\n<a href=\"chapter_usage/capability_view.html\">Capability View</a><br/>\n<a href=\"chapter_usage/settings.html\">Settings</a><br/>\n<a href=\"chapter_usage/key_bindings.html\">Key Bindings</a><br/>\n",
        "org_msg": "fixed link to node menager daemon in the docu",
        "sim_msg": "fix mkdocs doc paths",
        "sim_diff": "diff --git a/mkdocs.yml b/mkdocs.yml @@ -107,6 +107,7 @@ nav:\n- Common: 'api/common.md'\n- Exceptions: 'api/exceptions.md'\n- Launcher: 'api/launcher.md'\n+ - Manager: 'api/manager.md'\n- Multiplexer: 'api/multiplexer.md'\n- Runner: 'api/runner.md'\n- Runtime: 'api/runtime.md'\n@@ -117,6 +118,7 @@ nav:\n- Base: 'api/configurations/base.md'\n- Constants: 'api/configurations/constants.md'\n- Loader: 'api/configurations/loader.md'\n+ - Project: 'api/configurations/project.md'\n- Pypi: 'api/configurations/pypi.md'\n- Connections:\n- Base: 'api/connections/base.md'\n",
        "chatgpt_cot": "\"Update link to Node Manager Daemon in node_manager.html\""
    },
    {
        "org_diff": "diff --git a/fkie_node_manager/src/fkie_node_manager/main_window.py b/fkie_node_manager/src/fkie_node_manager/main_window.py @@ -1738,7 +1738,7 @@ class MainWindow(QMainWindow):\nincludes = nm.nmd().launch.get_included_files_set(path, True, search_in_ext=nm.settings().SEARCH_IN_EXT)\ncopy_set = set()\nfor inc_file in includes:\n- copy_set.add(inc_file.inc_path)\n+ copy_set.add(inc_file)\nfor cppath in copy_set:\nself.launch_dock.progress_queue.add2queue(utf8(uuid.uuid4()),\n'transfer file %s to %s' % (cppath, nmd_url),\n",
        "org_msg": "fkie_node_manager: fix transfer files",
        "sim_msg": "stupid backslashes in file paths",
        "sim_diff": "diff --git a/source1/content_manager.py b/source1/content_manager.py @@ -58,7 +58,8 @@ class ContentManager(metaclass=SingletonMeta):\nreturn False, path\ndef find_file(self, filepath: str, additional_dir=None, extension=None):\n- new_filepath = Path(filepath)\n+\n+ new_filepath = Path(str(filepath).strip('/\\\\').rstrip('/\\\\'))\nif additional_dir:\nnew_filepath = Path(additional_dir, new_filepath)\nif extension:\n",
        "chatgpt_cot": "Refactor MainWindow class to include file objects instead of paths for better handling of included files in launch process."
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/node_tree_model.py b/node_manager_fkie/src/node_manager_fkie/node_tree_model.py @@ -151,7 +151,9 @@ class GroupItem(QStandardItem):\n@property\ndef cfgs(self):\n- return self.get_configs()\n+ lc, dc = self.get_configs()\n+ lc[len(lc):] = dc\n+ return lc\ndef get_namespace(self):\nname = self._name\n",
        "org_msg": "node_manager_fkie: fixed launch view calculation",
        "sim_msg": "Dimming item node name's color",
        "sim_diff": "diff --git a/avalon/tools/cbsceneinventory/model.py b/avalon/tools/cbsceneinventory/model.py @@ -73,6 +73,9 @@ class InventoryModel(TreeModel):\nreturn self.GRAYOUT_COLOR\n+ if key == \"name\" and not node.get(\"isGroupNode\"):\n+ return self.GRAYOUT_COLOR\n+\n# Add icons\nif role == QtCore.Qt.DecorationRole:\nif index.column() == 0:\n",
        "chatgpt_cot": "\"Modify cfgs method in GroupItem class to return combined list of local and dynamic configurations.\""
    },
    {
        "org_diff": "diff --git a/src/operator-dashboard/agent/ansible/roles/deploy_k8s/fabricsetup/templates/fabric-pod.j2 b/src/operator-dashboard/agent/ansible/roles/deploy_k8s/fabricsetup/templates/fabric-pod.j2 @@ -354,7 +354,7 @@ spec:\n- { name: \"ORDERER_GENERAL_TLS_CERTIFICATE\", value: \"/etc/hyperledger/fabric/artifacts/keyfiles/{{ orderer.org }}/orderers/{{ orderer.name }}.{{ orderer.org }}/tls/server.crt\" }\n- { name: \"ORDERER_GENERAL_TLS_ROOTCAS\", value: \"[/etc/hyperledger/fabric/artifacts/keyfiles/{{ orderer.org }}/orderers/{{ orderer.name }}.{{ orderer.org }}/tls/ca.crt]\" }\n{% endif %}\n-{% if (project_version is version_compare('2.0.0','>=') or ('stable' in project_version or 'latest' in project_version)) and fabric.consensus_type is defined and fabric.consensus_type == 'etcdraft' %}\n+{% if (project_version is version_compare('1.4.1','>=') or ('stable' in project_version or 'latest' in project_version)) and fabric.consensus_type is defined and fabric.consensus_type == 'etcdraft' %}\n- { name: \"ORDERER_GENERAL_CLUSTER_CLIENTPRIVATEKEY\", value: \"/etc/hyperledger/fabric/artifacts/keyfiles/{{ orderer.org }}/orderers/{{ orderer.name }}.{{ orderer.org }}/tls/server.key\" }\n- { name: \"ORDERER_GENERAL_CLUSTER_CLIENTCERTIFICATE\", value: \"/etc/hyperledger/fabric/artifacts/keyfiles/{{ orderer.org }}/orderers/{{ orderer.name }}.{{ orderer.org }}/tls/server.crt\" }\n- { name: \"ORDERER_GENERAL_CLUSTER_ROOTCAS\", value: \"[/etc/hyperledger/fabric/artifacts/keyfiles/{{ orderer.org }}/orderers/{{ orderer.name }}.{{ orderer.org }}/tls/ca.crt]\" }\n",
        "org_msg": "Fix version compare in cello ansible for raft\nChanging version compare for raft cluster certs from 2.0.0 to 1.4.1\nin fabric-pod.j2",
        "sim_msg": "Make sure kubewatch properly generates ambassador_id for Pragma resources.",
        "sim_diff": "diff --git a/ambassador/kubewatch.py b/ambassador/kubewatch.py @@ -34,6 +34,7 @@ from ambassador.config import Config\nfrom ambassador.VERSION import Version\n__version__ = Version\n+ambassador_id = os.getenv(\"AMBASSADOR_ID\", \"default\")\nlogging.basicConfig(\nlevel=logging.INFO, # if appDebug else logging.INFO,\n@@ -208,6 +209,7 @@ class Restarter(threading.Thread):\n'---',\n'apiVersion: v0.1',\n'kind: Pragma',\n+ 'ambassador_id: %s' % ambassador_id,\n'source: \"%s\"' % source,\n'autogenerated: true'\n])\n@@ -338,8 +340,8 @@ def sync(restarter):\nif config_data:\nfor key, config_yaml in config_data.data.items():\n- # logger.info(\"ambassador-config: found %s\" % key)\n- restarter.update(key, config_yaml)\n+ logger.info(\"ambassador-config: found %s\" % key)\n+ restarter.update(key, restarter.read_yaml(config_yaml, \"ambassador-config %s\" % key))\n# If we don't already see a TLS server key in its usual spot...\nif not check_cert_file(\"/etc/certs/tls.crt\"):\n@@ -350,8 +352,6 @@ def sync(restarter):\nrestarter.namespace)\nif server_cert and server_key:\n- ambassador_id = os.getenv(\"AMBASSADOR_ID\", \"default\")\n-\ntls_mod = {\n\"apiVersion\": \"ambassador/v0\",\n\"kind\": \"Module\",\n",
        "chatgpt_cot": "Update fabric-pod.j2 to handle different project versions and consensus types, ensuring compatibility and functionality across different environments."
    },
    {
        "org_diff": "diff --git a/src/agent/ansible/roles/deploy_k8s/fabricsetup/templates/fabric-services.j2 b/src/agent/ansible/roles/deploy_k8s/fabricsetup/templates/fabric-services.j2 @@ -152,7 +152,7 @@ spec:\n{% if fabric.metrics is defined and fabric.metrics %}\n---\n-apiVersion: extensions/v1beta1\n+apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\nname: nodemetricds\n",
        "org_msg": "Ansible agent fails create daemonset on k8s 1.16\nWhen agent tried to create daemonset to monitor the node\nperformance, the daemonset was still using v1beta which\nhas been removed in k8s v1.16. This fix will move it up\nto apps/v1.",
        "sim_msg": "ci: Format ansible-playbook output as yaml",
        "sim_diff": "diff --git a/tests/ansible/ansible.cfg b/tests/ansible/ansible.cfg @@ -5,7 +5,9 @@ strategy_plugins = ../../ansible_mitogen/plugins/strategy\ninventory_plugins = lib/inventory\naction_plugins = lib/action\ncallback_plugins = lib/callback\n-stdout_callback = nice_stdout\n+stdout_callback = yaml\n+stdout_whitelist =\n+ yaml\nvars_plugins = lib/vars\nlibrary = lib/modules\nfilter_plugins = lib/filters\n",
        "chatgpt_cot": "Update apiVersion to apps/v1 in DaemonSet for nodemetricds in fabric-services template."
    },
    {
        "org_diff": "diff --git a/fkie_node_manager/src/fkie_node_manager/master_view_proxy.py b/fkie_node_manager/src/fkie_node_manager/master_view_proxy.py @@ -2616,6 +2616,12 @@ class MasterViewProxy(QWidget):\nret = MessageBox.question(self, \"Show IO\", \"You are going to open the IO of \" + utf8(len(selectedNodes)) + \" nodes at once\\nContinue?\", buttons=MessageBox.Ok | MessageBox.Cancel)\nret = (ret == MessageBox.Ok)\nif ret:\n+ key_mod = QApplication.keyboardModifiers()\n+ if activated and (key_mod & Qt.ShiftModifier or key_mod & Qt.ControlModifier):\n+ # show ROS log if shift or control was pressed while activating\n+ for node in selectedNodes:\n+ self.main_window.open_screen_dock(self.masteruri, screen_name='', nodename=node.name, user=self.current_user)\n+ else:\nqueue = self._progress_queue_prio\n# we use normal queue, if there are not a lot of processes\nif self._progress_queue.count() < 5:\n@@ -2649,7 +2655,7 @@ class MasterViewProxy(QWidget):\nfor node in nodes:\nnode.has_screen = False\nif nm.settings().show_noscreen_error:\n- self.info_frame.show_info(MessageFrame.TYPE_NOSCREEN, 'No screens found! See log for details!<br>The following nodes are affected:', MessageData('', [nodename]))\n+ self.info_frame.show_info(MessageFrame.TYPE_NOSCREEN, 'No screens found for:', MessageData('', [nodename]))\ndef on_kill_screens(self):\n'''\n",
        "org_msg": "fkie_node_manager: logscreen: show ROS log by {Ctrl,Shift}+Double Click",
        "sim_msg": "tree: improve popup menu handling",
        "sim_diff": "diff --git a/tree.py b/tree.py @@ -390,7 +390,8 @@ class WidgetTree(wx.TreeCtrl, Tree):\nself.Bind(wx.EVT_RIGHT_DOWN, self.popup_menu)\nself.Bind(wx.EVT_LEFT_DCLICK, self.on_left_dclick)\nself.Bind(wx.EVT_LEFT_DOWN, self.on_left_click) # allow direct placement of widgets\n- self.Bind(wx.EVT_MENU, self.show_toplevel)\n+ self.Bind(wx.EVT_MENU, self.on_menu) # for handling the selection of the first item\n+ self._popup_menu_widget = None # the widget for the popup menu\nself.Bind(wx.EVT_TREE_BEGIN_DRAG, self.begin_drag)\nself.Bind(wx.EVT_LEAVE_WINDOW, self.on_leave_window)\nself.Bind(wx.EVT_MOUSE_EVENTS, self.on_mouse_events)\n@@ -707,6 +708,12 @@ class WidgetTree(wx.TreeCtrl, Tree):\nself.SetCursor(wx.STANDARD_CURSOR)\nevent.Skip()\n+ def on_menu(self, event):\n+ # the first entry in the popup menu, i.e. the name was selected\n+ if self._popup_menu_widget is None: return\n+ if not getattr(self._popup_menu_widget, \"_is_toplevel_window\", False): return\n+ self.show_toplevel( None, self._popup_menu_widget )\n+\ndef on_mouse_events(self, event):\nif not self._drag_ongoing and not event.IsButton():\n# set cursor to indicate a possible drop\n@@ -730,8 +737,9 @@ class WidgetTree(wx.TreeCtrl, Tree):\nif not node:\nreturn\nself.select_item(node)\n- item = node.widget\n- item.popup_menu(event, pos)\n+ self._popup_menu_widget = node.widget\n+ node.widget.popup_menu(event, pos)\n+ self._popup_menu_widget = None\ndef expand(self, node=None, yes=True):\n\"expands or collapses the given node\"\n",
        "chatgpt_cot": "Add functionality to open ROS log when shift or control key is pressed while activating nodes; update info message for nodes with no screens."
    },
    {
        "org_diff": "diff --git a/docs/scenario.md b/docs/scenario.md # Scenarios\n## Admin\n+After start up, Cello provides a dashboar for administrators, which listens on localhost:8080.\n+\n+The default login user name and password are `admin:pass`, you can modify this by changing the variables `USERNAME` and `PASSWORD` in the `nginx` section of the [docker-compose file](../docker-compose.yml).\n### Add/Delete a host\n",
        "org_msg": "Update scenario doc\nAdd doc of default username and password for admin dashboard.",
        "sim_msg": "[fix] removing injected security breach",
        "sim_diff": "diff --git a/frappe/core/doctype/user/user.py b/frappe/core/doctype/user/user.py @@ -797,24 +797,17 @@ def sign_up(email, full_name, redirect_to):\nreturn 2, _(\"Please ask your administrator to verify your sign-up\")\n@frappe.whitelist(allow_guest=True)\n-def reset_password(user, send_email=True):\n+def reset_password(user):\nif user==\"Administrator\":\nreturn 'not allowed'\n- if isinstance(send_email, unicode) or isinstance(send_email, basestring):\n- if send_email=='false':\n- send_email = False\n-\ntry:\nuser = frappe.get_doc(\"User\", user)\nif not user.enabled:\nreturn 'disabled'\nuser.validate_reset_password()\n- link = user.reset_password(send_email=send_email)\n-\n- if not send_email:\n- return { \"link\": link }\n+ user.reset_password(send_email=True)\nreturn frappe.msgprint(_(\"Password reset instructions have been sent to your email\"))\n",
        "chatgpt_cot": "\"Add dashboard for administrators and allow modification of login credentials in docker-compose file for scenarios.md\""
    },
    {
        "org_diff": "diff --git a/rasa_core_sdk/forms.py b/rasa_core_sdk/forms.py @@ -23,7 +23,7 @@ REQUESTED_SLOT = \"requested_slot\"\nclass FormAction(Action):\n- FREETEXT = 'FREETEXT'\n+ FREETEXT = '__FREETEXT__'\ndef name(self):\n# type: () -> Text\n@@ -58,10 +58,7 @@ class FormAction(Action):\nslot_mapping = self.slot_mapping().get(slot_to_fill)\nif slot_mapping:\n- if slot_mapping == self.FREETEXT:\n- return [SlotSet(slot_to_fill,\n- tracker.latest_message.get(\"text\"))]\n- elif isinstance(slot_mapping, dict):\n+ if isinstance(slot_mapping, dict):\nintent = tracker.latest_message.get(\"intent\", {}).get(\"name\")\nif intent in slot_mapping.keys():\nreturn [SlotSet(slot_to_fill, slot_mapping[intent])]\n@@ -70,9 +67,15 @@ class FormAction(Action):\nif not isinstance(required_entities, list):\nrequired_entities = [required_entities]\n- for e in tracker.latest_message[\"entities\"]:\n- if e.get(\"entity\") in required_entities:\n- return [SlotSet(slot_to_fill, e['value'])]\n+ for entity_name in required_entities:\n+ entity_value = next(tracker.get_latest_entity_values(\n+ entity_name), None)\n+ if entity_value is not None:\n+ return [SlotSet(slot_to_fill, entity_value)]\n+\n+ if self.FREETEXT in required_entities:\n+ return [SlotSet(slot_to_fill,\n+ tracker.latest_message.get(\"text\"))]\nreturn None\n",
        "org_msg": "pick entities in the order they are present in slot_mapping list RasaHQ/roadmap#280",
        "sim_msg": "fix statusbar names",
        "sim_diff": "diff --git a/widgets/statusbar/statusbar.py b/widgets/statusbar/statusbar.py @@ -127,12 +127,12 @@ _NUMBER = 0\nclass Dialog(wx.Dialog):\ndef __init__(self):\nglobal _NUMBER\n- wx.Dialog.__init__(self, None, -1, _('Select toolbar class'))\n+ wx.Dialog.__init__(self, None, -1, _('Select statusbar class'))\nif common.root.language.lower() == 'xrc':\n- klass = 'wxToolBar'\n+ klass = 'wxStatusBar'\nelse:\n- klass = 'MyToolBar%s' % (_NUMBER or \"\")\n+ klass = 'MyStatusBar%s' % (_NUMBER or \"\")\n_NUMBER += 1\n# class\n@@ -153,13 +153,13 @@ class Dialog(wx.Dialog):\ndef builder(parent, index, klass):\n# only used from Frame.menubar property\n- editor = EditStatusBar(parent.name+\"_menubar\", parent)\n+ editor = EditStatusBar(parent.name+\"_statusbar\", parent)\nif parent.widget: editor.create()\nreturn editor\ndef xml_builder(parser, base, name, parent, index):\n- \"factory to build EditToolBar objects from a XML file\"\n+ \"factory to build EditStatusBar objects from a XML file\"\nparent.properties[\"statusbar\"].set(True)\nreturn EditStatusBar(name, parent)\n",
        "chatgpt_cot": "Update FREETEXT constant and entity extraction logic in FormAction to improve slot filling functionality in Rasa Core SDK."
    },
    {
        "org_diff": "diff --git a/sc2/main.py b/sc2/main.py @@ -6,6 +6,7 @@ import json\nimport mpyq\nimport os\nimport sys\n+import platform\nimport portpicker\nimport signal\nimport async_timeout\n@@ -719,13 +720,14 @@ async def maintain_SCII_count(count: int, controllers: List[Controller], proc_ar\nextra = [SC2Process(**proc_args[(index + _) % len(proc_args)]) for _ in range(needed)]\nlogger.info(f\"Creating {needed} more SC2 Processes\")\nfor k in range(3): # try thrice\n- # Doesnt seem to work on linux: starting 2 clients nearly at the same time\n- # new_controllers = await asyncio.wait_for(\n- # asyncio.gather(*[sc.__aenter__() for sc in extra], return_exceptions=True), timeout=50\n- # )\n-\n+ if platform.system() == \"Linux\":\n# Works on linux: start one client after the other\nnew_controllers = [await asyncio.wait_for(sc.__aenter__(), timeout=50) for sc in extra]\n+ else:\n+ # Doesnt seem to work on linux: starting 2 clients nearly at the same time\n+ new_controllers = await asyncio.wait_for(\n+ asyncio.gather(*[sc.__aenter__() for sc in extra], return_exceptions=True), timeout=50\n+ )\ncontrollers.extend(c for c in new_controllers if isinstance(c, Controller))\nif len(controllers) == count:\n",
        "org_msg": "Start sc2 at the same time on windows, sequentially on linux",
        "sim_msg": "move request semaphore to session and apply to all requests",
        "sim_diff": "diff --git a/lbry/wallet/network.py b/lbry/wallet/network.py @@ -30,7 +30,7 @@ class ClientSession(BaseClientSession):\nself.response_time: Optional[float] = None\nself.connection_latency: Optional[float] = None\nself._response_samples = 0\n- self.pending_amount = 0\n+ self._concurrency = asyncio.Semaphore(16)\n@property\ndef available(self):\n@@ -56,9 +56,9 @@ class ClientSession(BaseClientSession):\nreturn result\nasync def send_request(self, method, args=()):\n- self.pending_amount += 1\nlog.debug(\"send %s%s to %s:%i (%i timeout)\", method, tuple(args), self.server[0], self.server[1], self.timeout)\ntry:\n+ await self._concurrency.acquire()\nif method == 'server.version':\nreturn await self.send_timed_server_version_request(args, self.timeout)\nrequest = asyncio.ensure_future(super().send_request(method, args))\n@@ -92,7 +92,7 @@ class ClientSession(BaseClientSession):\n# self.synchronous_close()\nraise\nfinally:\n- self.pending_amount -= 1\n+ self._concurrency.release()\nasync def ensure_server_version(self, required=None, timeout=3):\nrequired = required or self.network.PROTOCOL_VERSION\n@@ -155,7 +155,6 @@ class Network:\n# self._switch_task: Optional[asyncio.Task] = None\nself.running = False\nself.remote_height: int = 0\n- self._concurrency = asyncio.Semaphore(16)\nself._on_connected_controller = StreamController()\nself.on_connected = self._on_connected_controller.stream\n@@ -377,7 +376,6 @@ class Network:\nraise ConnectionError(\"Attempting to send rpc request when connection is not available.\")\nasync def retriable_call(self, function, *args, **kwargs):\n- async with self._concurrency:\nwhile self.running:\nif not self.is_connected:\nlog.warning(\"Wallet server unavailable, waiting for it to come back and retry.\")\n",
        "chatgpt_cot": "Add platform import and change the code block to start one client after the other on Linux."
    },
    {
        "org_diff": "diff --git a/sc2/unit.py b/sc2/unit.py @@ -1170,7 +1170,9 @@ class Unit:\n@property\ndef surplus_harvesters(self) -> int:\n\"\"\" Returns a positive int if unit has too many harvesters mining,\n- a negative int if it has too few mining.\"\"\"\n+ a negative int if it has too few mining.\n+ will only works for townhalls, and gasgeysers\n+ \"\"\"\nreturn self._proto.assigned_harvesters - self._proto.ideal_harvesters\n@property_immutable_cache\n",
        "org_msg": "modify doc string of `surplus_harvesters`\nto indicate that it also accepts gas geysers",
        "sim_msg": "fix facade logging init error",
        "sim_diff": "diff --git a/workers/facade_worker/facade_worker/facade00mainprogram.py b/workers/facade_worker/facade_worker/facade00mainprogram.py @@ -68,7 +68,7 @@ class CollectorTask:\nclass FacadeWorker:\ndef __init__(self, config, task=None):\nself.config = config\n- logging.basicConfig(filename='worker_{}.log'.format(worker_port), filemode='w', level=logging.INFO)\n+ logging.basicConfig(filename='worker_{}.log'.format(self.config['id'].split('.')[len(self.config['id'].split('.')) - 1]), filemode='w', level=logging.INFO)\nprint('Worker (PID: {}) initializing...'.format(os.getpid()))\nlogging.info('Worker (PID: {}) initializing...'.format(os.getpid()))\n",
        "chatgpt_cot": "Add functionality to calculate surplus harvesters only for townhalls and gasgeysers in Unit class."
    },
    {
        "org_diff": "diff --git a/examples/show_debug.py b/examples/show_debug.py @@ -8,6 +8,7 @@ class MyBot(sc2.BotAI):\nself._client.debug_text_world(\n\"\\n\".join([\nf\"{unit.type_id.name}:{unit.type_id.value}\",\n+ f\"({unit.position.x:.2f},{unit.position.y:.2f})\",\nf\"{unit.build_progress:.2f}\",\n] + [repr(x) for x in unit.orders]),\nunit.position3d,\n",
        "org_msg": "Also show position in debug example",
        "sim_msg": "[disboardreminder] debug com aesthetic",
        "sim_diff": "diff --git a/disboardreminder/disboardreminder.py b/disboardreminder/disboardreminder.py @@ -96,19 +96,16 @@ class DisboardReminder(commands.Cog):\nasync def debug(self, ctx,):\n\"\"\"Debug command.\"\"\"\ndata = await self.config.guild(ctx.guild).all()\n- description = []\n- for key, value in data.items():\n- description.append(f\"`{key}`: {value}\")\n- description = \"\\n\".join(description)\n+\ne = discord.Embed(\ncolor=await self.bot.get_embed_color(ctx),\n- title=\"DisboardReminder Debug\",\n- description=description\n- )\n+ title=\"DisboardReminder Debug\")\n+ for key, value in data.items():\n+ e.add_field(name=key, value=f\"`{value}`\", inline=False)\nif data[\"nextBump\"]:\ntimestamp = datetime.utcfromtimestamp(data[\"nextBump\"])\ne.timestamp = timestamp\n- e.set_footer(text=\"Bump registered for\")\n+ e.set_footer(text=\"Next bump registered for\")\ne.set_author(name=ctx.guild, icon_url=ctx.guild.icon_url)\nawait ctx.send(embed=e)\n",
        "chatgpt_cot": "Add position coordinates to debug text in MyBot class."
    },
    {
        "org_diff": "diff --git a/rasa_core_sdk/forms.py b/rasa_core_sdk/forms.py @@ -121,23 +121,26 @@ class FormAction(Action):\nlogger.debug(\"Failed to extract\")\nreturn None\n- # noinspection PyUnusedLocal\ndef validate(self, dispatcher, tracker, domain):\n# type: (CollectingDispatcher, Tracker, Dict[Text, Any]) -> List[Dict]\n\"\"\"\"Validate extracted requested slot else raise an error\"\"\"\nslot_to_fill = tracker.get_slot(REQUESTED_SLOT)\nextracted_value = self.extract(dispatcher, tracker, domain)\n-\n- if extracted_value is not None:\n- return [SlotSet(slot_to_fill, extracted_value)]\n- else:\n+ if extracted_value is None:\n+ # reject to execute the form action if nothing was extracted,\n+ # it will allow other policies to predict another action\nraise ActionExecutionRejection(self.name(),\n\"Failed to validate slot {0} \"\n\"with action {1}\"\n\"\".format(slot_to_fill,\nself.name()))\n+ # add custom validation logic by subclassing this method\n+\n+ # validation succeed, set requested slot to extracted value\n+ return [SlotSet(slot_to_fill, extracted_value)]\n+\n# noinspection PyUnusedLocal\ndef request_next_slot(self,\ndispatcher, # type: CollectingDispatcher\n",
        "org_msg": "refactor validate() RasaHQ/roadmap#280",
        "sim_msg": "Allows to modify path parameters",
        "sim_diff": "diff --git a/src/poliastro/contrib/extract_czml.py b/src/poliastro/contrib/extract_czml.py @@ -113,6 +113,8 @@ class ExtractorCZML:\ndef change_id_params(self, i, id=None, name=None, description=None):\n\"\"\"\n+ Change the id parameters.\n+\nParameters\ni : int\nReferred body (count starts at i)\n@@ -130,10 +132,39 @@ class ExtractorCZML:\nif description is not None:\nself.parse_dict_tuples([i], [(\"description\", description)])\n- def change_label_params(self, i, fill_color=None, outline_color=None, font=None, text=None, show=True):\n+ def change_path_params(self, i, pixel_offset=None, color=None, width=None, show=None):\n\"\"\"\n+ Changes the path parameters.\n+\nParameters\n- n : int\n+ ----------\n+ i : int\n+ Referred body (count starts at 1)\n+ pixel_offset: list (int)\n+ The pixel offset (up and right)\n+ color: list (int)\n+ Rgba path color\n+ width: int\n+ Path width\n+ show: bool\n+ Indicates whether the path is visible\n+ \"\"\"\n+ if pixel_offset is not None:\n+ self.parse_dict_tuples([i, \"label\", \"pixelOffset\"], [(\"cartesian2\", pixel_offset)])\n+ if color is not None:\n+ self.parse_dict_tuples([i, \"path\", \"material\", \"solidColor\", \"color\"], [(\"rgba\", color)])\n+ if width is not None:\n+ self.parse_dict_tuples([i, \"path\"], [(\"width\", width)])\n+ if show is not None:\n+ self.parse_dict_tuples([i, \"path\", \"show\"], [(\"boolean\", show)])\n+\n+ def change_label_params(self, i, fill_color=None, outline_color=None, font=None, text=None, show=None):\n+ \"\"\"\n+ Change the label parameters.\n+\n+ Parameters\n+ ----------\n+ i : int\nReferred body (count starts at 1)\nfill_color: list (int)\nFill Color in rgba format\n",
        "chatgpt_cot": "\"Fix extraction validation issue and add custom validation logic by subclassing this method in FormAction\""
    },
    {
        "org_diff": "diff --git a/examples/terran/ramp_wall.py b/examples/terran/ramp_wall.py @@ -15,19 +15,21 @@ from sc2.units import Units\nclass RampWallBot(sc2.BotAI):\nasync def on_step(self, iteration):\n- cc = self.townhalls(COMMANDCENTER)\n- if not cc.exists:\n+ ccs = self.townhalls(COMMANDCENTER)\n+ if not ccs:\nreturn\nelse:\ncc = cc.first\n+ await self.distribute_workers()\n+\nif self.can_afford(SCV) and self.workers.amount < 16 and cc.is_idle:\n- self.do(cc.train(SCV))\n+ self.do(cc.train(SCV), subtract_cost=True, subtract_supply=True)\n# Raise depos when enemies are nearby\nfor depo in self.structures(SUPPLYDEPOT).ready:\nfor unit in self.enemy_units:\n- if unit.position.to2.distance_to(depo.position.to2) < 15:\n+ if unit.position.distance_to(depo) < 15:\nbreak\nelse:\nself.do(depo(MORPH_SUPPLYDEPOT_LOWER))\n@@ -35,7 +37,7 @@ class RampWallBot(sc2.BotAI):\n# Lower depos when no enemies are nearby\nfor depo in self.structures(SUPPLYDEPOTLOWERED).ready:\nfor unit in self.enemy_units:\n- if unit.position.to2.distance_to(depo.position.to2) < 10:\n+ if unit.position.distance_to(depo) < 10:\nself.do(depo(MORPH_SUPPLYDEPOT_RAISE))\nbreak\n@@ -63,7 +65,7 @@ class RampWallBot(sc2.BotAI):\ndepot_placement_positions = {d for d in depot_placement_positions if depots.closest_distance_to(d) > 1}\n# Build depots\n- if self.can_afford(SUPPLYDEPOT) and not self.already_pending(SUPPLYDEPOT):\n+ if self.can_afford(SUPPLYDEPOT) and self.already_pending(SUPPLYDEPOT) == 0:\nif len(depot_placement_positions) == 0:\nreturn\n# Choose any depot location\n@@ -74,7 +76,7 @@ class RampWallBot(sc2.BotAI):\nself.do(w.build(SUPPLYDEPOT, target_depot_location))\n# Build barracks\n- if depots.ready and self.can_afford(BARRACKS) and not self.already_pending(BARRACKS):\n+ if depots.ready and self.can_afford(BARRACKS) and self.already_pending(BARRACKS) == 0:\nif self.structures(BARRACKS).amount + self.already_pending(BARRACKS) > 0:\nreturn\nws = self.workers.gathering\n",
        "org_msg": "Change ramp wall bot",
        "sim_msg": "fixed tensorflow not loading correctly",
        "sim_diff": "diff --git a/main_agent/saltie.py b/main_agent/saltie.py @@ -3,20 +3,33 @@ import math\nfrom rlbot.agents.base_agent import BaseAgent, SimpleControllerState\nfrom rlbot.utils.structures.game_data_struct import GameTickPacket\n-from legacy.legacy_game_input_formatter import LegacyGameInputFormatter\n-from legacy.legacy_keras_model import LegacyKerasModel\n-from legacy.legacy_model_holder import LegacyModelHolder\n-from legacy.legacy_output_formatter import LegacyOutputFormatter\n-\nclass Saltie(BaseAgent):\nmodel_holder = None\n- def load_config(self):\n+ def initialize_agent(self):\n+ #This runs once before the bot starts up\n+ self.controller_state = SimpleControllerState()\n+\n+ from legacy.legacy_game_input_formatter import LegacyGameInputFormatter\n+ from legacy.legacy_keras_model import LegacyKerasModel\n+ from legacy.legacy_model_holder import LegacyModelHolder\n+ from legacy.legacy_output_formatter import LegacyOutputFormatter\n+\nself.model_holder = LegacyModelHolder(LegacyKerasModel(),\nLegacyGameInputFormatter(self.team, self.index),\nLegacyOutputFormatter())\ndef get_output(self, packet: GameTickPacket) -> SimpleControllerState:\n- return self.model_holder.predict(packet)\n+ result = self.model_holder.predict(packet)\n+ self.controller_state.throttle = result[0]\n+ self.controller_state.steer = result[1]\n+ self.controller_state.pitch = result[2]\n+ self.controller_state.yaw = result[3]\n+ self.controller_state.roll = result[4]\n+ self.controller_state.jump = result[5]\n+ self.controller_state.boost = result[6]\n+ self.controller_state.boost = result[7]\n+\n+ return self.controller_state\n",
        "chatgpt_cot": "Refactor SC2 Terran bot build logic for improved resource management and enemy detection in ramp wall strategy. Fix SCV training and depot placement conditions."
    },
    {
        "org_diff": "diff --git a/Makefile b/Makefile @@ -168,15 +168,15 @@ install: $(patsubst %,build/docker/%/.push,$(COMMON_DOCKER_IMAGES))\ncheck: ##@Code Check code format\n@$(MAKE) license\n- # find ./docs -type f -name \"*.md\" -exec egrep -l \" +$$\" {} \\;\n- # cd src/api-engine && tox && cd ${ROOT_PATH}\n- # make api-engine\n- # make docker-rest-agent\n- # make dashboard\n- # MODE=dev make start\n- # sleep 10\n- # # make test-api\n- # MODE=dev make stop\n+ find ./docs -type f -name \"*.md\" -exec egrep -l \" +$$\" {} \\;\n+ cd src/api-engine && tox && cd ${ROOT_PATH}\n+ make api-engine\n+ make docker-rest-agent\n+ make dashboard\n+ MODE=dev make start\n+ sleep 10\n+ # make test-api\n+ MODE=dev make stop\nmake check-dashboard\ntest-case: ##@Code Run test case for flask server\n",
        "org_msg": "Restore makefile\nRestore makefile to enable all check commands",
        "sim_msg": "Ensure unit tests are run within a docker context as part of CI builds",
        "sim_diff": "diff --git a/.github/workflows/docker_test.yaml b/.github/workflows/docker_test.yaml # This CI action runs on pushes to either the master or stable branches\n# 1. Build the development docker image (as per the documentation)\n-# 2. Install requied python libs into the docker container\n-# 3. Launch the container\n-# 4. Check that the API endpoint is available\n+# 2. Launch the development server, and update the installation\n+# 3. Run unit tests within the docker context\nname: Docker Test\n@@ -15,6 +14,10 @@ on:\n- 'master'\n- 'stable'\n+ pull_request:\n+ branches-ignore:\n+ - l10*\n+\njobs:\ndocker:\n@@ -26,12 +29,14 @@ jobs:\n- name: Build Docker Image\nrun: |\ncd docker\n- docker-compose -f docker-compose.sqlite.yml build\n- docker-compose -f docker-compose.sqlite.yml run inventree-dev-server invoke update\n- docker-compose -f docker-compose.sqlite.yml up -d\n- - name: Sleepy Time\n- run: sleep 60\n- - name: Test API\n+ docker-compose build\n+ docker-compose run inventree-dev-server invoke update\n+ docker-compose up -d\n+ - name: Wait for Server\n+ run: |\n+ cd docker\n+ docker-compose run inventree-dev-server invoke wait\n+ - name: Run unit tests\nrun: |\n- pip install requests\n- python3 ci/check_api_endpoint.py\n+ cd docker\n+ docker-compose run inventree-dev-server invoke test\n",
        "chatgpt_cot": "\"Update Makefile to fix code check and add test case for flask server\""
    },
    {
        "org_diff": "diff --git a/sc2/main.py b/sc2/main.py @@ -97,6 +97,8 @@ async def _play_game_ai(client, player_id, ai, realtime, step_time_limit, game_t\niteration = 0\nwhile True:\nstate = await client.observation()\n+ logger.debug(f\"Score: {state.observation.observation.score.score}\")\n+\nif client._game_result:\nai.on_end(client._game_result[player_id])\nreturn client._game_result[player_id]\n",
        "org_msg": "Log player scores",
        "sim_msg": "[Hockey] get_games returns list of game objects not single game object",
        "sim_diff": "diff --git a/hockey/hockey.py b/hockey/hockey.py @@ -1052,7 +1052,7 @@ class Hockey(getattr(commands, \"Cog\", object)):\npickems = [Pickems.from_json(p) for p in await self.config.guild(guild).pickems()]\nfor p in pickems:\ngame = await Game.get_games(p.home_team, p.game_start, p.game_start)\n- if game.game_state == \"Final\":\n+ if game[0].game_state == \"Final\":\nawait Pickems.set_guild_pickem_winner(self.bot, game)\nawait ctx.send(_(\"Pickems winners set.\"))\n",
        "chatgpt_cot": "Add debug log for score in game iteration in main.py"
    },
    {
        "org_diff": "diff --git a/src/api-engine/api/routes/node/views.py b/src/api-engine/api/routes/node/views.py @@ -9,8 +9,6 @@ import threading\nfrom django.core.exceptions import ObjectDoesNotExist\nfrom django.core.paginator import Paginator\n-from django.core.files.storage import default_storage\n-from django.core.files.base import ContentFile\nfrom django.http import HttpResponse\nfrom drf_yasg.utils import swagger_auto_schema\nfrom rest_framework import viewsets, status\n",
        "org_msg": "Remove unused libraries\nRemove unused libraries from import",
        "sim_msg": "Fix deprecation warning in DRF\nSee\nfor details.",
        "sim_diff": "diff --git a/api/views.py b/api/views.py @@ -14,7 +14,7 @@ from django.db.models import (\nWhen,\n)\nfrom rest_framework import viewsets\n-from rest_framework.decorators import list_route\n+from rest_framework.decorators import action\nfrom rest_framework.generics import ListAPIView, RetrieveAPIView\nfrom rest_framework.metadata import SimpleMetadata\nfrom rest_framework.pagination import PageNumberPagination\n@@ -424,7 +424,7 @@ class ReportsViewSet(ViewSet):\nreturn iterable\n- @list_route(methods=['GET'])\n+ @action(detail=False, methods=['GET'])\ndef workshops_over_time(self, request, format=None):\n\"\"\"Cumulative number of workshops run by Software Carpentry and other\ncarpentries over time.\"\"\"\n@@ -441,7 +441,7 @@ class ReportsViewSet(ViewSet):\nreturn Response(data)\n- @list_route(methods=['GET'])\n+ @action(detail=False, methods=['GET'])\ndef learners_over_time(self, request, format=None):\n\"\"\"Cumulative number of learners attending Software-Carpentry and other\ncarpentries' workshops over time.\"\"\"\n@@ -459,7 +459,7 @@ class ReportsViewSet(ViewSet):\nreturn Response(data)\n- @list_route(methods=['GET'])\n+ @action(detail=False, methods=['GET'])\ndef instructors_over_time(self, request, format=None):\n\"\"\"Cumulative number of instructor appearances on workshops over\ntime.\"\"\"\n@@ -486,7 +486,7 @@ class ReportsViewSet(ViewSet):\nreturn Response(data)\n- @list_route(methods=['GET'])\n+ @action(detail=False, methods=['GET'])\ndef instructor_num_taught(self, request, format=None):\nbadges = Badge.objects.instructor_badges()\npersons = Person.objects.filter(badges__in=badges).annotate(\n@@ -529,7 +529,7 @@ class ReportsViewSet(ViewSet):\nreturn start, end\n- @list_route(methods=['GET'])\n+ @action(detail=False, methods=['GET'])\ndef all_activity_over_time(self, request, format=None):\n\"\"\"Workshops, instructors, and missing data in specific periods.\"\"\"\nstart, end = self._default_start_end_dates(\n@@ -645,7 +645,7 @@ class ReportsViewSet(ViewSet):\n.select_related('person', 'event', 'role')\nreturn tasks\n- @list_route(methods=['GET'])\n+ @action(detail=False, methods=['GET'])\ndef instructors_by_time(self, request, format=None):\n\"\"\"Workshops and instructors who taught in specific time period.\"\"\"\nstart, end = self._default_start_end_dates(\n",
        "chatgpt_cot": "Remove unused imports and dependencies in node/views.py"
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/editor/editor.py b/node_manager_fkie/src/node_manager_fkie/editor/editor.py @@ -272,6 +272,10 @@ class Editor(QMainWindow):\nself.graphButton.setChecked(not self.graphButton.isChecked())\nelif event.modifiers() == Qt.ControlModifier and event.key() == Qt.Key_W:\nself.on_close_tab(self.tabWidget.currentIndex())\n+ elif event.modifiers() in [Qt.ControlModifier, Qt.AltModifier] and event.key() == Qt.Key_Up:\n+ self.on_upperButton_clicked()\n+ elif event.modifiers() in [Qt.ControlModifier, Qt.AltModifier] and event.key() == Qt.Key_Down:\n+ self.on_downButton_clicked()\nelse:\nevent.accept()\nQMainWindow.keyPressEvent(self, event)\n@@ -504,6 +508,13 @@ class Editor(QMainWindow):\nif self.tabWidget.currentIndex() != 0:\nself.graph_view.find_parent_file()\n+ def on_downButton_clicked(self):\n+ '''\n+ Select editor right from current.\n+ '''\n+ if self.tabWidget.currentIndex() < self.tabWidget.count():\n+ self.tabWidget.setCurrentIndex(self.tabWidget.currentIndex() + 1)\n+\ndef on_saveButton_clicked(self):\n'''\nSaves the current document. This method is called if the C{save button}\n",
        "org_msg": "node_manager_fkie: editor: added Ctrl/Alt Up to open the parent include file",
        "sim_msg": "add labels to blank tabs",
        "sim_diff": "diff --git a/qualcoder/GUI/ui_main.py b/qualcoder/GUI/ui_main.py @@ -22,12 +22,21 @@ class Ui_MainWindow(object):\nself.tabWidget.setObjectName(\"tabWidget\")\nself.tab_coding = QtWidgets.QWidget()\nself.tab_coding.setObjectName(\"tab_coding\")\n+ self.label_manage_2 = QtWidgets.QLabel(self.tab_coding)\n+ self.label_manage_2.setGeometry(QtCore.QRect(20, 20, 511, 17))\n+ self.label_manage_2.setObjectName(\"label_manage_2\")\nself.tabWidget.addTab(self.tab_coding, \"\")\nself.tab_reports = QtWidgets.QWidget()\nself.tab_reports.setObjectName(\"tab_reports\")\n+ self.label_reports = QtWidgets.QLabel(self.tab_reports)\n+ self.label_reports.setGeometry(QtCore.QRect(20, 20, 511, 17))\n+ self.label_reports.setObjectName(\"label_reports\")\nself.tabWidget.addTab(self.tab_reports, \"\")\nself.tab_manage = QtWidgets.QWidget()\nself.tab_manage.setObjectName(\"tab_manage\")\n+ self.label_manage = QtWidgets.QLabel(self.tab_manage)\n+ self.label_manage.setGeometry(QtCore.QRect(20, 20, 511, 17))\n+ self.label_manage.setObjectName(\"label_manage\")\nself.tabWidget.addTab(self.tab_manage, \"\")\nself.tab_action_log = QtWidgets.QWidget()\nself.tab_action_log.setObjectName(\"tab_action_log\")\n@@ -194,14 +203,17 @@ class Ui_MainWindow(object):\nself.menubar.addAction(self.menuHelp.menuAction())\nself.retranslateUi(MainWindow)\n- self.tabWidget.setCurrentIndex(3)\n+ self.tabWidget.setCurrentIndex(0)\nQtCore.QMetaObject.connectSlotsByName(MainWindow)\ndef retranslateUi(self, MainWindow):\n_translate = QtCore.QCoreApplication.translate\nMainWindow.setWindowTitle(_translate(\"MainWindow\", \"QualCoder\"))\n+ self.label_manage_2.setText(_translate(\"MainWindow\", \"Select an option in the Coding menu\"))\nself.tabWidget.setTabText(self.tabWidget.indexOf(self.tab_coding), _translate(\"MainWindow\", \"Coding\"))\n+ self.label_reports.setText(_translate(\"MainWindow\", \"Select an option in the Reports menu\"))\nself.tabWidget.setTabText(self.tabWidget.indexOf(self.tab_reports), _translate(\"MainWindow\", \"Reports\"))\n+ self.label_manage.setText(_translate(\"MainWindow\", \"Select an option in the Files and Cases menu\"))\nself.tabWidget.setTabText(self.tabWidget.indexOf(self.tab_manage), _translate(\"MainWindow\", \"Manage\"))\nself.tabWidget.setTabText(self.tabWidget.indexOf(self.tab_action_log), _translate(\"MainWindow\", \"Action Log\"))\nself.menuProject.setTitle(_translate(\"MainWindow\", \"Project\"))\n",
        "chatgpt_cot": "Add methods to the Editor class to handle up and down button clicks. This will allow users to navigate between tabs more easily."
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/editor/yamlformatter.py b/node_manager_fkie/src/node_manager_fkie/editor/yamlformatter.py @@ -45,26 +45,31 @@ class YamlFormatter(ruamel.yaml.YAML):\ndef format_string(self, data):\ncode = ruamel.yaml.load(data.encode('utf-8'), Loader=ruamel.yaml.RoundTripLoader)\nbuf = ruamel.yaml.compat.StringIO()\n- ruamel.yaml.dump(code, buf, Dumper=ruamel.yaml.RoundTripDumper, encoding='utf-8')\n- result = buf.getvalue() # self.dump(code)\n+ ruamel.yaml.dump(code, buf, Dumper=ruamel.yaml.RoundTripDumper, encoding='utf-8', default_style=None, indent=' ')\n+ result = buf.getvalue()\nif self.indent_data:\nlines = result.splitlines()\nresult = ''\n- last_idx = 0\n+ commented_line = False\n+ commented_lines = []\nfor line in lines:\nlen_line = len(line)\nidx = len_line - len(line.lstrip())\n- indent_ = self.indent_data\ntry:\n# handle comments\nif idx == line.index('#'):\n- indent_ = ' ' * (last_idx + len(indent_))\n- line = line.lstrip()\n- except ValueError:\n- pass\n- if idx < len_line:\n- result += '\\n%s%s' % (indent_, line)\n+ commented_lines.append(line.lstrip())\n+ commented_line = True\nelse:\n- result += line\n- last_idx = idx\n+ commented_line = False\n+ except ValueError:\n+ commented_line = False\n+ if not commented_line:\n+ # add all collected comments first\n+ indent_ = ' ' * (idx + len(self.indent_data))\n+ for cl in commented_lines:\n+ result += '\\n%s%s' % (indent_, cl)\n+ del commented_lines[:]\n+ # add the uncommented line now\n+ result += '\\n%s%s' % (self.indent_data, line)\nreturn result\n",
        "org_msg": "node_manager_fkie: fix autoformat yaml code",
        "sim_msg": "Preparation of supporting more metadata extraction methods.",
        "sim_diff": "diff --git a/v8/static_comments/static_comments.py b/v8/static_comments/static_comments.py @@ -97,15 +97,14 @@ class StaticComments(SignalHandler):\n_LOGGER.error(\"Page compiler plugin '{0}' provides no compile_string or compile_to_string function (comment {1})!\".format(compiler_name, filename))\nexit(1)\n- def _read_comment(self, filename, owner, id):\n- \"\"\"Read a comment from a file.\"\"\"\n+ def _parse_comment(self, filename):\n+ \"\"\"Read a comment from a file, and return metadata dict and content.\"\"\"\nwith open(filename, \"r\") as f:\nlines = f.readlines()\nstart = 0\n- # create comment object\n- comment = Comment(self.site, owner, id)\n# parse headers\ncompiler_name = None\n+ meta = {}\nwhile start < len(lines):\n# on empty line, header is definitely done\nif len(lines[start].strip()) == 0:\n@@ -117,6 +116,23 @@ class StaticComments(SignalHandler):\n# parse header line\nheader = result[0][0]\nvalue = result[0][1]\n+ meta[header] = value\n+ # go to next line\n+ start += 1\n+ # skip empty lines and re-combine content\n+ while start < len(lines) and len(lines[start]) == 0:\n+ start += 1\n+ content = '\\n'.join(lines[start:])\n+ return meta, content\n+\n+ def _read_comment(self, filename, owner, id):\n+ \"\"\"Read a comment from a file.\"\"\"\n+ meta, content = self._parse_comment(filename)\n+ # create comment object\n+ comment = Comment(self.site, owner, id)\n+ # parse headers\n+ compiler_name = None\n+ for header, value in meta.items():\nif header == 'id':\ncomment.id = value\nelif header == 'status':\n@@ -146,12 +162,6 @@ class StaticComments(SignalHandler):\nelse:\n_LOGGER.error(\"Unknown comment header: '{0}' (in file {1})\".format(header, filename))\nexit(1)\n- # go to next line\n- start += 1\n- # skip empty lines and re-combine content\n- while start < len(lines) and len(lines[start]) == 0:\n- start += 1\n- content = '\\n'.join(lines[start:])\n# check compiler name\nif compiler_name is None:\n_LOGGER.warn(\"Comment file '{0}' doesn't specify compiler! Using default 'wordpress'.\".format(filename))\n",
        "chatgpt_cot": "Refactor YamlFormatter to handle comments in YAML strings more efficiently, improving readability and maintainability of the code."
    },
    {
        "org_diff": "diff --git a/sc2/bot_ai.py b/sc2/bot_ai.py @@ -1071,24 +1071,26 @@ class BotAI(DistanceCalculation):\nrandom_alternative: bool = True,\nplacement_step: int = 2,\n) -> bool:\n- \"\"\" Not recommended as this function checks many positions if it \"can place\" on them until it found a valid position.\n- Also if the given position is not placeable, this function tries to find a nearby position to place the structure. Then uses 'self.do' to give the worker the order to start the construction.\n+ \"\"\" Not recommended as this function checks many positions if it \"can place\" on them until it found a valid\n+ position. Also if the given position is not placeable, this function tries to find a nearby position to place\n+ the structure. Then uses 'self.do' to give the worker the order to start the construction.\n:param building:\n:param near:\n:param max_distance:\n- :param unit:\n+ :param build_worker:\n:param random_alternative:\n:param placement_step: \"\"\"\nassert isinstance(near, (Unit, Point2, Point3))\n+ if not self.can_afford(building):\n+ return False\n+ p = None\ngas_buildings = {UnitTypeId.EXTRACTOR, UnitTypeId.ASSIMILATOR, UnitTypeId.REFINERY}\nif isinstance(near, Unit) and building not in gas_buildings:\nnear = near.position\nif isinstance(near, (Point2, Point3)):\nnear = near.to2\n- if not self.can_afford(building):\n- return False\nif isinstance(near, (Point2, Point3)):\np = await self.find_placement(building, near, max_distance, random_alternative, placement_step)\nif p is None:\n",
        "org_msg": "Some docstring reformatting + some pylint warning silencing and do maintainer requested changes",
        "sim_msg": "added get_slab_regions",
        "sim_diff": "diff --git a/pymatgen/core/surface.py b/pymatgen/core/surface.py @@ -1734,6 +1734,68 @@ def generate_all_slabs(structure, max_index, min_slab_size, min_vacuum_size,\nreturn all_slabs\n+def get_slab_regions(slab, blength=3):\n+ \"\"\"\n+ Function to get the ranges of the slab regions. Useful for discerning where\n+ the slab ends and vacuum begins if the slab is not fully within the cell\n+\n+ Args:\n+ slab (Structure): Structure object modelling the surface\n+ blength (float, Ang): The bondlength between atoms.\n+ \"\"\"\n+\n+ fcoords, indices, all_indices = [], [], []\n+ for site in slab:\n+ # find sites with c < 0 (noncontiguous)\n+ neighbors = slab.get_neighbors(site, blength, include_index=True,\n+ include_image=True)\n+ for nn in neighbors:\n+ if nn[0].frac_coords[2] < 0:\n+ # sites are noncontiguous within cell\n+ fcoords.append(nn[0].frac_coords[2])\n+ indices.append(nn[-2])\n+ if nn[-2] not in all_indices:\n+ all_indices.append(nn[-2])\n+\n+ if fcoords:\n+ # If slab is noncontiguous, locate the lowest\n+ # site within the upper region of the slab\n+ while fcoords:\n+ last_fcoords = copy.copy(fcoords)\n+ last_indices = copy.copy(indices)\n+ site = slab[indices[fcoords.index(min(fcoords))]]\n+ neighbors = slab.get_neighbors(site, blength, include_index=True,\n+ include_image=True)\n+ fcoords, indices = [], []\n+ for nn in neighbors:\n+ if 1 > nn[0].frac_coords[2] > 0 and \\\n+ nn[0].frac_coords[2] < site.frac_coords[2]:\n+ # sites are noncontiguous within cell\n+ fcoords.append(nn[0].frac_coords[2])\n+ indices.append(nn[-2])\n+ if nn[-2] not in all_indices:\n+ all_indices.append(nn[-2])\n+\n+ # Now locate the highest site within the lower region of the slab\n+ upper_fcoords = []\n+ for site in slab:\n+ if all([nn[-1] not in all_indices for nn in\n+ slab.get_neighbors(site, blength,\n+ include_index=True)]):\n+ upper_fcoords.append(site.frac_coords[2])\n+ coords = copy.copy(last_fcoords) if not fcoords else copy.copy(fcoords)\n+ min_top = slab[last_indices[coords.index(min(coords))]].frac_coords[2]\n+ ranges = [[0, max(upper_fcoords)], [min_top, 1]]\n+ else:\n+ # If the entire slab region is within the slab cell, just\n+ # set the range as the highest and lowest site in the slab\n+ sorted_sites = sorted(slab, key=lambda site: site.frac_coords[2])\n+ ranges = [[sorted_sites[0].frac_coords[2],\n+ sorted_sites[-1].frac_coords[2]]]\n+\n+ return ranges\n+\n+\ndef miller_index_from_sites(lattice, coords, coords_are_cartesian=True,\nround_dp=4, verbose=True):\n\"\"\"\n",
        "chatgpt_cot": "\"Fix find_placement function and add can_afford check in BotAI for better structure placement and construction.\""
    },
    {
        "org_diff": "diff --git a/README.md b/README.md @@ -18,7 +18,7 @@ Please note that not all commits are not released to PyPI. Releases are tagged w\nYou'll also need an StarCraft II executable. If you are running Windows or macOS, just install the normal SC2 from blizzard app. [The free starter edition works too.](https://us.battle.net/account/sc2/starter-edition/). Linux users must use the [Linux binary](https://github.com/Blizzard/s2client-proto#downloads).\n-You probably want some maps too. Official map downloads are available from [Blizzard/s2client-proto](https://github.com/Blizzard/s2client-proto#downloads),\n+You probably want some maps too. Official map downloads are available from [Blizzard/s2client-proto](https://github.com/Blizzard/s2client-proto#downloads). Notice: the map files are to be extracted into *subdirectories* of the `install-dir/Maps` directory.\n## Example\n",
        "org_msg": "Clarification for map locations",
        "sim_msg": "Fix twine deploy with caching in appveyor",
        "sim_diff": "diff --git a/.appveyor.yml b/.appveyor.yml @@ -49,7 +49,7 @@ artifacts:\n- path: dist\\*.whl\nbefore_deploy:\n- - \"%PYTHON%\\\\python.exe -m pip install twine\"\n+ - \"%PYTHON%\\\\python.exe -m pip install twine --upgrade --force-reinstall\"\n# set up the pypi credentials\n- \"echo [pypi] > %USERPROFILE%\\\\.pypirc\"\n@@ -57,4 +57,4 @@ before_deploy:\n- \"echo password: %password% >> %USERPROFILE%\\\\.pypirc\"\ndeploy_script:\n- - cmd: \"if [%APPVEYOR_REPO_TAG%]==[true] if NOT [%CPPDEBUG%]==[1] %PYTHON%\\\\Scripts\\\\twine upload --skip-existing dist\\\\*.whl\"\n+ - cmd: \"if [%APPVEYOR_REPO_TAG%]==[true] if NOT [%CPPDEBUG%]==[1] %PYTHON%\\\\python.exe -m twine upload --skip-existing dist\\\\*.whl\"\n",
        "chatgpt_cot": "\"Add instructions for extracting map files into subdirectories of the install directory in the README.md file.\""
    },
    {
        "org_diff": "diff --git a/node_manager_daemon_fkie/cmake/grpc_protoc.cmake b/node_manager_daemon_fkie/cmake/grpc_protoc.cmake @@ -2,8 +2,8 @@ include(CMakeParseArguments)\nmacro(generate_grpc)\nfind_program(PYTHON python)\n- # set(DEST_DIR \"${CATKIN_DEVEL_PREFIX}/${CATKIN_PACKAGE_PYTHON_DESTINATION}/generated\")\n- set(DEST_DIR \"${PROJECT_SOURCE_DIR}/src/${PROJECT_NAME}/generated\")\n+ set(DEST_DIR \"${CATKIN_DEVEL_PREFIX}/${CATKIN_PACKAGE_PYTHON_DESTINATION}/generated\")\n+ # set(DEST_DIR \"${PROJECT_SOURCE_DIR}/src/${PROJECT_NAME}/generated\")\nset(PROTO_FILES file launch screen)\nset(GEN_PROTO_FILES \"\")\nset(ABS_PROTO_PATH \"${PROJECT_SOURCE_DIR}/protos\")\n",
        "org_msg": "node_manager_daemon_fkie: changed destination for generated code",
        "sim_msg": "remove Release from path",
        "sim_diff": "diff --git a/CMakeBuild.py b/CMakeBuild.py @@ -83,7 +83,7 @@ class CMakeBuild(build_ext):\nelse:\nuse_python_casadi = True\n- build_type = os.getenv(\"PYBAMM_CPP_BUILD_TYPE\", \"Release\")\n+ build_type = os.getenv(\"PYBAMM_CPP_BUILD_TYPE\", \"\")\ncmake_args = [\n\"-DCMAKE_BUILD_TYPE={}\".format(build_type),\n\"-DPYTHON_EXECUTABLE={}\".format(sys.executable),\n",
        "chatgpt_cot": "Update DEST_DIR path in grpc_protoc.cmake to resolve path issue and set it to CATKIN_DEVEL_PREFIX for proper file generation."
    },
    {
        "org_diff": "diff --git a/setup.py b/setup.py @@ -3,13 +3,12 @@ from setuptools import setup\nsetup(\nname = \"sc2\",\npackages = [\"sc2\"],\n- version = \"0.1.0alpha0\",\n+ version = \"0.1.0alpha1\",\ndescription = \"A StarCraft II bot api library\",\nlicense='MIT',\nauthor = \"Hannes Karppila\",\nauthor_email = \"hannes.karppila@gmail.com\",\nurl = \"https://github.com/Dentosal/python-sc2\",\n- download_url = \"https://github.com/Dentosal/python-sc2/archive/v0.1.0-alpha.tar.gz\",\nkeywords = [\"StarCraft\", \"StarCraft 2\", \"StarCraft II\", \"AI\", \"Bot\"],\ninstall_requires=[\"s2clientprotocol\", \"websockets\", \"portpicker\", \"vectors\"],\nclassifiers = [\n",
        "org_msg": "Testing publishing at PyPITest",
        "sim_msg": "automatically find matchms package in setup.py",
        "sim_diff": "diff --git a/setup.py b/setup.py import os\nfrom setuptools import setup\n+from setuptools import find_packages\nhere = os.path.abspath(os.path.dirname(__file__))\n@@ -22,9 +23,7 @@ setup(\nauthor=\"Netherlands eScience Center\",\nauthor_email='generalization@esciencecenter.nl',\nurl='https://github.com/matchms/matchms',\n- packages=[\n- 'matchms',\n- ],\n+ packages=find_packages(),\ninclude_package_data=True,\nlicense=\"Apache Software License 2.0\",\nzip_safe=False,\n",
        "chatgpt_cot": "Update version to 0.1.0alpha1 in setup.py for sc2 library. Fix compilation issue and improve version tracking for StarCraft II bot api."
    },
    {
        "org_diff": "diff --git a/test/run_example_bots_vs_computer.py b/test/run_example_bots_vs_computer.py @@ -123,7 +123,7 @@ for bot_info in bot_infos:\nbot_class: Type[BotAI] = getattr(module, bot_class_name)\nlimit_match_duration = game_time_limit_vs_computer\n- if bot_class_name == \"SlowBot\":\n+ if bot_class_name in {\"SlowBot\", \"RampWallBot\"}:\nlimit_match_duration = 2\nmatches.append(\n",
        "org_msg": "Reduce match duration for ramp wall bot in tests",
        "sim_msg": "update test on cli gui search\none less package in local registry because we removed p2p_noise",
        "sim_diff": "diff --git a/tests/test_cli_gui/test_search.py b/tests/test_cli_gui/test_search.py @@ -141,7 +141,7 @@ def test_real_search():\nassert response_list.status_code == 200\ndata = json.loads(response_list.get_data(as_text=True))\n- assert len(data) == 13, data\n+ assert len(data) == 12, data\ni = 0\nassert data[i][\"id\"] == \"fetchai/gym:0.1.0\"\n",
        "chatgpt_cot": "Update match duration for SlowBot and RampWallBot in run_example_bots_vs_computer.py"
    },
    {
        "org_diff": "diff --git a/fkie_node_manager/src/fkie_node_manager/master_view_proxy.py b/fkie_node_manager/src/fkie_node_manager/master_view_proxy.py @@ -990,28 +990,35 @@ class MasterViewProxy(QWidget):\nnm.nmd().launch.get_mtimes_threaded(ld.path)\nnew_configs.append(ld.path)\nself.__configs[ld.path].nodes = ld.nodes\n+ alredy_added_nodes = set()\n# update capabilities\nfor rd in ld.robot_descriptions:\n# add capabilities\ncaps = dict()\n- node_cfgs = dict()\n+ rd_node_cfgs = dict()\nfor c in rd.capabilities:\nif c.namespace not in caps:\ncaps[c.namespace] = dict()\ncaps[c.namespace][utf8(c.name)] = {'type': c.type, 'images': [interpret_path(i) for i in c.images], 'description': interpret_path(utf8(c.description.replace(\"\\\\n \", \"\\n\"))), 'nodes': list(c.nodes)}\nfor n in c.nodes:\n- node_cfgs[n] = ld.path\n+ rd_node_cfgs[n] = ld.path\n+ alredy_added_nodes.add(n)\nrobot_addr = host_addr\nvalid_machine = False\nif rd.machine and rd.machine != host:\nrobot_addr = rd.machine\n- self.node_tree_model.append_config(masteruri, robot_addr, node_cfgs)\n+ self.node_tree_model.append_config(masteruri, robot_addr, rd_node_cfgs)\nif valid_machine or not rd.robot_name or utf8(rd.robot_name) == self.mastername:\nself.node_tree_model.add_capabilities(masteruri, robot_addr, ld.path, caps)\n# set host description\ntooltip = self.node_tree_model.update_host_description(masteruri, robot_addr, rd.robot_type, utf8(rd.robot_name), interpret_path(utf8(rd.robot_descr)))\nself.capabilities_update_signal.emit(masteruri, robot_addr, ld.path, [rd])\nself.host_description_updated.emit(masteruri, robot_addr, tooltip)\n+ node_cfgs = dict()\n+ for n in ld.nodes:\n+ if n not in alredy_added_nodes:\n+ node_cfgs[n] = ld.path\n+ self.node_tree_model.append_config(masteruri, host_addr, node_cfgs)\n# set the robot_icon\nif ld.path in self.__robot_icons:\nself.__robot_icons.remove(ld.path)\n",
        "org_msg": "fkie_node_manager: fix load launch files",
        "sim_msg": "Undo scheduled nodes fix",
        "sim_diff": "diff --git a/blueprints/settings.py b/blueprints/settings.py @@ -419,8 +419,7 @@ def admin_page():\nfrom classes.shared import celery\nnodes = celery.control.inspect(['celery@osp'])\n- # scheduled = nodes.scheduled() Deprecated\n- scheduled = {'celery@osp': []}\n+ scheduled = nodes.scheduled()\nactive = nodes.active()\nclaimed = nodes.reserved()\nschedulerList = {'nodes': nodes, 'scheduled': scheduled, 'active': active, 'claimed': claimed}\n",
        "chatgpt_cot": "\"Add new method to MasterViewProxy to fix compilation issue and update capabilities with new node configurations in the file.\""
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/main_window.py b/node_manager_fkie/src/node_manager_fkie/main_window.py @@ -813,6 +813,7 @@ class MainWindow(QMainWindow):\nif self._syncs_to_start:\nif msg.state in [MasterState.STATE_NEW, MasterState.STATE_CHANGED]:\n# we don't know which name for host was used to start master discovery\n+ try:\nif host in self._syncs_to_start:\nself.on_sync_start(msg.master.uri)\nself._syncs_to_start.remove(host)\n@@ -825,6 +826,8 @@ class MainWindow(QMainWindow):\nif address in self._syncs_to_start:\nself.on_sync_start(msg.master.uri)\nself._syncs_to_start.remove(address)\n+ except ValueError:\n+ pass\n# if len(self.masters) == 0:\n# self._setLocalMonitoring(True)\n",
        "org_msg": "node_manager_fkie: fix crash while start master_discovery with master_sync on",
        "sim_msg": "root block synchronizer checks TD before starting sync task",
        "sim_diff": "diff --git a/quarkchain/cluster/master.py b/quarkchain/cluster/master.py @@ -335,6 +335,9 @@ class Synchronizer:\nself.root_block_header_list_limit = ROOT_BLOCK_HEADER_LIST_LIMIT\ndef add_task(self, header, peer):\n+ if header.total_difficulty <= peer.root_state.tip.total_difficulty:\n+ return\n+\nself.tasks[peer] = header\nLogger.info(\n\"[R] added {} {} to sync queue (running={})\".format(\n@@ -367,17 +370,33 @@ class Synchronizer:\ndef _pop_best_task(self):\n\"\"\" pop and return the task with heightest root \"\"\"\ncheck(len(self.tasks) > 0)\n- peer, header = max(\n- self.tasks.items(), key=lambda pair: pair[1].total_difficulty\n- )\n+ remove_list = []\n+ best_peer = None\n+ best_header = None\n+ for peer, header in self.tasks.items():\n+ if header.total_difficulty <= peer.root_state.tip.total_difficulty:\n+ remove_list.append(peer)\n+ continue\n+\n+ if best_header is None or header.total_difficulty > best_header.total_difficulty:\n+ best_header = header\n+ best_peer = peer\n+\n+ for peer in remove_list:\ndel self.tasks[peer]\n- return header, peer\n+ if best_peer is not None:\n+ del self.tasks[best_peer]\n+\n+ return best_header, best_peer\nasync def __run(self):\nLogger.info(\"[R] synchronizer started!\")\nwhile len(self.tasks) > 0:\nself.running_task = self._pop_best_task()\nheader, peer = self.running_task\n+ if header is None:\n+ check(len(self.tasks) == 0)\n+ break\ntask = SyncTask(header, peer, self.stats, self.root_block_header_list_limit)\nLogger.info(\n\"[R] start sync task {} {}\".format(\n",
        "chatgpt_cot": "Add exception handling for value error in sync start method in MainWindow class."
    },
    {
        "org_diff": "diff --git a/test/autotest_bot.py b/test/autotest_bot.py @@ -536,6 +536,9 @@ class TestBot(sc2.BotAI):\n# Create a lot of units and check if their damage calculation is correct based on Unit.calculate_damage_vs_target()\nasync def test_botai_actions1001(self):\n+ # Turn off damage calculation test for now\n+ # TODO: move to seperate test bot file\n+ return\nupgrade_levels = [0, 1]\nattacker_units = [\n#\n",
        "org_msg": "Turn off damage calculation test",
        "sim_msg": "tests: mark some tests as skipped",
        "sim_diff": "diff --git a/tests/responder_test.py b/tests/responder_test.py @@ -79,15 +79,19 @@ class BrokenModulesTest(unittest2.TestCase):\nclass BlacklistTest(unittest2.TestCase):\n+ @unittest2.skip('implement me')\ndef test_whitelist_no_blacklist(self):\nassert 0\n+ @unittest2.skip('implement me')\ndef test_whitelist_has_blacklist(self):\nassert 0\n+ @unittest2.skip('implement me')\ndef test_blacklist_no_whitelist(self):\nassert 0\n+ @unittest2.skip('implement me')\ndef test_blacklist_has_whitelist(self):\nassert 0\n",
        "chatgpt_cot": "Turn off damage calculation test for now and move to separate test bot file."
    },
    {
        "org_diff": "diff --git a/Makefile b/Makefile @@ -113,8 +113,8 @@ build/docker/%/$(DUMMY): ##@Build an image locally\ndocker build -f $(@D)/Dockerfile \\\n-t $(IMG_NAME) \\\n-t $(IMG_NAME):$(IMG_TAG) \\\n- . ; \\\n- @touch $@\n+ . ;\n+ @touch $@ ;\nbuild/docker/%/.push: build/docker/%/$(DUMMY)\n@docker login \\\n",
        "org_msg": "make docker fails\nRecent changes to Makefile breaks `make docker`\nThis PR provies the required fix.",
        "sim_msg": "UI now has a latest docker tag",
        "sim_diff": "diff --git a/src/ui/Makefile b/src/ui/Makefile @@ -72,8 +72,9 @@ package: clean ## builds distribution\n# Docker\ndocker-build: package ## build docker image\n- docker build -t $(DOCKER_NAME):$(VERSION) .\n- docker tag $(DOCKER_NAME):$(VERSION) $(DOCKER_NAME):$(SHORT_VERSION)\n+ docker build -t $(DOCKER_NAME):latest .\n+ docker tag $(DOCKER_NAME):latest $(DOCKER_NAME):$(VERSION)\n+ docker tag $(DOCKER_NAME):latest $(DOCKER_NAME):$(SHORT_VERSION)\ndocker-build-unstable: package ## build nightly docker image\ndocker build -t $(DOCKER_NAME):unstable .\n@@ -81,6 +82,7 @@ docker-build-unstable: package ## build nightly docker image\n# Publishing\npublish-docker: docker-build ## push the docker image\n+ docker push $(DOCKER_NAME):latest\ndocker push $(DOCKER_NAME):$(VERSION)\ndocker push $(DOCKER_NAME):$(SHORT_VERSION)\n",
        "chatgpt_cot": "Fix indentation issue in Makefile for building docker image."
    },
    {
        "org_diff": "diff --git a/master_discovery_fkie/src/master_discovery_fkie/master_monitor.py b/master_discovery_fkie/src/master_discovery_fkie/master_monitor.py @@ -285,7 +285,7 @@ class MasterMonitor(object):\npid = _succeed(node.getPid(self.ros_node_name))\nexcept (Exception, socket.error) as e:\nwith self._lock:\n- self._limited_log(nodename, \"can't get PID: %s\" % str(e))\n+ self._limited_log(nodename, \"can't get PID: %s\" % str(e), level=rospy.DEBUG)\nmaster = xmlrpclib.ServerProxy(self.getMasteruri())\ncode, message, new_uri = master.lookupNode(self.ros_node_name, nodename)\nwith self._lock:\n@@ -350,7 +350,7 @@ class MasterMonitor(object):\n# raise ROSServiceIOException(\"Unable to communicate with service [%s], address [%s]\"%(service, uri))\nexcept:\nwith self._lock:\n- self._limited_log(service, \"can't get service type: %s\" % traceback.format_exc(), rospy.WARN)\n+ self._limited_log(service, \"can't get service type: %s\" % traceback.format_exc(), level=rospy.DEBUG)\nwith self._lock:\ntry:\ndel self.__cached_services[service]\n",
        "org_msg": "master_discovery_fkie: reduced warning outputs in cases a node or service is not reachable",
        "sim_msg": "Change the manager ips of the reporter to the private ips",
        "sim_diff": "diff --git a/status-reporter/status_reporter/status_reporter.py b/status-reporter/status_reporter/status_reporter.py @@ -117,7 +117,7 @@ class Reporter(object):\ndef _update_managers_ips_list(self, client):\nresponse = client.manager.get_managers()\n- self._managers_ips = [manager.get('public_ip') for manager in\n+ self._managers_ips = [manager.get('private_ip') for manager in\nresponse]\nupdate_yaml_file(CONFIGURATION_PATH, {\n'managers_ips': self._managers_ips\n",
        "chatgpt_cot": "Fix log level for service and PID errors in master_monitor file."
    },
    {
        "org_diff": "diff --git a/sc2/action.py b/sc2/action.py @@ -23,8 +23,15 @@ def combine_actions(action_iter, game_data):\nqueue_command=queue,\ntarget_world_space_pos=common_pb.Point2D(x=target.x, y=target.y)\n)\n+ elif isinstance(target, Unit):\n+ cmd = raw_pb.ActionRawUnitCommand(\n+ ability_id=ability_id,\n+ unit_tags=[u.unit.tag for u in items],\n+ queue_command=queue,\n+ target_unit_tag=target.tag\n+ )\nelse:\n- raise \"ERROR\"\n+ raise RuntimeError(f\"Must target an unit or a point or None, found '{target !r}'\")\nyield raw_pb.ActionRaw(unit_command=cmd)\n@@ -42,3 +49,6 @@ class UnitCommand(object):\n@property\ndef combining_tuple(self):\nreturn (self.ability_name, self.target, self.queue)\n+\n+ def __repr__(self):\n+ return f\"UnitCommand({self.ability_name}, {self.unit}, {self.target}, {self.queue})\"\n",
        "org_msg": "Allow targeting both units and positions",
        "sim_msg": "should fix custom command loading",
        "sim_diff": "diff --git a/GearBot/Cogs/CustCommands.py b/GearBot/Cogs/CustCommands.py @@ -17,10 +17,12 @@ class CustCommands(BaseCog):\nasync def reloadCommands(self):\n- for guild in self.bot.guilds:\n- self.commands[guild.id] = dict()\n- for command in await CustomCommand.filter(serverid = guild.id):\n- self.commands[guild.id][command.trigger] = command.response\n+ self.commands = dict()\n+ commands = await CustomCommand.all()\n+ for command in commands:\n+ if command.serverid not in self.commands:\n+ self.commands[command.serverid] = dict()\n+ self.commands[command.serverid][command.trigger] = command.response\nself.loaded = True\n@commands.Cog.listener()\n@@ -65,6 +67,8 @@ class CustCommands(BaseCog):\ncommand = await CustomCommand.get_or_none(serverid=ctx.guild.id, trigger=trigger)\nif command is None:\nawait CustomCommand.create(serverid = ctx.guild.id, trigger=trigger, response=reply)\n+ if ctx.guild.id not in self.commands:\n+ self.commands[ctx.guild.id] = dict()\nself.commands[ctx.guild.id][trigger] = reply\nawait ctx.send(f\"{Emoji.get_chat_emoji('YES')} {Translator.translate('custom_command_added', ctx.guild.id, trigger=trigger)}\")\nelse:\n@@ -83,7 +87,7 @@ class CustCommands(BaseCog):\ntrigger = await Utils.clean(trigger)\nif len(trigger) > 20:\nawait MessageUtils.send_to(ctx, 'WHAT', 'custom_command_trigger_too_long')\n- elif trigger in self.commands[ctx.guild.id]:\n+ elif ctx.guild.id in self.commands and trigger in self.commands[ctx.guild.id]:\nawait CustomCommand.filter(serverid = ctx.guild.id, trigger=trigger).delete()\ndel self.commands[ctx.guild.id][trigger]\nawait ctx.send(f\"{Emoji.get_chat_emoji('YES')} {Translator.translate('custom_command_removed', ctx.guild.id, trigger=trigger)}\")\n",
        "chatgpt_cot": "Add new method and __repr__ function in UnitCommand class to handle different types of targets and improve debugging."
    },
    {
        "org_diff": "diff --git a/fkie_node_manager/src/fkie_node_manager/node_tree_model.py b/fkie_node_manager/src/fkie_node_manager/node_tree_model.py @@ -1792,6 +1792,7 @@ class NodeTreeModel(QStandardItemModel):\nmuris = []\naddresses = []\nupdated_nodes = []\n+ local_info = nmdurl.equal_uri(self._local_masteruri, info_masteruri)\nfor i in reversed(range(self.invisibleRootItem().rowCount())):\nhost = self.invisibleRootItem().child(i)\nhost.reset_remote_launched_nodes()\n@@ -1807,7 +1808,6 @@ class NodeTreeModel(QStandardItemModel):\nfor (host_item, nodes_filtered) in hosts.items():\n# rename the host item if needed\nif host_item is not None:\n- local_info = nmdurl.equal_uri(host_item.masteruri, info_masteruri)\nupdated_nodes.extend(host_item.update_running_state(nodes_filtered, local_info))\n# request for all nodes in host the parameter capability_group\nself._requestCapabilityGroupParameter(host_item)\n",
        "org_msg": "fkie_node_manager: fixed view of synced nodes",
        "sim_msg": "Remove redundant docstring\nThe method is quite simple and it doesn't need a dostring.\nAlso existing docstring was incorrect. The name of the expected\nparameter is 'name', not 'node'. And it cannot be an object\nof the type node.StorageNode",
        "sim_diff": "diff --git a/watcher/decision_engine/model/model_root.py b/watcher/decision_engine/model/model_root.py @@ -391,10 +391,6 @@ class StorageModelRoot(nx.DiGraph, base.Model):\n@lockutils.synchronized(\"storage_model\")\ndef get_node_by_name(self, name):\n- \"\"\"Get a node by node name\n-\n- :param node: :py:class:`~.node.StorageNode` object or node name\n- \"\"\"\ntry:\nreturn self._get_by_name(name.split(\"#\")[0])\nexcept exception.StorageResourceNotFound:\n",
        "chatgpt_cot": "Fix local_info assignment issue in NodeTreeModel for better comparison of URIs."
    },
    {
        "org_diff": "diff --git a/.github/workflows/ci.yml b/.github/workflows/ci.yml @@ -55,7 +55,7 @@ jobs:\nrun: poetry config virtualenvs.in-project true\n- name: Set up cache\n- uses: actions/cache@v2\n+ uses: actions/cache@v3\nwith:\npath: .venv\nkey: ${{ matrix.os }}-${{ matrix.python-version }}-poetry-${{ hashFiles('poetry.lock') }}\n",
        "org_msg": "Use actions/cache@v3",
        "sim_msg": "ci: fix poetry install",
        "sim_diff": "diff --git a/.github/workflows/cicd.yaml b/.github/workflows/cicd.yaml @@ -26,6 +26,7 @@ jobs:\nwith:\nvirtualenvs-create: true\nvirtualenvs-in-project: true\n+ virtualenvs-path: \"{project-dir}/.venv\"\n- name: Load cached venv\nid: cached-poetry-dependencies\nuses: actions/cache@v3\n",
        "chatgpt_cot": "Update actions/cache to v3 in ci.yml for setting up cache."
    },
    {
        "org_diff": "diff --git a/fkie_node_manager/scripts/remote_nm.py b/fkie_node_manager/scripts/remote_nm.py @@ -104,24 +104,41 @@ def getCwdArg(arg, argv):\ndef main(argv=sys.argv):\ntry:\n+ print_help = True\noptions, args = parse_options(argv)\nif options['show_screen_log']:\nlogfile = screen.get_logfile(node=options['show_screen_log'])\n- p = subprocess.Popen(shlex.split(' '.join([nm.Settings.LOG_VIEWER, str(logfile)])))\n+ if not logfile:\n+ raise Exception('screen logfile not found for: %s' % options['show_screen_log'])\n+ cmd = ' '.join([nm.Settings.LOG_VIEWER, str(logfile)])\n+ print(cmd)\n+ p = subprocess.Popen(shlex.split(cmd))\np.wait()\n+ print_help = False\nif options['tail_screen_log']:\nlogfile = screen.get_logfile(node=options['tail_screen_log'])\n- p = subprocess.Popen(shlex.split(' '.join(['tail', '-f', '-n', '25', str(logfile)])))\n+ if not logfile:\n+ raise Exception('screen logfile not found for: %s' % options['tail_screen_log'])\n+ cmd = ' '.join(['tail', '-f', '-n', '25', str(logfile)])\n+ print(cmd)\n+ p = subprocess.Popen(shlex.split(cmd))\np.wait()\n+ print_help = False\nelif options['show_ros_log']:\nlogfile = screen.get_ros_logfile(node=options['show_ros_log'])\n- p = subprocess.Popen(shlex.split(' '.join([nm.Settings.LOG_VIEWER, str(logfile)])))\n+ if not logfile:\n+ raise Exception('ros logfile not found for: %s' % options['show_ros_log'])\n+ cmd = ' '.join([nm.Settings.LOG_VIEWER, str(logfile)])\n+ print(cmd)\n+ p = subprocess.Popen(shlex.split(cmd))\np.wait()\n+ print_help = False\nelif options['ros_log_path']:\nif options['ros_log_path'] == '[]':\nprint(nm.get_ros_home())\nelse:\nprint(screen.get_logfile(node=options['ros_log_path']))\n+ print_help = False\nelif options['delete_logs']:\nlogfile = screen.get_logfile(node=options['delete_logs'])\npidfile = screen.get_pidfile(node=options['delete_logs'])\n@@ -132,15 +149,19 @@ def main(argv=sys.argv):\nos.remove(pidfile)\nif os.path.isfile(roslog):\nos.remove(roslog)\n+ print_help = False\nelif options['node_type'] and options['package'] and options['node_name']:\nrunNode(options['package'], options['node_type'], options['node_name'],\nargs, options['prefix'], options['node_respawn'], options['masteruri'], loglevel=options['loglevel'])\n+ print_help = False\nelif options['pidkill']:\nimport signal\nos.kill(int(options['pidkill']), signal.SIGKILL)\n+ print_help = False\nelif options['package']:\nprint(roslib.packages.get_pkg_dir(options['package']))\n- else:\n+ print_help = False\n+ if print_help:\nparser = _get_optparse()\nparser.print_help()\ntime.sleep(3)\n",
        "org_msg": "fkie_node_manager: added more output to remote script",
        "sim_msg": "Remove outdated util commands",
        "sim_diff": "diff --git a/augur/cli/util.py b/augur/cli/util.py @@ -14,50 +14,6 @@ def cli():\ndef shell(app):\napp.shell()\n-@cli.command('edit-config', short_help='Edit your config file')\n-@pass_application\n-def edit_config(app):\n- \"\"\"\n- Edit your config file\n- \"\"\"\n- click.edit(filename=app._config_file_path)\n-\n-\n-@cli.command('python-location', short_help='Print the location of the interpreter that is running this')\n-def interpreter():\n- \"\"\"\n- Print the location of the interpreter that is running this\n- \"\"\"\n- print(sys.executable)\n-\n-\n-@cli.command('except', short_help='Test logging and raise an exception')\n-@pass_application\n-def excpt(app):\n- \"\"\"\n- Print the location of the interpreter that is running this\n- \"\"\"\n- print('Logging tests... ', file=sys.stderr)\n- app.log.info('Hello')\n- app.log.warn('Things are looking scary')\n- app.log.error('Things are bad!')\n- app.log.fatal('Now I am dying')\n- print('Exception handling...', file=sys.stderr)\n- raise Exception('is dead')\n-\n-\n-@cli.command('upgrade', short_help='Upgrade Augur')\n-@click.option('--from-directory', '-f', type=click.Path(), help='Upgrade from a provided directory rather than git.')\n-@pass_application\n-def upgrade(app, from_directory):\n- \"\"\"\n- Print the location of the interpreter that is running this\n- \"\"\"\n- pass\n- # app.log.info(pyrcss.util.self_upgrade(from_directory=from_directory, dry_run=true))\n- # pyrcss.util.self_upgrade(from_directory=from_directory)\n-\n-\n@cli.command('kill', short_help='Kill Augur')\n@pass_application\ndef kill(app):\n",
        "chatgpt_cot": "\"Fix compilation issue due to new conditional statements and add print_help variable to the remote_nm.py script for better user interaction.\""
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/master_view_proxy.py b/node_manager_fkie/src/node_manager_fkie/master_view_proxy.py @@ -2282,8 +2282,12 @@ class MasterViewProxy(QWidget):\nret = MessageBox.question(self, \"Show IO\", \"You are going to open the IO of \" + utf8(len(selectedNodes)) + \" nodes at once\\nContinue?\", buttons=MessageBox.Ok | MessageBox.Cancel)\nret = (ret == MessageBox.Ok)\nif ret:\n+ queue = self._progress_queue_prio\n+ # we use normal queue, if there are not a lot of processes\n+ if self._progress_queue.count() < 5:\n+ queue = self._progress_queue\nfor node in selectedNodes:\n- self._progress_queue_prio.add2queue(utf8(uuid.uuid4()),\n+ queue.add2queue(utf8(uuid.uuid4()),\n''.join(['show IO of ', node.name]),\nnm.screen().openScreen,\n(node.name, self.getHostFromNode(node), False, self.current_user))\n",
        "org_msg": "node_manager_fkie: use priority queue for sreen io only if normal queue has more than 5 elements",
        "sim_msg": "tree: improve popup menu handling",
        "sim_diff": "diff --git a/tree.py b/tree.py @@ -390,7 +390,8 @@ class WidgetTree(wx.TreeCtrl, Tree):\nself.Bind(wx.EVT_RIGHT_DOWN, self.popup_menu)\nself.Bind(wx.EVT_LEFT_DCLICK, self.on_left_dclick)\nself.Bind(wx.EVT_LEFT_DOWN, self.on_left_click) # allow direct placement of widgets\n- self.Bind(wx.EVT_MENU, self.show_toplevel)\n+ self.Bind(wx.EVT_MENU, self.on_menu) # for handling the selection of the first item\n+ self._popup_menu_widget = None # the widget for the popup menu\nself.Bind(wx.EVT_TREE_BEGIN_DRAG, self.begin_drag)\nself.Bind(wx.EVT_LEAVE_WINDOW, self.on_leave_window)\nself.Bind(wx.EVT_MOUSE_EVENTS, self.on_mouse_events)\n@@ -707,6 +708,12 @@ class WidgetTree(wx.TreeCtrl, Tree):\nself.SetCursor(wx.STANDARD_CURSOR)\nevent.Skip()\n+ def on_menu(self, event):\n+ # the first entry in the popup menu, i.e. the name was selected\n+ if self._popup_menu_widget is None: return\n+ if not getattr(self._popup_menu_widget, \"_is_toplevel_window\", False): return\n+ self.show_toplevel( None, self._popup_menu_widget )\n+\ndef on_mouse_events(self, event):\nif not self._drag_ongoing and not event.IsButton():\n# set cursor to indicate a possible drop\n@@ -730,8 +737,9 @@ class WidgetTree(wx.TreeCtrl, Tree):\nif not node:\nreturn\nself.select_item(node)\n- item = node.widget\n- item.popup_menu(event, pos)\n+ self._popup_menu_widget = node.widget\n+ node.widget.popup_menu(event, pos)\n+ self._popup_menu_widget = None\ndef expand(self, node=None, yes=True):\n\"expands or collapses the given node\"\n",
        "chatgpt_cot": "Add logic to use normal queue if there are not a lot of processes in MasterViewProxy for showing IO of selected nodes."
    },
    {
        "org_diff": "diff --git a/examples/competitive/ladderbots.json b/examples/competitive/ladderbots.json {\n\"Bots\": {\n- \"example_bot\": {\n+ \"YOUR_BOTS_NAME_HERE\": {\n\"Race\": \"Put Terran Zerg or Protoss here\",\n\"Type\": \"Python\",\n\"RootPath\": \"./\",\n",
        "org_msg": "Update example competitive ladderbots.json",
        "sim_msg": "Update: Adds the missing keys & values to the master.config.example",
        "sim_diff": "diff --git a/config/master.json.example b/config/master.json.example \"DATABASE_PORT\": 3306,\n\"DATABASE_USER\": \"gearbot\",\n\"APEX_KEY\": \"\",\n+ \"REDIS_HOST\": \"localhost\",\n+ \"REDIS_PORT\": 6379,\n+ \"REDIS_SOCKET\": \"\",\n+ \"SENTRY_DSN\": \"\",\n\"EMOJI\": {\n},\n+ \"EMOJI_GUILD\": null,\n\"GUIDES\": 0,\n\"inbox\": 0,\n\"COGS\": [\n\"ReactionHandler\",\n\"Censor\",\n\"Infractions\",\n+ \"Interactions\",\n\"Minecraft\",\n\"DMMessages\",\n\"Reminders\",\n\"Emoji\",\n\"AntiSpam\"\n],\n+ \"TRANSLATIONS\": {\n+ \"CHANNEL\": 0,\n+ \"KEY\": \"\",\n+ \"LOGIN\": \"\",\n+ \"SOURCE\": \"DISABLED\",\n+ \"WEBROOT\": \"\"\n+ },\n\"DOCS\": true,\n\"DISABLED_COMMANDS\": [],\n\"DASH_OUTAGE\": {\n}\n]\n}\n+ },\n+ \"global_inf_counter\": true,\n+ \"min_cached_users\": 0,\n+ \"purge_db\": true\n+\n}\n-}\n+\n",
        "chatgpt_cot": "Change example_bot name to YOUR_BOTS_NAME_HERE in ladderbots.json."
    },
    {
        "org_diff": "diff --git a/sc2/sc2process.py b/sc2/sc2process.py @@ -26,9 +26,16 @@ class kill_switch(object):\np._clean()\nclass SC2Process(object):\n- def __init__(self, fullscreen=False):\n+ def __init__(self, host=\"127.0.0.1\", port=None, fullscreen=False):\n+ assert isinstance(host, str)\n+ assert isinstance(port, int) or port is None\n+\nself._fullscreen = fullscreen\n+ self._host = host\n+ if port is None:\nself._port = portpicker.pick_unused_port()\n+ else:\n+ self._port = port\nself._tmp_dir = tempfile.mkdtemp(prefix=\"SC2_\")\nself._process = None\nself._ws = None\n@@ -56,12 +63,12 @@ class SC2Process(object):\n@property\ndef ws_url(self):\n- return f\"ws://127.0.0.1:{self._port}/sc2api\"\n+ return f\"ws://{self._host}:{self._port}/sc2api\"\ndef _launch(self):\nreturn subprocess.Popen([\nPaths.EXECUTABLE,\n- \"-listen\", \"127.0.0.1\",\n+ \"-listen\", self._host,\n\"-port\", str(self._port),\n\"-displayMode\", \"1\" if self._fullscreen else \"0\",\n\"-dataDir\", Paths.BASE,\n",
        "org_msg": "Allow custom hostname and port for sc2process websocket",
        "sim_msg": "Fixed Re-enabled static file serving in ChannelsLiveServerTestCase",
        "sim_diff": "diff --git a/channels/testing/live.py b/channels/testing/live.py @@ -4,6 +4,7 @@ from django.test.testcases import TransactionTestCase\nfrom django.test.utils import modify_settings\nfrom channels.routing import get_default_application\n+from channels.staticfiles import StaticFilesWrapper\nfrom daphne.testing import DaphneProcess\n@@ -17,6 +18,7 @@ class ChannelsLiveServerTestCase(TransactionTestCase):\nhost = \"localhost\"\nProtocolServerProcess = DaphneProcess\n+ static_wrapper = StaticFilesWrapper\nserve_static = True\n@property\n@@ -40,9 +42,13 @@ class ChannelsLiveServerTestCase(TransactionTestCase):\nALLOWED_HOSTS={\"append\": self.host}\n)\nself._live_server_modified_settings.enable()\n- self._server_process = self.ProtocolServerProcess(\n- self.host, get_default_application()\n- )\n+\n+ if self.serve_static:\n+ application = self.static_wrapper(get_default_application())\n+ else:\n+ application = get_default_application()\n+\n+ self._server_process = self.ProtocolServerProcess(self.host, application)\nself._server_process.start()\nself._server_process.ready.wait()\nself._port = self._server_process.port.value\n",
        "chatgpt_cot": "Add host and port arguments to SC2Process constructor, set host and port attributes, and update ws_url to use host."
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/supervised_popen.py b/node_manager_fkie/src/node_manager_fkie/supervised_popen.py @@ -41,7 +41,7 @@ import threading\nfrom .detailed_msg_box import WarningMessageBox\n-class SupervisedPopen(QObject, subprocess.Popen):\n+class SupervisedPopen(QObject):\n'''\nThe class overrides the subprocess.Popen and waits in a thread for its finish.\nIf an error is printed out, it will be shown in a message dialog.\n@@ -67,25 +67,15 @@ class SupervisedPopen(QObject, subprocess.Popen):\n:type description: str\n'''\ntry:\n- try:\n- super(SupervisedPopen, self).__init__(args=args, bufsize=bufsize, executable=executable, stdin=stdin, stdout=stdout,\n- stderr=stderr, preexec_fn=preexec_fn, close_fds=close_fds,\n- shell=shell, cwd=cwd, env=env, universal_newlines=universal_newlines,\n- startupinfo=startupinfo, creationflags=creationflags)\n- except:\n- try:\n- subprocess.Popen.__init__(self, args=args, bufsize=bufsize, executable=executable, stdin=stdin, stdout=stdout,\n- stderr=stderr, preexec_fn=preexec_fn, close_fds=close_fds, shell=shell, cwd=cwd, env=env,\n- universal_newlines=universal_newlines, startupinfo=startupinfo, creationflags=creationflags)\n- except:\n- import traceback\n- print traceback.format_exc()\nQObject.__init__(self)\nself._args = args\nself._object_id = object_id\nself._description = description\nself.error.connect(self.on_error)\n# wait for process to avoid 'defunct' processes\n+ self.popen = subprocess.Popen(args=args, bufsize=bufsize, executable=executable, stdin=stdin, stdout=stdout,\n+ stderr=stderr, preexec_fn=preexec_fn, close_fds=close_fds, shell=shell, cwd=cwd, env=env,\n+ universal_newlines=universal_newlines, startupinfo=startupinfo, creationflags=creationflags)\nthread = threading.Thread(target=self._supervise)\nthread.setDaemon(True)\nthread.start()\n@@ -95,11 +85,23 @@ class SupervisedPopen(QObject, subprocess.Popen):\n# def __del__(self):\n# print \"Deleted:\", self._description\n+ @property\n+ def stdout(self):\n+ return self.popen.stdout\n+\n+ @property\n+ def stderr(self):\n+ return self.popen.stderr\n+\n+ @property\n+ def stdin(self):\n+ return self.popen.stdin\n+\ndef _supervise(self):\n'''\nWait for process to avoid 'defunct' processes\n'''\n- self.wait()\n+ self.popen.wait()\nresult_err = ''\nif self.stderr is not None:\nresult_err = self.stderr.read()\n",
        "org_msg": "node_manager_fkie: changed supervised_popen initialization to avoid multi subclassing",
        "sim_msg": "separate launch cmd for running docker build, pull, up as individual steps",
        "sim_diff": "diff --git a/packages/hagrid/hagrid/cli.py b/packages/hagrid/hagrid/cli.py @@ -382,6 +382,12 @@ def execute_commands(\nelse GRID_SRC_PATH\n)\n+ def enqueue_output(out: Any, queue: Queue) -> None:\n+ for line in iter(out.readline, b\"\"):\n+ queue.put(line)\n+ out.close()\n+\n+\nprint(\"Current Working Directory: \", cwd)\nfor cmd in cmds:\n@@ -407,14 +413,42 @@ def execute_commands(\nelse:\ndisplay_jupyter_token(cmd)\nif silent:\n+ ON_POSIX = \"posix\" in sys.builtin_module_names\n+\nprocess = subprocess.Popen( # nosec\ncmd_to_exec,\nstdout=subprocess.PIPE,\nstderr=subprocess.PIPE,\ncwd=cwd,\n- shell=True,\n+ close_fds=ON_POSIX,\n+ shell=True\n)\n- process.communicate()\n+\n+ print(process.pid, process.poll())\n+\n+ queue: Queue = Queue()\n+ thread_1 = Thread(target=enqueue_output, args=(process.stdout, queue))\n+ thread_2 = Thread(target=enqueue_output, args=(process.stderr, queue))\n+ # thread_3 = Thread(target=enqueue_output, args=(process.stdin, queue))\n+ thread_1.daemon = True # thread dies with the program\n+ thread_1.start()\n+ thread_2.daemon = True # thread dies with the program\n+ thread_2.start()\n+ # thread_3.daemon = True # thread dies with the program\n+ # thread_3.start()\n+\n+ print(\"Queue started\")\n+ while process.poll() != 0:\n+ while True:\n+ if queue.empty():\n+ break\n+ line = queue.get()\n+ line = str(line, encoding=\"utf-8\").strip()\n+ print(f\"Logs: {line}\", end='\\r', flush=True)\n+\n+ if \"Building[\" in line:\n+ print(\"...............Building............\", line, flush=True)\n+\nelse:\nsubprocess.run( # nosec\ncmd_to_exec,\n@@ -1505,9 +1539,9 @@ def create_launch_docker_cmd(\nelse:\ncmd += \" \".join(args)\n- if not build:\n- pull_cmd = str(cmd)\n- pull_cmd += \" docker compose pull\"\n+ build_cmd = \"\"\n+ pull_cmd = \"\"\n+ up_cmd = \"\"\ncmd += \" docker compose -p \" + snake_name\n@@ -1575,20 +1609,34 @@ def create_launch_docker_cmd(\ncmd += \" --file docker-compose.tls.yml\"\nif \"test\" in kwargs and kwargs[\"test\"] is True:\ncmd += \" --file docker-compose.test.yml\"\n- cmd += \" up\"\n+\n+ up_cmd = str(cmd)\n+ up_cmd += \" up\"\n+\n+\n+ if not build:\n+ pull_cmd = str(cmd)\n+ pull_cmd += \" pull --ignore-pull-failures\"\n+\nif not tail:\n- cmd += \" -d\"\n+ up_cmd += \" -d\"\nif build:\n- cmd += \" --build\" # force rebuild\n- else:\n+ build_cmd = str(cmd)\n+ build_cmd += \" build\" # force rebuild\n+\nif is_windows():\n- cmd = pull_cmd + \"; \" + cmd\n+ final_cmd = \" ,\".join([build_cmd, pull_cmd, up_cmd])\nelse:\n- cmd = pull_cmd + \" && \" + cmd\n+ final_cmd = \" && \".join([build_cmd, pull_cmd, up_cmd])\n- return cmd\n+\n+ print(\"Command: \")\n+ print(final_cmd)\n+ return \"\"\n+\n+ return final_cmd\ndef create_launch_vagrant_cmd(verb: GrammarVerb) -> str:\n",
        "chatgpt_cot": "Fix inheritance issue in SupervisedPopen class, remove unnecessary super() and subprocess.Popen calls, and add properties for stdin, stdout, and stderr."
    },
    {
        "org_diff": "diff --git a/rasa_core_sdk/forms.py b/rasa_core_sdk/forms.py @@ -54,6 +54,15 @@ class FormAction(Action):\n# type: (Tracker) -> Dict[Text, Any]\n\"\"\"\"Validate the user input.\"\"\"\n+ events = []\n+ entities = tracker.latest_message[\"entities\"]\n+ print(entities)\n+ for e in entities:\n+ if e.get(\"name\") == tracker.slots[REQUESTED_SLOT]:\n+ events.append(SlotSet(e['name'], e['value']))\n+ if events:\n+ return events\n+ else:\nraise InputValidationError(\"validation not implemented\")\ndef activate_if_required(self, tracker):\n@@ -62,18 +71,11 @@ class FormAction(Action):\nelse:\nreturn [FormActivated(self.name())]\n- def get_requested_slot(self, tracker):\n- events = []\n- intent = tracker.latest_message[\"intent\"].get(\"name\")\n- if intent == \"extracted_slot\":\n- for slot in tracker.latest_message[\"slots\"]:\n- events.append(SlotSet(slot['name'], slot['value']))\n-\n- return events\n-\ndef run(self, dispatcher, tracker, domain):\n-\n- events = self.get_requested_slot(tracker)\n+ if tracker.active_form == self.name():\n+ events = self.validate(tracker)\n+ else:\n+ events = []\ntemp_tracker = tracker.copy()\nfor e in events:\ntemp_tracker.slots[e[\"name\"]] = e[\"value\"]\n",
        "org_msg": "fix validation method",
        "sim_msg": "Fix wrong permissions app name\nThis fixes by replacing the previous, wrong permission app name\n`workshops` with correct name `extrequests`.",
        "sim_diff": "diff --git a/amy/extrequests/views.py b/amy/extrequests/views.py @@ -279,7 +279,7 @@ class WorkshopInquirySetState(OnlyForAdminsMixin, ChangeRequestStateView):\nclass WorkshopInquiryAcceptEvent(OnlyForAdminsMixin, PermissionRequiredMixin,\nAMYCreateAndFetchObjectView):\n- permission_required = ['workshops.change_workshopinquiryrequest',\n+ permission_required = ['extrequests.change_workshopinquiryrequest',\n'workshops.add_event']\nmodel = Event\nform_class = EventCreateForm\n@@ -400,7 +400,7 @@ class SelfOrganisedSubmissionSetState(OnlyForAdminsMixin,\nclass SelfOrganisedSubmissionAcceptEvent(OnlyForAdminsMixin,\nPermissionRequiredMixin,\nAMYCreateAndFetchObjectView):\n- permission_required = ['workshops.change_selforganisedsubmission',\n+ permission_required = ['extrequests.change_selforganisedsubmission',\n'workshops.add_event']\nmodel = Event\nform_class = EventCreateForm\n",
        "chatgpt_cot": "Refactor FormAction class in forms.py, add validate method, remove get_requested_slot method, and update run method to use validate method."
    },
    {
        "org_diff": "diff --git a/README.md b/README.md @@ -10,7 +10,7 @@ Whats new:\n# FKIE multimaster for ROS\n-The ROS stack of *multimaster_fkie* offers a complete solution for using ROS with multicores.\n+The ROS stack of *fkie_multimaster* offers a complete solution for using ROS with multicores.\nIn addition, Node Manager with a daemon provide a GUI-based management environment that is very useful to manage ROS-launch configurations and control running nodes, also in a single-core system.\n![multimaster overview](multimaster_overview.png)\n@@ -23,14 +23,14 @@ The communication between Node Manager and the daemon is based on python [gRPC](\n```\ncd catkin_ws/src\n-git clone https://github.com/fkie/multimaster_fkie.git\n+git clone https://github.com/fkie/multimaster_fkie.git multimaster\nrosdep update\n-rosdep install -i --as-root pip:false --reinstall --from-paths multimaster_fkie\n+rosdep install -i --as-root pip:false --reinstall --from-paths multimaster\n```\nThan build all packages:\n```\n-catkin build multimaster_fkie\n+catkin build fkie_multimaster\n```\n## Manual:\n",
        "org_msg": "Fix package name references in README",
        "sim_msg": "resume downloads if DHT disabled",
        "sim_diff": "diff --git a/lbrynet/stream/stream_manager.py b/lbrynet/stream/stream_manager.py @@ -156,10 +156,10 @@ class StreamManager:\nlog.info(\"Started stream manager with %i files\", len(file_infos))\nasync def resume(self):\n- if not self.node:\n- log.warning(\"no DHT node given, cannot resume downloads\")\n- return\n+ if self.node:\nawait self.node.joined.wait()\n+ else:\n+ log.warning(\"no DHT node given, resuming downloads trusting that we can contact reflector\")\nt = [\nstream.start_download(self.node)\nfor stream in self.streams if stream.status == ManagedStream.STATUS_RUNNING\n",
        "chatgpt_cot": "Update file and folder names for consistency with project naming conventions. Update installation instructions to reflect changes in file and folder names."
    },
    {
        "org_diff": "diff --git a/fkie_master_sync/nodes/param_sync.py b/fkie_master_sync/nodes/param_sync.py @@ -23,9 +23,9 @@ def master_changed(msg, cb_args):\nif '/'+local_name in params_from:\ndel params_from['/'+local_name]\nrospy.logdebug(\"Syncing params from {} to {}...\".format(msg.master.name, local_name))\n- if param_cache.get(msg.master.name, None) != params_from:\n- param_cache[msg.master.name] = params_from\n- master_to['/'+msg.master.name] = params_from\n+ if param_cache.get('', None) != params_from:\n+ param_cache[''] = params_from\n+ master_to['/'] = params_from\nrospy.logdebug(\"Done syncing params from {} to {}.\".format(msg.master.name, local_name))\nelse:\nrospy.logdebug(\"Params have not changed from {} to {}.\".format(msg.master.name, local_name))\n@@ -39,7 +39,7 @@ def master_changed(msg, cb_args):\ndef main():\n- rospy.init_node('param_sync', log_level=rospy.DEBUG)\n+ rospy.init_node('param_sync', log_level=rospy.DEBUG, anonymous=True)\nparam_cache = dict()\nlocal_master = list()\n",
        "org_msg": "removed hostname namespace",
        "sim_msg": "don't flood the loop with a ton of tasks",
        "sim_diff": "diff --git a/GearBot/Cogs/ModLog.py b/GearBot/Cogs/ModLog.py @@ -64,23 +64,30 @@ class ModLog:\nlogged.save()\neditCount = editCount + 1\ncount = count + 1\n- if count % 50 is 0:\n+ if count % 25 is 0:\nawait asyncio.sleep(0)\nGearbotLogging.info(f\"Discovered {newCount} new messages and {editCount} edited in {guild.name} (checked {count})\")\n- if startup:\n- self.to_cache -= 1\n- if self.to_cache is 0:\n- await self.cache_message.edit(content=f\"{Emoji.get_chat_emoji('YES')} Modlog cache validation completed in {round(time.perf_counter() - self.cache_start, 2)}s\")\nasync def prep(self):\nself.cache_message = await GearbotLogging.logToBotlog(f\"{Emoji.get_chat_emoji('REFRESH')} Validating modlog cache\")\n- self.to_cache = 0\n+ self.to_cache = []\nfor guild in self.bot.guilds:\nif Configuration.getConfigVar(guild.id, \"MINOR_LOGS\") is not 0:\n- self.to_cache += 1\n- self.bot.loop.create_task(self.buildCache(guild, startup=True))\n+ self.to_cache.append(guild)\n+ for i in range(min(3, len(self.bot.guilds))):\n+ self.bot.loop.create_task(self.startup_cache())\nself.cache_start = time.perf_counter()\n+ async def startup_cache(self):\n+ while self.to_cache is not None:\n+ if len(self.to_cache) > 0:\n+ guild = self.to_cache.pop()\n+ await self.buildCache(guild, startup=True)\n+ else:\n+ self.to_cache = None\n+ await self.cache_message.edit(content=f\"{Emoji.get_chat_emoji('YES')} Modlog cache validation completed in {round(time.perf_counter() - self.cache_start, 2)}s\")\n+\n+\nasync def on_message(self, message: discord.Message):\nif not hasattr(message.channel, \"guild\") or message.channel.guild is None:\nreturn\n",
        "chatgpt_cot": "\"Fix param_sync initialization issue by adding anonymous=True parameter to rospy.init_node to ensure correct logging behavior.\""
    },
    {
        "org_diff": "diff --git a/sc2/client.py b/sc2/client.py @@ -279,6 +279,28 @@ class Client(Protocol):\n)\n)\n+ async def toggle_autocast(self, units: Union[List[Unit], Units], ability: AbilityId):\n+ \"\"\"Toggle autocast of all specified units\"\"\"\n+ assert isinstance(units, list)\n+ assert units\n+ assert all(isinstance(u, Unit) for u in units)\n+ assert isinstance(ability, AbilityId)\n+\n+ await self._execute(\n+ action=sc_pb.RequestAction(\n+ actions=[\n+ sc_pb.Action(\n+ action_raw=raw_pb.ActionRaw(\n+ toggle_autocast=raw_pb.ActionRawToggleAutocast(\n+ ability_id=ability.value,\n+ unit_tags=[u.tag for u in units]\n+ )\n+ )\n+ )\n+ ]\n+ )\n+ )\n+\nasync def debug_create_unit(self, unit_spawn_commands: List[List[Union[UnitTypeId, int, Point2, Point3]]]):\n\"\"\" Usage example (will spawn 1 marine in the center of the map for player ID 1):\nawait self._client.debug_create_unit([[UnitTypeId.MARINE, 1, self._game_info.map_center, 1]]) \"\"\"\n@@ -399,7 +421,7 @@ class Client(Protocol):\ndef debug_text_2d(self, text: str, pos: Union[Point2, Point3, tuple, list], color=None, size: int = 8):\nreturn self.debug_text_screen(text, pos, color, size)\n- def debug_text_world(self, text: str, pos: Union[Unit, Point2, Point3], color=None, size: int = 8):\n+ def debug_text_world(self, text: str, pos: Union[Point2, Point3], color=None, size: int = 8):\n\"\"\" Draws a text at Point3 position. Don't forget to add 'await self._client.send_debug'.\nTo grab a unit's 3d position, use unit.position3d\nUsually the Z value of a Point3 is between 8 and 14 (except for flying units)\n",
        "org_msg": "Add autocast toggle function",
        "sim_msg": "add paraboloid shader",
        "sim_diff": "diff --git a/gibson2/core/render/mesh_renderer/shaders/fisheye_vert.shader b/gibson2/core/render/mesh_renderer/shaders/fisheye_vert.shader @@ -135,16 +135,17 @@ void main() {\ngl_Position = P * V * pose_trans * pose_rot * vec4(position, 1);\n-\nvec4 tmp_Position = V * pose_trans * pose_rot * vec4(position, 1);\n-\n- tmp_Position.z = -tmp_Position.z;\n-\nvec4 projection = camera_model(tmp_Position.xyz);\n-\n- gl_Position.xy = (projection.xy - vec2(1.2109375 * FISHEYE_SIZE, 1.2109375 * FISHEYE_SIZE)) /(1.2109375 * FISHEYE_SIZE) ;\n- gl_Position.z = - 1 / (length(tmp_Position.xyz) * 10.0);\n+ float zfar = 100;\n+ float znear = 0.01;\n+ float l = length(tmp_Position.xyz);\n+ gl_Position.xyz = tmp_Position.xyz/l;\n+ gl_Position.z = gl_Position.z + 1;\n+ gl_Position.x = gl_Position.x / gl_Position.z;\n+ gl_Position.y = gl_Position.y / gl_Position.z;\n+ gl_Position.z = (l-znear) / (zfar - znear);\ngl_Position.w = 1;\nfloat angle;\n",
        "chatgpt_cot": "\"Add toggle_autocast method to the Client class and modify the debug_text_world method to draw text at a Point3 position.\""
    },
    {
        "org_diff": "diff --git a/.github/workflows/codecoverage.yml b/.github/workflows/codecoverage.yml @@ -94,10 +94,10 @@ jobs:\n# Output a cyclomatic complexity report of the project\nname: Run radon\nruns-on: ubuntu-latest\n- timeout-minutes: 3\n+ timeout-minutes: 10\nstrategy:\nmatrix:\n- python-version: ['3.9']\n+ python-version: ['3.10']\nsteps:\n- uses: actions/checkout@v2\n",
        "org_msg": "Increase timeout limit for radon",
        "sim_msg": "ci: add test job for examples in cd\nAdded a new job in cd.yml to run tests for each example in jina-ai/examples",
        "sim_diff": "diff --git a/.github/workflows/cd.yml b/.github/workflows/cd.yml @@ -221,3 +221,34 @@ jobs:\nenv_vars: OS,PYTHON\nname: codecov\nfail_ci_if_error: true\n+\n+ examples-test:\n+ runs-on: ${{ matrix.os }}\n+ strategy:\n+ matrix:\n+ os: [ubuntu-latest] #[macos-latest, ubuntu-latest]\n+ python-version: [3.7]\n+\n+ steps:\n+ - uses: actions/checkout@v2\n+ with:\n+ submodules: true\n+ - name: Set up Python ${{ matrix.python-version }}\n+ uses: actions/setup-python@v1\n+ with:\n+ python-version: ${{ matrix.python-version }}\n+ - name: Install dependencies\n+ run: |\n+ python -m pip install --upgrade pip\n+ pip install .[match-py-ver] --no-cache-dir\n+ - name: Test example with pytest\n+ run: |\n+ jina check\n+ export JINA_LOG_VERBOSITY=\"ERROR\"\n+ pip install .[test]\n+ git clone https://github.com/jina-ai/examples.git\n+ pytest --force-flaky --min-passes 1 -n 1 --timeout=0 -v examples\n+ timeout-minutes: 60\n+ env:\n+ JINAHUB_USERNAME: ${{ secrets.JINAHUB_USERNAME }}\n+ JINAHUB_PASSWORD: ${{ secrets.JINAHUB_PASSWORD }}\n\\ No newline at end of file\n",
        "chatgpt_cot": "Increase timeout for radon job to 10 minutes and update python version to 3.10 in codecoverage.yml workflow file."
    },
    {
        "org_diff": "diff --git a/docs_generate/conf.py b/docs_generate/conf.py @@ -26,7 +26,11 @@ author = \"tweakimp, BurnySc2\"\n# Add any Sphinx extension module names here, as strings. They can be\n# extensions coming with Sphinx (named 'sphinx.ext.*') or your custom\n# ones.\n-extensions = [\"sphinx.ext.autodoc\", \"sphinx_autodoc_typehints\"]\n+extensions = [\n+ \"sphinx.ext.autodoc\",\n+ \"sphinx_autodoc_typehints\",\n+ \"sphinx_rtd_theme\",\n+]\n# Add any paths that contain templates here, relative to this directory.\ntemplates_path = [\"_templates\"]\n",
        "org_msg": "Add sphinx_rtd_theme to sphinx extensions",
        "sim_msg": "stop using deprecated pngmath",
        "sim_diff": "diff --git a/web/conf.py b/web/conf.py @@ -27,7 +27,7 @@ sys.path.insert(0, os.path.abspath('..'))\n# Add any Sphinx extension module names here, as strings. They can be extensions\n# coming with Sphinx (named 'sphinx.ext.*') or your custom ones.\n-extensions = ['sphinx.ext.autodoc', 'sphinx.ext.coverage', 'sphinx.ext.pngmath',\n+extensions = ['sphinx.ext.autodoc', 'sphinx.ext.coverage', 'sphinx.ext.imgmath',\n'sphinx.ext.viewcode',]\n# Add any paths that contain templates here, relative to this directory.\n",
        "chatgpt_cot": "Add Sphinx RTD theme extension to improve documentation appearance in conf.py."
    },
    {
        "org_diff": "diff --git a/sc2/bot_ai.py b/sc2/bot_ai.py @@ -1678,6 +1678,7 @@ class BotAI(DistanceCalculation):\nself._total_time_in_on_step += step_duration\nself._total_steps_iterations += 1\n# Commit and clear bot actions\n+ if self.actions:\nawait self._do_actions(self.actions)\nself.actions.clear()\n# Clear set of unit tags that were given an order this frame by self.do()\n",
        "org_msg": "Don't do actions if list of actions is empty",
        "sim_msg": "made it a more reasonable number of close to 40fps",
        "sim_diff": "diff --git a/bot_manager.py b/bot_manager.py @@ -205,8 +205,8 @@ class BotManager:\nafter = datetime.now()\nafter2 = time.time()\n- # cant ever drop below 50 frames\n- if after2 - before2 > 0.02:\n+ # cant ever drop below 40 frames\n+ if after2 - before2 > 0.025:\nprint('Too slow for ' + self.name + ': ' + str(after2 - before2) +\n' frames since slowdown ' + str(counter))\ncounter = 0\n",
        "chatgpt_cot": "\"Add action execution in bot_ai.py to clear bot actions after execution\""
    },
    {
        "org_diff": "diff --git a/sc2/main.py b/sc2/main.py @@ -53,7 +53,7 @@ async def _play_game_ai(client, player_id, ai, realtime, step_time_limit, game_t\nlogger.debug(f\"Running AI step, realtime={realtime}\")\ntry:\n- ai.issue_events()\n+ await ai.issue_events()\nif realtime:\nawait ai.on_step(iteration)\nelse:\n",
        "org_msg": "Add missing await statement on issue_events",
        "sim_msg": "Forgot to update iNumPlayers",
        "sim_diff": "diff --git a/v3/runner.py b/v3/runner.py @@ -63,6 +63,8 @@ if __name__ == '__main__':\ncallbacks = []\nname_dict = dict()\n+ gameInputPacket.iNumPlayers = num_bots\n+\n# Set configuration values for bots and store name and team\nfor i in range(num_bots):\nbot_config = configparser.RawConfigParser()\n",
        "chatgpt_cot": "\"Fix asynchronous issue in AI event handling by changing 'ai.issue_events()' to 'await ai.issue_events()' for proper execution flow.\""
    },
    {
        "org_diff": "diff --git a/examples/zerg/onebase_broodlord.py b/examples/zerg/onebase_broodlord.py @@ -25,7 +25,7 @@ class BroodlordBot(sc2.BotAI):\nfor unit in forces:\nself.do(unit.attack(self.select_target()))\n- if self.supply_left < 2:11\n+ if self.supply_left < 2:\nif self.can_afford(OVERLORD) and larvae.exists:\nself.do(larvae.random.train(OVERLORD))\nreturn\n",
        "org_msg": "Fix broodlord example accidental typo",
        "sim_msg": "dont use tuples",
        "sim_diff": "diff --git a/baron/baron.py b/baron/baron.py @@ -465,11 +465,11 @@ class Baron(commands.Cog):\ntry:\nguild_data = data[str(guild.id)]\nexcept KeyError:\n- guilds.append((guild, 0))\n+ guilds.append(guild)\nelse:\ntotal_commands = sum(guild_data.values())\nif total_commands < commands:\n- guilds.append((guild, total_commands))\n+ guilds.append(guild)\nif not guilds:\nawait ctx.send(f\"There are no servers with a command usage count less than {commands}.\")\nawait self.leave_guilds(\n",
        "chatgpt_cot": "fix if condition to resolve supply issue in BroodlordBot."
    },
    {
        "org_diff": "diff --git a/sc2/sc2process.py b/sc2/sc2process.py import asyncio\n+import os\nimport os.path\nimport shutil\nimport signal\n@@ -56,7 +57,7 @@ class SC2Process:\ndef __init__(\nself,\n- host: str = \"127.0.0.1\",\n+ host: Optional[str] = None,\nport: Optional[int] = None,\nfullscreen: bool = False,\nresolution: Optional[Union[List[int], Tuple[int, int]]] = None,\n@@ -66,7 +67,7 @@ class SC2Process:\nbase_build: str = None,\ndata_hash: str = None,\n) -> None:\n- assert isinstance(host, str)\n+ assert isinstance(host, str) or host is None\nassert isinstance(port, int) or port is None\nself._render = render\n@@ -78,7 +79,10 @@ class SC2Process:\nif placement and len(placement) == 2:\nself._arguments[\"-windowx\"] = str(placement[0])\nself._arguments[\"-windowy\"] = str(placement[1])\n- self._host = host\n+\n+ self._host = host or os.environ.get(\"SC2CLIENTHOST\", \"127.0.0.1\")\n+ self._serverhost = os.environ.get(\"SC2SERVERHOST\", self._host)\n+\nif port is None:\nself._port = portpicker.pick_unused_port()\nelse:\n@@ -145,7 +149,7 @@ class SC2Process:\nargs = paths.get_runner_args(Paths.CWD) + [\nexecutable,\n\"-listen\",\n- self._host,\n+ self._serverhost,\n\"-port\",\nstr(self._port),\n\"-dataDir\",\n",
        "org_msg": "[WSL-SUPPORT] Allow env config of SC2Process ports\nAdds a new self._serverhost variable to allow client/server hosts to\ndiffer, and allows client/server hosts to be specified by environment\nvariables.",
        "sim_msg": "define arg types",
        "sim_diff": "diff --git a/scripts/dht_node.py b/scripts/dht_node.py @@ -32,7 +32,7 @@ async def main(host: str, port: int):\nif __name__ == '__main__':\nparser = argparse.ArgumentParser(\ndescription=\"Starts a single DHT node, which then can be used as a seed node or just a contributing node.\")\n- parser.add_argument(\"--host\", default='0.0.0.0', help=\"Host to listen for requests. Default: 0.0.0.0\")\n- parser.add_argument(\"--port\", default=4444, help=\"Port to listen for requests. Default: 4444\")\n+ parser.add_argument(\"--host\", default='0.0.0.0', type=str, help=\"Host to listen for requests. Default: 0.0.0.0\")\n+ parser.add_argument(\"--port\", default=4444, type=int, help=\"Port to listen for requests. Default: 4444\")\nargs = parser.parse_args()\nasyncio.run(main(args.host, args.port))\n",
        "chatgpt_cot": "Fix compilation issue by modifying the host parameter to be optional and setting default values using environment variables for SC2CLIENTHOST and SC2SERVERHOST."
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/master_view_proxy.py b/node_manager_fkie/src/node_manager_fkie/master_view_proxy.py @@ -2435,6 +2435,7 @@ class MasterViewProxy(QWidget):\ntry:\nselectedNodes = self.nodesFromIndexes(self.masterTab.nodeTreeView.selectionModel().selectedIndexes())\nfor node in selectedNodes:\n+ if not self._is_in_ignore_list(node.name):\nself._progress_queue.add2queue(utf8(uuid.uuid4()),\n\"kill screen of %s\" % node.name,\nnm.screen().kill_screens,\n",
        "org_msg": "node_manager_fkie: do not kill node_manager_daemon on kill all screens",
        "sim_msg": "Fix proxy connection: pickling changes broke it.",
        "sim_diff": "diff --git a/mitogen/master.py b/mitogen/master.py @@ -715,15 +715,38 @@ class Context(mitogen.core.Context):\nreturn self.call_with_deadline(None, False, fn, *args, **kwargs)\n-def _proxy_connect(mitogen, name, context_id, klass, kwargs):\n- if not isinstance(mitogen.router, Router): # TODO\n- mitogen.router.__class__ = Router # TODO\n+\n+def _local_method():\n+ return Stream\n+\n+def _ssh_method():\n+ import mitogen.ssh\n+ return mitogen.ssh.Stream\n+\n+def _sudo_method():\n+ import mitogen.sudo\n+ return mitogen.sudo.Stream\n+\n+\n+METHOD_NAMES = {\n+ 'local': _local_method,\n+ 'ssh': _ssh_method,\n+ 'sudo': _sudo_method,\n+}\n+\n+\n+def upgrade_router(econtext):\n+ if not isinstance(econtext.router, Router): # TODO\n+ econtext.router.__class__ = Router # TODO\nLOG.debug('_proxy_connect(): constructing ModuleForwarder')\n- ModuleForwarder(mitogen.router, mitogen.parent, mitogen.importer)\n+ ModuleForwarder(econtext.router, econtext.parent, econtext.importer)\n+\n- context = mitogen.router._connect(\n+def _proxy_connect(econtext, name, context_id, method_name, kwargs):\n+ upgrade_router(econtext)\n+ context = econtext.router._connect(\ncontext_id,\n- klass,\n+ METHOD_NAMES[method_name](),\nname=name,\n**kwargs\n)\n@@ -759,15 +782,13 @@ class Router(mitogen.core.Router):\nreturn self._context_by_id.get(context_id)\ndef local(self, **kwargs):\n- return self.connect(Stream, **kwargs)\n+ return self.connect('local', **kwargs)\ndef sudo(self, **kwargs):\n- import mitogen.sudo\n- return self.connect(mitogen.sudo.Stream, **kwargs)\n+ return self.connect('sudo', **kwargs)\ndef ssh(self, **kwargs):\n- import mitogen.ssh\n- return self.connect(mitogen.ssh.Stream, **kwargs)\n+ return self.connect('ssh', **kwargs)\ndef _connect(self, context_id, klass, name=None, **kwargs):\ncontext = Context(self, context_id)\n@@ -779,22 +800,22 @@ class Router(mitogen.core.Router):\nself.register(context, stream)\nreturn context\n- def connect(self, klass, name=None, **kwargs):\n+ def connect(self, method_name, name=None, **kwargs):\n+ klass = METHOD_NAMES[method_name]()\nkwargs.setdefault('debug', self.debug)\nvia = kwargs.pop('via', None)\nif via is not None:\n- return self.proxy_connect(via, klass, name=name, **kwargs)\n-\n+ return self.proxy_connect(via, method_name, name=name, **kwargs)\ncontext_id = self.context_id_counter.next()\nreturn self._connect(context_id, klass, name=name, **kwargs)\n- def proxy_connect(self, via_context, klass, name=None, **kwargs):\n+ def proxy_connect(self, via_context, method_name, name=None, **kwargs):\ncontext_id = self.context_id_counter.next()\n# Must be added prior to _proxy_connect() to avoid a race.\nself.add_route(context_id, via_context.context_id)\nname = via_context.call_with_deadline(None, True,\n- _proxy_connect, name, context_id, klass, kwargs\n+ _proxy_connect, name, context_id, method_name, kwargs\n)\n# name = '%s.%s' % (via_context.name, name)\ncontext = Context(self, context_id, name=name)\n",
        "chatgpt_cot": "Add conditional check to ignore list in MasterViewProxy to prevent killing screens of nodes in ignore list."
    },
    {
        "org_diff": "diff --git a/fkie_node_manager/src/fkie_node_manager/message_frame.py b/fkie_node_manager/src/fkie_node_manager/message_frame.py @@ -141,7 +141,7 @@ class MessageFrame(QFrame):\n7: QPixmap(\":/icons/crystal_clear_binary.png\").scaled(self.ICON_SIZE, self.ICON_SIZE, Qt.IgnoreAspectRatio, Qt.SmoothTransformation),\n8: QPixmap(\":/icons/crystal_clear_no_io.png\").scaled(self.ICON_SIZE, self.ICON_SIZE, Qt.IgnoreAspectRatio, Qt.SmoothTransformation),\n9: QPixmap(\":/icons/crystal_clear_run_zeroconf.png\").scaled(self.ICON_SIZE, self.ICON_SIZE, Qt.IgnoreAspectRatio, Qt.SmoothTransformation),\n- 10: QPixmap(\":/icons/crystal_clear_binary.png\").scaled(self.ICON_SIZE, self.ICON_SIZE, Qt.IgnoreAspectRatio, Qt.SmoothTransformation)\n+ 10: QPixmap(\":/icons/sekkyumu_restart.png\").scaled(self.ICON_SIZE, self.ICON_SIZE, Qt.IgnoreAspectRatio, Qt.SmoothTransformation)\n}\nself._new_request = False\nself.frameui = QFrame()\n",
        "org_msg": "fkie_node_manager: changed restart icon in question frame",
        "sim_msg": "move calls to child_widgets_created",
        "sim_diff": "diff --git a/widgets/frame/frame.py b/widgets/frame/frame.py @@ -92,6 +92,8 @@ class EditFrame(BitmapMixin, TopLevelBase, EditStylesMixin):\nself.widget.SetSize((400, 300))\nif wx.Platform == '__WXMSW__':\nself.widget.CenterOnScreen()\n+\n+ def child_widgets_created(self, level):\nif self.check_prop_truth(\"menubar\") and self._menubar.widget: self.widget.SetMenuBar(self._menubar.widget)\nif self.check_prop_truth(\"statusbar\") and self._statusbar.widget: self.widget.SetStatusBar(self._statusbar.widget)\nif self.check_prop_truth(\"toolbar\") and self._toolbar.widget: self.widget.SetToolBar(self._toolbar.widget)\n",
        "chatgpt_cot": "change icon for restart button in MessageFrame class."
    },
    {
        "org_diff": "diff --git a/.travis.yml b/.travis.yml @@ -6,7 +6,7 @@ env:\n- ROS_DISTRO=\"kinetic\"\n- ROS_DISTRO=\"melodic\"\ninstall:\n- - git clone --quiet --depth 1 https://github.com/ros-industrial/industrial_ci.git .industrial_ci -b master\n+ - git clone --quiet --depth 1 https://github.com/ros-industrial/industrial_ci.git .ci_config -b legacy\nscript:\n- - .industrial_ci/travis.sh\n+ - .ci_config/travis.sh\n",
        "org_msg": "change industrial_ci branch to legacy",
        "sim_msg": "Switch off useless versions of OSX from CI.",
        "sim_diff": "diff --git a/.travis.yml b/.travis.yml @@ -20,12 +20,26 @@ install:\n- sudo apt-get update\n- chmod u+x ci/travis-ci.sh\n-script:\n- - ./ci/travis-ci.sh\n-\nenv:\n- CI_JOB=BUILD_CCORE\n- CI_JOB=UT_CCORE\n- CI_JOB=VALGRIND_CCORE\n- CI_JOB=UT_PYCLUSTERING\n- CI_JOB=DOCUMENTATION\n+\n+matrix:\n+ exclude:\n+ - os: osx\n+ env: CI_JOB=UT_CCORE\n+\n+ - os: osx\n+ env: CI_JOB=VALGRIND_CCORE\n+\n+ - os: osx\n+ env: CI_JOB=UT_PYCLUSTERING\n+\n+ - os: osx\n+ env: CI_JOB=DOCUMENTATION\n+\n+script:\n+ - ./ci/travis-ci.sh\n\\ No newline at end of file\n",
        "chatgpt_cot": "Update Travis CI configuration to use new directory for industrial_ci setup."
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/master_view_proxy.py b/node_manager_fkie/src/node_manager_fkie/master_view_proxy.py @@ -342,10 +342,10 @@ class MasterViewProxy(QWidget):\nself._shortcut_stop = QShortcut(QKeySequence(self.tr(\"Alt+S\", \"stop selected nodes\")), self)\nself._shortcut_stop.activated.connect(self.on_stop_clicked)\n- self._shortcut_copy = QShortcut(QKeySequence(self.tr(\"Ctrl+C\", \"copy selected values to clipboard\")), self)\n- self._shortcut_copy.activated.connect(self.on_copy_c_pressed)\n- self._shortcut_copy = QShortcut(QKeySequence(self.tr(\"Ctrl+X\", \"copy selected alternative values to clipboard\")), self)\n- self._shortcut_copy.activated.connect(self.on_copy_x_pressed)\n+# self._shortcut_copy = QShortcut(QKeySequence(self.tr(\"Ctrl+C\", \"copy selected values to clipboard\")), self)\n+# self._shortcut_copy.activated.connect(self.on_copy_c_pressed)\n+# self._shortcut_copy = QShortcut(QKeySequence(self.tr(\"Ctrl+X\", \"copy selected alternative values to clipboard\")), self)\n+# self._shortcut_copy.activated.connect(self.on_copy_x_pressed)\n# print \"================ create\", self.objectName()\n#\n",
        "org_msg": "node_manager_fkie: removed handling for Ctrl+C and Ctrl+X, so this shortcut now works in description dock",
        "sim_msg": "fixed menu error",
        "sim_diff": "diff --git a/qualcoder/edit_textfile.py b/qualcoder/edit_textfile.py @@ -442,7 +442,7 @@ class DialogEditTextFile(QtWidgets.QDialog):\nmenu.setStyleSheet(\"QMenu {font-size:\" + str(self.app.settings['fontsize']) + \"pt} \")\naction_select_all = menu.addAction(_(\"Select all\"))\naction_copy = menu.addAction(_(\"Copy\"))\n- action = menu.exec_(self.ui.textEdit.mapToGlobal(position))\n+ action = menu.exec(self.ui.textEdit.mapToGlobal(position))\nif action == action_copy:\nselected_text = self.ui.textEdit.textCursor().selectedText()\ncb = QtWidgets.QApplication.clipboard()\n",
        "chatgpt_cot": "Fix duplicate shortcut assignment in MasterViewProxy to avoid conflicts and improve functionality for copying values to clipboard."
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/supervised_popen.py b/node_manager_fkie/src/node_manager_fkie/supervised_popen.py @@ -74,6 +74,7 @@ class SupervisedPopen(QObject, subprocess.Popen):\nstartupinfo=startupinfo, creationflags=creationflags)\nexcept:\ntry:\n+ print \"ARGS\", \"args=\", args, \"bufsize=\", bufsize, \"executable=\", executable, \"stdin=\", stdin, \"stdout=\", stdout, \"stderr=\", stderr, \"preexec_fn=\", preexec_fn, \"close_fds=\", close_fds, \"shell=\", shell, \"cwd=\", cwd, \"env=\", env, \"universal_newlines=\", universal_newlines, \"startupinfo=\", startupinfo, \"creationflags=\", creationflags\nsubprocess.Popen.__init__(self, args=args, bufsize=bufsize, executable=executable, stdin=stdin, stdout=stdout,\nstderr=stderr, preexec_fn=preexec_fn, close_fds=close_fds, shell=shell, cwd=cwd, env=env,\nuniversal_newlines=universal_newlines, startupinfo=startupinfo, creationflags=creationflags)\n",
        "org_msg": "added println while searching for popen error",
        "sim_msg": "Capture what output we can from in-process runs\nThis enables the use of contains and excludes.",
        "sim_diff": "diff --git a/plugin_tests/cli_results_test.py b/plugin_tests/cli_results_test.py @@ -78,10 +78,6 @@ class CliResultsTest(unittest.TestCase):\n\"\"\"\nchunkSize = 256 * 1024\n- if in_process and (contains or excludes):\n- raise ValueError(\"contains and excludes parameters may only be used\"\n- \" if in_process is False.\")\n-\ncwd = os.environ.get('CLI_CWD')\ntmppath = tempfile.mkdtemp()\ntry:\n@@ -90,11 +86,13 @@ class CliResultsTest(unittest.TestCase):\ncmd += ['--%s=%s' % (\nk, v if not v.startswith('tmp_') else os.path.join(tmppath, v))\nfor k, v in six.iteritems(cli_kwargs)]\n+ stdout = stderr = ''\nif in_process:\n- stdout = None\ntry:\nold_sys_argv = sys.argv[:]\n+ old_stdout, old_stderr = sys.stdout, sys.stderr\nsys.argv[:] = cmd\n+ sys.stdout, sys.stderr = six.StringIO(), six.StringIO()\nrunpy.run_path(\nos.path.join(cwd, cli_args[0], cli_args[0] + '.py'),\nrun_name='__main__',\n@@ -102,9 +100,10 @@ class CliResultsTest(unittest.TestCase):\nexcept SystemExit as e:\nself.assertIn(e.code, {0, None})\nfinally:\n+ stdout, stderr = sys.stdout.getvalue(), sys.stderr.getvalue()\nsys.argv[:] = old_sys_argv\n+ sys.stdout, sys.stderr = old_stdout, old_stderr\nelse:\n- stdout = ''\nprocess = subprocess.Popen(\n['python', os.environ['CLI_LIST_ENTRYPOINT']] + cmd,\nshell=False, stdout=subprocess.PIPE, cwd=cwd,\n",
        "chatgpt_cot": "Add print statement for debugging in SupervisedPopen initialization to display all arguments."
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/main_window.py b/node_manager_fkie/src/node_manager_fkie/main_window.py @@ -410,8 +410,9 @@ class MainWindow(QMainWindow):\ndef closeEvent(self, event):\n# ask to close nodes on exit\nif self._close_on_exit and nm.settings().confirm_exit_when_closing:\n+ masters = [uri for uri, m in self.masters.items() if m.online]\nres = SelectDialog.getValue('Stop nodes?', \"Select masters where to stop:\",\n- self.masters.keys(), False, False, '', self,\n+ masters, False, False, '', self,\nselect_if_single=False,\ncheckitem1=\"don't show this dialog again\")\nmasters2stop, self._close_on_exit = res[0], res[1]\n",
        "org_msg": "node_manager_fkie: fixed the list of closing hosts",
        "sim_msg": "rqda menu import option",
        "sim_diff": "diff --git a/qualcoder/GUI/ui_main.py b/qualcoder/GUI/ui_main.py @@ -111,6 +111,8 @@ class Ui_MainWindow(object):\nself.actionREFI_QDA_Project_import.setObjectName(\"actionREFI_QDA_Project_import\")\nself.actionView_Graph_2 = QtWidgets.QAction(MainWindow)\nself.actionView_Graph_2.setObjectName(\"actionView_Graph_2\")\n+ self.actionRQDA_Project_import = QtWidgets.QAction(MainWindow)\n+ self.actionRQDA_Project_import.setObjectName(\"actionRQDA_Project_import\")\nself.menuProject.addAction(self.actionCreate_New_Project)\nself.menuProject.addAction(self.actionOpen_Project)\nself.menuProject.addAction(self.actionClose_Project)\n@@ -121,6 +123,7 @@ class Ui_MainWindow(object):\nself.menuProject.addAction(self.actionProject_Exchange_Export)\nself.menuProject.addAction(self.actionREFI_Codebook_import)\nself.menuProject.addAction(self.actionREFI_QDA_Project_import)\n+ self.menuProject.addAction(self.actionRQDA_Project_import)\nself.menuProject.addSeparator()\nself.menuProject.addAction(self.actionExit)\nself.menuFiles_and_Cases.addAction(self.actionManage_files)\n@@ -196,6 +199,7 @@ class Ui_MainWindow(object):\nself.actionREFI_Codebook_import.setText(_translate(\"MainWindow\", \"REFI-QDA Codebook import\"))\nself.actionREFI_QDA_Project_import.setText(_translate(\"MainWindow\", \"REFI-QDA Project import\"))\nself.actionView_Graph_2.setText(_translate(\"MainWindow\", \"View Graph 2\"))\n+ self.actionRQDA_Project_import.setText(_translate(\"MainWindow\", \"RQDA Project import\"))\nif __name__ == \"__main__\":\n",
        "chatgpt_cot": "\"Add functionality to stop nodes on exit based on online masters, improving user experience and ensuring proper node shutdown.\""
    },
    {
        "org_diff": "diff --git a/sc2/observer_ai.py b/sc2/observer_ai.py @@ -330,18 +330,16 @@ class ObserverAI(DistanceCalculation):\nawait self.on_building_construction_complete(structure)\nasync def _issue_unit_dead_events(self):\n- for unit_tag in self.state.dead_units:\n- dead_unit: Optional[Unit] = self._all_units_previous_map.get(unit_tag, None)\n- if dead_unit:\n- await self.on_unit_destroyed(dead_unit)\n+ for unit_tag in self.state.dead_units & set(self._all_units_previous_map.keys()):\n+ await self.on_unit_destroyed(unit_tag)\n- async def on_unit_destroyed(self, unit: Unit):\n+ async def on_unit_destroyed(self, unit_tag: int):\n\"\"\"\nOverride this in your bot class.\nThis will event will be called when a unit (or structure, friendly or enemy) dies.\nFor enemy units, this only works if the enemy unit was in vision on death.\n- :param unit:\n+ :param unit_tag:\n\"\"\"\nasync def on_unit_created(self, unit: Unit):\n",
        "org_msg": "Change back observer_ai.py",
        "sim_msg": "Fix wrong method signature",
        "sim_diff": "diff --git a/rx/core/observerbase.py b/rx/core/observerbase.py @@ -44,7 +44,7 @@ class ObserverBase(Observer, Disposable):\nself._on_completed_core()\n@abstractmethod\n- def _on_completed_core(self, value):\n+ def _on_completed_core(self):\nreturn NotImplemented\ndef dispose(self):\n",
        "chatgpt_cot": "\"Refactor on_unit_destroyed method to take unit_tag as parameter, optimize dead unit event handling, and update documentation for on_unit_created method in ObserverAI class.\""
    },
    {
        "org_diff": "diff --git a/fkie_node_manager/src/fkie_node_manager/main_window.py b/fkie_node_manager/src/fkie_node_manager/main_window.py @@ -514,13 +514,13 @@ class MainWindow(QMainWindow):\nself.masternameLabel.setText('<span style=\" font-size:14pt; font-weight:600;\">%s ...closing...</span>' % self.masternameLabel.text())\nrospy.loginfo(\"Wait for running processes are finished...\")\nevent.ignore()\n- if event.isAccepted():\n- self.on_finish = True\n- self.master_timecheck_timer.stop()\ntry:\nself.storeSetting()\nexcept Exception as e:\nrospy.logwarn(\"Error while store settings: %s\" % e)\n+ if event.isAccepted():\n+ self.on_finish = True\n+ self.master_timecheck_timer.stop()\nself.finish()\nQMainWindow.closeEvent(self, event)\n",
        "org_msg": "fkie_node_manager: fixed save gui setting on exit if stop master was selected",
        "sim_msg": "added more frame slowdown info",
        "sim_diff": "diff --git a/bot_manager.py b/bot_manager.py @@ -68,6 +68,7 @@ class BotManager:\nself.game_file = open(filename.replace(\" \", \"\"), 'wb')\nold_time = 0\ncurrent_time = -10\n+ counter = 0\n# Run until main process tells to stop\nwhile not self.terminateEvent.is_set():\n@@ -109,7 +110,11 @@ class BotManager:\nafter = datetime.now()\nafter2 = time.time()\nif after2 - before2 > 0.03:\n- print('Too slow for ' + self.name + ': ' + str(after2 - before2))\n+ print('Too slow for ' + self.name + ': ' + str(after2 - before2) +\n+ ' frames since slowdown ' + str(counter))\n+ counter = 0\n+ else:\n+ counter += 1\n#print('Latency of ' + self.name + ': ' + str(after2 - before2))\nr.acquire(after-before)\n",
        "chatgpt_cot": "Fix issue with the handling of event acceptance in MainWindow closeEvent method. Stop timer and set flag on event acceptance."
    },
    {
        "org_diff": "diff --git a/fkie_node_manager/src/fkie_node_manager/master_view_proxy.py b/fkie_node_manager/src/fkie_node_manager/master_view_proxy.py @@ -1875,7 +1875,12 @@ class MasterViewProxy(QWidget):\nraise nm.InteractionNeededError(bsr, self.start_node, (node, force, config, force_host, logging, '', cmd_prefix))\nexcept (exceptions.StartException, nm.StartException) as e:\nrospy.logwarn(\"Error while start '%s': %s\" % (node.name, utf8(e)))\n- raise DetailedError(\"Start error\", 'Error while start %s' % node.name, '%s' % utf8(e))\n+ lines = utf8(e).splitlines()\n+ last_line = lines[-1]\n+ for line in lines:\n+ if line:\n+ last_line = line\n+ raise DetailedError(\"Start error\", 'Error while start %s:\\n%s' % (node.name, last_line), '%s' % utf8(e))\nexcept Exception as e:\nprint(type(e))\nprint(traceback.format_exc(3))\n",
        "org_msg": "fkie_node_manager: add more information on error while start",
        "sim_msg": "Python 2/3 compatibility\nProcess correctly an error message from compiling a dx app.",
        "sim_diff": "diff --git a/src/python/dxpy/scripts/dx_build_app.py b/src/python/dxpy/scripts/dx_build_app.py @@ -242,6 +242,20 @@ def _check_syntax(code, lang, temp_dir, enforce=True):\n_check_file_syntax(os.path.join(temp_dir, temp_basename), temp_dir, override_lang=lang, enforce=enforce)\n+# convert the error message embedded in the exception to a proper string\n+def _error_message_to_string(e):\n+ if USING_PYTHON2:\n+ return e.msg\n+ else:\n+ if isinstance(e.msg, str):\n+ return e.msg\n+ elif isinstance(e.msg, bytes):\n+ return e.msg.decode(\"utf-8\")\n+ else:\n+ # What kind of object is this?\n+ print(\"The error message is neither string nor bytes, it is {}\".format(type(e.msg)))\n+ raise e\n+\ndef _check_file_syntax(filename, temp_dir, override_lang=None, enforce=True):\n\"\"\"\nChecks that the code in FILENAME parses, attempting to autodetect\n@@ -294,20 +308,14 @@ def _check_file_syntax(filename, temp_dir, override_lang=None, enforce=True):\nchecker_fn(filename)\nexcept subprocess.CalledProcessError as e:\nprint(filename + \" has a syntax error! Interpreter output:\", file=sys.stderr)\n- if USING_PYTHON2:\n- errmsg = e.output\n- else:\n- errmsg = e.output.decode(\"utf-8\")\n+ errmsg = _error_message_to_string(e)\nfor line in errmsg.strip(\"\\n\").split(\"\\n\"):\nprint(\" \" + line.rstrip(\"\\n\"), file=sys.stderr)\nif enforce:\nraise DXSyntaxError(filename + \" has a syntax error\")\nexcept py_compile.PyCompileError as e:\nprint(filename + \" has a syntax error! Interpreter output:\", file=sys.stderr)\n- if USING_PYTHON2:\n- errmsg = e.msg\n- else:\n- errmsg = e.msg.decode(\"utf-8\")\n+ errmsg = _error_message_to_string(e)\nprint(\" \" + errmsg.strip(), file=sys.stderr)\nif enforce:\nraise DXSyntaxError(e.msg.strip())\n",
        "chatgpt_cot": "\"Handle exception in start method to display detailed error message with last line in case of start error.\""
    },
    {
        "org_diff": "diff --git a/build_image/dockerhub/v0.9.0/user-dashboard/Dockerfile b/build_image/dockerhub/v0.9.0/user-dashboard/Dockerfile FROM busybox as builder\nENV FABRIC_VERSION_1_0 1.0.5\nRUN cd /tmp && ARCH=$(echo \"$(uname -s|tr '[:upper:]' '[:lower:]'|sed 's/mingw64_nt.*/windows/')-$(uname -m | sed 's/x86_64/amd64/g')\" | awk '{print tolower($0)}') && \\\n- echo $ARCH &&wget -c https://nexus.hyperledger.org/content/repositories/releases/org/hyperledger/fabric/hyperledger-fabric/${ARCH}-${FABRIC_VERSION_1_0}/hyperledger-fabric-${ARCH}-${FABRIC_VERSION_1_0}.tar.gz && \\\n+ echo $ARCH && wget --no-check-certificate --content-disposition https://github.com/hyperledger/fabric/releases/download/v${FABRIC_VERSION_1_0}/hyperledger-fabric-${ARCH}-${FABRIC_VERSION_1_0}.tar.gz && \\\nmkdir fabric-1.0 && tar -zxvf hyperledger-fabric-${ARCH}-${FABRIC_VERSION_1_0}.tar.gz -C fabric-1.0\nENV FABRIC_VERSION_1_2 1.2.0\nRUN cd /tmp && ARCH=$(echo \"$(uname -s|tr '[:upper:]' '[:lower:]'|sed 's/mingw64_nt.*/windows/')-$(uname -m | sed 's/x86_64/amd64/g')\" | awk '{print tolower($0)}') && \\\n- echo $ARCH &&wget -c https://nexus.hyperledger.org/content/repositories/releases/org/hyperledger/fabric/hyperledger-fabric/${ARCH}-${FABRIC_VERSION_1_2}/hyperledger-fabric-${ARCH}-${FABRIC_VERSION_1_2}.tar.gz && \\\n+ echo $ARCH && wget --no-check-certificate --content-disposition https://github.com/hyperledger/fabric/releases/download/v${FABRIC_VERSION_1_2}/hyperledger-fabric-${ARCH}-${FABRIC_VERSION_1_2}.tar.gz && \\\nmkdir fabric-1.2 && tar -zxvf hyperledger-fabric-${ARCH}-${FABRIC_VERSION_1_2}.tar.gz -C fabric-1.2\nRUN cd /tmp && wget -c https://github.com/hyperledger/cello/archive/v0.9.0.zip && unzip v0.9.0.zip && mv cello-0.9.0 cello\n",
        "org_msg": "update url for downloading fabric artifacts(fix",
        "sim_msg": "adapt signature check",
        "sim_diff": "diff --git a/home.admin/config.scripts/bonus.chantools.sh b/home.admin/config.scripts/bonus.chantools.sh @@ -85,7 +85,7 @@ if [ \"$1\" = \"1\" ] || [ \"$1\" = \"on\" ]; then\nsudo -u admin wget -N https://github.com/guggero/chantools/releases/download/v${pinnedVersion}/${binaryName}\n# check binary was not manipulated (checksum test)\n- sudo -u admin wget -N https://github.com/guggero/chantools/releases/download/v${pinnedVersion}/manifest-v${pinnedVersion}.txt.asc\n+ sudo -u admin wget -N https://github.com/guggero/chantools/releases/download/v${pinnedVersion}/manifest-v${pinnedVersion}.txt.sig\nsudo -u admin wget --no-check-certificate -N -O \"${downloadDir}/pgp_keys.asc\" ${PGPpkeys}\nbinaryChecksum=$(sha256sum ${binaryName} | cut -d \" \" -f1)\nif [ \"${binaryChecksum}\" != \"${SHA256}\" ]; then\n@@ -105,8 +105,8 @@ if [ \"$1\" = \"1\" ] || [ \"$1\" = \"on\" ]; then\nfi\ngpg --import ./pgp_keys.asc\nsleep 3\n- echo \"# running: gpg --verify manifest-v${pinnedVersion}.txt.asc\"\n- verifyResult=$(gpg --verify manifest-v${pinnedVersion}.txt.asc 2>&1)\n+ echo \"# running: gpg --verify manifest-v${pinnedVersion}.txt.sig\"\n+ verifyResult=$(gpg --verify manifest-v${pinnedVersion}.txt.sig 2>&1)\necho \"# verifyResult(${verifyResult})\"\ngoodSignature=$(echo ${verifyResult} | grep 'Good signature' -c)\necho \"# goodSignature(${goodSignature})\"\n",
        "chatgpt_cot": "Update Dockerfile to download Hyperledger Fabric from GitHub releases to fix download issue and improve reliability."
    },
    {
        "org_diff": "diff --git a/node_manager_daemon_fkie/src/node_manager_daemon_fkie/common.py b/node_manager_daemon_fkie/src/node_manager_daemon_fkie/common.py @@ -241,8 +241,11 @@ def included_files(string,\nrecursive_list = res_list\nelse:\nresult += res_list\n+ elif os.path.isdir(file_name):\n+ file_name = ''\nexcept Exception as e:\nrospy.logwarn(utf8(e))\n+ if file_name:\nif not unique:\n# transform found position to line number\nresult.append((content.count(\"\\n\", 0, groups.start()) + 1, file_name, recursive_list))\n",
        "org_msg": "node_manager_daemon_fkie: ignore directories on read include files",
        "sim_msg": "stupid backslashes in file paths",
        "sim_diff": "diff --git a/source1/content_manager.py b/source1/content_manager.py @@ -58,7 +58,8 @@ class ContentManager(metaclass=SingletonMeta):\nreturn False, path\ndef find_file(self, filepath: str, additional_dir=None, extension=None):\n- new_filepath = Path(filepath)\n+\n+ new_filepath = Path(str(filepath).strip('/\\\\').rstrip('/\\\\'))\nif additional_dir:\nnew_filepath = Path(additional_dir, new_filepath)\nif extension:\n",
        "chatgpt_cot": "Add handling for directory file_name, fix logwarn encoding issue, and transform found position to line number in common.py."
    },
    {
        "org_diff": "diff --git a/src/agent/ansible/roles/deploy_k8s/certsetup/templates/configtx.j2 b/src/agent/ansible/roles/deploy_k8s/certsetup/templates/configtx.j2 @@ -50,21 +50,27 @@ Organizations:\n{% if project_version is version_compare('1.1.0','>=') or 'stable' in project_version or project_version == 'latest' %}\nCapabilities:\nGlobal: &ChannelCapabilities\n-{% if project_version is version_compare('1.4.0','>=') or 'stable' in project_version or project_version == 'latest' %}\n- V1_4: true\n-{% elif project_version is version_compare('1.3.0','>=') and project_version is version_compare('1.4.0','<') %}\n+{% if project_version is version_compare('1.4.3','>=') %}\n+ V1_4_3: true\n+{% elif project_version is version_compare('1.4.2','>=') and project_version is version_compare('1.4.3','<') %}\n+ V1_4_2: true\n+{% elif project_version is version_compare('1.3.0','>=') and project_version is version_compare('1.4.2','<') %}\nV1_3: true\n{% elif project_version is version_compare('1.1.0','>=') and project_version is version_compare('1.3.0','<') %}\nV1_1: true\n{% endif %}\nOrderer: &OrdererCapabilities\n+{% if project_version is version_compare('1.4.2','>=') %}\n+ V1_4_2: true\n+{% else %}\nV1_1: true\n+{% endif %}\nApplication: &ApplicationCapabilities\n-{% if project_version is version_compare('1.4.0','>=') or 'stable' in project_version or project_version == 'latest' %}\n- V1_4: true\n-{% elif project_version is version_compare('1.3.0','>=') and project_version is version_compare('1.4.0','<') %}\n+{% if project_version is version_compare('1.4.2','>=') %}\n+ V1_4_2: true\n+{% elif project_version is version_compare('1.3.0','>=') and project_version is version_compare('1.4.1','<=') %}\nV1_3: true\n{% elif project_version is version_compare('1.2.0','>=') and project_version is version_compare('1.3.0','<') %}\nV1_2: true\n",
        "org_msg": "[#70]Fixed the capability version string",
        "sim_msg": "Ignore legacy versions",
        "sim_diff": "diff --git a/aea/helpers/pypi_checker.py b/aea/helpers/pypi_checker.py @@ -24,7 +24,7 @@ from collections import defaultdict\nfrom typing import Dict, Set, cast\nfrom packaging.specifiers import Specifier, SpecifierSet\n-from packaging.version import parse\n+from packaging.version import InvalidVersion, Version\ndef and_(s1: SpecifierSet, s2: SpecifierSet):\n@@ -73,14 +73,26 @@ def _is_satisfiable(specifier_set: SpecifierSet) -> bool:\n>>> _is_satisfiable(SpecifierSet(\"<=1.0,>1.0\"))\nFalse\n+ We ignore legacy versions:\n+\n+ >>> _is_satisfiable(SpecifierSet(\"==1.0,==1.*\"))\n+ True\n+\n:param specifier_set: the specifier set.\n:return: False if the constraints are surely non-satisfiable, True if we don't know.\n\"\"\"\n# group single specifiers by operator\n- all_specifiers = list(specifier_set)\n+ all_specifiers = []\noperator_to_specifiers: Dict[str, Set[Specifier]] = defaultdict(lambda: set())\n- for specifier in all_specifiers:\n+ for specifier in list(specifier_set):\nspecifier = cast(Specifier, specifier)\n+ try:\n+ # if we can't parse the version number, ignore that specifier.\n+ # Even if it follows a legacy version format (e.g. \"2.*\")\n+ Version(specifier.version)\n+ except InvalidVersion:\n+ continue\n+ all_specifiers.append(specifier)\noperator_to_specifiers[specifier.operator].add(specifier)\n# if there are two different \"==\" specifier, return False\n@@ -98,7 +110,7 @@ def _is_satisfiable(specifier_set: SpecifierSet) -> bool:\nless_than_strict_specs = operator_to_specifiers[\"<\"]\nless_than_equal_specs = operator_to_specifiers[\"<=\"]\nless_than_specs = set.union(less_than_equal_specs, less_than_strict_specs)\n- sorted_less_than_specs = sorted(less_than_specs, key=lambda x: parse(x.version))\n+ sorted_less_than_specs = sorted(less_than_specs, key=lambda x: Version(x.version))\nlowest_less_than = (\nsorted_less_than_specs[0] if len(sorted_less_than_specs) > 0 else None\n)\n@@ -109,7 +121,7 @@ def _is_satisfiable(specifier_set: SpecifierSet) -> bool:\ngreater_than_equal_specs = operator_to_specifiers[\">=\"]\ngreater_than_specs = set.union(greater_than_strict_specs, greater_than_equal_specs)\nsorted_greater_than_specs = sorted(\n- greater_than_specs, key=lambda x: parse(x.version)\n+ greater_than_specs, key=lambda x: Version(x.version)\n)\ngreatest_greater_than = (\nsorted_greater_than_specs[-1] if len(sorted_greater_than_specs) > 0 else None\n@@ -148,8 +160,8 @@ def _handle_range_constraints(\n:param greatest_greater_than: the greater than constraint.\n:return: False if we are sure the two constraints are not satisfiable, True if we don't know.\n\"\"\"\n- version_less_than = parse(lowest_less_than.version)\n- version_greater_than = parse(greatest_greater_than.version)\n+ version_less_than = Version(lowest_less_than.version)\n+ version_greater_than = Version(greatest_greater_than.version)\nif version_less_than < version_greater_than:\nreturn False\nelif version_greater_than == version_less_than:\n",
        "chatgpt_cot": "Update capabilities in configtx template based on project version for compatibility with different versions of Hyperledger Fabric."
    },
    {
        "org_diff": "diff --git a/sc2/units.py b/sc2/units.py @@ -20,13 +20,13 @@ class Units(list):\ndef from_proto(cls, units, game_data=None): # game_data=None\nif game_data:\nlogger.info(\"Keyword argument 'game_data' in Units classmethod 'from_proto' is deprecated.\")\n- logger.info(\"You can safely remove it.\")\n+ logger.info(\"You can safely remove it from your Units objects created by the classmethod.\")\nreturn cls((Unit(u) for u in units))\ndef __init__(self, units, game_data=None):\nif game_data:\nlogger.info(\"Keyword argument 'game_data' in Units function '__init__' is deprecated.\")\n- logger.info(\"You can safely remove it.\")\n+ logger.info(\"You can safely remove it from your Units objects initializations.\")\nsuper().__init__(units)\ndef __call__(self, *args, **kwargs):\n",
        "org_msg": "Clarify deprecation notice",
        "sim_msg": "add some comments to Score.from_submission",
        "sim_diff": "diff --git a/objects/score.py b/objects/score.py @@ -262,6 +262,26 @@ class Score:\nasync def from_submission(cls, data: list[str]) -> \"Score\":\n\"\"\"Create a score object from an osu! submission string.\"\"\"\ns = cls()\n+\n+ \"\"\" parse the following format\n+ # 0 online_checksum\n+ # 1 n300\n+ # 2 n100\n+ # 3 n50\n+ # 4 ngeki\n+ # 5 nkatu\n+ # 6 nmiss\n+ # 7 score\n+ # 8 max_combo\n+ # 9 perfect\n+ # 10 grade\n+ # 11 mods\n+ # 12 passed\n+ # 13 gamemode\n+ # 14 play_time # yyMMddHHmmss\n+ # 15 osu_version + (\" \" * client_flags)\n+ \"\"\"\n+\ns.online_checksum = data[0]\ns.n300, s.n100, s.n50, s.ngeki, s.nkatu, s.nmiss, s.score, s.max_combo = map(\n@@ -275,7 +295,10 @@ class Score:\ns.passed = data[12] == \"True\"\ns.mode = GameMode.from_params(int(data[13]), s.mods)\n- s.play_time = datetime.now() # TODO: use data[16]\n+ # TODO: we might want to use data[14] to get more\n+ # accurate submission time (client side) but\n+ # we'd probably want to check if it's close.\n+ s.play_time = datetime.now()\ns.client_flags = ClientFlags(data[15].count(\" \") & ~4)\n",
        "chatgpt_cot": "Refactor Units class to remove deprecated game_data keyword argument in from_proto and __init__ methods for cleaner code initialization."
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/detailed_msg_box.py b/node_manager_fkie/src/node_manager_fkie/detailed_msg_box.py @@ -52,6 +52,7 @@ class WarningMessageBox(QMessageBox):\ndef __init__(self, icon, title, text, detailed_text=\"\", buttons=QMessageBox.Ok):\nQMessageBox.__init__(self, icon, title, text, buttons)\n+ self.textEdit = None\nif detailed_text:\nself.setDetailedText(detailed_text)\nself.textEdit = textEdit = self.findChild(QTextEdit)\n@@ -68,21 +69,25 @@ class WarningMessageBox(QMessageBox):\nself.setEscapeButton(QMessageBox.Abort)\nelif QMessageBox.Ignore & buttons:\nself.setEscapeButton(QMessageBox.Ignore)\n+ elif QMessageBox.Cancel & buttons:\n+ self.setEscapeButton(QMessageBox.Cancel)\nelse:\nself.setEscapeButton(buttons)\nself.ignore_all_btn = QPushButton('Don\\'t display again')\nself.addButton(self.ignore_all_btn, QMessageBox.HelpRole)\nself.setSizePolicy(QSizePolicy.Expanding, QSizePolicy.Expanding)\n+ self.ignore_all_btn.setVisible(False)\ndef paintEvent(self, event):\nQMessageBox.paintEvent(self, event)\n- if self.textEdit is not None and self.textEdit.isVisible():\n+ if self.textEdit is not None:\n+ if self.textEdit.isVisible():\nif not self.ignore_all_btn.isVisible():\nself.ignore_all_btn.setVisible(True)\nself.setSizeGripEnabled(True)\nself.setMaximumHeight(16777215)\nself.setMaximumWidth(16777215)\n- elif self.textEdit is not None and not self.textEdit.isVisible():\n+ elif not self.textEdit.isVisible():\nif self.ignore_all_btn.isVisible():\nself.ignore_all_btn.setVisible(False)\nself.setSizeGripEnabled(False)\n",
        "org_msg": "node_manager_fkie: fixed detailed dialog for messages without detailed text",
        "sim_msg": "default line colour gray. more menu line colour options",
        "sim_diff": "diff --git a/qualcoder/view_graph.py b/qualcoder/view_graph.py @@ -977,7 +977,7 @@ class FreeLineGraphicsItem(QtWidgets.QGraphicsLineItem):\nto_pos = None\nline_width = 2\nline_type = QtCore.Qt.PenStyle.SolidLine\n- line_color = QtCore.Qt.GlobalColor.black\n+ line_color = QtCore.Qt.GlobalColor.gray\ncorners_only = False # True for list graph\nweighting = 1\ntooltip = \"\"\n@@ -993,9 +993,7 @@ class FreeLineGraphicsItem(QtWidgets.QGraphicsLineItem):\nself.remove = False\nself.setFlags(QtWidgets.QGraphicsItem.GraphicsItemFlag.ItemIsSelectable)\nself.calculate_points_and_draw()\n- self.line_color = QtCore.Qt.GlobalColor.black\n- if app.settings['stylesheet'] == \"dark\":\n- self.line_color = QtCore.Qt.GlobalColor.white\n+ self.line_color = QtCore.Qt.GlobalColor.gray\ndef contextMenuEvent(self, event):\nmenu = QtWidgets.QMenu()\n@@ -1006,6 +1004,8 @@ class FreeLineGraphicsItem(QtWidgets.QGraphicsLineItem):\nmenu.addAction(_('Yellow'))\nmenu.addAction(_('Green'))\nmenu.addAction(_('Blue'))\n+ menu.addAction(_('Cyan'))\n+ menu.addAction(_('Magenta'))\nmenu.addAction(_('Remove'))\naction = menu.exec(QtGui.QCursor.pos())\nif action is None:\n@@ -1035,6 +1035,12 @@ class FreeLineGraphicsItem(QtWidgets.QGraphicsLineItem):\nif action.text() == 'Blue':\nself.line_color = QtCore.Qt.GlobalColor.blue\nself.redraw()\n+ if action.text() == 'Cyan':\n+ self.line_color = QtCore.Qt.GlobalColor.cyan\n+ self.redraw()\n+ if action.text() == 'Magenta':\n+ self.line_color = QtCore.Qt.GlobalColor.magenta\n+ self.redraw()\nif action.text() == \"Remove\":\nself.remove = True\n@@ -1222,7 +1228,7 @@ class LinkGraphicsItem(QtWidgets.QGraphicsLineItem):\nto_pos = None\nline_width = 2\nline_type = QtCore.Qt.PenStyle.SolidLine\n- line_color = QtCore.Qt.GlobalColor.black\n+ line_color = QtCore.Qt.GlobalColor.gray\ncorners_only = False # True for list graph\nweighting = 1\ntext = \"\"\n@@ -1237,9 +1243,7 @@ class LinkGraphicsItem(QtWidgets.QGraphicsLineItem):\nself.weighting = weighting\nself.setFlags(QtWidgets.QGraphicsItem.GraphicsItemFlag.ItemIsSelectable)\nself.calculate_points_and_draw()\n- self.line_color = QtCore.Qt.GlobalColor.black\n- if app.settings['stylesheet'] == \"dark\":\n- self.line_color = QtCore.Qt.GlobalColor.white\n+ self.line_color = QtCore.Qt.GlobalColor.gray\ndef contextMenuEvent(self, event):\nmenu = QtWidgets.QMenu()\n@@ -1250,6 +1254,8 @@ class LinkGraphicsItem(QtWidgets.QGraphicsLineItem):\nmenu.addAction(_('Yellow'))\nmenu.addAction(_('Green'))\nmenu.addAction(_('Blue'))\n+ menu.addAction(_('Cyan'))\n+ menu.addAction(_('Magenta'))\nmenu.addAction(_(\"Hide\"))\naction = menu.exec(QtGui.QCursor.pos())\n@@ -1280,6 +1286,12 @@ class LinkGraphicsItem(QtWidgets.QGraphicsLineItem):\nif action.text() == 'Blue':\nself.line_color = QtCore.Qt.GlobalColor.blue\nself.redraw()\n+ if action.text() == 'Cyan':\n+ self.line_color = QtCore.Qt.GlobalColor.cyan\n+ self.redraw()\n+ if action.text() == 'Magenta':\n+ self.line_color = QtCore.Qt.GlobalColor.magenta\n+ self.redraw()\nif action.text() == \"Hide\":\nself.hide()\n",
        "chatgpt_cot": "Fix visibility issue for ignore button in WarningMessageBox. Set button visibility based on textEdit visibility to ensure proper display."
    },
    {
        "org_diff": "diff --git a/fkie_node_manager/src/fkie_node_manager/launch_list_model.py b/fkie_node_manager/src/fkie_node_manager/launch_list_model.py @@ -487,7 +487,7 @@ class LaunchListModel(QStandardItemModel):\nself.pathlist_handled.emit(root_path)\ndef _nmd_error(self, method, url, path, error):\n- if not self.is_current_nmd(url):\n+ if method != 'list_path' or not self.is_current_nmd(url):\nreturn\nroot = self.invisibleRootItem()\nwhile root.rowCount():\n",
        "org_msg": "fkie_node_manager: do not handle not related errors in launch browser",
        "sim_msg": "Added fix for error message",
        "sim_diff": "diff --git a/avalon/tools/projectmanager/model.py b/avalon/tools/projectmanager/model.py @@ -113,7 +113,8 @@ class TreeModel(QtCore.QAbstractItemModel):\nkey = self.COLUMNS[column]\nnode[key] = value\n- self.dataChanged.emit(index, index)\n+ # passing `list()` for PyQt5 (see PYSIDE-462)\n+ self.dataChanged.emit(index, index, list())\n# must return true if successful\nreturn True\n",
        "chatgpt_cot": "Fix the condition to check if the method is 'list_path' in the LaunchListModel to handle the error."
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/test/test_ns_groups.launch b/node_manager_fkie/test/test_ns_groups.launch <?xml version=\"1.0\" encoding=\"utf-8\"?>\n<!-- Test launch file to check namespace-based grouping in node_manager -->\n<launch>\n+ <arg name=\"transformation\" default=\"0 0 0 0 0 0 1 world dummy 1\"/>\n+\n<group ns=\"ground_robot\">\n<group ns=\"lidar\">\n- <node name=\"velodyne_driver\" pkg=\"tf\" type=\"static_transform_publisher\"/>\n+ <node name=\"velodyne_driver\" pkg=\"tf\" type=\"static_transform_publisher\" args=\"$(arg transformation)\"/>\n</group>\n<group ns=\"vision\">\n- <node name=\"rgb_rectifier\" pkg=\"tf\" type=\"static_transform_publisher\"/>\n- <node name=\"nir_rectifier\" pkg=\"tf\" type=\"static_transform_publisher\"/>\n- <node name=\"camera_back_driver\" pkg=\"tf\" type=\"static_transform_publisher\"/>\n+ <node name=\"rgb_rectifier\" pkg=\"tf\" type=\"static_transform_publisher\" args=\"$(arg transformation)\"/>\n+ <node name=\"nir_rectifier\" pkg=\"tf\" type=\"static_transform_publisher\" args=\"$(arg transformation)\"/>\n+ <node name=\"camera_back_driver\" pkg=\"tf\" type=\"static_transform_publisher\" args=\"$(arg transformation)\"/>\n</group>\n</group>\n<group ns=\"aerial_robot\">\n- <node name=\"flight_controller\" pkg=\"tf\" type=\"static_transform_publisher\"/>\n+ <node name=\"flight_controller\" pkg=\"tf\" type=\"static_transform_publisher\" args=\"$(arg transformation)\"/>\n<group ns=\"vision\">\n- <node name=\"camera_1\" pkg=\"tf\" type=\"static_transform_publisher\"/>\n- <node name=\"camera_2\" pkg=\"tf\" type=\"static_transform_publisher\"/>\n+ <node name=\"camera_1\" pkg=\"tf\" type=\"static_transform_publisher\" args=\"$(arg transformation)\"/>\n+ <node name=\"camera_2\" pkg=\"tf\" type=\"static_transform_publisher\" args=\"$(arg transformation)\"/>\n</group>\n</group>\n</launch>\n",
        "org_msg": "Make sure dummy nodes can be started.",
        "sim_msg": "Added torchvision transforms[formatted]",
        "sim_diff": "diff --git a/src/syft/lib/torchvision/allowlist.py b/src/syft/lib/torchvision/allowlist.py @@ -105,3 +105,52 @@ allowlist[\"torchvision.datasets.VOCDetection\"] = \"torchvision.datasets.VOCDetect\nallowlist[\n\"torchvision.datasets.VOCDetection.__len__\"\n] = \"torchvision.datasets.VOCDetection\"\n+\n+allowlist[\"torchvision.transforms.CenterCrop\"] = \"torchvision.transforms.CenterCrop\"\n+allowlist[\"torchvision.transforms.ColorJitter\"] = \"torchvision.transforms.ColorJitter\"\n+allowlist[\"torchvision.transforms.FiveCrop\"] = \"torchvision.transforms.FiveCrop\"\n+allowlist[\"torchvision.transforms.Grayscale\"] = \"torchvision.transforms.Grayscale\"\n+allowlist[\"torchvision.transforms.Pad\"] = \"torchvision.transforms.Pad\"\n+allowlist[\"torchvision.transforms.RandomAffine\"] = \"torchvision.transforms.RandomAffine\"\n+allowlist[\"torchvision.transforms.RandomApply\"] = \"torchvision.transforms.RandomApply\"\n+allowlist[\"torchvision.transforms.RandomCrop\"] = \"torchvision.transforms.RandomCrop\"\n+allowlist[\n+ \"torchvision.transforms.RandomGrayscale\"\n+] = \"torchvision.transforms.RandomGrayscale\"\n+\n+allowlist[\n+ \"torchvision.transforms.RandomHorizontalFlip\"\n+] = \"torchvision.transforms.RandomHorizontalFlip\"\n+allowlist[\n+ \"torchvision.transforms.RandomPerspective\"\n+] = \"torchvision.transforms.RandomPerspective\"\n+allowlist[\n+ \"torchvision.transforms.RandomResizedCrop\"\n+] = \"torchvision.transforms.RandomResizedCrop\"\n+allowlist[\n+ \"torchvision.transforms.RandomRotation\"\n+] = \"torchvision.transforms.RandomRotation\"\n+allowlist[\n+ \"torchvision.transforms.RandomSizedCrop\"\n+] = \"torchvision.transforms.RandomSizedCrop\"\n+allowlist[\n+ \"torchvision.transforms.RandomVerticalFlip\"\n+] = \"torchvision.transforms.RandomVerticalFlip\"\n+allowlist[\"torchvision.transforms.Resize\"] = \"torchvision.transforms.Resize\"\n+allowlist[\"torchvision.transforms.Scale\"] = \"torchvision.transforms.Scale\"\n+allowlist[\"torchvision.transforms.TenCrop\"] = \"torchvision.transforms.TenCrop\"\n+allowlist[\"torchvision.transforms.GaussianBlur\"] = \"torchvision.transforms.GaussianBlur\"\n+allowlist[\"torchvision.transforms.RandomChoice\"] = \"torchvision.transforms.RandomChoice\"\n+allowlist[\"torchvision.transforms.RandomOrder\"] = \"torchvision.transforms.RandomOrder\"\n+allowlist[\n+ \"torchvision.transforms.LinearTransformation\"\n+] = \"torchvision.transforms.LinearTransformation\"\n+allowlist[\"torchvision.transforms.Normalize\"] = \"torchvision.transforms.Normalize\"\n+allowlist[\n+ \"torchvision.transforms.RandomErasing\"\n+] = \"torchvision.transforms.RandomErasing\"\n+allowlist[\n+ \"torchvision.transforms.ConvertImageDtype\"\n+] = \"torchvision.transforms.ConvertImageDtype\"\n+allowlist[\"torchvision.transforms.ToPILImage\"] = \"torchvision.transforms.ToPILImage\"\n+allowlist[\"torchvision.transforms.Lambda\"] = \"torchvision.transforms.Lambda\"\n",
        "chatgpt_cot": "Add transformation argument to static_transform_publisher nodes for namespace-based grouping in node_manager_fkie launch file."
    },
    {
        "org_diff": "diff --git a/bootup/docker-compose-files/docker-compose-dev.yml b/bootup/docker-compose-files/docker-compose-dev.yml @@ -55,7 +55,7 @@ services:\n- \"8080:8080\"\nvolumes:\n- /var/run/:/host/var/run/\n- # - /opt/fabric:/opt/fabric\n+ - /opt/cello:/opt/cello\n# - /etc/localtime:/etc/localtime\nnetworks:\n- cello-net\n",
        "org_msg": "Map api-engine data in docker container to local VM volume",
        "sim_msg": "Update docker-compose redis and nginx images",
        "sim_diff": "diff --git a/docker-compose.yml b/docker-compose.yml @@ -5,7 +5,7 @@ volumes:\nservices:\nnginx:\n- image: nginx:1.17-alpine\n+ image: nginx:1.19-alpine\nhostname: nginx\nports:\n- \"8000:8000\"\n@@ -16,7 +16,7 @@ services:\n- web\nredis:\n- image: redis:5-alpine\n+ image: redis:6-alpine\nports:\n- \"6379:6379\"\n",
        "chatgpt_cot": "Update docker-compose-dev.yml to mount /opt/cello instead of /opt/fabric, improving file structure and organization within the project."
    },
    {
        "org_diff": "diff --git a/sc2/unit.py b/sc2/unit.py @@ -85,7 +85,7 @@ class PassengerUnit:\nreturn self._type_data.cargo_size\n@property_immutable_cache\n- def _weapons(self) -> bool:\n+ def _weapons(self):\nif hasattr(self._type_data._proto, \"weapons\"):\nreturn self._type_data._proto.weapons\nreturn False\n",
        "org_msg": "Remove bool type check",
        "sim_msg": "fix for value_and_unit",
        "sim_diff": "diff --git a/apps/projects/models.py b/apps/projects/models.py @@ -261,6 +261,6 @@ class Value(Model):\nvalue = self.value\nif self.attribute.unit:\n- return str(value) + ' ' + self.attribute.unit\n+ return '%s %s' % (value, self.attribute.unit)\nelse:\nreturn value\n",
        "chatgpt_cot": "Remove unnecessary type hint from _weapons method in PassengerUnit class."
    },
    {
        "org_diff": "diff --git a/node_manager_daemon_fkie/tests/test_grpc_server.py b/node_manager_daemon_fkie/tests/test_grpc_server.py @@ -162,7 +162,8 @@ class TestGrpcServer(unittest.TestCase):\nrequest_args = False\nargs = psr.choices\nexcept Exception as err:\n- self.fail(\"`load_launch` raises wrong Exception on args requests, got: %s, expected: `exceptions.ParamSelectionReques`: %s\" % (type(err), err))\n+ pass\n+ # self.fail(\"`load_launch` raises wrong Exception on args requests, got: %s, expected: `exceptions.ParamSelectionReques`: %s\" % (type(err), err))\nrequest_args = False\ntry:\nlaunch_file, _argv = self.ls.load_launch(package, launch, path=path, args=args, request_args=request_args)\n",
        "org_msg": "changes to pass tests in industrial ci",
        "sim_msg": "added requirement for EGRPC",
        "sim_diff": "diff --git a/ambassador/tests/abstract_tests.py b/ambassador/tests/abstract_tests.py @@ -382,7 +382,11 @@ class EGRPC(ServiceType):\nsuper().__init__(*args, service_manifests=manifests.GRPC_ECHO_BACKEND, **kwargs)\ndef requirements(self):\n- yield (\"pod\", self.path.k8s)\n+ yield (\"url\", Query(\"http://%s/echo.EchoService/Echo\" % self.path.fqdn,\n+ headers={ \"content-type\": \"application/grpc\",\n+ \"requested-status\": \"0\" },\n+ expected=200,\n+ grpc_type=\"real\"))\nclass AHTTP(ServiceType):\nskip_variant: ClassVar[bool] = True\n",
        "chatgpt_cot": "Fix the wrong exception in `load_launch` method. The modification helps to handle the exception correctly."
    },
    {
        "org_diff": "diff --git a/src/api-engine/api/lib/peer/channel.py b/src/api-engine/api/lib/peer/channel.py @@ -11,9 +11,8 @@ class Channel(BasicEnv):\nsuper(Channel, self).__init__(version, **kwargs)\ndef create(self, channel, orderer_url, channel_tx, orderer_tls_rootcert, time_out=\"90s\"):\n+ try:\nres = 0x100\n- print(\"FABRIC_CFG_PATH\", os.getenv(\"FABRIC_CFG_PATH\"))\n- print(\"CORE_PEER_TLS_ENABLED\", os.getenv(\"CORE_PEER_TLS_ENABLED\"))\nif os.getenv(\"CORE_PEER_TLS_ENABLED\") == \"false\" or os.getenv(\"CORE_PEER_TLS_ENABLED\") is None:\nres = os.system(\"{} channel create -c {} -o {} -f {} --timeout {}\"\n.format(self.peer, channel, orderer_url, channel_tx, time_out))\n@@ -24,8 +23,16 @@ class Channel(BasicEnv):\n# The return value of os.system is not the result of executing the program. It is a 16 bit number,\n# and its high bit is the return code\nres = res >> 8\n+ except Exception as e:\n+ err_msg = \"create channel failed for {}!\".format(e)\n+ raise Exception(err_msg)\nreturn res\ndef list(self):\n+ try:\nres = os.system(\"{} channel list\".format(self.peer))\n+ res = res >> 8\n+ except Exception as e:\n+ err_msg = \"get channel list failed for {}!\".format(e)\n+ raise Exception(err_msg)\nreturn res\n",
        "org_msg": "[#issue-302]Add try exception judgment\nAdd try exception judgment",
        "sim_msg": "updated testnet & raspiconfig",
        "sim_diff": "diff --git a/home.admin/BBopenChannel.sh b/home.admin/BBopenChannel.sh _temp=\"./download/dialog.$$\"\n_error=\"./.error.out\"\n-# load network and chain info\n-network=`cat .network`\n-chain=$(sudo -bitcoin ${network}-cli -datadir=/home/bitcoin/.${network} getblockchaininfo | jq -r '.chain')\n+# load raspiblitz config data (with backup from old config)\n+source /mnt/hdd/raspiblitz.conf 2>/dev/null\n+if [ ${#network} -eq 0 ]; then network=`cat .network`; fi\n+if [ ${#chain} -eq 0 ]; then\n+ echo \"gathering chain info ... please wait\"\n+ chain=$(${network}-cli getblockchaininfo | jq -r '.chain')\n+fi\necho \"\"\necho \"*** Precheck ***\"\n# check if chain is in sync\n-chainInSync=$(lncli --chain=${network} getinfo | grep '\"synced_to_chain\": true' -c)\n+chainInSync=$(lncli --chain=${network} --network=${chain}net getinfo | grep '\"synced_to_chain\": true' -c)\nif [ ${chainInSync} -eq 0 ]; then\necho \"FAIL - 'lncli getinfo' shows 'synced_to_chain': false\"\necho \"Wait until chain is sync with LND and try again.\"\n@@ -19,7 +23,7 @@ if [ ${chainInSync} -eq 0 ]; then\nfi\n# check available funding\n-confirmedBalance=$(lncli --chain=${network} walletbalance | grep '\"confirmed_balance\"' | cut -d '\"' -f4)\n+confirmedBalance=$(lncli --chain=${network} --network=${chain}net walletbalance | grep '\"confirmed_balance\"' | cut -d '\"' -f4)\nif [ ${confirmedBalance} -eq 0 ]; then\necho \"FAIL - You have 0 SATOSHI in your confirmed LND On-Chain Wallet.\"\necho \"Please fund your on-chain wallet first and wait until confirmed.\"\n@@ -28,7 +32,7 @@ if [ ${confirmedBalance} -eq 0 ]; then\nfi\n# check number of connected peers\n-numConnectedPeers=$(lncli --chain=${network} listpeers | grep pub_key -c)\n+numConnectedPeers=$(lncli --chain=${network} --network=${chain}net listpeers | grep pub_key -c)\nif [ ${numConnectedPeers} -eq 0 ]; then\necho \"FAIL - no peers connected on lightning network\"\necho \"You can only open channels to peer nodes to connected to first.\"\n@@ -44,7 +48,7 @@ do\npubKey=$(echo ${grepLine} | cut -d '\"' -f4)\n#echo \"grepLine(${pubKey})\"\nOPTIONS+=(${pubKey} \"\")\n-done < <(lncli --chain=${network} listpeers | grep pub_key)\n+done < <(lncli --chain=${network} --network=${chain}net listpeers | grep pub_key)\nTITLE=\"Open (Payment) Channel\"\nMENU=\"\\nChoose a peer you connected to, to open the channel with: \\n \"\npubKey=$(dialog --clear \\\n@@ -69,7 +73,7 @@ if [ \"${network}\" = \"bitcoin\" ]; then\nminSat=250000\nfi\n_error=\"./.error.out\"\n-lncli --chain=${network} openchannel ${CHOICE} 1 0 2>$_error\n+lncli --chain=${network} openchannel --network=${chain}net ${CHOICE} 1 0 2>$_error\nerror=`cat ${_error}`\nif [ $(echo \"${error}\" | grep \"channel is too small\" -c) -eq 1 ]; then\nminSat=$(echo \"${error}\" | tr -dc '0-9')\n@@ -89,7 +93,7 @@ if [ ${#amount} -eq 0 ]; then\nfi\n# build command\n-command=\"lncli --chain=${network} openchannel ${pubKey} ${amount} 0\"\n+command=\"lncli --chain=${network} --network=${chain}net openchannel ${pubKey} ${amount} 0\"\n# info output\nclear\n",
        "chatgpt_cot": "\"Add exception handling for channel creation and channel listing to handle potential errors and improve error messaging for better debugging.\""
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/nodes/script_runner.py b/node_manager_fkie/nodes/script_runner.py @@ -6,6 +6,7 @@ import signal\nimport subprocess\nimport sys\nimport threading\n+import time\nimport rospy\n@@ -109,17 +110,28 @@ class RunThread(threading.Thread):\nself._cmd.insert(0, resolved)\nself.setDaemon(True)\nself.spopen = None\n+ self.stop = False\ndef run(self):\n'''\n'''\ntry:\nself.spopen = SupervisedPopen(self._cmd)\n+ while not self.stop and self.spopen.popen.returncode is None:\n+ if self.spopen.popen.stderr is not None:\n+ reserr = self.spopen.popen.stderr.read()\n+ if reserr:\n+ rospy.logwarn(\"script returns follow exception: %s\" % reserr.strip())\n+ time.sleep(0.1)\n+ if self.spopen.popen.returncode is not None and self.spopen.popen.returncode != 0:\n+ rospy.logerr(\"Script ends with error, code: %d\" % self.spopen.popen.returncode)\n+ os.kill(os.getpid(), signal.SIGKILL)\nexcept OSError as err:\n- rospy.logerr(\"Error on run %s: %s\" % (self._script, err))\n+ rospy.logerr(\"Error while run '%s': %s\" % (self._script, err))\nos.kill(os.getpid(), signal.SIGKILL)\ndef stop(self):\n+ self.stop = True\nif self.spopen is not None:\nif self.spopen.popen.pid is not None and self.spopen.popen.returncode is None:\nrospy.loginfo(\"stop process %d\" % self.spopen.popen.pid)\n@@ -131,7 +143,12 @@ if __name__ == '__main__':\nrospy.init_node(name, log_level=rospy.INFO)\nset_terminal_name(name)\nset_process_name(name)\n+ param_script = ''\n+ try:\nparam_script = rospy.get_param('~script')\n+ except KeyError:\n+ rospy.logerr(\"No script specified! Use ~script parameter to specify the script!\")\n+ os.kill(os.getpid(), signal.SIGKILL)\nparam_stop_script = rospy.get_param('~stop_script', '')\nrospy.loginfo(\"~script: %s\" % param_script)\nrospy.loginfo(\"~stop_script: %s\" % param_stop_script)\n@@ -140,6 +157,7 @@ if __name__ == '__main__':\nrospy.spin()\n# stop the script\nif param_stop_script:\n+ runthread.stop = True\nrospy.loginfo(\"stop using %s\" % param_stop_script)\nstopthread = RunThread(param_stop_script)\nstopthread.start()\n",
        "org_msg": "node_manager_fkie: added more error handling for script_runner",
        "sim_msg": "synctl warns when no process is stopped and avoids start\n* If an error occurs when stopping a process synctl now logs a warning.\n* During a restart, synctl will avoid attempting to start Synapse if an error\noccurs during stopping Synapse.",
        "sim_diff": "diff --git a/synctl b/synctl @@ -142,12 +142,23 @@ def start_worker(app: str, configfile: str, worker_configfile: str) -> bool:\nreturn False\n-def stop(pidfile, app):\n+def stop(pidfile: str, app: str) -> bool:\n+ \"\"\"Attempts to kill a synapse worker from the pidfile.\n+ Args:\n+ pidfile: path to file containing worker's pid\n+ app: name of the worker's appservice\n+\n+ Returns:\n+ True if the process stopped successfully\n+ False if process was already stopped or an error occured\n+ \"\"\"\n+\nif os.path.exists(pidfile):\npid = int(open(pidfile).read())\ntry:\nos.kill(pid, signal.SIGTERM)\nwrite(\"stopped %s\" % (app,), colour=GREEN)\n+ return True\nexcept OSError as err:\nif err.errno == errno.ESRCH:\nwrite(\"%s not running\" % (app,), colour=YELLOW)\n@@ -155,6 +166,14 @@ def stop(pidfile, app):\nabort(\"Cannot stop %s: Operation not permitted\" % (app,))\nelse:\nabort(\"Cannot stop %s: Unknown error\" % (app,))\n+ return False\n+ else:\n+ write(\n+ \"No running worker of %s found (from %s)\\nThe process might be managed by another controller (e.g. systemd)\"\n+ % (app, pidfile),\n+ colour=YELLOW,\n+ )\n+ return False\nWorker = collections.namedtuple(\n@@ -300,11 +319,17 @@ def main():\naction = options.action\nif action == \"stop\" or action == \"restart\":\n+ has_stopped = True\nfor worker in workers:\n- stop(worker.pidfile, worker.app)\n+ if not stop(worker.pidfile, worker.app):\n+ # A worker could not be stopped.\n+ has_stopped = False\nif start_stop_synapse:\n- stop(pidfile, \"synapse.app.homeserver\")\n+ if not stop(pidfile, \"synapse.app.homeserver\"):\n+ has_stopped = False\n+ if not has_stopped:\n+ sys.exit(1)\n# Wait for synapse to actually shutdown before starting it again\nif action == \"restart\":\n",
        "chatgpt_cot": "Add time import and stop flag, fix the compilation error. Add the stop method to stop the script. Fix error message and add script stop."
    },
    {
        "org_diff": "diff --git a/fkie_node_manager/src/fkie_node_manager/node_tree_model.py b/fkie_node_manager/src/fkie_node_manager/node_tree_model.py @@ -1037,7 +1037,7 @@ class HostItem(GroupItem):\ntooltip += '\\n<dt><font color=\"grey\">%s</font></dt>' % (diag.message.replace('>', '&gt;').replace('<', '&lt;'))\nif free is not None:\ntooltip += '\\n<dt><em>%s:</em> %s (%s%%)</dt>' % ('Free', free, free_percent)\n- has_cpu_processes = False\n+ cpu_processes = 3\nfor key, value in others:\nkey_fmt = key\nval_fmt = value\n@@ -1056,11 +1056,11 @@ class HostItem(GroupItem):\nif pid:\nkill_ref = ' <a href=\"kill-pid://pid%s\">kill</a>' % pid\ntooltip += '\\n<dt><font color=\"red\">%s</font>%s</dt>' % (val_fmt, kill_ref)\n- has_cpu_processes = True\n+ cpu_processes -= 1\nelse:\ntooltip += '\\n<dt><em>%s:</em> %s</dt>' % (key_fmt, val_fmt)\n- if not has_cpu_processes and diag.name == 'CPU Load':\n- for _idx in range(3):\n+ if cpu_processes > 0 and diag.name == 'CPU Load':\n+ for _idx in range(cpu_processes):\ntooltip += '\\n<dt><font color=\"grey\">%s</font></dt>' % ('--')\nexcept Exception as err:\ntooltip += '\\n<dt><font color=\"red\">%s</font></dt>' % (utf8(err))\n",
        "org_msg": "fkie_node_manager: display fix item count of processes in system monitoring",
        "sim_msg": "show avids in segments and ctids in coded text",
        "sim_diff": "diff --git a/qualcoder/view_av.py b/qualcoder/view_av.py @@ -1048,9 +1048,9 @@ class DialogCodeAV(QtWidgets.QDialog):\nfor c in self.code_text:\nif c['important'] == 1:\nimp_coded.append(c)\n- self.eventFilterTT.set_codes_and_annotations(imp_coded, self.codes, self.annotations)\n+ self.eventFilterTT.set_codes_and_annotations(self.app, imp_coded, self.codes, self.annotations)\nelse:\n- self.eventFilterTT.set_codes_and_annotations(self.code_text, self.codes, self.annotations)\n+ self.eventFilterTT.set_codes_and_annotations(self.app, self.code_text, self.codes, self.annotations)\nself.unlight()\nself.highlight()\n@@ -3063,8 +3063,12 @@ class ToolTipEventFilter(QtCore.QObject):\ncodes = None\ncode_text = None\nannotations = None\n+ app = None\n+\n+ def set_codes_and_annotations(self, app, code_text, codes, annotations):\n+ \"\"\" Update codes and coded text and annotations for tooltips. \"\"\"\n- def set_codes_and_annotations(self, code_text, codes, annotations):\n+ self.app = app\nself.code_text = code_text\nself.codes = codes\nself.annotations = annotations\n@@ -3075,7 +3079,7 @@ class ToolTipEventFilter(QtCore.QObject):\nitem['color'] = c['color']\ndef eventFilter(self, receiver, event):\n- \"\"\" Tool tip event filter for ?textEdit \"\"\"\n+ \"\"\" Tool tip event filter for textEdit \"\"\"\nif event.type() == QtCore.QEvent.Type.ToolTip:\ncursor = receiver.cursorForPosition(event.pos())\n@@ -3093,6 +3097,8 @@ class ToolTipEventFilter(QtCore.QObject):\ntry:\ntext_ += '<p style=\"background-color:' + item['color']\ntext_ += '; color:' + TextColor(item['color']).recommendation + '\">' + item['name']\n+ if self.app.settings['showids'] == 'True':\n+ text_ += \" [ctid:\" + str(item['ctid']) + \"] \"\nif item['avid'] is not None:\ntext_ += \" [\" + msecs_to_hours_mins_secs(item['av_pos0'])\ntext_ += \" - \" + msecs_to_hours_mins_secs(item['av_pos1']) + \"]\"\n@@ -3425,6 +3431,8 @@ class SegmentGraphicsItem(QtWidgets.QGraphicsLineItem):\nseg_time = \"[\" + msecs_to_hours_mins_secs(self.segment['pos0']) + \" - \"\nseg_time += msecs_to_hours_mins_secs(self.segment['pos1']) + \"]\"\ntooltip += seg_time\n+ if self.app.settings['showids'] == 'True':\n+ tooltip += \" [avid:\" + str(self.segment['avid']) + \"]\"\nif self.segment['memo'] != \"\":\ntooltip += \"\\n\" + _(\"MEMO: \") + self.segment['memo']\nif self.segment['seltext'] is not None and self.segment['seltext'] != \"\":\n",
        "chatgpt_cot": "\"Refactor HostItem class to handle CPU processes in tooltip\""
    },
    {
        "org_diff": "diff --git a/fkie_node_manager/src/fkie_node_manager/editor/editor.py b/fkie_node_manager/src/fkie_node_manager/editor/editor.py @@ -558,7 +558,8 @@ class Editor(QMainWindow):\nevent.accept()\nelif result == MessageBox.No:\nevent.accept()\n- elif rospy.is_shutdown():\n+ # elif rospy.is_shutdown():\n+ else:\nevent.ignore()\nelse:\nevent.accept()\n",
        "org_msg": "fkie_node_manager: editor: do not close editor on ESC",
        "sim_msg": "Fix: line too long\nAlthough I personally think the readability suffers from this.",
        "sim_diff": "diff --git a/avalon/tools/workfiles/app.py b/avalon/tools/workfiles/app.py @@ -367,7 +367,8 @@ class Window(QtWidgets.QDialog):\n\"\\nDo you want to save the changes?\"\n)\nself._messagebox.setStandardButtons(\n- self._messagebox.Yes | self._messagebox.No | self._messagebox.Cancel\n+ self._messagebox.Yes | self._messagebox.No |\n+ self._messagebox.Cancel\n)\nresult = self._messagebox.exec_()\n",
        "chatgpt_cot": "\"Fix event handling in Editor class to properly handle rospy shutdown\""
    },
    {
        "org_diff": "diff --git a/sc2/units.py b/sc2/units.py from __future__ import annotations\nimport random\n-from functools import cached_property\nfrom itertools import chain\nfrom typing import TYPE_CHECKING, Any, Callable, Generator, Iterable, List, Optional, Set, Tuple, Union\n@@ -633,15 +632,14 @@ class Units(list):\nunit_alias_types\n)\n- @cached_property\n+ @property\ndef center(self) -> Point2:\n\"\"\" Returns the central position of all units. \"\"\"\nassert self, \"Units object is empty\"\n- amount = self.amount\nreturn Point2(\n(\n- sum(unit._proto.pos.x for unit in self) / amount,\n- sum(unit._proto.pos.y for unit in self) / amount,\n+ sum(unit._proto.pos.x for unit in self) / self.amount,\n+ sum(unit._proto.pos.y for unit in self) / self.amount,\n)\n)\n",
        "org_msg": "Remove \"cached_property\" from Units class",
        "sim_msg": "Returns indexes instead of points if input argument 'return_index' is True (by default it is False).",
        "sim_diff": "diff --git a/pyclustering/cluster/center_initializer.py b/pyclustering/cluster/center_initializer.py @@ -204,13 +204,15 @@ class kmeans_plusplus_initializer:\nreturn shortest_distances\n- def __get_next_center(self, centers):\n+ def __get_next_center(self, centers, return_index):\n\"\"\"!\n@brief Calculates the next center for the data.\n@param[in] centers (array_like): Current initialized centers.\n+ @param[in] return_index (bool): If True then return center's index instead of point.\n- @return (array_like) Next initialized center.\n+ @return (array_like) Next initialized center.<br>\n+ (uint) Index of next initialized center if return_index is True.\n\"\"\"\n@@ -222,9 +224,30 @@ class kmeans_plusplus_initializer:\nprobabilities = self.__calculate_probabilities(distances)\ncenter_index = self.__get_probable_center(distances, probabilities)\n+ if return_index:\n+ return center_index\n+\nreturn self.__data[center_index]\n+ def __get_initial_center(self, return_index):\n+ \"\"\"!\n+ @brief Choose randomly first center.\n+\n+ @param[in] return_index (bool): If True then return center's index instead of point.\n+\n+ @return (array_like) First center.<br>\n+ (uint) Index of first center.\n+\n+ \"\"\"\n+\n+ index_center = random.randint(0, len(self.__data) - 1)\n+ if return_index:\n+ return index_center\n+\n+ return self.__data[index_center]\n+\n+\ndef __calculate_probabilities(self, distances):\n\"\"\"!\n@brief Calculates cumulative probabilities of being center of each point.\n@@ -272,20 +295,23 @@ class kmeans_plusplus_initializer:\nreturn index_best_candidate\n- def initialize(self):\n+ def initialize(self, return_index=False):\n\"\"\"!\n@brief Calculates initial centers using K-Means++ method.\n+ @param[in] return_index (bool): If True then returns indexes of points from input data instead of points itself.\n+\n@return (list) List of initialized initial centers.\n+ If argument 'return_index' is False then returns list of points.\n+ If argument 'return_index' is True then returns list of indexes.\n\"\"\"\n- index_center = random.randint(0, len(self.__data) - 1)\n- centers = [ self.__data[ index_center ] ]\n+ centers = [ self.__get_initial_center(return_index) ]\n# For each next center\nfor _ in range(1, self.__amount):\n- next_center = self.__get_next_center(centers)\n+ next_center = self.__get_next_center(centers, return_index)\ncenters.append(next_center)\nreturn centers\n\\ No newline at end of file\n",
        "chatgpt_cot": "\"Refactor center method in Units class to use regular property instead of cached_property for better performance and readability.\""
    },
    {
        "org_diff": "diff --git a/scripts/worker_node/download_images.sh b/scripts/worker_node/download_images.sh @@ -22,6 +22,7 @@ IMG_TAG=1.0.0\necho_b \"Downloading fabric images from DockerHub...with tag = ${IMG_TAG}... need a while\"\n# TODO: we may need some checking on pulling result?\ndocker pull hyperledger/fabric-peer:$ARCH-$IMG_TAG\n+docker pull hyperledger/fabric-tools:$ARCH-$IMG_TAG\ndocker pull hyperledger/fabric-orderer:$ARCH-$IMG_TAG\ndocker pull hyperledger/fabric-ca:$ARCH-$IMG_TAG\ndocker pull hyperledger/fabric-ccenv:$ARCH-$IMG_TAG\n@@ -33,7 +34,7 @@ docker pull hyperledger/fabric-baseos:$ARCH-$BASEIMAGE_RELEASE\necho_b \"===Re-tagging images to *latest* tag\"\ndocker tag hyperledger/fabric-peer:$ARCH-$IMG_TAG hyperledger/fabric-peer\n-docker tag hyperledger/fabric-peer:$ARCH-$IMG_TAG hyperledger/fabric-tools\n+docker tag hyperledger/fabric-tools:$ARCH-$IMG_TAG hyperledger/fabric-tools\ndocker tag hyperledger/fabric-orderer:$ARCH-$IMG_TAG hyperledger/fabric-orderer\ndocker tag hyperledger/fabric-ca:$ARCH-$IMG_TAG hyperledger/fabric-ca\n",
        "org_msg": "Modify fabric-tools image\nGet fabric-tools image from official registry.",
        "sim_msg": "Remove docker images from Jenkins node after build and push",
        "sim_diff": "diff --git a/Jenkinsfile b/Jenkinsfile @@ -71,6 +71,8 @@ pipeline {\nexport WCA_TAG=${GIT_BRANCH}-devel\nmake _wca_docker_devel\ndocker push $WCA_IMAGE:$WCA_TAG\n+ # Delete all wca images from Jenkins nodes\n+ docker rmi $WCA_IMAGE:${GIT_COMMIT} $WCA_IMAGE:${GIT_BRANCH} $WCA_IMAGE:${WCA_TAG}\n'''\n}\n}\n@@ -130,6 +132,7 @@ pipeline {\ndocker push ${IMAGE_NAME}\ndocker tag ${IMAGE_NAME} ${BRANCH_IMAGE_NAME}\ndocker push ${BRANCH_IMAGE_NAME}\n+ docker rmi ${IMAGE_NAME} ${BRANCH_IMAGE_NAME}\n'''\n}\n}\n@@ -146,6 +149,7 @@ pipeline {\ndocker push ${IMAGE_NAME}\ndocker tag ${IMAGE_NAME} ${BRANCH_IMAGE_NAME}\ndocker push ${BRANCH_IMAGE_NAME}\n+ docker rmi ${IMAGE_NAME} ${BRANCH_IMAGE_NAME}\n'''\n}\n}\n@@ -162,6 +166,7 @@ pipeline {\ndocker push ${IMAGE_NAME}\ndocker tag ${IMAGE_NAME} ${BRANCH_IMAGE_NAME}\ndocker push ${BRANCH_IMAGE_NAME}\n+ docker rmi ${IMAGE_NAME} ${BRANCH_IMAGE_NAME}\n'''\n}\n}\n@@ -178,6 +183,7 @@ pipeline {\ndocker push ${IMAGE_NAME}\ndocker tag ${IMAGE_NAME} ${BRANCH_IMAGE_NAME}\ndocker push ${BRANCH_IMAGE_NAME}\n+ docker rmi ${IMAGE_NAME} ${BRANCH_IMAGE_NAME}\n'''\n}\n}\n@@ -194,6 +200,7 @@ pipeline {\ndocker push ${IMAGE_NAME}\ndocker tag ${IMAGE_NAME} ${BRANCH_IMAGE_NAME}\ndocker push ${BRANCH_IMAGE_NAME}\n+ docker rmi ${IMAGE_NAME} ${BRANCH_IMAGE_NAME}\n'''\n}\n}\n@@ -210,6 +217,7 @@ pipeline {\ndocker push ${IMAGE_NAME}\ndocker tag ${IMAGE_NAME} ${BRANCH_IMAGE_NAME}\ndocker push ${BRANCH_IMAGE_NAME}\n+ docker rmi ${IMAGE_NAME} ${BRANCH_IMAGE_NAME}\n'''\n}\n}\n@@ -226,6 +234,7 @@ pipeline {\ndocker push ${IMAGE_NAME}\ndocker tag ${IMAGE_NAME} ${BRANCH_IMAGE_NAME}\ndocker push ${BRANCH_IMAGE_NAME}\n+ docker rmi ${IMAGE_NAME} ${BRANCH_IMAGE_NAME}\n'''\n}\n}\n@@ -242,6 +251,7 @@ pipeline {\ndocker push ${IMAGE_NAME}\ndocker tag ${IMAGE_NAME} ${BRANCH_IMAGE_NAME}\ndocker push ${BRANCH_IMAGE_NAME}\n+ docker rmi ${IMAGE_NAME} ${BRANCH_IMAGE_NAME}\n'''\n}\n}\n@@ -258,6 +268,7 @@ pipeline {\ndocker push ${IMAGE_NAME}\ndocker tag ${IMAGE_NAME} ${BRANCH_IMAGE_NAME}\ndocker push ${BRANCH_IMAGE_NAME}\n+ docker rmi ${IMAGE_NAME} ${BRANCH_IMAGE_NAME}\n'''\n}\n}\n@@ -274,6 +285,7 @@ pipeline {\ndocker push ${IMAGE_NAME}\ndocker tag ${IMAGE_NAME} ${BRANCH_IMAGE_NAME}\ndocker push ${BRANCH_IMAGE_NAME}\n+ docker rmi ${IMAGE_NAME} ${BRANCH_IMAGE_NAME}\n'''\n}\n}\n@@ -289,6 +301,7 @@ pipeline {\ndocker push ${IMAGE_NAME}\ndocker tag ${IMAGE_NAME} ${BRANCH_IMAGE_NAME}\ndocker push ${BRANCH_IMAGE_NAME}\n+ docker rmi ${IMAGE_NAME} ${BRANCH_IMAGE_NAME}\n'''\n}\n}\n@@ -308,6 +321,7 @@ pipeline {\ndocker push ${IMAGE_NAME}\ndocker tag ${IMAGE_NAME} ${BRANCH_IMAGE_NAME}\ndocker push ${BRANCH_IMAGE_NAME}\n+ docker rmi ${IMAGE_NAME} ${BRANCH_IMAGE_NAME}\n'''\n}\n}\n",
        "chatgpt_cot": "Add re-tagging of fabric-tools image and pull fabric-tools image from DockerHub to download_images.sh script."
    },
    {
        "org_diff": "diff --git a/sc2/position.py b/sc2/position.py @@ -236,9 +236,6 @@ class Point2(Pointlike):\nPoint2((self.x + 1, self.y + 1)),\n}\n- def offset(self, other) -> \"Point2\":\n- return self.__class__((self.x + other[0], self.y + other[1]))\n-\ndef negative_offset(self, other: \"Point2\") -> \"Point2\":\nreturn self.__class__((self.x - other.x, self.y - other.y))\n",
        "org_msg": "Remove offset overwrite",
        "sim_msg": "added round() to syft.py",
        "sim_diff": "diff --git a/syft/syft.py b/syft/syft.py @@ -174,6 +174,9 @@ class FloatTensor():\ndef floor_(self):\nreturn self.no_params_func(\"floor_\")\n+ def round(self):\n+ return self.no_params_func(\"round\", return_response=True)\n+\ndef mm(self, other):\nreturn self.params_func(\"mm\",[other.id],True)\n",
        "chatgpt_cot": "Remove offset method and replace it with negative_offset in Point2 class in position.py."
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/master_view_proxy.py b/node_manager_fkie/src/node_manager_fkie/master_view_proxy.py @@ -1797,16 +1797,16 @@ class MasterViewProxy(QWidget):\nresult = []\nif self.master_info is not None:\nfor n in nodes:\n- node_item = None\n- if cfg:\n+ node_items = self.getNode(n)\n+ if node_items:\n+ node_item = node_items[0]\n+ node_item.addConfig(cfg)\n+ node_item.next_start_cfg = cfg\n+ elif cfg:\nnode_info = NodeInfo(n, self.masteruri)\nnode_item = NodeItem(node_info)\nnode_item.addConfig(cfg)\nnode_item.next_start_cfg = cfg\n- else:\n- node_items = self.getNode(n)\n- if node_items:\n- node_item = node_items[0]\nif node_item is not None:\nresult.append(node_item)\nself.start_nodes(result, force)\n",
        "org_msg": "node_manager_fkie: fixed save profile after load profile",
        "sim_msg": "Tree: display title for e.g. Frame, allow editing of this and class name",
        "sim_diff": "diff --git a/tree.py b/tree.py @@ -484,7 +484,15 @@ class WidgetTree(wx.TreeCtrl, Tree):\nnew_value = evt.Label\nif new_value==self._build_label(node): return\n- new_name = new_label = new_title = new_tab = None\n+ new_name = new_label = new_title = new_tab = new_class = None\n+\n+ if node.widget.klass != node.widget.base and node.widget.klass != 'wxScrolledWindow':\n+ if new_value.count(\"(\")==1 and new_value.count(\")\")==1:\n+ pre, new_class = new_value.split(\"(\")\n+ new_class, post = new_class.split(\")\")\n+ if pre.endswith(\" \"): pre = pre[:-1]\n+ new_value = pre+post\n+\nif \"label\" in widget.properties and self._label_editable(widget):\nnew_name, new_label = self._split_name_label(new_value)\nelif \"label\" in widget.properties:\n@@ -507,14 +515,23 @@ class WidgetTree(wx.TreeCtrl, Tree):\nif new_name==name_p.get(): new_name = None\nif new_name:\n# check\n- name_OK = name_p.check(new_name)\n- if not name_OK: new_name = None\n+ OK = name_p.check(new_name)\n+ if not OK: new_name = None\n+\n+ # check class/klass\n+ if new_class:\n+ class_p = widget.properties[\"klass\"]\n+ if new_class==class_p.get(): new_class = None\n+ if new_class:\n+ # check\n+ OK = class_p.check(new_class)\n+ if not OK: new_class = None\n# check label\nif new_label is not None:\nlabel_p = widget.properties[\"label\"]\nif new_label==label_p.get(): new_label = None\n- if not new_name and new_label is None and new_title is None and new_tab is None:\n+ if not new_name and new_label is None and new_title is None and new_tab is None and new_class is None:\n# no change or an error\nwx.Bell()\nevt.Veto()\n@@ -543,6 +560,10 @@ class WidgetTree(wx.TreeCtrl, Tree):\nname_p.previous_value = name_p.value\nname_p.set(new_name, notify=False)\nmodified.add(\"name\")\n+ if new_class:\n+ class_p.previous_value = class_p.value\n+ class_p.set(new_class, notify=False)\n+ modified.add(\"class\")\nif new_label:\nlabel_p.previous_value = label_p.value\nlabel_p.set(new_label, notify=False)\n@@ -577,6 +598,9 @@ class WidgetTree(wx.TreeCtrl, Tree):\nif node.widget.klass != node.widget.base and node.widget.klass != 'wxScrolledWindow':\n# special case...\ns += ' (%s)' % node.widget.klass\n+ if getattr(node.widget, \"has_title\", None):\n+ # include title\n+ s += ': \"%s\"'%node.widget.title\nelif \"label\" in node.widget.properties and node.widget.properties[\"label\"].is_active():\n# include label of control\nlabel = node.widget.label\n",
        "chatgpt_cot": "Add method to retrieve node items, update node configuration, and fix start configuration assignment in MasterViewProxy to improve node management functionality."
    },
    {
        "org_diff": "diff --git a/.github/ISSUE_TEMPLATE/bug_report.md b/.github/ISSUE_TEMPLATE/bug_report.md @@ -29,10 +29,15 @@ assignees: ''\n## Context (Environment)\n<!--- How has this issue affected you? What are you trying to accomplish? -->\n<!--- Providing context helps us come up with a solution that is most useful in the real world -->\n+* OS:\n+* Architecture:\n+* Docker version:\n+* Docker compose version:\n+* Kubernetes version:\n<!--- Provide a general summary of the issue in the Title above -->\n-## Detailed Description\n+## Detailed Description and log\n<!--- Provide a detailed description of the change or addition you are proposing -->\n## Possible Implementation\n",
        "org_msg": "[Close Refine bug report issue template\nAdd more context info for bug report.",
        "sim_msg": "pin base pip requirements",
        "sim_diff": "diff --git a/docker/requirements.txt b/docker/requirements.txt -Flask_Sockets\n-PyGithub\n-aiodns\n-aiohttp\n-aiohttp_jinja2\n-aiomysql\n-asyncinit\n-authlib\n-cerberus\n-decorator\n-flake8\n-flask\n-flask-cors\n-google-cloud-storage\n-humanize\n-jinja2\n-kubernetes\n-libsass\n-pip\n-pylint\n-pymysql\n-pytest\n-requests\n-urllib3<1.25,>=1.21.1\n-uvloop>=0.12\n-werkzeug\n-parsimonious\n-kubernetes_asyncio\n+aiodns==2.0.0\n+aiohttp==3.5.4\n+aiohttp-jinja2==1.1.1\n+aiomysql==0.0.20\n+asyncinit==0.2.4\n+Authlib==0.11\n+Cerberus==1.3.1\n+decorator==4.4.0\n+flake8==3.7.7\n+Flask==1.0.3\n+Flask-Cors==3.0.8\n+Flask-Sockets==0.2.1\ngcsfs==0.2.1\n+google-cloud-storage==1.16.1\n+humanize==0.5.1\nhurry.filesize==0.9\n+Jinja2==2.10.1\n+kubernetes==9.0.0\n+kubernetes-asyncio==9.1.0\n+libsass==0.19.2\n+parsimonious==0.8.1\n+PyGithub==1.43.7\n+pylint==2.3.1\n+PyMySQL==0.9.3\n+pytest==4.6.3\n+requests==2.22.0\n+urllib3==1.24.3\n+uvloop==0.12.2\n+Werkzeug==0.15.4\n",
        "chatgpt_cot": "\"Add environment context fields and log to bug report template for better issue description and resolution in real world scenarios.\""
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/main_window.py b/node_manager_fkie/src/node_manager_fkie/main_window.py @@ -1785,6 +1785,7 @@ class MainWindow(QMainWindow):\nif (valid_sender) and (same_title or no_focus or self._accept_next_update):\nself._accept_next_update = False\n# _description_accept is set to True on click on link of {node, topic, service}\n+ if not same_title:\nif self._description_accept:\nself._description_history.append((wtitle, self.descriptionTextEdit.toHtml()))\nelse:\n",
        "org_msg": "node_manager_fkie: do not add 'back' on update of the same item description",
        "sim_msg": "fix result test",
        "sim_diff": "diff --git a/home.admin/00raspiblitz.sh b/home.admin/00raspiblitz.sh @@ -102,7 +102,7 @@ do\n# run statusscan with timeout - if status scan was not killed it will copy over the\ntimeout 10 /home/admin/config.scripts/blitz.statusscan.sh > /var/cache/raspiblitz/raspiblitz.status.tmp\nresult=$?\n- if [ \"${result}\" != \"0\" ]; then\n+ if [ \"${result}\" == \"0\" ]; then\n# statusscan finished in under 10 seconds - use results\ncp /var/cache/raspiblitz/raspiblitz.status.tmp /var/cache/raspiblitz/raspiblitz.status\nelse\n",
        "chatgpt_cot": "Add condition to check if the title is not the same before appending to description history in MainWindow class."
    },
    {
        "org_diff": "diff --git a/README.md b/README.md -> This is a new version with daemon instance! Since the packages are renamed, you need to clean your build space before build new packages.\n+## This is a new version with daemon instance!\n+\n+Whats new:\n+\n+ * Remote access and control of launch and configuration files.\n+ * Easy remote editing of launch files.\n+ * Monitoring for ROS nodes and system resources on remote hosts.\n> Old version is available on branch: `old_master` and is no longer supported!\n@@ -13,6 +19,8 @@ In addition, Node Manager with a daemon provide a GUI-based management environme\nThe communication between Node Manager and the daemon is based on python [gRPC](https://grpc.io/). Until Ubuntu *cosmic* you have to install *python-grpcio-tools* from PIP. That's why there are no debian packages for this version of FKIE multimaster. Use follow command line to install all dependencies:\n+> if you already build previous version (without node_manager_daemon) you need to clean your build space to remove all packages with `_fkie` suffix.\n+\n```\ncd catkin_ws/src\ngit clone https://github.com/fkie/multimaster_fkie.git\n",
        "org_msg": "update readme with info to new version",
        "sim_msg": "updated readme for docker-compose",
        "sim_diff": "diff --git a/README_EN.md b/README_EN.md @@ -211,7 +211,7 @@ administrator@myems.io\n### Docker Compose Repaid Deployment\n-See [Docker Compose Repaid Deployment](docker-compose.md)\n+See [Docker Compose Repaid Deployment](docker-compose-en.md)\n## MyEMS Roadmap\n",
        "chatgpt_cot": "Update README with information about the new version with daemon instance, cleaning build space required due to package renaming. Add details about remote access and monitoring features."
    },
    {
        "org_diff": "diff --git a/sc2/ids/buff_id.py b/sc2/ids/buff_id.py @@ -302,7 +302,7 @@ class BuffId(enum.Enum):\nRESONATINGGLAIVESPHASESHIFT = 294\nNEURALPARASITECHILDREN = 295\nAMORPHOUSARMORCLOUD = 296\n- DUMMYBUFF001 = 297\n+ RAVENSHREDDERMISSILEARMORREDUCTIONUISUBTRUCT = 297\nBATTERYOVERCHARGE = 298\nDUMMYBUFF001 = 299\nDUMMYBUFF002 = 300\n",
        "org_msg": "Fix buffid mistake",
        "sim_msg": "remove unneeded flake8 noqa: F601 comments",
        "sim_diff": "diff --git a/tests/test_nodes.py b/tests/test_nodes.py @@ -279,19 +279,19 @@ class Enum2(Enum):\n# True aliases\n(True, \"Y\", \"true\", \"yes\", \"on\"),\n{\n- \"BooleanNode\": True, # noqa F601\n- \"StringNode\": str, # noqa F601\n- \"AnyNode\": copy.copy, # noqa F601\n+ \"BooleanNode\": True,\n+ \"StringNode\": str,\n+ \"AnyNode\": copy.copy,\n},\n),\n(\n(\"1\", 1, 10, -10),\n{\n- \"BooleanNode\": True, # noqa F601\n- \"IntegerNode\": int, # noqa F601\n- \"FloatNode\": float, # noqa F601\n- \"StringNode\": str, # noqa F601\n- \"AnyNode\": copy.copy, # noqa F601\n+ \"BooleanNode\": True,\n+ \"IntegerNode\": int,\n+ \"FloatNode\": float,\n+ \"StringNode\": str,\n+ \"AnyNode\": copy.copy,\n},\n),\n(\n@@ -303,20 +303,20 @@ class Enum2(Enum):\n# False aliases\n(False, \"N\", \"false\", \"no\", \"off\"),\n{\n- \"BooleanNode\": False, # noqa F601\n- \"StringNode\": str, # noqa F601\n- \"AnyNode\": copy.copy, # noqa F601\n+ \"BooleanNode\": False,\n+ \"StringNode\": str,\n+ \"AnyNode\": copy.copy,\n},\n),\n(\n# Falsy integers\n(\"0\", 0),\n{\n- \"BooleanNode\": False, # noqa F601\n- \"IntegerNode\": 0, # noqa F601\n- \"FloatNode\": 0.0, # noqa F601\n- \"StringNode\": str, # noqa F601\n- \"AnyNode\": copy.copy, # noqa F601\n+ \"BooleanNode\": False,\n+ \"IntegerNode\": 0,\n+ \"FloatNode\": 0.0,\n+ \"StringNode\": str,\n+ \"AnyNode\": copy.copy,\n},\n),\n],\n",
        "chatgpt_cot": "\"Add new buff ID for Raven Shredder Missile Armor Reduction UI subtraction\""
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/editor/text_search_thread.py b/node_manager_fkie/src/node_manager_fkie/editor/text_search_thread.py @@ -147,7 +147,7 @@ class TextSearchThread(QObject, threading.Thread):\nnew_dict = dict(args)\nnew_dict.update(include_args)\n# test search string for 'name=' and skip search in not launch files\n- if self._only_launch and inc_path.endswith('.launch'):\n+ if self._only_launch or inc_path.endswith('.launch'):\nself.search(search_text, inc_path, recursive, new_dict, count + 1)\nif self._path == path and self._found == 0:\nself.warning_signal.emit(\"not found '%s' in %s (%srecursive)\" % (search_text, path, '' if recursive else 'not '))\n",
        "org_msg": "node_manager_fkie: editor: fixed recursive search",
        "sim_msg": "improved file searching",
        "sim_diff": "diff --git a/pymatgen/command_line/bader_caller.py b/pymatgen/command_line/bader_caller.py @@ -234,27 +234,28 @@ class BaderAnalysis(object):\nname_pattern = filename + suffix + '*' if filename != 'POTCAR' \\\nelse filename + '*'\npaths = glob.glob(os.path.join(path, name_pattern))\n- if not paths:\n- if filename == \"CHGCAR\":\n- raise IOError(\"Could not find CHGCAR!\")\n- else:\n- if filename == \"POTCAR\":\n- warning_msg = \"cannot calculate charge transfer.\"\n- else:\n- warning_msg = \"interpret Bader results with caution.\"\n- warnings.warn(\"Could not find %s, \" % filename\n- + warning_msg)\n- return None\n- if len(paths) > 1:\n+ fpath = None\n+ if len(paths) >= 1:\n# using reverse=True because, if multiple files are present,\n# they likely have suffixes 'static', 'relax', 'relax2', etc.\n# and this would give 'static' over 'relax2' over 'relax'\n# however, better to use 'suffix' kwarg to avoid this!\npaths.sort(reverse=True)\nwarning_msg = \"Multiple files detected, using %s\" \\\n- % os.path.basename(paths[0])\n- warnings.warn(warning_msg)\n+ % os.path.basename(paths[0]) if len(paths) > 1\\\n+ else None\nfpath = paths[0]\n+ else:\n+ if filename == \"CHGCAR\":\n+ raise IOError(\"Could not find CHGCAR!\")\n+ else:\n+ warning_msg = \"Could not find %s, \" % filename\n+ if filename == \"POTCAR\":\n+ warning_msg += \"cannot calculate charge transfer.\"\n+ else:\n+ warning_msg += \"interpret Bader results with caution.\"\n+ if warning_msg:\n+ warnings.warn(warning_msg)\nreturn fpath\nchgcar_filename = _get_filepath(\"CHGCAR\")\n",
        "chatgpt_cot": "Fix conditional statement in TextSearchThread to include .launch files in search."
    },
    {
        "org_diff": "diff --git a/fkie_master_discovery/src/fkie_master_discovery/master_discovery.py b/fkie_master_discovery/src/fkie_master_discovery/master_discovery.py @@ -708,7 +708,7 @@ class Discoverer(object):\nif not (invalid_uri or invalid_state or rospy.is_shutdown() or self.do_finish):\nself._publish_current_state()\n# send update requests to group\n- if timer and self._init_notifications < self.INIT_NOTIFICATION_COUNT:\n+ if timer and self._listen_mcast and self._init_notifications < self.INIT_NOTIFICATION_COUNT:\nself._init_notifications += 1\nrospy.logdebug(\"Send requests while init %d/%d\" % (self._init_notifications, self.INIT_NOTIFICATION_COUNT))\nself._request_state()\n@@ -1131,6 +1131,7 @@ class Discoverer(object):\nif v.mastername is not None:\n# send an active unicast request\nself._request_state(k[0][0], [v])\n+ if self._listen_mcast:\nself._request_state()\n# self._send_current_state()\nexcept:\n",
        "org_msg": "fkie_master_discovery: do not send requests if listen_mcast is disabled",
        "sim_msg": "Change the manager ips of the reporter to the private ips",
        "sim_diff": "diff --git a/status-reporter/status_reporter/status_reporter.py b/status-reporter/status_reporter/status_reporter.py @@ -117,7 +117,7 @@ class Reporter(object):\ndef _update_managers_ips_list(self, client):\nresponse = client.manager.get_managers()\n- self._managers_ips = [manager.get('public_ip') for manager in\n+ self._managers_ips = [manager.get('private_ip') for manager in\nresponse]\nupdate_yaml_file(CONFIGURATION_PATH, {\n'managers_ips': self._managers_ips\n",
        "chatgpt_cot": "Add condition to send update requests and active unicast request based on _listen_mcast in Discoverer to improve functionality."
    },
    {
        "org_diff": "diff --git a/docs_generate/text_files/introduction.rst b/docs_generate/text_files/introduction.rst @@ -207,12 +207,12 @@ A function that can test which position is valid for a spawning pool is ``self.f\nOne thing that was not mentioned yet is that you don't want to build more than 1 spawning pool. To prevent this, you can check that the number of pending and completed structures is zero::\n- if self.already_pending(UnitTypeId.SPAWNINGPOOL) + self.units.filter(lambda structure: structure.type_id == UnitTypeId.SPAWNINGPOOL and structure.is_ready).amount == 0:\n+ if self.already_pending(UnitTypeId.SPAWNINGPOOL) + self.structures.filter(lambda structure: structure.type_id == UnitTypeId.SPAWNINGPOOL and structure.is_ready).amount == 0:\n# Build spawning pool\nSo in total: To build a spawning pool in direction of the map center, it is recommended to use::\n- if self.can_afford(UnitTypeId.SPAWNINGPOOL) and self.already_pending(UnitTypeId.SPAWNINGPOOL) + self.units.filter(lambda structure: structure.type_id == UnitTypeId.SPAWNINGPOOL and structure.is_ready).amount == 0:\n+ if self.can_afford(UnitTypeId.SPAWNINGPOOL) and self.already_pending(UnitTypeId.SPAWNINGPOOL) + self.structures.filter(lambda structure: structure.type_id == UnitTypeId.SPAWNINGPOOL and structure.is_ready).amount == 0:\nworker_candidates = self.workers.filter(lambda worker: (worker.is_collecting or worker.is_idle) and worker.tag not in self.unit_tags_received_action)\n# Worker_candidates can be empty\nif worker_candidates:\n@@ -226,7 +226,7 @@ So in total: To build a spawning pool in direction of the map center, it is reco\nThe same can be achieved with the convenience function ``self.build`` which automatically picks a worker and internally uses ``self.find_placement``::\n- if self.can_afford(UnitTypeId.SPAWNINGPOOL) and self.already_pending(UnitTypeId.SPAWNINGPOOL) + self.units.filter(lambda structure: structure.type_id == UnitTypeId.SPAWNINGPOOL and structure.is_ready).amount == 0:\n+ if self.can_afford(UnitTypeId.SPAWNINGPOOL) and self.already_pending(UnitTypeId.SPAWNINGPOOL) + self.structures.filter(lambda structure: structure.type_id == UnitTypeId.SPAWNINGPOOL and structure.is_ready).amount == 0:\nmap_center = self.game_info.map_center\nposition_towards_map_center = self.start_location.towards(map_center, distance=5)\nawait self.build(UnitTypeId.SPAWNINGPOOL, near=position_towards_map_center, placement_step=1)\n",
        "org_msg": "Fix documentation - Change self.units to self.structures",
        "sim_msg": "[hail] RegionPool echoes at a doubling size threshold",
        "sim_diff": "diff --git a/hail/src/main/scala/is/hail/annotations/RegionPool.scala b/hail/src/main/scala/is/hail/annotations/RegionPool.scala @@ -20,13 +20,20 @@ final class RegionPool private(strictMemoryCheck: Boolean, threadName: String, t\nprotected[annotations] val freeBlocks: Array[ArrayBuilder[Long]] = Array.fill[ArrayBuilder[Long]](4)(new ArrayBuilder[Long])\nprotected[annotations] val regions = new ArrayBuilder[RegionMemory]()\nprivate val freeRegions = new ArrayBuilder[RegionMemory]()\n-\n- private val nBlocksAllocated: Array[Long] = Array(0L, 0L, 0L, 0L)\n-\n+ private val blocks: Array[Long] = Array(0L, 0L, 0L, 0L)\nprivate var totalAllocatedBytes: Long = 0L\n+ private var allocationEchoThreshold: Long = 8 * 1024 * 1024\ndef getTotalAllocatedBytes: Long = totalAllocatedBytes\n+ private def incrementAllocatedBytes(toAdd: Long): Unit = {\n+ totalAllocatedBytes += toAdd\n+ if (totalAllocatedBytes >= allocationEchoThreshold) {\n+ report(\"REPORT_THRESHOLD\")\n+ allocationEchoThreshold *= 2\n+ }\n+ }\n+\nprotected[annotations] def reclaim(memory: RegionMemory): Unit = {\nfreeRegions += memory\n}\n@@ -36,7 +43,7 @@ final class RegionPool private(strictMemoryCheck: Boolean, threadName: String, t\nif (pool.size > 0) {\npool.pop()\n} else {\n- nBlocksAllocated(size) += 1\n+ blocks(size) += 1\nval blockByteSize = Region.SIZES(size)\ntotalAllocatedBytes += blockByteSize\nMemory.malloc(blockByteSize)\n@@ -90,7 +97,7 @@ final class RegionPool private(strictMemoryCheck: Boolean, threadName: String, t\nval nBlocks = pool.numFreeBlocks()\nval freeBlockCounts = freeBlocks.map(_.size)\n- val usedBlockCounts = nBlocksAllocated.zip(freeBlockCounts).map { case (tot, free) => tot - free }\n+ val usedBlockCounts = blocks.zip(freeBlockCounts).map { case (tot, free) => tot - free }\ninfo(\ns\"\"\"Region count for $context\n| regions: $nRegions active, $nFree free\n@@ -99,10 +106,22 @@ final class RegionPool private(strictMemoryCheck: Boolean, threadName: String, t\n| used: ${ usedBlockCounts.mkString(\", \") }\"\"\".stripMargin)\n}\n+ def report(context: String): Unit = {\n+ var inBlocks = 0L\n+ var i = 0\n+ while (i < 4) {\n+ inBlocks += blocks(i) * Region.SIZES(i)\n+ i += 1\n+ }\n+\n+ log.info(s\"RegionPool: $context: ${readableBytes(totalAllocatedBytes)} allocated (${readableBytes(inBlocks)} blocks / \" +\n+ s\"${readableBytes(totalAllocatedBytes - inBlocks)} chunks), thread $threadID: $threadName\")\n+ }\n+\noverride def finalize(): Unit = close()\ndef close(): Unit = {\n- log.info(s\"freeing RegionPool with $totalAllocatedBytes bytes (${ readableBytes(totalAllocatedBytes) } allocated\")\n+ report(\"FREE\")\nvar i = 0\nwhile (i < regions.size) {\n",
        "chatgpt_cot": "\"Update spawning pool build logic to prevent building more than 1 spawning pool, using structures instead of units for filtering.\""
    },
    {
        "org_diff": "diff --git a/sc2/bot_ai.py b/sc2/bot_ai.py @@ -323,7 +323,7 @@ class BotAI:\nelse:\n# get tags of minerals around expansion\nlocal_minerals_tags = {\n- mineral.tag for mineral in self.mineral_fields if mineral.distance_to(mining_place) <= 8\n+ mineral.tag for mineral in self.state.mineral_field if mineral.distance_to(mining_place) <= 8\n}\n# get all target tags a worker can have\n# tags of the minerals he could mine at that base\n@@ -354,7 +354,7 @@ class BotAI:\n# as long as have workers and mining places\nif deficit_mining_places:\n# choose only mineral fields first if current mineral to gas ratio is less than target ratio\n- if self.vespene and self.minerals / self.vespene > resource_ratio:\n+ if self.vespene and self.minerals / self.vespene < resource_ratio:\npossible_mining_places = [place for place in deficit_mining_places if not place.vespene_contents]\n# else prefer gas\nelse:\n@@ -373,7 +373,7 @@ class BotAI:\n# go to the mineral field that is near and has the most minerals left\nelse:\nlocal_minerals = [\n- mineral for mineral in self.mineral_fields if mineral.distance_to(current_place) <= 8\n+ mineral for mineral in self.state.mineral_field if mineral.distance_to(current_place) <= 8\n]\ntarget_mineral = max(local_minerals, key=lambda mineral: mineral.mineral_contents)\nself.actions.append(worker.gather(target_mineral))\n",
        "org_msg": "Fix wrong variables and comparison in distribute workers",
        "sim_msg": "[cleanup] update multi_cluster.py with latest p2p module",
        "sim_diff": "diff --git a/quarkchain/cluster/multi_cluster.py b/quarkchain/cluster/multi_cluster.py +\"\"\"\n+multi_cluster.py - starts multiple clusters on localhost, and have them inter-connect using either simple network or real p2p\n+Usage:\n+multi_cluster.py accepts the same arguments as cluster.py\n+additional arguments:\n+--num_clusters\n+also note that p2p bootstrap key is fixed to a test value\n+\n+Examples:\n+1. simple network, with one (random) cluster mining\n+python multi_cluster.py --start_simulated_mining\n+2. p2p module, with one (random) cluster mining\n+python multi_cluster.py --p2p --start_simulated_mining\n+\"\"\"\n+\n+\nimport argparse\nimport asyncio\nimport os\n@@ -15,16 +31,31 @@ async def main():\nargs = parser.parse_args()\nclusters = []\nmine_i = random.randint(0, args.num_clusters - 1)\n- if args.mine:\n+ mine = args.start_simulated_mining\n+ if mine:\nprint(\"cluster {} will be mining\".format(mine_i))\nelse:\nprint(\"No one will be mining\")\n- mine = args.mine\n+\ndb_path_root = args.db_path_root\n+ p2p_port = args.p2p_port\nfor i in range(args.num_clusters):\n- args.mine = mine and i == mine_i\n+ args.start_simulated_mining = mine and i == mine_i\nargs.db_path_root = \"{}_C{}\".format(db_path_root, i)\n+ # set up p2p bootstrapping, with fixed bootstrap key for now\n+ if args.p2p:\n+ if i == 0:\n+ args.privkey = (\n+ \"31552f186bf90908ce386fb547dd0410bf443309125cc43fd0ffd642959bf6d9\"\n+ )\n+ else:\n+ args.privkey = \"\"\n+\n+ args.bootnodes = \"enode://c571e0db93d17cc405cb57640826b70588a6a28785f38b21be471c609ca12fcb06cb306ac44872908f5bed99046031a5af82072d484e3ef9029560c1707193a0@127.0.0.1:{}\".format(\n+ p2p_port\n+ )\n+\nconfig = ClusterConfig.create_from_args(args)\nprint(\"Cluster {} config file: {}\".format(i, config.json_filepath))\nprint(config.to_json())\n@@ -37,7 +68,6 @@ async def main():\nargs.port_start += 100\nargs.json_rpc_port += 1\nargs.json_rpc_private_port += 1\n- args.devp2p_port += 1\ntasks = list()\ntasks.append(asyncio.ensure_future(clusters[0].run()))\n",
        "chatgpt_cot": "Fix mineral field reference and resource ratio comparison in BotAI. The modification ensures correct mineral field reference and resource ratio comparison for mining places."
    },
    {
        "org_diff": "diff --git a/.travis.yml b/.travis.yml @@ -8,7 +8,7 @@ env:\n- ROS_DISTRO=\"kinetic\" ROS_REPO=\"ros-shadow-fixed\"\n- ROS_DISTRO=\"kinetic\" ROS_REPO=\"ros\"\n- ROS_DISTRO=\"lunar\" ROS_REPO=\"ros\"\n-before_config:\n+install:\n- git clone https://github.com/ros-industrial/industrial_ci.git .ci_config\nscript:\n- .ci_config/travis.sh\n",
        "org_msg": "CI: never trust the manual",
        "sim_msg": "issue enable a 2->3 Mitogen job.",
        "sim_diff": "diff --git a/.travis.yml b/.travis.yml @@ -32,6 +32,9 @@ matrix:\n# 2.6 -> 2.7\n- python: \"2.6\"\nenv: MODE=mitogen DISTRO=centos7\n+ # 2.6 -> 3.5\n+ - python: \"2.6\"\n+ env: MODE=mitogen DISTRO=debian-py3\n# 3.6 -> 2.6\n- python: \"3.6\"\nenv: MODE=mitogen DISTRO=centos6\n",
        "chatgpt_cot": "\"Update Travis configuration to install dependencies before running the script\""
    },
    {
        "org_diff": "diff --git a/src/api-engine/api/routes/chaincode/views.py b/src/api-engine/api/routes/chaincode/views.py @@ -243,6 +243,77 @@ class ChainCodeViewSet(viewsets.ViewSet):\nok(\"success\"), status=status.HTTP_200_OK\n)\n+ @swagger_auto_schema(\n+ method=\"get\",\n+ responses=with_common_response(\n+ {status.HTTP_201_CREATED: ChainCodeIDSerializer}\n+ ),\n+ )\n+ @action(detail=False, methods=['get'])\n+ def query_approved(self, request):\n+ try:\n+ org = request.user.organization\n+ peer_node = Node.objects.get(type=\"peer\", organization=org.id)\n+ envs = init_env_vars(peer_node, org)\n+\n+ channel_name = request.data.get(\"channel_name\")\n+ cc_name = request.data.get(\"cc_name\")\n+\n+ peer_channel_cli = PeerChainCode(\"v2.2.0\", **envs)\n+ code, content = peer_channel_cli.lifecycle_query_approved(channel_name, cc_name)\n+ if code != 0:\n+ return Response(err(\"query_approved failed.\"), status=status.HTTP_400_BAD_REQUEST)\n+\n+ except Exception as e:\n+ return Response(\n+ err(e.args), status=status.HTTP_400_BAD_REQUEST\n+ )\n+ return Response(\n+ ok(content), status=status.HTTP_200_OK\n+ )\n+\n+ @swagger_auto_schema(\n+ method=\"post\",\n+ responses=with_common_response(\n+ {status.HTTP_201_CREATED: ChainCodeIDSerializer}\n+ ),\n+ )\n+ @action(detail=False, methods=['post'])\n+ def check_commit_readiness(self, request):\n+ serializer = ChainCodeApproveForMyOrgBody(data=request.data)\n+ if serializer.is_valid(raise_exception=True):\n+ try:\n+ channel_name = serializer.validated_data.get(\"channel_name\")\n+ chaincode_name = serializer.validated_data.get(\"chaincode_name\")\n+ chaincode_version = serializer.validated_data.get(\"chaincode_version\")\n+ policy = serializer.validated_data.get(\"policy\")\n+ # Perhaps the orderer's port is best stored in the database\n+ orderer_url = serializer.validated_data.get(\"orderer_url\")\n+ sequence = serializer.validated_data.get(\"sequence\")\n+ org = request.user.organization\n+ orderer_node = Node.objects.get(type=\"orderer\", organization=org.id)\n+\n+ orderer_tls_dir = \"{}/{}/crypto-config/ordererOrganizations/{}/orderers/{}/msp/tlscacerts\" \\\n+ .format(CELLO_HOME, org.name, org.name.split(\".\", 1)[1], orderer_node.name + \".\" +\n+ org.name.split(\".\", 1)[1])\n+\n+ peer_node = Node.objects.get(type=\"peer\", organization=org.id)\n+ envs = init_env_vars(peer_node, org)\n+\n+ peer_channel_cli = PeerChainCode(\"v2.2.0\", **envs)\n+ code, content = peer_channel_cli.lifecycle_check_commit_readiness(orderer_url, orderer_tls_dir, channel_name, chaincode_name, chaincode_version,\n+ policy, sequence)\n+ if code != 0:\n+ return Response(err(\"check_commit_readiness failed.\"), status=status.HTTP_400_BAD_REQUEST)\n+\n+ except Exception as e:\n+ return Response(\n+ err(e.args), status=status.HTTP_400_BAD_REQUEST\n+ )\n+ return Response(\n+ ok(content), status=status.HTTP_200_OK\n+ )\n+\ndef init_env_vars(node, org):\n\"\"\"\n",
        "org_msg": "[#issue-395] implement query_approved and check_commit_readiness function\nimplement query_approved and check_commit_readiness function of chaincode.\nClose",
        "sim_msg": "Add validation checks for the PurchaseOrderLineItem serializer",
        "sim_diff": "diff --git a/InvenTree/order/serializers.py b/InvenTree/order/serializers.py @@ -164,8 +164,23 @@ class POLineItemSerializer(InvenTreeModelSerializer):\nif order_detail is not True:\nself.fields.pop('order_detail')\n- quantity = serializers.FloatField(default=1)\n- received = serializers.FloatField(default=0)\n+ quantity = serializers.FloatField(min_value=0, required=True)\n+\n+ def validate_quantity(self, quantity):\n+\n+ if quantity <= 0:\n+ raise ValidationError(_(\"Quantity must be greater than zero\"))\n+\n+ return quantity\n+\n+ def validate_purchase_order(self, purchase_order):\n+\n+ if purchase_order.status not in PurchaseOrderStatus.OPEN:\n+ raise ValidationError(_('Order is not open'))\n+\n+ return purchase_order\n+\n+ received = serializers.FloatField(default=0, read_only=True)\noverdue = serializers.BooleanField(required=False, read_only=True)\n@@ -189,6 +204,22 @@ class POLineItemSerializer(InvenTreeModelSerializer):\norder_detail = POSerializer(source='order', read_only=True, many=False)\n+ def validate(self, data):\n+\n+ data = super().validate(data)\n+\n+ supplier_part = data['part']\n+ purchase_order = data['order']\n+\n+ # Check that the supplier part and purchase order match\n+ if supplier_part is not None and supplier_part.supplier != purchase_order.supplier:\n+ raise ValidationError({\n+ 'part': _('Supplier must match purchase order'),\n+ 'order': _('Purchase order must match supplier'),\n+ })\n+\n+ return data\n+\nclass Meta:\nmodel = order.models.PurchaseOrderLineItem\n@@ -349,7 +380,7 @@ class POReceiveSerializer(serializers.Serializer):\nSerializer for receiving items against a purchase order\n\"\"\"\n- items = POLineItemReceiveSerializer(many=True)\n+ items = POLineItemReceiveSerializer(many=True, required=True)\nlocation = serializers.PrimaryKeyRelatedField(\nqueryset=stock.models.StockLocation.objects.all(),\n",
        "chatgpt_cot": "Add two new methods to the ChainCodeViewSet class for query_approved and check_commit_readiness, and handle exceptions for errors."
    },
    {
        "org_diff": "diff --git a/sc2/bot_ai.py b/sc2/bot_ai.py @@ -442,7 +442,7 @@ class BotAI(object):\ndef _prepare_step(self, state):\n\"\"\"Set attributes from new state before on_step.\"\"\"\nself.state: GameState = state\n- # need this for checking for new units\n+ # Required for events\nself._units_previous_map.clear()\nfor unit in self.units:\nself._units_previous_map[unit.tag] = unit\n@@ -458,31 +458,48 @@ class BotAI(object):\nself.supply_cap: Union[float, int] = state.common.food_cap\nself.supply_left: Union[float, int] = self.supply_cap - self.supply_used\n- def issue_events(self):\n- self._issue_unit_dead_events()\n- self._issue_unit_added_events()\n+ async def issue_events(self):\n+ \"\"\" Run this in your bot class to trigger event functions:\n+ - on_unit_created\n+ - on_unit_destroyed\n+ - on_building_construction_complete\n+ \"\"\"\n+ await self._issue_unit_dead_events()\n+ await self._issue_unit_added_events()\nfor unit in self.units:\n- self._issue_building_complete_event(unit)\n+ await self._issue_building_complete_event(unit)\n- def _issue_unit_added_events(self):\n+ async def _issue_unit_added_events(self):\nfor unit in self.units:\nif unit.tag not in self._units_previous_map:\n- self.on_unit_created(unit)\n+ await self.on_unit_created(unit)\n- def _issue_building_complete_event(self, unit):\n+ async def _issue_building_complete_event(self, unit):\nif unit.build_progress < 1:\nreturn\nif unit.tag not in self._units_previous_map:\nreturn\nunit_prev = self._units_previous_map[unit.tag]\nif unit_prev.build_progress < 1:\n- self.on_building_construction_complete(unit)\n+ await self.on_building_construction_complete(unit)\n- def _issue_unit_dead_events(self):\n+ async def _issue_unit_dead_events(self):\nevent = self.state.observation.raw_data.event\nif event is not None:\nfor tag in event.dead_units:\n- self.on_unit_destroyed(tag)\n+ await self.on_unit_destroyed(tag)\n+\n+ async def on_unit_destroyed(self, unit_tag):\n+ \"\"\" Override this in your bot class. \"\"\"\n+ pass\n+\n+ async def on_unit_created(self, unit):\n+ \"\"\" Override this in your bot class. \"\"\"\n+ pass\n+\n+ async def on_building_construction_complete(self, unit):\n+ \"\"\" Override this in your bot class. \"\"\"\n+ pass\ndef on_start(self):\n\"\"\"Allows initializing the bot when the game data is available.\"\"\"\n@@ -493,22 +510,9 @@ class BotAI(object):\nraise NotImplementedError\ndef on_end(self, game_result):\n- \"\"\"Ran on on end of a game.\"\"\"\n+ \"\"\"Ran at the end of a game.\"\"\"\npass\n- def on_unit_destroyed(self, unit_tag):\n- \"\"\" Override this in your bot class \"\"\"\n- pass\n-\n- def on_unit_created(self, unit):\n- \"\"\" Override this in your bot class \"\"\"\n- pass\n-\n- def on_building_construction_complete(self, unit):\n- \"\"\" Override this in your bot class \"\"\"\n- pass\n-\n-\nclass CanAffordWrapper(object):\ndef __init__(self, can_afford_minerals, can_afford_vespene, have_enough_supply):\nself.can_afford_minerals = can_afford_minerals\n",
        "org_msg": "Make events async",
        "sim_msg": "prepare for messy merge",
        "sim_diff": "diff --git a/bot_manager.py b/bot_manager.py @@ -38,6 +38,7 @@ class BotManager:\ndef __init__(self, terminateEvent, callbackEvent, config_file, name, team, index, modulename, gamename, savedata, server_manager):\nself.terminateEvent = terminateEvent\nself.callbackEvent = callbackEvent\n+ self.config_file = config_file\nself.name = name\nself.team = team\nself.index = index\n@@ -47,7 +48,6 @@ class BotManager:\nself.input_converter = input_formatter.InputFormatter(team, index)\nself.frames = 0\nself.file_number = 1\n- self.config_file = config_file\nself.server_manager = server_manager\nself.input_array = np.array([])\nself.output_array = np.array([])\n",
        "chatgpt_cot": "Add async and await to issue_events method in BotAI to trigger event functions and fix compilation errors in bot_ai.py."
    },
    {
        "org_diff": "diff --git a/sc2/cache.py b/sc2/cache.py @@ -17,19 +17,26 @@ def property_cache_forever(f):\ndef property_cache_once_per_frame(f):\n\"\"\" This decorator caches the return value for one game loop, then clears it if it is accessed in a different game loop\nOnly works on properties of the bot object because it requires access to self.state.game_loop \"\"\"\n- f.frame = -1\n- f.cache = None\n-\n@wraps(f)\ndef inner(self):\n- if f.cache is None or f.frame != self.state.game_loop:\n- f.cache = f(self)\n- f.frame = self.state.game_loop\n- if type(f.cache).__name__ == \"Units\":\n- return f.cache.copy()\n- if isinstance(f.cache, (list, set, dict, Counter)):\n- return f.cache.copy()\n- return f.cache\n+ property_cache = \"_cache_\" + f.__name__\n+ state_cache = \"_frame_\" + f.__name__\n+ cache_updated = (\n+ hasattr(self, property_cache) and\n+ getattr(self, state_cache, None) == self.state.game_loop\n+ )\n+ if not cache_updated:\n+ setattr(self, property_cache, f(self))\n+ setattr(self, state_cache, self.state.game_loop)\n+\n+ cache = getattr(self, property_cache)\n+ should_copy = (\n+ type(cache).__name__ == \"Units\" or\n+ isinstance(cache, (list, set, dict, Counter))\n+ )\n+ if should_copy:\n+ return cache.copy()\n+ return cache\nreturn property(inner)\n",
        "org_msg": "Roll back property_cache_once_per_frame",
        "sim_msg": "self_memoized: new memoization helper\nTN:",
        "sim_diff": "diff --git a/langkit/utils.py b/langkit/utils.py @@ -164,6 +164,37 @@ def memoized(func):\nreturn wrapper\n+def self_memoized(func):\n+ \"\"\"\n+ Like `memoized`, but specific to instance methods and offers a\n+ instance-specific reset switch.\n+\n+ :param func: The instance method to decorate.\n+ \"\"\"\n+\n+ cache_name = '_cache_{}'.format(func.__name__)\n+\n+ def wrapper(self, *args, **kwargs):\n+ # Install the self-specific cache, if needed\n+ cache = getattr(self, cache_name, {})\n+ setattr(self, cache_name, cache)\n+\n+ key = (args, tuple(kwargs.items()))\n+ try:\n+ result = cache[key]\n+ except KeyError:\n+ result = func(self, *args, **kwargs)\n+ cache[key] = result\n+ return result\n+\n+ def reset(self):\n+ setattr(self, cache_name, {})\n+\n+ wrapper.reset = reset\n+\n+ return wrapper\n+\n+\ndef reset_memoized():\nfor cache in getattr(memoized, \"caches\", []):\ncache.clear()\n",
        "chatgpt_cot": "\"Add property caching functionality for game loop in cache.py\""
    },
    {
        "org_diff": "diff --git a/src/agent/ansible/vars/aws.yml b/src/agent/ansible/vars/aws.yml auth: {\nauth_url: \"\",\n# This should be your AWS Access Key ID\n- username: \"AKIAJY32VWHYOFOR4J7Q\",\n+ username: \"{{ username | default(lookup('env', 'AWS_ACCESS_KEY_ID')) }}\",\n# This should be your AWS Secret Access Key\n# can be passed as part of cmd line when running the playbook\npassword: \"{{ password | default(lookup('env', 'AWS_SECRET_KEY')) }}\"\n",
        "org_msg": "Fixes hard-coded AWS credentials\nReads AWS_ACCESS_KEY id from env vars,\nreplacing the hardcoded creds in aws.yaml",
        "sim_msg": "Use state \"present\" instead of \"installed\"\nThe latter is deprecated and due to be removed in Ansible v2.9.",
        "sim_diff": "diff --git a/ansible/roles/setup/tasks/main.yml b/ansible/roles/setup/tasks/main.yml become: yes\napt:\npkg: apt-transport-https\n- state: installed\n+ state: present\n- name: Add NodeSource apt signing key\nbecome: yes\nbecome: yes\napt:\npkg: \"{{ item }}\"\n- state: installed\n+ state: present\nwith_items:\n- apt-transport-https\n- ca-certificates\nbecome: yes\napt:\npkg: \"{{item}}\"\n- state: installed\n+ state: present\nwith_items:\n- nodejs\nbecome: yes\napt:\npkg: \"{{ item }}\"\n- state: installed\n+ state: present\nwith_items:\n- postgresql-9.5-postgis-2.2\n- postgresql-server-dev-9.5 # required for building pyscopg against correct postgres\n",
        "chatgpt_cot": "\"Update AWS credentials in ansible vars file to use environment variables for username and password.\""
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/editor/xmlformatter.py b/node_manager_fkie/src/node_manager_fkie/editor/xmlformatter.py @@ -55,7 +55,7 @@ class Formatter():\n# Use internal encoding:\nencoding_internal = None\n- def __init__(self, indent = DEFAULT_INDENT, preserve = [], compress = DEFAULT_COMPRESS, indent_char = DEFAULT_INDENT_CHAR, encoding_input = DEFAULT_ENCODING_INPUT, encoding_output = DEFAULT_ENCODING_OUTPUT, inline = DEFAULT_INLINE, correct = DEFAULT_CORRECT, noemptytag = DEFAULT_NOEMPTYTAG, emptyattr = DEFAULT_EMPTYATTR, indent_data = DEFAULT_INDENT_DATA):\n+ def __init__(self, indent = DEFAULT_INDENT, preserve = [], compress = DEFAULT_COMPRESS, indent_char = DEFAULT_INDENT_CHAR, encoding_input = DEFAULT_ENCODING_INPUT, encoding_output = DEFAULT_ENCODING_OUTPUT, inline = DEFAULT_INLINE, correct = DEFAULT_CORRECT, noemptytag = DEFAULT_NOEMPTYTAG, emptyattr = DEFAULT_EMPTYATTR, indent_data = DEFAULT_INDENT_DATA, wraped = ['node', 'group', 'include']):\n# Minify the XML document:\nself.compress = compress\n# Allow self closing tag also it not compress\n@@ -78,6 +78,8 @@ class Formatter():\nself.inline = inline\n# Don't compress this elements and their descendants:\nself.preserve = preserve\n+ # Insert new line before this elements\n+ self.wraped = wraped\n@property\ndef encoding_effective(self, enc = None):\n@@ -673,6 +675,8 @@ class Formatter():\ndef __unicode__(self):\nstr = \"\"\n+ if self.arg[0] in self.formatter.wraped:\n+ str += \"\\n\"\nif (self.preserve in [0, 1] and self.indent):\nstr += self.indent_insert()\nstr += \"<%s\" %self.arg[0]\n",
        "org_msg": "node_manager_fkie: added a new line before node, group and include on formating XML",
        "sim_msg": "Clean up xmlwriter constructor",
        "sim_diff": "diff --git a/gaphor/storage/xmlwriter.py b/gaphor/storage/xmlwriter.py -import sys\nimport xml.sax.handler\nfrom typing import Dict, List, Tuple\nfrom xml.sax.saxutils import escape, quoteattr\n@@ -15,15 +14,13 @@ except ImportError:\nclass XMLWriter(xml.sax.handler.ContentHandler):\n- def __init__(self, out=None, encoding=None):\n- if out is None:\n- out = sys.stdout\n- xml.sax.handler.ContentHandler.__init__(self)\n+ def __init__(self, out, encoding=\"utf-8\"):\n+ super().__init__()\nself._out = out\n+ self._encoding = encoding\nself._ns_contexts: List[Dict[str, str]] = [{}] # contains uri -> prefix dicts\nself._current_context = self._ns_contexts[-1]\nself._undeclared_ns_maps: List[Tuple[str, str]] = []\n- self._encoding = encoding or sys.getdefaultencoding()\nself._in_cdata = False\nself._in_start_tag = False\n",
        "chatgpt_cot": "\"Add new attribute 'wraped' and insert new line before the specified elements in XML formatter.\""
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/master_view_proxy.py b/node_manager_fkie/src/node_manager_fkie/master_view_proxy.py @@ -557,11 +557,13 @@ class MasterViewProxy(QWidget):\n'''\nreturn self.node_tree_model.getNode(\"%s\" % node_name, self.masteruri)\n- def updateButtons(self):\n+ def updateButtons(self, selected_nodes=None):\n'''\nUpdates the enable state of the buttons depending of the selection and\nrunning state of the selected node.\n'''\n+ selectedNodes = selected_nodes\n+ if selectedNodes is None:\nselectedNodes = self.nodesFromIndexes(self.masterTab.nodeTreeView.selectionModel().selectedIndexes())\nhas_running = False\nhas_stopped = False\n@@ -1174,6 +1176,8 @@ class MasterViewProxy(QWidget):\n@param index: The index of the activated node\n@type index: U{QtCore.QModelIndex<https://srinikom.github.io/pyside-docs/PySide/QtCore/QModelIndex.html>}\n'''\n+ selectedNodes = []\n+ if index.column() == 0:\nselectedNodes = self.nodesFromIndexes(self.masterTab.nodeTreeView.selectionModel().selectedIndexes(), False)\nif not selectedNodes:\nreturn\n@@ -1397,7 +1401,7 @@ class MasterViewProxy(QWidget):\nif (self._is_current_tab_name('tabNodes') and self.__last_info_text != text) or force_emit:\nself.__last_info_text = text\nself.description_signal.emit(name, text, True if selected or deselected or force_emit else False)\n- self.updateButtons()\n+ self.updateButtons(selectedNodes)\ndef get_node_description(self, node_name, node=None):\ntext = ''\n",
        "org_msg": "node_manager_fkie: reduced update count",
        "sim_msg": "Added docstrings, fixed issue with RMB and previous selection",
        "sim_diff": "diff --git a/avalon/tools/cbsceneinventory/app.py b/avalon/tools/cbsceneinventory/app.py @@ -133,10 +133,19 @@ class View(QtWidgets.QTreeView):\npipeline.is_compatible_inventory_action(p, containers)],\nkey=sorter)\n- def process_custom_action(self, Action, items):\n+ def process_custom_action(self, Action, containers):\n+ \"\"\"Run action and if results are returned update the view\n+\n+ Args:\n+ Action (InventoryAction): Inventory Action module\n+ containers (list): Data of currently selected items\n+\n+ Returns:\n+ None\n+ \"\"\"\naction = Action()\n- result = action.process(items)\n+ result = action.process(containers)\nif result:\nself.data_changed.emit()\n@@ -149,7 +158,7 @@ class View(QtWidgets.QTreeView):\n# move index under mouse\nindices = self.get_indices()\n- if not active.parent().isValid():\n+ if active not in indices:\nassert active in indices, \"No active item found in the selection\"\n# Push the active one as *last* to selected\n",
        "chatgpt_cot": "\"Add method to update buttons and fix compilation issue with selectedNodes parameter in MasterViewProxy.py\""
    },
    {
        "org_diff": "diff --git a/test/test_pickled_data.py b/test/test_pickled_data.py @@ -104,8 +104,6 @@ class TestClass:\n# Test bot_ai functions\nassert bot.time == 0\nassert bot.time_formatted in {\"0:00\", \"00:00\"}\n- assert bot.nuke_detected is False\n- assert bot.nydus_detected is False\nassert bot.start_location is None # Is populated by main.py\nbot._game_info.player_start_location = bot.townhalls.random.position\nassert bot.townhalls.random.position not in bot.enemy_start_locations\n",
        "org_msg": "remove alert tests",
        "sim_msg": "tests: stubs for future whitelist/blacklist tests.",
        "sim_diff": "diff --git a/tests/responder_test.py b/tests/responder_test.py @@ -78,5 +78,19 @@ class BrokenModulesTest(unittest2.TestCase):\nself.assertIsInstance(msg.unpickle(), tuple)\n+class BlacklistTest(unittest.TestCase):\n+ def test_whitelist_no_blacklist(self):\n+ assert 0\n+\n+ def test_whitelist_has_blacklist(self):\n+ assert 0\n+\n+ def test_blacklist_no_whitelist(self):\n+ assert 0\n+\n+ def test_blacklist_has_whitelist(self):\n+ assert 0\n+\n+\nif __name__ == '__main__':\nunittest2.main()\n",
        "chatgpt_cot": "\"Remove unnecessary assertions and update test for pickled data in test_pickled_data.py\""
    },
    {
        "org_diff": "diff --git a/fkie_node_manager/src/fkie_node_manager/MainWindow.ui b/fkie_node_manager/src/fkie_node_manager/MainWindow.ui <property name=\"windowTitle\">\n<string>ROS Node Manager</string>\n</property>\n- <property name=\"toolTip\">\n- <string>Go to the root of the help</string>\n- </property>\n<property name=\"locale\">\n<locale language=\"English\" country=\"UnitedStates\"/>\n</property>\n@@ -808,8 +805,12 @@ p, li { white-space: pre-wrap; }\n<height>26</height>\n</size>\n</property>\n+ <property name=\"toolTip\">\n+ <string>Go to the root of the help</string>\n+ </property>\n<property name=\"icon\">\n- <iconset theme=\"go-home\"/>\n+ <iconset theme=\"go-home\">\n+ <normaloff>.</normaloff>.</iconset>\n</property>\n<property name=\"flat\">\n<bool>true</bool>\n@@ -834,7 +835,8 @@ p, li { white-space: pre-wrap; }\n<string>Go back in history</string>\n</property>\n<property name=\"icon\">\n- <iconset theme=\"go-previous\"/>\n+ <iconset theme=\"go-previous\">\n+ <normaloff>.</normaloff>.</iconset>\n</property>\n<property name=\"flat\">\n<bool>true</bool>\n@@ -859,7 +861,8 @@ p, li { white-space: pre-wrap; }\n<string>Go forward in history</string>\n</property>\n<property name=\"icon\">\n- <iconset theme=\"go-next\"/>\n+ <iconset theme=\"go-next\">\n+ <normaloff>.</normaloff>.</iconset>\n</property>\n<property name=\"flat\">\n<bool>true</bool>\n",
        "org_msg": "fkie_node_manager: fixed tooltip",
        "sim_msg": "Make info icon a bit more subtle",
        "sim_diff": "diff --git a/gaphor/UML/classes/propertypages.glade b/gaphor/UML/classes/propertypages.glade @@ -91,14 +91,11 @@ renderers and such.</property>\n<child>\n<object class=\"GtkEventBox\" id=\"head-info-icon\">\n<property name=\"visible\">1</property>\n- <property name=\"can_focus\">1</property>\n- <property name=\"receives_default\">1</property>\n+ <property name=\"valign\">start</property>\n<signal name=\"button-release-event\" handler=\"head-info-clicked\" swapped=\"no\"/>\n<child>\n<object class=\"GtkImage\">\n<property name=\"visible\">1</property>\n- <property name=\"margin-start\">6</property>\n- <property name=\"margin-end\">6</property>\n<property name=\"icon-name\">info-symbolic</property>\n</object>\n</child>\n@@ -237,14 +234,11 @@ renderers and such.</property>\n<child>\n<object class=\"GtkEventBox\" id=\"tail-info-icon\">\n<property name=\"visible\">1</property>\n- <property name=\"can_focus\">1</property>\n- <property name=\"receives_default\">1</property>\n+ <property name=\"valign\">start</property>\n<signal name=\"button-release-event\" handler=\"tail-info-clicked\" swapped=\"no\"/>\n<child>\n<object class=\"GtkImage\">\n<property name=\"visible\">1</property>\n- <property name=\"margin-start\">6</property>\n- <property name=\"margin-end\">6</property>\n<property name=\"icon-name\">info-symbolic</property>\n</object>\n</child>\n@@ -403,12 +397,11 @@ Use &lt;b&gt;-&lt;/b&gt;/&lt;b&gt;=&lt;/b&gt; to move items up or down.</propert\n<child>\n<object class=\"GtkEventBox\" id=\"attributes-info-icon\">\n<property name=\"visible\">1</property>\n+ <property name=\"valign\">start</property>\n<signal name=\"button-release-event\" handler=\"attributes-info-clicked\" swapped=\"no\"/>\n<child>\n<object class=\"GtkImage\">\n<property name=\"visible\">1</property>\n- <property name=\"margin-start\">6</property>\n- <property name=\"margin-end\">6</property>\n<property name=\"icon-name\">info-symbolic</property>\n</object>\n</child>\n@@ -685,12 +678,11 @@ Use &lt;b&gt;-&lt;/b&gt;/&lt;b&gt;=&lt;/b&gt; to move items up or down.</propert\n<child>\n<object class=\"GtkEventBox\" id=\"operations-info-icon\">\n<property name=\"visible\">1</property>\n+ <property name=\"valign\">start</property>\n<signal name=\"button-release-event\" handler=\"operations-info-clicked\" swapped=\"no\"/>\n<child>\n<object class=\"GtkImage\">\n<property name=\"visible\">1</property>\n- <property name=\"margin-start\">6</property>\n- <property name=\"margin-end\">6</property>\n<property name=\"icon-name\">info-symbolic</property>\n</object>\n</child>\n@@ -838,12 +830,11 @@ Use &lt;b&gt;-&lt;/b&gt;/&lt;b&gt;=&lt;/b&gt; to move items up or down.</propert\n<child>\n<object class=\"GtkEventBox\" id=\"enumerations-info-icon\">\n<property name=\"visible\">1</property>\n+ <property name=\"valign\">start</property>\n<signal name=\"button-release-event\" handler=\"enumerations-info-clicked\" swapped=\"no\"/>\n<child>\n<object class=\"GtkImage\">\n<property name=\"visible\">1</property>\n- <property name=\"margin-start\">6</property>\n- <property name=\"margin-end\">6</property>\n<property name=\"icon-name\">info-symbolic</property>\n</object>\n</child>\n",
        "chatgpt_cot": "Update tool tip and iconset themes in MainWindow.ui for better user experience. Fixing tool tip duplication and improving iconset themes for navigation buttons."
    },
    {
        "org_diff": "diff --git a/sc2/bot_ai.py b/sc2/bot_ai.py @@ -872,6 +872,7 @@ class BotAI(DistanceCalculation):\nmax_distance: int = 20,\nrandom_alternative: bool = True,\nplacement_step: int = 2,\n+ addon_place: bool = False,\n) -> Optional[Point2]:\n\"\"\" Finds a placement location for building.\n@@ -896,6 +897,7 @@ class BotAI(DistanceCalculation):\nbuilding = self._game_data.abilities[building.value]\nif await self.can_place(building, near):\n+ if not addon_place or await self.can_place(UnitTypeId.SUPPLYDEPOT, near.offset((2.5, -0.5))):\nreturn near\nif max_distance == 0:\n@@ -913,6 +915,14 @@ class BotAI(DistanceCalculation):\n]\nres = await self._client.query_building_placement(building, possible_positions)\npossible = [p for r, p in zip(res, possible_positions) if r == ActionResult.Success]\n+\n+ if addon_place:\n+ res = await self._client.query_building_placement(\n+ self._game_data.units[UnitTypeId.SUPPLYDEPOT.value].creation_ability,\n+ [p.offset((2.5, -0.5)) for p in possible]\n+ )\n+ possible = [p for r, p in zip(res, possible) if r == ActionResult.Success]\n+\nif not possible:\ncontinue\n",
        "org_msg": "Add addon_place option in find_placement\nWith this option finds placement with free space for add-on",
        "sim_msg": "Forgot to update iNumPlayers",
        "sim_diff": "diff --git a/v3/runner.py b/v3/runner.py @@ -63,6 +63,8 @@ if __name__ == '__main__':\ncallbacks = []\nname_dict = dict()\n+ gameInputPacket.iNumPlayers = num_bots\n+\n# Set configuration values for bots and store name and team\nfor i in range(num_bots):\nbot_config = configparser.RawConfigParser()\n",
        "chatgpt_cot": "Add addon placement functionality to building placement method in BotAI class. Fixes issue with checking placement for supply depots."
    },
    {
        "org_diff": "diff --git a/fkie_master_sync/nodes/param_sync.py b/fkie_master_sync/nodes/param_sync.py @@ -8,7 +8,7 @@ from fkie_master_discovery.common import masteruri_from_master\nfrom fkie_multimaster_msgs.msg import MasterState\ndef master_changed(msg, cb_args):\n- param_cache, local_master, __add_ns = cb_args\n+ param_cache, local_master, __add_ns, __ignore, __only = cb_args\nlocal_name = ''\nif local_master:\nlocal_name = local_master[0]\n@@ -16,20 +16,32 @@ def master_changed(msg, cb_args):\nmaster_to = rospy.MasterProxy(masteruri_from_master())\nmaster_from = rospy.MasterProxy(msg.master.uri)\nrospy.logdebug(\"Getting params from {}...\".format(msg.master.uri))\n- params_from = master_from['/']\n- rospy.logdebug(\"Got {} params.\".format(len(msg.master.uri)))\n- if local_name in params_from:\n- del params_from[local_name]\n- if '/'+local_name in params_from:\n- del params_from['/'+local_name]\n+ params_from = master_from.getParam('/')[2]\n+ if not __add_ns:\n+ for key in ['run_id', 'rosversion', 'roslaunch', 'rosdistro', 'master_sync', 'master_discovery', 'capabilities', 'mastername', 'robots']:\n+ try:\n+ del params_from[key]\n+ except Exception:\n+ pass\n+ for key in __ignore + [local_name, '/'+local_name]:\n+ try:\n+ del params_from[key]\n+ except Exception:\n+ pass\n+ if __only:\n+ for key in params_from.keys():\n+ if key not in __only:\n+ del params_from[key]\nrospy.logdebug(\"Syncing params from {} to {}...\".format(msg.master.name, local_name))\nif __add_ns:\n_ns = msg.master.name\nelse:\n_ns = ''\n+ rospy.logdebug(\"Got {} params.\".format(len(params_from)))\nif param_cache.get(_ns, None) != params_from:\nparam_cache[_ns] = params_from\n- master_to['/'+_ns] = params_from\n+ for key, value in params_from.items():\n+ master_to.setParam('/'+_ns+key, value)\nrospy.logdebug(\"Done syncing params from {} to {}.\".format(msg.master.name, local_name))\nelse:\nrospy.logdebug(\"Params have not changed from {} to {}.\".format(msg.master.name, local_name))\n@@ -38,8 +50,8 @@ def master_changed(msg, cb_args):\nlocal_master.append(local_name)\nmaster_from = rospy.MasterProxy(msg.master.uri)\nrospy.logdebug(\"Getting params from local {}...\".format(msg.master.uri))\n- param_cache[local_name] = master_from['/']\n- rospy.logdebug(\"Got {} params.\".format(len(msg.master.uri)))\n+ param_cache[local_name] = master_from.getParam('/')[2]\n+ rospy.logdebug(\"Got {} local params.\".format(len(param_cache[local_name])))\ndef main():\n@@ -50,7 +62,9 @@ def main():\nmasteruri_from_master()\n__add_ns = rospy.get_param('~add_ns', True)\n- sub = rospy.Subscriber('master_discovery/changes', MasterState, master_changed, callback_args=(param_cache, local_master, __add_ns))\n+ __ignore = rospy.get_param('~ignore', [])\n+ __only = rospy.get_param('~only', [])\n+ sub = rospy.Subscriber('master_discovery/changes', MasterState, master_changed, callback_args=(param_cache, local_master, __add_ns, __ignore, __only))\nrospy.spin()\n",
        "org_msg": "fixed param sync",
        "sim_msg": "don't flood the loop with a ton of tasks",
        "sim_diff": "diff --git a/GearBot/Cogs/ModLog.py b/GearBot/Cogs/ModLog.py @@ -64,23 +64,30 @@ class ModLog:\nlogged.save()\neditCount = editCount + 1\ncount = count + 1\n- if count % 50 is 0:\n+ if count % 25 is 0:\nawait asyncio.sleep(0)\nGearbotLogging.info(f\"Discovered {newCount} new messages and {editCount} edited in {guild.name} (checked {count})\")\n- if startup:\n- self.to_cache -= 1\n- if self.to_cache is 0:\n- await self.cache_message.edit(content=f\"{Emoji.get_chat_emoji('YES')} Modlog cache validation completed in {round(time.perf_counter() - self.cache_start, 2)}s\")\nasync def prep(self):\nself.cache_message = await GearbotLogging.logToBotlog(f\"{Emoji.get_chat_emoji('REFRESH')} Validating modlog cache\")\n- self.to_cache = 0\n+ self.to_cache = []\nfor guild in self.bot.guilds:\nif Configuration.getConfigVar(guild.id, \"MINOR_LOGS\") is not 0:\n- self.to_cache += 1\n- self.bot.loop.create_task(self.buildCache(guild, startup=True))\n+ self.to_cache.append(guild)\n+ for i in range(min(3, len(self.bot.guilds))):\n+ self.bot.loop.create_task(self.startup_cache())\nself.cache_start = time.perf_counter()\n+ async def startup_cache(self):\n+ while self.to_cache is not None:\n+ if len(self.to_cache) > 0:\n+ guild = self.to_cache.pop()\n+ await self.buildCache(guild, startup=True)\n+ else:\n+ self.to_cache = None\n+ await self.cache_message.edit(content=f\"{Emoji.get_chat_emoji('YES')} Modlog cache validation completed in {round(time.perf_counter() - self.cache_start, 2)}s\")\n+\n+\nasync def on_message(self, message: discord.Message):\nif not hasattr(message.channel, \"guild\") or message.channel.guild is None:\nreturn\n",
        "chatgpt_cot": "Add parameters __ignore and __only, improve parameter handling in master_changed function, and enhance syncing functionality for params in param_sync.py."
    },
    {
        "org_diff": "diff --git a/sc2/client.py b/sc2/client.py @@ -23,6 +23,7 @@ from .data import Race, ActionResult, ChatChannel\nfrom .action import combine_actions\nfrom .position import Point2, Point3\nfrom .unit import Unit\n+from .units import Units\nfrom typing import List, Dict, Set, Tuple, Any, Optional, Union # mypy type checking\nclass Client(Protocol):\n@@ -258,6 +259,17 @@ class Client(Protocol):\n)) for unit_type, amount_of_units, position, owner_id in unit_spawn_commands]\n))\n+ async def debug_kill_unit(self, unit_tags: Union[Units, List[int], Set[int]]):\n+ if isinstance(unit_tags, Units):\n+ unit_tags = unit_tags.tags\n+ assert len(unit_tags) > 0\n+\n+ await self._execute(debug=sc_pb.RequestDebug(\n+ debug=[debug_pb.DebugCommand(kill_unit=debug_pb.DebugKillUnit(\n+ tag=unit_tags\n+ ))]\n+ ))\n+\nasync def move_camera(self, position: Union[Unit, Point2, Point3]):\n\"\"\" Moves camera to the target position \"\"\"\nassert isinstance(position, (Unit, Point2, Point3))\n@@ -363,18 +375,10 @@ class Client(Protocol):\n\"\"\" Helper function for color conversion \"\"\"\nif color is None:\nreturn debug_pb.Color(r=255, g=255, b=255)\n- else:\n- if isinstance(color, (tuple, list)):\n- assert(len(color) == 3)\n-\n- r = color[0]\n- g = color[1]\n- b = color[2]\nelse:\nr = getattr(color, \"r\", getattr(color, \"x\", 255))\ng = getattr(color, \"g\", getattr(color, \"y\", 255))\nb = getattr(color, \"b\", getattr(color, \"z\", 255))\n-\nif max(r, g, b) <= 1:\nr *= 255\ng *= 255\n",
        "org_msg": "Add debug_unit_function",
        "sim_msg": "Grid Client Small changes\nRemove proxy/unproxy methods\nADD load method\nAdd user_key optional parameter",
        "sim_diff": "diff --git a/src/syft/grid/client/client.py b/src/syft/grid/client/client.py from typing import Any\nfrom typing import Dict\nfrom typing import Optional\n+from typing import Type\nfrom typing import Union\n# third party\n@@ -24,8 +25,10 @@ from ...core.node.device.client import DeviceClient\nfrom ...core.node.domain.client import DomainClient\nfrom ...core.node.network.client import NetworkClient\nfrom ...core.node.vm.client import VirtualMachineClient\n+from ...core.pointer.pointer import Pointer\nfrom ..messages.setup_messages import CreateInitialSetUpMessage\nfrom ..messages.setup_messages import GetSetUpMessage\n+from ..messages.transfer_messages import LoadObjectMessage\nfrom .request_api.association_api import AssociationRequestAPI\nfrom .request_api.group_api import GroupRequestAPI\nfrom .request_api.role_api import RoleRequestAPI\n@@ -38,6 +41,7 @@ def connect(\nconn_type: ClientConnection,\nclient_type: Client,\ncredentials: Dict = {},\n+ user_key: Optional[SigningKey] = None,\n) -> Any:\nclass GridClient(client_type): # type: ignore\ndef __init__(\n@@ -52,11 +56,14 @@ def connect(\nconn = conn_type(url=url) # type: ignore\nif credentials:\n- metadata, user_key = conn.login(credentials=credentials)\n- user_key = SigningKey(user_key.encode(\"utf-8\"), encoder=HexEncoder)\n+ metadata, _user_key = conn.login(credentials=credentials)\n+ _user_key = SigningKey(_user_key.encode(\"utf-8\"), encoder=HexEncoder)\nelse:\nmetadata = conn._get_metadata()\n- user_key = SigningKey.generate()\n+ if not user_key:\n+ _user_key = SigningKey.generate()\n+ else:\n+ _user_key = user_key\n(\nspec_location,\n@@ -81,22 +88,28 @@ def connect(\nvm=location_args[VirtualMachineClient],\nname=name,\nroutes=[route],\n- signing_key=user_key,\n+ signing_key=_user_key,\n)\nself.groups = GroupRequestAPI(send=self.__perform_grid_request)\nself.users = UserRequestAPI(send=self.__perform_grid_request)\nself.roles = RoleRequestAPI(send=self.__perform_grid_request)\n- self.workers = WorkerRequestAPI(send=self.__perform_grid_request)\n+ self.workers = WorkerRequestAPI(\n+ send=self.__perform_grid_request, client=self\n+ )\nself.association_requests = AssociationRequestAPI(\nsend=self.__perform_grid_request\n)\n- def proxy(self, vm_address: Address) -> None:\n- self.proxy_address = vm_address\n-\n- def unproxy(self) -> None:\n- self.proxy_address = None\n+ def load(\n+ self, obj_ptr: Type[Pointer], address: Address, searchable: bool = False\n+ ) -> None:\n+ content = {\n+ \"address\": address.serialize().SerializeToString().decode(\"ISO-8859-1\"), # type: ignore\n+ \"uid\": str(obj_ptr.id_at_location.value),\n+ \"searchable\": searchable,\n+ }\n+ self.__perform_grid_request(grid_msg=LoadObjectMessage, content=content)\ndef initial_setup(self, **kwargs: Any) -> Any:\nreturn self.__perform_grid_request(\n@@ -113,7 +126,6 @@ def connect(\n],\nroute_index: int = 0,\n) -> SyftMessage:\n-\nif self.proxy_address:\nmsg.address = self.proxy_address\n",
        "chatgpt_cot": "Add debug_kill_unit method to Client; add the method to kill unit in debug mode, which can be used to debug the game."
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/detailed_msg_box.py b/node_manager_fkie/src/node_manager_fkie/detailed_msg_box.py @@ -54,28 +54,35 @@ class WarningMessageBox(QMessageBox):\nQMessageBox.__init__(self, icon, title, text, buttons)\nif detailed_text:\nself.setDetailedText(detailed_text)\n- horizontalSpacer = QSpacerItem(480, 0, QSizePolicy.Minimum, QSizePolicy.Expanding)\n- layout = self.layout()\n- layout.addItem(horizontalSpacer, layout.rowCount(), 0, 1, layout.columnCount())\n-\n+ self.textEdit = textEdit = self.findChild(QTextEdit)\n+ if textEdit is not None:\n+ textEdit.setMinimumHeight(0)\n+ textEdit.setMaximumHeight(16777215)\n+ textEdit.setMinimumWidth(0)\n+ textEdit.setMaximumWidth(16777215)\n+ textEdit.setSizePolicy(QSizePolicy.Expanding, QSizePolicy.Expanding)\n+ # horizontalSpacer = QSpacerItem(480, 0, QSizePolicy.Minimum, QSizePolicy.Expanding)\n+ # layout = self.layout()\n+ # layout.addItem(horizontalSpacer, layout.rowCount(), 0, 1, layout.columnCount())\nif QMessageBox.Abort & buttons:\nself.setEscapeButton(QMessageBox.Abort)\nelif QMessageBox.Ignore & buttons:\nself.setEscapeButton(QMessageBox.Ignore)\nelse:\nself.setEscapeButton(buttons)\n-\n- self.textEdit = textEdit = self.findChild(QTextEdit)\n- if textEdit is not None:\n- textEdit.setMinimumHeight(0)\n- textEdit.setMaximumHeight(600)\n- textEdit.setMinimumWidth(0)\n- textEdit.setMaximumWidth(600)\n- textEdit.setSizePolicy(QSizePolicy.Expanding, QSizePolicy.Expanding)\n-\nself.ignore_all_btn = QPushButton('Don\\'t display again')\nself.addButton(self.ignore_all_btn, QMessageBox.HelpRole)\n+ self.setSizePolicy(QSizePolicy.Expanding, QSizePolicy.Expanding)\ndef paintEvent(self, event):\nQMessageBox.paintEvent(self, event)\n- self.ignore_all_btn.setVisible(self.textEdit.isVisible() if self.textEdit else False)\n+ if self.textEdit is not None and self.textEdit.isVisible():\n+ if not self.ignore_all_btn.isVisible():\n+ self.ignore_all_btn.setVisible(True)\n+ self.setSizeGripEnabled(True)\n+ self.setMaximumHeight(16777215)\n+ self.setMaximumWidth(16777215)\n+ elif self.textEdit is not None and not self.textEdit.isVisible():\n+ if self.ignore_all_btn.isVisible():\n+ self.ignore_all_btn.setVisible(False)\n+ self.setSizeGripEnabled(False)\n",
        "org_msg": "node_manager_fkie: added possibility to resize the details message dialog",
        "sim_msg": "default line colour gray. more menu line colour options",
        "sim_diff": "diff --git a/qualcoder/view_graph.py b/qualcoder/view_graph.py @@ -977,7 +977,7 @@ class FreeLineGraphicsItem(QtWidgets.QGraphicsLineItem):\nto_pos = None\nline_width = 2\nline_type = QtCore.Qt.PenStyle.SolidLine\n- line_color = QtCore.Qt.GlobalColor.black\n+ line_color = QtCore.Qt.GlobalColor.gray\ncorners_only = False # True for list graph\nweighting = 1\ntooltip = \"\"\n@@ -993,9 +993,7 @@ class FreeLineGraphicsItem(QtWidgets.QGraphicsLineItem):\nself.remove = False\nself.setFlags(QtWidgets.QGraphicsItem.GraphicsItemFlag.ItemIsSelectable)\nself.calculate_points_and_draw()\n- self.line_color = QtCore.Qt.GlobalColor.black\n- if app.settings['stylesheet'] == \"dark\":\n- self.line_color = QtCore.Qt.GlobalColor.white\n+ self.line_color = QtCore.Qt.GlobalColor.gray\ndef contextMenuEvent(self, event):\nmenu = QtWidgets.QMenu()\n@@ -1006,6 +1004,8 @@ class FreeLineGraphicsItem(QtWidgets.QGraphicsLineItem):\nmenu.addAction(_('Yellow'))\nmenu.addAction(_('Green'))\nmenu.addAction(_('Blue'))\n+ menu.addAction(_('Cyan'))\n+ menu.addAction(_('Magenta'))\nmenu.addAction(_('Remove'))\naction = menu.exec(QtGui.QCursor.pos())\nif action is None:\n@@ -1035,6 +1035,12 @@ class FreeLineGraphicsItem(QtWidgets.QGraphicsLineItem):\nif action.text() == 'Blue':\nself.line_color = QtCore.Qt.GlobalColor.blue\nself.redraw()\n+ if action.text() == 'Cyan':\n+ self.line_color = QtCore.Qt.GlobalColor.cyan\n+ self.redraw()\n+ if action.text() == 'Magenta':\n+ self.line_color = QtCore.Qt.GlobalColor.magenta\n+ self.redraw()\nif action.text() == \"Remove\":\nself.remove = True\n@@ -1222,7 +1228,7 @@ class LinkGraphicsItem(QtWidgets.QGraphicsLineItem):\nto_pos = None\nline_width = 2\nline_type = QtCore.Qt.PenStyle.SolidLine\n- line_color = QtCore.Qt.GlobalColor.black\n+ line_color = QtCore.Qt.GlobalColor.gray\ncorners_only = False # True for list graph\nweighting = 1\ntext = \"\"\n@@ -1237,9 +1243,7 @@ class LinkGraphicsItem(QtWidgets.QGraphicsLineItem):\nself.weighting = weighting\nself.setFlags(QtWidgets.QGraphicsItem.GraphicsItemFlag.ItemIsSelectable)\nself.calculate_points_and_draw()\n- self.line_color = QtCore.Qt.GlobalColor.black\n- if app.settings['stylesheet'] == \"dark\":\n- self.line_color = QtCore.Qt.GlobalColor.white\n+ self.line_color = QtCore.Qt.GlobalColor.gray\ndef contextMenuEvent(self, event):\nmenu = QtWidgets.QMenu()\n@@ -1250,6 +1254,8 @@ class LinkGraphicsItem(QtWidgets.QGraphicsLineItem):\nmenu.addAction(_('Yellow'))\nmenu.addAction(_('Green'))\nmenu.addAction(_('Blue'))\n+ menu.addAction(_('Cyan'))\n+ menu.addAction(_('Magenta'))\nmenu.addAction(_(\"Hide\"))\naction = menu.exec(QtGui.QCursor.pos())\n@@ -1280,6 +1286,12 @@ class LinkGraphicsItem(QtWidgets.QGraphicsLineItem):\nif action.text() == 'Blue':\nself.line_color = QtCore.Qt.GlobalColor.blue\nself.redraw()\n+ if action.text() == 'Cyan':\n+ self.line_color = QtCore.Qt.GlobalColor.cyan\n+ self.redraw()\n+ if action.text() == 'Magenta':\n+ self.line_color = QtCore.Qt.GlobalColor.magenta\n+ self.redraw()\nif action.text() == \"Hide\":\nself.hide()\n",
        "chatgpt_cot": "Adjust detailed message box size and layout to improve visibility and usability for the user. Fix button visibility and resizing issues."
    },
    {
        "org_diff": "diff --git a/node_manager_daemon_fkie/src/node_manager_daemon_fkie/file_servicer.py b/node_manager_daemon_fkie/src/node_manager_daemon_fkie/file_servicer.py @@ -36,7 +36,7 @@ import rospy\nimport multimaster_msgs_fkie.grpc.file_pb2_grpc as fms_grpc\nimport multimaster_msgs_fkie.grpc.file_pb2 as fms\n-from .common import is_package, get_pkg_path, package_name, utf8\n+from .common import interpret_path, is_package, get_pkg_path, package_name, utf8\nimport url as nmdurl\nimport file_item\nimport remote\n@@ -85,7 +85,7 @@ class FileServicer(fms_grpc.FileServiceServicer):\nresult = fms.GetFileContentReply()\ntry:\nwith open(request.path, 'r') as outfile:\n- result.file.path = request.path\n+ result.file.path = interpret_path(request.path)\na = os.path.getmtime(request.path)\nresult.file.mtime = a\nresult.file.size = os.path.getsize(request.path)\n",
        "org_msg": "node_manager_daemon_fkie: interpret paths for requested file content",
        "sim_msg": "remove file_utils import from Daemon",
        "sim_diff": "diff --git a/lbrynet/lbrynet_daemon/Daemon.py b/lbrynet/lbrynet_daemon/Daemon.py @@ -38,7 +38,7 @@ from lbrynet.lbrynet_daemon.Publisher import Publisher\nfrom lbrynet.lbrynet_daemon.ExchangeRateManager import ExchangeRateManager\nfrom lbrynet.lbrynet_daemon.auth.server import AuthJSONRPCServer\nfrom lbrynet.core.PaymentRateManager import OnlyFreePaymentsManager\n-from lbrynet.core import log_support, utils, file_utils\n+from lbrynet.core import log_support, utils\nfrom lbrynet.core import system_info\nfrom lbrynet.core.StreamDescriptor import StreamDescriptorIdentifier, download_sd_blob\nfrom lbrynet.core.Session import Session\n",
        "chatgpt_cot": "Refactor interpret_path method in FileServicer to handle file paths, improving path interpretation and readability in FileServicer class in node_manager_daemon_fkie."
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/editor/xmlformatter.py b/node_manager_fkie/src/node_manager_fkie/editor/xmlformatter.py @@ -20,6 +20,12 @@ CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\nhttps://pypi.org/project/xmlformatter\n+Changes by Alexander Tiderko:\n+04.04.2019 added functionality for\n+ DEFAULT_NOEMPTYTAG = False\n+ DEFAULT_EMPTYATTR = True\n+ DEFAULT_INDENT_DATA = True\n+\nFormat and compress XML documents\n\"\"\"\n",
        "org_msg": "node_manager_fkie: added description for xmlformatter",
        "sim_msg": "Preserve node id on re-edit",
        "sim_diff": "diff --git a/textext/base.py b/textext/base.py @@ -469,8 +469,10 @@ class TexText(inkex.EffectExtension):\nReplace an XML node old_node with new_node\n\"\"\"\nparent = old_node.getparent()\n+ old_id = old_node.get_id()\nparent.remove(old_node)\nparent.append(new_node)\n+ new_node.set_id(old_id)\nself.copy_style(old_node, new_node)\n@staticmethod\n",
        "chatgpt_cot": "\"Add functionality for default settings in XML formatter\""
    },
    {
        "org_diff": "diff --git a/examples/terran/mass_reaper.py b/examples/terran/mass_reaper.py @@ -113,6 +113,9 @@ class MassReaperBot(sc2.BotAI):\n# caution: the target for the refinery has to be the vespene geyser, not its position!\nself.do(w.build(UnitTypeId.REFINERY, vg), subtract_cost=True)\n+ # dont build more than one each frame\n+ break\n+\n# make scvs until 18, usually you only need 1:1 mineral:gas ratio for reapers, but if you don't lose any then you will need additional depots (mule income should take care of that)\n# stop scv production when barracks is complete but we still have a command cender (priotize morphing to orbital command)\nif (\n",
        "org_msg": "Additional change",
        "sim_msg": "bump back up to 8h",
        "sim_diff": "diff --git a/GearBot/Util/ReactionManager.py b/GearBot/Util/ReactionManager.py @@ -110,7 +110,7 @@ async def register(bot, message_id, channel_id, type, pipe=None, **kwargs):\npipe = bot.redis_pool.pipeline()\nkey = f\"reactor:{message_id}\"\npipe.hmset_dict(key, message_id=message_id, channel_id=channel_id, type=type, **kwargs)\n- pipe.expire(key, kwargs.get(\"duration\", 60*60))\n+ pipe.expire(key, kwargs.get(\"duration\", 60*60*8))\nawait pipe.execute()\n",
        "chatgpt_cot": "Fix issue with building multiple refineries in one frame in MassReaperBot. Added break statement to prevent this."
    },
    {
        "org_diff": "diff --git a/fkie_node_manager_daemon/src/fkie_node_manager_daemon/remote.py b/fkie_node_manager_daemon/src/fkie_node_manager_daemon/remote.py @@ -77,20 +77,6 @@ def clear_channels():\nINSECURE_CHANNEL_CACHE.clear()\n-def add_insecure_channel(url):\n- '''\n- Adds a new insecure channel for given url. Ports are ignored!\n- :param str url: the url to parse\n- '''\n- global INSECURE_CHANNEL_CACHE\n-# global CREDENTIALS\n- cn = ChannelName(url)\n- if cn not in INSECURE_CHANNEL_CACHE:\n- rospy.logdebug(\"add insecure channel to %s\" % url)\n-# INSECURE_CHANNEL_CACHE[cn] = grpc.secure_channel(url, CREDENTIALS)\n- INSECURE_CHANNEL_CACHE[cn] = grpc.insecure_channel(url)\n-\n-\ndef remove_insecure_channel(url):\nglobal INSECURE_CHANNEL_CACHE\ntry:\n@@ -115,8 +101,10 @@ def get_insecure_channel(url):\nexcept Exception:\nif host.get_port(url):\nrospy.logdebug(\"create insecure channel to %s\" % url)\n- INSECURE_CHANNEL_CACHE[cn] = grpc.insecure_channel(url)\n+ # does the storeage cause delays on connection problems?\n+ # INSECURE_CHANNEL_CACHE[cn] = grpc.insecure_channel(url)\n+ # return INSECURE_CHANNEL_CACHE[cn]\n# INSECURE_CHANNEL_CACHE[cn] = grpc.secure_channel(url, CREDENTIALS)\n- return INSECURE_CHANNEL_CACHE[cn]\n+ return grpc.insecure_channel(url)\nprint(\"No cached URL for insecure channel: %s\" % url)\nreturn None\n",
        "org_msg": "fkie_node_manager_daemon: do not cache channels",
        "sim_msg": "Feature/SK-248 Enable CA signed cert for GRPC channel",
        "sim_diff": "diff --git a/fedn/fedn/client.py b/fedn/fedn/client.py @@ -264,6 +264,12 @@ class Client:\nwith open(os.environ[\"FEDN_GRPC_ROOT_CERT_PATH\"], 'rb') as f:\ncredentials = grpc.ssl_channel_credentials(f.read())\nchannel = grpc.secure_channel(\"{}:{}\".format(host, str(port)), credentials)\n+ elif self.config['secure']:\n+ secure = True\n+ print(\"CLIENT: using CA certificate for GRPC channel\")\n+\n+ credentials = grpc.ssl_channel_credentials()\n+ channel = grpc.secure_channel(\"{}:{}\".format(host, str(port)), credentials)\nelse:\nprint(\"CLIENT: using insecure GRPC channel\")\nchannel = grpc.insecure_channel(\"{}:{}\".format(\n",
        "chatgpt_cot": "Refactor insecure channel handling in remote.py for better connection management. Removed redundant code, improved error handling, and clarified function purpose."
    },
    {
        "org_diff": "diff --git a/sc2/main.py b/sc2/main.py @@ -116,11 +116,11 @@ async def _play_game_ai(client, player_id, ai, realtime, step_time_limit, game_t\nreturn Result.Defeat\niteration = 0\n- realtime_game_loop = -1\nwhile True:\nif iteration != 0:\nif realtime:\n- state = await client.observation(realtime_game_loop + client.game_step)\n+ # TODO: check what happens if a bot takes too long to respond, so that the requested game_loop might already be in the past\n+ state = await client.observation(gs.game_loop + client.game_step)\nelse:\nstate = await client.observation()\n# check game result every time we get the observation\n@@ -148,7 +148,7 @@ async def _play_game_ai(client, player_id, ai, realtime, step_time_limit, game_t\n# Issue event like unit created or unit destroyed\nawait ai.issue_events()\nawait ai.on_step(iteration)\n- realtime_game_loop = await ai._after_step()\n+ await ai._after_step()\nelse:\nif time_penalty_cooldown > 0:\ntime_penalty_cooldown -= 1\n",
        "org_msg": "Remove realtime_game_loop variable",
        "sim_msg": "added more frame slowdown info",
        "sim_diff": "diff --git a/bot_manager.py b/bot_manager.py @@ -68,6 +68,7 @@ class BotManager:\nself.game_file = open(filename.replace(\" \", \"\"), 'wb')\nold_time = 0\ncurrent_time = -10\n+ counter = 0\n# Run until main process tells to stop\nwhile not self.terminateEvent.is_set():\n@@ -109,7 +110,11 @@ class BotManager:\nafter = datetime.now()\nafter2 = time.time()\nif after2 - before2 > 0.03:\n- print('Too slow for ' + self.name + ': ' + str(after2 - before2))\n+ print('Too slow for ' + self.name + ': ' + str(after2 - before2) +\n+ ' frames since slowdown ' + str(counter))\n+ counter = 0\n+ else:\n+ counter += 1\n#print('Latency of ' + self.name + ': ' + str(after2 - before2))\nr.acquire(after-before)\n",
        "chatgpt_cot": "Fix real-time game loop issue and time penalty cooldown in main.py. Update observation and after step methods for better game performance."
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/__init__.py b/node_manager_fkie/src/node_manager_fkie/__init__.py @@ -89,6 +89,9 @@ _QAPP = None\ndef detect_version():\n+ '''\n+ Try to detect the current version from git, installed VERSION/DATE files or package.xml\n+ '''\ntry:\nglobal __version__\nglobal __date__\n",
        "org_msg": "node_manager_fkie: added method description",
        "sim_msg": "fix: use warnings and threading",
        "sim_diff": "diff --git a/cli/__init__.py b/cli/__init__.py @@ -118,9 +118,8 @@ def _is_latest_version(package='jina', suppress_on_error=True):\n) as resp: # 'with' is important to close the resource after use\nlatest_release_ver = _parse_latest_release_version(resp)\nif cur_ver < latest_release_ver:\n- from jina.logging.predefined import default_logger\n- default_logger.warning(\n+ warnings.warn(\nf'You are using {package} version {cur_ver}, however version {latest_release_ver} is available. '\nf'You should consider upgrading via the \"pip install --upgrade {package}\" command.'\n)\n@@ -159,9 +158,9 @@ def _try_plugin_command():\nsubcommand = argv[1]\ncmd = 'jina-' + subcommand\nif _cmd_exists(cmd):\n- import multiprocessing\n+ import threading\n- multiprocessing.Process(\n+ threading.Thread(\ntarget=_is_latest_version_plugin,\ndaemon=True,\nargs=(subcommand,),\n",
        "chatgpt_cot": "Add function to detect current version from git, installed files, or package.xml in node_manager_fkie/__init__.py."
    },
    {
        "org_diff": "diff --git a/src/agent/fabric-operator/pkg/controller/ca/ca_controller.go b/src/agent/fabric-operator/pkg/controller/ca/ca_controller.go @@ -2,6 +2,7 @@ package ca\nimport (\n\"context\"\n+ \"encoding/base64\"\n\"strconv\"\n\"strings\"\n\"time\"\n@@ -234,10 +235,10 @@ func (r *ReconcileCA) newSecretForCR(cr *fabricv1alpha1.CA, request reconcile.Re\nsecret.Namespace = request.Namespace\nsecret.Data = make(map[string][]byte)\nif cr.Spec.Certs != nil {\n- secret.Data[\"cert\"] = []byte(cr.Spec.Certs.Cert)\n- secret.Data[\"key\"] = []byte(cr.Spec.Certs.Key)\n- secret.Data[\"tlsCert\"] = []byte(cr.Spec.Certs.TLSCert)\n- secret.Data[\"tlsKey\"] = []byte(cr.Spec.Certs.TLSKey)\n+ secret.Data[\"cert\"], _ = base64.StdEncoding.DecodeString(cr.Spec.Certs.Cert)\n+ secret.Data[\"key\"], _ = base64.StdEncoding.DecodeString(cr.Spec.Certs.Key)\n+ secret.Data[\"tlsCert\"], _ = base64.StdEncoding.DecodeString(cr.Spec.Certs.TLSCert)\n+ secret.Data[\"tlsKey\"], _ = base64.StdEncoding.DecodeString(cr.Spec.Certs.TLSKey)\n}\ncontrollerutil.SetControllerReference(cr, secret, r.scheme)\n}\n",
        "org_msg": "Fixed issue report in\nIssue 165 stated that the ca cert were not correctly\ndecoded when provided to stand up a ca node. This\npatch will fix that issue.",
        "sim_msg": "(from AES) Rename Ref to SecretRef, to make it easier to use elsewhere.",
        "sim_diff": "diff --git a/cmd/entrypoint/secrets.go b/cmd/entrypoint/secrets.go @@ -8,6 +8,12 @@ import (\n\"github.com/datawire/ambassador/pkg/kates\"\n)\n+// SecretRef is a secret reference -- basically, a namespace/name pair.\n+type SecretRef struct {\n+ Namespace string\n+ Name string\n+}\n+\n// ReconcileSecrets figures out which secrets we're actually using,\n// since we don't want to send secrets to Ambassador unless we're\n// using them, since any secret we send will be saved to disk.\n@@ -88,12 +94,12 @@ func (s *AmbassadorInputs) ReconcileSecrets() {\n// Once we have our list of secrets, go figure out the names of all\n// the secrets we need. We'll use this \"refs\" map to hold all the names...\n- refs := map[Ref]bool{}\n+ refs := map[SecretRef]bool{}\n// ...and, uh, this \"action\" function is really just a closure to avoid\n// needing to pass \"refs\" to findSecretRefs. Shrug. Arguably more\n// complex than needed, but meh.\n- action := func(ref Ref) {\n+ action := func(ref SecretRef) {\nrefs[ref] = true\n}\n@@ -114,7 +120,7 @@ func (s *AmbassadorInputs) ReconcileSecrets() {\n// to Secrets.\ns.Secrets = make([]*kates.Secret, 0, len(refs))\nfor _, secret := range s.AllSecrets {\n- if refs[Ref{secret.GetNamespace(), secret.GetName()}] {\n+ if refs[SecretRef{secret.GetNamespace(), secret.GetName()}] {\ns.Secrets = append(s.Secrets, secret)\n}\n}\n@@ -151,7 +157,7 @@ func include(id amb.AmbassadorID) bool {\n}\n// Find all the secrets a given Ambassador resource references.\n-func findSecretRefs(resource kates.Object, secretNamespacing bool, action func(Ref)) {\n+func findSecretRefs(resource kates.Object, secretNamespacing bool, action func(SecretRef)) {\nswitch r := resource.(type) {\ncase *amb.Host:\n// The Host resource is a little odd. Host.spec.tls, Host.spec.tlsSecret, and\n@@ -226,7 +232,7 @@ func findSecretRefs(resource kates.Object, secretNamespacing bool, action func(R\n}\n// Mark a secret as one we reference, handling secretNamespacing correctly.\n-func secretRef(namespace, name string, secretNamespacing bool, action func(Ref)) {\n+func secretRef(namespace, name string, secretNamespacing bool, action func(SecretRef)) {\nif secretNamespacing {\nparts := strings.Split(name, \".\")\nif len(parts) > 1 {\n@@ -235,13 +241,7 @@ func secretRef(namespace, name string, secretNamespacing bool, action func(Ref))\n}\n}\n- action(Ref{namespace, name})\n-}\n-\n-// Ref is a secret reference -- basically, a namespace/name pair.\n-type Ref struct {\n- Namespace string\n- Name string\n+ action(SecretRef{namespace, name})\n}\n// ModuleSecrets is... a hack. It's sort of a mashup of the chunk of the Ambassador\n",
        "chatgpt_cot": "Fix base64 encoding for certificate and key data in CA controller file. Fix compilation issue for decoding certificate and key data."
    },
    {
        "org_diff": "diff --git a/.github/workflows/ci.yml b/.github/workflows/ci.yml @@ -111,6 +111,8 @@ jobs:\nos: [ubuntu-latest]\npython-version: ['3.8', '3.9', '3.10']\nsc2-version: ['4.10']\n+ env:\n+ IMAGE_NAME: burnysc2/python-sc2:local\nsteps:\n# Copy data from repository\n@@ -124,7 +126,6 @@ jobs:\n- name: Load and build docker image\n# Build docker image from Dockerfile using specific python and sc2 version\nenv:\n- IMAGE_NAME: burnysc2/python-sc2:local\nBUILD_ARGS: --build-arg PYTHON_VERSION=${{ matrix.python-version }} --build-arg SC2_VERSION=${{ matrix.sc2-version }}\nrun: |\ndocker build -f test/Dockerfile -t $IMAGE_NAME $BUILD_ARGS .\n@@ -139,21 +140,21 @@ jobs:\n- name: Run upgradestest_bot.py\nrun: |\n- docker run -i -d --name my_container test_image\n+ docker run -i -d --name my_container $IMAGE_NAME\ndocker exec -i my_container bash -c \"python test/travis_test_script.py test/upgradestest_bot.py\"\ndocker exec -i my_container bash -c \"tree\"\ndocker rm -f my_container\n- name: Run damagetest_bot.py\nrun: |\n- docker run -i -d --name my_container test_image\n+ docker run -i -d --name my_container $IMAGE_NAME\ndocker exec -i my_container bash -c \"python test/travis_test_script.py test/damagetest_bot.py\"\ndocker exec -i my_container bash -c \"tree\"\ndocker rm -f my_container\n- name: Run queries_test_bot.py\nrun: |\n- docker run -i -d --name my_container test_image\n+ docker run -i -d --name my_container $IMAGE_NAME\ndocker exec -i my_container bash -c \"python test/travis_test_script.py test/queries_test_bot.py\"\ndocker exec -i my_container bash -c \"tree\"\ndocker rm -f my_container\n@@ -168,6 +169,8 @@ jobs:\nfail-fast: false\nmatrix:\nos: [ubuntu-latest]\n+ env:\n+ IMAGE_NAME: burnysc2/python-sc2-docker:local\nsteps:\n# Copy data from repository\n@@ -181,14 +184,13 @@ jobs:\n- name: Load and build docker image\n# Build docker image from Dockerfile using specific python and sc2 version\nenv:\n- IMAGE_NAME: burnysc2/python-sc2-docker:local\nBUILD_ARGS: --build-arg PYTHON_VERSION=${{ env.LATEST_PYTHON_VERSION }} --build-arg SC2_VERSION=${{ env.LATEST_SC2_VERSION }}\nrun: |\ndocker build -f test/Dockerfile -t $IMAGE_NAME $BUILD_ARGS --build-arg VERSION_NUMBER=${{ env.VERSION_NUMBER }} .\n- name: Run example bots vs computer\nrun: |\n- docker run -i -d --name my_container test_image\n+ docker run -i -d --name my_container $IMAGE_NAME\ndocker exec -i my_container bash -c \"python test/run_example_bots_vs_computer.py\"\ndocker exec -i my_container bash -c \"tree\"\ndocker rm -f my_container\n",
        "org_msg": "Fix ci.yml env variables",
        "sim_msg": "Debug: Print version before building the package.",
        "sim_diff": "diff --git a/.github/workflows/build-docker-image.yml b/.github/workflows/build-docker-image.yml @@ -17,6 +17,8 @@ jobs:\nuses: actions/setup-python@v1\nwith:\npython-version: 3.7\n+ - name: Determine version\n+ run: python setup.py --version\n#- name: Install build environment\n# run: python -m pip install build --user\n# - name: Build source tarball\n",
        "chatgpt_cot": "Update Docker image name in CI workflow to use local image for testing and add environment variable for image name."
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/cmake/version.cmake b/node_manager_fkie/cmake/version.cmake @@ -4,8 +4,7 @@ macro(generate_version)\nfind_program(GIT git)\nif (NOT GIT)\nmessage(STATUS \"git binary not found, VERSION and DATE files are not created\")\n- return()\n- endif()\n+ else(GIT)\n# install a file with version tag\nset(VERSION_DIR \"${CATKIN_DEVEL_PREFIX}/${CATKIN_PACKAGE_SHARE_DESTINATION}\")\nset(VERSION_FILES \"\")\n@@ -36,4 +35,5 @@ macro(generate_version)\nDEPENDS ${VERSION_FILES}\nCOMMENT \"Generate version files\"\n)\n+ endif()\nendmacro()\n",
        "org_msg": "fixed node manager install",
        "sim_msg": "Added SPARSEZOO_TEST_MODE flag for makefile",
        "sim_diff": "diff --git a/Makefile b/Makefile @@ -6,6 +6,7 @@ CHECKGLOBS := 'examples/**/*.py' 'integrations/**/*.py' 'scripts/**/*.py' 'src/*\nDOCDIR := docs\nMDCHECKGLOBS := 'docs/**/*.md' 'docs/**/*.rst' 'examples/**/*.md' 'integrations/**/*.md' 'notebooks/**/*.md' 'scripts/**/*.md'\nMDCHECKFILES := CODE_OF_CONDUCT.md CONTRIBUTING.md DEVELOPING.md README.md\n+SPARSEZOO_TEST_MODE := \"true\"\nBUILD_ARGS := # set nightly to build nightly release\nTARGETS := \"\" # targets for running pytests: keras,onnx,pytorch,pytorch_models,pytorch_datasets,tensorflow_v1,tensorflow_v1_models,tensorflow_v1_datasets\n",
        "chatgpt_cot": "\"Fix issue with version.cmake file to create version and date files if git binary is not found.\""
    },
    {
        "org_diff": "diff --git a/fkie_node_manager/src/fkie_node_manager/ui/logscreen/ScreenWidget.ui b/fkie_node_manager/src/fkie_node_manager/ui/logscreen/ScreenWidget.ui </item>\n<item>\n<widget class=\"QFrame\" name=\"logframe\">\n+ <property name=\"sizePolicy\">\n+ <sizepolicy hsizetype=\"Minimum\" vsizetype=\"Preferred\">\n+ <horstretch>0</horstretch>\n+ <verstretch>0</verstretch>\n+ </sizepolicy>\n+ </property>\n<property name=\"frameShape\">\n<enum>QFrame::NoFrame</enum>\n</property>\n</property>\n<item>\n<widget class=\"EnhancedLineEdit\" name=\"loggerFilterInput\">\n+ <property name=\"sizePolicy\">\n+ <sizepolicy hsizetype=\"Preferred\" vsizetype=\"Fixed\">\n+ <horstretch>0</horstretch>\n+ <verstretch>0</verstretch>\n+ </sizepolicy>\n+ </property>\n<property name=\"visible\">\n<bool>true</bool>\n</property>\n<rect>\n<x>0</x>\n<y>0</y>\n- <width>68</width>\n- <height>552</height>\n+ <width>140</width>\n+ <height>518</height>\n</rect>\n</property>\n+ <property name=\"sizePolicy\">\n+ <sizepolicy hsizetype=\"Minimum\" vsizetype=\"Minimum\">\n+ <horstretch>0</horstretch>\n+ <verstretch>0</verstretch>\n+ </sizepolicy>\n+ </property>\n<layout class=\"QVBoxLayout\" name=\"loggerLayout\">\n<property name=\"spacing\">\n<number>3</number>\n",
        "org_msg": "fkie_node_manager: fixed logger with in logscreen",
        "sim_msg": "buttons to enter and exit edit mode",
        "sim_diff": "diff --git a/GUI_UIs/ui_dialog_code_text.ui b/GUI_UIs/ui_dialog_code_text.ui <rect>\n<x>0</x>\n<y>0</y>\n- <width>1024</width>\n+ <width>1054</width>\n<height>695</height>\n</rect>\n</property>\n<string>Code Text</string>\n</property>\n<layout class=\"QGridLayout\" name=\"gridLayout_2\">\n+ <item row=\"1\" column=\"0\">\n+ <widget class=\"QGroupBox\" name=\"groupBox_edit_mode\">\n+ <property name=\"minimumSize\">\n+ <size>\n+ <width>0</width>\n+ <height>80</height>\n+ </size>\n+ </property>\n+ <property name=\"maximumSize\">\n+ <size>\n+ <width>16777215</width>\n+ <height>80</height>\n+ </size>\n+ </property>\n+ <property name=\"title\">\n+ <string/>\n+ </property>\n+ <layout class=\"QGridLayout\" name=\"gridLayout_3\">\n+ <item row=\"1\" column=\"1\">\n+ <widget class=\"QPushButton\" name=\"pushButton_exit_edit\">\n+ <property name=\"minimumSize\">\n+ <size>\n+ <width>28</width>\n+ <height>28</height>\n+ </size>\n+ </property>\n+ <property name=\"maximumSize\">\n+ <size>\n+ <width>28</width>\n+ <height>28</height>\n+ </size>\n+ </property>\n+ <property name=\"toolTip\">\n+ <string>Exit Edit text </string>\n+ </property>\n+ <property name=\"text\">\n+ <string/>\n+ </property>\n+ </widget>\n+ </item>\n+ <item row=\"0\" column=\"0\" rowspan=\"2\">\n+ <widget class=\"QLabel\" name=\"label_editing\">\n+ <property name=\"enabled\">\n+ <bool>true</bool>\n+ </property>\n+ <property name=\"maximumSize\">\n+ <size>\n+ <width>16777215</width>\n+ <height>76</height>\n+ </size>\n+ </property>\n+ <property name=\"text\">\n+ <string/>\n+ </property>\n+ <property name=\"wordWrap\">\n+ <bool>true</bool>\n+ </property>\n+ </widget>\n+ </item>\n+ </layout>\n+ </widget>\n+ </item>\n<item row=\"0\" column=\"0\">\n<widget class=\"QGroupBox\" name=\"groupBox\">\n<property name=\"minimumSize\">\n</rect>\n</property>\n<property name=\"toolTip\">\n- <string>Edit text mode.\n-You can click on a position, without selecting text, to type, delete, or paste text.\n-You can select text that is not underlined and delete or paste over.\n+ <string>Edit text\n+Click on a position, without selecting text, to type, delete, or paste text.\n+Select text that is not underlined and delete or paste over.\nAvoid selecting text to delete or paste over if the selected text is underlined:\n(coded - red, annotated - yellow, case-assigned - green)\n-As all assigned positions may be wrong. </string>\n+As all assigned positions may be incorrect. </string>\n</property>\n<property name=\"text\">\n<string/>\n@@ -487,25 +549,6 @@ As all assigned positions may be wrong. </string>\n</widget>\n</widget>\n</item>\n- <item row=\"1\" column=\"0\">\n- <widget class=\"QLabel\" name=\"label_editing\">\n- <property name=\"enabled\">\n- <bool>true</bool>\n- </property>\n- <property name=\"maximumSize\">\n- <size>\n- <width>16777215</width>\n- <height>80</height>\n- </size>\n- </property>\n- <property name=\"text\">\n- <string/>\n- </property>\n- <property name=\"wordWrap\">\n- <bool>true</bool>\n- </property>\n- </widget>\n- </item>\n<item row=\"2\" column=\"0\">\n<widget class=\"QSplitter\" name=\"splitter\">\n<property name=\"orientation\">\n",
        "chatgpt_cot": "\"Fix size policy for logframe and loggerFilterInput in ScreenWidget.ui\""
    },
    {
        "org_diff": "diff --git a/.github/workflows/codecoverage.yml b/.github/workflows/codecoverage.yml @@ -68,6 +68,17 @@ jobs:\nrun: |\ndocker exec -i my_container bash -c \"poetry run coverage run test/run_example_bots_vs_computer.py\"\n+ - name: Generate xml coverage file\n+ run: |\n+ docker exec -i my_container bash -c \"poetry run coverage xml\"\n+ docker cp my_container:/root/python-sc2/coverage.xml $(pwd)/coverage.xml\n+\n+ - name: Upload coverage to Codecov\n+ uses: codecov/codecov-action@v2\n+ with:\n+ files: coverage.xml\n+ fail_ci_if_error: true\n+\n- name: Generate html coverage files in htmlcov/ folder\nrun: |\ndocker exec -i my_container bash -c \"poetry run coverage html\"\n",
        "org_msg": "Add 'Upload coverage to Codecov'",
        "sim_msg": "small fix for workflow",
        "sim_diff": "diff --git a/.github/workflows/workflow.yml b/.github/workflows/workflow.yml @@ -514,10 +514,9 @@ jobs:\nmake test\n- name: Upload coverage report\nuses: codecov/codecov-action@v1.0.2\n- working-directory: ./libs/go/libp2p_node/\nwith:\ntoken: ${{ secrets.CODECOV_TOKEN }}\n- file: ./coverage.out\n+ file: ./libs/go/libp2p_node/coverage.out\nflags: unittests_go\nname: codecov-umbrella\ncoverage_checks:\n",
        "chatgpt_cot": "Add code coverage workflow to generate xml and html coverage files, and upload xml file to Codecov to ensure comprehensive test coverage."
    },
    {
        "org_diff": "diff --git a/README.md b/README.md An easy-to-use library for wrting AI Bots for StarCraft II in Python 3. The ultimate goal is simplicity and ease of use, while still preserving all funcionality. A really simple worker rush bot should be no more than twenty lines of code, not two hundred. However, this library intends to provide both high and low level abstractions.\n-**This library (currently) covers only the raw scripted interface.** At this time I don't ident to add support for graphics-based iterfaces.\n+**This library (currently) covers only the raw scripted interface.** At this time I don't intend to add support for graphics-based iterfaces.\n-**NOTE: This library is still in very early stages, and features are change often.**\n+**NOTE: This library is still in very early stages, and features can still change.**\n## Installation\n@@ -32,8 +32,8 @@ from sc2.player import Bot, Computer\nclass WorkerRushBot(sc2.BotAI):\nasync def on_step(self, state, iteration):\nif iteration == 0:\n- for probe in self.units(\"Probe\"):\n- await self.do(probe(\"Attack\", self.enemy_start_locations[0]))\n+ for probe in self.workers:\n+ await self.do(probe.attack(self.enemy_start_locations[0]))\nrun_game(maps.get(\"Abyssal Reef LE\"), [\nBot(Race.Protoss, WorkerRushBot()),\n@@ -42,3 +42,8 @@ run_game(maps.get(\"Abyssal Reef LE\"), [\n```\nThis is probably the simplest bot that has any realistic chances of winning the game. I have ran it against the medium AI quite a few times, and once in a while it wins.\n+\n+\n+## Bug reports, ideas and contributing\n+\n+If you have any issues, ideas or feedback, please create [a new issue](https://github.com/Dentosal/python-sc2/issues/new). Pull requests are also welcome!\n",
        "org_msg": "Polish README.md",
        "sim_msg": "Forgot to update iNumPlayers",
        "sim_diff": "diff --git a/v3/runner.py b/v3/runner.py @@ -63,6 +63,8 @@ if __name__ == '__main__':\ncallbacks = []\nname_dict = dict()\n+ gameInputPacket.iNumPlayers = num_bots\n+\n# Set configuration values for bots and store name and team\nfor i in range(num_bots):\nbot_config = configparser.RawConfigParser()\n",
        "chatgpt_cot": "Add intention clarification and code improvement in README for StarCraft II AI bot library. Fix typos, clarify library status, and update code for WorkerRushBot."
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/editor/text_edit.py b/node_manager_fkie/src/node_manager_fkie/editor/text_edit.py @@ -312,7 +312,11 @@ class TextEdit(QTextEdit):\nself.shiftText(back=True)\nelse:\nevent.accept()\n+ if event.key() in [Qt.Key_Enter, Qt.Key_Return]:\n+ ident = self.getIdentOfCurretLine()\nQTextEdit.keyPressEvent(self, event)\n+ if event.key() in [Qt.Key_Enter, Qt.Key_Return]:\n+ self.indentCurrentLine(ident)\nelse:\nevent.accept()\nQTextEdit.keyPressEvent(self, event)\n@@ -476,6 +480,49 @@ class TextEdit(QTextEdit):\nself.setTextCursor(cursor)\ncursor.endEditBlock()\n+ def indentCurrentLine(self, count=0):\n+ '''\n+ Increase indentation of current line according to the preview line.\n+ '''\n+ cursor = self.textCursor()\n+ if not cursor.isNull():\n+ # one undo operation\n+ cursor.beginEditBlock()\n+ start = cursor.selectionStart()\n+ end = cursor.selectionEnd()\n+ cursor.setPosition(start)\n+ block_start = cursor.blockNumber()\n+ cursor.setPosition(end)\n+ block_end = cursor.blockNumber()\n+ ident = ''\n+ for _ in range(count):\n+ ident += ' '\n+ if block_end - block_start == 0:\n+ # shift one line of count spaces to the right\n+ cursor.movePosition(QTextCursor.NextCharacter, QTextCursor.KeepAnchor, end - start)\n+ cursor.insertText(ident)\n+ else:\n+ # shift selected block two spaces to the right\n+ inserted = 0\n+ for i in reversed(range(start, end)):\n+ cursor.setPosition(i)\n+ if cursor.atBlockStart():\n+ cursor.insertText(ident)\n+ inserted += count\n+ cursor.setPosition(start)\n+ cursor.movePosition(QTextCursor.NextCharacter, QTextCursor.KeepAnchor, end - start + inserted)\n+ self.setTextCursor(cursor)\n+ cursor.endEditBlock()\n+\n+ def getIdentOfCurretLine(self):\n+ cursor = self.textCursor()\n+ if not cursor.isNull():\n+ cursor.movePosition(QTextCursor.StartOfLine)\n+ cursor.movePosition(QTextCursor.EndOfLine, QTextCursor.KeepAnchor)\n+ line = cursor.selectedText()\n+ return len(line) - len(line.lstrip(' '))\n+ return 0\n+\n#############################################################################\n########## Drag&Drop ######\n#############################################################################\n",
        "org_msg": "node_manager_fkie: editor: ident to preview line on pressed return/enter",
        "sim_msg": "fixed error with 60000 characters option and multiple coded text segment",
        "sim_diff": "diff --git a/qualcoder/code_text.py b/qualcoder/code_text.py # -*- coding: utf-8 -*-\n\"\"\"\n-Copyright (c) 2020 Colin Curtain\n+Copyright (c) 2021 Colin Curtain\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\n@@ -1982,27 +1982,27 @@ class DialogCodeText(QtWidgets.QWidget):\nHighlight this coded text.\nAccount for start of text file, as this may be a smaller portion of the full text file.\"\"\"\n- current_text = self.ui.comboBox_codes_in_text.currentText()\n+ current_codename = self.ui.comboBox_codes_in_text.currentText()\ncurrent_code = None\nfor code in self.codes:\n- if code['name'] == current_text:\n+ if code['name'] == current_codename:\ncurrent_code = code\nbreak\nif current_code is None:\nreturn\n- #print(\"Current code\", current_code) # tmp\npos = self.ui.textEdit.textCursor().position() + self.file_['start']\n- codes_here = []\n+ current_item = None\nfor item in self.code_text:\nif item['pos0'] <= pos and item['pos1'] >= pos and item['cid'] == current_code['cid']:\n- current_coded_text = item\n+ current_item = item\nbreak\n- #print(\"current coded text\", current_coded_text) # tmp\n+ #print(\"current item\", current_item) # tmp\n+ if current_item is None:\n+ return\n# Remove formatting\n- # TODO !!!!!!!!!!!!!!!!!!!!!!!\ncursor = self.ui.textEdit.textCursor()\n- cursor.setPosition(int(item['pos0'] - self.file_['start']), QtGui.QTextCursor.MoveAnchor)\n- cursor.setPosition(int(item['pos1'] - self.file_['start']), QtGui.QTextCursor.KeepAnchor)\n+ cursor.setPosition(int(current_item['pos0'] - self.file_['start']), QtGui.QTextCursor.MoveAnchor)\n+ cursor.setPosition(int(current_item['pos1'] - self.file_['start']), QtGui.QTextCursor.KeepAnchor)\ncursor.setCharFormat(QtGui.QTextCharFormat())\n# Reapply formatting\nfmt = QtGui.QTextCharFormat()\n",
        "chatgpt_cot": "Add methods to increase indentation of the current line and get the indentation of the current line to the TextEdit class."
    },
    {
        "org_diff": "diff --git a/fkie_node_manager/src/fkie_node_manager/master_list_model.py b/fkie_node_manager/src/fkie_node_manager/master_list_model.py @@ -41,6 +41,7 @@ except Exception:\nfrom socket import getaddrinfo, AF_INET6\nimport threading\n+from fkie_master_discovery.master_discovery import DiscoveredMaster\nfrom fkie_master_discovery.common import get_hostname\nfrom fkie_node_manager_daemon.common import isstring\nimport fkie_node_manager as nm\n@@ -270,7 +271,7 @@ class MasterItem(QStandardItem):\nif quality is not None and quality != -1.:\ntooltip = ''.join([tooltip, '<dt>', 'Quality: ', str(quality), ' %', '</dt>'])\nelse:\n- tooltip = ''.join([tooltip, '<dt>', 'Quality: not available</dt>'])\n+ tooltip = ''.join([tooltip, '<dt>', 'Quality: not available, start <b>master_discovery</b> with <b>heartbeat_hz</b> parameter >= %.02f</dt>' % DiscoveredMaster.MIN_HZ_FOR_QUALILTY])\nelse:\ntooltip = ''.join([tooltip, '<dt>', 'offline', '</dt>'])\ntooltip = ''.join([tooltip, '</dl>'])\n@@ -638,7 +639,7 @@ class MasterIconsDelegate(QItemDelegate):\nif item.quality is not None and item.quality != -1.:\ntooltip = '%s\\n<dt>Quality: %.2f </dt>' % (tooltip, item.quality)\nelse:\n- tooltip = '%s\\n<dt>Quality: not available</dt>' % (tooltip)\n+ tooltip = '%s\\n<dt>Quality: not available, start <b>master_discovery</b> with <b>heartbeat_hz</b> parameter >= %.02f</dt>' % (tooltip, DiscoveredMaster.MIN_HZ_FOR_QUALILTY)\nelse:\ntooltip = '%s\\n<dt>offline</dt>' % (tooltip)\n# update warnings\n",
        "org_msg": "fkie_node_manager: added info to a host if no quality is available",
        "sim_msg": "show avids in segments and ctids in coded text",
        "sim_diff": "diff --git a/qualcoder/view_av.py b/qualcoder/view_av.py @@ -1048,9 +1048,9 @@ class DialogCodeAV(QtWidgets.QDialog):\nfor c in self.code_text:\nif c['important'] == 1:\nimp_coded.append(c)\n- self.eventFilterTT.set_codes_and_annotations(imp_coded, self.codes, self.annotations)\n+ self.eventFilterTT.set_codes_and_annotations(self.app, imp_coded, self.codes, self.annotations)\nelse:\n- self.eventFilterTT.set_codes_and_annotations(self.code_text, self.codes, self.annotations)\n+ self.eventFilterTT.set_codes_and_annotations(self.app, self.code_text, self.codes, self.annotations)\nself.unlight()\nself.highlight()\n@@ -3063,8 +3063,12 @@ class ToolTipEventFilter(QtCore.QObject):\ncodes = None\ncode_text = None\nannotations = None\n+ app = None\n+\n+ def set_codes_and_annotations(self, app, code_text, codes, annotations):\n+ \"\"\" Update codes and coded text and annotations for tooltips. \"\"\"\n- def set_codes_and_annotations(self, code_text, codes, annotations):\n+ self.app = app\nself.code_text = code_text\nself.codes = codes\nself.annotations = annotations\n@@ -3075,7 +3079,7 @@ class ToolTipEventFilter(QtCore.QObject):\nitem['color'] = c['color']\ndef eventFilter(self, receiver, event):\n- \"\"\" Tool tip event filter for ?textEdit \"\"\"\n+ \"\"\" Tool tip event filter for textEdit \"\"\"\nif event.type() == QtCore.QEvent.Type.ToolTip:\ncursor = receiver.cursorForPosition(event.pos())\n@@ -3093,6 +3097,8 @@ class ToolTipEventFilter(QtCore.QObject):\ntry:\ntext_ += '<p style=\"background-color:' + item['color']\ntext_ += '; color:' + TextColor(item['color']).recommendation + '\">' + item['name']\n+ if self.app.settings['showids'] == 'True':\n+ text_ += \" [ctid:\" + str(item['ctid']) + \"] \"\nif item['avid'] is not None:\ntext_ += \" [\" + msecs_to_hours_mins_secs(item['av_pos0'])\ntext_ += \" - \" + msecs_to_hours_mins_secs(item['av_pos1']) + \"]\"\n@@ -3425,6 +3431,8 @@ class SegmentGraphicsItem(QtWidgets.QGraphicsLineItem):\nseg_time = \"[\" + msecs_to_hours_mins_secs(self.segment['pos0']) + \" - \"\nseg_time += msecs_to_hours_mins_secs(self.segment['pos1']) + \"]\"\ntooltip += seg_time\n+ if self.app.settings['showids'] == 'True':\n+ tooltip += \" [avid:\" + str(self.segment['avid']) + \"]\"\nif self.segment['memo'] != \"\":\ntooltip += \"\\n\" + _(\"MEMO: \") + self.segment['memo']\nif self.segment['seltext'] is not None and self.segment['seltext'] != \"\":\n",
        "chatgpt_cot": "Add DiscoveredMaster import, use DiscoveredMaster.MIN_HZ_FOR_QUALILTY, and improve tooltip in MasterItem and MasterIconsDelegate."
    },
    {
        "org_diff": "diff --git a/src/api-engine/api/lib/peer/channel.py b/src/api-engine/api/lib/peer/channel.py @@ -37,12 +37,38 @@ class Channel(BasicEnv):\nraise Exception(err_msg)\nreturn res\n- def update(self, channel, channel_tx, orderer_url, time_out=\"90s\"):\n+ def update(self, channel, channel_tx, orderer_url):\n+ \"\"\"\n+ Send a configtx update.\n+\n+ params:\n+ channel: channel id.\n+ channel_tx: Configuration transaction file generated by a tool such as configtxgen for submitting to orderer\n+ orderer_url: Ordering service endpoint.\n+ \"\"\"\ntry:\n- res = os.system(\"{} channel create -c {} -f {} -o {} --timeout {}\"\n- .format(self.peer, channel, channel_tx, orderer_url, time_out))\n+ res = os.system(\"{} channel update -c {} -f {} -o {}\"\n+ .format(self.peer, channel, channel_tx, orderer_url))\nexcept Exception as e:\nerr_msg = \"update channel failed for {e}!\"\nraise Exception(err_msg)\nres = res >> 8\nreturn res\n+\n+ def fetch(self, option, channel, orderer_url, time_out=\"90s\"):\n+ \"\"\"\n+ Fetch a specified block, writing it to a file e.g. <channelID>.block.\n+\n+ params:\n+ option: block option newest|oldest|config|(block number).\n+ channel: channel id.\n+ orderer_url: Ordering service endpoint.\n+ \"\"\"\n+ try:\n+ res = os.system(\"{} channel fetch {} -c {} -o {} --timeout {}\".format(\n+ self.peer, option, channel, orderer_url, time_out))\n+ except Exception as e:\n+ err_msg = \"fetch a specified block for {}!\".format(e)\n+ raise Exception(err_msg)\n+ res = res >> 8\n+ return res\n",
        "org_msg": "added fetch command\nfetching command allows us to get the newest block so that we can use it to\nupdate channel later.",
        "sim_msg": "Resign when block hash is changed",
        "sim_diff": "diff --git a/loopchain/channel/channel_service.py b/loopchain/channel/channel_service.py @@ -745,15 +745,19 @@ class ChannelService:\nblock_builder = BlockBuilder.from_new(block, self.block_manager.get_blockchain().tx_versioner)\nblock_builder.reset_cache()\nblock_builder.peer_id = block.header.peer_id\n- block_builder.signature = block.header.signature\n-\nblock_builder.commit_state = {\nChannelProperty().name: response['stateRootHash']\n}\nblock_builder.state_hash = Hash32(bytes.fromhex(response['stateRootHash']))\nblock_builder.receipts = tx_receipts\nblock_builder.reps = self.get_rep_ids()\n+ if block.header.peer_id.hex_hx() == ChannelProperty().peer_id:\n+ block_builder.signer = self.peer_auth\n+ else:\n+ block_builder.signature = block.header.signature\nnew_block = block_builder.build()\n+\n+ self.__block_manager.set_old_block_hash(new_block.header.hash, block.header.hash)\nreturn new_block, tx_receipts\ndef score_invoke(self, _block: Block) -> dict or None:\n@@ -786,7 +790,6 @@ class ChannelService:\nblock_builder = BlockBuilder.from_new(_block, self.__block_manager.get_blockchain().tx_versioner)\nblock_builder.reset_cache()\nblock_builder.peer_id = _block.header.peer_id\n- block_builder.signature = _block.header.signature\nblock_builder.commit_state = {\nChannelProperty().name: response['stateRootHash']\n@@ -794,6 +797,10 @@ class ChannelService:\nblock_builder.state_hash = Hash32(bytes.fromhex(response['stateRootHash']))\nblock_builder.receipts = tx_receipts\nblock_builder.reps = self.get_rep_ids()\n+ if _block.header.peer_id.hex_hx() == ChannelProperty().peer_id:\n+ block_builder.signer = self.peer_auth\n+ else:\n+ block_builder.signature = _block.header.signature\nnew_block = block_builder.build()\nself.__block_manager.set_old_block_hash(new_block.header.hash, _block.header.hash)\n@@ -810,8 +817,12 @@ class ChannelService:\nlogging.debug(f\"call score commit {ChannelProperty().name} {block.header.height} {block.header.hash.hex()}\")\nnew_block_hash = block.header.hash\n+ try:\nold_block_hash = self.__block_manager.get_old_block_hash(new_block_hash)\n+ except KeyError:\n+ old_block_hash = new_block_hash\n+ logging.debug(f\"Block Hash : {old_block_hash} -> {new_block_hash}\")\nrequest = {\n\"blockHeight\": block.header.height,\n\"oldBlockHash\": old_block_hash.hex(),\n",
        "chatgpt_cot": "\"Add update and fetch methods to Channel for configtx update and block fetching functionality.\""
    },
    {
        "org_diff": "diff --git a/fkie_node_manager/src/fkie_node_manager/launch_list_model.py b/fkie_node_manager/src/fkie_node_manager/launch_list_model.py @@ -235,21 +235,21 @@ class PathItem(QStandardItem):\nnew_path = os.path.join(os.path.dirname(self.path), value)\ntry:\n# save a new file or rename existing file?\n- content = ''\n+ content = b''\nnew_id = self._identify_path_on_ext(new_path, self.id)\nif self._isnew:\nif new_id in [self.FOLDER]:\nnm.nmd().file.new(new_path, 1)\nelif new_id in [self.LAUNCH_FILE]:\n- content = (\"<launch>\\n\"\n- \" <arg name=\\\"robot_ns\\\" default=\\\"my_robot\\\"/>\\n\"\n- \" <group ns=\\\"$(arg robot_ns)\\\">\\n\"\n- \" <node pkg=\\\"my_pkg\\\" type=\\\"my_node\\\" name=\\\"my_name\\\" >\\n\"\n- \" <param name=\\\"capability_group\\\" value=\\\"MY_GROUP\\\"/>\\n\"\n- \" </node>\\n\"\n- \" </group>\\n\"\n- \"</launch>\\n\")\n- nm.nmd().file.save_file(new_path, bytes(content), 0)\n+ content = (b'<launch>\\n'\n+ b' <arg name=\"robot_ns\" default=\"my_robot\"/>\\n'\n+ b' <group ns=\"$(arg robot_ns)\">\\n'\n+ b' <node pkg=\"my_pkg\" type=\"my_node\" name=\"my_name\" >\\n'\n+ b' <param name=\"capability_group\" value=\"MY_GROUP\"/>\\n'\n+ b' </node>\\n'\n+ b' </group>\\n'\n+ b'</launch>\\n')\n+ nm.nmd().file.save_file(new_path, content, 0)\nelse:\nnm.nmd().file.new(new_path, 0)\nself._isnew = False\n",
        "org_msg": "fkie_node_manager: fixed create new file in launch widget",
        "sim_msg": "tuple is returned",
        "sim_diff": "diff --git a/frappe/core/doctype/file/file.py b/frappe/core/doctype/file/file.py @@ -80,10 +80,10 @@ class File(Document):\ndef after_rename(self, olddn, newdn, merge=False):\nfor successor in self.get_successor():\n- setup_folder_path(successor, self.name)\n+ setup_folder_path(successor[0], self.name)\ndef get_successor(self):\n- return frappe.db.get_value(doctype='File',\n+ return frappe.db.get_values(doctype='File',\nfilters={'folder': self.name},\nfieldname='name')\n",
        "chatgpt_cot": "Fix file content encoding issue in launch_list_model.py. Change content variable to bytes type to correctly save launch file content."
    },
    {
        "org_diff": "diff --git a/build_image/dockerhub/latest/ansible-agent/Dockerfile b/build_image/dockerhub/latest/ansible-agent/Dockerfile @@ -7,7 +7,7 @@ FROM alpine/git AS BUILD\nRUN cd /tmp && git init cello && cd cello && \\\ngit remote add origin https://github.com/hyperledger/cello.git && \\\ngit config core.sparsecheckout true && \\\n- echo \"src/agent/ansible/*\" >> .git/info/sparse-checkout && \\\n+ echo \"src/operator-dashboard/agent/ansible/*\" >> .git/info/sparse-checkout && \\\ngit pull --depth=1 origin master\nFROM ubuntu:xenial\n",
        "org_msg": "Fix ansible agent docker hub build\nAnsible agent docker hub build was broken.this patch\nset fixes the issue",
        "sim_msg": "Update dockerfile to allow downloading against a specific git tag",
        "sim_diff": "diff --git a/docker/Dockerfile b/docker/Dockerfile @@ -4,6 +4,9 @@ FROM alpine:3.13 as base\nARG repository=\"https://github.com/inventree/InvenTree.git\"\nARG branch=\"master\"\n+# Optionally specify a particular tag to checkout\n+ARG tag=\"\"\n+\nENV PYTHONUNBUFFERED 1\n# InvenTree key settings\n@@ -12,8 +15,9 @@ ENV PYTHONUNBUFFERED 1\nENV INVENTREE_HOME=\"/home/inventree\"\n# GitHub settings\n-ENV INVENTREE_REPO=\"${repository}\"\n-ENV INVENTREE_BRANCH=\"${branch}\"\n+ENV INVENTREE_GIT_REPO=\"${repository}\"\n+ENV INVENTREE_GIT_BRANCH=\"${branch}\"\n+ENV INVENTREE_GIT_TAG=\"${tag}\"\nENV INVENTREE_LOG_LEVEL=\"INFO\"\nENV INVENTREE_DOCKER=\"true\"\n@@ -80,8 +84,12 @@ RUN pip install --no-cache-dir -U gunicorn\nFROM base as production\n# Clone source code\n-RUN echo \"Downloading InvenTree from ${INVENTREE_REPO}\"\n-RUN git clone --branch ${INVENTREE_BRANCH} --depth 1 ${INVENTREE_REPO} ${INVENTREE_HOME}\n+RUN echo \"Downloading InvenTree from ${INVENTREE_GIT_REPO}\"\n+\n+RUN git clone --branch ${INVENTREE_GIT_BRANCH} --depth 1 ${INVENTREE_GIT_REPO} ${INVENTREE_HOME}\n+\n+# Checkout against a particular git tag\n+RUN if [ -n \"${INVENTREE_GIT_TAG}\" ] ; then cd ${INVENTREE_HOME} && git fetch --all --tags && git checkout tags/${INVENTREE_GIT_TAG} -b v${INVENTREE_GIT_TAG}-branch ; fi\n# Install InvenTree packages\nRUN pip install --no-cache-dir -U -r ${INVENTREE_HOME}/requirements.txt\n",
        "chatgpt_cot": "Update sparse-checkout path in Dockerfile to include src/operator-dashboard/agent/ansible/* from hyperledger/cello.git. Fixes issue with sparse checkout."
    },
    {
        "org_diff": "diff --git a/sc2/unit.py b/sc2/unit.py @@ -178,6 +178,24 @@ class Unit(object):\n\"\"\" Checks if a geyser has gas remaining (cant build extractors on empty geysers), useful for lategame \"\"\"\nreturn self._proto.vespene_contents > 0\n+ @property\n+ def can_attack_ground(self):\n+ # See data_pb2.py line 141 for info on weapon data\n+ if hasattr(self._type_data._proto, \"weapons\"):\n+ weapons = self._type_data._proto.weapons\n+ weapon = next((weapon for weapon in weapons if weapon.type in [1, 3]), None)\n+ return weapon is not None\n+ return False\n+\n+ @property\n+ def can_attack_air(self):\n+ # See data_pb2.py line 141 for info on weapon data\n+ if hasattr(self._type_data._proto, \"weapons\"):\n+ weapons = self._type_data._proto.weapons\n+ weapon = next((weapon for weapon in weapons if weapon.type in [2, 3]), None)\n+ return weapon is not None\n+ return False\n+\n@property\ndef is_selected(self):\nreturn self._proto.is_selected\n",
        "org_msg": "Add checks if Unit can attack ground and/or air",
        "sim_msg": "changed selection mode from MultiItem to ExtendedItemSelection",
        "sim_diff": "diff --git a/qualcoder/select_items.py b/qualcoder/select_items.py @@ -33,6 +33,7 @@ import logging\nimport traceback\nfrom GUI.ui_dialog_select_items import Ui_Dialog_selectitems\n+from helpers import Message\npath = os.path.abspath(os.path.dirname(__file__))\nlogger = logging.getLogger(__name__)\n@@ -63,8 +64,13 @@ class DialogSelectItems(QtWidgets.QDialog):\ntitle = None\ndef __init__(self, app, data, title, selectionmode):\n- \"\"\" present list of name to user for selection.\n- data is a list of dictionaries containing the key 'name' \"\"\"\n+ \"\"\" present list of names to user for selection.\n+\n+ params:\n+ data: list of dictionaries containing the key 'name'\n+ title: Dialog title, String\n+ selectionmode: 'single' or anything else for 'multiple', String\n+ \"\"\"\nsys.excepthook = exception_handler\nQtWidgets.QDialog.__init__(self)\n@@ -78,16 +84,16 @@ class DialogSelectItems(QtWidgets.QDialog):\nself.selection_mode = selectionmode\n# Check data exists\nif len(data) == 0:\n- QtWidgets.QMessageBox.critical(None, _('Dictionary is empty'), \"No data to select from\")\n-\n+ Message(app, _('Dictionary is empty'), _(\"No data to select from\"), \"warning\")\n# Check for 'name' key\nno_name_key = False\n+\nfor d in data:\nif not d['name']:\nno_name_key = True\nif no_name_key:\n- text = \"This data has no name to select from\"\n- QtWidgets.QMessageBox.critical(None, _('Dictionary has no \"name\" key'), text)\n+ text = _(\"This data does not contain names to select from\")\n+ Message(app, _('Dictionary has no \"name\" key'), text, \"warning\")\nself.dict_list = data\nself.model = list_model(self.dict_list)\n@@ -95,7 +101,7 @@ class DialogSelectItems(QtWidgets.QDialog):\nif self.selection_mode == \"single\":\nself.ui.listView.setSelectionMode(QtWidgets.QAbstractItemView.SingleSelection)\nelse:\n- self.ui.listView.setSelectionMode(QtWidgets.QAbstractItemView.MultiSelection)\n+ self.ui.listView.setSelectionMode(QtWidgets.QAbstractItemView.ExtendedSelection)\nself.ui.listView.doubleClicked.connect(self.accept)\ndef get_selected(self):\n",
        "chatgpt_cot": "Add properties for checking if unit can attack ground and air, utilizing weapon data. Fixes issue with checking unit attack capabilities."
    },
    {
        "org_diff": "diff --git a/src/api-engine/api/config.py b/src/api-engine/api/config.py CELLO_HOME = \"/opt/cello\"\nFABRIC_TOOL = \"/opt/bin\"\nFABRIC_CFG = \"/opt/node\"\n-FABRIC_NODE = \"/opt/fabric\"\n-PRODUCTION_NODE = \"/opt/production\"\n+FABRIC_NODE = \"/opt/hyperledger/fabric\"\n+PRODUCTION_NODE = \"/opt/hyperledger/production\"\nFABRIC_PEER_CFG = \"/opt/node/peer.yaml.bak\"\nFABRIC_ORDERER_CFG = \"/opt/node/orderer.yaml.bak\"\n",
        "org_msg": "Update config variable.",
        "sim_msg": "Update config required",
        "sim_diff": "diff --git a/config_bot.py b/config_bot.py -API_KEY_ALPHAVANTAGE = 'P6YGOQ6FL6OEIZ3B'\n-API_KEY_FINANCIALMODELINGPREP = \"845b22316eeec4168d249976bba94330\"\n\\ No newline at end of file\n+API_KEY_ALPHAVANTAGE = \"EXAMPLE\"\n+API_KEY_FINANCIALMODELINGPREP = \"EXAMPLE\"\n+API_REDDIT_CLIENT_ID = \"EXAMPLE\"\n+API_REDDIT_CLIENT_SECRET = \"EXAMPLE\"\n+API_REDDIT_USERNAME = \"EXAMPLE\"\n+API_REDDIT_USER_AGENT = \"EXAMPLE\"\n+API_REDDIT_PASSWORD = \"EXAMPLE\"\n",
        "chatgpt_cot": "Update fabric and production node paths to hyperledger directory in config.py."
    },
    {
        "org_diff": "diff --git a/src/api-engine/api/routes/channel/serializers.py b/src/api-engine/api/routes/channel/serializers.py @@ -3,7 +3,6 @@ from rest_framework import serializers\nfrom api.models import Channel\nfrom api.common.serializers import ListResponseSerializer\n-from api.routes.organization.serializers import OrganizationResponse\nclass ChannelCreateBody(serializers.Serializer):\n",
        "org_msg": "Removed unused libs.",
        "sim_msg": "Added validation method for uploaded file using imghdr library",
        "sim_diff": "diff --git a/InvenTree/part/serializers.py b/InvenTree/part/serializers.py \"\"\"\nJSON serializers for Part app\n\"\"\"\n+import imghdr\nfrom rest_framework import serializers\n@@ -95,6 +96,15 @@ class PartThumbSerializer(serializers.Serializer):\nclass PartThumbSerializerUpdate(InvenTreeModelSerializer):\n\"\"\" Serializer for updating Part thumbnail \"\"\"\n+ def validate_image(self, value):\n+ \"\"\"\n+ Check that file is an image.\n+ \"\"\"\n+ validate = imghdr.what(value)\n+ if not validate:\n+ raise serializers.ValidationError(\"File is not an image\")\n+ return value\n+\nimage = InvenTreeAttachmentSerializerField(required=True)\nclass Meta:\n",
        "chatgpt_cot": "\"Remove unused import and class reference in serializers.py\""
    },
    {
        "org_diff": "diff --git a/.travis.yml b/.travis.yml @@ -33,6 +33,7 @@ jobs:\n- docker exec -i app bash -c \"cd /root/template && pipenv install --dev --python 3.7\"\n# Run tests\n- docker exec -i app bash -c \"cd /root/template && pipenv run pytest test/\"\n+ # Benchmark tests\n# - docker exec -i app bash -c \"cd /root/template && pipenv run pytest test/benchmark_distance_two_points.py --benchmark-compare\"\n# - docker exec -i app bash -c \"cd /root/template && pipenv run pytest test/benchmark_distances_units.py --benchmark-compare\"\n# - docker exec -i app bash -c \"cd /root/template && pipenv run pytest test/benchmark_array_creation.py --benchmark-compare\"\n@@ -67,7 +68,7 @@ jobs:\n# Shut down and remove container after finishing\n- docker rm -f app\n-\n+ - stage: release to Pypi\nbefore_deploy:\n- pip install pipenv\ndeploy:\n",
        "org_msg": "Indent release script",
        "sim_msg": "Clear test cache",
        "sim_diff": "diff --git a/.travis.yml b/.travis.yml @@ -20,7 +20,7 @@ install:\n# command to run the dependencies\nscript:\n- - 'if [[ \"$TEST_SUITE\" == \"install\" ]]; then rm -fr ~/.cache/pip; fi'\n+ - 'if [[ \"$TEST_SUITE\" == \"install\" ]]; then export PYTEST_ADDOPTS=\"--cache-clear\"; fi'\n- \"pipenv run bash ./run-tests.sh\"\njobs:\n",
        "chatgpt_cot": "Add benchmark tests and release to PyPi stage in Travis CI configuration. Fix indentation issue."
    },
    {
        "org_diff": "diff --git a/sc2/bot_ai.py b/sc2/bot_ai.py @@ -328,6 +328,11 @@ class BotAI(object):\nreturn r\nasync def do_actions(self, actions):\n+ for action in actions:\n+ cost = self._game_data.calculate_ability_cost(action.ability)\n+ self.minerals -= cost.minerals\n+ self.vespene -= cost.vespene\n+\nr = await self._client.actions(actions, game_data=self._game_data)\nreturn r\n",
        "org_msg": "Add resource subtraction on action execute attempt",
        "sim_msg": "Forgot to update iNumPlayers",
        "sim_diff": "diff --git a/v3/runner.py b/v3/runner.py @@ -63,6 +63,8 @@ if __name__ == '__main__':\ncallbacks = []\nname_dict = dict()\n+ gameInputPacket.iNumPlayers = num_bots\n+\n# Set configuration values for bots and store name and team\nfor i in range(num_bots):\nbot_config = configparser.RawConfigParser()\n",
        "chatgpt_cot": "Add resource deduction for actions in do_actions method in BotAI."
    },
    {
        "org_diff": "diff --git a/sc2/game_state.py b/sc2/game_state.py from .units import Units\nfrom .power_source import PsionicMatrix\nfrom .pixel_map import PixelMap\n+from .ids.upgrade_id import UpgradeId\n+from .ids.effect_id import EffectId\nclass Common(object):\nATTRIBUTES = [\n@@ -27,7 +29,7 @@ class GameState(object):\ndestructables = [x for x in observation.observation.raw_data.units if x.alliance == 3 and x.radius > 1.5] # all destructable rocks except the one below the main base ramps\nself.destructables = Units.from_proto(destructables, game_data)\n- # fix for enemy units detected by sensor tower\n+ # fix for enemy units detected by my sensor tower\nvisibleUnits, hiddenUnits = [], []\nfor u in observation.observation.raw_data.units:\nhiddenUnits.append(u) if u.is_blip else visibleUnits.append(u)\n@@ -37,6 +39,10 @@ class GameState(object):\nself.visibility = PixelMap(observation.observation.raw_data.map_state.visibility)\nself.creep = PixelMap(observation.observation.raw_data.map_state.creep)\n+ self.dead_units = {dead_unit_tag for dead_unit_tag in observation.observation.raw_data.event.dead_units} # set of unit tags that died this step - sometimes has multiple entries\n+ self.effects = {EffectId(effect) for effect in observation.observation.raw_data.effects} # effects like ravager bile shot, lurker attack, everything in effect_id.py # usage: if RAVAGERCORROSIVEBILECP in self.state.effects: do stuff\n+ self.upgrades = {UpgradeId(upgrade) for upgrade in observation.observation.raw_data.player.upgrade_ids} # usage: if TERRANINFANTRYWEAPONSLEVEL1 in self.state.upgrades: do stuff\n+\n@property\ndef mineral_field(self):\nreturn self.units.mineral_field\n",
        "org_msg": "Add dead unit events, effects and upgrades",
        "sim_msg": "Change to using scipy constants.",
        "sim_diff": "diff --git a/SimPEG/FLOW/Richards/Empirical.py b/SimPEG/FLOW/Richards/Empirical.py @@ -5,6 +5,7 @@ from __future__ import unicode_literals\nimport numpy as np\nimport scipy.sparse as sp\n+from scipy import constants\nfrom SimPEG import Utils, Props\n@@ -575,77 +576,77 @@ class VanGenuchtenParams(object):\ndef sand(self):\nreturn {\n\"theta_r\": 0.020, \"theta_s\": 0.417, \"alpha\": 0.138*100.,\n- \"n\": 1.592, \"Ks\": 504.0/100./24./60./60.\n+ \"n\": 1.592, \"Ks\": 504.0*constants.centi/constants.day\n}\n@property\ndef loamy_sand(self):\nreturn {\n\"theta_r\": 0.035, \"theta_s\": 0.401, \"alpha\": 0.115*100.,\n- \"n\": 1.474, \"Ks\": 146.6/100./24./60./60.\n+ \"n\": 1.474, \"Ks\": 146.6*constants.centi/constants.day\n}\n@property\ndef sandy_loam(self):\nreturn {\n\"theta_r\": 0.041, \"theta_s\": 0.412, \"alpha\": 0.068*100.,\n- \"n\": 1.322, \"Ks\": 62.16/100./24./60./60.\n+ \"n\": 1.322, \"Ks\": 62.16*constants.centi/constants.day\n}\n@property\ndef loam(self):\nreturn {\n\"theta_r\": 0.027, \"theta_s\": 0.434, \"alpha\": 0.090*100.,\n- \"n\": 1.220, \"Ks\": 16.32/100./24./60./60.\n+ \"n\": 1.220, \"Ks\": 16.32*constants.centi/constants.day\n}\n@property\ndef silt_loam(self):\nreturn {\n\"theta_r\": 0.015, \"theta_s\": 0.486, \"alpha\": 0.048*100.,\n- \"n\": 1.211, \"Ks\": 31.68/100./24./60./60.\n+ \"n\": 1.211, \"Ks\": 31.68*constants.centi/constants.day\n}\n@property\ndef sandy_clay_loam(self):\nreturn {\n\"theta_r\": 0.068, \"theta_s\": 0.330, \"alpha\": 0.036*100.,\n- \"n\": 1.250, \"Ks\": 10.32/100./24./60./60.\n+ \"n\": 1.250, \"Ks\": 10.32*constants.centi/constants.day\n}\n@property\ndef clay_loam(self):\nreturn {\n\"theta_r\": 0.075, \"theta_s\": 0.390, \"alpha\": 0.039*100.,\n- \"n\": 1.194, \"Ks\": 5.52/100./24./60./60.\n+ \"n\": 1.194, \"Ks\": 5.52*constants.centi/constants.day\n}\n@property\ndef silty_clay_loam(self):\nreturn {\n\"theta_r\": 0.040, \"theta_s\": 0.432, \"alpha\": 0.031*100.,\n- \"n\": 1.151, \"Ks\": 3.60/100./24./60./60.\n+ \"n\": 1.151, \"Ks\": 3.60*constants.centi/constants.day\n}\n@property\ndef sandy_clay(self):\nreturn {\n\"theta_r\": 0.109, \"theta_s\": 0.321, \"alpha\": 0.034*100.,\n- \"n\": 1.168, \"Ks\": 2.88/100./24./60./60.\n+ \"n\": 1.168, \"Ks\": 2.88*constants.centi/constants.day\n}\n@property\ndef silty_clay(self):\nreturn {\n\"theta_r\": 0.056, \"theta_s\": 0.423, \"alpha\": 0.029*100.,\n- \"n\": 1.127, \"Ks\": 2.16/100./24./60./60.\n+ \"n\": 1.127, \"Ks\": 2.16*constants.centi/constants.day\n}\n@property\ndef clay(self):\nreturn {\n\"theta_r\": 0.090, \"theta_s\": 0.385, \"alpha\": 0.027*100.,\n- \"n\": 1.131, \"Ks\": 1.44/100./24./60./60.\n+ \"n\": 1.131, \"Ks\": 1.44*constants.centi/constants.day\n}\n# From:\n",
        "chatgpt_cot": "Add UpgradeId and EffectId imports, fix sensor tower comment, and add new attributes for dead units and upgrades."
    },
    {
        "org_diff": "diff --git a/fkie_node_manager_daemon/src/fkie_node_manager_daemon/launcher.py b/fkie_node_manager_daemon/src/fkie_node_manager_daemon/launcher.py @@ -203,8 +203,8 @@ def run_node(startcfg):\nif 'DISPLAY' in startcfg.env:\nif not startcfg.env['DISPLAY'] or startcfg.env['DISPLAY'] == 'remote':\ndel startcfg.env['DISPLAY']\n- else:\n- new_env['DISPLAY'] = ':0'\n+ #else:\n+ # new_env['DISPLAY'] = ':0'\n# add environment from launch\nnew_env.update(startcfg.env)\nif startcfg.namespace:\n",
        "org_msg": "changed screen environment: do not set DISPLAY environment",
        "sim_msg": "retry startup",
        "sim_diff": "diff --git a/lbrynet/lbrynet_daemon/DaemonControl.py b/lbrynet/lbrynet_daemon/DaemonControl.py @@ -114,7 +114,7 @@ def update_settings_from_args(args):\n@defer.inlineCallbacks\n-def start_server_and_listen(launchui, use_auth, analytics_manager):\n+def start_server_and_listen(launchui, use_auth, analytics_manager, max_tries=5):\n\"\"\"The primary entry point for launching the daemon.\nArgs:\n@@ -124,13 +124,19 @@ def start_server_and_listen(launchui, use_auth, analytics_manager):\n\"\"\"\nanalytics_manager.send_server_startup()\nlog_support.configure_analytics_handler(analytics_manager)\n+ tries = 1\n+ while tries < max_tries:\n+ log.info('Making attempt %s / %s to startup', tries, max_tries)\ntry:\ndaemon_server = DaemonServer(analytics_manager)\nyield daemon_server.start(use_auth, launchui)\nanalytics_manager.send_server_startup_success()\n+ break\nexcept Exception as e:\nlog.exception('Failed to startup')\nanalytics_manager.send_server_startup_error(str(e))\n+ tries += 1\n+ else:\nreactor.callFromThread(reactor.stop)\n",
        "chatgpt_cot": "Refactor environment setup in launcher.py by commenting out unnecessary code for setting DISPLAY variable to ':0', ensuring proper environment configuration."
    },
    {
        "org_diff": "diff --git a/sc2/main.py b/sc2/main.py @@ -121,7 +121,12 @@ async def _play_game_ai(client, player_id, ai, realtime, step_time_limit, game_t\nstate = await client.observation()\n# check game result every time we get the observation\nif client._game_result:\n+ try:\nawait ai.on_end(client._game_result[player_id])\n+ except TypeError as error:\n+ # print(f\"caught type error {error}\")\n+ # print(f\"return {client._game_result[player_id]}\")\n+ return client._game_result[player_id]\nreturn client._game_result[player_id]\ngs = GameState(state.observation)\nlogger.debug(f\"Score: {gs.score.summary}\")\n@@ -202,7 +207,12 @@ async def _play_game_ai(client, player_id, ai, realtime, step_time_limit, game_t\nlogger.exception(f\"AI step threw an error\") # DO NOT EDIT!\nlogger.error(f\"Error: {e}\")\nlogger.error(f\"Resigning due to previous error\")\n+ try:\nawait ai.on_end(Result.Defeat)\n+ except TypeError as error:\n+ # print(f\"caught type error {error}\")\n+ # print(f\"return {Result.Defeat}\")\n+ return Result.Defeat\nreturn Result.Defeat\nlogger.debug(f\"Running AI step: done\")\n",
        "org_msg": "Fix TypeError on game end",
        "sim_msg": "Use `mode.value` instead enumerate.",
        "sim_diff": "diff --git a/app/objects/player.py b/app/objects/player.py @@ -536,14 +536,14 @@ class Player:\nasync with app.state.services.database.connection() as db_conn:\nawait self.stats_from_sql_full(db_conn)\n- for idx, mode_stat in enumerate(self.stats.values()):\n+ for mode, stats in self.stats.items():\nawait app.state.services.redis.zadd(\n- f\"gulag:leaderboard:{idx}\",\n- {self.id: mode_stat.pp},\n+ f\"gulag:leaderboard:{mode.value}\",\n+ {self.id: stats.pp},\n)\nawait app.state.services.redis.zadd(\n- f\"gulag:leaderboard:{idx}:{self.geoloc['country']['acronym']}\",\n- {self.id: mode_stat.pp},\n+ f\"gulag:leaderboard:{mode.value}:{self.geoloc['country']['acronym']}\",\n+ {self.id: stats.pp},\n)\nif \"restricted\" in self.__dict__:\n",
        "chatgpt_cot": "Add exception handling for AI on_end method to prevent TypeError, ensuring proper game result handling in main game loop."
    },
    {
        "org_diff": "diff --git a/sc2/bot_ai.py b/sc2/bot_ai.py @@ -1572,7 +1572,8 @@ class BotAI(DistanceCalculation):\n# Check if a unit took damage this frame and then trigger event\nprevious_frame_unit: Unit = self._units_previous_map[unit.tag]\nif unit.health < previous_frame_unit.health or unit.shield < previous_frame_unit.shield:\n- await self.on_unit_took_damage(unit)\n+ damage_amount = previous_frame_unit.health - unit.health + previous_frame_unit.shield - unit.shield\n+ await self.on_unit_took_damage(unit, damage_amount)\nasync def _issue_upgrade_events(self):\ndifference = self.state.upgrades - self._previous_upgrades\n@@ -1593,7 +1594,8 @@ class BotAI(DistanceCalculation):\nstructure.health < previous_frame_structure.health\nor structure.shield < previous_frame_structure.shield\n):\n- await self.on_unit_took_damage(structure)\n+ damage_amount = previous_frame_structure.health - structure.health + previous_frame_structure.shield - structure.shield\n+ await self.on_unit_took_damage(structure, damage_amount)\n# From here on, only check completed structure, so we ignore structures with build_progress < 1\nif structure.build_progress < 1:\ncontinue\n@@ -1664,7 +1666,7 @@ class BotAI(DistanceCalculation):\n:param upgrade:\n\"\"\"\n- async def on_unit_took_damage(self, unit: Unit):\n+ async def on_unit_took_damage(self, unit: Unit, amount_damage_taken: float):\n\"\"\"\nOverride this in your bot class. This function is called when a unit (unit or structure) took damage. It will not be called if the unit died this frame.\nThis may be called frequently for terran structures that are burning down, or zerg buildings that are off creep, or terran bio units that just used stimpack ability.\n",
        "org_msg": "Add amount of damage taken to on_unit_took_damage event",
        "sim_msg": "added time to the saved files",
        "sim_diff": "diff --git a/bot_manager.py b/bot_manager.py @@ -178,7 +178,7 @@ class BotManager:\ncurrent_time = game_tick_packet.gameInfo.TimeSeconds\nif self.save_data and game_tick_packet.gameInfo.bRoundActive and not old_time == current_time and not current_time == -10:\n- np_input = self.input_converter.create_input_array(game_tick_packet)\n+ np_input = self.input_converter.create_input_array(game_tick_packet, passed_time=time.time() - before2)\nnp_output = np.array(controller_input, dtype=np.float32)\nself.input_array = np.append(self.input_array, np_input)\nself.output_array = np.append(self.output_array, np_output)\n",
        "chatgpt_cot": "Add damage amount parameter to on_unit_took_damage method for better tracking of damage taken by units and structures in BotAI class."
    },
    {
        "org_diff": "diff --git a/README.md b/README.md @@ -69,9 +69,9 @@ SC2PATH=/home/burny/Games/battlenet/drive_c/Program Files (x86)/StarCraft II/\n#### WSL\n-WSL1 should not require any configuration. You may be asked to allow Python through your firewall.\n+WSL version 1 should not require any configuration. You may be asked to allow Python through your firewall.\n-When running WSL you need to supply the following environment variables so that your bot can connect:\n+When running WSL version 2 you need to supply the following environment variables so that your bot can connect:\n```sh\nSC2CLIENTHOST=<your windows IP>\n",
        "org_msg": "Update README.md\nClarifies WSL v1 versus v2 in WSL setup instructions.",
        "sim_msg": "setup: conditionally require pydocstyle 3",
        "sim_diff": "diff --git a/setup.py b/setup.py @@ -47,7 +47,8 @@ INSTALL_REQUIRES = [\n'troposphere>=2.4.2',\n# botocore pins its urllib3 dependency like this, so we need to do the\n# same to ensure v1.25+ isn't pulled in by pip\n- 'urllib3>=1.20,<1.25'\n+ 'urllib3>=1.20,<1.25',\n+ \"pydocstyle<=3.0.0; python_version<'3'\"\n]\n# pylint v2+ is only py3 compatible\n",
        "chatgpt_cot": "Update README to specify environment variable requirements for WSL version 2 and clarify version numbering for WSL throughout the file."
    },
    {
        "org_diff": "diff --git a/src/api-engine/api/lib/peer/chaincode.py b/src/api-engine/api/lib/peer/chaincode.py @@ -109,6 +109,7 @@ class ChainCode(BasicEnv):\n:param sequence: The channel chain code defines the serial number. The default value is 1\n:return:\n\"\"\"\n+ try:\nres, installed = self.lifecycle_query_installed(\"3s\")\ncc_label = cc_name+\"_\"+chaincode_version\npackage_id = \"\"\n@@ -139,6 +140,9 @@ class ChainCode(BasicEnv):\nelse:\nstderr = str(stderr, encoding=\"utf-8\")\nreturn return_code, stderr\n+ except Exception as e:\n+ err_msg = \"lifecycle_approve_for_my_org failed for {}!\".format(e)\n+ raise Exception(err_msg)\nreturn return_code, content\ndef lifecycle_query_approved(self, channel_name, cc_name):\n@@ -149,6 +153,7 @@ class ChainCode(BasicEnv):\n:return:\n\"\"\"\n+ try:\nres = subprocess.Popen(\"{} lifecycle chaincode queryapproved --output json --channelID {}\"\n\" --name {}\".format(self.peer, channel_name, cc_name),\nshell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n@@ -160,6 +165,9 @@ class ChainCode(BasicEnv):\nelse:\nstderr = str(stderr, encoding=\"utf-8\")\nreturn return_code, stderr\n+ except Exception as e:\n+ err_msg = \"lifecycle_query_approved failed for {}!\".format(e)\n+ raise Exception(err_msg)\nreturn return_code, chaincodes_info\n@@ -176,6 +184,7 @@ class ChainCode(BasicEnv):\n:param sequence:The channel chain code defines the serial number. The default value is 1\n:return:\n\"\"\"\n+ try:\nif os.getenv(\"CORE_PEER_TLS_ENABLED\") == \"false\" or os.getenv(\"CORE_PEER_TLS_ENABLED\") is None:\nres = subprocess.Popen(\"{} lifecycle chaincode checkcommitreadiness --output json \"\n\" --channelID {} --name {} --version {} --init-required --sequence {} \"\n@@ -207,6 +216,9 @@ class ChainCode(BasicEnv):\nelse:\nstderr = str(stderr, encoding=\"utf-8\")\nreturn return_code, stderr\n+ except Exception as e:\n+ err_msg = \"lifecycle_check_commit_readiness failed for {}!\".format(e)\n+ raise Exception(err_msg)\ndef lifecycle_commit(self, orderer_url, orderer_tls_rootcert, channel_name, cc_name, chaincode_version,\npolicy, peerlist, peer_root_certs, sequency=1):\n@@ -224,6 +236,7 @@ class ChainCode(BasicEnv):\n:param sequency:The channel chain code defines the serial number. The default value is 1\n:return:\n\"\"\"\n+ try:\npeer_addresses_format = \" --peerAddresses {} --tlsRootCertFiles {}\"\ncommand_str_with_tls = \"{} lifecycle chaincode commit -o {} --tls --cafile {} \" \\\n\"--channelID {} --name {} --version {} --init-required --sequence {} \" \\\n@@ -245,5 +258,8 @@ class ChainCode(BasicEnv):\ncommand_str_with_tls = command_str_with_tls + peer_addresses_format\nres = os.system(command_str_with_tls.format(self.peer, orderer_url, orderer_tls_rootcert, channel_name,\ncc_name, chaincode_version, sequency, policy, *peer_addressed))\n+ except Exception as e:\n+ err_msg = \"lifecycle_commit failed for {}!\".format(e)\n+ raise Exception(err_msg)\nres = res >> 8\nreturn res\n",
        "org_msg": "[#issue-330] cmdlinelib implement of lifecycle_check_commit_readiness\ncmdlinelib implement of lifecycle_check_commit_readiness&lifecycle_commit functions\nClose #issue-330",
        "sim_msg": "delete response_temp from load peer from iiss",
        "sim_diff": "diff --git a/loopchain/channel/channel_service.py b/loopchain/channel/channel_service.py @@ -305,7 +305,7 @@ class ChannelService:\ndef reset_network_by_block_height(self, height):\nself._load_peers_from_iiss()\nif self.__peer_manager.get_peer(ChannelProperty().peer_id) and self.state_machine.state == \"Watch\":\n- util.logger.notice(f\"Prep({ChannelProperty().peer_id}) test right is enabled.\")\n+ utils.logger.notice(f\"Prep({ChannelProperty().peer_id}) test right is enabled.\")\nself.__state_machine.switch_role()\nreturn\n@@ -457,14 +457,14 @@ class ChannelService:\nutils.logger.notice(f\"from icon service channels is {response}\")\npeer_ids = ''\n- for preps in response_temp[\"result\"][\"preps\"]:\n+ for preps in response[\"result\"][\"preps\"]:\npeer_ids += preps['id']\nif self.__peer_manager.get_peer_ids_hash(peer_ids) == self.__peer_manager.peer_ids_hash():\n- util.logger.notice(f\"There is no change in peers.\")\n+ utils.logger.notice(f\"There is no change in peers.\")\nreturn\n- util.logger.notice(f\"Peer manager have to update with new list.\")\n+ utils.logger.notice(f\"Peer manager have to update with new list.\")\nself.__peer_manager.reset_peers(check_status=False)\norder = 1\n@@ -686,14 +686,14 @@ class ChannelService:\n:param complained:\n:return:\n\"\"\"\n- util.logger.notice(f\"do _load_peers_from_iiss in reset_leader\")\n+ utils.logger.notice(f\"do _load_peers_from_iiss in reset_leader\")\n# self._load_peers_from_iiss()\nif not self.__peer_manager.get_peer(ChannelProperty().peer_id):\n- util.exit_and_msg(f\"Prep({ChannelProperty().peer_id}) test right was expired.\")\n+ utils.exit_and_msg(f\"Prep({ChannelProperty().peer_id}) test right was expired.\")\n# epoch = self.block_manager.epoch\n# if epoch and epoch.leader_id == new_leader_id:\n- # util.logger.warning(f\"New leader({new_leader_id}) equals current epoch leader({epoch.leader_id})\")\n+ # utils.logger.warning(f\"New leader({new_leader_id}) equals current epoch leader({epoch.leader_id})\")\n# return\nutils.logger.info(f\"RESET LEADER channel({ChannelProperty().name}) leader_id({new_leader_id}), \"\n",
        "chatgpt_cot": "Add exception handling for lifecycle methods in ChainCode class to raise specific error messages."
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/__init__.py b/node_manager_fkie/src/node_manager_fkie/__init__.py @@ -57,8 +57,8 @@ PKG_NAME = 'node_manager_fkie'\n__author__ = \"Alexander Tiderko (Alexander.Tiderko@fkie.fraunhofer.de)\"\n__copyright__ = \"Copyright (c) 2012 Alexander Tiderko, Fraunhofer FKIE/US\"\n__license__ = \"BSD\"\n-__version__ = \"0.6.2\" # git describe --tags --dirty --always\n-__date__ = \"2016-11-12\" # git log -1 --date=iso\n+__version__ = \"0.7.0\" # git describe --tags --dirty --always\n+__date__ = \"2017-01-09\" # git log -1 --date=iso\n# PYTHONVER = (2, 7, 1)\n# if sys.version_info < PYTHONVER:\n",
        "org_msg": "node_manager_fkie: version info updated",
        "sim_msg": "MAINT: fix release version in docs conf.py",
        "sim_diff": "diff --git a/docs/conf.py b/docs/conf.py @@ -22,7 +22,7 @@ copyright = '2020, Projeto Jupiter'\nauthor = 'Giovani Hdalgo Ceotto'\n# The full version, including alpha/beta/rc tags\n-release = '0.9.7'\n+release = '0.9.8'\n# -- General configuration ---------------------------------------------------\n",
        "chatgpt_cot": "Update version and date in __init__.py from 0.6.2 to 0.7.0 and from 2016-11-12 to 2017-01-09."
    },
    {
        "org_diff": "diff --git a/node_manager_fkie/src/node_manager_fkie/editor/text_edit.py b/node_manager_fkie/src/node_manager_fkie/editor/text_edit.py @@ -311,9 +311,10 @@ class TextEdit(QTextEdit):\n# handle the shifting of the block\nif event.modifiers() == Qt.NoModifier and event.key() == Qt.Key_Tab:\nself.shiftText()\n- elif event.modifiers() == Qt.ControlModifier and event.key() == Qt.Key_Tab:\n+ elif event.modifiers() == Qt.ShiftModifier and event.key() == Qt.Key_Backtab:\nself.shiftText(back=True)\nelse:\n+ event.accept()\nQTextEdit.keyPressEvent(self, event)\nelse:\nevent.accept()\n",
        "org_msg": "node_manager_fkie: Tab and Backtab fixed",
        "sim_msg": "Fixed: Missing/ doubled accelerators in settings menu",
        "sim_diff": "diff --git a/extension/textext/asktext.py b/extension/textext/asktext.py @@ -505,7 +505,7 @@ if TOOLKIT in (GTK, GTKSOURCEVIEW):\n('ViewMenu', None, '_View'),\n('SettingsMenu', None, '_Settings'),\n('NewNodeContent', None, '_New Node Content'),\n- ('CloseShortcut', None, '_Close TexText Shortcut'),\n+ ('CloseShortcut', None, 'Close TexText _Shortcut'),\n('TabsWidth', None, '_Tabs Width'),\n]\nelse:\n@@ -551,17 +551,17 @@ if TOOLKIT in (GTK, GTKSOURCEVIEW):\nself._new_node_content_actions = [\n# name of action , stock id, label, accelerator, tooltip, callback/value\n- ('NewNodeContentEmpty', None, 'Empty', None, 'New node will be initialized with empty content', 0),\n- ('NewNodeContentInlineMath', None, 'Inline math', None, 'New node will be initialized with $ $', 1),\n- ('NewNodeContentDisplayMath', None, 'Display math', None, 'New node will be initialized with $$ $$', 2)\n+ ('NewNodeContentEmpty', None, '_Empty', None, 'New node will be initialized with empty content', 0),\n+ ('NewNodeContentInlineMath', None, '_Inline math', None, 'New node will be initialized with $ $', 1),\n+ ('NewNodeContentDisplayMath', None, '_Display math', None, 'New node will be initialized with $$ $$', 2)\n]\nnew_node_content = \"\\n\".join(\n['<menuitem action=\\'%s\\'/>' % action for (action, _, _, _, _, _) in self._new_node_content_actions])\nself._close_shortcut_actions = [\n- ('CloseShortcutEscape', None, 'ESC', None, 'TexText window closes when pressing ESC', 0),\n- ('CloseShortcutCtrlQ', None, 'CTRL + Q', None, 'TexText window closes when pressing CTRL + Q', 1),\n- ('CloseShortcutNone', None, 'None', None, 'No shortcut for closing TexText window', 2)\n+ ('CloseShortcutEscape', None, '_ESC', None, 'TexText window closes when pressing ESC', 0),\n+ ('CloseShortcutCtrlQ', None, 'CTRL + _Q', None, 'TexText window closes when pressing CTRL + Q', 1),\n+ ('CloseShortcutNone', None, '_None', None, 'No shortcut for closing TexText window', 2)\n]\nclose_shortcut = \"\\n\".join(\n['<menuitem action=\\'%s\\'/>' % action for (action, _, _, _, _, _) in self._close_shortcut_actions])\n",
        "chatgpt_cot": "\"Add handling for ShiftModifier and Key_Backtab in TextEdit keyPressEvent to shift text back.\""
    },
    {
        "org_diff": "diff --git a/sc2/unit.py b/sc2/unit.py @@ -53,6 +53,12 @@ class Unit(object):\n@property\ndef position(self):\n+ \"\"\"2d position of the unit.\"\"\"\n+ return self.position3d.to2\n+\n+ @property\n+ def position3d(self):\n+ \"\"\"3d position of the unit.\"\"\"\nreturn Point3.from_proto(self._proto.pos)\ndef distance_to(self, p):\n@@ -123,6 +129,12 @@ class Unit(object):\ndef health_max(self):\nreturn self._proto.health_max\n+ @property\n+ def health_percentage(self):\n+ if self._proto.health_max == 0:\n+ return 0\n+ return self._proto.health / self._proto.health_max\n+\n@property\ndef shield(self):\nreturn self._proto.shield\n@@ -131,18 +143,41 @@ class Unit(object):\ndef shield_max(self):\nreturn self._proto.shield_max\n+ @property\n+ def shield_percentage(self):\n+ if self._proto.shield_max == 0:\n+ return 0\n+ return self._proto.shield / self._proto.shield_max\n+\n@property\ndef energy(self):\nreturn self._proto.energy\n+ @property\n+ def energy_max(self):\n+ return self._proto.energy_max\n+\n+ @property\n+ def energy_percentage(self):\n+ if self._proto.energy_max == 0:\n+ return 0\n+ return self._proto.energy / self._proto.energy_max\n+\n@property\ndef mineral_contents(self):\n+ \"\"\" How many minerals a mineral field has left to mine from \"\"\"\nreturn self._proto.mineral_contents\n@property\ndef vespene_contents(self):\n+ \"\"\" How much gas is remaining in a geyser \"\"\"\nreturn self._proto.vespene_contents\n+ @property\n+ def has_vespene(self):\n+ \"\"\" Checks if a geyser has gas remaining (cant build extractors on empty geysers), useful for lategame \"\"\"\n+ return self._proto.vespene_contents > 0\n+\n@property\ndef is_selected(self):\nreturn self._proto.is_selected\n@@ -155,6 +190,26 @@ class Unit(object):\ndef noqueue(self):\nreturn len(self.orders) == 0\n+ @property\n+ def is_moving(self):\n+ return len(self.orders) > 0 and self.orders[0] in [AbilityId.MOVE]\n+\n+ @property\n+ def is_attacking(self):\n+ return len(self.orders) > 0 and self.orders[0] in [AbilityId.ATTACK]\n+\n+ @property\n+ def is_gathering(self):\n+ \"\"\" Checks if a unit is on its way to a mineral field / vespene geyser to mine \"\"\"\n+ return len(self.orders) > 0 and self.orders[0] in [AbilityId.HARVEST_GATHER]\n+\n+ @property\n+ def order_target(self):\n+ \"\"\" returns the target tag from the first order \"\"\"\n+ if len(self.orders) > 0:\n+ return self.orders[0].target\n+ return None\n+\n@property\ndef is_idle(self):\nreturn not self.orders\n@@ -175,6 +230,11 @@ class Unit(object):\ndef ideal_harvesters(self):\nreturn self._proto.ideal_harvesters\n+ @property\n+ def surplus_harvesters(self):\n+ \"\"\" returns a positive number if it has too many harvesters mining, a negative number if it has too few mining \"\"\"\n+ return self._proto.assigned_harvesters - self._proto.ideal_harvesters\n+\n@property\ndef name(self):\nreturn self._type_data.name\n",
        "org_msg": "Added a few more attributes",
        "sim_msg": "Use available quantities in part table, enhance stock badge",
        "sim_diff": "diff --git a/InvenTree/templates/js/translated/part.js b/InvenTree/templates/js/translated/part.js @@ -1160,12 +1160,14 @@ function partGridTile(part) {\nif (!part.in_stock) {\nstock = `<span class='badge rounded-pill bg-danger'>{% trans \"No Stock\" %}</span>`;\n+ } else if (!part.unallocated_stock) {\n+ stock = `<span class='badge rounded-pill bg-warning'>{% trans \"Not available\" %}</span>`;\n}\nrows += `<tr><td><b>{% trans \"Stock\" %}</b></td><td>${stock}</td></tr>`;\n- if (part.on_order) {\n- rows += `<tr><td><b>{$ trans \"On Order\" %}</b></td><td>${part.on_order}</td></tr>`;\n+ if (part.ordering) {\n+ rows += `<tr><td><b>{% trans \"On Order\" %}</b></td><td>${part.ordering}</td></tr>`;\n}\nif (part.building) {\n@@ -1322,32 +1324,48 @@ function loadPartTable(table, url, options={}) {\ncolumns.push(col);\ncol = {\n- field: 'in_stock',\n- title: '{% trans \"Stock\" %}',\n+ field: 'unallocated_stock',\n+ title: '{% trans \"Available\" %}',\nsearchable: false,\nformatter: function(value, row) {\nvar link = '?display=part-stock';\n- if (value) {\n+ if (row.in_stock) {\n// There IS stock available for this part\n// Is stock \"low\" (below the 'minimum_stock' quantity)?\n- if (row.minimum_stock && row.minimum_stock > value) {\n+ if (row.minimum_stock && row.minimum_stock > row.in_stock) {\nvalue += `<span class='badge badge-right rounded-pill bg-warning'>{% trans \"Low stock\" %}</span>`;\n+ } else if (value == 0) {\n+ if (row.ordering) {\n+ // There is no available stock, but stock is on order\n+ value = `0<span class='badge badge-right rounded-pill bg-info'>{% trans \"On Order\" %}: ${row.ordering}</span>`;\n+ link = '?display=purchase-orders';\n+ } else if (row.building) {\n+ // There is no available stock, but stock is being built\n+ value = `0<span class='badge badge-right rounded-pill bg-info'>{% trans \"Building\" %}: ${row.building}</span>`;\n+ link = '?display=build-orders';\n+ } else {\n+ // There is no available stock\n+ value = `0<span class='badge badge-right rounded-pill bg-warning'>{% trans \"Not available\" %}</span>`;\n+ }\n}\n+ } else {\n+ // There IS NO stock available for this part\n- } else if (row.on_order) {\n- // There is no stock available, but stock is on order\n- value = `0<span class='badge badge-right rounded-pill bg-info'>{% trans \"On Order\" %}: ${row.on_order}</span>`;\n+ if (row.ordering) {\n+ // There is no stock, but stock is on order\n+ value = `0<span class='badge badge-right rounded-pill bg-info'>{% trans \"On Order\" %}: ${row.ordering}</span>`;\nlink = '?display=purchase-orders';\n} else if (row.building) {\n- // There is no stock available, but stock is being built\n+ // There is no stock, but stock is being built\nvalue = `0<span class='badge badge-right rounded-pill bg-info'>{% trans \"Building\" %}: ${row.building}</span>`;\nlink = '?display=build-orders';\n} else {\n- // There is no stock available\n+ // There is no stock\nvalue = `0<span class='badge badge-right rounded-pill bg-danger'>{% trans \"No Stock\" %}</span>`;\n}\n+ }\nreturn renderLink(value, `/part/${row.pk}/${link}`);\n}\n",
        "chatgpt_cot": "\"Add properties for unit position, health, shield, energy, mineral and vespene contents, and unit actions to the Unit class.\""
    },
    {
        "org_diff": "diff --git a/sc2/distances.py b/sc2/distances.py @@ -7,10 +7,13 @@ import logging\nlogger = logging.getLogger(__name__)\n-from scipy.spatial.distance import pdist, cdist\nimport math\nfrom math import pow\nimport numpy as np\n+import warnings\n+with warnings.catch_warnings():\n+ warnings.simplefilter(\"ignore\")\n+ from scipy.spatial.distance import pdist, cdist\nfrom typing import Dict, Tuple, Iterable, Generator\n",
        "org_msg": "Suppress numpy warnings",
        "sim_msg": "Added operator import",
        "sim_diff": "diff --git a/nltk/metrics/distance.py b/nltk/metrics/distance.py @@ -24,7 +24,7 @@ from __future__ import print_function\nfrom __future__ import division\nimport warnings\n-\n+import operator\ndef _edit_dist_init(len1, len2):\nlev = []\n@@ -135,6 +135,13 @@ def edit_distance_align(s1, s2, substitution_cost=1):\nNB: (0, 0) is the start state without any letters associated\nSee more: https://web.stanford.edu/class/cs124/lec/med.pdf\n+ In case of multiple valid minimum-distance alignments, the\n+ backtrace has the following operation precedence:\n+ 1. Skip s1 character\n+ 2. Skip s2 character\n+ 3. Substitute s1 and s2 characters\n+ The backtrace is carried out in reverse string order.\n+\nThis function does not support transposition.\n:param s1, s2: The strings to be aligned\n",
        "chatgpt_cot": "Fix import issue and suppress warnings for scipy.spatial.distance in distances.py"
    }
]