[
    {
        "org_diff": "diff --git a/.pre-commit-config.yaml b/a/.pre-commit-config.yaml @@ -2,7 +2,7 @@ ci:\n   autoupdate_schedule: monthly\n repos:\n   - repo: https://github.com/astral-sh/ruff-pre-commit\n-    rev: v0.3.5\n+    rev: v0.4.3\n     hooks:\n       - id: ruff\n       - id: ruff-format",
        "org_msg": "[pre-commit.ci] pre-commit autoupdate (#5477)",
        "sim_msg": "add pre_commit dependency for pre_commit for black, click version compatability",
        "sim_diff": "diff --git a/.pre-commit-config.yaml b/.pre-commit-config.yaml @@ -27,6 +27,7 @@ repos:\nhooks:\n- id: black\nlanguage_version: python3\n+ additional_dependencies: ['click==8.0.4']\n- repo: https://github.com/pre-commit/mirrors-isort\nrev: v4.3.21\nhooks:\n"
    },
    {
        "org_diff": "diff --git a/.pre-commit-config.yaml b/a/.pre-commit-config.yaml @@ -2,7 +2,7 @@ ci:\n   autoupdate_schedule: monthly\n repos:\n   - repo: https://github.com/astral-sh/ruff-pre-commit\n-    rev: v0.3.5\n+    rev: v0.4.3\n     hooks:\n       - id: ruff\n       - id: ruff-format",
        "org_msg": "[pre-commit.ci] pre-commit autoupdate\n\nupdates:\n- [github.com/astral-sh/ruff-pre-commit: v0.3.5 â†’ v0.4.3](https://github.com/astral-sh/ruff-pre-commit/compare/v0.3.5...v0.4.3)",
        "sim_msg": "add pre_commit dependency for pre_commit for black, click version compatability",
        "sim_diff": "diff --git a/.pre-commit-config.yaml b/.pre-commit-config.yaml @@ -27,6 +27,7 @@ repos:\nhooks:\n- id: black\nlanguage_version: python3\n+ additional_dependencies: ['click==8.0.4']\n- repo: https://github.com/pre-commit/mirrors-isort\nrev: v4.3.21\nhooks:\n"
    },
    {
        "org_diff": "diff --git a/src/flask/helpers.py b/a/src/flask/helpers.py @@ -91,7 +91,7 @@ def decorator(*args: t.Any, **kwargs: t.Any) -> t.Any:\n             gen = generator_or_function(*args, **kwargs)  # type: ignore[operator]\n             return stream_with_context(gen)\n \n-        return update_wrapper(decorator, generator_or_function)  # type: ignore[arg-type]\n+        return update_wrapper(decorator, generator_or_function)  # type: ignore[arg-type, return-value]\n \n     def generator() -> t.Iterator[t.AnyStr | None]:\n         ctx = _cv_request.get(None)",
        "org_msg": "fix mypy finding",
        "sim_msg": "Remove context copying from run_async function\nThis was required with the previous implementation of Werkzeug's\nlocals which didn't persist across threads. However as the current\nimplementation uses ContextVars which do persist the context copying\nis no longer required.",
        "sim_diff": "diff --git a/src/flask/helpers.py b/src/flask/helpers.py @@ -819,33 +819,8 @@ def run_async(func: t.Callable[..., t.Coroutine]) -> t.Callable[..., t.Any]:\n)\n@wraps(func)\n- def outer(*args: t.Any, **kwargs: t.Any) -> t.Any:\n- \"\"\"This function grabs the current context for the inner function.\n+ def wrapper(*args: t.Any, **kwargs: t.Any) -> t.Any:\n+ return async_to_sync(func)(*args, **kwargs)\n- This is similar to the copy_current_xxx_context functions in the\n- ctx module, except it has an async inner.\n- \"\"\"\n- ctx = None\n-\n- if _request_ctx_stack.top is not None:\n- ctx = _request_ctx_stack.top.copy()\n-\n- @wraps(func)\n- async def inner(*a: t.Any, **k: t.Any) -> t.Any:\n- \"\"\"This restores the context before awaiting the func.\n-\n- This is required as the function must be awaited within the\n- context. Only calling ``func`` (as per the\n- ``copy_current_xxx_context`` functions) doesn't work as the\n- with block will close before the coroutine is awaited.\n- \"\"\"\n- if ctx is not None:\n- with ctx:\n- return await func(*a, **k)\n- else:\n- return await func(*a, **k)\n-\n- return async_to_sync(inner)(*args, **kwargs)\n-\n- outer._flask_sync_wrapper = True # type: ignore\n- return outer\n+ wrapper._flask_sync_wrapper = True # type: ignore\n+ return wrapper\n"
    },
    {
        "org_diff": "diff --git a/src/flask/sessions.py b/a/src/flask/sessions.py @@ -365,10 +365,10 @@ def save_session(\n             return\n \n         expires = self.get_expiration_time(app, session)\n-        val = self.get_signing_serializer(app).dumps(dict(session))  # type: ignore\n+        val = self.get_signing_serializer(app).dumps(dict(session))  # type: ignore[union-attr]\n         response.set_cookie(\n             name,\n-            val,  # type: ignore\n+            val,\n             expires=expires,\n             httponly=httponly,\n             domain=domain,",
        "org_msg": "fix mypy finding",
        "sim_msg": "once again fixed for unix",
        "sim_diff": "diff --git a/flask_app.py b/flask_app.py @@ -11,7 +11,7 @@ THIS_FOLDER = os.path.dirname(os.path.abspath(__file__)) + \"/..\"\nsys.path.insert(1, THIS_FOLDER)\nos.system(\"rm -rf sessions\")\n-os.system(\"md sessions\")\n+os.system(\"mkdir sessions\")\nsessions = {}\nterminated = set()\n"
    },
    {
        "org_diff": "diff --git a/src/flask/wrappers.py b/a/src/flask/wrappers.py @@ -71,7 +71,7 @@ def endpoint(self) -> str | None:\n         reconstruct the same URL or a modified URL.\n         \"\"\"\n         if self.url_rule is not None:\n-            return self.url_rule.endpoint\n+            return self.url_rule.endpoint  # type: ignore[no-any-return]\n \n         return None\n ",
        "org_msg": "fix mypy finding with new werkzeug endpoint type",
        "sim_msg": "Add re.sub for blueprint add_url_rule handler, prevent '/a//b/'(blueprint.url_prefix='/a/' and the route is '/b/') happened.",
        "sim_diff": "diff --git a/flask/blueprints.py b/flask/blueprints.py :license: BSD, see LICENSE for more details.\n\"\"\"\n+import re\nfrom functools import update_wrapper\nfrom .helpers import _PackageBoundObject, _endpoint_from_view_func\n@@ -67,6 +68,7 @@ class BlueprintSetupState(object):\n\"\"\"\nif self.url_prefix:\nrule = self.url_prefix + rule\n+ rule = re.sub('/+', '/', rule)\noptions.setdefault('subdomain', self.subdomain)\nif endpoint is None:\nendpoint = _endpoint_from_view_func(view_func)\n"
    },
    {
        "org_diff": "diff --git a/examples/javascript/pyproject.toml b/a/examples/javascript/pyproject.toml @@ -8,7 +8,7 @@ maintainers = [{name = \"Pallets\", email = \"contact@palletsprojects.com\"}]\n dependencies = [\"flask\"]\n \n [project.urls]\n-Documentation = \"https://flask.palletsprojects.com/patterns/jquery/\"\n+Documentation = \"https://flask.palletsprojects.com/patterns/javascript/\"\n \n [project.optional-dependencies]\n test = [\"pytest\"]",
        "org_msg": "examples/javascript: Update Documentation URL in pyproject.toml (#5475)",
        "sim_msg": "random commit to trigger CI",
        "sim_diff": "diff --git a/pyproject.toml b/pyproject.toml @@ -67,6 +67,8 @@ pytest-github-actions-annotate-failures = {version = \"*\", optional = true}\n[tool.poetry.dev-dependencies]\n# checks and make tools\n+pre-commit = \"^2.15.0\"\n+\ninvoke = \"*\"\nflake8 = \"*\"\nmypy = \"*\"\n@@ -91,7 +93,6 @@ pydata-sphinx-theme = \"*\"\nnbsphinx = \"*\"\npandoc = \"*\"\nrecommonmark = \"*\"\n-pre-commit = \"^2.15.0\"\n[tool.poetry.extras] # extras\n"
    },
    {
        "org_diff": "diff --git a/examples/javascript/pyproject.toml b/a/examples/javascript/pyproject.toml @@ -8,7 +8,7 @@ maintainers = [{name = \"Pallets\", email = \"contact@palletsprojects.com\"}]\n dependencies = [\"flask\"]\n \n [project.urls]\n-Documentation = \"https://flask.palletsprojects.com/patterns/jquery/\"\n+Documentation = \"https://flask.palletsprojects.com/patterns/javascript/\"\n \n [project.optional-dependencies]\n test = [\"pytest\"]",
        "org_msg": "Update pyproject.toml\n\nCorrection to Documentation URL",
        "sim_msg": "random commit to trigger CI",
        "sim_diff": "diff --git a/pyproject.toml b/pyproject.toml @@ -67,6 +67,8 @@ pytest-github-actions-annotate-failures = {version = \"*\", optional = true}\n[tool.poetry.dev-dependencies]\n# checks and make tools\n+pre-commit = \"^2.15.0\"\n+\ninvoke = \"*\"\nflake8 = \"*\"\nmypy = \"*\"\n@@ -91,7 +93,6 @@ pydata-sphinx-theme = \"*\"\nnbsphinx = \"*\"\npandoc = \"*\"\nrecommonmark = \"*\"\n-pre-commit = \"^2.15.0\"\n[tool.poetry.extras] # extras\n"
    },
    {
        "org_diff": "diff --git a/src/flask/sessions.py b/a/src/flask/sessions.py @@ -368,7 +368,7 @@ def save_session(\n         val = self.get_signing_serializer(app).dumps(dict(session))  # type: ignore\n         response.set_cookie(\n             name,\n-            val,  # type: ignore\n+            val,\n             expires=expires,\n             httponly=httponly,\n             domain=domain,",
        "org_msg": "fix mypy findings",
        "sim_msg": "once again fixed for unix",
        "sim_diff": "diff --git a/flask_app.py b/flask_app.py @@ -11,7 +11,7 @@ THIS_FOLDER = os.path.dirname(os.path.abspath(__file__)) + \"/..\"\nsys.path.insert(1, THIS_FOLDER)\nos.system(\"rm -rf sessions\")\n-os.system(\"md sessions\")\n+os.system(\"mkdir sessions\")\nsessions = {}\nterminated = set()\n"
    },
    {
        "org_diff": "diff --git a/.github/dependabot.yml b/a/.github/dependabot.yml @@ -4,12 +4,6 @@ updates:\n     directory: /\n     schedule:\n       interval: monthly\n-    ignore:\n-      # slsa depends on upload/download v3\n-      - dependency-name: actions/upload-artifact\n-        versions: '>= 4'\n-      - dependency-name: actions/download-artifact\n-        versions: '>= 4'\n     groups:\n       github-actions:\n         patterns:",
        "org_msg": "unignore upload/download-artifact",
        "sim_msg": "ci: add github-actions to dependabot",
        "sim_diff": "diff --git a/.github/dependabot.yml b/.github/dependabot.yml @@ -6,3 +6,9 @@ updates:\ninterval: daily\ntime: \"11:00\"\nopen-pull-requests-limit: 10\n+ - package-ecosystem: github-actions\n+ directory: \"/\"\n+ schedule:\n+ interval: daily\n+ time: \"11:00\"\n+ open-pull-requests-limit: 10\n"
    },
    {
        "org_diff": "diff --git a/tox.ini b/a/tox.ini @@ -32,7 +32,7 @@ commands = mypy\n \n [testenv:docs]\n deps = -r requirements/docs.txt\n-commands = sphinx-build -W -b dirhtml docs docs/_build/dirhtml\n+commands = sphinx-build -E -W -b dirhtml docs docs/_build/dirhtml\n \n [testenv:update-requirements]\n deps =",
        "org_msg": "build docs from scratch each test",
        "sim_msg": "Use skip_install where appropriate",
        "sim_diff": "diff --git a/tox.ini b/tox.ini @@ -21,11 +21,13 @@ changedir = doc\ndeps =\nsphinx\nsphinx_issues\n+skip_install = true\ncommands = sphinx-build -W -b html -d {envtmpdir}/doctrees . {envtmpdir}/html\n[testenv:flake8]\nbasepython = python3.6\ndeps = flake8\n+skip_install = true\ncommands = flake8 src/ tests/\n[testenv:mypy]\n"
    },
    {
        "org_diff": "diff --git a/README.md b/a/README.md @@ -16,18 +16,6 @@ community that make adding new functionality easy.\n [Jinja]: https://jinja.palletsprojects.com/\n \n \n-## Installing\n-\n-Install and update from [PyPI][] using an installer such as [pip][]:\n-\n-```\n-$ pip install -U Flask\n-```\n-\n-[PyPI]: https://pypi.org/project/Flask/\n-[pip]: https://pip.pypa.io/en/stable/getting-started/\n-\n-\n ## A Simple Example\n \n ```python\n@@ -47,14 +35,6 @@ $ flask run\n ```\n \n \n-## Contributing\n-\n-For guidance on setting up a development environment and how to make a\n-contribution to Flask, see the [contributing guidelines][].\n-\n-[contributing guidelines]: https://github.com/pallets/flask/blob/main/CONTRIBUTING.rst\n-\n-\n ## Donate\n \n The Pallets organization develops and supports Flask and the libraries",
        "org_msg": "remove install and contribute sections\n\ninstall leads people to install into the system instead of a virtualenv,\nand readme isn't the place to teach that\ncontribute is now linked in the github interface above the readme",
        "sim_msg": "Changed Setup Script to use Requirements.txt for Python Pip installs",
        "sim_diff": "diff --git a/setup-osp.sh b/setup-osp.sh @@ -50,8 +50,7 @@ sudo chown -R www-data:www-data images\n# Setup Python\nsudo apt-get install python2.7 python-pip gunicorn uwsgi-plugin-python -y\n-sudo pip install flask flask-sqlalchemy flask-security flask-socketio gevent flask-uploads psutil requests flask-migrate\n-sudo pip install --upgrade git+ https://github.com/mattupstate/flask-security.git@develop\n+sudo pip install -r requirements.txt\nsudo mkdir /opt/osp/\ncd $cwd/flask-nginx-rtmp-mgmt\n"
    },
    {
        "org_diff": "diff --git a/CHANGES.rst b/a/CHANGES.rst @@ -1,7 +1,7 @@\n Version 3.0.3\n -------------\n \n-Unreleased\n+Released 2024-04-07\n \n -   The default ``hashlib.sha1`` may not be available in FIPS builds. Don't\n     access it at import time so the developer has time to change the default.",
        "org_msg": "release version 3.0.3 (#5461)",
        "sim_msg": "Upgrade Kombu to 3.0.37.",
        "sim_diff": "diff --git a/requirements/prod.txt b/requirements/prod.txt @@ -268,9 +268,9 @@ cffi==1.9.1 \\\n--hash=sha256:86c68a3f8246495962446c6f96f6a27f182b91208187b68f1e87ec3dfd29fa32 \\\n--hash=sha256:e5ef800ef8ef9ee05ae9a5b7d7d9cf7d6c936b32e312e54823faca3034ee16ab \\\n--hash=sha256:563e0bd53fda03c151573217b3a49b3abad8813de9dd0632e10090f6190fdaf8\n-kombu==3.0.35 \\\n- --hash=sha256:2c59a5e087d5895675cdb4d6a38a0aa147f0411366e68330a76e480ba3b25727 \\\n- --hash=sha256:22ab336a17962717a5d9470547e5508d4bcf1b6ec10cd9486868daf4e5edb727\n+kombu==3.0.37 \\\n+ --hash=sha256:7ceab743e3e974f3e5736082e8cc514c009e254e646d6167342e0e192aee81a6 \\\n+ --hash=sha256:e064a00c66b4d1058cd2b0523fb8d98c82c18450244177b6c0f7913016642650\ndjango-jinja==2.2.2 \\\n--hash=sha256:f2456d767dfbe4123e42b96015ea4b119838e2d88457999bd574cf7c634a2b25\npuente==0.5.0 \\\n"
    },
    {
        "org_diff": "diff --git a/CHANGES.rst b/a/CHANGES.rst @@ -1,7 +1,7 @@\n Version 3.0.3\n -------------\n \n-Unreleased\n+Released 2024-04-07\n \n -   The default ``hashlib.sha1`` may not be available in FIPS builds. Don't\n     access it at import time so the developer has time to change the default.",
        "org_msg": "release version 3.0.3",
        "sim_msg": "Upgrade Kombu to 3.0.37.",
        "sim_diff": "diff --git a/requirements/prod.txt b/requirements/prod.txt @@ -268,9 +268,9 @@ cffi==1.9.1 \\\n--hash=sha256:86c68a3f8246495962446c6f96f6a27f182b91208187b68f1e87ec3dfd29fa32 \\\n--hash=sha256:e5ef800ef8ef9ee05ae9a5b7d7d9cf7d6c936b32e312e54823faca3034ee16ab \\\n--hash=sha256:563e0bd53fda03c151573217b3a49b3abad8813de9dd0632e10090f6190fdaf8\n-kombu==3.0.35 \\\n- --hash=sha256:2c59a5e087d5895675cdb4d6a38a0aa147f0411366e68330a76e480ba3b25727 \\\n- --hash=sha256:22ab336a17962717a5d9470547e5508d4bcf1b6ec10cd9486868daf4e5edb727\n+kombu==3.0.37 \\\n+ --hash=sha256:7ceab743e3e974f3e5736082e8cc514c009e254e646d6167342e0e192aee81a6 \\\n+ --hash=sha256:e064a00c66b4d1058cd2b0523fb8d98c82c18450244177b6c0f7913016642650\ndjango-jinja==2.2.2 \\\n--hash=sha256:f2456d767dfbe4123e42b96015ea4b119838e2d88457999bd574cf7c634a2b25\npuente==0.5.0 \\\n"
    },
    {
        "org_diff": "diff --git a/docs/logging.rst b/a/docs/logging.rst @@ -159,7 +159,7 @@ Depending on your project, it may be more useful to configure each logger you\n care about separately, instead of configuring only the root logger. ::\n \n     for logger in (\n-        app.logger,\n+        logging.getLogger(app.name),\n         logging.getLogger('sqlalchemy'),\n         logging.getLogger('other_package'),\n     ):",
        "org_msg": "don't access app.logger when configuring app.logger",
        "sim_msg": "Make logs use config for log level and logs directory",
        "sim_diff": "diff --git a/augur/application/logs.py b/augur/application/logs.py @@ -101,7 +101,13 @@ def get_log_config():\n#TODO dynamically define loggers for every task names.\nclass TaskLogConfig():\n- def __init__(self, all_tasks, disable_log_files=False,reset_logfiles=False,base_log_dir=ROOT_AUGUR_DIRECTORY + \"/logs/\",logLevel=logging.INFO):\n+ def __init__(self, all_tasks, disable_log_files=False,reset_logfiles=False,base_log_dir=ROOT_AUGUR_DIRECTORY + \"/logs/\"):\n+\n+ log_config = get_log_config()\n+\n+ if log_config[\"logs_directory\"] != \"\":\n+ base_log_dir=log_config[\"logs_directory\"]\n+\nif reset_logfiles is True:\ntry:\nprint(\"(tasks) Reseting log files\")\n@@ -109,9 +115,10 @@ class TaskLogConfig():\nexcept FileNotFoundError as e:\npass\n- self.log_confg = get_log_config()\n-\n- self.logLevel = logLevel\n+ if log_config[\"log_level\"].lower() == \"debug\":\n+ self.logLevel = logging.DEBUG\n+ else:\n+ self.logLevel = logging.INFO\nself.base_log_dir = Path(base_log_dir)\n@@ -165,7 +172,13 @@ class TaskLogConfig():\nclass AugurLogger():\n- def __init__(self, logger_name, disable_log_files=False,reset_logfiles=False,base_log_dir=ROOT_AUGUR_DIRECTORY + \"/logs/\",logLevel=logging.INFO):\n+ def __init__(self, logger_name, disable_log_files=False,reset_logfiles=False,base_log_dir=ROOT_AUGUR_DIRECTORY + \"/logs/\"):\n+\n+ log_config = get_log_config()\n+\n+ if log_config[\"logs_directory\"] != \"\":\n+ base_log_dir=log_config[\"logs_directory\"]\n+\nif reset_logfiles is True:\ntry:\nprint(\"(augur) Reseting log files\")\n@@ -173,7 +186,10 @@ class AugurLogger():\nexcept FileNotFoundError as e:\npass\n- self.logLevel = logLevel\n+ if log_config[\"log_level\"].lower() == \"debug\":\n+ self.logLevel = logging.DEBUG\n+ else:\n+ self.logLevel = logging.INFO\nself.base_log_dir = Path(base_log_dir)\n"
    },
    {
        "org_diff": "diff --git a/.github/workflows/publish.yaml b/a/.github/workflows/publish.yaml @@ -55,9 +55,11 @@ jobs:\n           GH_TOKEN: ${{ github.token }}\n   publish-pypi:\n     needs: [provenance]\n-    # Wait for approval before attempting to upload to PyPI. This allows reviewing the\n-    # files in the draft release.\n-    environment: publish\n+    environment:\n+      # Wait for approval before attempting to upload to PyPI. This allows reviewing the\n+      # files in the draft release. The projection is configured in the repository settings.\n+      name: publish\n+      url: https://pypi.org/project/flask/${{ github.ref_name }}\n     runs-on: ubuntu-latest\n     permissions:\n       id-token: write",
        "org_msg": "Use per-release URLs in GH env UI when publishing to the PyPI (#5423)",
        "sim_msg": "Update pypi release action.",
        "sim_diff": "diff --git a/.github/workflows/pypi_upload.yml b/.github/workflows/pypi_upload.yml @@ -47,7 +47,7 @@ jobs:\n# to upload to test pypi, pass repository_url: https://test.pypi.org/legacy/ and use secrets.TEST_PYPI_TOKEN\n- name: Publish a Python distribution to PyPI\n- uses: pypa/gh-action-pypi-publish@master\n+ uses: pypa/gh-action-pypi-publish@release/v1\nwith:\nuser: __token__\npassword: ${{ secrets.PYPI_TOKEN }}\n"
    },
    {
        "org_diff": "diff --git a/.github/workflows/publish.yaml b/a/.github/workflows/publish.yaml @@ -55,9 +55,11 @@ jobs:\n           GH_TOKEN: ${{ github.token }}\n   publish-pypi:\n     needs: [provenance]\n-    # Wait for approval before attempting to upload to PyPI. This allows reviewing the\n-    # files in the draft release.\n-    environment: publish\n+    environment:\n+      # Wait for approval before attempting to upload to PyPI. This allows reviewing the\n+      # files in the draft release. The projection is configured in the repository settings.\n+      name: publish\n+      url: https://pypi.org/project/flask/${{ github.ref_name }}\n     runs-on: ubuntu-latest\n     permissions:\n       id-token: write",
        "org_msg": "Use per-release URLs in GH env UI when publishing to the PyPI\n\nThis essentially, makes the UI nicer in a few places with a clickable link to the released version being presented in the web interface of GitHub.",
        "sim_msg": "Update pypi release action.",
        "sim_diff": "diff --git a/.github/workflows/pypi_upload.yml b/.github/workflows/pypi_upload.yml @@ -47,7 +47,7 @@ jobs:\n# to upload to test pypi, pass repository_url: https://test.pypi.org/legacy/ and use secrets.TEST_PYPI_TOKEN\n- name: Publish a Python distribution to PyPI\n- uses: pypa/gh-action-pypi-publish@master\n+ uses: pypa/gh-action-pypi-publish@release/v1\nwith:\nuser: __token__\npassword: ${{ secrets.PYPI_TOKEN }}\n"
    },
    {
        "org_diff": "diff --git a/.pre-commit-config.yaml b/a/.pre-commit-config.yaml @@ -2,7 +2,7 @@ ci:\n   autoupdate_schedule: monthly\n repos:\n   - repo: https://github.com/astral-sh/ruff-pre-commit\n-    rev: v0.1.13\n+    rev: v0.2.0\n     hooks:\n       - id: ruff\n       - id: ruff-format",
        "org_msg": "[pre-commit.ci] pre-commit autoupdate (#5404)",
        "sim_msg": "add pre_commit dependency for pre_commit for black, click version compatability",
        "sim_diff": "diff --git a/.pre-commit-config.yaml b/.pre-commit-config.yaml @@ -27,6 +27,7 @@ repos:\nhooks:\n- id: black\nlanguage_version: python3\n+ additional_dependencies: ['click==8.0.4']\n- repo: https://github.com/pre-commit/mirrors-isort\nrev: v4.3.21\nhooks:\n"
    },
    {
        "org_diff": "diff --git a/.pre-commit-config.yaml b/a/.pre-commit-config.yaml @@ -2,7 +2,7 @@ ci:\n   autoupdate_schedule: monthly\n repos:\n   - repo: https://github.com/astral-sh/ruff-pre-commit\n-    rev: v0.1.13\n+    rev: v0.2.0\n     hooks:\n       - id: ruff\n       - id: ruff-format",
        "org_msg": "[pre-commit.ci] pre-commit autoupdate\n\nupdates:\n- [github.com/astral-sh/ruff-pre-commit: v0.1.13 â†’ v0.2.0](https://github.com/astral-sh/ruff-pre-commit/compare/v0.1.13...v0.2.0)",
        "sim_msg": "add pre_commit dependency for pre_commit for black, click version compatability",
        "sim_diff": "diff --git a/.pre-commit-config.yaml b/.pre-commit-config.yaml @@ -27,6 +27,7 @@ repos:\nhooks:\n- id: black\nlanguage_version: python3\n+ additional_dependencies: ['click==8.0.4']\n- repo: https://github.com/pre-commit/mirrors-isort\nrev: v4.3.21\nhooks:\n"
    },
    {
        "org_diff": "diff --git a/.github/workflows/publish.yaml b/a/.github/workflows/publish.yaml @@ -48,8 +48,9 @@ jobs:\n       - uses: actions/download-artifact@9bc31d5ccc31df68ecc42ccf4149144866c47d8a\n       - name: create release\n         run: >\n-          gh release create --draft --repo ${{ github.repository }} ${{ github.ref_name }} *.intoto.jsonl/* artifact/*\n-\n+          gh release create --draft --repo ${{ github.repository }}\n+          ${{ github.ref_name }}\n+          *.intoto.jsonl/* dist/*\n         env:\n           GH_TOKEN: ${{ github.token }}\n   publish-pypi:",
        "org_msg": "fix create release action",
        "sim_msg": "Upload Linux assets during release",
        "sim_diff": "diff --git a/.github/workflows/build.yml b/.github/workflows/build.yml @@ -81,6 +81,15 @@ jobs:\nwith:\nname: Gaphor-${{ steps.meta.outputs.version }}-x86_64.AppImage\npath: packaging/dist/Gaphor-${{ steps.meta.outputs.version }}-x86_64.AppImage\n+ - name: Upload Assets (release only)\n+ uses: AButler/upload-release-assets@v2.0\n+ if: github.event_name == 'release'\n+ with:\n+ files: |\n+ \"packaging/dist/Gaphor-${{ steps.meta.outputs.version }}-x86_64.AppImage;\n+ dist/gaphor-${{ steps.meta.outputs.version }}-py3-none-any.whl;\n+ dist/gaphor-${{ steps.meta.outputs.version }}.tar.gz\"\n+ repo-token: ${{ secrets.GITHUB_TOKEN }}\n- name: Publish to PyPI (release only)\nif: github.event_name == 'release'\nrun: poetry publish -u __token__ -p ${{ secrets.PYPI_TOKEN }}\n"
    },
    {
        "org_diff": "diff --git a/.github/workflows/publish.yaml b/a/.github/workflows/publish.yaml @@ -33,7 +33,8 @@ jobs:\n       actions: read\n       id-token: write\n       contents: write\n-    uses: slsa-framework/slsa-github-generator/.github/workflows/generator_generic_slsa3.yml@07e64b653f10a80b6510f4568f685f8b7b9ea830\n+    # Can't pin with hash due to how this workflow works.\n+    uses: slsa-framework/slsa-github-generator/.github/workflows/generator_generic_slsa3.yml@v1.9.0\n     with:\n       base64-subjects: ${{ needs.build.outputs.hash }}\n   create-release:",
        "org_msg": "fix slsa generator version",
        "sim_msg": "Need to mark job output",
        "sim_diff": "diff --git a/.github/workflows/tag-actions.yml b/.github/workflows/tag-actions.yml @@ -10,6 +10,9 @@ jobs:\nname: Github Release\nruns-on: ubuntu-latest\n+ outputs:\n+ upload_url: ${{ steps.create_release.outputs.upload_url }}\n+\nsteps:\n- name: Create Release\nid: create_release\n@@ -125,7 +128,7 @@ jobs:\nenv:\nGITHUB_TOKEN: ${{ secrets.RELEASE_TOKEN }}\nwith:\n- upload_url: ${{ steps.create_release.outputs.upload_url }}\n+ upload_url: ${{ needs.github-release.outputs.upload_url }}\nasset_path: ./rpm/dist/beer-garden-${GITHUB_REF#refs/tags/}-1.el7.x86_64.rpm\nasset_name: beer-garden-${GITHUB_REF#refs/tags/}-1.el7.x86_64.rpm\nasset_content_type: application/octet-stream\n"
    },
    {
        "org_diff": "diff --git a/src/flask/helpers.py b/a/src/flask/helpers.py @@ -49,7 +49,7 @@ def get_load_dotenv(default: bool = True) -> bool:\n \n \n def stream_with_context(\n-    generator_or_function: t.Iterator[t.AnyStr] | t.Callable[..., t.Iterator[t.AnyStr]]\n+    generator_or_function: t.Iterator[t.AnyStr] | t.Callable[..., t.Iterator[t.AnyStr]],\n ) -> t.Iterator[t.AnyStr]:\n     \"\"\"Request contexts disappear when the response is started on the server.\n     This is done for efficiency reasons and to make it less likely to encounter",
        "org_msg": "[pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci",
        "sim_msg": "Remove context copying from run_async function\nThis was required with the previous implementation of Werkzeug's\nlocals which didn't persist across threads. However as the current\nimplementation uses ContextVars which do persist the context copying\nis no longer required.",
        "sim_diff": "diff --git a/src/flask/helpers.py b/src/flask/helpers.py @@ -819,33 +819,8 @@ def run_async(func: t.Callable[..., t.Coroutine]) -> t.Callable[..., t.Any]:\n)\n@wraps(func)\n- def outer(*args: t.Any, **kwargs: t.Any) -> t.Any:\n- \"\"\"This function grabs the current context for the inner function.\n+ def wrapper(*args: t.Any, **kwargs: t.Any) -> t.Any:\n+ return async_to_sync(func)(*args, **kwargs)\n- This is similar to the copy_current_xxx_context functions in the\n- ctx module, except it has an async inner.\n- \"\"\"\n- ctx = None\n-\n- if _request_ctx_stack.top is not None:\n- ctx = _request_ctx_stack.top.copy()\n-\n- @wraps(func)\n- async def inner(*a: t.Any, **k: t.Any) -> t.Any:\n- \"\"\"This restores the context before awaiting the func.\n-\n- This is required as the function must be awaited within the\n- context. Only calling ``func`` (as per the\n- ``copy_current_xxx_context`` functions) doesn't work as the\n- with block will close before the coroutine is awaited.\n- \"\"\"\n- if ctx is not None:\n- with ctx:\n- return await func(*a, **k)\n- else:\n- return await func(*a, **k)\n-\n- return async_to_sync(inner)(*args, **kwargs)\n-\n- outer._flask_sync_wrapper = True # type: ignore\n- return outer\n+ wrapper._flask_sync_wrapper = True # type: ignore\n+ return wrapper\n"
    },
    {
        "org_diff": "diff --git a/.pre-commit-config.yaml b/a/.pre-commit-config.yaml @@ -2,7 +2,7 @@ ci:\n   autoupdate_schedule: monthly\n repos:\n   - repo: https://github.com/astral-sh/ruff-pre-commit\n-    rev: v0.1.6\n+    rev: v0.1.9\n     hooks:\n       - id: ruff\n       - id: ruff-format",
        "org_msg": "[pre-commit.ci] pre-commit autoupdate\n\nupdates:\n- [github.com/astral-sh/ruff-pre-commit: v0.1.6 â†’ v0.1.9](https://github.com/astral-sh/ruff-pre-commit/compare/v0.1.6...v0.1.9)",
        "sim_msg": "add pre_commit dependency for pre_commit for black, click version compatability",
        "sim_diff": "diff --git a/.pre-commit-config.yaml b/.pre-commit-config.yaml @@ -27,6 +27,7 @@ repos:\nhooks:\n- id: black\nlanguage_version: python3\n+ additional_dependencies: ['click==8.0.4']\n- repo: https://github.com/pre-commit/mirrors-isort\nrev: v4.3.21\nhooks:\n"
    },
    {
        "org_diff": "diff --git a/pyproject.toml b/a/pyproject.toml @@ -79,7 +79,7 @@ source = [\"src\", \"*/site-packages\"]\n \n [tool.mypy]\n python_version = \"3.8\"\n-files = [\"src/flask\"]\n+files = [\"src/flask\", \"tests/typing\"]\n show_error_codes = true\n pretty = true\n #strict = true",
        "org_msg": "Merge branch '3.0.x'",
        "sim_msg": "add types-dataclasses for python 3.6",
        "sim_diff": "diff --git a/pyproject.toml b/pyproject.toml @@ -100,6 +100,7 @@ types-aiofiles = \"^0.1.9\"\ntypes-pkg-resources = \"^0.1.3\"\ntypes-requests = \"^2.25.9\"\ntypes-toml = \"^0.10.0\"\n+types-dataclasses = { version = \"^0.1.7\", markers = \"python_version < '3.7'\" }\n# Documantation\nmkdocs = \"^1.2.2\"\n"
    },
    {
        "org_diff": "diff --git a/pyproject.toml b/a/pyproject.toml @@ -79,7 +79,7 @@ source = [\"src\", \"*/site-packages\"]\n \n [tool.mypy]\n python_version = \"3.8\"\n-files = [\"src/flask\"]\n+files = [\"src/flask\", \"tests/typing\"]\n show_error_codes = true\n pretty = true\n #strict = true",
        "org_msg": "run typing tests",
        "sim_msg": "add types-dataclasses for python 3.6",
        "sim_diff": "diff --git a/pyproject.toml b/pyproject.toml @@ -100,6 +100,7 @@ types-aiofiles = \"^0.1.9\"\ntypes-pkg-resources = \"^0.1.3\"\ntypes-requests = \"^2.25.9\"\ntypes-toml = \"^0.10.0\"\n+types-dataclasses = { version = \"^0.1.7\", markers = \"python_version < '3.7'\" }\n# Documantation\nmkdocs = \"^1.2.2\"\n"
    },
    {
        "org_diff": "diff --git a/docs/server.rst b/a/docs/server.rst @@ -76,8 +76,8 @@ following example shows that process id 6847 is using port 5000.\n             TCP 127.0.0.1:5000 0.0.0.0:0 LISTENING 6847\n \n macOS Monterey and later automatically starts a service that uses port\n-5000. To disable the service, go to System Preferences, Sharing, and\n-disable \"AirPlay Receiver\".\n+5000. You can choose to disable this service instead of using a different port by\n+searching for \"AirPlay Receiver\" in System Preferences and toggling it off.\n \n \n Deferred Errors on Reload",
        "org_msg": "Update docs to address redesigned macOS settings app (#5355)",
        "sim_msg": "set custom LND port",
        "sim_diff": "diff --git a/home.admin/config.scripts/lnd.setport.sh b/home.admin/config.scripts/lnd.setport.sh #!/bin/bash\n# based on: https://github.com/rootzoll/raspiblitz/issues/100#issuecomment-465997126\n+# based on: https://github.com/rootzoll/raspiblitz/issues/386\nif [ $# -eq 0 ]; then\necho \"small config script set the port LND is running on\"\n@@ -62,6 +63,16 @@ sudo systemctl disable lnd\necho \"change port in lnd config\"\nsudo sed -i \"s/^listen=.*/listen=0.0.0.0:${portnumber}/g\" /mnt/hdd/lnd/lnd.conf\n+# add to raspiblitz.config (so it can survive update)\n+valueExists=$(sudo cat /mnt/hdd/raspiblitz.conf | grep -c 'customPortLND=')\n+if [ ${valueExists} -eq 0 ]; then\n+ # add as new value\n+ echo \"customPortLND=${portnumber}\" >> /mnt/hdd/raspiblitz.conf\n+else\n+ # update existing value\n+ sudo sed -i \"s/^customPortLND=.*/customPortLND=${portnumber}/g\" /mnt/hdd/raspiblitz.conf\n+fi\n+\n# editing service file\necho \"editing /etc/systemd/system/lnd.service\"\nsudo sed -i \"s/^ExecStart=\\/usr\\/local\\/bin\\/lnd.*/ExecStart=\\/usr\\/local\\/bin\\/lnd --externalip=\\${publicIP}:${portnumber}/g\" /etc/systemd/system/lnd.service\n"
    },
    {
        "org_diff": "diff --git a/docs/server.rst b/a/docs/server.rst @@ -76,8 +76,8 @@ following example shows that process id 6847 is using port 5000.\n             TCP 127.0.0.1:5000 0.0.0.0:0 LISTENING 6847\n \n macOS Monterey and later automatically starts a service that uses port\n-5000. To disable the service, go to System Preferences, Sharing, and\n-disable \"AirPlay Receiver\".\n+5000. You can choose to disable this service instead of using a different port by\n+searching for \"AirPlay Receiver\" in System Preferences and toggling it off.\n \n \n Deferred Errors on Reload",
        "org_msg": "Update docs to address redesigned macOS settings app",
        "sim_msg": "set custom LND port",
        "sim_diff": "diff --git a/home.admin/config.scripts/lnd.setport.sh b/home.admin/config.scripts/lnd.setport.sh #!/bin/bash\n# based on: https://github.com/rootzoll/raspiblitz/issues/100#issuecomment-465997126\n+# based on: https://github.com/rootzoll/raspiblitz/issues/386\nif [ $# -eq 0 ]; then\necho \"small config script set the port LND is running on\"\n@@ -62,6 +63,16 @@ sudo systemctl disable lnd\necho \"change port in lnd config\"\nsudo sed -i \"s/^listen=.*/listen=0.0.0.0:${portnumber}/g\" /mnt/hdd/lnd/lnd.conf\n+# add to raspiblitz.config (so it can survive update)\n+valueExists=$(sudo cat /mnt/hdd/raspiblitz.conf | grep -c 'customPortLND=')\n+if [ ${valueExists} -eq 0 ]; then\n+ # add as new value\n+ echo \"customPortLND=${portnumber}\" >> /mnt/hdd/raspiblitz.conf\n+else\n+ # update existing value\n+ sudo sed -i \"s/^customPortLND=.*/customPortLND=${portnumber}/g\" /mnt/hdd/raspiblitz.conf\n+fi\n+\n# editing service file\necho \"editing /etc/systemd/system/lnd.service\"\nsudo sed -i \"s/^ExecStart=\\/usr\\/local\\/bin\\/lnd.*/ExecStart=\\/usr\\/local\\/bin\\/lnd --externalip=\\${publicIP}:${portnumber}/g\" /etc/systemd/system/lnd.service\n"
    },
    {
        "org_diff": "diff --git a/.pre-commit-config.yaml b/a/.pre-commit-config.yaml @@ -2,7 +2,7 @@ ci:\n   autoupdate_schedule: monthly\n repos:\n   - repo: https://github.com/astral-sh/ruff-pre-commit\n-    rev: v0.1.5\n+    rev: v0.1.6\n     hooks:\n       - id: ruff\n       - id: ruff-format",
        "org_msg": "[pre-commit.ci] pre-commit autoupdate (#5354)",
        "sim_msg": "add pre_commit dependency for pre_commit for black, click version compatability",
        "sim_diff": "diff --git a/.pre-commit-config.yaml b/.pre-commit-config.yaml @@ -27,6 +27,7 @@ repos:\nhooks:\n- id: black\nlanguage_version: python3\n+ additional_dependencies: ['click==8.0.4']\n- repo: https://github.com/pre-commit/mirrors-isort\nrev: v4.3.21\nhooks:\n"
    },
    {
        "org_diff": "diff --git a/.pre-commit-config.yaml b/a/.pre-commit-config.yaml @@ -2,7 +2,7 @@ ci:\n   autoupdate_schedule: monthly\n repos:\n   - repo: https://github.com/astral-sh/ruff-pre-commit\n-    rev: v0.1.5\n+    rev: v0.1.6\n     hooks:\n       - id: ruff\n       - id: ruff-format",
        "org_msg": "[pre-commit.ci] pre-commit autoupdate\n\nupdates:\n- [github.com/astral-sh/ruff-pre-commit: v0.1.5 â†’ v0.1.6](https://github.com/astral-sh/ruff-pre-commit/compare/v0.1.5...v0.1.6)",
        "sim_msg": "add pre_commit dependency for pre_commit for black, click version compatability",
        "sim_diff": "diff --git a/.pre-commit-config.yaml b/.pre-commit-config.yaml @@ -27,6 +27,7 @@ repos:\nhooks:\n- id: black\nlanguage_version: python3\n+ additional_dependencies: ['click==8.0.4']\n- repo: https://github.com/pre-commit/mirrors-isort\nrev: v4.3.21\nhooks:\n"
    },
    {
        "org_diff": "diff --git a/.pre-commit-config.yaml b/a/.pre-commit-config.yaml @@ -2,12 +2,12 @@ ci:\n   autoupdate_schedule: monthly\n repos:\n   - repo: https://github.com/astral-sh/ruff-pre-commit\n-    rev: v0.1.3\n+    rev: v0.1.5\n     hooks:\n       - id: ruff\n       - id: ruff-format\n   - repo: https://github.com/pre-commit/pre-commit-hooks\n-    rev: v4.4.0\n+    rev: v4.5.0\n     hooks:\n       - id: check-merge-conflict\n       - id: debug-statements",
        "org_msg": "Merge branch '3.0.x'",
        "sim_msg": "Update precommit dependencies",
        "sim_diff": "diff --git a/.pre-commit-config.yaml b/.pre-commit-config.yaml @@ -6,11 +6,11 @@ repos:\nhooks:\n- id: isort\n- repo: https://github.com/psf/black\n- rev: 22.6.0\n+ rev: 22.10.0\nhooks:\n- id: black\n- repo: https://github.com/PyCQA/flake8\n- rev: 5.0.3\n+ rev: 5.0.4\nhooks:\n- id: flake8\n- repo: https://github.com/pre-commit/pre-commit-hooks\n"
    },
    {
        "org_diff": "diff --git a/.pre-commit-config.yaml b/a/.pre-commit-config.yaml @@ -2,12 +2,12 @@ ci:\n   autoupdate_schedule: monthly\n repos:\n   - repo: https://github.com/astral-sh/ruff-pre-commit\n-    rev: v0.1.3\n+    rev: v0.1.5\n     hooks:\n       - id: ruff\n       - id: ruff-format\n   - repo: https://github.com/pre-commit/pre-commit-hooks\n-    rev: v4.4.0\n+    rev: v4.5.0\n     hooks:\n       - id: check-merge-conflict\n       - id: debug-statements",
        "org_msg": "update pre-commit hooks",
        "sim_msg": "Update precommit dependencies",
        "sim_diff": "diff --git a/.pre-commit-config.yaml b/.pre-commit-config.yaml @@ -6,11 +6,11 @@ repos:\nhooks:\n- id: isort\n- repo: https://github.com/psf/black\n- rev: 22.6.0\n+ rev: 22.10.0\nhooks:\n- id: black\n- repo: https://github.com/PyCQA/flake8\n- rev: 5.0.3\n+ rev: 5.0.4\nhooks:\n- id: flake8\n- repo: https://github.com/pre-commit/pre-commit-hooks\n"
    },
    {
        "org_diff": "diff --git a/.github/workflows/tests.yaml b/a/.github/workflows/tests.yaml @@ -9,9 +9,6 @@ on:\n       - '*.md'\n       - '*.rst'\n   pull_request:\n-    branches:\n-      - main\n-      - '*.x'\n     paths-ignore:\n       - 'docs/**'\n       - '*.md'\n@@ -24,17 +21,17 @@ jobs:\n       fail-fast: false\n       matrix:\n         include:\n-          - {name: Linux, python: '3.11', os: ubuntu-latest, tox: py311}\n-          - {name: Windows, python: '3.11', os: windows-latest, tox: py311}\n-          - {name: Mac, python: '3.11', os: macos-latest, tox: py311}\n-          - {name: '3.12-dev', python: '3.12-dev', os: ubuntu-latest, tox: py312}\n+          - {name: Linux, python: '3.12', os: ubuntu-latest, tox: py312}\n+          - {name: Windows, python: '3.12', os: windows-latest, tox: py312}\n+          - {name: Mac, python: '3.12', os: macos-latest, tox: py312}\n+          - {name: '3.11', python: '3.11', os: ubuntu-latest, tox: py311}\n           - {name: '3.10', python: '3.10', os: ubuntu-latest, tox: py310}\n           - {name: '3.9', python: '3.9', os: ubuntu-latest, tox: py39}\n           - {name: '3.8', python: '3.8', os: ubuntu-latest, tox: py38}\n           - {name: 'PyPy', python: 'pypy-3.10', os: ubuntu-latest, tox: pypy310}\n-          - {name: 'Minimum Versions', python: '3.11', os: ubuntu-latest, tox: py311-min}\n+          - {name: 'Minimum Versions', python: '3.12', os: ubuntu-latest, tox: py312-min}\n           - {name: 'Development Versions', python: '3.8', os: ubuntu-latest, tox: py38-dev}\n-          - {name: Typing, python: '3.11', os: ubuntu-latest, tox: typing}\n+          - {name: Typing, python: '3.12', os: ubuntu-latest, tox: typing}\n     steps:\n       - uses: actions/checkout@f43a0e5ff2bd294095638e18286ca9a3d1956744\n       - uses: actions/setup-python@61a6322f88396a6271a6ee3565807d608ecaddd1",
        "org_msg": "update python version matrix\n\n(cherry picked from commit 6ee5dcc0ec93e8c11e5362f1e151d99168d6d2e6)",
        "sim_msg": "Update test GA workflow for more consistent style\n* Update test GA workflow for more consistent style\n* Fix prettier formatting\nRetrocookie-Original-Commit:",
        "sim_diff": "diff --git a/{{cookiecutter.project_name}}/.github/workflows/tests.yml b/{{cookiecutter.project_name}}/.github/workflows/tests.yml @@ -12,21 +12,33 @@ jobs:\nfail-fast: false\nmatrix:\ninclude:\n- - { python-version: \"3.10\", os: ubuntu-latest, session: \"pre-commit\" }\n- - { python-version: \"3.10\", os: ubuntu-latest, session: \"safety\" }\n- - { python-version: \"3.10\", os: ubuntu-latest, session: \"mypy\" }\n- - { python-version: 3.9, os: ubuntu-latest, session: \"mypy\" }\n- - { python-version: 3.8, os: ubuntu-latest, session: \"mypy\" }\n- - { python-version: 3.7, os: ubuntu-latest, session: \"mypy\" }\n- - { python-version: \"3.10\", os: ubuntu-latest, session: \"tests\" }\n- - { python-version: 3.9, os: ubuntu-latest, session: \"tests\" }\n- - { python-version: 3.8, os: ubuntu-latest, session: \"tests\" }\n- - { python-version: 3.7, os: ubuntu-latest, session: \"tests\" }\n- - { python-version: \"3.10\", os: windows-latest, session: \"tests\" }\n- - { python-version: \"3.10\", os: macos-latest, session: \"tests\" }\n- - { python-version: \"3.10\", os: ubuntu-latest, session: \"typeguard\" }\n- - { python-version: \"3.10\", os: ubuntu-latest, session: \"xdoctest\" }\n- - { python-version: \"3.10\", os: ubuntu-latest, session: \"docs-build\" }\n+ - {\n+ python-version: \"3.10\",\n+ os: \"ubuntu-latest\",\n+ session: \"pre-commit\",\n+ }\n+ - { python-version: \"3.10\", os: \"ubuntu-latest\", session: \"safety\" }\n+ - { python-version: \"3.10\", os: \"ubuntu-latest\", session: \"mypy\" }\n+ - { python-version: \"3.9\", os: \"ubuntu-latest\", session: \"mypy\" }\n+ - { python-version: \"3.8\", os: \"ubuntu-latest\", session: \"mypy\" }\n+ - { python-version: \"3.7\", os: \"ubuntu-latest\", session: \"mypy\" }\n+ - { python-version: \"3.10\", os: \"ubuntu-latest\", session: \"tests\" }\n+ - { python-version: \"3.9\", os: \"ubuntu-latest\", session: \"tests\" }\n+ - { python-version: \"3.8\", os: \"ubuntu-latest\", session: \"tests\" }\n+ - { python-version: \"3.7\", os: \"ubuntu-latest\", session: \"tests\" }\n+ - { python-version: \"3.10\", os: \"windows-latest\", session: \"tests\" }\n+ - { python-version: \"3.10\", os: \"macos-latest\", session: \"tests\" }\n+ - {\n+ python-version: \"3.10\",\n+ os: \"ubuntu-latest\",\n+ session: \"typeguard\",\n+ }\n+ - { python-version: \"3.10\", os: \"ubuntu-latest\", session: \"xdoctest\" }\n+ - {\n+ python-version: \"3.10\",\n+ os: \"ubuntu-latest\",\n+ session: \"docs-build\",\n+ }\nenv:\nNOXSESSION: {{ \"${{ matrix.session }}\" }}\n@@ -105,10 +117,10 @@ jobs:\n- name: Check out the repository\nuses: actions/checkout@v2.4.0\n- - name: Set up Python 3.9\n+ - name: Set up Python\nuses: actions/setup-python@v2.3.0\nwith:\n- python-version: 3.9\n+ python-version: \"3.10\"\n- name: Upgrade pip\nrun: |\n"
    },
    {
        "org_diff": "diff --git a/.readthedocs.yaml b/a/.readthedocs.yaml @@ -1,8 +1,8 @@\n version: 2\n build:\n-  os: ubuntu-20.04\n+  os: ubuntu-22.04\n   tools:\n-    python: \"3.10\"\n+    python: \"3.12\"\n python:\n   install:\n     - requirements: requirements/docs.txt",
        "org_msg": "update read the docs env\n\n(cherry picked from commit 29f1bd22d75cab1b0433339425fabd21b8229228)",
        "sim_msg": "Upgrade SQLalchemy",
        "sim_diff": "diff --git a/requirements.txt b/requirements.txt @@ -52,7 +52,7 @@ pyyaml==4.2b4\nredis==2.10.6\nrequests==2.20.1\nsix==1.12.0 # via altair, bcrypt, cryptography, flask-restful, jsonschema, pyrsistent, python-dateutil\n-sqlalchemy==1.3.0\n+sqlalchemy==1.3.2\ntoolz==0.9.0 # via altair\ntyping==3.6.6 # via altair\nurllib3==1.24.2\n"
    },
    {
        "org_diff": "diff --git a/.github/dependabot.yml b/a/.github/dependabot.yml @@ -1,9 +1,18 @@\n version: 2\n updates:\n-- package-ecosystem: \"github-actions\"\n-  directory: \"/\"\n-  schedule:\n-    interval: \"monthly\"\n-    day: \"monday\"\n-    time: \"16:00\"\n-    timezone: \"UTC\"\n+  - package-ecosystem: github-actions\n+    directory: /\n+    schedule:\n+      interval: monthly\n+    groups:\n+      github-actions:\n+        patterns:\n+          - '*'\n+  - package-ecosystem: pip\n+    directory: /requirements/\n+    schedule:\n+      interval: monthly\n+    groups:\n+      python-requirements:\n+        patterns:\n+          - '*'",
        "org_msg": "enable grouped updates for actions and python",
        "sim_msg": "Add skip-changelog label to dependabot PRs",
        "sim_diff": "diff --git a/.github/dependabot.yml b/.github/dependabot.yml version: 2\nupdates:\n-\n- package-ecosystem: \"github-actions\"\ndirectory: \"/\"\nschedule:\ninterval: \"daily\"\n+ labels: [\"skip-changelog\"]\n- package-ecosystem: \"pip\"\ndirectory: \"/\"\nschedule:\ninterval: \"daily\"\n+ labels: [\"skip-changelog\"]\n"
    },
    {
        "org_diff": "diff --git a/.github/workflows/tests.yaml b/a/.github/workflows/tests.yaml @@ -9,9 +9,6 @@ on:\n       - '*.md'\n       - '*.rst'\n   pull_request:\n-    branches:\n-      - main\n-      - '*.x'\n     paths-ignore:\n       - 'docs/**'\n       - '*.md'\n@@ -24,17 +21,17 @@ jobs:\n       fail-fast: false\n       matrix:\n         include:\n-          - {name: Linux, python: '3.11', os: ubuntu-latest, tox: py311}\n-          - {name: Windows, python: '3.11', os: windows-latest, tox: py311}\n-          - {name: Mac, python: '3.11', os: macos-latest, tox: py311}\n-          - {name: '3.12-dev', python: '3.12-dev', os: ubuntu-latest, tox: py312}\n+          - {name: Linux, python: '3.12', os: ubuntu-latest, tox: py312}\n+          - {name: Windows, python: '3.12', os: windows-latest, tox: py312}\n+          - {name: Mac, python: '3.12', os: macos-latest, tox: py312}\n+          - {name: '3.11', python: '3.11', os: ubuntu-latest, tox: py311}\n           - {name: '3.10', python: '3.10', os: ubuntu-latest, tox: py310}\n           - {name: '3.9', python: '3.9', os: ubuntu-latest, tox: py39}\n           - {name: '3.8', python: '3.8', os: ubuntu-latest, tox: py38}\n           - {name: 'PyPy', python: 'pypy-3.10', os: ubuntu-latest, tox: pypy310}\n-          - {name: 'Minimum Versions', python: '3.11', os: ubuntu-latest, tox: py311-min}\n+          - {name: 'Minimum Versions', python: '3.12', os: ubuntu-latest, tox: py312-min}\n           - {name: 'Development Versions', python: '3.8', os: ubuntu-latest, tox: py38-dev}\n-          - {name: Typing, python: '3.11', os: ubuntu-latest, tox: typing}\n+          - {name: Typing, python: '3.12', os: ubuntu-latest, tox: typing}\n     steps:\n       - uses: actions/checkout@f43a0e5ff2bd294095638e18286ca9a3d1956744\n       - uses: actions/setup-python@61a6322f88396a6271a6ee3565807d608ecaddd1",
        "org_msg": "update python version matrix",
        "sim_msg": "Update test GA workflow for more consistent style\n* Update test GA workflow for more consistent style\n* Fix prettier formatting\nRetrocookie-Original-Commit:",
        "sim_diff": "diff --git a/{{cookiecutter.project_name}}/.github/workflows/tests.yml b/{{cookiecutter.project_name}}/.github/workflows/tests.yml @@ -12,21 +12,33 @@ jobs:\nfail-fast: false\nmatrix:\ninclude:\n- - { python-version: \"3.10\", os: ubuntu-latest, session: \"pre-commit\" }\n- - { python-version: \"3.10\", os: ubuntu-latest, session: \"safety\" }\n- - { python-version: \"3.10\", os: ubuntu-latest, session: \"mypy\" }\n- - { python-version: 3.9, os: ubuntu-latest, session: \"mypy\" }\n- - { python-version: 3.8, os: ubuntu-latest, session: \"mypy\" }\n- - { python-version: 3.7, os: ubuntu-latest, session: \"mypy\" }\n- - { python-version: \"3.10\", os: ubuntu-latest, session: \"tests\" }\n- - { python-version: 3.9, os: ubuntu-latest, session: \"tests\" }\n- - { python-version: 3.8, os: ubuntu-latest, session: \"tests\" }\n- - { python-version: 3.7, os: ubuntu-latest, session: \"tests\" }\n- - { python-version: \"3.10\", os: windows-latest, session: \"tests\" }\n- - { python-version: \"3.10\", os: macos-latest, session: \"tests\" }\n- - { python-version: \"3.10\", os: ubuntu-latest, session: \"typeguard\" }\n- - { python-version: \"3.10\", os: ubuntu-latest, session: \"xdoctest\" }\n- - { python-version: \"3.10\", os: ubuntu-latest, session: \"docs-build\" }\n+ - {\n+ python-version: \"3.10\",\n+ os: \"ubuntu-latest\",\n+ session: \"pre-commit\",\n+ }\n+ - { python-version: \"3.10\", os: \"ubuntu-latest\", session: \"safety\" }\n+ - { python-version: \"3.10\", os: \"ubuntu-latest\", session: \"mypy\" }\n+ - { python-version: \"3.9\", os: \"ubuntu-latest\", session: \"mypy\" }\n+ - { python-version: \"3.8\", os: \"ubuntu-latest\", session: \"mypy\" }\n+ - { python-version: \"3.7\", os: \"ubuntu-latest\", session: \"mypy\" }\n+ - { python-version: \"3.10\", os: \"ubuntu-latest\", session: \"tests\" }\n+ - { python-version: \"3.9\", os: \"ubuntu-latest\", session: \"tests\" }\n+ - { python-version: \"3.8\", os: \"ubuntu-latest\", session: \"tests\" }\n+ - { python-version: \"3.7\", os: \"ubuntu-latest\", session: \"tests\" }\n+ - { python-version: \"3.10\", os: \"windows-latest\", session: \"tests\" }\n+ - { python-version: \"3.10\", os: \"macos-latest\", session: \"tests\" }\n+ - {\n+ python-version: \"3.10\",\n+ os: \"ubuntu-latest\",\n+ session: \"typeguard\",\n+ }\n+ - { python-version: \"3.10\", os: \"ubuntu-latest\", session: \"xdoctest\" }\n+ - {\n+ python-version: \"3.10\",\n+ os: \"ubuntu-latest\",\n+ session: \"docs-build\",\n+ }\nenv:\nNOXSESSION: {{ \"${{ matrix.session }}\" }}\n@@ -105,10 +117,10 @@ jobs:\n- name: Check out the repository\nuses: actions/checkout@v2.4.0\n- - name: Set up Python 3.9\n+ - name: Set up Python\nuses: actions/setup-python@v2.3.0\nwith:\n- python-version: 3.9\n+ python-version: \"3.10\"\n- name: Upgrade pip\nrun: |\n"
    },
    {
        "org_diff": "diff --git a/.github/workflows/lock.yaml b/a/.github/workflows/lock.yaml @@ -1,8 +1,8 @@\n-name: 'Lock threads'\n-# Lock closed issues that have not received any further activity for\n-# two weeks. This does not close open issues, only humans may do that.\n-# We find that it is easier to respond to new issues with fresh examples\n-# rather than continuing discussions on old issues.\n+name: 'Lock inactive closed issues'\n+# Lock closed issues that have not received any further activity for two weeks.\n+# This does not close open issues, only humans may do that. We find that it is\n+# easier to respond to new issues with fresh examples rather than continuing\n+# discussions on old issues.\n \n on:\n   schedule:",
        "org_msg": "update description",
        "sim_msg": "changed the PR stale days",
        "sim_diff": "diff --git a/.github/workflows/stale.yml b/.github/workflows/stale.yml @@ -21,7 +21,7 @@ jobs:\nrepo-token: ${{ secrets.GITHUB_TOKEN }}\ndays-before-issue-stale: 30\ndays-before-issue-close: 7\n- days-before-pr-stale: 30\n+ days-before-pr-stale: 45\ndays-before-pr-close: -1\nstale-issue-message: 'This issue has been automatically marked as stale due to lack of activity. It will be closed if no further activity occurs. Thank you'\nclose-issue-message: 'This issue is closed due to lack of activity. Feel free to reopen it if you still have questions.'\n"
    },
    {
        "org_diff": "diff --git a/.readthedocs.yaml b/a/.readthedocs.yaml @@ -1,8 +1,8 @@\n version: 2\n build:\n-  os: ubuntu-20.04\n+  os: ubuntu-22.04\n   tools:\n-    python: \"3.10\"\n+    python: \"3.12\"\n python:\n   install:\n     - requirements: requirements/docs.txt",
        "org_msg": "update read the docs env",
        "sim_msg": "Upgrade SQLalchemy",
        "sim_diff": "diff --git a/requirements.txt b/requirements.txt @@ -52,7 +52,7 @@ pyyaml==4.2b4\nredis==2.10.6\nrequests==2.20.1\nsix==1.12.0 # via altair, bcrypt, cryptography, flask-restful, jsonschema, pyrsistent, python-dateutil\n-sqlalchemy==1.3.0\n+sqlalchemy==1.3.2\ntoolz==0.9.0 # via altair\ntyping==3.6.6 # via altair\nurllib3==1.24.2\n"
    },
    {
        "org_diff": "diff --git a/docs/deploying/asgi.rst b/a/docs/deploying/asgi.rst @@ -20,7 +20,7 @@ wrapping the Flask app,\n     asgi_app = WsgiToAsgi(app)\n \n and then serving the ``asgi_app`` with the ASGI server, e.g. using\n-`Hypercorn <https://gitlab.com/pgjones/hypercorn>`_,\n+`Hypercorn <https://github.com/pgjones/hypercorn>`_,\n \n .. sourcecode:: text\n ",
        "org_msg": "Update link to hypercorn (#5313)",
        "sim_msg": "Adjusted deployment asgi.py example.",
        "sim_diff": "diff --git a/docs/deploying.rst b/docs/deploying.rst @@ -22,18 +22,23 @@ Here's an example of what that ``asgi.py`` might look like:\nimport os\n- from channels.auth import AuthMiddlewareStack\n- from channels.routing import ProtocolTypeRouter, URLRouter\nfrom django.conf.urls import url\nfrom django.core.asgi import get_asgi_application\n- from chat.consumers import AdminChatConsumer, PublicChatConsumer\n-\n+ # Fetch Django ASGI application early to ensure AppRegistry is populated\n+ # before importing consumers and AuthMiddlewareStack that may import ORM\n+ # models.\nos.environ.setdefault(\"DJANGO_SETTINGS_MODULE\", \"mysite.settings\")\n+ django_asgi_app = get_asgi_application()\n+\n+ from channels.auth import AuthMiddlewareStack\n+ from channels.routing import ProtocolTypeRouter, URLRouter\n+\n+ from chat.consumers import AdminChatConsumer, PublicChatConsumer\napplication = ProtocolTypeRouter({\n# Django's ASGI application to handle traditional HTTP requests\n- \"http\": get_asgi_application(),\n+ \"http\": django_asgi_app,\n# WebSocket chat handler\n\"websocket\": AuthMiddlewareStack(\n@@ -44,7 +49,6 @@ Here's an example of what that ``asgi.py`` might look like:\n),\n})\n-\nSetting up a channel backend\n----------------------------\n"
    },
    {
        "org_diff": "diff --git a/docs/deploying/asgi.rst b/a/docs/deploying/asgi.rst @@ -20,7 +20,7 @@ wrapping the Flask app,\n     asgi_app = WsgiToAsgi(app)\n \n and then serving the ``asgi_app`` with the ASGI server, e.g. using\n-`Hypercorn <https://gitlab.com/pgjones/hypercorn>`_,\n+`Hypercorn <https://github.com/pgjones/hypercorn>`_,\n \n .. sourcecode:: text\n ",
        "org_msg": "Fix link to Hypercorn in docs/deploying/asgi.rst - they moved from gitlab from github.",
        "sim_msg": "Adjusted deployment asgi.py example.",
        "sim_diff": "diff --git a/docs/deploying.rst b/docs/deploying.rst @@ -22,18 +22,23 @@ Here's an example of what that ``asgi.py`` might look like:\nimport os\n- from channels.auth import AuthMiddlewareStack\n- from channels.routing import ProtocolTypeRouter, URLRouter\nfrom django.conf.urls import url\nfrom django.core.asgi import get_asgi_application\n- from chat.consumers import AdminChatConsumer, PublicChatConsumer\n-\n+ # Fetch Django ASGI application early to ensure AppRegistry is populated\n+ # before importing consumers and AuthMiddlewareStack that may import ORM\n+ # models.\nos.environ.setdefault(\"DJANGO_SETTINGS_MODULE\", \"mysite.settings\")\n+ django_asgi_app = get_asgi_application()\n+\n+ from channels.auth import AuthMiddlewareStack\n+ from channels.routing import ProtocolTypeRouter, URLRouter\n+\n+ from chat.consumers import AdminChatConsumer, PublicChatConsumer\napplication = ProtocolTypeRouter({\n# Django's ASGI application to handle traditional HTTP requests\n- \"http\": get_asgi_application(),\n+ \"http\": django_asgi_app,\n# WebSocket chat handler\n\"websocket\": AuthMiddlewareStack(\n@@ -44,7 +49,6 @@ Here's an example of what that ``asgi.py`` might look like:\n),\n})\n-\nSetting up a channel backend\n----------------------------\n"
    },
    {
        "org_diff": "diff --git a/docs/testing.rst b/a/docs/testing.rst @@ -192,7 +192,7 @@ which records the request that produced that response.\n .. code-block:: python\n \n     def test_logout_redirect(client):\n-        response = client.get(\"/logout\")\n+        response = client.get(\"/logout\", follow_redirects=True)\n         # Check that there was one redirect response.\n         assert len(response.history) == 1\n         # Check that the second request was to the index page.",
        "org_msg": "docs/testing.rst: fix follow_redirects sample code (#5303)",
        "sim_msg": "Add `--follow --verbose` test for HTTP 308",
        "sim_diff": "diff --git a/tests/test_redirects.py b/tests/test_redirects.py @@ -68,10 +68,18 @@ def test_http_307_allow_redirect_post(httpbin):\nassert HTTP_OK in r\n-def test_http_307_allow_redirect_post_verbose(httpbin):\n- r = http('--follow', '--verbose', 'POST', httpbin.url + '/redirect-to',\n- f'url=={httpbin.url}/post', 'status_code==307',\n- '@' + FILE_PATH_ARG)\n+@pytest.mark.parametrize('status_code', [307, 308])\n+def test_verbose_follow_redirect_with_repost(httpbin, status_code):\n+ # <https://developer.mozilla.org/en-US/docs/Web/HTTP/Redirections>\n+ r = http(\n+ '--follow',\n+ '--verbose',\n+ httpbin.url + '/redirect-to',\n+ f'url=={httpbin.url}/post',\n+ f'status_code=={status_code}',\n+ '@' + FILE_PATH_ARG,\n+ )\n+ assert f'HTTP/1.1 {status_code}' in r\nassert r.count('POST /redirect-to') == 1\nassert r.count('POST /post') == 1\nassert r.count(FILE_CONTENT) == 3 # two requests + final response contain it\n"
    },
    {
        "org_diff": "diff --git a/docs/testing.rst b/a/docs/testing.rst @@ -192,7 +192,7 @@ which records the request that produced that response.\n .. code-block:: python\n \n     def test_logout_redirect(client):\n-        response = client.get(\"/logout\")\n+        response = client.get(\"/logout\", follow_redirects=True)\n         # Check that there was one redirect response.\n         assert len(response.history) == 1\n         # Check that the second request was to the index page.",
        "org_msg": "docs/testing.rst: fix follow_redirects sample code",
        "sim_msg": "Add `--follow --verbose` test for HTTP 308",
        "sim_diff": "diff --git a/tests/test_redirects.py b/tests/test_redirects.py @@ -68,10 +68,18 @@ def test_http_307_allow_redirect_post(httpbin):\nassert HTTP_OK in r\n-def test_http_307_allow_redirect_post_verbose(httpbin):\n- r = http('--follow', '--verbose', 'POST', httpbin.url + '/redirect-to',\n- f'url=={httpbin.url}/post', 'status_code==307',\n- '@' + FILE_PATH_ARG)\n+@pytest.mark.parametrize('status_code', [307, 308])\n+def test_verbose_follow_redirect_with_repost(httpbin, status_code):\n+ # <https://developer.mozilla.org/en-US/docs/Web/HTTP/Redirections>\n+ r = http(\n+ '--follow',\n+ '--verbose',\n+ httpbin.url + '/redirect-to',\n+ f'url=={httpbin.url}/post',\n+ f'status_code=={status_code}',\n+ '@' + FILE_PATH_ARG,\n+ )\n+ assert f'HTTP/1.1 {status_code}' in r\nassert r.count('POST /redirect-to') == 1\nassert r.count('POST /post') == 1\nassert r.count(FILE_CONTENT) == 3 # two requests + final response contain it\n"
    },
    {
        "org_diff": "diff --git a/examples/javascript/README.rst b/a/examples/javascript/README.rst @@ -15,7 +15,7 @@ page. Demonstrates using |fetch|_, |XMLHttpRequest|_,  and\n .. |jQuery.ajax| replace:: ``jQuery.ajax``\n .. _jQuery.ajax: https://api.jquery.com/jQuery.ajax/\n \n-.. _Flask docs: https://flask.palletsprojects.com/patterns/jquery/\n+.. _Flask docs: https://flask.palletsprojects.com/patterns/javascript/\n \n \n Install",
        "org_msg": "examples/javascript: replace obsolete link (#5287)",
        "sim_msg": "Fixing sub autocomplete",
        "sim_diff": "diff --git a/app/static/js/main.js b/app/static/js/main.js @@ -114,7 +114,7 @@ if(sa){\nfetch: function(text, update) {\ntext = text.toLowerCase();\n// you can also use AJAX requests instead of preloaded data\n- u.get('/api/v3/search/sub?query=' + text, function(data){\n+ u.get('/api/v3/sub?query=' + text, function(data){\nconsole.log(data.results)\nvar suggestions = data.results\nupdate(suggestions);\n"
    },
    {
        "org_diff": "diff --git a/docs/index.rst b/a/docs/index.rst @@ -6,7 +6,11 @@ Welcome to Flask\n .. image:: _static/flask-horizontal.png\n     :align: center\n \n-Welcome to Flask's documentation. Get started with :doc:`installation`\n+Welcome to Flask's documentation. Flask is a lightweight WSGI web application framework.\n+It is designed to make getting started quick and easy, with the ability to scale up to\n+complex applications.\n+\n+Get started with :doc:`installation`\n and then get an overview with the :doc:`quickstart`. There is also a\n more detailed :doc:`tutorial/index` that shows how to create a small but\n complete application with Flask. Common patterns are described in the",
        "org_msg": "Update index.rst (#5291)\n\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>",
        "sim_msg": "docs: update \"Deploying on Google App Engine\"\nUse the documentation for Python 3 instead of Python 2, which is deprecated.",
        "sim_diff": "diff --git a/docs/deploying/index.rst b/docs/deploying/index.rst @@ -17,7 +17,7 @@ Hosted options\n--------------\n- `Deploying Flask on Heroku <https://devcenter.heroku.com/articles/getting-started-with-python>`_\n-- `Deploying Flask on Google App Engine <https://cloud.google.com/appengine/docs/standard/python/getting-started/python-standard-env>`_\n+- `Deploying Flask on Google App Engine <https://cloud.google.com/appengine/docs/standard/python3/runtime>`_\n- `Deploying Flask on AWS Elastic Beanstalk <https://docs.aws.amazon.com/elasticbeanstalk/latest/dg/create-deploy-python-flask.html>`_\n- `Deploying on Azure (IIS) <https://docs.microsoft.com/en-us/azure/app-service/containers/how-to-configure-python>`_\n- `Deploying on PythonAnywhere <https://help.pythonanywhere.com/pages/Flask/>`_\n"
    },
    {
        "org_diff": "diff --git a/docs/patterns/javascript.rst b/a/docs/patterns/javascript.rst @@ -197,7 +197,7 @@ in the previous section. The following example shows how to replace a\n         const geology_div = getElementById(\"geology-fact\")\n         fetch(geology_url)\n             .then(response => response.text)\n-            .then(text => geology_div.innerHtml = text)\n+            .then(text => geology_div.innerHTML = text)\n     </script>\n \n ",
        "org_msg": "Fix wrong spelling of JS method .innerHTML",
        "sim_msg": "Properly removing the 'required' property of the link field when switching the form to text post.\nFixes T487",
        "sim_diff": "diff --git a/app/static/js/Sub.js b/app/static/js/Sub.js @@ -62,7 +62,7 @@ u.sub('#ptoggle', 'click', function(e){\nthis.innerHTML = 'Change to ' + oval + ' post';\ndocument.getElementById('ptype').innerHTML = val;\nif(val=='text'){\n- if(document.getElementById('link').getAttribute('required')){\n+ if(document.getElementById('link').getAttribute('required') === ''){\nwindow.rReq = true;\ndocument.getElementById('link').removeAttribute('required');\n}\n"
    },
    {
        "org_diff": "diff --git a/.github/workflows/publish.yaml b/a/.github/workflows/publish.yaml @@ -63,10 +63,10 @@ jobs:\n     steps:\n       - uses: actions/download-artifact@9bc31d5ccc31df68ecc42ccf4149144866c47d8a\n       # Try uploading to Test PyPI first, in case something fails.\n-      - uses: pypa/gh-action-pypi-publish@f8c70e705ffc13c3b4d1221169b84f12a75d6ca8\n+      - uses: pypa/gh-action-pypi-publish@b7f401de30cb6434a1e19f805ff006643653240e\n         with:\n           repository-url: https://test.pypi.org/legacy/\n           packages-dir: artifact/\n-      - uses: pypa/gh-action-pypi-publish@f8c70e705ffc13c3b4d1221169b84f12a75d6ca8\n+      - uses: pypa/gh-action-pypi-publish@b7f401de30cb6434a1e19f805ff006643653240e\n         with:\n           packages-dir: artifact/",
        "org_msg": "Bump pypa/gh-action-pypi-publish from 1.8.8 to 1.8.10 (#5248)",
        "sim_msg": "Change publish target for production",
        "sim_diff": "diff --git a/.github/workflows/full-build.yml b/.github/workflows/full-build.yml @@ -397,7 +397,7 @@ jobs:\nname: Publish to PyPI (release only)\nneeds: [ linux-gtk4, linux-flatpak-devel, macos-gtk4, check-linux-appimage, check-macos-app, check-windows-installer ]\nruns-on: ubuntu-22.04\n- # if: github.event_name == 'release'\n+ if: github.event_name == 'release'\nsteps:\n- uses: actions/download-artifact@v3\nwith:\n@@ -410,4 +410,3 @@ jobs:\n- uses: pypa/gh-action-pypi-publish@release/v1\nwith:\npassword: ${{ secrets.PYPI_TOKEN }}\n- repository_url: https://test.pypi.org/legacy/\n"
    },
    {
        "org_diff": "diff --git a/.github/workflows/publish.yaml b/a/.github/workflows/publish.yaml @@ -33,7 +33,7 @@ jobs:\n       id-token: write\n       contents: write\n     # Can't pin with hash due to how this workflow works.\n-    uses: slsa-framework/slsa-github-generator/.github/workflows/generator_generic_slsa3.yml@v1.7.0\n+    uses: slsa-framework/slsa-github-generator/.github/workflows/generator_generic_slsa3.yml@v1.9.0\n     with:\n       base64-subjects: ${{ needs.build.outputs.hash }}\n   create-release:",
        "org_msg": "Bump slsa-framework/slsa-github-generator from 1.7.0 to 1.9.0 (#5247)",
        "sim_msg": "Need to mark job output",
        "sim_diff": "diff --git a/.github/workflows/tag-actions.yml b/.github/workflows/tag-actions.yml @@ -10,6 +10,9 @@ jobs:\nname: Github Release\nruns-on: ubuntu-latest\n+ outputs:\n+ upload_url: ${{ steps.create_release.outputs.upload_url }}\n+\nsteps:\n- name: Create Release\nid: create_release\n@@ -125,7 +128,7 @@ jobs:\nenv:\nGITHUB_TOKEN: ${{ secrets.RELEASE_TOKEN }}\nwith:\n- upload_url: ${{ steps.create_release.outputs.upload_url }}\n+ upload_url: ${{ needs.github-release.outputs.upload_url }}\nasset_path: ./rpm/dist/beer-garden-${GITHUB_REF#refs/tags/}-1.el7.x86_64.rpm\nasset_name: beer-garden-${GITHUB_REF#refs/tags/}-1.el7.x86_64.rpm\nasset_content_type: application/octet-stream\n"
    },
    {
        "org_diff": "diff --git a/.github/workflows/publish.yaml b/a/.github/workflows/publish.yaml @@ -63,10 +63,10 @@ jobs:\n     steps:\n       - uses: actions/download-artifact@9bc31d5ccc31df68ecc42ccf4149144866c47d8a\n       # Try uploading to Test PyPI first, in case something fails.\n-      - uses: pypa/gh-action-pypi-publish@f8c70e705ffc13c3b4d1221169b84f12a75d6ca8\n+      - uses: pypa/gh-action-pypi-publish@b7f401de30cb6434a1e19f805ff006643653240e\n         with:\n           repository-url: https://test.pypi.org/legacy/\n           packages-dir: artifact/\n-      - uses: pypa/gh-action-pypi-publish@f8c70e705ffc13c3b4d1221169b84f12a75d6ca8\n+      - uses: pypa/gh-action-pypi-publish@b7f401de30cb6434a1e19f805ff006643653240e\n         with:\n           packages-dir: artifact/",
        "org_msg": "Bump pypa/gh-action-pypi-publish from 1.8.8 to 1.8.10\n\nBumps [pypa/gh-action-pypi-publish](https://github.com/pypa/gh-action-pypi-publish) from 1.8.8 to 1.8.10.\n- [Release notes](https://github.com/pypa/gh-action-pypi-publish/releases)\n- [Commits](https://github.com/pypa/gh-action-pypi-publish/compare/f8c70e705ffc13c3b4d1221169b84f12a75d6ca8...b7f401de30cb6434a1e19f805ff006643653240e)\n\n---\nupdated-dependencies:\n- dependency-name: pypa/gh-action-pypi-publish\n  dependency-type: direct:production\n  update-type: version-update:semver-patch\n...\n\nSigned-off-by: dependabot[bot] <support@github.com>",
        "sim_msg": "Change publish target for production",
        "sim_diff": "diff --git a/.github/workflows/full-build.yml b/.github/workflows/full-build.yml @@ -397,7 +397,7 @@ jobs:\nname: Publish to PyPI (release only)\nneeds: [ linux-gtk4, linux-flatpak-devel, macos-gtk4, check-linux-appimage, check-macos-app, check-windows-installer ]\nruns-on: ubuntu-22.04\n- # if: github.event_name == 'release'\n+ if: github.event_name == 'release'\nsteps:\n- uses: actions/download-artifact@v3\nwith:\n@@ -410,4 +410,3 @@ jobs:\n- uses: pypa/gh-action-pypi-publish@release/v1\nwith:\npassword: ${{ secrets.PYPI_TOKEN }}\n- repository_url: https://test.pypi.org/legacy/\n"
    },
    {
        "org_diff": "diff --git a/.github/workflows/publish.yaml b/a/.github/workflows/publish.yaml @@ -33,7 +33,7 @@ jobs:\n       id-token: write\n       contents: write\n     # Can't pin with hash due to how this workflow works.\n-    uses: slsa-framework/slsa-github-generator/.github/workflows/generator_generic_slsa3.yml@v1.7.0\n+    uses: slsa-framework/slsa-github-generator/.github/workflows/generator_generic_slsa3.yml@v1.9.0\n     with:\n       base64-subjects: ${{ needs.build.outputs.hash }}\n   create-release:",
        "org_msg": "Bump slsa-framework/slsa-github-generator from 1.7.0 to 1.9.0\n\nBumps [slsa-framework/slsa-github-generator](https://github.com/slsa-framework/slsa-github-generator) from 1.7.0 to 1.9.0.\n- [Release notes](https://github.com/slsa-framework/slsa-github-generator/releases)\n- [Changelog](https://github.com/slsa-framework/slsa-github-generator/blob/main/CHANGELOG.md)\n- [Commits](https://github.com/slsa-framework/slsa-github-generator/compare/v1.7.0...v1.9.0)\n\n---\nupdated-dependencies:\n- dependency-name: slsa-framework/slsa-github-generator\n  dependency-type: direct:production\n  update-type: version-update:semver-minor\n...\n\nSigned-off-by: dependabot[bot] <support@github.com>",
        "sim_msg": "Need to mark job output",
        "sim_diff": "diff --git a/.github/workflows/tag-actions.yml b/.github/workflows/tag-actions.yml @@ -10,6 +10,9 @@ jobs:\nname: Github Release\nruns-on: ubuntu-latest\n+ outputs:\n+ upload_url: ${{ steps.create_release.outputs.upload_url }}\n+\nsteps:\n- name: Create Release\nid: create_release\n@@ -125,7 +128,7 @@ jobs:\nenv:\nGITHUB_TOKEN: ${{ secrets.RELEASE_TOKEN }}\nwith:\n- upload_url: ${{ steps.create_release.outputs.upload_url }}\n+ upload_url: ${{ needs.github-release.outputs.upload_url }}\nasset_path: ./rpm/dist/beer-garden-${GITHUB_REF#refs/tags/}-1.el7.x86_64.rpm\nasset_name: beer-garden-${GITHUB_REF#refs/tags/}-1.el7.x86_64.rpm\nasset_content_type: application/octet-stream\n"
    },
    {
        "org_diff": "diff --git a/CHANGES.rst b/a/CHANGES.rst @@ -11,7 +11,7 @@ Unreleased\n Version 2.3.3\n -------------\n \n-Unreleased\n+Released 2023-08-21\n \n -   Python 3.12 compatibility.\n -   Require Werkzeug >= 2.3.7.",
        "org_msg": "Merge remote-tracking branch 'origin/2.3.x'",
        "sim_msg": "Cutadapt 2.0",
        "sim_diff": "diff --git a/CHANGES.rst b/CHANGES.rst Changes\n=======\n-v2.0 (in development)\n----------------------\n+v2.0 (2019-03-06)\n+-----------------\n-This is a major new release with some backwards-incompatible changes.\n-Please review them and adjust your scripts if necessary.\n+This is a major new release with lots of bug fixes and new features, but\n+also some backwards-incompatible changes. These should hopefully\n+not affect too many users, but please make sure to review them and\n+possibly update your scripts!\nBackwards-incompatible changes\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n"
    },
    {
        "org_diff": "diff --git a/src/flask/app.py b/a/src/flask/app.py @@ -409,7 +409,6 @@ def create_url_adapter(self, request: Request | None) -> MapAdapter | None:\n             else:\n                 subdomain = None\n \n-            print(self.config[\"SERVER_NAME\"], subdomain)\n             return self.url_map.bind_to_environ(\n                 request.environ,\n                 server_name=self.config[\"SERVER_NAME\"],",
        "org_msg": "Remove print left in by accident\n\nThis was added as per 0ec7f713d679ceed2c605e62ac5d38d579f29fa0 by\nmistake.",
        "sim_msg": "make_test_environ_builder: use url_scheme from path if provided\nWhen providing https url in path (\"https://example.com/\")\nwe hope that we will get https scheme in environment",
        "sim_diff": "diff --git a/flask/testing.py b/flask/testing.py @@ -40,10 +40,10 @@ def make_test_environ_builder(\nif subdomain:\nhttp_host = '{0}.{1}'.format(subdomain, http_host)\n+ url = url_parse(path)\nif url_scheme is None:\n- url_scheme = app.config['PREFERRED_URL_SCHEME']\n+ url_scheme = url.scheme or app.config['PREFERRED_URL_SCHEME']\n- url = url_parse(path)\nbase_url = '{0}://{1}/{2}'.format(\nurl_scheme, url.netloc or http_host, app_root.lstrip('/')\n)\n"
    },
    {
        "org_diff": "diff --git a/CHANGES.rst b/a/CHANGES.rst @@ -4,6 +4,8 @@ Version 3.0.0\n Unreleased\n \n -   Remove previously deprecated code. :pr:`5223`\n+-   Restructure the code such that the Flask (app) and Blueprint\n+    classes have Sans-IO bases. :pr:`5127`\n \n \n Version 2.3.3",
        "org_msg": "Add a changelog for the sans-io changes",
        "sim_msg": "Add coverage for Blueprint request process methods\nAdd test to cover following methodss to the Blueprint object:\nbefore_request, after_request, before_app_request,\nbefore_app_first_request, after_app_request.\nThis PR increases the coverage of flask.blueprints by 6%.",
        "sim_diff": "diff --git a/tests/test_blueprints.py b/tests/test_blueprints.py @@ -679,3 +679,65 @@ def test_template_global():\nwith app.app_context():\nrv = flask.render_template_string('{{ get_answer() }}')\nassert rv == '42'\n+\n+def test_request_processing():\n+ app = flask.Flask(__name__)\n+ bp = flask.Blueprint('bp', __name__)\n+ evts = []\n+ @bp.before_request\n+ def before_bp():\n+ evts.append('before')\n+ @bp.after_request\n+ def after_bp(response):\n+ response.data += b'|after'\n+ evts.append('after')\n+ return response\n+\n+ # Setup routes for testing\n+ @bp.route('/bp')\n+ def bp_endpoint():\n+ return 'request'\n+\n+ app.register_blueprint(bp)\n+\n+ assert evts == []\n+ rv = app.test_client().get('/bp')\n+ assert rv.data == b'request|after'\n+ assert evts == ['before', 'after']\n+\n+def test_app_request_processing():\n+ app = flask.Flask(__name__)\n+ bp = flask.Blueprint('bp', __name__)\n+ evts = []\n+\n+ @bp.before_app_first_request\n+ def before_first_request():\n+ evts.append('first')\n+ @bp.before_app_request\n+ def before_app():\n+ evts.append('before')\n+ @bp.after_app_request\n+ def after_app(response):\n+ response.data += b'|after'\n+ evts.append('after')\n+ return response\n+\n+ app.register_blueprint(bp)\n+\n+ # Setup routes for testing\n+ @app.route('/')\n+ def bp_endpoint():\n+ return 'request'\n+\n+ # before first request\n+ assert evts == []\n+\n+ # first request\n+ resp = app.test_client().get('/').data\n+ assert resp == b'request|after'\n+ assert evts == ['first', 'before', 'after']\n+\n+ # second request\n+ resp = app.test_client().get('/').data\n+ assert resp == b'request|after'\n+ assert evts == ['first', 'before', 'after', 'before', 'after']\n"
    },
    {
        "org_diff": "diff --git a/src/flask/typing.py b/a/src/flask/typing.py @@ -77,7 +77,10 @@\n # https://github.com/pallets/flask/issues/4095\n # https://github.com/pallets/flask/issues/4295\n # https://github.com/pallets/flask/issues/4297\n-ErrorHandlerCallable = t.Callable[[t.Any], ResponseReturnValue]\n+ErrorHandlerCallable = t.Union[\n+    t.Callable[[t.Any], ResponseReturnValue],\n+    t.Callable[[t.Any], t.Awaitable[ResponseReturnValue]],\n+]\n \n RouteCallable = t.Union[\n     t.Callable[..., ResponseReturnValue],",
        "org_msg": "Correct the error handler typing\n\nIt may also be awaitable, as invocations are wrapped in ensure_sync.",
        "sim_msg": "clean up outdated code",
        "sim_diff": "diff --git a/src/flask/app.py b/src/flask/app.py @@ -23,7 +23,6 @@ from werkzeug.exceptions import BadRequestKeyError\nfrom werkzeug.exceptions import default_exceptions\nfrom werkzeug.exceptions import HTTPException\nfrom werkzeug.exceptions import InternalServerError\n-from werkzeug.exceptions import MethodNotAllowed\nfrom werkzeug.routing import BuildError\nfrom werkzeug.routing import Map\nfrom werkzeug.routing import RequestRedirect\n@@ -2000,17 +1999,7 @@ class Flask(_PackageBoundObject):\n.. versionadded:: 0.7\n\"\"\"\nadapter = _request_ctx_stack.top.url_adapter\n- if hasattr(adapter, \"allowed_methods\"):\nmethods = adapter.allowed_methods()\n- else:\n- # fallback for Werkzeug < 0.7\n- methods = []\n- try:\n- adapter.match(method=\"--\")\n- except MethodNotAllowed as e:\n- methods = e.valid_methods\n- except HTTPException:\n- pass\nrv = self.response_class()\nrv.allow.update(methods)\nreturn rv\n"
    },
    {
        "org_diff": "diff --git a/src/flask/typing.py b/a/src/flask/typing.py @@ -5,7 +5,7 @@\n if t.TYPE_CHECKING:  # pragma: no cover\n     from _typeshed.wsgi import WSGIApplication  # noqa: F401\n     from werkzeug.datastructures import Headers  # noqa: F401\n-    from werkzeug.wrappers import Response  # noqa: F401\n+    from werkzeug.sansio.response import Response  # noqa: F401\n \n # The possible types that are directly convertible or are a Response object.\n ResponseValue = t.Union[",
        "org_msg": "Widen the response typing\n\nWhilst not strictly true for Flask, it is true for Flask and Quart and\nhence makes it much easier for Quart to extend Flask classes. The\nalternatives are generic usage in the sansio codebase or mixed usage\nwithin Flask. I think this is a good compromise.",
        "sim_msg": "Issue Remove unused werkzeug datastructure import",
        "sim_diff": "diff --git a/flask/helpers.py b/flask/helpers.py @@ -23,7 +23,7 @@ from werkzeug.routing import BuildError\nfrom functools import update_wrapper\nfrom werkzeug.urls import url_quote\n-from werkzeug.datastructures import Headers, Range\n+from werkzeug.datastructures import Headers\nfrom werkzeug.exceptions import BadRequest, NotFound, RequestedRangeNotSatisfiable\nfrom werkzeug.wsgi import wrap_file\n"
    },
    {
        "org_diff": "diff --git a/docs/patterns/appdispatch.rst b/a/docs/patterns/appdispatch.rst @@ -146,7 +146,7 @@ the ``Host`` header to figure out the subdomain one simply looks at the\n request path up to the first slash::\n \n     from threading import Lock\n-    from werkzeug.wsgi import pop_path_info, peek_path_info\n+    from wsgiref.util import shift_path_info\n \n     class PathDispatcher:\n \n@@ -166,13 +166,20 @@ request path up to the first slash::\n                 return app\n \n         def __call__(self, environ, start_response):\n-            app = self.get_application(peek_path_info(environ))\n+            app = self.get_application(self._peek_path_info(environ))\n             if app is not None:\n-                pop_path_info(environ)\n+                shift_path_info(environ)\n             else:\n                 app = self.default_app\n             return app(environ, start_response)\n \n+    def _peek_path_info(environ):\n+        segments = environ.get(\"PATH_INFO\", \"\").lstrip(\"/\").split(\"/\", 1)\n+        if segments:\n+            return segments[0]\n+\n+        return None\n+\n The big difference between this and the subdomain one is that this one\n falls back to another application if the creator function returns ``None``::\n ",
        "org_msg": "update dispatch-by-path example",
        "sim_msg": "Allow passing a base_url to BaseClient objects",
        "sim_diff": "diff --git a/globus_sdk/base.py b/globus_sdk/base.py @@ -54,7 +54,7 @@ class BaseClient(object):\nBASE_USER_AGENT = 'globus-sdk-py-{0}'.format(__version__)\n- def __init__(self, service, environment=None,\n+ def __init__(self, service, environment=None, base_url=None,\nbase_path=None, authorizer=None, app_name=None):\n# get the fully qualified name of the client class, so that it's a\n# child of globus_sdk\n@@ -85,7 +85,10 @@ class BaseClient(object):\nself.environment = environment\nself.authorizer = authorizer\n+ if base_url is None:\nself.base_url = config.get_service_url(environment, service)\n+ else:\n+ self.base_url = base_url\nif base_path is not None:\nself.base_url = slash_join(self.base_url, base_path)\n"
    },
    {
        "org_diff": "diff --git a/tests/test_basic.py b/a/tests/test_basic.py @@ -431,9 +431,9 @@ def dump_session_contents():\n         client.get(\"/\")\n         s = flask.session\n         assert s[\"t\"] == (1, 2, 3)\n-        assert type(s[\"b\"]) == bytes\n+        assert type(s[\"b\"]) is bytes\n         assert s[\"b\"] == b\"\\xff\"\n-        assert type(s[\"m\"]) == Markup\n+        assert type(s[\"m\"]) is Markup\n         assert s[\"m\"] == Markup(\"<html>\")\n         assert s[\"u\"] == the_uuid\n         assert s[\"d\"] == now\n@@ -760,7 +760,7 @@ def test_teardown_request_handler_error(app, client):\n \n     @app.teardown_request\n     def teardown_request1(exc):\n-        assert type(exc) == ZeroDivisionError\n+        assert type(exc) is ZeroDivisionError\n         called.append(True)\n         # This raises a new error and blows away sys.exc_info(), so we can\n         # test that all teardown_requests get passed the same original\n@@ -772,7 +772,7 @@ def teardown_request1(exc):\n \n     @app.teardown_request\n     def teardown_request2(exc):\n-        assert type(exc) == ZeroDivisionError\n+        assert type(exc) is ZeroDivisionError\n         called.append(True)\n         # This raises a new error and blows away sys.exc_info(), so we can\n         # test that all teardown_requests get passed the same original",
        "org_msg": "fix flake8 bugbear findings",
        "sim_msg": "Allow partial content on bytesio",
        "sim_diff": "diff --git a/tests/test_helpers.py b/tests/test_helpers.py \"\"\"\nimport datetime\n+import io\nimport os\nimport uuid\n@@ -608,6 +609,23 @@ class TestSendfile(object):\nassert rv.status_code == 200\nrv.close()\n+ @pytest.mark.skipif(\n+ not callable(getattr(Range, 'to_content_range_header', None)),\n+ reason=\"not implemented within werkzeug\"\n+ )\n+ def test_send_file_range_request_bytesio(self, app, client):\n+ @app.route('/')\n+ def index():\n+ file = io.BytesIO(b'somethingsomething')\n+ return flask.send_file(\n+ file, attachment_filename='filename', conditional=True\n+ )\n+\n+ rv = client.get('/', headers={'Range': 'bytes=4-15'})\n+ assert rv.status_code == 206\n+ assert rv.data == b'somethingsomething'[4:16]\n+ rv.close()\n+\n@pytest.mark.skipif(\nnot callable(getattr(Range, 'to_content_range_header', None)),\nreason=\"not implemented within werkzeug\"\n"
    },
    {
        "org_diff": "diff --git a/tests/test_basic.py b/a/tests/test_basic.py @@ -431,9 +431,9 @@ def dump_session_contents():\n         client.get(\"/\")\n         s = flask.session\n         assert s[\"t\"] == (1, 2, 3)\n-        assert type(s[\"b\"]) == bytes\n+        assert type(s[\"b\"]) is bytes\n         assert s[\"b\"] == b\"\\xff\"\n-        assert type(s[\"m\"]) == Markup\n+        assert type(s[\"m\"]) is Markup\n         assert s[\"m\"] == Markup(\"<html>\")\n         assert s[\"u\"] == the_uuid\n         assert s[\"d\"] == now\n@@ -760,7 +760,7 @@ def test_teardown_request_handler_error(app, client):\n \n     @app.teardown_request\n     def teardown_request1(exc):\n-        assert type(exc) == ZeroDivisionError\n+        assert type(exc) is ZeroDivisionError\n         called.append(True)\n         # This raises a new error and blows away sys.exc_info(), so we can\n         # test that all teardown_requests get passed the same original\n@@ -772,7 +772,7 @@ def teardown_request1(exc):\n \n     @app.teardown_request\n     def teardown_request2(exc):\n-        assert type(exc) == ZeroDivisionError\n+        assert type(exc) is ZeroDivisionError\n         called.append(True)\n         # This raises a new error and blows away sys.exc_info(), so we can\n         # test that all teardown_requests get passed the same original",
        "org_msg": "fix flake8 bugbear findings",
        "sim_msg": "Allow partial content on bytesio",
        "sim_diff": "diff --git a/tests/test_helpers.py b/tests/test_helpers.py \"\"\"\nimport datetime\n+import io\nimport os\nimport uuid\n@@ -608,6 +609,23 @@ class TestSendfile(object):\nassert rv.status_code == 200\nrv.close()\n+ @pytest.mark.skipif(\n+ not callable(getattr(Range, 'to_content_range_header', None)),\n+ reason=\"not implemented within werkzeug\"\n+ )\n+ def test_send_file_range_request_bytesio(self, app, client):\n+ @app.route('/')\n+ def index():\n+ file = io.BytesIO(b'somethingsomething')\n+ return flask.send_file(\n+ file, attachment_filename='filename', conditional=True\n+ )\n+\n+ rv = client.get('/', headers={'Range': 'bytes=4-15'})\n+ assert rv.status_code == 206\n+ assert rv.data == b'somethingsomething'[4:16]\n+ rv.close()\n+\n@pytest.mark.skipif(\nnot callable(getattr(Range, 'to_content_range_header', None)),\nreason=\"not implemented within werkzeug\"\n"
    },
    {
        "org_diff": "diff --git a/src/flask/cli.py b/a/src/flask/cli.py @@ -302,7 +302,7 @@ def load_app(self) -> Flask:\n         else:\n             if self.app_import_path:\n                 path, name = (\n-                    re.split(r\":(?![\\\\/])\", self.app_import_path, 1) + [None]\n+                    re.split(r\":(?![\\\\/])\", self.app_import_path, maxsplit=1) + [None]\n                 )[:2]\n                 import_name = prepare_import(path)\n                 app = locate_app(import_name, name)",
        "org_msg": "Merge branch '2.3.x'",
        "sim_msg": "Cache return values to avoid repeated function calls.",
        "sim_diff": "diff --git a/flask/cli.py b/flask/cli.py @@ -206,8 +206,9 @@ def prepare_import(path):\n\"\"\"\npath = os.path.realpath(path)\n- if os.path.splitext(path)[1] == '.py':\n- path = os.path.splitext(path)[0]\n+ fname, ext = os.path.splitext(path)\n+ if ext == '.py':\n+ path = fname\nif os.path.basename(path) == '__init__':\npath = os.path.dirname(path)\n"
    },
    {
        "org_diff": "diff --git a/src/flask/cli.py b/a/src/flask/cli.py @@ -302,7 +302,7 @@ def load_app(self) -> Flask:\n         else:\n             if self.app_import_path:\n                 path, name = (\n-                    re.split(r\":(?![\\\\/])\", self.app_import_path, 1) + [None]\n+                    re.split(r\":(?![\\\\/])\", self.app_import_path, maxsplit=1) + [None]\n                 )[:2]\n                 import_name = prepare_import(path)\n                 app = locate_app(import_name, name)",
        "org_msg": "Pass maxsplit via kwarg to re.split (#5215)",
        "sim_msg": "Cache return values to avoid repeated function calls.",
        "sim_diff": "diff --git a/flask/cli.py b/flask/cli.py @@ -206,8 +206,9 @@ def prepare_import(path):\n\"\"\"\npath = os.path.realpath(path)\n- if os.path.splitext(path)[1] == '.py':\n- path = os.path.splitext(path)[0]\n+ fname, ext = os.path.splitext(path)\n+ if ext == '.py':\n+ path = fname\nif os.path.basename(path) == '__init__':\npath = os.path.dirname(path)\n"
    },
    {
        "org_diff": "diff --git a/src/flask/cli.py b/a/src/flask/cli.py @@ -302,7 +302,7 @@ def load_app(self) -> Flask:\n         else:\n             if self.app_import_path:\n                 path, name = (\n-                    re.split(r\":(?![\\\\/])\", self.app_import_path, 1) + [None]\n+                    re.split(r\":(?![\\\\/])\", self.app_import_path, maxsplit=1) + [None]\n                 )[:2]\n                 import_name = prepare_import(path)\n                 app = locate_app(import_name, name)",
        "org_msg": "Pass maxsplit via kwarg to re.split",
        "sim_msg": "Cache return values to avoid repeated function calls.",
        "sim_diff": "diff --git a/flask/cli.py b/flask/cli.py @@ -206,8 +206,9 @@ def prepare_import(path):\n\"\"\"\npath = os.path.realpath(path)\n- if os.path.splitext(path)[1] == '.py':\n- path = os.path.splitext(path)[0]\n+ fname, ext = os.path.splitext(path)\n+ if ext == '.py':\n+ path = fname\nif os.path.basename(path) == '__init__':\npath = os.path.dirname(path)\n"
    },
    {
        "org_diff": "diff --git a/.github/workflows/publish.yaml b/a/.github/workflows/publish.yaml @@ -63,10 +63,10 @@ jobs:\n     steps:\n       - uses: actions/download-artifact@9bc31d5ccc31df68ecc42ccf4149144866c47d8a\n       # Try uploading to Test PyPI first, in case something fails.\n-      - uses: pypa/gh-action-pypi-publish@f5622bde02b04381239da3573277701ceca8f6a0\n+      - uses: pypa/gh-action-pypi-publish@f8c70e705ffc13c3b4d1221169b84f12a75d6ca8\n         with:\n           repository-url: https://test.pypi.org/legacy/\n           packages-dir: artifact/\n-      - uses: pypa/gh-action-pypi-publish@f5622bde02b04381239da3573277701ceca8f6a0\n+      - uses: pypa/gh-action-pypi-publish@f8c70e705ffc13c3b4d1221169b84f12a75d6ca8\n         with:\n           packages-dir: artifact/",
        "org_msg": "Bump pypa/gh-action-pypi-publish from 1.8.7 to 1.8.8 (#5213)",
        "sim_msg": "Change publish target for production",
        "sim_diff": "diff --git a/.github/workflows/full-build.yml b/.github/workflows/full-build.yml @@ -397,7 +397,7 @@ jobs:\nname: Publish to PyPI (release only)\nneeds: [ linux-gtk4, linux-flatpak-devel, macos-gtk4, check-linux-appimage, check-macos-app, check-windows-installer ]\nruns-on: ubuntu-22.04\n- # if: github.event_name == 'release'\n+ if: github.event_name == 'release'\nsteps:\n- uses: actions/download-artifact@v3\nwith:\n@@ -410,4 +410,3 @@ jobs:\n- uses: pypa/gh-action-pypi-publish@release/v1\nwith:\npassword: ${{ secrets.PYPI_TOKEN }}\n- repository_url: https://test.pypi.org/legacy/\n"
    },
    {
        "org_diff": "diff --git a/.github/workflows/publish.yaml b/a/.github/workflows/publish.yaml @@ -63,10 +63,10 @@ jobs:\n     steps:\n       - uses: actions/download-artifact@9bc31d5ccc31df68ecc42ccf4149144866c47d8a\n       # Try uploading to Test PyPI first, in case something fails.\n-      - uses: pypa/gh-action-pypi-publish@f5622bde02b04381239da3573277701ceca8f6a0\n+      - uses: pypa/gh-action-pypi-publish@f8c70e705ffc13c3b4d1221169b84f12a75d6ca8\n         with:\n           repository-url: https://test.pypi.org/legacy/\n           packages-dir: artifact/\n-      - uses: pypa/gh-action-pypi-publish@f5622bde02b04381239da3573277701ceca8f6a0\n+      - uses: pypa/gh-action-pypi-publish@f8c70e705ffc13c3b4d1221169b84f12a75d6ca8\n         with:\n           packages-dir: artifact/",
        "org_msg": "Bump pypa/gh-action-pypi-publish from 1.8.7 to 1.8.8\n\nBumps [pypa/gh-action-pypi-publish](https://github.com/pypa/gh-action-pypi-publish) from 1.8.7 to 1.8.8.\n- [Release notes](https://github.com/pypa/gh-action-pypi-publish/releases)\n- [Commits](https://github.com/pypa/gh-action-pypi-publish/compare/f5622bde02b04381239da3573277701ceca8f6a0...f8c70e705ffc13c3b4d1221169b84f12a75d6ca8)\n\n---\nupdated-dependencies:\n- dependency-name: pypa/gh-action-pypi-publish\n  dependency-type: direct:production\n  update-type: version-update:semver-patch\n...\n\nSigned-off-by: dependabot[bot] <support@github.com>",
        "sim_msg": "Change publish target for production",
        "sim_diff": "diff --git a/.github/workflows/full-build.yml b/.github/workflows/full-build.yml @@ -397,7 +397,7 @@ jobs:\nname: Publish to PyPI (release only)\nneeds: [ linux-gtk4, linux-flatpak-devel, macos-gtk4, check-linux-appimage, check-macos-app, check-windows-installer ]\nruns-on: ubuntu-22.04\n- # if: github.event_name == 'release'\n+ if: github.event_name == 'release'\nsteps:\n- uses: actions/download-artifact@v3\nwith:\n@@ -410,4 +410,3 @@ jobs:\n- uses: pypa/gh-action-pypi-publish@release/v1\nwith:\npassword: ${{ secrets.PYPI_TOKEN }}\n- repository_url: https://test.pypi.org/legacy/\n"
    },
    {
        "org_diff": "diff --git a/.pre-commit-config.yaml b/a/.pre-commit-config.yaml @@ -3,7 +3,7 @@ ci:\n   autoupdate_schedule: monthly\n repos:\n   - repo: https://github.com/asottile/pyupgrade\n-    rev: v3.8.0\n+    rev: v3.10.1\n     hooks:\n       - id: pyupgrade\n         args: [\"--py38-plus\"]\n@@ -15,11 +15,11 @@ repos:\n         files: \"^(?!examples/)\"\n         args: [\"--application-directories\", \"src\"]\n   - repo: https://github.com/psf/black\n-    rev: 23.3.0\n+    rev: 23.7.0\n     hooks:\n       - id: black\n   - repo: https://github.com/PyCQA/flake8\n-    rev: 6.0.0\n+    rev: 6.1.0\n     hooks:\n       - id: flake8\n         additional_dependencies:",
        "org_msg": "[pre-commit.ci] pre-commit autoupdate (#5211)",
        "sim_msg": "Upgrade pre-commit hook versions",
        "sim_diff": "diff --git a/.pre-commit-config.yaml b/.pre-commit-config.yaml @@ -22,7 +22,7 @@ repos:\nhooks:\n- id: isort\n- repo: https://github.com/asottile/pyupgrade\n- rev: v3.0.0\n+ rev: v3.2.0\nhooks:\n- id: pyupgrade\nargs: [--py36-plus]\n@@ -38,7 +38,7 @@ repos:\n- id: rst-inline-touching-normal\n- id: text-unicode-replacement-char\n- repo: https://github.com/psf/black\n- rev: 22.8.0\n+ rev: 22.10.0\nhooks:\n- id: black\nargs: [--safe, --quiet, --target-version=py36]\n"
    },
    {
        "org_diff": "diff --git a/.pre-commit-config.yaml b/a/.pre-commit-config.yaml @@ -3,7 +3,7 @@ ci:\n   autoupdate_schedule: monthly\n repos:\n   - repo: https://github.com/asottile/pyupgrade\n-    rev: v3.8.0\n+    rev: v3.10.1\n     hooks:\n       - id: pyupgrade\n         args: [\"--py38-plus\"]\n@@ -15,11 +15,11 @@ repos:\n         files: \"^(?!examples/)\"\n         args: [\"--application-directories\", \"src\"]\n   - repo: https://github.com/psf/black\n-    rev: 23.3.0\n+    rev: 23.7.0\n     hooks:\n       - id: black\n   - repo: https://github.com/PyCQA/flake8\n-    rev: 6.0.0\n+    rev: 6.1.0\n     hooks:\n       - id: flake8\n         additional_dependencies:",
        "org_msg": "[pre-commit.ci] pre-commit autoupdate\n\nupdates:\n- [github.com/asottile/pyupgrade: v3.8.0 â†’ v3.10.1](https://github.com/asottile/pyupgrade/compare/v3.8.0...v3.10.1)\n- [github.com/psf/black: 23.3.0 â†’ 23.7.0](https://github.com/psf/black/compare/23.3.0...23.7.0)\n- [github.com/PyCQA/flake8: 6.0.0 â†’ 6.1.0](https://github.com/PyCQA/flake8/compare/6.0.0...6.1.0)",
        "sim_msg": "Upgrade pre-commit hook versions",
        "sim_diff": "diff --git a/.pre-commit-config.yaml b/.pre-commit-config.yaml @@ -22,7 +22,7 @@ repos:\nhooks:\n- id: isort\n- repo: https://github.com/asottile/pyupgrade\n- rev: v3.0.0\n+ rev: v3.2.0\nhooks:\n- id: pyupgrade\nargs: [--py36-plus]\n@@ -38,7 +38,7 @@ repos:\n- id: rst-inline-touching-normal\n- id: text-unicode-replacement-char\n- repo: https://github.com/psf/black\n- rev: 22.8.0\n+ rev: 22.10.0\nhooks:\n- id: black\nargs: [--safe, --quiet, --target-version=py36]\n"
    },
    {
        "org_diff": "diff --git a/.pre-commit-config.yaml b/a/.pre-commit-config.yaml @@ -3,7 +3,7 @@ ci:\n   autoupdate_schedule: monthly\n repos:\n   - repo: https://github.com/asottile/pyupgrade\n-    rev: v3.7.0\n+    rev: v3.8.0\n     hooks:\n       - id: pyupgrade\n         args: [\"--py38-plus\"]",
        "org_msg": "[pre-commit.ci] pre-commit autoupdate (#5187)",
        "sim_msg": "Update pre-commit config: mypy, pyupgrade",
        "sim_diff": "diff --git a/.pre-commit-config.yaml b/.pre-commit-config.yaml @@ -5,7 +5,7 @@ repos:\n- id: black\nlanguage_version: python3\n- repo: https://github.com/pre-commit/mirrors-mypy\n- rev: v0.931\n+ rev: v0.941\nhooks:\n- id: mypy\nadditional_dependencies:\n@@ -36,6 +36,6 @@ repos:\n- id: shellcheck\nargs: [--exclude, SC1017]\n- repo: https://github.com/asottile/pyupgrade\n- rev: v2.31.0\n+ rev: v2.31.1\nhooks:\n- id: pyupgrade\n"
    },
    {
        "org_diff": "diff --git a/.pre-commit-config.yaml b/a/.pre-commit-config.yaml @@ -3,7 +3,7 @@ ci:\n   autoupdate_schedule: monthly\n repos:\n   - repo: https://github.com/asottile/pyupgrade\n-    rev: v3.7.0\n+    rev: v3.8.0\n     hooks:\n       - id: pyupgrade\n         args: [\"--py38-plus\"]",
        "org_msg": "[pre-commit.ci] pre-commit autoupdate\n\nupdates:\n- [github.com/asottile/pyupgrade: v3.7.0 â†’ v3.8.0](https://github.com/asottile/pyupgrade/compare/v3.7.0...v3.8.0)",
        "sim_msg": "Update pre-commit config: mypy, pyupgrade",
        "sim_diff": "diff --git a/.pre-commit-config.yaml b/.pre-commit-config.yaml @@ -5,7 +5,7 @@ repos:\n- id: black\nlanguage_version: python3\n- repo: https://github.com/pre-commit/mirrors-mypy\n- rev: v0.931\n+ rev: v0.941\nhooks:\n- id: mypy\nadditional_dependencies:\n@@ -36,6 +36,6 @@ repos:\n- id: shellcheck\nargs: [--exclude, SC1017]\n- repo: https://github.com/asottile/pyupgrade\n- rev: v2.31.0\n+ rev: v2.31.1\nhooks:\n- id: pyupgrade\n"
    },
    {
        "org_diff": "diff --git a/docs/tutorial/install.rst b/a/docs/tutorial/install.rst @@ -35,6 +35,7 @@ The ``pyproject.toml`` file describes your project and how to build it.\n     [project]\n     name = \"flaskr\"\n     version = \"1.0.0\"\n+    description = \"The basic blog app built in the Flask tutorial.\"\n     dependencies = [\n         \"flask\",\n     ]",
        "org_msg": "Update install.rst with required description (#5182)",
        "sim_msg": "setuptools version",
        "sim_diff": "diff --git a/pyproject.toml b/pyproject.toml [build-system]\nrequires = [\n- \"setuptools\",\n+ \"setuptools==59.5.0\",\n\"wheel\",\n]\n[tool.black]\n# https://github.com/psf/black\nline-length = 120\n-target-version = [\"py36\"]\n+target-version = [\"py37\"]\n[tool.isort]\nknown_first_party = [\n@@ -19,7 +19,7 @@ known_first_party = [\nknown_third_party = [\n\"matplotlib\",\n\"numpy\",\n- \"setuptools\",\n+ \"setuptools==59.5.0\",\n\"sphinx_rtd_theme\",\n\"torch\",\n]\n"
    },
    {
        "org_diff": "diff --git a/docs/tutorial/install.rst b/a/docs/tutorial/install.rst @@ -35,6 +35,7 @@ The ``pyproject.toml`` file describes your project and how to build it.\n     [project]\n     name = \"flaskr\"\n     version = \"1.0.0\"\n+    description = \"The basic blog app built in the Flask tutorial.\"\n     dependencies = [\n         \"flask\",\n     ]",
        "org_msg": "Update install.rst with required description",
        "sim_msg": "setuptools version",
        "sim_diff": "diff --git a/pyproject.toml b/pyproject.toml [build-system]\nrequires = [\n- \"setuptools\",\n+ \"setuptools==59.5.0\",\n\"wheel\",\n]\n[tool.black]\n# https://github.com/psf/black\nline-length = 120\n-target-version = [\"py36\"]\n+target-version = [\"py37\"]\n[tool.isort]\nknown_first_party = [\n@@ -19,7 +19,7 @@ known_first_party = [\nknown_third_party = [\n\"matplotlib\",\n\"numpy\",\n- \"setuptools\",\n+ \"setuptools==59.5.0\",\n\"sphinx_rtd_theme\",\n\"torch\",\n]\n"
    },
    {
        "org_diff": "diff --git a/.github/workflows/publish.yaml b/a/.github/workflows/publish.yaml @@ -33,7 +33,7 @@ jobs:\n       id-token: write\n       contents: write\n     # Can't pin with hash due to how this workflow works.\n-    uses: slsa-framework/slsa-github-generator/.github/workflows/generator_generic_slsa3.yml@v1.6.0\n+    uses: slsa-framework/slsa-github-generator/.github/workflows/generator_generic_slsa3.yml@v1.7.0\n     with:\n       base64-subjects: ${{ needs.build.outputs.hash }}\n   create-release:",
        "org_msg": "Bump slsa-framework/slsa-github-generator from 1.6.0 to 1.7.0 (#5185)",
        "sim_msg": "Need to mark job output",
        "sim_diff": "diff --git a/.github/workflows/tag-actions.yml b/.github/workflows/tag-actions.yml @@ -10,6 +10,9 @@ jobs:\nname: Github Release\nruns-on: ubuntu-latest\n+ outputs:\n+ upload_url: ${{ steps.create_release.outputs.upload_url }}\n+\nsteps:\n- name: Create Release\nid: create_release\n@@ -125,7 +128,7 @@ jobs:\nenv:\nGITHUB_TOKEN: ${{ secrets.RELEASE_TOKEN }}\nwith:\n- upload_url: ${{ steps.create_release.outputs.upload_url }}\n+ upload_url: ${{ needs.github-release.outputs.upload_url }}\nasset_path: ./rpm/dist/beer-garden-${GITHUB_REF#refs/tags/}-1.el7.x86_64.rpm\nasset_name: beer-garden-${GITHUB_REF#refs/tags/}-1.el7.x86_64.rpm\nasset_content_type: application/octet-stream\n"
    },
    {
        "org_diff": "diff --git a/.github/workflows/lock.yaml b/a/.github/workflows/lock.yaml @@ -19,7 +19,7 @@ jobs:\n   lock:\n     runs-on: ubuntu-latest\n     steps:\n-      - uses: dessant/lock-threads@c1b35aecc5cdb1a34539d14196df55838bb2f836\n+      - uses: dessant/lock-threads@be8aa5be94131386884a6da4189effda9b14aa21\n         with:\n           issue-inactive-days: 14\n           pr-inactive-days: 14",
        "org_msg": "Bump dessant/lock-threads from 4.0.0 to 4.0.1 (#5184)",
        "sim_msg": ".github/workflows/stale.yml: Missing dash",
        "sim_diff": "diff --git a/.github/workflows/stale.yml b/.github/workflows/stale.yml @@ -12,7 +12,7 @@ jobs:\nstale:\nruns-on: ubuntu-latest\nsteps:\n- uses: actions/stale@v4\n+ - uses: actions/stale@v4\nwith:\nexempt-all-milestones: true\nany-of-labels: 'need info'\n"
    },
    {
        "org_diff": "diff --git a/.github/workflows/publish.yaml b/a/.github/workflows/publish.yaml @@ -63,10 +63,10 @@ jobs:\n     steps:\n       - uses: actions/download-artifact@9bc31d5ccc31df68ecc42ccf4149144866c47d8a\n       # Try uploading to Test PyPI first, in case something fails.\n-      - uses: pypa/gh-action-pypi-publish@a56da0b891b3dc519c7ee3284aff1fad93cc8598\n+      - uses: pypa/gh-action-pypi-publish@f5622bde02b04381239da3573277701ceca8f6a0\n         with:\n           repository-url: https://test.pypi.org/legacy/\n           packages-dir: artifact/\n-      - uses: pypa/gh-action-pypi-publish@a56da0b891b3dc519c7ee3284aff1fad93cc8598\n+      - uses: pypa/gh-action-pypi-publish@f5622bde02b04381239da3573277701ceca8f6a0\n         with:\n           packages-dir: artifact/",
        "org_msg": "Bump pypa/gh-action-pypi-publish from 1.8.6 to 1.8.7 (#5183)",
        "sim_msg": "Change publish target for production",
        "sim_diff": "diff --git a/.github/workflows/full-build.yml b/.github/workflows/full-build.yml @@ -397,7 +397,7 @@ jobs:\nname: Publish to PyPI (release only)\nneeds: [ linux-gtk4, linux-flatpak-devel, macos-gtk4, check-linux-appimage, check-macos-app, check-windows-installer ]\nruns-on: ubuntu-22.04\n- # if: github.event_name == 'release'\n+ if: github.event_name == 'release'\nsteps:\n- uses: actions/download-artifact@v3\nwith:\n@@ -410,4 +410,3 @@ jobs:\n- uses: pypa/gh-action-pypi-publish@release/v1\nwith:\npassword: ${{ secrets.PYPI_TOKEN }}\n- repository_url: https://test.pypi.org/legacy/\n"
    },
    {
        "org_diff": "diff --git a/.github/workflows/publish.yaml b/a/.github/workflows/publish.yaml @@ -33,7 +33,7 @@ jobs:\n       id-token: write\n       contents: write\n     # Can't pin with hash due to how this workflow works.\n-    uses: slsa-framework/slsa-github-generator/.github/workflows/generator_generic_slsa3.yml@v1.6.0\n+    uses: slsa-framework/slsa-github-generator/.github/workflows/generator_generic_slsa3.yml@v1.7.0\n     with:\n       base64-subjects: ${{ needs.build.outputs.hash }}\n   create-release:",
        "org_msg": "Bump slsa-framework/slsa-github-generator from 1.6.0 to 1.7.0\n\nBumps [slsa-framework/slsa-github-generator](https://github.com/slsa-framework/slsa-github-generator) from 1.6.0 to 1.7.0.\n- [Release notes](https://github.com/slsa-framework/slsa-github-generator/releases)\n- [Changelog](https://github.com/slsa-framework/slsa-github-generator/blob/main/CHANGELOG.md)\n- [Commits](https://github.com/slsa-framework/slsa-github-generator/compare/v1.6.0...v1.7.0)\n\n---\nupdated-dependencies:\n- dependency-name: slsa-framework/slsa-github-generator\n  dependency-type: direct:production\n  update-type: version-update:semver-minor\n...\n\nSigned-off-by: dependabot[bot] <support@github.com>",
        "sim_msg": "Need to mark job output",
        "sim_diff": "diff --git a/.github/workflows/tag-actions.yml b/.github/workflows/tag-actions.yml @@ -10,6 +10,9 @@ jobs:\nname: Github Release\nruns-on: ubuntu-latest\n+ outputs:\n+ upload_url: ${{ steps.create_release.outputs.upload_url }}\n+\nsteps:\n- name: Create Release\nid: create_release\n@@ -125,7 +128,7 @@ jobs:\nenv:\nGITHUB_TOKEN: ${{ secrets.RELEASE_TOKEN }}\nwith:\n- upload_url: ${{ steps.create_release.outputs.upload_url }}\n+ upload_url: ${{ needs.github-release.outputs.upload_url }}\nasset_path: ./rpm/dist/beer-garden-${GITHUB_REF#refs/tags/}-1.el7.x86_64.rpm\nasset_name: beer-garden-${GITHUB_REF#refs/tags/}-1.el7.x86_64.rpm\nasset_content_type: application/octet-stream\n"
    },
    {
        "org_diff": "diff --git a/.github/workflows/lock.yaml b/a/.github/workflows/lock.yaml @@ -19,7 +19,7 @@ jobs:\n   lock:\n     runs-on: ubuntu-latest\n     steps:\n-      - uses: dessant/lock-threads@c1b35aecc5cdb1a34539d14196df55838bb2f836\n+      - uses: dessant/lock-threads@be8aa5be94131386884a6da4189effda9b14aa21\n         with:\n           issue-inactive-days: 14\n           pr-inactive-days: 14",
        "org_msg": "Bump dessant/lock-threads from 4.0.0 to 4.0.1\n\nBumps [dessant/lock-threads](https://github.com/dessant/lock-threads) from 4.0.0 to 4.0.1.\n- [Release notes](https://github.com/dessant/lock-threads/releases)\n- [Changelog](https://github.com/dessant/lock-threads/blob/main/CHANGELOG.md)\n- [Commits](https://github.com/dessant/lock-threads/compare/c1b35aecc5cdb1a34539d14196df55838bb2f836...be8aa5be94131386884a6da4189effda9b14aa21)\n\n---\nupdated-dependencies:\n- dependency-name: dessant/lock-threads\n  dependency-type: direct:production\n  update-type: version-update:semver-patch\n...\n\nSigned-off-by: dependabot[bot] <support@github.com>",
        "sim_msg": ".github/workflows/stale.yml: Missing dash",
        "sim_diff": "diff --git a/.github/workflows/stale.yml b/.github/workflows/stale.yml @@ -12,7 +12,7 @@ jobs:\nstale:\nruns-on: ubuntu-latest\nsteps:\n- uses: actions/stale@v4\n+ - uses: actions/stale@v4\nwith:\nexempt-all-milestones: true\nany-of-labels: 'need info'\n"
    },
    {
        "org_diff": "diff --git a/.github/workflows/publish.yaml b/a/.github/workflows/publish.yaml @@ -63,10 +63,10 @@ jobs:\n     steps:\n       - uses: actions/download-artifact@9bc31d5ccc31df68ecc42ccf4149144866c47d8a\n       # Try uploading to Test PyPI first, in case something fails.\n-      - uses: pypa/gh-action-pypi-publish@a56da0b891b3dc519c7ee3284aff1fad93cc8598\n+      - uses: pypa/gh-action-pypi-publish@f5622bde02b04381239da3573277701ceca8f6a0\n         with:\n           repository-url: https://test.pypi.org/legacy/\n           packages-dir: artifact/\n-      - uses: pypa/gh-action-pypi-publish@a56da0b891b3dc519c7ee3284aff1fad93cc8598\n+      - uses: pypa/gh-action-pypi-publish@f5622bde02b04381239da3573277701ceca8f6a0\n         with:\n           packages-dir: artifact/",
        "org_msg": "Bump pypa/gh-action-pypi-publish from 1.8.6 to 1.8.7\n\nBumps [pypa/gh-action-pypi-publish](https://github.com/pypa/gh-action-pypi-publish) from 1.8.6 to 1.8.7.\n- [Release notes](https://github.com/pypa/gh-action-pypi-publish/releases)\n- [Commits](https://github.com/pypa/gh-action-pypi-publish/compare/a56da0b891b3dc519c7ee3284aff1fad93cc8598...f5622bde02b04381239da3573277701ceca8f6a0)\n\n---\nupdated-dependencies:\n- dependency-name: pypa/gh-action-pypi-publish\n  dependency-type: direct:production\n  update-type: version-update:semver-patch\n...\n\nSigned-off-by: dependabot[bot] <support@github.com>",
        "sim_msg": "Change publish target for production",
        "sim_diff": "diff --git a/.github/workflows/full-build.yml b/.github/workflows/full-build.yml @@ -397,7 +397,7 @@ jobs:\nname: Publish to PyPI (release only)\nneeds: [ linux-gtk4, linux-flatpak-devel, macos-gtk4, check-linux-appimage, check-macos-app, check-windows-installer ]\nruns-on: ubuntu-22.04\n- # if: github.event_name == 'release'\n+ if: github.event_name == 'release'\nsteps:\n- uses: actions/download-artifact@v3\nwith:\n@@ -410,4 +410,3 @@ jobs:\n- uses: pypa/gh-action-pypi-publish@release/v1\nwith:\npassword: ${{ secrets.PYPI_TOKEN }}\n- repository_url: https://test.pypi.org/legacy/\n"
    },
    {
        "org_diff": "diff --git a/docs/errorhandling.rst b/a/docs/errorhandling.rst @@ -231,7 +231,7 @@ responses, you could also pass them through directly.\n Error handlers still respect the exception class hierarchy. If you\n register handlers for both ``HTTPException`` and ``Exception``, the\n ``Exception`` handler will not handle ``HTTPException`` subclasses\n-because it the ``HTTPException`` handler is more specific.\n+because the ``HTTPException`` handler is more specific.\n \n \n Unhandled Exceptions",
        "org_msg": "fix typo in errorhandling doc (#5180)",
        "sim_msg": "Fix docs errors\n1.Grammar error: 'return' should be 'returns'; 'would is' should be\n'would be'.\n2.Reloader is used to reload and fork process if modules were changed\nrather than when an exception occurred.\n3.The sample code is not concise enough.",
        "sim_diff": "diff --git a/docs/errorhandling.rst b/docs/errorhandling.rst @@ -76,9 +76,9 @@ Error handlers\nYou might want to show custom error pages to the user when an error occurs.\nThis can be done by registering error handlers.\n-An error handler is a normal view function that return a response, but instead\n+An error handler is a normal view function that returns a response, but instead\nof being registered for a route, it is registered for an exception or HTTP\n-status code that would is raised while trying to handle a request.\n+status code that would be raised while trying to handle a request.\nRegistering\n```````````\n@@ -184,7 +184,7 @@ options in order to use your favorite debugger:\n* ``debug`` - whether to enable debug mode and catch exceptions\n* ``use_debugger`` - whether to use the internal Flask debugger\n-* ``use_reloader`` - whether to reload and fork the process on exception\n+* ``use_reloader`` - whether to reload and fork the process if modules were changed\n``debug`` must be True (i.e., exceptions must be caught) in order for the other\ntwo options to have any value.\n@@ -205,11 +205,6 @@ Then in your application's entry-point (main.py), you could have something like:\n# To allow aptana to receive errors, set use_debugger=False\napp = create_app(config=\"config.yaml\")\n- if app.debug: use_debugger = True\n- try:\n- # Disable Flask's debugger if external debugger is requested\n- use_debugger = not(app.config.get('DEBUG_WITH_APTANA'))\n- except:\n- pass\n+ use_debugger = app.debug and not(app.config.get('DEBUG_WITH_APTANA'))\napp.run(use_debugger=use_debugger, debug=app.debug,\nuse_reloader=use_debugger, host='0.0.0.0')\n"
    },
    {
        "org_diff": "diff --git a/docs/errorhandling.rst b/a/docs/errorhandling.rst @@ -231,7 +231,7 @@ responses, you could also pass them through directly.\n Error handlers still respect the exception class hierarchy. If you\n register handlers for both ``HTTPException`` and ``Exception``, the\n ``Exception`` handler will not handle ``HTTPException`` subclasses\n-because it the ``HTTPException`` handler is more specific.\n+because the ``HTTPException`` handler is more specific.\n \n \n Unhandled Exceptions",
        "org_msg": "fix typo in errorhandling doc",
        "sim_msg": "Fix docs errors\n1.Grammar error: 'return' should be 'returns'; 'would is' should be\n'would be'.\n2.Reloader is used to reload and fork process if modules were changed\nrather than when an exception occurred.\n3.The sample code is not concise enough.",
        "sim_diff": "diff --git a/docs/errorhandling.rst b/docs/errorhandling.rst @@ -76,9 +76,9 @@ Error handlers\nYou might want to show custom error pages to the user when an error occurs.\nThis can be done by registering error handlers.\n-An error handler is a normal view function that return a response, but instead\n+An error handler is a normal view function that returns a response, but instead\nof being registered for a route, it is registered for an exception or HTTP\n-status code that would is raised while trying to handle a request.\n+status code that would be raised while trying to handle a request.\nRegistering\n```````````\n@@ -184,7 +184,7 @@ options in order to use your favorite debugger:\n* ``debug`` - whether to enable debug mode and catch exceptions\n* ``use_debugger`` - whether to use the internal Flask debugger\n-* ``use_reloader`` - whether to reload and fork the process on exception\n+* ``use_reloader`` - whether to reload and fork the process if modules were changed\n``debug`` must be True (i.e., exceptions must be caught) in order for the other\ntwo options to have any value.\n@@ -205,11 +205,6 @@ Then in your application's entry-point (main.py), you could have something like:\n# To allow aptana to receive errors, set use_debugger=False\napp = create_app(config=\"config.yaml\")\n- if app.debug: use_debugger = True\n- try:\n- # Disable Flask's debugger if external debugger is requested\n- use_debugger = not(app.config.get('DEBUG_WITH_APTANA'))\n- except:\n- pass\n+ use_debugger = app.debug and not(app.config.get('DEBUG_WITH_APTANA'))\napp.run(use_debugger=use_debugger, debug=app.debug,\nuse_reloader=use_debugger, host='0.0.0.0')\n"
    },
    {
        "org_diff": "diff --git a/tox.ini b/a/tox.ini @@ -34,17 +34,9 @@ skip_install = true\n commands = pre-commit run --all-files\n \n [testenv:typing]\n-package = wheel\n-wheel_build_env = .pkg\n-constrain_package_deps = true\n-use_frozen_constraints = true\n deps = -r requirements/typing.txt\n commands = mypy\n \n [testenv:docs]\n-package = wheel\n-wheel_build_env = .pkg\n-constrain_package_deps = true\n-use_frozen_constraints = true\n deps = -r requirements/docs.txt\n commands = sphinx-build -W -b html -d {envtmpdir}/doctrees docs {envtmpdir}/html",
        "org_msg": "Merge branch '2.3.x'",
        "sim_msg": "Run mypy as part of CI",
        "sim_diff": "diff --git a/tox.ini b/tox.ini [tox]\n-envlist = flake8,py35,py36,py37,py38,docs\n+envlist = flake8,py35,py36,py37,py38,mypy,docs\nrequires = Cython>=0.29.13\n[testenv]\n@@ -26,9 +26,14 @@ basepython = python3.6\ndeps = flake8\ncommands = flake8 src/ tests/\n+[testenv:mypy]\n+basepython = python3.6\n+deps = mypy\n+commands = mypy src/\n+\n[travis]\npython =\n- 3.6: py36, docs\n+ 3.6: py36, docs, mypy\n[coverage:run]\nparallel = True\n"
    },
    {
        "org_diff": "diff --git a/tox.ini b/a/tox.ini @@ -34,17 +34,9 @@ skip_install = true\n commands = pre-commit run --all-files\n \n [testenv:typing]\n-package = wheel\n-wheel_build_env = .pkg\n-constrain_package_deps = true\n-use_frozen_constraints = true\n deps = -r requirements/typing.txt\n commands = mypy\n \n [testenv:docs]\n-package = wheel\n-wheel_build_env = .pkg\n-constrain_package_deps = true\n-use_frozen_constraints = true\n deps = -r requirements/docs.txt\n commands = sphinx-build -W -b html -d {envtmpdir}/doctrees docs {envtmpdir}/html",
        "org_msg": "simplify tox config\n\nenvs inherit base testenv",
        "sim_msg": "Run mypy as part of CI",
        "sim_diff": "diff --git a/tox.ini b/tox.ini [tox]\n-envlist = flake8,py35,py36,py37,py38,docs\n+envlist = flake8,py35,py36,py37,py38,mypy,docs\nrequires = Cython>=0.29.13\n[testenv]\n@@ -26,9 +26,14 @@ basepython = python3.6\ndeps = flake8\ncommands = flake8 src/ tests/\n+[testenv:mypy]\n+basepython = python3.6\n+deps = mypy\n+commands = mypy src/\n+\n[travis]\npython =\n- 3.6: py36, docs\n+ 3.6: py36, docs, mypy\n[coverage:run]\nparallel = True\n"
    },
    {
        "org_diff": "diff --git a/docs/patterns/sqlalchemy.rst b/a/docs/patterns/sqlalchemy.rst @@ -34,8 +34,7 @@ official documentation on the `declarative`_ extension.\n Here's the example :file:`database.py` module for your application::\n \n     from sqlalchemy import create_engine\n-    from sqlalchemy.orm import scoped_session, sessionmaker\n-    from sqlalchemy.ext.declarative import declarative_base\n+    from sqlalchemy.orm import scoped_session, sessionmaker, declarative_base\n \n     engine = create_engine('sqlite:////tmp/test.db')\n     db_session = scoped_session(sessionmaker(autocommit=False,",
        "org_msg": "update import of declarative_base from SQLAlchemy (#5171)",
        "sim_msg": "RENAME engine -> db_engine",
        "sim_diff": "diff --git a/packages/syft/src/syft/core/node/common/node.py b/packages/syft/src/syft/core/node/common/node.py @@ -110,7 +110,7 @@ class Node(AbstractNode):\nverify_key: Optional[VerifyKey] = None,\ndb_path: Optional[str] = None,\nTableBase: Any = None,\n- engine: Any = None,\n+ db_engine: Any = None,\ndb: Any = None,\n):\n@@ -132,14 +132,14 @@ class Node(AbstractNode):\nif db is None:\n# If a DB engine isn't provided then\n- if engine is None:\n+ if db_engine is None:\nengine = create_engine(\"sqlite://\", echo=False)\n- db = sessionmaker(bind=engine)()\n+ db = sessionmaker(bind=db_engine)()\n# cache these variables on self\nself.TableBase = TableBase\n- self.engine = engine\n+ self.db_engine = db_engine\nself.db = db\n# launch the tables in the database\n@@ -153,8 +153,9 @@ class Node(AbstractNode):\n# become quite numerous (or otherwise fill up RAM).\n# self.store is the elastic memory.\n+\nself.store = BinObjectManager(\n- db=self.db\n+ db=self.db_engine\n)\n# We need to register all the services once a node is created\n"
    },
    {
        "org_diff": "diff --git a/docs/patterns/sqlalchemy.rst b/a/docs/patterns/sqlalchemy.rst @@ -34,8 +34,7 @@ official documentation on the `declarative`_ extension.\n Here's the example :file:`database.py` module for your application::\n \n     from sqlalchemy import create_engine\n-    from sqlalchemy.orm import scoped_session, sessionmaker\n-    from sqlalchemy.ext.declarative import declarative_base\n+    from sqlalchemy.orm import scoped_session, sessionmaker, declarative_base\n \n     engine = create_engine('sqlite:////tmp/test.db')\n     db_session = scoped_session(sessionmaker(autocommit=False,",
        "org_msg": "update import of declarative_base from SQLAlchemy",
        "sim_msg": "RENAME engine -> db_engine",
        "sim_diff": "diff --git a/packages/syft/src/syft/core/node/common/node.py b/packages/syft/src/syft/core/node/common/node.py @@ -110,7 +110,7 @@ class Node(AbstractNode):\nverify_key: Optional[VerifyKey] = None,\ndb_path: Optional[str] = None,\nTableBase: Any = None,\n- engine: Any = None,\n+ db_engine: Any = None,\ndb: Any = None,\n):\n@@ -132,14 +132,14 @@ class Node(AbstractNode):\nif db is None:\n# If a DB engine isn't provided then\n- if engine is None:\n+ if db_engine is None:\nengine = create_engine(\"sqlite://\", echo=False)\n- db = sessionmaker(bind=engine)()\n+ db = sessionmaker(bind=db_engine)()\n# cache these variables on self\nself.TableBase = TableBase\n- self.engine = engine\n+ self.db_engine = db_engine\nself.db = db\n# launch the tables in the database\n@@ -153,8 +153,9 @@ class Node(AbstractNode):\n# become quite numerous (or otherwise fill up RAM).\n# self.store is the elastic memory.\n+\nself.store = BinObjectManager(\n- db=self.db\n+ db=self.db_engine\n)\n# We need to register all the services once a node is created\n"
    },
    {
        "org_diff": "diff --git a/pyproject.toml b/a/pyproject.toml @@ -54,8 +54,8 @@ version = {attr = \"flask.__version__\"}\n testpaths = [\"tests\"]\n filterwarnings = [\n     \"error\",\n-    # change in Python 3.12 alpha causes warning from inside pytest\n-    \"ignore:onerror argument:DeprecationWarning\",\n+    # change in Python 3.12 causes warning from inside pytest\n+    \"ignore:ast:DeprecationWarning\",\n ]\n \n [tool.coverage.run]",
        "org_msg": "ignore pytest ast warnings",
        "sim_msg": "Exclude operators for mypy",
        "sim_diff": "diff --git a/pyproject.toml b/pyproject.toml @@ -59,7 +59,7 @@ float_to_top=true\npython_version = \"3.9\"\nfollow_imports = \"silent\"\nfiles = [\"reactivex\"]\n-exclude = [\"reactivex/core/operators\"]\n+exclude = [\"reactivex/operators/_\\\\w.*\\\\.py$\"]\n[tool.pytest.ini_options]\ntestpaths = [\"tests\"]\n"
    },
    {
        "org_diff": "diff --git a/.pre-commit-config.yaml b/a/.pre-commit-config.yaml @@ -7,7 +7,7 @@ repos:\n     hooks:\n       - id: pyupgrade\n         args: [\"--py38-plus\"]\n-  - repo: https://github.com/asottile/reorder_python_imports\n+  - repo: https://github.com/asottile/reorder-python-imports\n     rev: v3.9.0\n     hooks:\n       - id: reorder-python-imports",
        "org_msg": "[pre-commit.ci] pre-commit autoupdate\n\nupdates:\n- https://github.com/asottile/reorder_python_imports â†’ https://github.com/asottile/reorder-python-imports",
        "sim_msg": "run reorder-python-imports with `--py37-plus`",
        "sim_diff": "diff --git a/.pre-commit-config.yaml b/.pre-commit-config.yaml @@ -20,7 +20,7 @@ repos:\nrev: v2.7.1\nhooks:\n- id: reorder-python-imports\n- args: [--add-import, 'from __future__ import annotations']\n+ args: [--py37-plus, --add-import, 'from __future__ import annotations']\n- repo: https://github.com/asottile/add-trailing-comma\nrev: v2.2.1\nhooks:\n"
    },
    {
        "org_diff": "diff --git a/.pre-commit-config.yaml b/a/.pre-commit-config.yaml @@ -1,5 +1,5 @@\n ci:\n-  autoupdate_branch: \"2.2.x\"\n+  autoupdate_branch: \"2.3.x\"\n   autoupdate_schedule: monthly\n repos:\n   - repo: https://github.com/asottile/pyupgrade",
        "org_msg": "Merge branch '2.3.x'",
        "sim_msg": "Update black and mypy versions in pre-commit yaml",
        "sim_diff": "diff --git a/.pre-commit-config.yaml b/.pre-commit-config.yaml @@ -5,7 +5,7 @@ default_language_version:\nrepos:\n- repo: https://github.com/psf/black\n- rev: 21.12b0\n+ rev: 22.1.0\nhooks:\n- id: black\n@@ -39,6 +39,6 @@ repos:\n- --ignore-init-module-imports\n- repo: https://github.com/pre-commit/mirrors-mypy\n- rev: v0.930\n+ rev: v0.931\nhooks:\n- id: mypy\n"
    },
    {
        "org_diff": "diff --git a/.pre-commit-config.yaml b/a/.pre-commit-config.yaml @@ -1,5 +1,5 @@\n ci:\n-  autoupdate_branch: \"2.2.x\"\n+  autoupdate_branch: \"2.3.x\"\n   autoupdate_schedule: monthly\n repos:\n   - repo: https://github.com/asottile/pyupgrade",
        "org_msg": "retarget pre-commit.ci",
        "sim_msg": "Update black and mypy versions in pre-commit yaml",
        "sim_diff": "diff --git a/.pre-commit-config.yaml b/.pre-commit-config.yaml @@ -5,7 +5,7 @@ default_language_version:\nrepos:\n- repo: https://github.com/psf/black\n- rev: 21.12b0\n+ rev: 22.1.0\nhooks:\n- id: black\n@@ -39,6 +39,6 @@ repos:\n- --ignore-init-module-imports\n- repo: https://github.com/pre-commit/mirrors-mypy\n- rev: v0.930\n+ rev: v0.931\nhooks:\n- id: mypy\n"
    },
    {
        "org_diff": "diff --git a/.github/workflows/publish.yaml b/a/.github/workflows/publish.yaml @@ -63,10 +63,10 @@ jobs:\n     steps:\n       - uses: actions/download-artifact@9bc31d5ccc31df68ecc42ccf4149144866c47d8a\n       # Try uploading to Test PyPI first, in case something fails.\n-      - uses: pypa/gh-action-pypi-publish@0bf742be3ebe032c25dd15117957dc15d0cfc38d\n+      - uses: pypa/gh-action-pypi-publish@a56da0b891b3dc519c7ee3284aff1fad93cc8598\n         with:\n           repository-url: https://test.pypi.org/legacy/\n           packages-dir: artifact/\n-      - uses: pypa/gh-action-pypi-publish@0bf742be3ebe032c25dd15117957dc15d0cfc38d\n+      - uses: pypa/gh-action-pypi-publish@a56da0b891b3dc519c7ee3284aff1fad93cc8598\n         with:\n           packages-dir: artifact/",
        "org_msg": "Bump pypa/gh-action-pypi-publish from 1.8.5 to 1.8.6 (#5149)",
        "sim_msg": "Change publish target for production",
        "sim_diff": "diff --git a/.github/workflows/full-build.yml b/.github/workflows/full-build.yml @@ -397,7 +397,7 @@ jobs:\nname: Publish to PyPI (release only)\nneeds: [ linux-gtk4, linux-flatpak-devel, macos-gtk4, check-linux-appimage, check-macos-app, check-windows-installer ]\nruns-on: ubuntu-22.04\n- # if: github.event_name == 'release'\n+ if: github.event_name == 'release'\nsteps:\n- uses: actions/download-artifact@v3\nwith:\n@@ -410,4 +410,3 @@ jobs:\n- uses: pypa/gh-action-pypi-publish@release/v1\nwith:\npassword: ${{ secrets.PYPI_TOKEN }}\n- repository_url: https://test.pypi.org/legacy/\n"
    },
    {
        "org_diff": "diff --git a/.github/workflows/publish.yaml b/a/.github/workflows/publish.yaml @@ -33,7 +33,7 @@ jobs:\n       id-token: write\n       contents: write\n     # Can't pin with hash due to how this workflow works.\n-    uses: slsa-framework/slsa-github-generator/.github/workflows/generator_generic_slsa3.yml@v1.5.0\n+    uses: slsa-framework/slsa-github-generator/.github/workflows/generator_generic_slsa3.yml@v1.6.0\n     with:\n       base64-subjects: ${{ needs.build.outputs.hash }}\n   create-release:",
        "org_msg": "Bump slsa-framework/slsa-github-generator from 1.5.0 to 1.6.0 (#5148)",
        "sim_msg": "Need to mark job output",
        "sim_diff": "diff --git a/.github/workflows/tag-actions.yml b/.github/workflows/tag-actions.yml @@ -10,6 +10,9 @@ jobs:\nname: Github Release\nruns-on: ubuntu-latest\n+ outputs:\n+ upload_url: ${{ steps.create_release.outputs.upload_url }}\n+\nsteps:\n- name: Create Release\nid: create_release\n@@ -125,7 +128,7 @@ jobs:\nenv:\nGITHUB_TOKEN: ${{ secrets.RELEASE_TOKEN }}\nwith:\n- upload_url: ${{ steps.create_release.outputs.upload_url }}\n+ upload_url: ${{ needs.github-release.outputs.upload_url }}\nasset_path: ./rpm/dist/beer-garden-${GITHUB_REF#refs/tags/}-1.el7.x86_64.rpm\nasset_name: beer-garden-${GITHUB_REF#refs/tags/}-1.el7.x86_64.rpm\nasset_content_type: application/octet-stream\n"
    },
    {
        "org_diff": "diff --git a/.github/workflows/publish.yaml b/a/.github/workflows/publish.yaml @@ -63,10 +63,10 @@ jobs:\n     steps:\n       - uses: actions/download-artifact@9bc31d5ccc31df68ecc42ccf4149144866c47d8a\n       # Try uploading to Test PyPI first, in case something fails.\n-      - uses: pypa/gh-action-pypi-publish@0bf742be3ebe032c25dd15117957dc15d0cfc38d\n+      - uses: pypa/gh-action-pypi-publish@a56da0b891b3dc519c7ee3284aff1fad93cc8598\n         with:\n           repository-url: https://test.pypi.org/legacy/\n           packages-dir: artifact/\n-      - uses: pypa/gh-action-pypi-publish@0bf742be3ebe032c25dd15117957dc15d0cfc38d\n+      - uses: pypa/gh-action-pypi-publish@a56da0b891b3dc519c7ee3284aff1fad93cc8598\n         with:\n           packages-dir: artifact/",
        "org_msg": "Bump pypa/gh-action-pypi-publish from 1.8.5 to 1.8.6\n\nBumps [pypa/gh-action-pypi-publish](https://github.com/pypa/gh-action-pypi-publish) from 1.8.5 to 1.8.6.\n- [Release notes](https://github.com/pypa/gh-action-pypi-publish/releases)\n- [Commits](https://github.com/pypa/gh-action-pypi-publish/compare/0bf742be3ebe032c25dd15117957dc15d0cfc38d...a56da0b891b3dc519c7ee3284aff1fad93cc8598)\n\n---\nupdated-dependencies:\n- dependency-name: pypa/gh-action-pypi-publish\n  dependency-type: direct:production\n  update-type: version-update:semver-patch\n...\n\nSigned-off-by: dependabot[bot] <support@github.com>",
        "sim_msg": "Change publish target for production",
        "sim_diff": "diff --git a/.github/workflows/full-build.yml b/.github/workflows/full-build.yml @@ -397,7 +397,7 @@ jobs:\nname: Publish to PyPI (release only)\nneeds: [ linux-gtk4, linux-flatpak-devel, macos-gtk4, check-linux-appimage, check-macos-app, check-windows-installer ]\nruns-on: ubuntu-22.04\n- # if: github.event_name == 'release'\n+ if: github.event_name == 'release'\nsteps:\n- uses: actions/download-artifact@v3\nwith:\n@@ -410,4 +410,3 @@ jobs:\n- uses: pypa/gh-action-pypi-publish@release/v1\nwith:\npassword: ${{ secrets.PYPI_TOKEN }}\n- repository_url: https://test.pypi.org/legacy/\n"
    },
    {
        "org_diff": "diff --git a/.github/workflows/publish.yaml b/a/.github/workflows/publish.yaml @@ -33,7 +33,7 @@ jobs:\n       id-token: write\n       contents: write\n     # Can't pin with hash due to how this workflow works.\n-    uses: slsa-framework/slsa-github-generator/.github/workflows/generator_generic_slsa3.yml@v1.5.0\n+    uses: slsa-framework/slsa-github-generator/.github/workflows/generator_generic_slsa3.yml@v1.6.0\n     with:\n       base64-subjects: ${{ needs.build.outputs.hash }}\n   create-release:",
        "org_msg": "Bump slsa-framework/slsa-github-generator from 1.5.0 to 1.6.0\n\nBumps [slsa-framework/slsa-github-generator](https://github.com/slsa-framework/slsa-github-generator) from 1.5.0 to 1.6.0.\n- [Release notes](https://github.com/slsa-framework/slsa-github-generator/releases)\n- [Changelog](https://github.com/slsa-framework/slsa-github-generator/blob/main/CHANGELOG.md)\n- [Commits](https://github.com/slsa-framework/slsa-github-generator/compare/v1.5.0...v1.6.0)\n\n---\nupdated-dependencies:\n- dependency-name: slsa-framework/slsa-github-generator\n  dependency-type: direct:production\n  update-type: version-update:semver-minor\n...\n\nSigned-off-by: dependabot[bot] <support@github.com>",
        "sim_msg": "Need to mark job output",
        "sim_diff": "diff --git a/.github/workflows/tag-actions.yml b/.github/workflows/tag-actions.yml @@ -10,6 +10,9 @@ jobs:\nname: Github Release\nruns-on: ubuntu-latest\n+ outputs:\n+ upload_url: ${{ steps.create_release.outputs.upload_url }}\n+\nsteps:\n- name: Create Release\nid: create_release\n@@ -125,7 +128,7 @@ jobs:\nenv:\nGITHUB_TOKEN: ${{ secrets.RELEASE_TOKEN }}\nwith:\n- upload_url: ${{ steps.create_release.outputs.upload_url }}\n+ upload_url: ${{ needs.github-release.outputs.upload_url }}\nasset_path: ./rpm/dist/beer-garden-${GITHUB_REF#refs/tags/}-1.el7.x86_64.rpm\nasset_name: beer-garden-${GITHUB_REF#refs/tags/}-1.el7.x86_64.rpm\nasset_content_type: application/octet-stream\n"
    },
    {
        "org_diff": "diff --git a/pyproject.toml b/a/pyproject.toml @@ -4,7 +4,6 @@ description = \"A simple framework for building complex web applications.\"\n readme = \"README.rst\"\n license = {text = \"BSD-3-Clause\"}\n maintainers = [{name = \"Pallets\", email = \"contact@palletsprojects.com\"}]\n-authors = [{name = \"Armin Ronacher\", email = \"armin.ronacher@active-4.com\"}]\n classifiers = [\n     \"Development Status :: 5 - Production/Stable\",\n     \"Environment :: Web Environment\",",
        "org_msg": "update metadata",
        "sim_msg": "Added doc and test source to sdist",
        "sim_diff": "diff --git a/pyproject.toml b/pyproject.toml @@ -14,7 +14,9 @@ classifiers = [\n\"Programming Language :: Python :: 3.7\",\n]\npackages = [\n- { include = \"astral\", from = \"src\"}\n+ { include = \"astral\", from = \"src\"},\n+ { include = \"doc\", from = \"src\", format = \"sdist\"},\n+ { include = \"test\", from = \"src\", format = \"sdist\"},\n]\n[tool.poetry.dependencies]\n"
    },
    {
        "org_diff": "diff --git a/docs/config.rst b/a/docs/config.rst @@ -410,8 +410,8 @@ from a TOML file:\n \n .. code-block:: python\n \n-    import toml\n-    app.config.from_file(\"config.toml\", load=toml.load)\n+    import tomllib\n+    app.config.from_file(\"config.toml\", load=tomllib.load, text=False)\n \n Or from a JSON file:\n ",
        "org_msg": "Merge pull request #5140 from Jeroendevr/patch-1",
        "sim_msg": "Fix relative path to pyproject.toml is not found",
        "sim_diff": "diff --git a/docs/conf.py b/docs/conf.py # import os\n# import sys\n# sys.path.insert(0, os.path.abspath('.'))\n+from pathlib import Path\n+\nfrom tomlkit import parse\n# -- Project information -----------------------------------------------------\n@@ -25,10 +27,9 @@ author = \"Arjan J. Molenaar\"\n# The short X.Y version\nversion = \"\"\n-with open(\"../pyproject.toml\", \"r\") as f:\n- parsed_toml = parse(f.read())\n- # The full version, including alpha/beta/rc tags.\n- release = parsed_toml[\"tool\"][\"poetry\"][\"version\"]\n+project_dir = Path(__file__).resolve().parent.parent\n+f = project_dir.joinpath(\"pyproject.toml\")\n+release = parse(f.read_text())[\"tool\"][\"poetry\"][\"version\"]\n# -- General configuration ---------------------------------------------------\n"
    },
    {
        "org_diff": "diff --git a/docs/config.rst b/a/docs/config.rst @@ -410,8 +410,8 @@ from a TOML file:\n \n .. code-block:: python\n \n-    import toml\n-    app.config.from_file(\"config.toml\", load=toml.load)\n+    import tomllib\n+    app.config.from_file(\"config.toml\", load=tomllib.load, text=False)\n \n Or from a JSON file:\n ",
        "org_msg": "Config from Data Files to match from_file API\n\nIn the API docs using a TOML file to load config is referred to as https://flask.palletsprojects.com/en/2.3.x/api/#flask.Config.from_file\r\n\r\nTo keep docs consistent a small change to the config docs.",
        "sim_msg": "Fix relative path to pyproject.toml is not found",
        "sim_diff": "diff --git a/docs/conf.py b/docs/conf.py # import os\n# import sys\n# sys.path.insert(0, os.path.abspath('.'))\n+from pathlib import Path\n+\nfrom tomlkit import parse\n# -- Project information -----------------------------------------------------\n@@ -25,10 +27,9 @@ author = \"Arjan J. Molenaar\"\n# The short X.Y version\nversion = \"\"\n-with open(\"../pyproject.toml\", \"r\") as f:\n- parsed_toml = parse(f.read())\n- # The full version, including alpha/beta/rc tags.\n- release = parsed_toml[\"tool\"][\"poetry\"][\"version\"]\n+project_dir = Path(__file__).resolve().parent.parent\n+f = project_dir.joinpath(\"pyproject.toml\")\n+release = parse(f.read_text())[\"tool\"][\"poetry\"][\"version\"]\n# -- General configuration ---------------------------------------------------\n"
    },
    {
        "org_diff": "diff --git a/docs/patterns/javascript.rst b/a/docs/patterns/javascript.rst @@ -125,8 +125,8 @@ in a Flask view.\n .. code-block:: javascript\n \n     let data = new FormData()\n-    data.append(\"name\": \"Flask Room\")\n-    data.append(\"description\": \"Talk about Flask here.\")\n+    data.append(\"name\", \"Flask Room\")\n+    data.append(\"description\", \"Talk about Flask here.\")\n     fetch(room_url, {\n         \"method\": \"POST\",\n         \"body\": data,",
        "org_msg": "docs: fix wrong JS syntax (#5136)",
        "sim_msg": "Prettily returning thingy with mime type and stuff",
        "sim_diff": "diff --git a/app/views/api.py b/app/views/api.py @@ -6,7 +6,7 @@ Some rules we should follow:\n\"\"\"\nfrom datetime import datetime, timedelta\n-from flask import Blueprint, jsonify, request, render_template, g\n+from flask import Blueprint, jsonify, request, render_template, g, send_file\nfrom flask_login import login_required, current_user\nfrom flask_oauthlib.provider import OAuth2Provider\nfrom .. import misc, sorting\n@@ -435,7 +435,7 @@ def whoamiv2():\n@api.route('/api/paint/canvas')\ndef getCanvas():\npixels = db.query('SELECT * FROM `pixel`').fetchall()\n- final = ''\n+ final = b''\nfor pixel in pixels:\nfinal += bytes([pixel['posy'],\n@@ -443,4 +443,4 @@ def getCanvas():\npixel['color'],\npixel['value'], 0])\n- return final\n+ return send_file(final, mimetype='application/octet-stream')\n"
    },
    {
        "org_diff": "diff --git a/src/flask/config.py b/a/src/flask/config.py @@ -72,7 +72,9 @@ class Config(dict):\n     :param defaults: an optional dictionary of default values\n     \"\"\"\n \n-    def __init__(self, root_path: str, defaults: dict | None = None) -> None:\n+    def __init__(\n+        self, root_path: str | os.PathLike, defaults: dict | None = None\n+    ) -> None:\n         super().__init__(defaults or {})\n         self.root_path = root_path\n \n@@ -164,7 +166,7 @@ def from_prefixed_env(\n \n         return True\n \n-    def from_pyfile(self, filename: str, silent: bool = False) -> bool:\n+    def from_pyfile(self, filename: str | os.PathLike, silent: bool = False) -> bool:\n         \"\"\"Updates the values in the config from a Python file.  This function\n         behaves as if the file was imported as module with the\n         :meth:`from_object` function.\n@@ -233,7 +235,7 @@ class and has ``@property`` attributes, it needs to be\n \n     def from_file(\n         self,\n-        filename: str,\n+        filename: str | os.PathLike,\n         load: t.Callable[[t.IO[t.Any]], t.Mapping],\n         silent: bool = False,\n         text: bool = True,",
        "org_msg": "Merge pull request #5126 from pgjones/pathlike\n\nAllow for PathLike types for config file variables",
        "sim_msg": "Fix misrendered docstring\nThe API reference for `flask.Config.from_mapping` needs a newline to separate\nthe summary from the return description.  I also wrapped the docstring at 72\ncharacters as suggested in CONTRIBUTING.rst.",
        "sim_diff": "diff --git a/src/flask/config.py b/src/flask/config.py @@ -275,8 +275,9 @@ class Config(dict):\ndef from_mapping(\nself, mapping: t.Optional[t.Mapping[str, t.Any]] = None, **kwargs: t.Any\n) -> bool:\n- \"\"\"Updates the config like :meth:`update` ignoring items with non-upper\n- keys.\n+ \"\"\"Updates the config like :meth:`update` ignoring items with\n+ non-upper keys.\n+\n:return: Always returns ``True``.\n.. versionadded:: 0.11\n"
    },
    {
        "org_diff": "diff --git a/src/flask/config.py b/a/src/flask/config.py @@ -72,7 +72,9 @@ class Config(dict):\n     :param defaults: an optional dictionary of default values\n     \"\"\"\n \n-    def __init__(self, root_path: str, defaults: dict | None = None) -> None:\n+    def __init__(\n+        self, root_path: str | os.PathLike, defaults: dict | None = None\n+    ) -> None:\n         super().__init__(defaults or {})\n         self.root_path = root_path\n \n@@ -164,7 +166,7 @@ def from_prefixed_env(\n \n         return True\n \n-    def from_pyfile(self, filename: str, silent: bool = False) -> bool:\n+    def from_pyfile(self, filename: str | os.PathLike, silent: bool = False) -> bool:\n         \"\"\"Updates the values in the config from a Python file.  This function\n         behaves as if the file was imported as module with the\n         :meth:`from_object` function.\n@@ -233,7 +235,7 @@ class and has ``@property`` attributes, it needs to be\n \n     def from_file(\n         self,\n-        filename: str,\n+        filename: str | os.PathLike,\n         load: t.Callable[[t.IO[t.Any]], t.Mapping],\n         silent: bool = False,\n         text: bool = True,",
        "org_msg": "Allow for PathLike types for config file variables\n\nThis follows the Flask practice elsewhere and makes it clear PathLike\nfilenames are valid.",
        "sim_msg": "Fix misrendered docstring\nThe API reference for `flask.Config.from_mapping` needs a newline to separate\nthe summary from the return description.  I also wrapped the docstring at 72\ncharacters as suggested in CONTRIBUTING.rst.",
        "sim_diff": "diff --git a/src/flask/config.py b/src/flask/config.py @@ -275,8 +275,9 @@ class Config(dict):\ndef from_mapping(\nself, mapping: t.Optional[t.Mapping[str, t.Any]] = None, **kwargs: t.Any\n) -> bool:\n- \"\"\"Updates the config like :meth:`update` ignoring items with non-upper\n- keys.\n+ \"\"\"Updates the config like :meth:`update` ignoring items with\n+ non-upper keys.\n+\n:return: Always returns ``True``.\n.. versionadded:: 0.11\n"
    },
    {
        "org_diff": "diff --git a/CHANGES.rst b/a/CHANGES.rst @@ -69,6 +69,15 @@ Released 2023-04-25\n -   Use postponed evaluation of annotations. :pr:`5071`\n \n \n+Version 2.2.5\n+-------------\n+\n+Released 2023-05-02\n+\n+-   Update for compatibility with Werkzeug 2.3.3.\n+-   Set ``Vary: Cookie`` header when the session is accessed, modified, or refreshed.\n+\n+\n Version 2.2.4\n -------------\n ",
        "org_msg": "Merge branch '2.2.x' into 2.3.x",
        "sim_msg": "Changelog entry for cookie expiration based on `Set-Cookie: max-age=<n>`",
        "sim_diff": "diff --git a/CHANGELOG.rst b/CHANGELOG.rst @@ -9,6 +9,7 @@ This project adheres to `Semantic Versioning <https://semver.org/>`_.\n`2.4.0-dev`_ (unreleased)\n-------------------------\n+* Added support for ``--session`` cookie expiration based on ``Set-Cookie: max-age=<n>``. (`#1029`_)\n* Show a ``--check-status`` warning with ``--quiet`` as well, not only when the output si redirected. (`#1026`_)\n* Fixed upload with ``--session`` (`#1020`_).\n* Fixed a missing blank line between request and response (`#1006`_).\n@@ -489,3 +490,4 @@ This project adheres to `Semantic Versioning <https://semver.org/>`_.\n.. _#1006: https://github.com/httpie/httpie/issues/1006\n.. _#1020: https://github.com/httpie/httpie/issues/1020\n.. _#1026: https://github.com/httpie/httpie/issues/1026\n+.. _#1029: https://github.com/httpie/httpie/issues/1029\n"
    },
    {
        "org_diff": "diff --git a/.github/workflows/publish.yaml b/a/.github/workflows/publish.yaml @@ -63,10 +63,10 @@ jobs:\n     steps:\n       - uses: actions/download-artifact@9bc31d5ccc31df68ecc42ccf4149144866c47d8a\n       # Try uploading to Test PyPI first, in case something fails.\n-      - uses: pypa/gh-action-pypi-publish@29930c9cf57955dc1b98162d0d8bc3ec80d9e75c\n+      - uses: pypa/gh-action-pypi-publish@0bf742be3ebe032c25dd15117957dc15d0cfc38d\n         with:\n           repository_url: https://test.pypi.org/legacy/\n           packages_dir: artifact/\n-      - uses: pypa/gh-action-pypi-publish@29930c9cf57955dc1b98162d0d8bc3ec80d9e75c\n+      - uses: pypa/gh-action-pypi-publish@0bf742be3ebe032c25dd15117957dc15d0cfc38d\n         with:\n           packages_dir: artifact/",
        "org_msg": "Merge pull request #5106 from pallets/dependabot/github_actions/pypa/gh-action-pypi-publish-1.8.5\n\nBump pypa/gh-action-pypi-publish from 1.8.4 to 1.8.5",
        "sim_msg": "Change publish target for production",
        "sim_diff": "diff --git a/.github/workflows/full-build.yml b/.github/workflows/full-build.yml @@ -397,7 +397,7 @@ jobs:\nname: Publish to PyPI (release only)\nneeds: [ linux-gtk4, linux-flatpak-devel, macos-gtk4, check-linux-appimage, check-macos-app, check-windows-installer ]\nruns-on: ubuntu-22.04\n- # if: github.event_name == 'release'\n+ if: github.event_name == 'release'\nsteps:\n- uses: actions/download-artifact@v3\nwith:\n@@ -410,4 +410,3 @@ jobs:\n- uses: pypa/gh-action-pypi-publish@release/v1\nwith:\npassword: ${{ secrets.PYPI_TOKEN }}\n- repository_url: https://test.pypi.org/legacy/\n"
    },
    {
        "org_diff": "diff --git a/.github/workflows/publish.yaml b/a/.github/workflows/publish.yaml @@ -63,10 +63,10 @@ jobs:\n     steps:\n       - uses: actions/download-artifact@9bc31d5ccc31df68ecc42ccf4149144866c47d8a\n       # Try uploading to Test PyPI first, in case something fails.\n-      - uses: pypa/gh-action-pypi-publish@29930c9cf57955dc1b98162d0d8bc3ec80d9e75c\n+      - uses: pypa/gh-action-pypi-publish@0bf742be3ebe032c25dd15117957dc15d0cfc38d\n         with:\n           repository_url: https://test.pypi.org/legacy/\n           packages_dir: artifact/\n-      - uses: pypa/gh-action-pypi-publish@29930c9cf57955dc1b98162d0d8bc3ec80d9e75c\n+      - uses: pypa/gh-action-pypi-publish@0bf742be3ebe032c25dd15117957dc15d0cfc38d\n         with:\n           packages_dir: artifact/",
        "org_msg": "Bump pypa/gh-action-pypi-publish from 1.8.4 to 1.8.5\n\nBumps [pypa/gh-action-pypi-publish](https://github.com/pypa/gh-action-pypi-publish) from 1.8.4 to 1.8.5.\n- [Release notes](https://github.com/pypa/gh-action-pypi-publish/releases)\n- [Commits](https://github.com/pypa/gh-action-pypi-publish/compare/29930c9cf57955dc1b98162d0d8bc3ec80d9e75c...0bf742be3ebe032c25dd15117957dc15d0cfc38d)\n\n---\nupdated-dependencies:\n- dependency-name: pypa/gh-action-pypi-publish\n  dependency-type: direct:production\n  update-type: version-update:semver-patch\n...\n\nSigned-off-by: dependabot[bot] <support@github.com>",
        "sim_msg": "Change publish target for production",
        "sim_diff": "diff --git a/.github/workflows/full-build.yml b/.github/workflows/full-build.yml @@ -397,7 +397,7 @@ jobs:\nname: Publish to PyPI (release only)\nneeds: [ linux-gtk4, linux-flatpak-devel, macos-gtk4, check-linux-appimage, check-macos-app, check-windows-installer ]\nruns-on: ubuntu-22.04\n- # if: github.event_name == 'release'\n+ if: github.event_name == 'release'\nsteps:\n- uses: actions/download-artifact@v3\nwith:\n@@ -410,4 +410,3 @@ jobs:\n- uses: pypa/gh-action-pypi-publish@release/v1\nwith:\npassword: ${{ secrets.PYPI_TOKEN }}\n- repository_url: https://test.pypi.org/legacy/\n"
    },
    {
        "org_diff": "diff --git a/CHANGES.rst b/a/CHANGES.rst @@ -1,7 +1,7 @@\n Version 2.3.2\n -------------\n \n-Released 2022-05-01\n+Released 2023-05-01\n \n -   Set ``Vary: Cookie`` header when the session is accessed, modified, or refreshed.\n -   Update Werkzeug requirement to >=2.3.3 to apply recent bug fixes.",
        "org_msg": "fix release date",
        "sim_msg": "Changelog entry for cookie expiration based on `Set-Cookie: max-age=<n>`",
        "sim_diff": "diff --git a/CHANGELOG.rst b/CHANGELOG.rst @@ -9,6 +9,7 @@ This project adheres to `Semantic Versioning <https://semver.org/>`_.\n`2.4.0-dev`_ (unreleased)\n-------------------------\n+* Added support for ``--session`` cookie expiration based on ``Set-Cookie: max-age=<n>``. (`#1029`_)\n* Show a ``--check-status`` warning with ``--quiet`` as well, not only when the output si redirected. (`#1026`_)\n* Fixed upload with ``--session`` (`#1020`_).\n* Fixed a missing blank line between request and response (`#1006`_).\n@@ -489,3 +490,4 @@ This project adheres to `Semantic Versioning <https://semver.org/>`_.\n.. _#1006: https://github.com/httpie/httpie/issues/1006\n.. _#1020: https://github.com/httpie/httpie/issues/1020\n.. _#1026: https://github.com/httpie/httpie/issues/1026\n+.. _#1029: https://github.com/httpie/httpie/issues/1029\n"
    },
    {
        "org_diff": "diff --git a/CHANGES.rst b/a/CHANGES.rst @@ -3,6 +3,9 @@ Version 2.3.2\n \n Unreleased\n \n+-   Session cookie sets ``Vary: Cookie`` header when it is accessed, modified, cleared,\n+    or refreshed.\n+\n \n Version 2.3.1\n -------------",
        "org_msg": "update changelog",
        "sim_msg": "Fix cookie auth parameter in docs\nCookie authentication uses the \"cookies\" parameter, not \"cookie\".\nSee atlassian/rest_client.py",
        "sim_diff": "diff --git a/docs/index.rst b/docs/index.rst @@ -133,19 +133,19 @@ Or reuse cookie file:\njira = Jira(\nurl='http://localhost:8080',\n- cookie=cookie_dict)\n+ cookies=cookie_dict)\nconfluence = Confluence(\nurl='http://localhost:8090',\n- cookie=cookie_dict)\n+ cookies=cookie_dict)\nbitbucket = Bitbucket(\nurl='http://localhost:7990',\n- cookie=cookie_dict)\n+ cookies=cookie_dict)\nservice_desk = ServiceDesk(\nurl='http://localhost:8080',\n- cookie=cookie_dict)\n+ cookies=cookie_dict)\nTo authenticate to the Atlassian Cloud APIs:\n"
    },
    {
        "org_diff": "diff --git a/src/flask/app.py b/a/src/flask/app.py @@ -1852,7 +1852,7 @@ def make_response(self, rv: ft.ResponseReturnValue) -> Response:\n \n         # extend existing headers with provided headers\n         if headers:\n-            rv.headers.update(headers)\n+            rv.headers.update(headers)  # type: ignore[arg-type]\n \n         return rv\n ",
        "org_msg": "fix mypy finding",
        "sim_msg": "added time.sleep as a digraph\nand maybe done something cool",
        "sim_diff": "diff --git a/flask_app.py b/flask_app.py @@ -107,6 +107,18 @@ def oeis():\nreturn render_template(\"oeis.html\")\n+@app.route(\"/update\", methods=(\"GET\", ))\n+def update():\n+ # Updates the server after a commit\n+\n+ if request.method == 'POST':\n+ repo = git.Repo('/home/Lyxal/mysite')\n+ origin = repo.remotes.origin\n+ origin.pull()\n+ return 'Updated PythonAnywhere successfully', 200\n+ else:\n+ return 'Wrong event type', 400\n+\ndef parse_file():\nimport os\n"
    },
    {
        "org_diff": "diff --git a/CHANGES.rst b/a/CHANGES.rst @@ -53,7 +53,7 @@ Unreleased\n Version 2.2.4\n -------------\n \n-Unreleased\n+Released 2023-04-25\n \n -   Update for compatibility with Werkzeug 2.3.\n ",
        "org_msg": "Merge branch '2.2.x'",
        "sim_msg": "Cutadapt 2.0",
        "sim_diff": "diff --git a/CHANGES.rst b/CHANGES.rst Changes\n=======\n-v2.0 (in development)\n----------------------\n+v2.0 (2019-03-06)\n+-----------------\n-This is a major new release with some backwards-incompatible changes.\n-Please review them and adjust your scripts if necessary.\n+This is a major new release with lots of bug fixes and new features, but\n+also some backwards-incompatible changes. These should hopefully\n+not affect too many users, but please make sure to review them and\n+possibly update your scripts!\nBackwards-incompatible changes\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n"
    },
    {
        "org_diff": "diff --git a/.github/workflows/tests.yaml b/a/.github/workflows/tests.yaml @@ -34,7 +34,7 @@ jobs:\n           - {name: '3.7', python: '3.7', os: ubuntu-latest, tox: py37}\n           - {name: 'PyPy', python: 'pypy-3.9', os: ubuntu-latest, tox: pypy39}\n           - {name: 'Pallets Minimum Versions', python: '3.11', os: ubuntu-latest, tox: py311-min}\n-          - {name: 'Pallets Development Versions', python: '3.7', os: ubuntu-latest, tox: py37-dev}\n+          - {name: 'Pallets Development Versions', python: '3.8', os: ubuntu-latest, tox: py38-dev}\n           - {name: Typing, python: '3.11', os: ubuntu-latest, tox: typing}\n     steps:\n       - uses: actions/checkout@ac593985615ec2ede58e132d2e21d2b1cbd6127c",
        "org_msg": "update dev env",
        "sim_msg": "ignore dictionary suggestions codespell",
        "sim_diff": "diff --git a/.github/workflows/test.yml b/.github/workflows/test.yml @@ -30,7 +30,7 @@ jobs:\n- run: pip install types-pytz types-requests types-termcolor types-tabulate types-PyYAML types-python-dateutil\n- run: bandit -r . || true\n- run: black --check .\n- - run: codespell --ignore-words-list=\"mape,ba,hist,Pres,COO,Navagation,Ser,Buil,Operatio\" --quiet-level=2 --skip=\".git\" --skip=\"*.yaml\" --skip=\"*.json\" --skip=\"*.html\"\n+ - run: codespell --ignore-words-list=\"mape\",\"ba\",\"hist\",\"Press\",\"COUP\",\"Navigation\",\"Set\",\"Build\",\"built\",\"Operation\" --quiet-level=2 --skip=\".git\" --skip=\"*.yaml\" --skip=\"*.json\" --skip=\"*.html\"\n- run: flake8 . --count --ignore=E203,W503 --max-line-length=122 --show-source --statistics\n- run: mypy --ignore-missing-imports .\n- run: shopt -s globstar && pyupgrade --py36-plus **/*.py\n"
    }
]