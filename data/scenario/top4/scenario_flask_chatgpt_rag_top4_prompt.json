[
    {
        "org_diff": "diff --git a/.pre-commit-config.yaml b/a/.pre-commit-config.yaml @@ -2,7 +2,7 @@ ci:\n   autoupdate_schedule: monthly\n repos:\n   - repo: https://github.com/astral-sh/ruff-pre-commit\n-    rev: v0.3.5\n+    rev: v0.4.3\n     hooks:\n       - id: ruff\n       - id: ruff-format",
        "sim_diff_0": "diff --git a/.pre-commit-config.yaml b/.pre-commit-config.yaml @@ -27,6 +27,7 @@ repos:\nhooks:\n- id: black\nlanguage_version: python3\n+ additional_dependencies: ['click==8.0.4']\n- repo: https://github.com/pre-commit/mirrors-isort\nrev: v4.3.21\nhooks:\n",
        "sim_msg_0": "add pre_commit dependency for pre_commit for black, click version compatability",
        "sim_diff_1": "diff --git a/.pre-commit-config.yaml b/.pre-commit-config.yaml @@ -6,11 +6,11 @@ repos:\nhooks:\n- id: isort\n- repo: https://github.com/psf/black\n- rev: 22.6.0\n+ rev: 22.10.0\nhooks:\n- id: black\n- repo: https://github.com/PyCQA/flake8\n- rev: 5.0.3\n+ rev: 5.0.4\nhooks:\n- id: flake8\n- repo: https://github.com/pre-commit/pre-commit-hooks\n",
        "sim_msg_1": "Update precommit dependencies",
        "sim_diff_2": "diff --git a/.pre-commit-config.yaml b/.pre-commit-config.yaml @@ -5,7 +5,7 @@ default_language_version:\nrepos:\n- repo: https://github.com/psf/black\n- rev: 21.12b0\n+ rev: 22.1.0\nhooks:\n- id: black\n@@ -39,6 +39,6 @@ repos:\n- --ignore-init-module-imports\n- repo: https://github.com/pre-commit/mirrors-mypy\n- rev: v0.930\n+ rev: v0.931\nhooks:\n- id: mypy\n",
        "sim_msg_2": "Update black and mypy versions in pre-commit yaml",
        "sim_diff_3": "diff --git a/.pre-commit-config.yaml b/.pre-commit-config.yaml @@ -8,10 +8,13 @@ repos:\nrev: v0.740\nhooks:\n- id: mypy\n+- repo: https://gitlab.com/pycqa/flake8\n+ rev: 3.7.9\n+ hooks:\n+ - id: flake8\n- repo: https://github.com/pre-commit/pre-commit-hooks\nrev: v2.4.0\nhooks:\n- - id: flake8\n- id: check-toml\n- id: check-yaml\n- repo: https://github.com/asottile/seed-isort-config\n",
        "sim_msg_3": "Switch to main flake8 repo to install pre-commit hook"
    },
    {
        "org_diff": "diff --git a/.pre-commit-config.yaml b/a/.pre-commit-config.yaml @@ -2,7 +2,7 @@ ci:\n   autoupdate_schedule: monthly\n repos:\n   - repo: https://github.com/astral-sh/ruff-pre-commit\n-    rev: v0.3.5\n+    rev: v0.4.3\n     hooks:\n       - id: ruff\n       - id: ruff-format",
        "sim_diff_0": "diff --git a/.pre-commit-config.yaml b/.pre-commit-config.yaml @@ -27,6 +27,7 @@ repos:\nhooks:\n- id: black\nlanguage_version: python3\n+ additional_dependencies: ['click==8.0.4']\n- repo: https://github.com/pre-commit/mirrors-isort\nrev: v4.3.21\nhooks:\n",
        "sim_msg_0": "add pre_commit dependency for pre_commit for black, click version compatability",
        "sim_diff_1": "diff --git a/.pre-commit-config.yaml b/.pre-commit-config.yaml @@ -6,11 +6,11 @@ repos:\nhooks:\n- id: isort\n- repo: https://github.com/psf/black\n- rev: 22.6.0\n+ rev: 22.10.0\nhooks:\n- id: black\n- repo: https://github.com/PyCQA/flake8\n- rev: 5.0.3\n+ rev: 5.0.4\nhooks:\n- id: flake8\n- repo: https://github.com/pre-commit/pre-commit-hooks\n",
        "sim_msg_1": "Update precommit dependencies",
        "sim_diff_2": "diff --git a/.pre-commit-config.yaml b/.pre-commit-config.yaml @@ -5,7 +5,7 @@ default_language_version:\nrepos:\n- repo: https://github.com/psf/black\n- rev: 21.12b0\n+ rev: 22.1.0\nhooks:\n- id: black\n@@ -39,6 +39,6 @@ repos:\n- --ignore-init-module-imports\n- repo: https://github.com/pre-commit/mirrors-mypy\n- rev: v0.930\n+ rev: v0.931\nhooks:\n- id: mypy\n",
        "sim_msg_2": "Update black and mypy versions in pre-commit yaml",
        "sim_diff_3": "diff --git a/.pre-commit-config.yaml b/.pre-commit-config.yaml @@ -8,10 +8,13 @@ repos:\nrev: v0.740\nhooks:\n- id: mypy\n+- repo: https://gitlab.com/pycqa/flake8\n+ rev: 3.7.9\n+ hooks:\n+ - id: flake8\n- repo: https://github.com/pre-commit/pre-commit-hooks\nrev: v2.4.0\nhooks:\n- - id: flake8\n- id: check-toml\n- id: check-yaml\n- repo: https://github.com/asottile/seed-isort-config\n",
        "sim_msg_3": "Switch to main flake8 repo to install pre-commit hook"
    },
    {
        "org_diff": "diff --git a/src/flask/helpers.py b/a/src/flask/helpers.py @@ -91,7 +91,7 @@ def decorator(*args: t.Any, **kwargs: t.Any) -> t.Any:\n             gen = generator_or_function(*args, **kwargs)  # type: ignore[operator]\n             return stream_with_context(gen)\n \n-        return update_wrapper(decorator, generator_or_function)  # type: ignore[arg-type]\n+        return update_wrapper(decorator, generator_or_function)  # type: ignore[arg-type, return-value]\n \n     def generator() -> t.Iterator[t.AnyStr | None]:\n         ctx = _cv_request.get(None)",
        "sim_diff_0": "diff --git a/src/flask/helpers.py b/src/flask/helpers.py @@ -819,33 +819,8 @@ def run_async(func: t.Callable[..., t.Coroutine]) -> t.Callable[..., t.Any]:\n)\n@wraps(func)\n- def outer(*args: t.Any, **kwargs: t.Any) -> t.Any:\n- \"\"\"This function grabs the current context for the inner function.\n+ def wrapper(*args: t.Any, **kwargs: t.Any) -> t.Any:\n+ return async_to_sync(func)(*args, **kwargs)\n- This is similar to the copy_current_xxx_context functions in the\n- ctx module, except it has an async inner.\n- \"\"\"\n- ctx = None\n-\n- if _request_ctx_stack.top is not None:\n- ctx = _request_ctx_stack.top.copy()\n-\n- @wraps(func)\n- async def inner(*a: t.Any, **k: t.Any) -> t.Any:\n- \"\"\"This restores the context before awaiting the func.\n-\n- This is required as the function must be awaited within the\n- context. Only calling ``func`` (as per the\n- ``copy_current_xxx_context`` functions) doesn't work as the\n- with block will close before the coroutine is awaited.\n- \"\"\"\n- if ctx is not None:\n- with ctx:\n- return await func(*a, **k)\n- else:\n- return await func(*a, **k)\n-\n- return async_to_sync(inner)(*args, **kwargs)\n-\n- outer._flask_sync_wrapper = True # type: ignore\n- return outer\n+ wrapper._flask_sync_wrapper = True # type: ignore\n+ return wrapper\n",
        "sim_msg_0": "Remove context copying from run_async function\nThis was required with the previous implementation of Werkzeug's\nlocals which didn't persist across threads. However as the current\nimplementation uses ContextVars which do persist the context copying\nis no longer required.",
        "sim_diff_1": "diff --git a/ghdata/server.py b/ghdata/server.py @@ -30,8 +30,8 @@ def flaskify(func):\nserializes them and spits them out\n\"\"\"\ndef generated_function(*args, **kwargs):\n- params = request.args.to_dict()\n- df = func(*args, **kwargs, **params)\n+ kwargs.update(request.args.to_dict())\n+ df = func(*args, **kwargs)\nreturn Response(response=serialize(df, orient=request.args.get('orient')),\nstatus=200,\nmimetype=\"application/json\")\n",
        "sim_msg_1": "Changed to single kwargs variable",
        "sim_diff_2": "diff --git a/ghdata/server.py b/ghdata/server.py @@ -30,7 +30,8 @@ def flaskify(func):\nserializes them and spits them out\n\"\"\"\ndef generated_function(*args, **kwargs):\n- df = func(*args, **kwargs)\n+ params = request.args.to_dict()\n+ df = func(*args, **kwargs, **params)\nreturn Response(response=serialize(df, orient=request.args.get('orient')),\nstatus=200,\nmimetype=\"application/json\")\n",
        "sim_msg_2": "Added abilty to pass params in API calls",
        "sim_diff_3": "diff --git a/Vyxal.py b/Vyxal.py @@ -116,13 +116,15 @@ class Generator:\nreturn Generator(map(lambda x: function([x])[-1], self.gen))\ndef _filter(self, function):\nindex = 0\n- while index < self.__len__():\n- obj = self[index]\n+ l = self.__len__()\n+ while True:\n+ if index == l:\n+ break\n+ obj = self.__getitem__(index)\nret = _safe_apply(function, [obj])[-1][-1]\nif ret:\nyield obj\nindex += 1\n- return self\ndef _reduce(self, function):\nimport copy\ndef ensure_singleton(function, left, right):\n",
        "sim_msg_3": "Okay so maybe I didn't fully fix filtering on generators\nsomething to do with length screwing up getting the generator properities"
    },
    {
        "org_diff": "diff --git a/src/flask/sessions.py b/a/src/flask/sessions.py @@ -365,10 +365,10 @@ def save_session(\n             return\n \n         expires = self.get_expiration_time(app, session)\n-        val = self.get_signing_serializer(app).dumps(dict(session))  # type: ignore\n+        val = self.get_signing_serializer(app).dumps(dict(session))  # type: ignore[union-attr]\n         response.set_cookie(\n             name,\n-            val,  # type: ignore\n+            val,\n             expires=expires,\n             httponly=httponly,\n             domain=domain,",
        "sim_diff_0": "diff --git a/flask_app.py b/flask_app.py @@ -11,7 +11,7 @@ THIS_FOLDER = os.path.dirname(os.path.abspath(__file__)) + \"/..\"\nsys.path.insert(1, THIS_FOLDER)\nos.system(\"rm -rf sessions\")\n-os.system(\"md sessions\")\n+os.system(\"mkdir sessions\")\nsessions = {}\nterminated = set()\n",
        "sim_msg_0": "once again fixed for unix",
        "sim_diff_1": "diff --git a/flask_app.py b/flask_app.py @@ -6,8 +6,8 @@ app = Flask(__name__)\nCORS(app)\nimport os\n-os.system(\"rm -rf sessions\")\n-os.system(\"mkdir sessions\")\n+os.system(\"rmdir /Q /S sessions\")\n+os.system(\"md sessions\")\nsessions = {}\nterminated = set()\n@@ -30,14 +30,14 @@ def execute():\nif session not in sessions:\nreturn {\"stdout\": \"\", \"stderr\": \"The session was invalid! You may need to reload your tab.\"}\n- os.system(f\"mkdir sessions/{session}\")\n+ os.system(f\"md sessions\\\\{session}\")\n- with open(f\"sessions/{session}/.stdin\", \"w\") as f:\n+ with open(f\"sessions/{session}/.stdin\", \"w\", encoding=\"utf-8\") as f:\nf.write(input_list)\n- with open(f\"sessions/{session}/.stdin\", \"r\") as x:\n- with open(f\"sessions/{session}/.stdout\", \"w\") as y:\n- with open(f\"sessions/{session}/.stderr\", \"w\") as z:\n+ with open(f\"sessions/{session}/.stdin\", \"r\", encoding=\"utf-8\") as x:\n+ with open(f\"sessions/{session}/.stdout\", \"w\", encoding=\"utf-8\") as y:\n+ with open(f\"sessions/{session}/.stderr\", \"w\", encoding=\"utf-8\") as z:\nmanager = multiprocessing.Manager()\nret = manager.dict()\n@@ -70,16 +70,16 @@ def execute():\noutput = ret[1]\ny.write(ret[1])\nz.write(ret[2])\n- with open(f\"sessions/{session}/.stdout\", \"r\") as x:\n- with open(f\"sessions/{session}/.stderr\", \"r\") as y:\n+ with open(f\"sessions/{session}/.stdout\", \"r\", encoding=\"utf-8\") as x:\n+ with open(f\"sessions/{session}/.stderr\", \"r\", encoding=\"utf-8\") as y:\nval = {\"stdout\": x.read(), \"stderr\": y.read()}\n- os.system(f\"rm -rf sessions/{session}\")\n+ os.system(f\"rmdir /Q /S sessions\\\\{session}\")\nreturn val\n@app.route(\"/kill\", methods=(\"POST\",))\ndef kill():\n- session = int(request.form[\"session\"])\n+ session = request.form[\"session\"]\nif sessions.get(session) is None: return \"\"\nsessions[session].kill()\nterminated.add(session)\n",
        "sim_msg_1": "thank you HN for the online template.",
        "sim_diff_2": "diff --git a/flask_app.py b/flask_app.py @@ -6,7 +6,7 @@ app = Flask(__name__)\nCORS(app)\nimport os\n-os.system(\"rmdir /Q /S sessions\")\n+os.system(\"rm -rf sessions\")\nos.system(\"md sessions\")\nsessions = {}\n@@ -30,7 +30,8 @@ def execute():\nif session not in sessions:\nreturn {\"stdout\": \"\", \"stderr\": \"The session was invalid! You may need to reload your tab.\"}\n- os.system(f\"md sessions\\\\{session}\")\n+ os.system(f\"rm -rf sessions/{session}\")\n+ os.system(f\"mkdir sessions/{session}\")\nwith open(f\"sessions/{session}/.stdin\", \"w\", encoding=\"utf-8\") as f:\nf.write(input_list)\n@@ -73,7 +74,7 @@ def execute():\nwith open(f\"sessions/{session}/.stdout\", \"r\", encoding=\"utf-8\") as x:\nwith open(f\"sessions/{session}/.stderr\", \"r\", encoding=\"utf-8\") as y:\nval = {\"stdout\": x.read(), \"stderr\": y.read()}\n- os.system(f\"rmdir /Q /S sessions\\\\{session}\")\n+ os.system(f\"rm -rf sessions/{session}\")\nreturn val\n",
        "sim_msg_2": "I forgot to make it work for linux/unix",
        "sim_diff_3": "diff --git a/flask_app.py b/flask_app.py @@ -60,9 +60,11 @@ def execute():\nwith open(f\"sessions/{session}/.stdin\", \"w\", encoding=\"utf-8\") as f:\nf.write(input_list)\n- with open(f\"sessions/{session}/.stdin\", \"r\", encoding=\"utf-8\") as x, open(\n- f\"sessions/{session}/.stdout\", \"w\", encoding=\"utf-8\"\n- ) as y, open(f\"sessions/{session}/.stderr\", \"w\", encoding=\"utf-8\") as z:\n+ with (\n+ open(f\"sessions/{session}/.stdin\", \"r\", encoding=\"utf-8\") as x,\n+ open(f\"sessions/{session}/.stdout\", \"w\", encoding=\"utf-8\") as y,\n+ open(f\"sessions/{session}/.stderr\", \"w\", encoding=\"utf-8\") as z,\n+ ):\nmanager = multiprocessing.Manager()\nret = manager.dict()\n",
        "sim_msg_3": "Format withs to look nicer"
    },
    {
        "org_diff": "diff --git a/src/flask/wrappers.py b/a/src/flask/wrappers.py @@ -71,7 +71,7 @@ def endpoint(self) -> str | None:\n         reconstruct the same URL or a modified URL.\n         \"\"\"\n         if self.url_rule is not None:\n-            return self.url_rule.endpoint\n+            return self.url_rule.endpoint  # type: ignore[no-any-return]\n \n         return None\n ",
        "sim_diff_0": "diff --git a/flask/blueprints.py b/flask/blueprints.py :license: BSD, see LICENSE for more details.\n\"\"\"\n+import re\nfrom functools import update_wrapper\nfrom .helpers import _PackageBoundObject, _endpoint_from_view_func\n@@ -67,6 +68,7 @@ class BlueprintSetupState(object):\n\"\"\"\nif self.url_prefix:\nrule = self.url_prefix + rule\n+ rule = re.sub('/+', '/', rule)\noptions.setdefault('subdomain', self.subdomain)\nif endpoint is None:\nendpoint = _endpoint_from_view_func(view_func)\n",
        "sim_msg_0": "Add re.sub for blueprint add_url_rule handler, prevent '/a//b/'(blueprint.url_prefix='/a/' and the route is '/b/') happened.",
        "sim_diff_1": "diff --git a/flask/helpers.py b/flask/helpers.py @@ -58,7 +58,7 @@ def get_debug_flag(default=None):\nval = os.environ.get('FLASK_DEBUG')\nif not val:\nreturn default\n- return val not in ('0', 'false', 'no')\n+ return val.lower() not in ('0', 'false', 'no')\ndef _endpoint_from_view_func(view_func):\n",
        "sim_msg_1": "Disable debug when FLASK_DEBUG=False\nConvert FLASK_DEBUG envvar to lower before test if in tuple",
        "sim_diff_2": "diff --git a/flask_app.py b/flask_app.py @@ -40,3 +40,7 @@ def index():\nreturn render_template('index.html', code=code, header=header, footer=footer, flags=flags, output=output, inputs=input_list, errors=ret[2])\nreturn render_template('index.html', code=\"\", flags=\"\", output=\"\", header=\"\", footer=\"\", inputs=\"\", errors=\"\")\n+\n+@app.route(\"/ash\")\n+def ash():\n+ return render_template(\"ash.html\")\n\\ No newline at end of file\n",
        "sim_msg_2": "added ash to the online interpreter",
        "sim_diff_3": "diff --git a/flask/ctx.py b/flask/ctx.py @@ -282,7 +282,11 @@ class RequestContext(object):\nif request is None:\nrequest = app.request_class(environ)\nself.request = request\n+ self.url_adapter = None\n+ try:\nself.url_adapter = app.create_url_adapter(self.request)\n+ except HTTPException as e:\n+ self.request.routing_exception = e\nself.flashes = None\nself.session = session\n@@ -305,6 +309,7 @@ class RequestContext(object):\n# functions.\nself._after_request_functions = []\n+ if self.url_adapter is not None:\nself.match_request()\ndef _get_g(self):\n",
        "sim_msg_3": "Handle errors during create_url_adapter\nIf create_url_adapter raises (which it can if werkzeug cannot bind\nenvironment, for example on non-ASCII Host header), we handle it as\nother routing exceptions rather than raising through.\nref"
    },
    {
        "org_diff": "diff --git a/examples/javascript/pyproject.toml b/a/examples/javascript/pyproject.toml @@ -8,7 +8,7 @@ maintainers = [{name = \"Pallets\", email = \"contact@palletsprojects.com\"}]\n dependencies = [\"flask\"]\n \n [project.urls]\n-Documentation = \"https://flask.palletsprojects.com/patterns/jquery/\"\n+Documentation = \"https://flask.palletsprojects.com/patterns/javascript/\"\n \n [project.optional-dependencies]\n test = [\"pytest\"]",
        "sim_diff_0": "diff --git a/pyproject.toml b/pyproject.toml @@ -67,6 +67,8 @@ pytest-github-actions-annotate-failures = {version = \"*\", optional = true}\n[tool.poetry.dev-dependencies]\n# checks and make tools\n+pre-commit = \"^2.15.0\"\n+\ninvoke = \"*\"\nflake8 = \"*\"\nmypy = \"*\"\n@@ -91,7 +93,6 @@ pydata-sphinx-theme = \"*\"\nnbsphinx = \"*\"\npandoc = \"*\"\nrecommonmark = \"*\"\n-pre-commit = \"^2.15.0\"\n[tool.poetry.extras] # extras\n",
        "sim_msg_0": "random commit to trigger CI",
        "sim_diff_1": "diff --git a/pyproject.toml b/pyproject.toml @@ -59,7 +59,7 @@ float_to_top=true\npython_version = \"3.9\"\nfollow_imports = \"silent\"\nfiles = [\"reactivex\"]\n-exclude = [\"reactivex/core/operators\"]\n+exclude = [\"reactivex/operators/_\\\\w.*\\\\.py$\"]\n[tool.pytest.ini_options]\ntestpaths = [\"tests\"]\n",
        "sim_msg_1": "Exclude operators for mypy",
        "sim_diff_2": "diff --git a/pyproject.toml b/pyproject.toml @@ -40,6 +40,9 @@ sphinx-book-theme = \"^0.3.3\"\n[tool.poetry.group.dev.dependencies]\npre-commit = \"^2.20.0\"\n+types-backports = \"^0.1.3\"\n+mypy = \"^0.990\"\n+types-freezegun = \"^1.1.10\"\n[tool.pytest.ini_options]\npythonpath = [\"src\"]\n",
        "sim_msg_2": "Added mypy and type stubs to dev group",
        "sim_diff_3": "diff --git a/pyproject.toml b/pyproject.toml @@ -33,11 +33,10 @@ classifiers = [\n[tool.poetry.dependencies]\npython = \"^3.5\"\n-pycairo = \"^1.18\"\n+pycairo = \"^1.16\"\nPyGObject = \"^3.30\"\ngaphas = \"^1.0.0\"\n\"zope.component\" = \"^4.5\"\n-setuptools = \"^41.0\"\n[tool.poetry.dev-dependencies]\npytest = \"^4.0\"\n",
        "sim_msg_3": "Relax pycairo and setuptools version requirements for Flatpak builds"
    },
    {
        "org_diff": "diff --git a/examples/javascript/pyproject.toml b/a/examples/javascript/pyproject.toml @@ -8,7 +8,7 @@ maintainers = [{name = \"Pallets\", email = \"contact@palletsprojects.com\"}]\n dependencies = [\"flask\"]\n \n [project.urls]\n-Documentation = \"https://flask.palletsprojects.com/patterns/jquery/\"\n+Documentation = \"https://flask.palletsprojects.com/patterns/javascript/\"\n \n [project.optional-dependencies]\n test = [\"pytest\"]",
        "sim_diff_0": "diff --git a/pyproject.toml b/pyproject.toml @@ -67,6 +67,8 @@ pytest-github-actions-annotate-failures = {version = \"*\", optional = true}\n[tool.poetry.dev-dependencies]\n# checks and make tools\n+pre-commit = \"^2.15.0\"\n+\ninvoke = \"*\"\nflake8 = \"*\"\nmypy = \"*\"\n@@ -91,7 +93,6 @@ pydata-sphinx-theme = \"*\"\nnbsphinx = \"*\"\npandoc = \"*\"\nrecommonmark = \"*\"\n-pre-commit = \"^2.15.0\"\n[tool.poetry.extras] # extras\n",
        "sim_msg_0": "random commit to trigger CI",
        "sim_diff_1": "diff --git a/pyproject.toml b/pyproject.toml @@ -59,7 +59,7 @@ float_to_top=true\npython_version = \"3.9\"\nfollow_imports = \"silent\"\nfiles = [\"reactivex\"]\n-exclude = [\"reactivex/core/operators\"]\n+exclude = [\"reactivex/operators/_\\\\w.*\\\\.py$\"]\n[tool.pytest.ini_options]\ntestpaths = [\"tests\"]\n",
        "sim_msg_1": "Exclude operators for mypy",
        "sim_diff_2": "diff --git a/pyproject.toml b/pyproject.toml @@ -40,6 +40,9 @@ sphinx-book-theme = \"^0.3.3\"\n[tool.poetry.group.dev.dependencies]\npre-commit = \"^2.20.0\"\n+types-backports = \"^0.1.3\"\n+mypy = \"^0.990\"\n+types-freezegun = \"^1.1.10\"\n[tool.pytest.ini_options]\npythonpath = [\"src\"]\n",
        "sim_msg_2": "Added mypy and type stubs to dev group",
        "sim_diff_3": "diff --git a/pyproject.toml b/pyproject.toml @@ -33,11 +33,10 @@ classifiers = [\n[tool.poetry.dependencies]\npython = \"^3.5\"\n-pycairo = \"^1.18\"\n+pycairo = \"^1.16\"\nPyGObject = \"^3.30\"\ngaphas = \"^1.0.0\"\n\"zope.component\" = \"^4.5\"\n-setuptools = \"^41.0\"\n[tool.poetry.dev-dependencies]\npytest = \"^4.0\"\n",
        "sim_msg_3": "Relax pycairo and setuptools version requirements for Flatpak builds"
    },
    {
        "org_diff": "diff --git a/src/flask/sessions.py b/a/src/flask/sessions.py @@ -368,7 +368,7 @@ def save_session(\n         val = self.get_signing_serializer(app).dumps(dict(session))  # type: ignore\n         response.set_cookie(\n             name,\n-            val,  # type: ignore\n+            val,\n             expires=expires,\n             httponly=httponly,\n             domain=domain,",
        "sim_diff_0": "diff --git a/flask_app.py b/flask_app.py @@ -11,7 +11,7 @@ THIS_FOLDER = os.path.dirname(os.path.abspath(__file__)) + \"/..\"\nsys.path.insert(1, THIS_FOLDER)\nos.system(\"rm -rf sessions\")\n-os.system(\"md sessions\")\n+os.system(\"mkdir sessions\")\nsessions = {}\nterminated = set()\n",
        "sim_msg_0": "once again fixed for unix",
        "sim_diff_1": "diff --git a/flask_app.py b/flask_app.py @@ -6,7 +6,7 @@ app = Flask(__name__)\nCORS(app)\nimport os\n-os.system(\"rmdir /Q /S sessions\")\n+os.system(\"rm -rf sessions\")\nos.system(\"md sessions\")\nsessions = {}\n@@ -30,7 +30,8 @@ def execute():\nif session not in sessions:\nreturn {\"stdout\": \"\", \"stderr\": \"The session was invalid! You may need to reload your tab.\"}\n- os.system(f\"md sessions\\\\{session}\")\n+ os.system(f\"rm -rf sessions/{session}\")\n+ os.system(f\"mkdir sessions/{session}\")\nwith open(f\"sessions/{session}/.stdin\", \"w\", encoding=\"utf-8\") as f:\nf.write(input_list)\n@@ -73,7 +74,7 @@ def execute():\nwith open(f\"sessions/{session}/.stdout\", \"r\", encoding=\"utf-8\") as x:\nwith open(f\"sessions/{session}/.stderr\", \"r\", encoding=\"utf-8\") as y:\nval = {\"stdout\": x.read(), \"stderr\": y.read()}\n- os.system(f\"rmdir /Q /S sessions\\\\{session}\")\n+ os.system(f\"rm -rf sessions/{session}\")\nreturn val\n",
        "sim_msg_1": "I forgot to make it work for linux/unix",
        "sim_diff_2": "diff --git a/flask_app.py b/flask_app.py @@ -6,8 +6,8 @@ app = Flask(__name__)\nCORS(app)\nimport os\n-os.system(\"rm -rf sessions\")\n-os.system(\"mkdir sessions\")\n+os.system(\"rmdir /Q /S sessions\")\n+os.system(\"md sessions\")\nsessions = {}\nterminated = set()\n@@ -30,14 +30,14 @@ def execute():\nif session not in sessions:\nreturn {\"stdout\": \"\", \"stderr\": \"The session was invalid! You may need to reload your tab.\"}\n- os.system(f\"mkdir sessions/{session}\")\n+ os.system(f\"md sessions\\\\{session}\")\n- with open(f\"sessions/{session}/.stdin\", \"w\") as f:\n+ with open(f\"sessions/{session}/.stdin\", \"w\", encoding=\"utf-8\") as f:\nf.write(input_list)\n- with open(f\"sessions/{session}/.stdin\", \"r\") as x:\n- with open(f\"sessions/{session}/.stdout\", \"w\") as y:\n- with open(f\"sessions/{session}/.stderr\", \"w\") as z:\n+ with open(f\"sessions/{session}/.stdin\", \"r\", encoding=\"utf-8\") as x:\n+ with open(f\"sessions/{session}/.stdout\", \"w\", encoding=\"utf-8\") as y:\n+ with open(f\"sessions/{session}/.stderr\", \"w\", encoding=\"utf-8\") as z:\nmanager = multiprocessing.Manager()\nret = manager.dict()\n@@ -70,16 +70,16 @@ def execute():\noutput = ret[1]\ny.write(ret[1])\nz.write(ret[2])\n- with open(f\"sessions/{session}/.stdout\", \"r\") as x:\n- with open(f\"sessions/{session}/.stderr\", \"r\") as y:\n+ with open(f\"sessions/{session}/.stdout\", \"r\", encoding=\"utf-8\") as x:\n+ with open(f\"sessions/{session}/.stderr\", \"r\", encoding=\"utf-8\") as y:\nval = {\"stdout\": x.read(), \"stderr\": y.read()}\n- os.system(f\"rm -rf sessions/{session}\")\n+ os.system(f\"rmdir /Q /S sessions\\\\{session}\")\nreturn val\n@app.route(\"/kill\", methods=(\"POST\",))\ndef kill():\n- session = int(request.form[\"session\"])\n+ session = request.form[\"session\"]\nif sessions.get(session) is None: return \"\"\nsessions[session].kill()\nterminated.add(session)\n",
        "sim_msg_2": "thank you HN for the online template.",
        "sim_diff_3": "diff --git a/flask_app.py b/flask_app.py @@ -6,6 +6,10 @@ app = Flask(__name__)\nCORS(app)\nimport os\n+\n+THIS_FOLDER = os.path.dirname(os.path.abspath(__file__)) + \"/..\"\n+sys.path.insert(1, THIS_FOLDER)\n+\nos.system(\"rm -rf sessions\")\nos.system(\"md sessions\")\n",
        "sim_msg_3": "I forgot that pythonanywhere gets fussy about file locations"
    },
    {
        "org_diff": "diff --git a/.github/dependabot.yml b/a/.github/dependabot.yml @@ -4,12 +4,6 @@ updates:\n     directory: /\n     schedule:\n       interval: monthly\n-    ignore:\n-      # slsa depends on upload/download v3\n-      - dependency-name: actions/upload-artifact\n-        versions: '>= 4'\n-      - dependency-name: actions/download-artifact\n-        versions: '>= 4'\n     groups:\n       github-actions:\n         patterns:",
        "sim_diff_0": "diff --git a/.github/dependabot.yml b/.github/dependabot.yml @@ -6,3 +6,9 @@ updates:\ninterval: daily\ntime: \"11:00\"\nopen-pull-requests-limit: 10\n+ - package-ecosystem: github-actions\n+ directory: \"/\"\n+ schedule:\n+ interval: daily\n+ time: \"11:00\"\n+ open-pull-requests-limit: 10\n",
        "sim_msg_0": "ci: add github-actions to dependabot",
        "sim_diff_1": "diff --git a/.github/dependabot.yml b/.github/dependabot.yml @@ -5,3 +5,39 @@ updates:\nschedule:\ninterval: daily\nopen-pull-requests-limit: 10\n+\n+ - package-ecosystem: gomod\n+ directory: \"/tools/src/yq/\"\n+ schedule:\n+ interval: daily\n+ open-pull-requests-limit: 10\n+\n+ - package-ecosystem: gomod\n+ directory: \"/tools/src/chart-doc-gen\"\n+ schedule:\n+ interval: daily\n+ open-pull-requests-limit: 10\n+\n+ - package-ecosystem: gomod\n+ directory: \"/tools/src/crane\"\n+ schedule:\n+ interval: daily\n+ open-pull-requests-limit: 10\n+\n+ - package-ecosystem: gomod\n+ directory: \"/tools/src/ct\"\n+ schedule:\n+ interval: daily\n+ open-pull-requests-limit: 10\n+\n+ - package-ecosystem: gomod\n+ directory: \"/tools/src/golangci-lint\"\n+ schedule:\n+ interval: daily\n+ open-pull-requests-limit: 10\n+\n+ - package-ecosystem: gomod\n+ directory: \"/tools/src/ocibuild\"\n+ schedule:\n+ interval: daily\n+ open-pull-requests-limit: 10\n",
        "sim_msg_1": "deps : adding all go.mod locations to dependabots monitoring",
        "sim_diff_2": "diff --git a/.github/dependabot.yml b/.github/dependabot.yml version: 2\nupdates:\n-\n- package-ecosystem: \"github-actions\"\ndirectory: \"/\"\nschedule:\ninterval: \"daily\"\n+ labels: [\"skip-changelog\"]\n- package-ecosystem: \"pip\"\ndirectory: \"/\"\nschedule:\ninterval: \"daily\"\n+ labels: [\"skip-changelog\"]\n",
        "sim_msg_2": "Add skip-changelog label to dependabot PRs",
        "sim_diff_3": "diff --git a/.github/dependabot.yml b/.github/dependabot.yml @@ -15,3 +15,8 @@ updates:\nschedule:\ninterval: \"daily\"\nopen-pull-requests-limit: 1\n+ - package-ecosystem: \"gradle\"\n+ directory: \"/hail\"\n+ schedule:\n+ interval: \"daily\"\n+ open-pull-requests-limit: 1\n",
        "sim_msg_3": "[dependabot] also monitor hail/build.gradle"
    },
    {
        "org_diff": "diff --git a/tox.ini b/a/tox.ini @@ -32,7 +32,7 @@ commands = mypy\n \n [testenv:docs]\n deps = -r requirements/docs.txt\n-commands = sphinx-build -W -b dirhtml docs docs/_build/dirhtml\n+commands = sphinx-build -E -W -b dirhtml docs docs/_build/dirhtml\n \n [testenv:update-requirements]\n deps =",
        "sim_diff_0": "diff --git a/tox.ini b/tox.ini @@ -21,11 +21,13 @@ changedir = doc\ndeps =\nsphinx\nsphinx_issues\n+skip_install = true\ncommands = sphinx-build -W -b html -d {envtmpdir}/doctrees . {envtmpdir}/html\n[testenv:flake8]\nbasepython = python3.6\ndeps = flake8\n+skip_install = true\ncommands = flake8 src/ tests/\n[testenv:mypy]\n",
        "sim_msg_0": "Use skip_install where appropriate",
        "sim_diff_1": "diff --git a/tox.ini b/tox.ini @@ -29,7 +29,7 @@ commands = sphinx-build -W -b html -d {envtmpdir}/doctrees . {envtmpdir}/html\nbasepython = python3.7\ndeps = flake8\nskip_install = true\n-commands = flake8 src/ tests/\n+commands = flake8 src/ tests/ setup.py\n[testenv:mypy]\nbasepython = python3.7\n",
        "sim_msg_1": "Run flake8 on setup.py",
        "sim_diff_2": "diff --git a/tox.ini b/tox.ini @@ -50,6 +50,17 @@ commands =\nmypy --ignore-missing-imports --check-untyped-defs --no-strict-optional src\n+[testenv:reformat]\n+description = reformats the code using black and isort\n+deps =\n+ black\n+ isort\n+skip_install = true\n+commands =\n+ isort --recursive --project poliastro --section-default THIRDPARTY src setup.py\n+ black src setup.py\n+\n+\n[testenv:docs]\ndescription = invoke sphinx-build to build the HTML docs\nextras = docs\n",
        "sim_msg_2": "Add tox environment to reformat code",
        "sim_diff_3": "diff --git a/tox.ini b/tox.ini @@ -16,7 +16,7 @@ commands =\ncoverage xml\n[testenv:docs]\n-basepython = python3.6\n+basepython = python3.7\nchangedir = doc\ndeps =\nsphinx\n@@ -24,13 +24,13 @@ deps =\ncommands = sphinx-build -W -b html -d {envtmpdir}/doctrees . {envtmpdir}/html\n[testenv:flake8]\n-basepython = python3.6\n+basepython = python3.7\ndeps = flake8\nskip_install = true\ncommands = flake8 src/ tests/\n[testenv:mypy]\n-basepython = python3.6\n+basepython = python3.7\ndeps = mypy\ncommands = mypy src/\n",
        "sim_msg_3": "Use Python 3.7 in tox"
    },
    {
        "org_diff": "diff --git a/README.md b/a/README.md @@ -16,18 +16,6 @@ community that make adding new functionality easy.\n [Jinja]: https://jinja.palletsprojects.com/\n \n \n-## Installing\n-\n-Install and update from [PyPI][] using an installer such as [pip][]:\n-\n-```\n-$ pip install -U Flask\n-```\n-\n-[PyPI]: https://pypi.org/project/Flask/\n-[pip]: https://pip.pypa.io/en/stable/getting-started/\n-\n-\n ## A Simple Example\n \n ```python\n@@ -47,14 +35,6 @@ $ flask run\n ```\n \n \n-## Contributing\n-\n-For guidance on setting up a development environment and how to make a\n-contribution to Flask, see the [contributing guidelines][].\n-\n-[contributing guidelines]: https://github.com/pallets/flask/blob/main/CONTRIBUTING.rst\n-\n-\n ## Donate\n \n The Pallets organization develops and supports Flask and the libraries",
        "sim_diff_0": "diff --git a/setup-osp.sh b/setup-osp.sh @@ -50,8 +50,7 @@ sudo chown -R www-data:www-data images\n# Setup Python\nsudo apt-get install python2.7 python-pip gunicorn uwsgi-plugin-python -y\n-sudo pip install flask flask-sqlalchemy flask-security flask-socketio gevent flask-uploads psutil requests flask-migrate\n-sudo pip install --upgrade git+ https://github.com/mattupstate/flask-security.git@develop\n+sudo pip install -r requirements.txt\nsudo mkdir /opt/osp/\ncd $cwd/flask-nginx-rtmp-mgmt\n",
        "sim_msg_0": "Changed Setup Script to use Requirements.txt for Python Pip installs",
        "sim_diff_1": "diff --git a/setup/requirements.txt b/setup/requirements.txt @@ -9,7 +9,7 @@ Flask-Migrate==2.5.2\nFlask-Principal==0.4.0\nflask-restplus==0.12.1\nFlask-Script==2.0.6\n-Flask-Security-Too==3.4.5\n+Flask-Security-Too==4.0.0\nFlask-SocketIO==4.3.0\nFlask-SQLAlchemy==2.4.0\nFlask-Uploads==0.2.1\n@@ -49,3 +49,4 @@ flask-cors==3.0.8\nPillow==7.1.2\npilkit==2.0\nauthlib==0.14.1\n+bleach==3.3.0\n\\ No newline at end of file\n",
        "sim_msg_1": "Added Bleach\nUpgrade Flask-Security-Too to 4.0.0",
        "sim_diff_2": "diff --git a/README.rst b/README.rst @@ -72,10 +72,7 @@ Links\n* Releases: https://pypi.org/project/Flask/\n* Code: https://github.com/pallets/flask\n* Issue tracker: https://github.com/pallets/flask/issues\n-* Test status:\n-\n- * Linux, Mac: https://travis-ci.org/pallets/flask\n- * Windows: https://ci.appveyor.com/project/pallets/flask\n+* Test status: https://dev.azure.com/pallets/pallets/_build?definitionId=2\n* Test coverage: https://codecov.io/gh/pallets/flask\n",
        "sim_msg_2": "add Azure Pipelines to readme",
        "sim_diff_3": "diff --git a/setup/requirements.txt b/setup/requirements.txt @@ -10,7 +10,7 @@ Flask-Principal==0.4.0\nflask-restplus==0.12.1\nFlask-Script==2.0.6\nFlask-Security-Too==3.3.3\n-Flask-SocketIO==4.2.1\n+Flask-SocketIO==4.3.0\nFlask-SQLAlchemy==2.4.0\nFlask-Uploads==0.2.1\nFlask-WTF==0.14.2\n@@ -27,8 +27,8 @@ psutil==5.6.6\nPyMySQL==0.9.3\npython-dateutil==2.8.0\npython-editor==1.0.4\n-python-engineio==3.11.2\n-python-socketio==4.4.0\n+python-engineio==3.13.0\n+python-socketio==4.6.0\npytz==2019.1\nsmmap2==2.0.5\nspeaklater==1.3\n",
        "sim_msg_3": "Updated Flask-Socketio and dependencies"
    },
    {
        "org_diff": "diff --git a/CHANGES.rst b/a/CHANGES.rst @@ -1,7 +1,7 @@\n Version 3.0.3\n -------------\n \n-Unreleased\n+Released 2024-04-07\n \n -   The default ``hashlib.sha1`` may not be available in FIPS builds. Don't\n     access it at import time so the developer has time to change the default.",
        "sim_diff_0": "diff --git a/requirements/prod.txt b/requirements/prod.txt @@ -268,9 +268,9 @@ cffi==1.9.1 \\\n--hash=sha256:86c68a3f8246495962446c6f96f6a27f182b91208187b68f1e87ec3dfd29fa32 \\\n--hash=sha256:e5ef800ef8ef9ee05ae9a5b7d7d9cf7d6c936b32e312e54823faca3034ee16ab \\\n--hash=sha256:563e0bd53fda03c151573217b3a49b3abad8813de9dd0632e10090f6190fdaf8\n-kombu==3.0.35 \\\n- --hash=sha256:2c59a5e087d5895675cdb4d6a38a0aa147f0411366e68330a76e480ba3b25727 \\\n- --hash=sha256:22ab336a17962717a5d9470547e5508d4bcf1b6ec10cd9486868daf4e5edb727\n+kombu==3.0.37 \\\n+ --hash=sha256:7ceab743e3e974f3e5736082e8cc514c009e254e646d6167342e0e192aee81a6 \\\n+ --hash=sha256:e064a00c66b4d1058cd2b0523fb8d98c82c18450244177b6c0f7913016642650\ndjango-jinja==2.2.2 \\\n--hash=sha256:f2456d767dfbe4123e42b96015ea4b119838e2d88457999bd574cf7c634a2b25\npuente==0.5.0 \\\n",
        "sim_msg_0": "Upgrade Kombu to 3.0.37.",
        "sim_diff_1": "diff --git a/requirements/default.txt b/requirements/default.txt backports.csv==1.0.5 \\\n--hash=sha256:d3b0cefaaca92be3d2d4ceec140827cae1d871da7fff5db70697d72328357d65 \\\n--hash=sha256:8c421385cbc6042ba90c68c871c5afc13672acaf91e1508546d6cda6725ebfc6\n-bleach==3.1.2 \\\n- --hash=sha256:2ffa40dfa80b141ff58eee538bce0d2a09c7d456018d00f7a2cb0ebf967c524d \\\n- --hash=sha256:f0b1ee0315062e60afa6b7cc39b1c3718b591e1d552a8841044dc49a68465659\n+bleach==3.1.4 \\\n+ --hash=sha256:cc8da25076a1fe56c3ac63671e2194458e0c4d9c7becfd52ca251650d517903c \\\n+ --hash=sha256:e78e426105ac07026ba098f04de8abe9b6e3e98b5befbf89b51a5ef0a4292b03\ncaighdean==0.0.4 \\\n--hash=sha256:a0a05b39f8e185a3698a4fb67dd2b388e7fb01b28f7f53c041e0857680655d4e \\\n--hash=sha256:0aff328adac0faad0e42584a573512f4fc4d06a7d251e71bb9098f08c40456b6\n",
        "sim_msg_1": "Update to bleach 3.1.4",
        "sim_diff_2": "diff --git a/requirements/prod.txt b/requirements/prod.txt @@ -355,3 +355,7 @@ jmespath==0.9.3 \\\ns3transfer==0.1.10 \\\n--hash=sha256:bc52f38637f37572ae180c08a2dd87a4825b46713797633aab6e1a42d6b2b8ff \\\n--hash=sha256:ba1a9104939b7c0331dc4dd234d79afeed8b66edce77bbeeecd4f56de74a0fc1\n+python-dateutil==2.6.0 \\\n+ --hash=sha256:62a2f8df3d66f878373fd0072eacf4ee52194ba302e00082828e0d263b0418d2 \\\n+ --hash=sha256:3acbef017340600e9ff8f2994d8f7afd6eacb295383f286466a6df3961e486f0 \\\n+ --hash=sha256:537bf2a8f8ce6f6862ad705cd68f9e405c0b5db014aa40fa29eab4335d4b1716\n",
        "sim_msg_2": "Add missing boto3 dependency.",
        "sim_diff_3": "diff --git a/poetry.lock b/poetry.lock @@ -5140,6 +5140,7 @@ isodate = []\nisort = [\n{file = \"isort-5.10.1-py3-none-any.whl\", hash = \"sha256:6f62d78e2f89b4500b080fe3a81690850cd254227f27f75c3a0c491a1f351ba7\"},\n{file = \"isort-5.10.1.tar.gz\", hash = \"sha256:e8443a5e7a020e9d7f97f1d7d9cd17c88bcb3bc7e218bf9cf5095fe550be2951\"},\n+]\njedi-language-server = [\n{file = \"jedi_language_server-0.40.0-py3-none-any.whl\", hash = \"sha256:53e590400b5cd2f6e363e77a4d824b1883798994b731cb0b4370d103748d30e2\"},\n{file = \"jedi_language_server-0.40.0.tar.gz\", hash = \"sha256:bacbae2930b6a8a0f1f284c211672fceec94b4808b0415d1c3352fa4b1ac5ad6\"},\n",
        "sim_msg_3": "issue with poetry.lock after merge"
    },
    {
        "org_diff": "diff --git a/CHANGES.rst b/a/CHANGES.rst @@ -1,7 +1,7 @@\n Version 3.0.3\n -------------\n \n-Unreleased\n+Released 2024-04-07\n \n -   The default ``hashlib.sha1`` may not be available in FIPS builds. Don't\n     access it at import time so the developer has time to change the default.",
        "sim_diff_0": "diff --git a/requirements/prod.txt b/requirements/prod.txt @@ -268,9 +268,9 @@ cffi==1.9.1 \\\n--hash=sha256:86c68a3f8246495962446c6f96f6a27f182b91208187b68f1e87ec3dfd29fa32 \\\n--hash=sha256:e5ef800ef8ef9ee05ae9a5b7d7d9cf7d6c936b32e312e54823faca3034ee16ab \\\n--hash=sha256:563e0bd53fda03c151573217b3a49b3abad8813de9dd0632e10090f6190fdaf8\n-kombu==3.0.35 \\\n- --hash=sha256:2c59a5e087d5895675cdb4d6a38a0aa147f0411366e68330a76e480ba3b25727 \\\n- --hash=sha256:22ab336a17962717a5d9470547e5508d4bcf1b6ec10cd9486868daf4e5edb727\n+kombu==3.0.37 \\\n+ --hash=sha256:7ceab743e3e974f3e5736082e8cc514c009e254e646d6167342e0e192aee81a6 \\\n+ --hash=sha256:e064a00c66b4d1058cd2b0523fb8d98c82c18450244177b6c0f7913016642650\ndjango-jinja==2.2.2 \\\n--hash=sha256:f2456d767dfbe4123e42b96015ea4b119838e2d88457999bd574cf7c634a2b25\npuente==0.5.0 \\\n",
        "sim_msg_0": "Upgrade Kombu to 3.0.37.",
        "sim_diff_1": "diff --git a/requirements/default.txt b/requirements/default.txt backports.csv==1.0.5 \\\n--hash=sha256:d3b0cefaaca92be3d2d4ceec140827cae1d871da7fff5db70697d72328357d65 \\\n--hash=sha256:8c421385cbc6042ba90c68c871c5afc13672acaf91e1508546d6cda6725ebfc6\n-bleach==3.1.2 \\\n- --hash=sha256:2ffa40dfa80b141ff58eee538bce0d2a09c7d456018d00f7a2cb0ebf967c524d \\\n- --hash=sha256:f0b1ee0315062e60afa6b7cc39b1c3718b591e1d552a8841044dc49a68465659\n+bleach==3.1.4 \\\n+ --hash=sha256:cc8da25076a1fe56c3ac63671e2194458e0c4d9c7becfd52ca251650d517903c \\\n+ --hash=sha256:e78e426105ac07026ba098f04de8abe9b6e3e98b5befbf89b51a5ef0a4292b03\ncaighdean==0.0.4 \\\n--hash=sha256:a0a05b39f8e185a3698a4fb67dd2b388e7fb01b28f7f53c041e0857680655d4e \\\n--hash=sha256:0aff328adac0faad0e42584a573512f4fc4d06a7d251e71bb9098f08c40456b6\n",
        "sim_msg_1": "Update to bleach 3.1.4",
        "sim_diff_2": "diff --git a/requirements/prod.txt b/requirements/prod.txt @@ -355,3 +355,7 @@ jmespath==0.9.3 \\\ns3transfer==0.1.10 \\\n--hash=sha256:bc52f38637f37572ae180c08a2dd87a4825b46713797633aab6e1a42d6b2b8ff \\\n--hash=sha256:ba1a9104939b7c0331dc4dd234d79afeed8b66edce77bbeeecd4f56de74a0fc1\n+python-dateutil==2.6.0 \\\n+ --hash=sha256:62a2f8df3d66f878373fd0072eacf4ee52194ba302e00082828e0d263b0418d2 \\\n+ --hash=sha256:3acbef017340600e9ff8f2994d8f7afd6eacb295383f286466a6df3961e486f0 \\\n+ --hash=sha256:537bf2a8f8ce6f6862ad705cd68f9e405c0b5db014aa40fa29eab4335d4b1716\n",
        "sim_msg_2": "Add missing boto3 dependency.",
        "sim_diff_3": "diff --git a/poetry.lock b/poetry.lock @@ -5140,6 +5140,7 @@ isodate = []\nisort = [\n{file = \"isort-5.10.1-py3-none-any.whl\", hash = \"sha256:6f62d78e2f89b4500b080fe3a81690850cd254227f27f75c3a0c491a1f351ba7\"},\n{file = \"isort-5.10.1.tar.gz\", hash = \"sha256:e8443a5e7a020e9d7f97f1d7d9cd17c88bcb3bc7e218bf9cf5095fe550be2951\"},\n+]\njedi-language-server = [\n{file = \"jedi_language_server-0.40.0-py3-none-any.whl\", hash = \"sha256:53e590400b5cd2f6e363e77a4d824b1883798994b731cb0b4370d103748d30e2\"},\n{file = \"jedi_language_server-0.40.0.tar.gz\", hash = \"sha256:bacbae2930b6a8a0f1f284c211672fceec94b4808b0415d1c3352fa4b1ac5ad6\"},\n",
        "sim_msg_3": "issue with poetry.lock after merge"
    },
    {
        "org_diff": "diff --git a/docs/logging.rst b/a/docs/logging.rst @@ -159,7 +159,7 @@ Depending on your project, it may be more useful to configure each logger you\n care about separately, instead of configuring only the root logger. ::\n \n     for logger in (\n-        app.logger,\n+        logging.getLogger(app.name),\n         logging.getLogger('sqlalchemy'),\n         logging.getLogger('other_package'),\n     ):",
        "sim_diff_0": "diff --git a/augur/application/logs.py b/augur/application/logs.py @@ -101,7 +101,13 @@ def get_log_config():\n#TODO dynamically define loggers for every task names.\nclass TaskLogConfig():\n- def __init__(self, all_tasks, disable_log_files=False,reset_logfiles=False,base_log_dir=ROOT_AUGUR_DIRECTORY + \"/logs/\",logLevel=logging.INFO):\n+ def __init__(self, all_tasks, disable_log_files=False,reset_logfiles=False,base_log_dir=ROOT_AUGUR_DIRECTORY + \"/logs/\"):\n+\n+ log_config = get_log_config()\n+\n+ if log_config[\"logs_directory\"] != \"\":\n+ base_log_dir=log_config[\"logs_directory\"]\n+\nif reset_logfiles is True:\ntry:\nprint(\"(tasks) Reseting log files\")\n@@ -109,9 +115,10 @@ class TaskLogConfig():\nexcept FileNotFoundError as e:\npass\n- self.log_confg = get_log_config()\n-\n- self.logLevel = logLevel\n+ if log_config[\"log_level\"].lower() == \"debug\":\n+ self.logLevel = logging.DEBUG\n+ else:\n+ self.logLevel = logging.INFO\nself.base_log_dir = Path(base_log_dir)\n@@ -165,7 +172,13 @@ class TaskLogConfig():\nclass AugurLogger():\n- def __init__(self, logger_name, disable_log_files=False,reset_logfiles=False,base_log_dir=ROOT_AUGUR_DIRECTORY + \"/logs/\",logLevel=logging.INFO):\n+ def __init__(self, logger_name, disable_log_files=False,reset_logfiles=False,base_log_dir=ROOT_AUGUR_DIRECTORY + \"/logs/\"):\n+\n+ log_config = get_log_config()\n+\n+ if log_config[\"logs_directory\"] != \"\":\n+ base_log_dir=log_config[\"logs_directory\"]\n+\nif reset_logfiles is True:\ntry:\nprint(\"(augur) Reseting log files\")\n@@ -173,7 +186,10 @@ class AugurLogger():\nexcept FileNotFoundError as e:\npass\n- self.logLevel = logLevel\n+ if log_config[\"log_level\"].lower() == \"debug\":\n+ self.logLevel = logging.DEBUG\n+ else:\n+ self.logLevel = logging.INFO\nself.base_log_dir = Path(base_log_dir)\n",
        "sim_msg_0": "Make logs use config for log level and logs directory",
        "sim_diff_1": "diff --git a/packages/grid/backend/app/app/logger/log.py b/packages/grid/backend/app/app/logger/log.py @@ -22,7 +22,7 @@ class LogHandler:\n\"<cyan>{name}</cyan>:<cyan>{function}</cyan>:<cyan>{line}</cyan>: \"\n\"<level>{message}</level>\"\n),\n- \"level\": 0,\n+ \"level\": \"DEBUG\",\n\"sink\": sys.stdout,\n\"filter\": None,\n\"compression\": None,\n@@ -92,7 +92,7 @@ class LogHandler:\nlogging.getLogger(log).handlers = [intercept_handler]\nlogger.configure(\n- handlers=[{\"sink\": sys.stdout, \"level\": 0, \"format\": self.format_record}],\n+ handlers=[{\"sink\": sys.stdout, \"level\": self.config['level'], \"format\": self.format_record}],\n)\ntry:\n",
        "sim_msg_1": "fix: get log level from config",
        "sim_diff_2": "diff --git a/src/app/example_configs/app-logging.yaml b/src/app/example_configs/app-logging.yaml @@ -21,14 +21,18 @@ handlers:\nloggers:\napscheduler:\nlevel: \"WARNING\"\n+ asyncio:\n+ level: \"INFO\"\n+ beer_garden:\n+ level: \"INFO\"\npika:\nlevel: \"ERROR\"\ntornado:\nlevel: \"WARNING\"\n- requests.packages.urllib3.connectionpool:\n- level: \"WARNING\"\nstomp:\nlevel: \"WARNING\"\n+ urllib3:\n+ level: \"INFO\"\nroot:\nlevel: \"INFO\"\n",
        "sim_msg_2": "Adding additional log level configs",
        "sim_diff_3": "diff --git a/atlassian/bitbucket.py b/atlassian/bitbucket.py @@ -6,6 +6,7 @@ log = logging.getLogger(__name__)\nclass Bitbucket(AtlassianRestAPI):\n+\ndef project_list(self, limit=None):\n\"\"\"\nProvide the project list\n@@ -41,6 +42,22 @@ class Bitbucket(AtlassianRestAPI):\n}\nreturn self.post(url, data=data)\n+ def update_project(self, key, **params):\n+ \"\"\"\n+ Update project\n+ :param key:\n+ :param **params:\n+ :return:\n+ \"\"\"\n+ data = self.project(key)\n+ if not 'errors' in data:\n+ data.update(params)\n+ url = 'rest/api/1.0/projects/{0}'.format(key)\n+ return self.put(url, data=data)\n+ else:\n+ log.debug('Failed to update project: {0}: Unable to read project'.format(key))\n+ return None\n+\ndef project_users(self, key, limit=99999, filter_str=None):\n\"\"\"\nGet users who has permission in project\n",
        "sim_msg_3": "Add update_project call"
    },
    {
        "org_diff": "diff --git a/.github/workflows/publish.yaml b/a/.github/workflows/publish.yaml @@ -55,9 +55,11 @@ jobs:\n           GH_TOKEN: ${{ github.token }}\n   publish-pypi:\n     needs: [provenance]\n-    # Wait for approval before attempting to upload to PyPI. This allows reviewing the\n-    # files in the draft release.\n-    environment: publish\n+    environment:\n+      # Wait for approval before attempting to upload to PyPI. This allows reviewing the\n+      # files in the draft release. The projection is configured in the repository settings.\n+      name: publish\n+      url: https://pypi.org/project/flask/${{ github.ref_name }}\n     runs-on: ubuntu-latest\n     permissions:\n       id-token: write",
        "sim_diff_0": "diff --git a/.github/workflows/pypi_upload.yml b/.github/workflows/pypi_upload.yml @@ -47,7 +47,7 @@ jobs:\n# to upload to test pypi, pass repository_url: https://test.pypi.org/legacy/ and use secrets.TEST_PYPI_TOKEN\n- name: Publish a Python distribution to PyPI\n- uses: pypa/gh-action-pypi-publish@master\n+ uses: pypa/gh-action-pypi-publish@release/v1\nwith:\nuser: __token__\npassword: ${{ secrets.PYPI_TOKEN }}\n",
        "sim_msg_0": "Update pypi release action.",
        "sim_diff_1": "diff --git a/.github/workflows/build.yml b/.github/workflows/build.yml @@ -73,8 +73,7 @@ jobs:\npath: dist/gaphor-${{ steps.meta.outputs.version }}-py3-none-any.whl\n- name: Publish to PyPI\nif: github.event_name == 'release'\n- run: |\n- poetry publish -u __token__ -p ${{ secrets.PYPI_TOKEN }}\n+ run: poetry publish -u __token__ -p ${{ secrets.PYPI_TOKEN }}\nwindows:\nneeds: lint\n@@ -104,16 +103,14 @@ jobs:\nkey: ${{ runner.os }}-poetry-${{ hashFiles('**/poetry.lock') }}\nrestore-keys: ${{ runner.os }}-poetry-\n- name: Install Dependencies\n- run: |\n- ./win-installer/msys2-install.sh\n+ run: ./win-installer/msys2-install.sh\n- name: Install Poetry\nrun: |\npip install poetry==$POETRY_VERSION\npoetry config virtualenvs.create false\n- name: Collect Metadata\nid: meta\n- run: |\n- .github/scripts/metadata.sh\n+ run: .github/scripts/metadata.sh\n- name: Install Python Dependencies\nrun: mingw32-make install\n- name: Run Tests\n@@ -168,9 +165,7 @@ jobs:\n- name: Set up Python\nuses: actions/setup-python@v2.1.3\n- name: Install macOS Dependencies\n- run: |\n- brew list\n- brew install gobject-introspection gtk+3 adwaita-icon-theme gtk-mac-integration create-dmg\n+ run: brew install gobject-introspection gtk+3 adwaita-icon-theme gtk-mac-integration create-dmg\n- name: Install Poetry\nrun: pip install poetry==$POETRY_VERSION\n- name: Collect Metadata\n@@ -183,8 +178,7 @@ jobs:\nkey: ${{ runner.os }}-poetry-${{ hashFiles('**/poetry.lock') }}\nrestore-keys: ${{ runner.os }}-poetry-\n- name: Install Python Dependencies\n- run: |\n- poetry install\n+ run: poetry install\n- name: Test with Pytest\nrun: make test-all\n- name: Create macOS Application\n",
        "sim_msg_1": "Put single line build statements on one line",
        "sim_diff_2": "diff --git a/.github/workflows/full-build.yml b/.github/workflows/full-build.yml @@ -397,7 +397,7 @@ jobs:\nname: Publish to PyPI (release only)\nneeds: [ linux-gtk4, linux-flatpak-devel, macos-gtk4, check-linux-appimage, check-macos-app, check-windows-installer ]\nruns-on: ubuntu-22.04\n- # if: github.event_name == 'release'\n+ if: github.event_name == 'release'\nsteps:\n- uses: actions/download-artifact@v3\nwith:\n@@ -410,4 +410,3 @@ jobs:\n- uses: pypa/gh-action-pypi-publish@release/v1\nwith:\npassword: ${{ secrets.PYPI_TOKEN }}\n- repository_url: https://test.pypi.org/legacy/\n",
        "sim_msg_2": "Change publish target for production",
        "sim_diff_3": "diff --git a/.github/workflows/pypi_upload.yml b/.github/workflows/pypi_upload.yml @@ -54,8 +54,8 @@ jobs:\nuses: pypa/gh-action-pypi-publish@master\nwith:\nuser: __token__\n- password: ${{ secrets.TEST_PYPI_TOKEN }}\n- repository_url: https://test.pypi.org/legacy/\n+ password: ${{ secrets.PYPI_TOKEN }}\n+ # repository_url: https://test.pypi.org/legacy/\npackages_dir: dist/\n# git push https://${{ github.actor }}:${{ secrets.GITHUB_TOKEN }}@github.com/${{ github.repository }}.git HEAD:master\n",
        "sim_msg_3": "Switch automated release action to point at production pypi"
    },
    {
        "org_diff": "diff --git a/.github/workflows/publish.yaml b/a/.github/workflows/publish.yaml @@ -55,9 +55,11 @@ jobs:\n           GH_TOKEN: ${{ github.token }}\n   publish-pypi:\n     needs: [provenance]\n-    # Wait for approval before attempting to upload to PyPI. This allows reviewing the\n-    # files in the draft release.\n-    environment: publish\n+    environment:\n+      # Wait for approval before attempting to upload to PyPI. This allows reviewing the\n+      # files in the draft release. The projection is configured in the repository settings.\n+      name: publish\n+      url: https://pypi.org/project/flask/${{ github.ref_name }}\n     runs-on: ubuntu-latest\n     permissions:\n       id-token: write",
        "sim_diff_0": "diff --git a/.github/workflows/pypi_upload.yml b/.github/workflows/pypi_upload.yml @@ -47,7 +47,7 @@ jobs:\n# to upload to test pypi, pass repository_url: https://test.pypi.org/legacy/ and use secrets.TEST_PYPI_TOKEN\n- name: Publish a Python distribution to PyPI\n- uses: pypa/gh-action-pypi-publish@master\n+ uses: pypa/gh-action-pypi-publish@release/v1\nwith:\nuser: __token__\npassword: ${{ secrets.PYPI_TOKEN }}\n",
        "sim_msg_0": "Update pypi release action.",
        "sim_diff_1": "diff --git a/.github/workflows/build.yml b/.github/workflows/build.yml @@ -73,8 +73,7 @@ jobs:\npath: dist/gaphor-${{ steps.meta.outputs.version }}-py3-none-any.whl\n- name: Publish to PyPI\nif: github.event_name == 'release'\n- run: |\n- poetry publish -u __token__ -p ${{ secrets.PYPI_TOKEN }}\n+ run: poetry publish -u __token__ -p ${{ secrets.PYPI_TOKEN }}\nwindows:\nneeds: lint\n@@ -104,16 +103,14 @@ jobs:\nkey: ${{ runner.os }}-poetry-${{ hashFiles('**/poetry.lock') }}\nrestore-keys: ${{ runner.os }}-poetry-\n- name: Install Dependencies\n- run: |\n- ./win-installer/msys2-install.sh\n+ run: ./win-installer/msys2-install.sh\n- name: Install Poetry\nrun: |\npip install poetry==$POETRY_VERSION\npoetry config virtualenvs.create false\n- name: Collect Metadata\nid: meta\n- run: |\n- .github/scripts/metadata.sh\n+ run: .github/scripts/metadata.sh\n- name: Install Python Dependencies\nrun: mingw32-make install\n- name: Run Tests\n@@ -168,9 +165,7 @@ jobs:\n- name: Set up Python\nuses: actions/setup-python@v2.1.3\n- name: Install macOS Dependencies\n- run: |\n- brew list\n- brew install gobject-introspection gtk+3 adwaita-icon-theme gtk-mac-integration create-dmg\n+ run: brew install gobject-introspection gtk+3 adwaita-icon-theme gtk-mac-integration create-dmg\n- name: Install Poetry\nrun: pip install poetry==$POETRY_VERSION\n- name: Collect Metadata\n@@ -183,8 +178,7 @@ jobs:\nkey: ${{ runner.os }}-poetry-${{ hashFiles('**/poetry.lock') }}\nrestore-keys: ${{ runner.os }}-poetry-\n- name: Install Python Dependencies\n- run: |\n- poetry install\n+ run: poetry install\n- name: Test with Pytest\nrun: make test-all\n- name: Create macOS Application\n",
        "sim_msg_1": "Put single line build statements on one line",
        "sim_diff_2": "diff --git a/.github/workflows/full-build.yml b/.github/workflows/full-build.yml @@ -397,7 +397,7 @@ jobs:\nname: Publish to PyPI (release only)\nneeds: [ linux-gtk4, linux-flatpak-devel, macos-gtk4, check-linux-appimage, check-macos-app, check-windows-installer ]\nruns-on: ubuntu-22.04\n- # if: github.event_name == 'release'\n+ if: github.event_name == 'release'\nsteps:\n- uses: actions/download-artifact@v3\nwith:\n@@ -410,4 +410,3 @@ jobs:\n- uses: pypa/gh-action-pypi-publish@release/v1\nwith:\npassword: ${{ secrets.PYPI_TOKEN }}\n- repository_url: https://test.pypi.org/legacy/\n",
        "sim_msg_2": "Change publish target for production",
        "sim_diff_3": "diff --git a/.github/workflows/pypi_upload.yml b/.github/workflows/pypi_upload.yml @@ -54,8 +54,8 @@ jobs:\nuses: pypa/gh-action-pypi-publish@master\nwith:\nuser: __token__\n- password: ${{ secrets.TEST_PYPI_TOKEN }}\n- repository_url: https://test.pypi.org/legacy/\n+ password: ${{ secrets.PYPI_TOKEN }}\n+ # repository_url: https://test.pypi.org/legacy/\npackages_dir: dist/\n# git push https://${{ github.actor }}:${{ secrets.GITHUB_TOKEN }}@github.com/${{ github.repository }}.git HEAD:master\n",
        "sim_msg_3": "Switch automated release action to point at production pypi"
    },
    {
        "org_diff": "diff --git a/.pre-commit-config.yaml b/a/.pre-commit-config.yaml @@ -2,7 +2,7 @@ ci:\n   autoupdate_schedule: monthly\n repos:\n   - repo: https://github.com/astral-sh/ruff-pre-commit\n-    rev: v0.1.13\n+    rev: v0.2.0\n     hooks:\n       - id: ruff\n       - id: ruff-format",
        "sim_diff_0": "diff --git a/.pre-commit-config.yaml b/.pre-commit-config.yaml @@ -27,6 +27,7 @@ repos:\nhooks:\n- id: black\nlanguage_version: python3\n+ additional_dependencies: ['click==8.0.4']\n- repo: https://github.com/pre-commit/mirrors-isort\nrev: v4.3.21\nhooks:\n",
        "sim_msg_0": "add pre_commit dependency for pre_commit for black, click version compatability",
        "sim_diff_1": "diff --git a/.pre-commit-config.yaml b/.pre-commit-config.yaml @@ -6,11 +6,11 @@ repos:\nhooks:\n- id: isort\n- repo: https://github.com/psf/black\n- rev: 22.6.0\n+ rev: 22.10.0\nhooks:\n- id: black\n- repo: https://github.com/PyCQA/flake8\n- rev: 5.0.3\n+ rev: 5.0.4\nhooks:\n- id: flake8\n- repo: https://github.com/pre-commit/pre-commit-hooks\n",
        "sim_msg_1": "Update precommit dependencies",
        "sim_diff_2": "diff --git a/.pre-commit-config.yaml b/.pre-commit-config.yaml @@ -5,7 +5,7 @@ default_language_version:\nrepos:\n- repo: https://github.com/psf/black\n- rev: 21.12b0\n+ rev: 22.1.0\nhooks:\n- id: black\n@@ -39,6 +39,6 @@ repos:\n- --ignore-init-module-imports\n- repo: https://github.com/pre-commit/mirrors-mypy\n- rev: v0.930\n+ rev: v0.931\nhooks:\n- id: mypy\n",
        "sim_msg_2": "Update black and mypy versions in pre-commit yaml",
        "sim_diff_3": "diff --git a/.pre-commit-config.yaml b/.pre-commit-config.yaml @@ -8,10 +8,13 @@ repos:\nrev: v0.740\nhooks:\n- id: mypy\n+- repo: https://gitlab.com/pycqa/flake8\n+ rev: 3.7.9\n+ hooks:\n+ - id: flake8\n- repo: https://github.com/pre-commit/pre-commit-hooks\nrev: v2.4.0\nhooks:\n- - id: flake8\n- id: check-toml\n- id: check-yaml\n- repo: https://github.com/asottile/seed-isort-config\n",
        "sim_msg_3": "Switch to main flake8 repo to install pre-commit hook"
    },
    {
        "org_diff": "diff --git a/.pre-commit-config.yaml b/a/.pre-commit-config.yaml @@ -2,7 +2,7 @@ ci:\n   autoupdate_schedule: monthly\n repos:\n   - repo: https://github.com/astral-sh/ruff-pre-commit\n-    rev: v0.1.13\n+    rev: v0.2.0\n     hooks:\n       - id: ruff\n       - id: ruff-format",
        "sim_diff_0": "diff --git a/.pre-commit-config.yaml b/.pre-commit-config.yaml @@ -27,6 +27,7 @@ repos:\nhooks:\n- id: black\nlanguage_version: python3\n+ additional_dependencies: ['click==8.0.4']\n- repo: https://github.com/pre-commit/mirrors-isort\nrev: v4.3.21\nhooks:\n",
        "sim_msg_0": "add pre_commit dependency for pre_commit for black, click version compatability",
        "sim_diff_1": "diff --git a/.pre-commit-config.yaml b/.pre-commit-config.yaml @@ -6,11 +6,11 @@ repos:\nhooks:\n- id: isort\n- repo: https://github.com/psf/black\n- rev: 22.6.0\n+ rev: 22.10.0\nhooks:\n- id: black\n- repo: https://github.com/PyCQA/flake8\n- rev: 5.0.3\n+ rev: 5.0.4\nhooks:\n- id: flake8\n- repo: https://github.com/pre-commit/pre-commit-hooks\n",
        "sim_msg_1": "Update precommit dependencies",
        "sim_diff_2": "diff --git a/.pre-commit-config.yaml b/.pre-commit-config.yaml @@ -5,7 +5,7 @@ default_language_version:\nrepos:\n- repo: https://github.com/psf/black\n- rev: 21.12b0\n+ rev: 22.1.0\nhooks:\n- id: black\n@@ -39,6 +39,6 @@ repos:\n- --ignore-init-module-imports\n- repo: https://github.com/pre-commit/mirrors-mypy\n- rev: v0.930\n+ rev: v0.931\nhooks:\n- id: mypy\n",
        "sim_msg_2": "Update black and mypy versions in pre-commit yaml",
        "sim_diff_3": "diff --git a/.pre-commit-config.yaml b/.pre-commit-config.yaml @@ -8,10 +8,13 @@ repos:\nrev: v0.740\nhooks:\n- id: mypy\n+- repo: https://gitlab.com/pycqa/flake8\n+ rev: 3.7.9\n+ hooks:\n+ - id: flake8\n- repo: https://github.com/pre-commit/pre-commit-hooks\nrev: v2.4.0\nhooks:\n- - id: flake8\n- id: check-toml\n- id: check-yaml\n- repo: https://github.com/asottile/seed-isort-config\n",
        "sim_msg_3": "Switch to main flake8 repo to install pre-commit hook"
    },
    {
        "org_diff": "diff --git a/.github/workflows/publish.yaml b/a/.github/workflows/publish.yaml @@ -48,8 +48,9 @@ jobs:\n       - uses: actions/download-artifact@9bc31d5ccc31df68ecc42ccf4149144866c47d8a\n       - name: create release\n         run: >\n-          gh release create --draft --repo ${{ github.repository }} ${{ github.ref_name }} *.intoto.jsonl/* artifact/*\n-\n+          gh release create --draft --repo ${{ github.repository }}\n+          ${{ github.ref_name }}\n+          *.intoto.jsonl/* dist/*\n         env:\n           GH_TOKEN: ${{ github.token }}\n   publish-pypi:",
        "sim_diff_0": "diff --git a/.github/workflows/build.yml b/.github/workflows/build.yml @@ -81,6 +81,15 @@ jobs:\nwith:\nname: Gaphor-${{ steps.meta.outputs.version }}-x86_64.AppImage\npath: packaging/dist/Gaphor-${{ steps.meta.outputs.version }}-x86_64.AppImage\n+ - name: Upload Assets (release only)\n+ uses: AButler/upload-release-assets@v2.0\n+ if: github.event_name == 'release'\n+ with:\n+ files: |\n+ \"packaging/dist/Gaphor-${{ steps.meta.outputs.version }}-x86_64.AppImage;\n+ dist/gaphor-${{ steps.meta.outputs.version }}-py3-none-any.whl;\n+ dist/gaphor-${{ steps.meta.outputs.version }}.tar.gz\"\n+ repo-token: ${{ secrets.GITHUB_TOKEN }}\n- name: Publish to PyPI (release only)\nif: github.event_name == 'release'\nrun: poetry publish -u __token__ -p ${{ secrets.PYPI_TOKEN }}\n",
        "sim_msg_0": "Upload Linux assets during release",
        "sim_diff_1": "diff --git a/.github/workflows/build.yml b/.github/workflows/build.yml @@ -235,7 +235,7 @@ jobs:\nuses: actions/upload-artifact@v2\nwith:\nname: Gaphor-${{ steps.meta.outputs.version }}.dmg\n- path: packaging/Gaphor-${{ steps.meta.outputs.version }}.dmg\n+ path: packaging/dist/Gaphor-${{ steps.meta.outputs.version }}.dmg\n- name: Upload Assets (release only)\nuses: AButler/upload-release-assets@v2.0\nif: github.event_name == 'release'\n",
        "sim_msg_1": "Fix dmg upload failed due to incorrect path",
        "sim_diff_2": "diff --git a/.github/workflows/tag-actions.yml b/.github/workflows/tag-actions.yml @@ -10,6 +10,9 @@ jobs:\nname: Github Release\nruns-on: ubuntu-latest\n+ outputs:\n+ upload_url: ${{ steps.create_release.outputs.upload_url }}\n+\nsteps:\n- name: Create Release\nid: create_release\n@@ -125,7 +128,7 @@ jobs:\nenv:\nGITHUB_TOKEN: ${{ secrets.RELEASE_TOKEN }}\nwith:\n- upload_url: ${{ steps.create_release.outputs.upload_url }}\n+ upload_url: ${{ needs.github-release.outputs.upload_url }}\nasset_path: ./rpm/dist/beer-garden-${GITHUB_REF#refs/tags/}-1.el7.x86_64.rpm\nasset_name: beer-garden-${GITHUB_REF#refs/tags/}-1.el7.x86_64.rpm\nasset_content_type: application/octet-stream\n",
        "sim_msg_2": "Need to mark job output",
        "sim_diff_3": "diff --git a/.github/workflows/full-build.yml b/.github/workflows/full-build.yml @@ -79,12 +79,6 @@ jobs:\nwith:\nname: gaphor-${{ steps.setup_and_test.outputs.version }}-py3-none-any.whl\npath: dist/gaphor-${{ steps.setup_and_test.outputs.version }}-py3-none-any.whl\n- - name: Upload Release Asset gaphor-${{ steps.setup_and_test.outputs.version }}.tar.gz\n- uses: AButler/upload-release-assets@v2.0\n- if: github.event_name == 'release'\n- with:\n- files: dist/gaphor-${{ steps.setup_and_test.outputs.version }}.tar.gz\n- repo-token: ${{ secrets.GITHUB_TOKEN }}\n- name: Publish to PyPI (release only)\nif: github.event_name == 'release'\nrun: poetry publish -u __token__ -p ${{ secrets.PYPI_TOKEN }}\n",
        "sim_msg_3": "Prevent uploading python source tar ball as well"
    },
    {
        "org_diff": "diff --git a/.github/workflows/publish.yaml b/a/.github/workflows/publish.yaml @@ -33,7 +33,8 @@ jobs:\n       actions: read\n       id-token: write\n       contents: write\n-    uses: slsa-framework/slsa-github-generator/.github/workflows/generator_generic_slsa3.yml@07e64b653f10a80b6510f4568f685f8b7b9ea830\n+    # Can't pin with hash due to how this workflow works.\n+    uses: slsa-framework/slsa-github-generator/.github/workflows/generator_generic_slsa3.yml@v1.9.0\n     with:\n       base64-subjects: ${{ needs.build.outputs.hash }}\n   create-release:",
        "sim_diff_0": "diff --git a/.github/workflows/tag-actions.yml b/.github/workflows/tag-actions.yml @@ -10,6 +10,9 @@ jobs:\nname: Github Release\nruns-on: ubuntu-latest\n+ outputs:\n+ upload_url: ${{ steps.create_release.outputs.upload_url }}\n+\nsteps:\n- name: Create Release\nid: create_release\n@@ -125,7 +128,7 @@ jobs:\nenv:\nGITHUB_TOKEN: ${{ secrets.RELEASE_TOKEN }}\nwith:\n- upload_url: ${{ steps.create_release.outputs.upload_url }}\n+ upload_url: ${{ needs.github-release.outputs.upload_url }}\nasset_path: ./rpm/dist/beer-garden-${GITHUB_REF#refs/tags/}-1.el7.x86_64.rpm\nasset_name: beer-garden-${GITHUB_REF#refs/tags/}-1.el7.x86_64.rpm\nasset_content_type: application/octet-stream\n",
        "sim_msg_0": "Need to mark job output",
        "sim_diff_1": "diff --git a/.github/workflows/release-drafter.yml b/.github/workflows/release-drafter.yml @@ -16,7 +16,7 @@ jobs:\nruns-on: ubuntu-latest\nsteps:\n- uses: release-drafter/release-drafter@v5\n- # with:\n- # disable-autolabeler: true\n+ with:\n+ disable-autolabeler: true\nenv:\nGITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n",
        "sim_msg_1": "explictly disable autolabeler for good measure",
        "sim_diff_2": "diff --git a/.github/workflows/tag-actions.yml b/.github/workflows/tag-actions.yml @@ -116,8 +116,8 @@ jobs:\nenv:\nGITHUB_TOKEN: ${{ secrets.RELEASE_TOKEN }}\nwith:\n- tag_name: ${{ github.ref }}\n- release_name: Release ${{ github.ref }}\n+ tag_name: ${GITHUB_REF#refs/tags/}\n+ release_name: Release ${GITHUB_REF#refs/tags/}\ndraft: false\nprerelease: false\n",
        "sim_msg_2": "Fixing Github Tag",
        "sim_diff_3": "diff --git a/.github/workflows/build.yml b/.github/workflows/build.yml @@ -73,8 +73,7 @@ jobs:\npath: dist/gaphor-${{ steps.meta.outputs.version }}-py3-none-any.whl\n- name: Publish to PyPI\nif: github.event_name == 'release'\n- run: |\n- poetry publish -u __token__ -p ${{ secrets.PYPI_TOKEN }}\n+ run: poetry publish -u __token__ -p ${{ secrets.PYPI_TOKEN }}\nwindows:\nneeds: lint\n@@ -104,16 +103,14 @@ jobs:\nkey: ${{ runner.os }}-poetry-${{ hashFiles('**/poetry.lock') }}\nrestore-keys: ${{ runner.os }}-poetry-\n- name: Install Dependencies\n- run: |\n- ./win-installer/msys2-install.sh\n+ run: ./win-installer/msys2-install.sh\n- name: Install Poetry\nrun: |\npip install poetry==$POETRY_VERSION\npoetry config virtualenvs.create false\n- name: Collect Metadata\nid: meta\n- run: |\n- .github/scripts/metadata.sh\n+ run: .github/scripts/metadata.sh\n- name: Install Python Dependencies\nrun: mingw32-make install\n- name: Run Tests\n@@ -168,9 +165,7 @@ jobs:\n- name: Set up Python\nuses: actions/setup-python@v2.1.3\n- name: Install macOS Dependencies\n- run: |\n- brew list\n- brew install gobject-introspection gtk+3 adwaita-icon-theme gtk-mac-integration create-dmg\n+ run: brew install gobject-introspection gtk+3 adwaita-icon-theme gtk-mac-integration create-dmg\n- name: Install Poetry\nrun: pip install poetry==$POETRY_VERSION\n- name: Collect Metadata\n@@ -183,8 +178,7 @@ jobs:\nkey: ${{ runner.os }}-poetry-${{ hashFiles('**/poetry.lock') }}\nrestore-keys: ${{ runner.os }}-poetry-\n- name: Install Python Dependencies\n- run: |\n- poetry install\n+ run: poetry install\n- name: Test with Pytest\nrun: make test-all\n- name: Create macOS Application\n",
        "sim_msg_3": "Put single line build statements on one line"
    },
    {
        "org_diff": "diff --git a/src/flask/helpers.py b/a/src/flask/helpers.py @@ -49,7 +49,7 @@ def get_load_dotenv(default: bool = True) -> bool:\n \n \n def stream_with_context(\n-    generator_or_function: t.Iterator[t.AnyStr] | t.Callable[..., t.Iterator[t.AnyStr]]\n+    generator_or_function: t.Iterator[t.AnyStr] | t.Callable[..., t.Iterator[t.AnyStr]],\n ) -> t.Iterator[t.AnyStr]:\n     \"\"\"Request contexts disappear when the response is started on the server.\n     This is done for efficiency reasons and to make it less likely to encounter",
        "sim_diff_0": "diff --git a/src/flask/helpers.py b/src/flask/helpers.py @@ -819,33 +819,8 @@ def run_async(func: t.Callable[..., t.Coroutine]) -> t.Callable[..., t.Any]:\n)\n@wraps(func)\n- def outer(*args: t.Any, **kwargs: t.Any) -> t.Any:\n- \"\"\"This function grabs the current context for the inner function.\n+ def wrapper(*args: t.Any, **kwargs: t.Any) -> t.Any:\n+ return async_to_sync(func)(*args, **kwargs)\n- This is similar to the copy_current_xxx_context functions in the\n- ctx module, except it has an async inner.\n- \"\"\"\n- ctx = None\n-\n- if _request_ctx_stack.top is not None:\n- ctx = _request_ctx_stack.top.copy()\n-\n- @wraps(func)\n- async def inner(*a: t.Any, **k: t.Any) -> t.Any:\n- \"\"\"This restores the context before awaiting the func.\n-\n- This is required as the function must be awaited within the\n- context. Only calling ``func`` (as per the\n- ``copy_current_xxx_context`` functions) doesn't work as the\n- with block will close before the coroutine is awaited.\n- \"\"\"\n- if ctx is not None:\n- with ctx:\n- return await func(*a, **k)\n- else:\n- return await func(*a, **k)\n-\n- return async_to_sync(inner)(*args, **kwargs)\n-\n- outer._flask_sync_wrapper = True # type: ignore\n- return outer\n+ wrapper._flask_sync_wrapper = True # type: ignore\n+ return wrapper\n",
        "sim_msg_0": "Remove context copying from run_async function\nThis was required with the previous implementation of Werkzeug's\nlocals which didn't persist across threads. However as the current\nimplementation uses ContextVars which do persist the context copying\nis no longer required.",
        "sim_diff_1": "diff --git a/flask/ctx.py b/flask/ctx.py @@ -282,7 +282,11 @@ class RequestContext(object):\nif request is None:\nrequest = app.request_class(environ)\nself.request = request\n+ self.url_adapter = None\n+ try:\nself.url_adapter = app.create_url_adapter(self.request)\n+ except HTTPException as e:\n+ self.request.routing_exception = e\nself.flashes = None\nself.session = session\n@@ -305,6 +309,7 @@ class RequestContext(object):\n# functions.\nself._after_request_functions = []\n+ if self.url_adapter is not None:\nself.match_request()\ndef _get_g(self):\n",
        "sim_msg_1": "Handle errors during create_url_adapter\nIf create_url_adapter raises (which it can if werkzeug cannot bind\nenvironment, for example on non-ASCII Host header), we handle it as\nother routing exceptions rather than raising through.\nref",
        "sim_diff_2": "diff --git a/flask/app.py b/flask/app.py @@ -2140,8 +2140,8 @@ class Flask(_PackageBoundObject):\nreturn RequestContext(self, environ)\ndef test_request_context(self, *args, **kwargs):\n- \"\"\"Creates a WSGI environment from the given values (see\n- :class:`werkzeug.test.EnvironBuilder` for more information, this\n+ \"\"\"Creates a :class:`~flask.ctx.RequestContext` from the given values\n+ (see :class:`werkzeug.test.EnvironBuilder` for more information, this\nfunction accepts the same arguments plus two additional).\nAdditional arguments (only if ``base_url`` is not specified):\n",
        "sim_msg_2": "Fix docs for test_request_context\nFixes",
        "sim_diff_3": "diff --git a/flask/cli.py b/flask/cli.py @@ -614,7 +614,7 @@ def load_dotenv(path=None):\nreturn new_dir is not None # at least one file was located and loaded\n-def show_server_banner(env, debug, app_import_path):\n+def show_server_banner(env, debug, app_import_path, eager_loading=True):\n\"\"\"Show extra startup messages the first time the server is run,\nignoring the reloader.\n\"\"\"\n@@ -622,7 +622,10 @@ def show_server_banner(env, debug, app_import_path):\nreturn\nif app_import_path is not None:\n- print(' * Serving Flask app \"{0}\"'.format(app_import_path))\n+ message = ' * Serving Flask app \"{0}\"'.format(app_import_path)\n+ if not eager_loading:\n+ message += ' (lazy loading)'\n+ print(message)\nprint(' * Environment: {0}'.format(env))\n@@ -759,7 +762,7 @@ def run_command(info, host, port, reload, debugger, eager_loading,\nif eager_loading is None:\neager_loading = not reload\n- show_server_banner(get_env(), debug, info.app_import_path)\n+ show_server_banner(get_env(), debug, info.app_import_path, eager_loading)\napp = DispatchingApp(info.load_app, use_eager_loading=eager_loading)\nfrom werkzeug.serving import run_simple\n",
        "sim_msg_3": "Add explicit `(lazy loading)` message to `flask run` related to"
    },
    {
        "org_diff": "diff --git a/.pre-commit-config.yaml b/a/.pre-commit-config.yaml @@ -2,7 +2,7 @@ ci:\n   autoupdate_schedule: monthly\n repos:\n   - repo: https://github.com/astral-sh/ruff-pre-commit\n-    rev: v0.1.6\n+    rev: v0.1.9\n     hooks:\n       - id: ruff\n       - id: ruff-format",
        "sim_diff_0": "diff --git a/.pre-commit-config.yaml b/.pre-commit-config.yaml @@ -27,6 +27,7 @@ repos:\nhooks:\n- id: black\nlanguage_version: python3\n+ additional_dependencies: ['click==8.0.4']\n- repo: https://github.com/pre-commit/mirrors-isort\nrev: v4.3.21\nhooks:\n",
        "sim_msg_0": "add pre_commit dependency for pre_commit for black, click version compatability",
        "sim_diff_1": "diff --git a/.pre-commit-config.yaml b/.pre-commit-config.yaml @@ -6,11 +6,11 @@ repos:\nhooks:\n- id: isort\n- repo: https://github.com/psf/black\n- rev: 22.6.0\n+ rev: 22.10.0\nhooks:\n- id: black\n- repo: https://github.com/PyCQA/flake8\n- rev: 5.0.3\n+ rev: 5.0.4\nhooks:\n- id: flake8\n- repo: https://github.com/pre-commit/pre-commit-hooks\n",
        "sim_msg_1": "Update precommit dependencies",
        "sim_diff_2": "diff --git a/.pre-commit-config.yaml b/.pre-commit-config.yaml @@ -5,7 +5,7 @@ default_language_version:\nrepos:\n- repo: https://github.com/psf/black\n- rev: 21.12b0\n+ rev: 22.1.0\nhooks:\n- id: black\n@@ -39,6 +39,6 @@ repos:\n- --ignore-init-module-imports\n- repo: https://github.com/pre-commit/mirrors-mypy\n- rev: v0.930\n+ rev: v0.931\nhooks:\n- id: mypy\n",
        "sim_msg_2": "Update black and mypy versions in pre-commit yaml",
        "sim_diff_3": "diff --git a/.pre-commit-config.yaml b/.pre-commit-config.yaml @@ -8,10 +8,13 @@ repos:\nrev: v0.740\nhooks:\n- id: mypy\n+- repo: https://gitlab.com/pycqa/flake8\n+ rev: 3.7.9\n+ hooks:\n+ - id: flake8\n- repo: https://github.com/pre-commit/pre-commit-hooks\nrev: v2.4.0\nhooks:\n- - id: flake8\n- id: check-toml\n- id: check-yaml\n- repo: https://github.com/asottile/seed-isort-config\n",
        "sim_msg_3": "Switch to main flake8 repo to install pre-commit hook"
    },
    {
        "org_diff": "diff --git a/pyproject.toml b/a/pyproject.toml @@ -79,7 +79,7 @@ source = [\"src\", \"*/site-packages\"]\n \n [tool.mypy]\n python_version = \"3.8\"\n-files = [\"src/flask\"]\n+files = [\"src/flask\", \"tests/typing\"]\n show_error_codes = true\n pretty = true\n #strict = true",
        "sim_diff_0": "diff --git a/pyproject.toml b/pyproject.toml @@ -100,6 +100,7 @@ types-aiofiles = \"^0.1.9\"\ntypes-pkg-resources = \"^0.1.3\"\ntypes-requests = \"^2.25.9\"\ntypes-toml = \"^0.10.0\"\n+types-dataclasses = { version = \"^0.1.7\", markers = \"python_version < '3.7'\" }\n# Documantation\nmkdocs = \"^1.2.2\"\n",
        "sim_msg_0": "add types-dataclasses for python 3.6",
        "sim_diff_1": "diff --git a/pyproject.toml b/pyproject.toml @@ -24,7 +24,7 @@ include = [\"src/doc\", \"src/test\"]\n[tool.poetry.dependencies]\npython = \"^3.6\"\n-dataclasses = { version=\"*\", python = \"3.6\"}\n+dataclasses = { version = \"*\", python = \"<3.7\"}\n\"backports.zoneinfo\" = { version = \"*\", markers = \"python_version < '3.9'\" }\ntzdata = { version = \"*\", markers = \"sys_platform == 'win32'\" }\n",
        "sim_msg_1": "Updated dataclasses python requirement",
        "sim_diff_2": "diff --git a/pyproject.toml b/pyproject.toml @@ -14,6 +14,8 @@ classifiers = [\n\"Programming Language :: Python :: 3.6\",\n\"Programming Language :: Python :: 3.7\",\n\"Programming Language :: Python :: 3.8\",\n+ \"Programming Language :: Python :: 3.9\",\n+ \"Programming Language :: Python :: 3.10\",\n]\npackages = [\n{ include = \"astral\", from = \"src\"},\n",
        "sim_msg_2": "Also supports Python 3.9 and 3.10",
        "sim_diff_3": "diff --git a/pyproject.toml b/pyproject.toml @@ -13,6 +13,7 @@ classifiers = [\n\"Programming Language :: Python\",\n\"Programming Language :: Python :: 3.6\",\n\"Programming Language :: Python :: 3.7\",\n+ \"Programming Language :: Python :: 3.8\",\n]\npackages = [\n{ include = \"astral\", from = \"src\"},\n",
        "sim_msg_3": "Switch to LF line endings. Update classifiers"
    },
    {
        "org_diff": "diff --git a/pyproject.toml b/a/pyproject.toml @@ -79,7 +79,7 @@ source = [\"src\", \"*/site-packages\"]\n \n [tool.mypy]\n python_version = \"3.8\"\n-files = [\"src/flask\"]\n+files = [\"src/flask\", \"tests/typing\"]\n show_error_codes = true\n pretty = true\n #strict = true",
        "sim_diff_0": "diff --git a/pyproject.toml b/pyproject.toml @@ -100,6 +100,7 @@ types-aiofiles = \"^0.1.9\"\ntypes-pkg-resources = \"^0.1.3\"\ntypes-requests = \"^2.25.9\"\ntypes-toml = \"^0.10.0\"\n+types-dataclasses = { version = \"^0.1.7\", markers = \"python_version < '3.7'\" }\n# Documantation\nmkdocs = \"^1.2.2\"\n",
        "sim_msg_0": "add types-dataclasses for python 3.6",
        "sim_diff_1": "diff --git a/pyproject.toml b/pyproject.toml @@ -24,7 +24,7 @@ include = [\"src/doc\", \"src/test\"]\n[tool.poetry.dependencies]\npython = \"^3.6\"\n-dataclasses = { version=\"*\", python = \"3.6\"}\n+dataclasses = { version = \"*\", python = \"<3.7\"}\n\"backports.zoneinfo\" = { version = \"*\", markers = \"python_version < '3.9'\" }\ntzdata = { version = \"*\", markers = \"sys_platform == 'win32'\" }\n",
        "sim_msg_1": "Updated dataclasses python requirement",
        "sim_diff_2": "diff --git a/pyproject.toml b/pyproject.toml @@ -14,6 +14,8 @@ classifiers = [\n\"Programming Language :: Python :: 3.6\",\n\"Programming Language :: Python :: 3.7\",\n\"Programming Language :: Python :: 3.8\",\n+ \"Programming Language :: Python :: 3.9\",\n+ \"Programming Language :: Python :: 3.10\",\n]\npackages = [\n{ include = \"astral\", from = \"src\"},\n",
        "sim_msg_2": "Also supports Python 3.9 and 3.10",
        "sim_diff_3": "diff --git a/pyproject.toml b/pyproject.toml @@ -13,6 +13,7 @@ classifiers = [\n\"Programming Language :: Python\",\n\"Programming Language :: Python :: 3.6\",\n\"Programming Language :: Python :: 3.7\",\n+ \"Programming Language :: Python :: 3.8\",\n]\npackages = [\n{ include = \"astral\", from = \"src\"},\n",
        "sim_msg_3": "Switch to LF line endings. Update classifiers"
    },
    {
        "org_diff": "diff --git a/docs/server.rst b/a/docs/server.rst @@ -76,8 +76,8 @@ following example shows that process id 6847 is using port 5000.\n             TCP 127.0.0.1:5000 0.0.0.0:0 LISTENING 6847\n \n macOS Monterey and later automatically starts a service that uses port\n-5000. To disable the service, go to System Preferences, Sharing, and\n-disable \"AirPlay Receiver\".\n+5000. You can choose to disable this service instead of using a different port by\n+searching for \"AirPlay Receiver\" in System Preferences and toggling it off.\n \n \n Deferred Errors on Reload",
        "sim_diff_0": "diff --git a/home.admin/config.scripts/lnd.setport.sh b/home.admin/config.scripts/lnd.setport.sh #!/bin/bash\n# based on: https://github.com/rootzoll/raspiblitz/issues/100#issuecomment-465997126\n+# based on: https://github.com/rootzoll/raspiblitz/issues/386\nif [ $# -eq 0 ]; then\necho \"small config script set the port LND is running on\"\n@@ -62,6 +63,16 @@ sudo systemctl disable lnd\necho \"change port in lnd config\"\nsudo sed -i \"s/^listen=.*/listen=0.0.0.0:${portnumber}/g\" /mnt/hdd/lnd/lnd.conf\n+# add to raspiblitz.config (so it can survive update)\n+valueExists=$(sudo cat /mnt/hdd/raspiblitz.conf | grep -c 'customPortLND=')\n+if [ ${valueExists} -eq 0 ]; then\n+ # add as new value\n+ echo \"customPortLND=${portnumber}\" >> /mnt/hdd/raspiblitz.conf\n+else\n+ # update existing value\n+ sudo sed -i \"s/^customPortLND=.*/customPortLND=${portnumber}/g\" /mnt/hdd/raspiblitz.conf\n+fi\n+\n# editing service file\necho \"editing /etc/systemd/system/lnd.service\"\nsudo sed -i \"s/^ExecStart=\\/usr\\/local\\/bin\\/lnd.*/ExecStart=\\/usr\\/local\\/bin\\/lnd --externalip=\\${publicIP}:${portnumber}/g\" /etc/systemd/system/lnd.service\n",
        "sim_msg_0": "set custom LND port",
        "sim_diff_1": "diff --git a/home.admin/97addMobileWalletZap.sh b/home.admin/97addMobileWalletZap.sh @@ -77,7 +77,21 @@ else\nlndconnect --host=${dynDomain}\nfi\n-echo \"(To shrink QR code: OSX->CMD- / LINUX-> CTRL-) Press ENTER when finished.\"\n+\n+platform='unknown'\n+unamestr=`uname`\n+if [[ \"$unamestr\" == 'Linux' ]]; then\n+ platform='linux'\n+elif [[ \"$unamestr\" == 'Darwin' ]]; then\n+ platform='Darwin' # mac OSX\n+fi\n+\n+if [[ $platform == 'Linux' ]]; then\n+ echo \"(To shrink QR code: CTRL-) Press ENTER when finished.\"\n+elif [[ $platform == 'Darwin' ]]; then\n+ echo \"(To shrink QR code: CMD-) Press ENTER when finished.\"\n+fi\n+\nread key\nclear\n",
        "sim_msg_1": "detect os and print corresponding QR command",
        "sim_diff_2": "diff --git a/home.admin/00settingsMenuServices.sh b/home.admin/00settingsMenuServices.sh @@ -9,9 +9,10 @@ CHOICES=$(dialog --checklist \"Activate/Deactivate Services:\" 15 40 5 \\\n2>&1 >/dev/tty)\n#CHOICES=$(dialog --checklist \"Activate/Deactivate Services:\" 15 40 5 \\\n#1 \"Channel Autopilot\" ${autoPilot} \\\n-#2 \"Seed Torrent Blockchain\" ${torrentSeeding} \\\n-#3 \"RTL Webinterface\" ${rtlWebinterface} \\\n-#4 \"Electrum Server\" ${electrumServer} \\\n+#2 \"UPnP Router-Portforwarding\" ${natUPnP} \\\n+#3 \"Auto Unlock on Start\" ${autoUnlock} \\\n+#4 \"Seed Torrent Blockchain\" ${torrentSeed} \\\n+#4 \"RTL Webinterface\" ${rtlWebinterface} \\\n#2>&1 >/dev/tty)\ndialogcancel=$?\nclear\n@@ -27,21 +28,6 @@ choice=\"off\"; check=$(echo \"${CHOICES}\" | grep -c \"1\")\nif [ ${check} -eq 1 ]; then choice=\"on\"; fi\nsudo sed -i \"s/^autoPilot=.*/autoPilot=${choice}/g\" /mnt/hdd/raspiblitz.conf\n-# TORRENTSEED process choice\n-#choice=\"off\"; check=$(echo \"${CHOICES}\" | grep -c \"2\")\n-#if [ ${check} -eq 1 ]; then choice=\"on\"; fi\n-#sudo sed -i \"s/^torrentSeeding=.*/torrentSeeding=${choice}/g\" /mnt/hdd/raspiblitz.conf\n-\n-# RTLWEBINTERFACE process choice\n-#choice=\"off\"; check=$(echo \"${CHOICES}\" | grep -c \"3\")\n-#if [ ${check} -eq 1 ]; then choice=\"on\"; fi\n-#sudo sed -i \"s/^rtlWebinterface=.*/rtlWebinterface=${choice}/g\" /mnt/hdd/raspiblitz.conf\n-\n-# ELECTRUMSERVER process choice\n-#choice=\"off\"; check=$(echo \"${CHOICES}\" | grep -c \"4\")\n-#if [ ${check} -eq 1 ]; then choice=\"on\"; fi\n-#sudo sed -i \"s/^electrumServer=.*/electrumServer=${choice}/g\" /mnt/hdd/raspiblitz.conf\n-\n# confirm reboot to activate new settings with bootstrap.service\ndialog --backtitle \"Rebooting\" --yesno \"To activate the settings a reboot is needed.\" 6 52\nif [ $? -eq 0 ];then\n",
        "sim_msg_2": "service setting ideas",
        "sim_diff_3": "diff --git a/common/run_presenter_server.sh b/common/run_presenter_server.sh @@ -6,6 +6,7 @@ app_name=\"display\"\npresenter_connect_ip=\"\"\npresenter_view_ip=\"\"\n+presenter_server_port=\"\"\nfunction check_config_file()\n{\n@@ -46,6 +47,7 @@ function check_ip_addr()\nreturn 0\n}\n+\nfunction check_python3_lib()\n{\necho \"Check python3 libs ......\"\n@@ -137,6 +139,33 @@ function check_ip()\n}\n+function check_port()\n+{\n+ presenter_server_port=$(cat ${config_file} | grep \"presenter_server_port\" | awk -F'[ =]+' '{print $2}')\n+ presenter_server_port=$(echo $presenter_server_port | sed -e 's/\\r//' | sed -e 's/\\n//' | sed -e 's/ //')\n+ if [[ \"$presenter_server_port\" = \"\" ]];then\n+ echo \"please check your param.conf to make sure that each parameter has a value\"\n+ return 1\n+ fi\n+ check_port_legal $presenter_server_port\n+ if [ $? -ne 0 ];then\n+ echo \"ERROR: invalid presenter_server_port port, please check your settings in configuration file\"\n+ return 1\n+ fi\n+\n+\n+\n+}\n+\n+function check_port_legal()\n+{\n+ if grep '^[[:digit:]]*$' <<< \"$1\";then\n+ return 0\n+ else\n+ return 1\n+ fi\n+}\n+\nfunction main()\n{\ncheck_config_file $config_file\n@@ -157,9 +186,11 @@ function main()\nfi\ncheck_ip\n+ check_port\n- echo \"Use ${presenter_connect_ip} to connect to Atlas...\"\n+ echo \"Use ${presenter_connect_ip}:${presenter_server_port} to connect to Atlas...\"\nsed -i \"s/presenter_server_ip=[0-9.]*/presenter_server_ip=${presenter_connect_ip}/g\" ${cur_path}/presenterserver/${app_name}/config/config.conf\n+ sed -i \"s/presenter_server_port=[0-9]*/presenter_server_port=${presenter_server_port}/g\" ${cur_path}/presenterserver/${app_name}/config/config.conf\necho \"Use ${presenter_view_ip} to show information in browser...\"\nsed -i \"s/web_server_ip=[0-9.]*/web_server_ip=${presenter_view_ip}/g\" ${cur_path}/presenterserver/${app_name}/config/config.conf\n",
        "sim_msg_3": "update common/run_presenter_server.sh."
    },
    {
        "org_diff": "diff --git a/docs/server.rst b/a/docs/server.rst @@ -76,8 +76,8 @@ following example shows that process id 6847 is using port 5000.\n             TCP 127.0.0.1:5000 0.0.0.0:0 LISTENING 6847\n \n macOS Monterey and later automatically starts a service that uses port\n-5000. To disable the service, go to System Preferences, Sharing, and\n-disable \"AirPlay Receiver\".\n+5000. You can choose to disable this service instead of using a different port by\n+searching for \"AirPlay Receiver\" in System Preferences and toggling it off.\n \n \n Deferred Errors on Reload",
        "sim_diff_0": "diff --git a/home.admin/config.scripts/lnd.setport.sh b/home.admin/config.scripts/lnd.setport.sh #!/bin/bash\n# based on: https://github.com/rootzoll/raspiblitz/issues/100#issuecomment-465997126\n+# based on: https://github.com/rootzoll/raspiblitz/issues/386\nif [ $# -eq 0 ]; then\necho \"small config script set the port LND is running on\"\n@@ -62,6 +63,16 @@ sudo systemctl disable lnd\necho \"change port in lnd config\"\nsudo sed -i \"s/^listen=.*/listen=0.0.0.0:${portnumber}/g\" /mnt/hdd/lnd/lnd.conf\n+# add to raspiblitz.config (so it can survive update)\n+valueExists=$(sudo cat /mnt/hdd/raspiblitz.conf | grep -c 'customPortLND=')\n+if [ ${valueExists} -eq 0 ]; then\n+ # add as new value\n+ echo \"customPortLND=${portnumber}\" >> /mnt/hdd/raspiblitz.conf\n+else\n+ # update existing value\n+ sudo sed -i \"s/^customPortLND=.*/customPortLND=${portnumber}/g\" /mnt/hdd/raspiblitz.conf\n+fi\n+\n# editing service file\necho \"editing /etc/systemd/system/lnd.service\"\nsudo sed -i \"s/^ExecStart=\\/usr\\/local\\/bin\\/lnd.*/ExecStart=\\/usr\\/local\\/bin\\/lnd --externalip=\\${publicIP}:${portnumber}/g\" /etc/systemd/system/lnd.service\n",
        "sim_msg_0": "set custom LND port",
        "sim_diff_1": "diff --git a/home.admin/97addMobileWalletZap.sh b/home.admin/97addMobileWalletZap.sh @@ -77,7 +77,21 @@ else\nlndconnect --host=${dynDomain}\nfi\n-echo \"(To shrink QR code: OSX->CMD- / LINUX-> CTRL-) Press ENTER when finished.\"\n+\n+platform='unknown'\n+unamestr=`uname`\n+if [[ \"$unamestr\" == 'Linux' ]]; then\n+ platform='linux'\n+elif [[ \"$unamestr\" == 'Darwin' ]]; then\n+ platform='Darwin' # mac OSX\n+fi\n+\n+if [[ $platform == 'Linux' ]]; then\n+ echo \"(To shrink QR code: CTRL-) Press ENTER when finished.\"\n+elif [[ $platform == 'Darwin' ]]; then\n+ echo \"(To shrink QR code: CMD-) Press ENTER when finished.\"\n+fi\n+\nread key\nclear\n",
        "sim_msg_1": "detect os and print corresponding QR command",
        "sim_diff_2": "diff --git a/home.admin/00settingsMenuServices.sh b/home.admin/00settingsMenuServices.sh @@ -9,9 +9,10 @@ CHOICES=$(dialog --checklist \"Activate/Deactivate Services:\" 15 40 5 \\\n2>&1 >/dev/tty)\n#CHOICES=$(dialog --checklist \"Activate/Deactivate Services:\" 15 40 5 \\\n#1 \"Channel Autopilot\" ${autoPilot} \\\n-#2 \"Seed Torrent Blockchain\" ${torrentSeeding} \\\n-#3 \"RTL Webinterface\" ${rtlWebinterface} \\\n-#4 \"Electrum Server\" ${electrumServer} \\\n+#2 \"UPnP Router-Portforwarding\" ${natUPnP} \\\n+#3 \"Auto Unlock on Start\" ${autoUnlock} \\\n+#4 \"Seed Torrent Blockchain\" ${torrentSeed} \\\n+#4 \"RTL Webinterface\" ${rtlWebinterface} \\\n#2>&1 >/dev/tty)\ndialogcancel=$?\nclear\n@@ -27,21 +28,6 @@ choice=\"off\"; check=$(echo \"${CHOICES}\" | grep -c \"1\")\nif [ ${check} -eq 1 ]; then choice=\"on\"; fi\nsudo sed -i \"s/^autoPilot=.*/autoPilot=${choice}/g\" /mnt/hdd/raspiblitz.conf\n-# TORRENTSEED process choice\n-#choice=\"off\"; check=$(echo \"${CHOICES}\" | grep -c \"2\")\n-#if [ ${check} -eq 1 ]; then choice=\"on\"; fi\n-#sudo sed -i \"s/^torrentSeeding=.*/torrentSeeding=${choice}/g\" /mnt/hdd/raspiblitz.conf\n-\n-# RTLWEBINTERFACE process choice\n-#choice=\"off\"; check=$(echo \"${CHOICES}\" | grep -c \"3\")\n-#if [ ${check} -eq 1 ]; then choice=\"on\"; fi\n-#sudo sed -i \"s/^rtlWebinterface=.*/rtlWebinterface=${choice}/g\" /mnt/hdd/raspiblitz.conf\n-\n-# ELECTRUMSERVER process choice\n-#choice=\"off\"; check=$(echo \"${CHOICES}\" | grep -c \"4\")\n-#if [ ${check} -eq 1 ]; then choice=\"on\"; fi\n-#sudo sed -i \"s/^electrumServer=.*/electrumServer=${choice}/g\" /mnt/hdd/raspiblitz.conf\n-\n# confirm reboot to activate new settings with bootstrap.service\ndialog --backtitle \"Rebooting\" --yesno \"To activate the settings a reboot is needed.\" 6 52\nif [ $? -eq 0 ];then\n",
        "sim_msg_2": "service setting ideas",
        "sim_diff_3": "diff --git a/common/run_presenter_server.sh b/common/run_presenter_server.sh @@ -6,6 +6,7 @@ app_name=\"display\"\npresenter_connect_ip=\"\"\npresenter_view_ip=\"\"\n+presenter_server_port=\"\"\nfunction check_config_file()\n{\n@@ -46,6 +47,7 @@ function check_ip_addr()\nreturn 0\n}\n+\nfunction check_python3_lib()\n{\necho \"Check python3 libs ......\"\n@@ -137,6 +139,33 @@ function check_ip()\n}\n+function check_port()\n+{\n+ presenter_server_port=$(cat ${config_file} | grep \"presenter_server_port\" | awk -F'[ =]+' '{print $2}')\n+ presenter_server_port=$(echo $presenter_server_port | sed -e 's/\\r//' | sed -e 's/\\n//' | sed -e 's/ //')\n+ if [[ \"$presenter_server_port\" = \"\" ]];then\n+ echo \"please check your param.conf to make sure that each parameter has a value\"\n+ return 1\n+ fi\n+ check_port_legal $presenter_server_port\n+ if [ $? -ne 0 ];then\n+ echo \"ERROR: invalid presenter_server_port port, please check your settings in configuration file\"\n+ return 1\n+ fi\n+\n+\n+\n+}\n+\n+function check_port_legal()\n+{\n+ if grep '^[[:digit:]]*$' <<< \"$1\";then\n+ return 0\n+ else\n+ return 1\n+ fi\n+}\n+\nfunction main()\n{\ncheck_config_file $config_file\n@@ -157,9 +186,11 @@ function main()\nfi\ncheck_ip\n+ check_port\n- echo \"Use ${presenter_connect_ip} to connect to Atlas...\"\n+ echo \"Use ${presenter_connect_ip}:${presenter_server_port} to connect to Atlas...\"\nsed -i \"s/presenter_server_ip=[0-9.]*/presenter_server_ip=${presenter_connect_ip}/g\" ${cur_path}/presenterserver/${app_name}/config/config.conf\n+ sed -i \"s/presenter_server_port=[0-9]*/presenter_server_port=${presenter_server_port}/g\" ${cur_path}/presenterserver/${app_name}/config/config.conf\necho \"Use ${presenter_view_ip} to show information in browser...\"\nsed -i \"s/web_server_ip=[0-9.]*/web_server_ip=${presenter_view_ip}/g\" ${cur_path}/presenterserver/${app_name}/config/config.conf\n",
        "sim_msg_3": "update common/run_presenter_server.sh."
    },
    {
        "org_diff": "diff --git a/.pre-commit-config.yaml b/a/.pre-commit-config.yaml @@ -2,7 +2,7 @@ ci:\n   autoupdate_schedule: monthly\n repos:\n   - repo: https://github.com/astral-sh/ruff-pre-commit\n-    rev: v0.1.5\n+    rev: v0.1.6\n     hooks:\n       - id: ruff\n       - id: ruff-format",
        "sim_diff_0": "diff --git a/.pre-commit-config.yaml b/.pre-commit-config.yaml @@ -27,6 +27,7 @@ repos:\nhooks:\n- id: black\nlanguage_version: python3\n+ additional_dependencies: ['click==8.0.4']\n- repo: https://github.com/pre-commit/mirrors-isort\nrev: v4.3.21\nhooks:\n",
        "sim_msg_0": "add pre_commit dependency for pre_commit for black, click version compatability",
        "sim_diff_1": "diff --git a/.pre-commit-config.yaml b/.pre-commit-config.yaml @@ -6,11 +6,11 @@ repos:\nhooks:\n- id: isort\n- repo: https://github.com/psf/black\n- rev: 22.6.0\n+ rev: 22.10.0\nhooks:\n- id: black\n- repo: https://github.com/PyCQA/flake8\n- rev: 5.0.3\n+ rev: 5.0.4\nhooks:\n- id: flake8\n- repo: https://github.com/pre-commit/pre-commit-hooks\n",
        "sim_msg_1": "Update precommit dependencies",
        "sim_diff_2": "diff --git a/.pre-commit-config.yaml b/.pre-commit-config.yaml @@ -5,7 +5,7 @@ default_language_version:\nrepos:\n- repo: https://github.com/psf/black\n- rev: 21.12b0\n+ rev: 22.1.0\nhooks:\n- id: black\n@@ -39,6 +39,6 @@ repos:\n- --ignore-init-module-imports\n- repo: https://github.com/pre-commit/mirrors-mypy\n- rev: v0.930\n+ rev: v0.931\nhooks:\n- id: mypy\n",
        "sim_msg_2": "Update black and mypy versions in pre-commit yaml",
        "sim_diff_3": "diff --git a/.pre-commit-config.yaml b/.pre-commit-config.yaml @@ -8,10 +8,13 @@ repos:\nrev: v0.740\nhooks:\n- id: mypy\n+- repo: https://gitlab.com/pycqa/flake8\n+ rev: 3.7.9\n+ hooks:\n+ - id: flake8\n- repo: https://github.com/pre-commit/pre-commit-hooks\nrev: v2.4.0\nhooks:\n- - id: flake8\n- id: check-toml\n- id: check-yaml\n- repo: https://github.com/asottile/seed-isort-config\n",
        "sim_msg_3": "Switch to main flake8 repo to install pre-commit hook"
    },
    {
        "org_diff": "diff --git a/.pre-commit-config.yaml b/a/.pre-commit-config.yaml @@ -2,7 +2,7 @@ ci:\n   autoupdate_schedule: monthly\n repos:\n   - repo: https://github.com/astral-sh/ruff-pre-commit\n-    rev: v0.1.5\n+    rev: v0.1.6\n     hooks:\n       - id: ruff\n       - id: ruff-format",
        "sim_diff_0": "diff --git a/.pre-commit-config.yaml b/.pre-commit-config.yaml @@ -27,6 +27,7 @@ repos:\nhooks:\n- id: black\nlanguage_version: python3\n+ additional_dependencies: ['click==8.0.4']\n- repo: https://github.com/pre-commit/mirrors-isort\nrev: v4.3.21\nhooks:\n",
        "sim_msg_0": "add pre_commit dependency for pre_commit for black, click version compatability",
        "sim_diff_1": "diff --git a/.pre-commit-config.yaml b/.pre-commit-config.yaml @@ -6,11 +6,11 @@ repos:\nhooks:\n- id: isort\n- repo: https://github.com/psf/black\n- rev: 22.6.0\n+ rev: 22.10.0\nhooks:\n- id: black\n- repo: https://github.com/PyCQA/flake8\n- rev: 5.0.3\n+ rev: 5.0.4\nhooks:\n- id: flake8\n- repo: https://github.com/pre-commit/pre-commit-hooks\n",
        "sim_msg_1": "Update precommit dependencies",
        "sim_diff_2": "diff --git a/.pre-commit-config.yaml b/.pre-commit-config.yaml @@ -5,7 +5,7 @@ default_language_version:\nrepos:\n- repo: https://github.com/psf/black\n- rev: 21.12b0\n+ rev: 22.1.0\nhooks:\n- id: black\n@@ -39,6 +39,6 @@ repos:\n- --ignore-init-module-imports\n- repo: https://github.com/pre-commit/mirrors-mypy\n- rev: v0.930\n+ rev: v0.931\nhooks:\n- id: mypy\n",
        "sim_msg_2": "Update black and mypy versions in pre-commit yaml",
        "sim_diff_3": "diff --git a/.pre-commit-config.yaml b/.pre-commit-config.yaml @@ -8,10 +8,13 @@ repos:\nrev: v0.740\nhooks:\n- id: mypy\n+- repo: https://gitlab.com/pycqa/flake8\n+ rev: 3.7.9\n+ hooks:\n+ - id: flake8\n- repo: https://github.com/pre-commit/pre-commit-hooks\nrev: v2.4.0\nhooks:\n- - id: flake8\n- id: check-toml\n- id: check-yaml\n- repo: https://github.com/asottile/seed-isort-config\n",
        "sim_msg_3": "Switch to main flake8 repo to install pre-commit hook"
    },
    {
        "org_diff": "diff --git a/.pre-commit-config.yaml b/a/.pre-commit-config.yaml @@ -2,12 +2,12 @@ ci:\n   autoupdate_schedule: monthly\n repos:\n   - repo: https://github.com/astral-sh/ruff-pre-commit\n-    rev: v0.1.3\n+    rev: v0.1.5\n     hooks:\n       - id: ruff\n       - id: ruff-format\n   - repo: https://github.com/pre-commit/pre-commit-hooks\n-    rev: v4.4.0\n+    rev: v4.5.0\n     hooks:\n       - id: check-merge-conflict\n       - id: debug-statements",
        "sim_diff_0": "diff --git a/.pre-commit-config.yaml b/.pre-commit-config.yaml @@ -6,11 +6,11 @@ repos:\nhooks:\n- id: isort\n- repo: https://github.com/psf/black\n- rev: 22.6.0\n+ rev: 22.10.0\nhooks:\n- id: black\n- repo: https://github.com/PyCQA/flake8\n- rev: 5.0.3\n+ rev: 5.0.4\nhooks:\n- id: flake8\n- repo: https://github.com/pre-commit/pre-commit-hooks\n",
        "sim_msg_0": "Update precommit dependencies",
        "sim_diff_1": "diff --git a/.pre-commit-config.yaml b/.pre-commit-config.yaml @@ -17,7 +17,7 @@ repos:\n- repo: https://github.com/python-jsonschema/check-jsonschema\nrev: 0.19.2\nhooks:\n- - id: check-github-actions\n+ - id: check-github-workflows\n- id: check-dependabot\n- repo: https://github.com/pre-commit/mirrors-prettier\nrev: v3.0.0-alpha.4\n@@ -28,6 +28,10 @@ repos:\nrev: 5.11.4\nhooks:\n- id: isort\n+ - repo: https://github.com/PyCQA/autoflake\n+ rev: v2.0.0\n+ hooks:\n+ - id: autoflake\n- repo: https://github.com/psf/black\nrev: 22.12.0\nhooks:\n@@ -46,6 +50,6 @@ repos:\nhooks:\n- id: mypy\nadditional_dependencies:\n- - types-PyYAML==6.0.6\n- - types-mock==4.0.13\n- - pytest==7.1.1\n+ - types-PyYAML==6.0.12\n+ - types-mock==4.0.15\n+ - pytest==7.2.0\n",
        "sim_msg_1": "build: fix pre-commit hooks",
        "sim_diff_2": "diff --git a/.pre-commit-config.yaml b/.pre-commit-config.yaml @@ -8,10 +8,13 @@ repos:\nrev: v0.740\nhooks:\n- id: mypy\n+- repo: https://gitlab.com/pycqa/flake8\n+ rev: 3.7.9\n+ hooks:\n+ - id: flake8\n- repo: https://github.com/pre-commit/pre-commit-hooks\nrev: v2.4.0\nhooks:\n- - id: flake8\n- id: check-toml\n- id: check-yaml\n- repo: https://github.com/asottile/seed-isort-config\n",
        "sim_msg_2": "Switch to main flake8 repo to install pre-commit hook",
        "sim_diff_3": "diff --git a/.pre-commit-config.yaml b/.pre-commit-config.yaml @@ -16,16 +16,16 @@ repos:\n- id: check-merge-conflict\n- id: debug-statements\n- repo: https://github.com/timothycrosley/isort\n- rev: 5.8.0\n+ rev: 5.9.1\nhooks:\n- id: isort\n- repo: https://github.com/asottile/pyupgrade\n- rev: v2.16.0\n+ rev: v2.19.4\nhooks:\n- id: pyupgrade\nargs: [--py36-plus]\n- repo: https://github.com/pre-commit/pygrep-hooks\n- rev: v1.8.0\n+ rev: v1.9.0\nhooks:\n- id: python-no-eval\n- id: python-check-blanket-noqa\n@@ -34,7 +34,7 @@ repos:\n- id: rst-directive-colons\n- id: rst-inline-touching-normal\n- repo: https://github.com/psf/black\n- rev: 21.5b1\n+ rev: 21.6b0\nhooks:\n- id: black\nargs: [--safe, --quiet, --target-version=py36]\n@@ -44,6 +44,7 @@ repos:\n- id: flake8\nadditional_dependencies: [flake8-bugbear]\n- repo: https://github.com/pre-commit/mirrors-mypy\n- rev: 'v0.812'\n+ rev: 'v0.910'\nhooks:\n- id: mypy\n+ additional_dependencies: [types-python-dateutil]\n",
        "sim_msg_3": "Improve _format_timeframe type annotations and update pre-commit dependencies."
    },
    {
        "org_diff": "diff --git a/.pre-commit-config.yaml b/a/.pre-commit-config.yaml @@ -2,12 +2,12 @@ ci:\n   autoupdate_schedule: monthly\n repos:\n   - repo: https://github.com/astral-sh/ruff-pre-commit\n-    rev: v0.1.3\n+    rev: v0.1.5\n     hooks:\n       - id: ruff\n       - id: ruff-format\n   - repo: https://github.com/pre-commit/pre-commit-hooks\n-    rev: v4.4.0\n+    rev: v4.5.0\n     hooks:\n       - id: check-merge-conflict\n       - id: debug-statements",
        "sim_diff_0": "diff --git a/.pre-commit-config.yaml b/.pre-commit-config.yaml @@ -6,11 +6,11 @@ repos:\nhooks:\n- id: isort\n- repo: https://github.com/psf/black\n- rev: 22.6.0\n+ rev: 22.10.0\nhooks:\n- id: black\n- repo: https://github.com/PyCQA/flake8\n- rev: 5.0.3\n+ rev: 5.0.4\nhooks:\n- id: flake8\n- repo: https://github.com/pre-commit/pre-commit-hooks\n",
        "sim_msg_0": "Update precommit dependencies",
        "sim_diff_1": "diff --git a/.pre-commit-config.yaml b/.pre-commit-config.yaml @@ -17,7 +17,7 @@ repos:\n- repo: https://github.com/python-jsonschema/check-jsonschema\nrev: 0.19.2\nhooks:\n- - id: check-github-actions\n+ - id: check-github-workflows\n- id: check-dependabot\n- repo: https://github.com/pre-commit/mirrors-prettier\nrev: v3.0.0-alpha.4\n@@ -28,6 +28,10 @@ repos:\nrev: 5.11.4\nhooks:\n- id: isort\n+ - repo: https://github.com/PyCQA/autoflake\n+ rev: v2.0.0\n+ hooks:\n+ - id: autoflake\n- repo: https://github.com/psf/black\nrev: 22.12.0\nhooks:\n@@ -46,6 +50,6 @@ repos:\nhooks:\n- id: mypy\nadditional_dependencies:\n- - types-PyYAML==6.0.6\n- - types-mock==4.0.13\n- - pytest==7.1.1\n+ - types-PyYAML==6.0.12\n+ - types-mock==4.0.15\n+ - pytest==7.2.0\n",
        "sim_msg_1": "build: fix pre-commit hooks",
        "sim_diff_2": "diff --git a/.pre-commit-config.yaml b/.pre-commit-config.yaml @@ -8,10 +8,13 @@ repos:\nrev: v0.740\nhooks:\n- id: mypy\n+- repo: https://gitlab.com/pycqa/flake8\n+ rev: 3.7.9\n+ hooks:\n+ - id: flake8\n- repo: https://github.com/pre-commit/pre-commit-hooks\nrev: v2.4.0\nhooks:\n- - id: flake8\n- id: check-toml\n- id: check-yaml\n- repo: https://github.com/asottile/seed-isort-config\n",
        "sim_msg_2": "Switch to main flake8 repo to install pre-commit hook",
        "sim_diff_3": "diff --git a/.pre-commit-config.yaml b/.pre-commit-config.yaml @@ -16,16 +16,16 @@ repos:\n- id: check-merge-conflict\n- id: debug-statements\n- repo: https://github.com/timothycrosley/isort\n- rev: 5.8.0\n+ rev: 5.9.1\nhooks:\n- id: isort\n- repo: https://github.com/asottile/pyupgrade\n- rev: v2.16.0\n+ rev: v2.19.4\nhooks:\n- id: pyupgrade\nargs: [--py36-plus]\n- repo: https://github.com/pre-commit/pygrep-hooks\n- rev: v1.8.0\n+ rev: v1.9.0\nhooks:\n- id: python-no-eval\n- id: python-check-blanket-noqa\n@@ -34,7 +34,7 @@ repos:\n- id: rst-directive-colons\n- id: rst-inline-touching-normal\n- repo: https://github.com/psf/black\n- rev: 21.5b1\n+ rev: 21.6b0\nhooks:\n- id: black\nargs: [--safe, --quiet, --target-version=py36]\n@@ -44,6 +44,7 @@ repos:\n- id: flake8\nadditional_dependencies: [flake8-bugbear]\n- repo: https://github.com/pre-commit/mirrors-mypy\n- rev: 'v0.812'\n+ rev: 'v0.910'\nhooks:\n- id: mypy\n+ additional_dependencies: [types-python-dateutil]\n",
        "sim_msg_3": "Improve _format_timeframe type annotations and update pre-commit dependencies."
    },
    {
        "org_diff": "diff --git a/.github/workflows/tests.yaml b/a/.github/workflows/tests.yaml @@ -9,9 +9,6 @@ on:\n       - '*.md'\n       - '*.rst'\n   pull_request:\n-    branches:\n-      - main\n-      - '*.x'\n     paths-ignore:\n       - 'docs/**'\n       - '*.md'\n@@ -24,17 +21,17 @@ jobs:\n       fail-fast: false\n       matrix:\n         include:\n-          - {name: Linux, python: '3.11', os: ubuntu-latest, tox: py311}\n-          - {name: Windows, python: '3.11', os: windows-latest, tox: py311}\n-          - {name: Mac, python: '3.11', os: macos-latest, tox: py311}\n-          - {name: '3.12-dev', python: '3.12-dev', os: ubuntu-latest, tox: py312}\n+          - {name: Linux, python: '3.12', os: ubuntu-latest, tox: py312}\n+          - {name: Windows, python: '3.12', os: windows-latest, tox: py312}\n+          - {name: Mac, python: '3.12', os: macos-latest, tox: py312}\n+          - {name: '3.11', python: '3.11', os: ubuntu-latest, tox: py311}\n           - {name: '3.10', python: '3.10', os: ubuntu-latest, tox: py310}\n           - {name: '3.9', python: '3.9', os: ubuntu-latest, tox: py39}\n           - {name: '3.8', python: '3.8', os: ubuntu-latest, tox: py38}\n           - {name: 'PyPy', python: 'pypy-3.10', os: ubuntu-latest, tox: pypy310}\n-          - {name: 'Minimum Versions', python: '3.11', os: ubuntu-latest, tox: py311-min}\n+          - {name: 'Minimum Versions', python: '3.12', os: ubuntu-latest, tox: py312-min}\n           - {name: 'Development Versions', python: '3.8', os: ubuntu-latest, tox: py38-dev}\n-          - {name: Typing, python: '3.11', os: ubuntu-latest, tox: typing}\n+          - {name: Typing, python: '3.12', os: ubuntu-latest, tox: typing}\n     steps:\n       - uses: actions/checkout@f43a0e5ff2bd294095638e18286ca9a3d1956744\n       - uses: actions/setup-python@61a6322f88396a6271a6ee3565807d608ecaddd1",
        "sim_diff_0": "diff --git a/{{cookiecutter.project_name}}/.github/workflows/tests.yml b/{{cookiecutter.project_name}}/.github/workflows/tests.yml @@ -12,21 +12,33 @@ jobs:\nfail-fast: false\nmatrix:\ninclude:\n- - { python-version: \"3.10\", os: ubuntu-latest, session: \"pre-commit\" }\n- - { python-version: \"3.10\", os: ubuntu-latest, session: \"safety\" }\n- - { python-version: \"3.10\", os: ubuntu-latest, session: \"mypy\" }\n- - { python-version: 3.9, os: ubuntu-latest, session: \"mypy\" }\n- - { python-version: 3.8, os: ubuntu-latest, session: \"mypy\" }\n- - { python-version: 3.7, os: ubuntu-latest, session: \"mypy\" }\n- - { python-version: \"3.10\", os: ubuntu-latest, session: \"tests\" }\n- - { python-version: 3.9, os: ubuntu-latest, session: \"tests\" }\n- - { python-version: 3.8, os: ubuntu-latest, session: \"tests\" }\n- - { python-version: 3.7, os: ubuntu-latest, session: \"tests\" }\n- - { python-version: \"3.10\", os: windows-latest, session: \"tests\" }\n- - { python-version: \"3.10\", os: macos-latest, session: \"tests\" }\n- - { python-version: \"3.10\", os: ubuntu-latest, session: \"typeguard\" }\n- - { python-version: \"3.10\", os: ubuntu-latest, session: \"xdoctest\" }\n- - { python-version: \"3.10\", os: ubuntu-latest, session: \"docs-build\" }\n+ - {\n+ python-version: \"3.10\",\n+ os: \"ubuntu-latest\",\n+ session: \"pre-commit\",\n+ }\n+ - { python-version: \"3.10\", os: \"ubuntu-latest\", session: \"safety\" }\n+ - { python-version: \"3.10\", os: \"ubuntu-latest\", session: \"mypy\" }\n+ - { python-version: \"3.9\", os: \"ubuntu-latest\", session: \"mypy\" }\n+ - { python-version: \"3.8\", os: \"ubuntu-latest\", session: \"mypy\" }\n+ - { python-version: \"3.7\", os: \"ubuntu-latest\", session: \"mypy\" }\n+ - { python-version: \"3.10\", os: \"ubuntu-latest\", session: \"tests\" }\n+ - { python-version: \"3.9\", os: \"ubuntu-latest\", session: \"tests\" }\n+ - { python-version: \"3.8\", os: \"ubuntu-latest\", session: \"tests\" }\n+ - { python-version: \"3.7\", os: \"ubuntu-latest\", session: \"tests\" }\n+ - { python-version: \"3.10\", os: \"windows-latest\", session: \"tests\" }\n+ - { python-version: \"3.10\", os: \"macos-latest\", session: \"tests\" }\n+ - {\n+ python-version: \"3.10\",\n+ os: \"ubuntu-latest\",\n+ session: \"typeguard\",\n+ }\n+ - { python-version: \"3.10\", os: \"ubuntu-latest\", session: \"xdoctest\" }\n+ - {\n+ python-version: \"3.10\",\n+ os: \"ubuntu-latest\",\n+ session: \"docs-build\",\n+ }\nenv:\nNOXSESSION: {{ \"${{ matrix.session }}\" }}\n@@ -105,10 +117,10 @@ jobs:\n- name: Check out the repository\nuses: actions/checkout@v2.4.0\n- - name: Set up Python 3.9\n+ - name: Set up Python\nuses: actions/setup-python@v2.3.0\nwith:\n- python-version: 3.9\n+ python-version: \"3.10\"\n- name: Upgrade pip\nrun: |\n",
        "sim_msg_0": "Update test GA workflow for more consistent style\n* Update test GA workflow for more consistent style\n* Fix prettier formatting\nRetrocookie-Original-Commit:",
        "sim_diff_1": "diff --git a/.github/workflows/test.yml b/.github/workflows/test.yml @@ -2,10 +2,12 @@ name: Tests\non: [pull_request, push]\njobs:\ntests:\n- runs-on: ubuntu-latest\n+ runs-on: ${{ matrix.os }}\nstrategy:\n+ fail-fast: false\nmatrix:\npython-version: ['3.6.13', '3.7', '3.8']\n+ os: [ubuntu-latest, macos-latest, windows-latest]\nname: Python ${{ matrix.python-version }}\nsteps:\n- name: Checkout Code\n",
        "sim_msg_1": "change tests to run on windows and mac.",
        "sim_diff_2": "diff --git a/.github/workflows/tests.yml b/.github/workflows/tests.yml @@ -6,6 +6,11 @@ on:\nbranches:\n- master\npull_request:\n+ types:\n+ - opened\n+ - reopened\n+ - synchronize\n+ - ready_for_review\npaths:\n- '**/*.py'\n- '**/*.yml'\n",
        "sim_msg_2": "make 'ready for review' an event that triggers the tests",
        "sim_diff_3": "diff --git a/.github/workflows/tests.yml b/.github/workflows/tests.yml @@ -5,8 +5,10 @@ on:\nbranches:\n- master\npaths:\n+ - .github/workflows/tests.yml\n- httpie/**/*.py\n- setup.*\n+ - tests/**/*.py\npull_request:\npaths:\n- .github/workflows/tests.yml\n",
        "sim_msg_3": "Add self to paths; same paths for PR and push"
    },
    {
        "org_diff": "diff --git a/.readthedocs.yaml b/a/.readthedocs.yaml @@ -1,8 +1,8 @@\n version: 2\n build:\n-  os: ubuntu-20.04\n+  os: ubuntu-22.04\n   tools:\n-    python: \"3.10\"\n+    python: \"3.12\"\n python:\n   install:\n     - requirements: requirements/docs.txt",
        "sim_diff_0": "diff --git a/requirements.txt b/requirements.txt @@ -52,7 +52,7 @@ pyyaml==4.2b4\nredis==2.10.6\nrequests==2.20.1\nsix==1.12.0 # via altair, bcrypt, cryptography, flask-restful, jsonschema, pyrsistent, python-dateutil\n-sqlalchemy==1.3.0\n+sqlalchemy==1.3.2\ntoolz==0.9.0 # via altair\ntyping==3.6.6 # via altair\nurllib3==1.24.2\n",
        "sim_msg_0": "Upgrade SQLalchemy",
        "sim_diff_1": "diff --git a/requirements.txt b/requirements.txt @@ -39,7 +39,7 @@ pycodestyle==2.3.1 # via flake8\npyflakes==1.6.0 # via flake8\npygments==2.2.0 # via sphinx\npymongo==3.5.1 # via mongoengine\n-pyrabbit2==1.0.0\n+pyrabbit2==1.0.3\npytest==3.4.2\npython-box==3.1.1 # via yapconf\npytz==2017.3\n",
        "sim_msg_1": "Bumping pyrabbit2 version to address RabbitMQ 3.7 compatibility",
        "sim_diff_2": "diff --git a/requirements.txt b/requirements.txt @@ -39,7 +39,7 @@ packaging==17.1 # via sphinx\npasslib==1.7.1 # via bg-utils\npathtools==0.1.2 # via watchdog\npbr==4.0.4 # via mock\n-pika==0.11.2 # via brewtils\n+pika==0.12.0 # via brewtils\npkginfo==1.4.2 # via twine\npluggy==0.6.0 # via pytest, tox\nply==3.11 # via thriftpy\n",
        "sim_msg_2": "Bumping pika version in requirements.txt",
        "sim_diff_3": "diff --git a/requirements.txt b/requirements.txt @@ -4,19 +4,19 @@ prefixcommons>=0.1.9\nrequests>=0.0\npip>=9.0.1\nwheel>0.25.0\n-pysolr==3.6.0\n-networkx==2.2\n-matplotlib==2.0.0\n-SPARQLWrapper==1.8.0\n+pysolr>=3.6.0\n+networkx>=2.2\n+matplotlib>=2.0.0\n+SPARQLWrapper>=1.8.0\npandas>=0.0\n-scipy==1.2.0\n+scipy>=1.2.0\ntwine\njsonpickle>=0.0\njsonpath_rw>=0.0\npytest>=0.0\npytest_logging>=0.0\npydotplus>=0.0\n-plotly==2.0.7\n+plotly>=2.0.7\npyyaml\nyamldown>=0.1.7\nclick\n",
        "sim_msg_3": "Remove most of the pinned dependencies from requirements.txt"
    },
    {
        "org_diff": "diff --git a/.github/dependabot.yml b/a/.github/dependabot.yml @@ -1,9 +1,18 @@\n version: 2\n updates:\n-- package-ecosystem: \"github-actions\"\n-  directory: \"/\"\n-  schedule:\n-    interval: \"monthly\"\n-    day: \"monday\"\n-    time: \"16:00\"\n-    timezone: \"UTC\"\n+  - package-ecosystem: github-actions\n+    directory: /\n+    schedule:\n+      interval: monthly\n+    groups:\n+      github-actions:\n+        patterns:\n+          - '*'\n+  - package-ecosystem: pip\n+    directory: /requirements/\n+    schedule:\n+      interval: monthly\n+    groups:\n+      python-requirements:\n+        patterns:\n+          - '*'",
        "sim_diff_0": "diff --git a/.github/dependabot.yml b/.github/dependabot.yml version: 2\nupdates:\n-\n- package-ecosystem: \"github-actions\"\ndirectory: \"/\"\nschedule:\ninterval: \"daily\"\n+ labels: [\"skip-changelog\"]\n- package-ecosystem: \"pip\"\ndirectory: \"/\"\nschedule:\ninterval: \"daily\"\n+ labels: [\"skip-changelog\"]\n",
        "sim_msg_0": "Add skip-changelog label to dependabot PRs",
        "sim_diff_1": "diff --git a/.github/dependabot.yml b/.github/dependabot.yml @@ -6,3 +6,9 @@ updates:\ninterval: daily\ntime: \"11:00\"\nopen-pull-requests-limit: 10\n+ - package-ecosystem: github-actions\n+ directory: \"/\"\n+ schedule:\n+ interval: daily\n+ time: \"11:00\"\n+ open-pull-requests-limit: 10\n",
        "sim_msg_1": "ci: add github-actions to dependabot",
        "sim_diff_2": "diff --git a/.github/dependabot.yml b/.github/dependabot.yml @@ -3,12 +3,15 @@ updates:\n- package-ecosystem: \"pip\"\ndirectory: \"/docker\"\nschedule:\n- interval: \"weekly\"\n+ interval: \"daily\"\n+ open-pull-requests-limit: 1\n- package-ecosystem: \"pip\"\ndirectory: \"/hail/python\"\nschedule:\n- interval: \"weekly\"\n+ interval: \"daily\"\n+ open-pull-requests-limit: 1\n- package-ecosystem: \"pip\"\ndirectory: \"/hail/python/dev\"\nschedule:\n- interval: \"weekly\"\n+ interval: \"daily\"\n+ open-pull-requests-limit: 1\n",
        "sim_msg_2": "[dependabot] check daily, but never more than 1 PR",
        "sim_diff_3": "diff --git a/.github/dependabot.yml b/.github/dependabot.yml @@ -5,3 +5,39 @@ updates:\nschedule:\ninterval: daily\nopen-pull-requests-limit: 10\n+\n+ - package-ecosystem: gomod\n+ directory: \"/tools/src/yq/\"\n+ schedule:\n+ interval: daily\n+ open-pull-requests-limit: 10\n+\n+ - package-ecosystem: gomod\n+ directory: \"/tools/src/chart-doc-gen\"\n+ schedule:\n+ interval: daily\n+ open-pull-requests-limit: 10\n+\n+ - package-ecosystem: gomod\n+ directory: \"/tools/src/crane\"\n+ schedule:\n+ interval: daily\n+ open-pull-requests-limit: 10\n+\n+ - package-ecosystem: gomod\n+ directory: \"/tools/src/ct\"\n+ schedule:\n+ interval: daily\n+ open-pull-requests-limit: 10\n+\n+ - package-ecosystem: gomod\n+ directory: \"/tools/src/golangci-lint\"\n+ schedule:\n+ interval: daily\n+ open-pull-requests-limit: 10\n+\n+ - package-ecosystem: gomod\n+ directory: \"/tools/src/ocibuild\"\n+ schedule:\n+ interval: daily\n+ open-pull-requests-limit: 10\n",
        "sim_msg_3": "deps : adding all go.mod locations to dependabots monitoring"
    },
    {
        "org_diff": "diff --git a/.github/workflows/tests.yaml b/a/.github/workflows/tests.yaml @@ -9,9 +9,6 @@ on:\n       - '*.md'\n       - '*.rst'\n   pull_request:\n-    branches:\n-      - main\n-      - '*.x'\n     paths-ignore:\n       - 'docs/**'\n       - '*.md'\n@@ -24,17 +21,17 @@ jobs:\n       fail-fast: false\n       matrix:\n         include:\n-          - {name: Linux, python: '3.11', os: ubuntu-latest, tox: py311}\n-          - {name: Windows, python: '3.11', os: windows-latest, tox: py311}\n-          - {name: Mac, python: '3.11', os: macos-latest, tox: py311}\n-          - {name: '3.12-dev', python: '3.12-dev', os: ubuntu-latest, tox: py312}\n+          - {name: Linux, python: '3.12', os: ubuntu-latest, tox: py312}\n+          - {name: Windows, python: '3.12', os: windows-latest, tox: py312}\n+          - {name: Mac, python: '3.12', os: macos-latest, tox: py312}\n+          - {name: '3.11', python: '3.11', os: ubuntu-latest, tox: py311}\n           - {name: '3.10', python: '3.10', os: ubuntu-latest, tox: py310}\n           - {name: '3.9', python: '3.9', os: ubuntu-latest, tox: py39}\n           - {name: '3.8', python: '3.8', os: ubuntu-latest, tox: py38}\n           - {name: 'PyPy', python: 'pypy-3.10', os: ubuntu-latest, tox: pypy310}\n-          - {name: 'Minimum Versions', python: '3.11', os: ubuntu-latest, tox: py311-min}\n+          - {name: 'Minimum Versions', python: '3.12', os: ubuntu-latest, tox: py312-min}\n           - {name: 'Development Versions', python: '3.8', os: ubuntu-latest, tox: py38-dev}\n-          - {name: Typing, python: '3.11', os: ubuntu-latest, tox: typing}\n+          - {name: Typing, python: '3.12', os: ubuntu-latest, tox: typing}\n     steps:\n       - uses: actions/checkout@f43a0e5ff2bd294095638e18286ca9a3d1956744\n       - uses: actions/setup-python@61a6322f88396a6271a6ee3565807d608ecaddd1",
        "sim_diff_0": "diff --git a/{{cookiecutter.project_name}}/.github/workflows/tests.yml b/{{cookiecutter.project_name}}/.github/workflows/tests.yml @@ -12,21 +12,33 @@ jobs:\nfail-fast: false\nmatrix:\ninclude:\n- - { python-version: \"3.10\", os: ubuntu-latest, session: \"pre-commit\" }\n- - { python-version: \"3.10\", os: ubuntu-latest, session: \"safety\" }\n- - { python-version: \"3.10\", os: ubuntu-latest, session: \"mypy\" }\n- - { python-version: 3.9, os: ubuntu-latest, session: \"mypy\" }\n- - { python-version: 3.8, os: ubuntu-latest, session: \"mypy\" }\n- - { python-version: 3.7, os: ubuntu-latest, session: \"mypy\" }\n- - { python-version: \"3.10\", os: ubuntu-latest, session: \"tests\" }\n- - { python-version: 3.9, os: ubuntu-latest, session: \"tests\" }\n- - { python-version: 3.8, os: ubuntu-latest, session: \"tests\" }\n- - { python-version: 3.7, os: ubuntu-latest, session: \"tests\" }\n- - { python-version: \"3.10\", os: windows-latest, session: \"tests\" }\n- - { python-version: \"3.10\", os: macos-latest, session: \"tests\" }\n- - { python-version: \"3.10\", os: ubuntu-latest, session: \"typeguard\" }\n- - { python-version: \"3.10\", os: ubuntu-latest, session: \"xdoctest\" }\n- - { python-version: \"3.10\", os: ubuntu-latest, session: \"docs-build\" }\n+ - {\n+ python-version: \"3.10\",\n+ os: \"ubuntu-latest\",\n+ session: \"pre-commit\",\n+ }\n+ - { python-version: \"3.10\", os: \"ubuntu-latest\", session: \"safety\" }\n+ - { python-version: \"3.10\", os: \"ubuntu-latest\", session: \"mypy\" }\n+ - { python-version: \"3.9\", os: \"ubuntu-latest\", session: \"mypy\" }\n+ - { python-version: \"3.8\", os: \"ubuntu-latest\", session: \"mypy\" }\n+ - { python-version: \"3.7\", os: \"ubuntu-latest\", session: \"mypy\" }\n+ - { python-version: \"3.10\", os: \"ubuntu-latest\", session: \"tests\" }\n+ - { python-version: \"3.9\", os: \"ubuntu-latest\", session: \"tests\" }\n+ - { python-version: \"3.8\", os: \"ubuntu-latest\", session: \"tests\" }\n+ - { python-version: \"3.7\", os: \"ubuntu-latest\", session: \"tests\" }\n+ - { python-version: \"3.10\", os: \"windows-latest\", session: \"tests\" }\n+ - { python-version: \"3.10\", os: \"macos-latest\", session: \"tests\" }\n+ - {\n+ python-version: \"3.10\",\n+ os: \"ubuntu-latest\",\n+ session: \"typeguard\",\n+ }\n+ - { python-version: \"3.10\", os: \"ubuntu-latest\", session: \"xdoctest\" }\n+ - {\n+ python-version: \"3.10\",\n+ os: \"ubuntu-latest\",\n+ session: \"docs-build\",\n+ }\nenv:\nNOXSESSION: {{ \"${{ matrix.session }}\" }}\n@@ -105,10 +117,10 @@ jobs:\n- name: Check out the repository\nuses: actions/checkout@v2.4.0\n- - name: Set up Python 3.9\n+ - name: Set up Python\nuses: actions/setup-python@v2.3.0\nwith:\n- python-version: 3.9\n+ python-version: \"3.10\"\n- name: Upgrade pip\nrun: |\n",
        "sim_msg_0": "Update test GA workflow for more consistent style\n* Update test GA workflow for more consistent style\n* Fix prettier formatting\nRetrocookie-Original-Commit:",
        "sim_diff_1": "diff --git a/.github/workflows/test.yml b/.github/workflows/test.yml @@ -2,10 +2,12 @@ name: Tests\non: [pull_request, push]\njobs:\ntests:\n- runs-on: ubuntu-latest\n+ runs-on: ${{ matrix.os }}\nstrategy:\n+ fail-fast: false\nmatrix:\npython-version: ['3.6.13', '3.7', '3.8']\n+ os: [ubuntu-latest, macos-latest, windows-latest]\nname: Python ${{ matrix.python-version }}\nsteps:\n- name: Checkout Code\n",
        "sim_msg_1": "change tests to run on windows and mac.",
        "sim_diff_2": "diff --git a/.github/workflows/tests.yml b/.github/workflows/tests.yml @@ -6,6 +6,11 @@ on:\nbranches:\n- master\npull_request:\n+ types:\n+ - opened\n+ - reopened\n+ - synchronize\n+ - ready_for_review\npaths:\n- '**/*.py'\n- '**/*.yml'\n",
        "sim_msg_2": "make 'ready for review' an event that triggers the tests",
        "sim_diff_3": "diff --git a/.github/workflows/tests.yml b/.github/workflows/tests.yml @@ -5,8 +5,10 @@ on:\nbranches:\n- master\npaths:\n+ - .github/workflows/tests.yml\n- httpie/**/*.py\n- setup.*\n+ - tests/**/*.py\npull_request:\npaths:\n- .github/workflows/tests.yml\n",
        "sim_msg_3": "Add self to paths; same paths for PR and push"
    },
    {
        "org_diff": "diff --git a/.github/workflows/lock.yaml b/a/.github/workflows/lock.yaml @@ -1,8 +1,8 @@\n-name: 'Lock threads'\n-# Lock closed issues that have not received any further activity for\n-# two weeks. This does not close open issues, only humans may do that.\n-# We find that it is easier to respond to new issues with fresh examples\n-# rather than continuing discussions on old issues.\n+name: 'Lock inactive closed issues'\n+# Lock closed issues that have not received any further activity for two weeks.\n+# This does not close open issues, only humans may do that. We find that it is\n+# easier to respond to new issues with fresh examples rather than continuing\n+# discussions on old issues.\n \n on:\n   schedule:",
        "sim_diff_0": "diff --git a/.github/workflows/stale.yml b/.github/workflows/stale.yml @@ -21,7 +21,7 @@ jobs:\nrepo-token: ${{ secrets.GITHUB_TOKEN }}\ndays-before-issue-stale: 30\ndays-before-issue-close: 7\n- days-before-pr-stale: 30\n+ days-before-pr-stale: 45\ndays-before-pr-close: -1\nstale-issue-message: 'This issue has been automatically marked as stale due to lack of activity. It will be closed if no further activity occurs. Thank you'\nclose-issue-message: 'This issue is closed due to lack of activity. Feel free to reopen it if you still have questions.'\n",
        "sim_msg_0": "changed the PR stale days",
        "sim_diff_1": "diff --git a/.github/workflows/stale.yml b/.github/workflows/stale.yml @@ -29,4 +29,3 @@ jobs:\nclose-pr-message: 'This pull request is closed due to lack of activity.'\nstale-issue-label: 'stale-issue'\nexempt-issue-labels: 'bug, enhancement, new feature'\n-\n",
        "sim_msg_1": "pre-commit checked",
        "sim_diff_2": "diff --git a/.github/workflows/close-inactive-issue-pr.yml b/.github/workflows/close-inactive-issue-pr.yml @@ -18,8 +18,8 @@ jobs:\nstale-issue-label: \"stale\"\nstale-issue-message: \"This issue is stale because it has been open for 30 days with no activity. Remove stale label or comment or this will be closed in 7 days.\"\nclose-issue-message: \"This issue was closed because it has been inactive for 7 days since being marked as stale.\"\n- days-before-pr-stale: 30\n+ days-before-pr-stale: 14\ndays-before-pr-close: 7\n- stale-pr-message: \"This PR is stale because it has been open for 30 days with no activity. Remove stale label or comment or update or this will be closed in 7 days.\"\n+ stale-pr-message: \"This PR is stale because it has been open for 14 days with no activity. Remove stale label or comment or update or this will be closed in 7 days.\"\nclose-pr-message: \"This PR was closed because it has been inactive for 7 days since being marked as stale.\"\nrepo-token: ${{ secrets.GITHUB_TOKEN }}\n",
        "sim_msg_2": "reduced to 14 inactive days to be stale for PRs.",
        "sim_diff_3": "diff --git a/.github/workflows/stale.yml b/.github/workflows/stale.yml @@ -11,6 +11,6 @@ jobs:\n- uses: actions/stale@v1\nwith:\nrepo-token: ${{ secrets.JINA_DEV_BOT }}\n- stale-issue-message: 'This issue is stale because it has been open 20 days with no activity. Remove stale label or comment or this will be closed in 4 days'\n- days-before-stale: 20\n- days-before-close: 4\n\\ No newline at end of file\n+ stale-issue-message: '@jina-ai/product This issue is stale because it has been open 90 days with no activity. Remove stale label or comment or this will be closed in 14 days'\n+ days-before-stale: 90\n+ days-before-close: 14\n\\ No newline at end of file\n",
        "sim_msg_3": "chore(ci): change stalebot interval"
    },
    {
        "org_diff": "diff --git a/.readthedocs.yaml b/a/.readthedocs.yaml @@ -1,8 +1,8 @@\n version: 2\n build:\n-  os: ubuntu-20.04\n+  os: ubuntu-22.04\n   tools:\n-    python: \"3.10\"\n+    python: \"3.12\"\n python:\n   install:\n     - requirements: requirements/docs.txt",
        "sim_diff_0": "diff --git a/requirements.txt b/requirements.txt @@ -52,7 +52,7 @@ pyyaml==4.2b4\nredis==2.10.6\nrequests==2.20.1\nsix==1.12.0 # via altair, bcrypt, cryptography, flask-restful, jsonschema, pyrsistent, python-dateutil\n-sqlalchemy==1.3.0\n+sqlalchemy==1.3.2\ntoolz==0.9.0 # via altair\ntyping==3.6.6 # via altair\nurllib3==1.24.2\n",
        "sim_msg_0": "Upgrade SQLalchemy",
        "sim_diff_1": "diff --git a/requirements.txt b/requirements.txt @@ -39,7 +39,7 @@ pycodestyle==2.3.1 # via flake8\npyflakes==1.6.0 # via flake8\npygments==2.2.0 # via sphinx\npymongo==3.5.1 # via mongoengine\n-pyrabbit2==1.0.0\n+pyrabbit2==1.0.3\npytest==3.4.2\npython-box==3.1.1 # via yapconf\npytz==2017.3\n",
        "sim_msg_1": "Bumping pyrabbit2 version to address RabbitMQ 3.7 compatibility",
        "sim_diff_2": "diff --git a/requirements.txt b/requirements.txt @@ -39,7 +39,7 @@ packaging==17.1 # via sphinx\npasslib==1.7.1 # via bg-utils\npathtools==0.1.2 # via watchdog\npbr==4.0.4 # via mock\n-pika==0.11.2 # via brewtils\n+pika==0.12.0 # via brewtils\npkginfo==1.4.2 # via twine\npluggy==0.6.0 # via pytest, tox\nply==3.11 # via thriftpy\n",
        "sim_msg_2": "Bumping pika version in requirements.txt",
        "sim_diff_3": "diff --git a/requirements.txt b/requirements.txt @@ -4,19 +4,19 @@ prefixcommons>=0.1.9\nrequests>=0.0\npip>=9.0.1\nwheel>0.25.0\n-pysolr==3.6.0\n-networkx==2.2\n-matplotlib==2.0.0\n-SPARQLWrapper==1.8.0\n+pysolr>=3.6.0\n+networkx>=2.2\n+matplotlib>=2.0.0\n+SPARQLWrapper>=1.8.0\npandas>=0.0\n-scipy==1.2.0\n+scipy>=1.2.0\ntwine\njsonpickle>=0.0\njsonpath_rw>=0.0\npytest>=0.0\npytest_logging>=0.0\npydotplus>=0.0\n-plotly==2.0.7\n+plotly>=2.0.7\npyyaml\nyamldown>=0.1.7\nclick\n",
        "sim_msg_3": "Remove most of the pinned dependencies from requirements.txt"
    },
    {
        "org_diff": "diff --git a/docs/deploying/asgi.rst b/a/docs/deploying/asgi.rst @@ -20,7 +20,7 @@ wrapping the Flask app,\n     asgi_app = WsgiToAsgi(app)\n \n and then serving the ``asgi_app`` with the ASGI server, e.g. using\n-`Hypercorn <https://gitlab.com/pgjones/hypercorn>`_,\n+`Hypercorn <https://github.com/pgjones/hypercorn>`_,\n \n .. sourcecode:: text\n ",
        "sim_diff_0": "diff --git a/docs/deploying.rst b/docs/deploying.rst @@ -22,18 +22,23 @@ Here's an example of what that ``asgi.py`` might look like:\nimport os\n- from channels.auth import AuthMiddlewareStack\n- from channels.routing import ProtocolTypeRouter, URLRouter\nfrom django.conf.urls import url\nfrom django.core.asgi import get_asgi_application\n- from chat.consumers import AdminChatConsumer, PublicChatConsumer\n-\n+ # Fetch Django ASGI application early to ensure AppRegistry is populated\n+ # before importing consumers and AuthMiddlewareStack that may import ORM\n+ # models.\nos.environ.setdefault(\"DJANGO_SETTINGS_MODULE\", \"mysite.settings\")\n+ django_asgi_app = get_asgi_application()\n+\n+ from channels.auth import AuthMiddlewareStack\n+ from channels.routing import ProtocolTypeRouter, URLRouter\n+\n+ from chat.consumers import AdminChatConsumer, PublicChatConsumer\napplication = ProtocolTypeRouter({\n# Django's ASGI application to handle traditional HTTP requests\n- \"http\": get_asgi_application(),\n+ \"http\": django_asgi_app,\n# WebSocket chat handler\n\"websocket\": AuthMiddlewareStack(\n@@ -44,7 +49,6 @@ Here's an example of what that ``asgi.py`` might look like:\n),\n})\n-\nSetting up a channel backend\n----------------------------\n",
        "sim_msg_0": "Adjusted deployment asgi.py example.",
        "sim_diff_1": "diff --git a/docs/deploying/wsgi-standalone.rst b/docs/deploying/wsgi-standalone.rst @@ -27,6 +27,22 @@ For example, to run a Flask application with 4 worker processes (``-w\n.. _eventlet: http://eventlet.net/\n.. _greenlet: https://greenlet.readthedocs.io/en/latest/\n+uWSGI\n+--------\n+\n+`uWSGI`_ is a fast application server written in C. It is very configurable\n+which makes it more complicated to setup than gunicorn.\n+\n+Running `uWSGI HTTP Router`_::\n+\n+ uwsgi --http 127.0.0.1:5000 --module myproject:app\n+\n+For a more optimized setup, see `configuring uWSGI and NGINX`_.\n+\n+.. _uWSGI: http://uwsgi-docs.readthedocs.io/en/latest/\n+.. _uWSGI HTTP Router: http://uwsgi-docs.readthedocs.io/en/latest/HTTP.html#the-uwsgi-http-https-router\n+.. _configuring uWSGI and NGINX: uwsgi.html#starting-your-app-with-uwsgi\n+\nGevent\n-------\n",
        "sim_msg_1": "Added uWSGI and example usage to stand-alone WSGI containers documentation",
        "sim_diff_2": "diff --git a/docs/deploying.rst b/docs/deploying.rst @@ -25,9 +25,9 @@ Here's an example of what that ``asgi.py`` might look like:\nfrom django.conf.urls import url\nfrom django.core.asgi import get_asgi_application\n- # Fetch Django ASGI application early to ensure AppRegistry is populated\n- # before importing consumers and AuthMiddlewareStack that may import ORM\n- # models.\n+ # Fetch Django ASGI application early to ensure Django settings are\n+ # configured and the AppRegistry is populated before importing consumers\n+ # and AuthMiddlewareStack that may use ORM models or the settings.\nos.environ.setdefault(\"DJANGO_SETTINGS_MODULE\", \"mysite.settings\")\ndjango_asgi_app = get_asgi_application()\n",
        "sim_msg_2": "Tweaked asgi.py example to mention Django settings.\nSettings are configured by the django.setup() call when fetching the asgi\napplication.",
        "sim_diff_3": "diff --git a/docs/deploying/index.rst b/docs/deploying/index.rst @@ -17,7 +17,7 @@ Hosted options\n--------------\n- `Deploying Flask on Heroku <https://devcenter.heroku.com/articles/getting-started-with-python>`_\n-- `Deploying Flask on Google App Engine <https://cloud.google.com/appengine/docs/standard/python/getting-started/python-standard-env>`_\n+- `Deploying Flask on Google App Engine <https://cloud.google.com/appengine/docs/standard/python3/runtime>`_\n- `Deploying Flask on AWS Elastic Beanstalk <https://docs.aws.amazon.com/elasticbeanstalk/latest/dg/create-deploy-python-flask.html>`_\n- `Deploying on Azure (IIS) <https://docs.microsoft.com/en-us/azure/app-service/containers/how-to-configure-python>`_\n- `Deploying on PythonAnywhere <https://help.pythonanywhere.com/pages/Flask/>`_\n",
        "sim_msg_3": "docs: update \"Deploying on Google App Engine\"\nUse the documentation for Python 3 instead of Python 2, which is deprecated."
    },
    {
        "org_diff": "diff --git a/docs/deploying/asgi.rst b/a/docs/deploying/asgi.rst @@ -20,7 +20,7 @@ wrapping the Flask app,\n     asgi_app = WsgiToAsgi(app)\n \n and then serving the ``asgi_app`` with the ASGI server, e.g. using\n-`Hypercorn <https://gitlab.com/pgjones/hypercorn>`_,\n+`Hypercorn <https://github.com/pgjones/hypercorn>`_,\n \n .. sourcecode:: text\n ",
        "sim_diff_0": "diff --git a/docs/deploying.rst b/docs/deploying.rst @@ -22,18 +22,23 @@ Here's an example of what that ``asgi.py`` might look like:\nimport os\n- from channels.auth import AuthMiddlewareStack\n- from channels.routing import ProtocolTypeRouter, URLRouter\nfrom django.conf.urls import url\nfrom django.core.asgi import get_asgi_application\n- from chat.consumers import AdminChatConsumer, PublicChatConsumer\n-\n+ # Fetch Django ASGI application early to ensure AppRegistry is populated\n+ # before importing consumers and AuthMiddlewareStack that may import ORM\n+ # models.\nos.environ.setdefault(\"DJANGO_SETTINGS_MODULE\", \"mysite.settings\")\n+ django_asgi_app = get_asgi_application()\n+\n+ from channels.auth import AuthMiddlewareStack\n+ from channels.routing import ProtocolTypeRouter, URLRouter\n+\n+ from chat.consumers import AdminChatConsumer, PublicChatConsumer\napplication = ProtocolTypeRouter({\n# Django's ASGI application to handle traditional HTTP requests\n- \"http\": get_asgi_application(),\n+ \"http\": django_asgi_app,\n# WebSocket chat handler\n\"websocket\": AuthMiddlewareStack(\n@@ -44,7 +49,6 @@ Here's an example of what that ``asgi.py`` might look like:\n),\n})\n-\nSetting up a channel backend\n----------------------------\n",
        "sim_msg_0": "Adjusted deployment asgi.py example.",
        "sim_diff_1": "diff --git a/docs/deploying/wsgi-standalone.rst b/docs/deploying/wsgi-standalone.rst @@ -27,6 +27,22 @@ For example, to run a Flask application with 4 worker processes (``-w\n.. _eventlet: http://eventlet.net/\n.. _greenlet: https://greenlet.readthedocs.io/en/latest/\n+uWSGI\n+--------\n+\n+`uWSGI`_ is a fast application server written in C. It is very configurable\n+which makes it more complicated to setup than gunicorn.\n+\n+Running `uWSGI HTTP Router`_::\n+\n+ uwsgi --http 127.0.0.1:5000 --module myproject:app\n+\n+For a more optimized setup, see `configuring uWSGI and NGINX`_.\n+\n+.. _uWSGI: http://uwsgi-docs.readthedocs.io/en/latest/\n+.. _uWSGI HTTP Router: http://uwsgi-docs.readthedocs.io/en/latest/HTTP.html#the-uwsgi-http-https-router\n+.. _configuring uWSGI and NGINX: uwsgi.html#starting-your-app-with-uwsgi\n+\nGevent\n-------\n",
        "sim_msg_1": "Added uWSGI and example usage to stand-alone WSGI containers documentation",
        "sim_diff_2": "diff --git a/docs/deploying.rst b/docs/deploying.rst @@ -25,9 +25,9 @@ Here's an example of what that ``asgi.py`` might look like:\nfrom django.conf.urls import url\nfrom django.core.asgi import get_asgi_application\n- # Fetch Django ASGI application early to ensure AppRegistry is populated\n- # before importing consumers and AuthMiddlewareStack that may import ORM\n- # models.\n+ # Fetch Django ASGI application early to ensure Django settings are\n+ # configured and the AppRegistry is populated before importing consumers\n+ # and AuthMiddlewareStack that may use ORM models or the settings.\nos.environ.setdefault(\"DJANGO_SETTINGS_MODULE\", \"mysite.settings\")\ndjango_asgi_app = get_asgi_application()\n",
        "sim_msg_2": "Tweaked asgi.py example to mention Django settings.\nSettings are configured by the django.setup() call when fetching the asgi\napplication.",
        "sim_diff_3": "diff --git a/docs/deploying/index.rst b/docs/deploying/index.rst @@ -17,7 +17,7 @@ Hosted options\n--------------\n- `Deploying Flask on Heroku <https://devcenter.heroku.com/articles/getting-started-with-python>`_\n-- `Deploying Flask on Google App Engine <https://cloud.google.com/appengine/docs/standard/python/getting-started/python-standard-env>`_\n+- `Deploying Flask on Google App Engine <https://cloud.google.com/appengine/docs/standard/python3/runtime>`_\n- `Deploying Flask on AWS Elastic Beanstalk <https://docs.aws.amazon.com/elasticbeanstalk/latest/dg/create-deploy-python-flask.html>`_\n- `Deploying on Azure (IIS) <https://docs.microsoft.com/en-us/azure/app-service/containers/how-to-configure-python>`_\n- `Deploying on PythonAnywhere <https://help.pythonanywhere.com/pages/Flask/>`_\n",
        "sim_msg_3": "docs: update \"Deploying on Google App Engine\"\nUse the documentation for Python 3 instead of Python 2, which is deprecated."
    },
    {
        "org_diff": "diff --git a/docs/testing.rst b/a/docs/testing.rst @@ -192,7 +192,7 @@ which records the request that produced that response.\n .. code-block:: python\n \n     def test_logout_redirect(client):\n-        response = client.get(\"/logout\")\n+        response = client.get(\"/logout\", follow_redirects=True)\n         # Check that there was one redirect response.\n         assert len(response.history) == 1\n         # Check that the second request was to the index page.",
        "sim_diff_0": "diff --git a/tests/test_redirects.py b/tests/test_redirects.py @@ -68,10 +68,18 @@ def test_http_307_allow_redirect_post(httpbin):\nassert HTTP_OK in r\n-def test_http_307_allow_redirect_post_verbose(httpbin):\n- r = http('--follow', '--verbose', 'POST', httpbin.url + '/redirect-to',\n- f'url=={httpbin.url}/post', 'status_code==307',\n- '@' + FILE_PATH_ARG)\n+@pytest.mark.parametrize('status_code', [307, 308])\n+def test_verbose_follow_redirect_with_repost(httpbin, status_code):\n+ # <https://developer.mozilla.org/en-US/docs/Web/HTTP/Redirections>\n+ r = http(\n+ '--follow',\n+ '--verbose',\n+ httpbin.url + '/redirect-to',\n+ f'url=={httpbin.url}/post',\n+ f'status_code=={status_code}',\n+ '@' + FILE_PATH_ARG,\n+ )\n+ assert f'HTTP/1.1 {status_code}' in r\nassert r.count('POST /redirect-to') == 1\nassert r.count('POST /post') == 1\nassert r.count(FILE_CONTENT) == 3 # two requests + final response contain it\n",
        "sim_msg_0": "Add `--follow --verbose` test for HTTP 308",
        "sim_diff_1": "diff --git a/tests/test_redirects.py b/tests/test_redirects.py @@ -7,6 +7,10 @@ from .utils import http, HTTP_OK\nfrom .utils.matching import assert_output_matches, Expect, ExpectSequence\n+# <https://developer.mozilla.org/en-US/docs/Web/HTTP/Redirections>\n+REDIRECTS_WITH_METHOD_BODY_PRESERVED = [307, 308]\n+\n+\ndef test_follow_all_redirects_shown(httpbin):\nr = http('--follow', '--all', httpbin.url + '/redirect/2')\nassert r.count('HTTP/1.1') == 3\n@@ -37,6 +41,7 @@ def test_follow_all_output_options_used_for_redirects(httpbin):\nassert r.count('GET /') == 3\nassert HTTP_OK not in r\n+\n#\n# def test_follow_redirect_output_options(httpbin):\n# r = http('--check-status',\n@@ -61,16 +66,21 @@ def test_max_redirects(httpbin):\nassert r.exit_status == ExitStatus.ERROR_TOO_MANY_REDIRECTS\n-def test_http_307_allow_redirect_post(httpbin):\n- r = http('--follow', 'POST', httpbin.url + '/redirect-to',\n- f'url=={httpbin.url}/post', 'status_code==307',\n- '@' + FILE_PATH_ARG)\n+@pytest.mark.parametrize('status_code', REDIRECTS_WITH_METHOD_BODY_PRESERVED)\n+def test_follow_redirect_with_repost(httpbin, status_code):\n+ r = http(\n+ '--follow',\n+ httpbin.url + '/redirect-to',\n+ f'url=={httpbin.url}/post',\n+ f'status_code=={status_code}',\n+ '@' + FILE_PATH_ARG,\n+ )\nassert HTTP_OK in r\n+ assert FILE_CONTENT in r\n-@pytest.mark.parametrize('status_code', [307, 308])\n+@pytest.mark.parametrize('status_code', REDIRECTS_WITH_METHOD_BODY_PRESERVED)\ndef test_verbose_follow_redirect_with_repost(httpbin, status_code):\n- # <https://developer.mozilla.org/en-US/docs/Web/HTTP/Redirections>\nr = http(\n'--follow',\n'--verbose',\n",
        "sim_msg_1": "Add `--follow` test for HTTP 308",
        "sim_diff_2": "diff --git a/tests/test_exit_status.py b/tests/test_exit_status.py @@ -33,7 +33,7 @@ def test_error_response_exits_0_without_check_status(httpbin):\ndef test_timeout_exit_status(httpbin):\n- r = http('--timeout=0.01', 'GET', httpbin.url + '/delay/0.02',\n+ r = http('--timeout=0.01', 'GET', httpbin.url + '/delay/0.5',\nerror_exit_ok=True)\nassert r.exit_status == ExitStatus.ERROR_TIMEOUT\n",
        "sim_msg_2": "Test --timeout with longer delay\ntest_timeout_exit_status fails on Python 2.7",
        "sim_diff_3": "diff --git a/test_scaffold/tests.py b/test_scaffold/tests.py @@ -128,7 +128,16 @@ class BaseWebTestCase(BaseTestCase):\nlen(redirect_chain),\n'Unexpected redirect, should have stayed on [%s]. %s' % (view_name, extra_message,))\n- def _check_response_redirect_chain(self, view_name, another, response, extra_message='', secure=False):\n+ def _check_response_redirect_chain(\n+ self,\n+ view_name,\n+ another,\n+ response,\n+ extra_message='',\n+ secure=False,\n+ redirect_chain_offset=-1,\n+ **kwargs\n+ ):\n\"\"\"Check that response.redirect_chain is behaving correctly\n\"\"\"\nredirect_chain = response.redirect_chain\n@@ -147,7 +156,7 @@ class BaseWebTestCase(BaseTestCase):\nprotocol_pattern = protocol_pattern + '%s%s'\npattern = protocol_pattern % (TESTSERVER, reverse(another),)\n- actual = redirect_chain[-1][0]\n+ actual = redirect_chain[redirect_chain_offset][0]\nmatch = re.match(pattern, actual)\nself.assertIsNotNone(\nmatch,\n@@ -158,7 +167,18 @@ class BaseWebTestCase(BaseTestCase):\n)\n)\n- def _check_view_redirects_to_another(self, view_name, another, client=None, params=None, view_args=None, view_kwargs=None, method='get', secure=False):\n+ def _check_view_redirects_to_another(\n+ self,\n+ view_name,\n+ another,\n+ client=None,\n+ params=None,\n+ view_args=None,\n+ view_kwargs=None,\n+ method='get',\n+ secure=False,\n+ **kwargs\n+ ):\n\"\"\"Perform an HTTP request and check that the redirect_chain behaves correctly for a page that is expected to redirect\n\"\"\"\nif method == 'get':\n@@ -167,7 +187,13 @@ class BaseWebTestCase(BaseTestCase):\nresponse = self._post(view_name, client=client, params=params, view_args=view_args, view_kwargs=view_kwargs, follow=True, secure=secure)\nelse:\nraise Exception('Unknown HTTP method: %s' % method)\n- self._check_response_redirect_chain(view_name, another, response, secure=secure)\n+ self._check_response_redirect_chain(\n+ view_name,\n+ another,\n+ response,\n+ secure=secure,\n+ **kwargs\n+ )\ndef _check_view_redirects_to_login(self, view_name, client=None, login_url_name='account_login', secure=False):\nself._check_view_redirects_to_another(view_name, login_url_name, client=client, secure=secure)\n",
        "sim_msg_3": "allow specifying arbitrary redirect_chain_offset"
    },
    {
        "org_diff": "diff --git a/docs/testing.rst b/a/docs/testing.rst @@ -192,7 +192,7 @@ which records the request that produced that response.\n .. code-block:: python\n \n     def test_logout_redirect(client):\n-        response = client.get(\"/logout\")\n+        response = client.get(\"/logout\", follow_redirects=True)\n         # Check that there was one redirect response.\n         assert len(response.history) == 1\n         # Check that the second request was to the index page.",
        "sim_diff_0": "diff --git a/tests/test_redirects.py b/tests/test_redirects.py @@ -68,10 +68,18 @@ def test_http_307_allow_redirect_post(httpbin):\nassert HTTP_OK in r\n-def test_http_307_allow_redirect_post_verbose(httpbin):\n- r = http('--follow', '--verbose', 'POST', httpbin.url + '/redirect-to',\n- f'url=={httpbin.url}/post', 'status_code==307',\n- '@' + FILE_PATH_ARG)\n+@pytest.mark.parametrize('status_code', [307, 308])\n+def test_verbose_follow_redirect_with_repost(httpbin, status_code):\n+ # <https://developer.mozilla.org/en-US/docs/Web/HTTP/Redirections>\n+ r = http(\n+ '--follow',\n+ '--verbose',\n+ httpbin.url + '/redirect-to',\n+ f'url=={httpbin.url}/post',\n+ f'status_code=={status_code}',\n+ '@' + FILE_PATH_ARG,\n+ )\n+ assert f'HTTP/1.1 {status_code}' in r\nassert r.count('POST /redirect-to') == 1\nassert r.count('POST /post') == 1\nassert r.count(FILE_CONTENT) == 3 # two requests + final response contain it\n",
        "sim_msg_0": "Add `--follow --verbose` test for HTTP 308",
        "sim_diff_1": "diff --git a/tests/test_redirects.py b/tests/test_redirects.py @@ -7,6 +7,10 @@ from .utils import http, HTTP_OK\nfrom .utils.matching import assert_output_matches, Expect, ExpectSequence\n+# <https://developer.mozilla.org/en-US/docs/Web/HTTP/Redirections>\n+REDIRECTS_WITH_METHOD_BODY_PRESERVED = [307, 308]\n+\n+\ndef test_follow_all_redirects_shown(httpbin):\nr = http('--follow', '--all', httpbin.url + '/redirect/2')\nassert r.count('HTTP/1.1') == 3\n@@ -37,6 +41,7 @@ def test_follow_all_output_options_used_for_redirects(httpbin):\nassert r.count('GET /') == 3\nassert HTTP_OK not in r\n+\n#\n# def test_follow_redirect_output_options(httpbin):\n# r = http('--check-status',\n@@ -61,16 +66,21 @@ def test_max_redirects(httpbin):\nassert r.exit_status == ExitStatus.ERROR_TOO_MANY_REDIRECTS\n-def test_http_307_allow_redirect_post(httpbin):\n- r = http('--follow', 'POST', httpbin.url + '/redirect-to',\n- f'url=={httpbin.url}/post', 'status_code==307',\n- '@' + FILE_PATH_ARG)\n+@pytest.mark.parametrize('status_code', REDIRECTS_WITH_METHOD_BODY_PRESERVED)\n+def test_follow_redirect_with_repost(httpbin, status_code):\n+ r = http(\n+ '--follow',\n+ httpbin.url + '/redirect-to',\n+ f'url=={httpbin.url}/post',\n+ f'status_code=={status_code}',\n+ '@' + FILE_PATH_ARG,\n+ )\nassert HTTP_OK in r\n+ assert FILE_CONTENT in r\n-@pytest.mark.parametrize('status_code', [307, 308])\n+@pytest.mark.parametrize('status_code', REDIRECTS_WITH_METHOD_BODY_PRESERVED)\ndef test_verbose_follow_redirect_with_repost(httpbin, status_code):\n- # <https://developer.mozilla.org/en-US/docs/Web/HTTP/Redirections>\nr = http(\n'--follow',\n'--verbose',\n",
        "sim_msg_1": "Add `--follow` test for HTTP 308",
        "sim_diff_2": "diff --git a/tests/test_exit_status.py b/tests/test_exit_status.py @@ -33,7 +33,7 @@ def test_error_response_exits_0_without_check_status(httpbin):\ndef test_timeout_exit_status(httpbin):\n- r = http('--timeout=0.01', 'GET', httpbin.url + '/delay/0.02',\n+ r = http('--timeout=0.01', 'GET', httpbin.url + '/delay/0.5',\nerror_exit_ok=True)\nassert r.exit_status == ExitStatus.ERROR_TIMEOUT\n",
        "sim_msg_2": "Test --timeout with longer delay\ntest_timeout_exit_status fails on Python 2.7",
        "sim_diff_3": "diff --git a/test_scaffold/tests.py b/test_scaffold/tests.py @@ -128,7 +128,16 @@ class BaseWebTestCase(BaseTestCase):\nlen(redirect_chain),\n'Unexpected redirect, should have stayed on [%s]. %s' % (view_name, extra_message,))\n- def _check_response_redirect_chain(self, view_name, another, response, extra_message='', secure=False):\n+ def _check_response_redirect_chain(\n+ self,\n+ view_name,\n+ another,\n+ response,\n+ extra_message='',\n+ secure=False,\n+ redirect_chain_offset=-1,\n+ **kwargs\n+ ):\n\"\"\"Check that response.redirect_chain is behaving correctly\n\"\"\"\nredirect_chain = response.redirect_chain\n@@ -147,7 +156,7 @@ class BaseWebTestCase(BaseTestCase):\nprotocol_pattern = protocol_pattern + '%s%s'\npattern = protocol_pattern % (TESTSERVER, reverse(another),)\n- actual = redirect_chain[-1][0]\n+ actual = redirect_chain[redirect_chain_offset][0]\nmatch = re.match(pattern, actual)\nself.assertIsNotNone(\nmatch,\n@@ -158,7 +167,18 @@ class BaseWebTestCase(BaseTestCase):\n)\n)\n- def _check_view_redirects_to_another(self, view_name, another, client=None, params=None, view_args=None, view_kwargs=None, method='get', secure=False):\n+ def _check_view_redirects_to_another(\n+ self,\n+ view_name,\n+ another,\n+ client=None,\n+ params=None,\n+ view_args=None,\n+ view_kwargs=None,\n+ method='get',\n+ secure=False,\n+ **kwargs\n+ ):\n\"\"\"Perform an HTTP request and check that the redirect_chain behaves correctly for a page that is expected to redirect\n\"\"\"\nif method == 'get':\n@@ -167,7 +187,13 @@ class BaseWebTestCase(BaseTestCase):\nresponse = self._post(view_name, client=client, params=params, view_args=view_args, view_kwargs=view_kwargs, follow=True, secure=secure)\nelse:\nraise Exception('Unknown HTTP method: %s' % method)\n- self._check_response_redirect_chain(view_name, another, response, secure=secure)\n+ self._check_response_redirect_chain(\n+ view_name,\n+ another,\n+ response,\n+ secure=secure,\n+ **kwargs\n+ )\ndef _check_view_redirects_to_login(self, view_name, client=None, login_url_name='account_login', secure=False):\nself._check_view_redirects_to_another(view_name, login_url_name, client=client, secure=secure)\n",
        "sim_msg_3": "allow specifying arbitrary redirect_chain_offset"
    },
    {
        "org_diff": "diff --git a/examples/javascript/README.rst b/a/examples/javascript/README.rst @@ -15,7 +15,7 @@ page. Demonstrates using |fetch|_, |XMLHttpRequest|_,  and\n .. |jQuery.ajax| replace:: ``jQuery.ajax``\n .. _jQuery.ajax: https://api.jquery.com/jQuery.ajax/\n \n-.. _Flask docs: https://flask.palletsprojects.com/patterns/jquery/\n+.. _Flask docs: https://flask.palletsprojects.com/patterns/javascript/\n \n \n Install",
        "sim_diff_0": "diff --git a/app/static/js/main.js b/app/static/js/main.js @@ -114,7 +114,7 @@ if(sa){\nfetch: function(text, update) {\ntext = text.toLowerCase();\n// you can also use AJAX requests instead of preloaded data\n- u.get('/api/v3/search/sub?query=' + text, function(data){\n+ u.get('/api/v3/sub?query=' + text, function(data){\nconsole.log(data.results)\nvar suggestions = data.results\nupdate(suggestions);\n",
        "sim_msg_0": "Fixing sub autocomplete",
        "sim_diff_1": "diff --git a/inc/overview.js b/inc/overview.js @@ -6,7 +6,8 @@ function ajaxActionServers(action, id) {\nurl: \"options.py\",\ndata: {\naction_hap: action,\n- serv: id\n+ serv: id,\n+ token: $('#token').val()\n},\nsuccess: function( data ) {\ndata = data.replace(/\\s+/g,' ');\n",
        "sim_msg_1": "v2.5.6\nNeed more security!!\nbugs",
        "sim_diff_2": "diff --git a/v7/localsearch/conf.py.sample b/v7/localsearch/conf.py.sample @@ -32,17 +32,22 @@ BODY_END = \"\"\"\n</div>\n</div>\n<script>\n+\"\"\"\n+BODY_END += \"\"\"\n+ var siteUrl = \"{siteUrl}\"\n+\"\"\".format(siteUrl = SITE_URL)\n+BODY_END += \"\"\"\n$(document).ready(function() {\n$.when(\n- $.getScript( \"/assets/js/tipuesearch_set.js\" ),\n- $.getScript( \"/assets/js/tipuesearch.js\" ),\n+ $.getScript( siteUrl + \"/assets/js/tipuesearch_set.js\" ),\n+ $.getScript( siteUrl + \"/assets/js/tipuesearch.js\" ),\n$.Deferred(function( deferred ){\n$( deferred.resolve );\n})\n).done(function() {\n$('#tipue_search_input').tipuesearch({\n'mode': 'json',\n- 'contentLocation': '/assets/js/tipuesearch_content.json'\n+ 'contentLocation': siteUrl + '/assets/js/tipuesearch_content.json'\n});\n$('#tipue_search_input').keyup(function (e) {\nif (e.keyCode == 13) {\n",
        "sim_msg_2": "Fix for Non-root context",
        "sim_diff_3": "diff --git a/app/static/js/site.js b/app/static/js/site.js @@ -839,7 +839,7 @@ $(document).ready(function() {\n});\n}\n});\n- $('span[id^=\"block\"').click(function(e){\n+ $('span[id^=\"block\"]').click(function(e){\nvar sid = $(e.currentTarget).data().sid\nif($(this).hasClass('unblocked')) {\n$.ajax({\n",
        "sim_msg_3": "Fixing yet another js error."
    },
    {
        "org_diff": "diff --git a/docs/index.rst b/a/docs/index.rst @@ -6,7 +6,11 @@ Welcome to Flask\n .. image:: _static/flask-horizontal.png\n     :align: center\n \n-Welcome to Flask's documentation. Get started with :doc:`installation`\n+Welcome to Flask's documentation. Flask is a lightweight WSGI web application framework.\n+It is designed to make getting started quick and easy, with the ability to scale up to\n+complex applications.\n+\n+Get started with :doc:`installation`\n and then get an overview with the :doc:`quickstart`. There is also a\n more detailed :doc:`tutorial/index` that shows how to create a small but\n complete application with Flask. Common patterns are described in the",
        "sim_diff_0": "diff --git a/docs/deploying/index.rst b/docs/deploying/index.rst @@ -17,7 +17,7 @@ Hosted options\n--------------\n- `Deploying Flask on Heroku <https://devcenter.heroku.com/articles/getting-started-with-python>`_\n-- `Deploying Flask on Google App Engine <https://cloud.google.com/appengine/docs/standard/python/getting-started/python-standard-env>`_\n+- `Deploying Flask on Google App Engine <https://cloud.google.com/appengine/docs/standard/python3/runtime>`_\n- `Deploying Flask on AWS Elastic Beanstalk <https://docs.aws.amazon.com/elasticbeanstalk/latest/dg/create-deploy-python-flask.html>`_\n- `Deploying on Azure (IIS) <https://docs.microsoft.com/en-us/azure/app-service/containers/how-to-configure-python>`_\n- `Deploying on PythonAnywhere <https://help.pythonanywhere.com/pages/Flask/>`_\n",
        "sim_msg_0": "docs: update \"Deploying on Google App Engine\"\nUse the documentation for Python 3 instead of Python 2, which is deprecated.",
        "sim_diff_1": "diff --git a/modules/frontend/server.py b/modules/frontend/server.py @@ -4,10 +4,29 @@ import os\nPEOPLE_FOLDER = os.path.join('static','styles')\napp = Flask(__name__)\n-@app.route(\"/\")\n-def hello_world():\n+@app.route(\"/\", methods=['GET'])\n+def index():\nreturn render_template('pngHome.html')\n+config_values = {}\n+\n+@app.route('/process', methods=['POST'])\n+def getValues():\n+ if request.method =='POST':\n+ config_values[\"dcmFolder\"] = request.form['DICOMFolder']\n+ config_values[\"outputFolder\"] = request.form['outputFolder']\n+ config_values[\"depth\"] = request.form['depth']\n+ config_values[\"chunks\"] = request.form['chunks']\n+ config_values[\"useProcess\"] = request.form['useProcess']\n+ config_values[\"level\"] = request.form['level']\n+ config_values[\"16Bit\"] = request.form['16Bit']\n+ config_values[\"printImages\"] = request.form['printImages']\n+ config_values[\"headers\"] = request.form['headers']\n+ config_values[\"sendEmail\"] = request.form['sendEmail']\n+ config_values[\"email\"] = request.form['email']\n+ print(config_values)\n+ return config_values\n+\n#JUST DO IT!!!\nif __name__==\"__main__\":\n- app.run(host=\"0.0.0.0\", port=\"9000\",threaded=False)\n\\ No newline at end of file\n+ app.run( port=\"9000\")\n\\ No newline at end of file\n",
        "sim_msg_1": "PNG Extraction Frontend",
        "sim_diff_2": "diff --git a/flask_app.py b/flask_app.py @@ -59,7 +59,9 @@ def parse_file():\ndef parse_file():\nret = []\nkeys = {}\n- with open(\"docs/elements.txt\", \"r\", encoding=\"utf8\") as txt:\n+ THIS_FOLDER = os.path.dirname(os.path.abspath(__file__))\n+ file = os.path.join(THIS_FOLDER, 'docs/elements.txt')\n+ with open(file, \"r\", encoding=\"utf8\") as txt:\nfor line in txt:\nif line == \"\\n\": #Finished\nbreak\n",
        "sim_msg_2": "frick you pythonanywhere for not letting my file references work",
        "sim_diff_3": "diff --git a/flask_app.py b/flask_app.py @@ -40,3 +40,7 @@ def index():\nreturn render_template('index.html', code=code, header=header, footer=footer, flags=flags, output=output, inputs=input_list, errors=ret[2])\nreturn render_template('index.html', code=\"\", flags=\"\", output=\"\", header=\"\", footer=\"\", inputs=\"\", errors=\"\")\n+\n+@app.route(\"/ash\")\n+def ash():\n+ return render_template(\"ash.html\")\n\\ No newline at end of file\n",
        "sim_msg_3": "added ash to the online interpreter"
    },
    {
        "org_diff": "diff --git a/docs/patterns/javascript.rst b/a/docs/patterns/javascript.rst @@ -197,7 +197,7 @@ in the previous section. The following example shows how to replace a\n         const geology_div = getElementById(\"geology-fact\")\n         fetch(geology_url)\n             .then(response => response.text)\n-            .then(text => geology_div.innerHtml = text)\n+            .then(text => geology_div.innerHTML = text)\n     </script>\n \n ",
        "sim_diff_0": "diff --git a/app/static/js/Sub.js b/app/static/js/Sub.js @@ -62,7 +62,7 @@ u.sub('#ptoggle', 'click', function(e){\nthis.innerHTML = 'Change to ' + oval + ' post';\ndocument.getElementById('ptype').innerHTML = val;\nif(val=='text'){\n- if(document.getElementById('link').getAttribute('required')){\n+ if(document.getElementById('link').getAttribute('required') === ''){\nwindow.rReq = true;\ndocument.getElementById('link').removeAttribute('required');\n}\n",
        "sim_msg_0": "Properly removing the 'required' property of the link field when switching the form to text post.\nFixes T487",
        "sim_diff_1": "diff --git a/app/static/js/Sub.js b/app/static/js/Sub.js @@ -60,6 +60,7 @@ u.sub('#ptoggle', 'click', function(e){\ndocument.getElementById('ptypeval').value = (document.getElementById('ptypeval').value == 'text') ? 'link' : 'text' ;\nvar val = document.getElementById('ptypeval').value;\nthis.innerHTML = 'Change to ' + oval + ' post';\n+ document.getElementById('ptype').innerHTML = val;\nif(val=='text'){\ndocument.getElementById('txcont').style.display = 'block';\ndocument.getElementById('link').removeAttribute('required');\n",
        "sim_msg_1": "Properly changing the header text on the submit post page",
        "sim_diff_2": "diff --git a/app/static/js/Sub.js b/app/static/js/Sub.js @@ -62,11 +62,16 @@ u.sub('#ptoggle', 'click', function(e){\nthis.innerHTML = 'Change to ' + oval + ' post';\ndocument.getElementById('ptype').innerHTML = val;\nif(val=='text'){\n+ if(document.getElementById('link').getAttribute('required')){\n+ window.rReq = true;\ndocument.getElementById('link').removeAttribute('required');\n+ }\nu.each('.lncont', function(e){e.style.display='none';});\nu.each('.txcont', function(e){e.style.display='inline-block';});\n}else{\n+ if(window.rReq){\ndocument.getElementById('link').setAttribute('required', true);\n+ }\nu.each('.lncont', function(e){e.style.display='inline-block';});\nu.each('.txcont', function(e){e.style.display='none';});\n}\n",
        "sim_msg_2": "Only setting required attribute on link field if the user can't upload files. Fixes T430",
        "sim_diff_3": "diff --git a/app/static/js/Sub.js b/app/static/js/Sub.js @@ -63,12 +63,10 @@ u.sub('#ptoggle', 'click', function(e){\nif(val=='text'){\ndocument.getElementById('txcont').style.display = 'block';\ndocument.getElementById('link').removeAttribute('required');\n- document.getElementById('content').setAttribute('required', true);\nu.each('.lncont', function(e){e.style.display='none';});\n}else{\ndocument.getElementById('txcont').style.display = 'none';\ndocument.getElementById('link').setAttribute('required', true);\n- document.getElementById('content').removeAttribute('required');\nu.each('.lncont', function(e){e.style.display='inline-block';});\n}\n});\n",
        "sim_msg_3": "Not adding required attribute to post content box after switching from link mode. Fixes T379"
    },
    {
        "org_diff": "diff --git a/.github/workflows/publish.yaml b/a/.github/workflows/publish.yaml @@ -63,10 +63,10 @@ jobs:\n     steps:\n       - uses: actions/download-artifact@9bc31d5ccc31df68ecc42ccf4149144866c47d8a\n       # Try uploading to Test PyPI first, in case something fails.\n-      - uses: pypa/gh-action-pypi-publish@f8c70e705ffc13c3b4d1221169b84f12a75d6ca8\n+      - uses: pypa/gh-action-pypi-publish@b7f401de30cb6434a1e19f805ff006643653240e\n         with:\n           repository-url: https://test.pypi.org/legacy/\n           packages-dir: artifact/\n-      - uses: pypa/gh-action-pypi-publish@f8c70e705ffc13c3b4d1221169b84f12a75d6ca8\n+      - uses: pypa/gh-action-pypi-publish@b7f401de30cb6434a1e19f805ff006643653240e\n         with:\n           packages-dir: artifact/",
        "sim_diff_0": "diff --git a/.github/workflows/full-build.yml b/.github/workflows/full-build.yml @@ -397,7 +397,7 @@ jobs:\nname: Publish to PyPI (release only)\nneeds: [ linux-gtk4, linux-flatpak-devel, macos-gtk4, check-linux-appimage, check-macos-app, check-windows-installer ]\nruns-on: ubuntu-22.04\n- # if: github.event_name == 'release'\n+ if: github.event_name == 'release'\nsteps:\n- uses: actions/download-artifact@v3\nwith:\n@@ -410,4 +410,3 @@ jobs:\n- uses: pypa/gh-action-pypi-publish@release/v1\nwith:\npassword: ${{ secrets.PYPI_TOKEN }}\n- repository_url: https://test.pypi.org/legacy/\n",
        "sim_msg_0": "Change publish target for production",
        "sim_diff_1": "diff --git a/.github/workflows/pypi_upload.yml b/.github/workflows/pypi_upload.yml @@ -47,7 +47,7 @@ jobs:\n# to upload to test pypi, pass repository_url: https://test.pypi.org/legacy/ and use secrets.TEST_PYPI_TOKEN\n- name: Publish a Python distribution to PyPI\n- uses: pypa/gh-action-pypi-publish@master\n+ uses: pypa/gh-action-pypi-publish@release/v1\nwith:\nuser: __token__\npassword: ${{ secrets.PYPI_TOKEN }}\n",
        "sim_msg_1": "Update pypi release action.",
        "sim_diff_2": "diff --git a/.github/workflows/pypi_upload.yml b/.github/workflows/pypi_upload.yml @@ -54,8 +54,8 @@ jobs:\nuses: pypa/gh-action-pypi-publish@master\nwith:\nuser: __token__\n- password: ${{ secrets.TEST_PYPI_TOKEN }}\n- repository_url: https://test.pypi.org/legacy/\n+ password: ${{ secrets.PYPI_TOKEN }}\n+ # repository_url: https://test.pypi.org/legacy/\npackages_dir: dist/\n# git push https://${{ github.actor }}:${{ secrets.GITHUB_TOKEN }}@github.com/${{ github.repository }}.git HEAD:master\n",
        "sim_msg_2": "Switch automated release action to point at production pypi",
        "sim_diff_3": "diff --git a/.github/workflows/build.yml b/.github/workflows/build.yml @@ -73,8 +73,7 @@ jobs:\npath: dist/gaphor-${{ steps.meta.outputs.version }}-py3-none-any.whl\n- name: Publish to PyPI\nif: github.event_name == 'release'\n- run: |\n- poetry publish -u __token__ -p ${{ secrets.PYPI_TOKEN }}\n+ run: poetry publish -u __token__ -p ${{ secrets.PYPI_TOKEN }}\nwindows:\nneeds: lint\n@@ -104,16 +103,14 @@ jobs:\nkey: ${{ runner.os }}-poetry-${{ hashFiles('**/poetry.lock') }}\nrestore-keys: ${{ runner.os }}-poetry-\n- name: Install Dependencies\n- run: |\n- ./win-installer/msys2-install.sh\n+ run: ./win-installer/msys2-install.sh\n- name: Install Poetry\nrun: |\npip install poetry==$POETRY_VERSION\npoetry config virtualenvs.create false\n- name: Collect Metadata\nid: meta\n- run: |\n- .github/scripts/metadata.sh\n+ run: .github/scripts/metadata.sh\n- name: Install Python Dependencies\nrun: mingw32-make install\n- name: Run Tests\n@@ -168,9 +165,7 @@ jobs:\n- name: Set up Python\nuses: actions/setup-python@v2.1.3\n- name: Install macOS Dependencies\n- run: |\n- brew list\n- brew install gobject-introspection gtk+3 adwaita-icon-theme gtk-mac-integration create-dmg\n+ run: brew install gobject-introspection gtk+3 adwaita-icon-theme gtk-mac-integration create-dmg\n- name: Install Poetry\nrun: pip install poetry==$POETRY_VERSION\n- name: Collect Metadata\n@@ -183,8 +178,7 @@ jobs:\nkey: ${{ runner.os }}-poetry-${{ hashFiles('**/poetry.lock') }}\nrestore-keys: ${{ runner.os }}-poetry-\n- name: Install Python Dependencies\n- run: |\n- poetry install\n+ run: poetry install\n- name: Test with Pytest\nrun: make test-all\n- name: Create macOS Application\n",
        "sim_msg_3": "Put single line build statements on one line"
    },
    {
        "org_diff": "diff --git a/.github/workflows/publish.yaml b/a/.github/workflows/publish.yaml @@ -33,7 +33,7 @@ jobs:\n       id-token: write\n       contents: write\n     # Can't pin with hash due to how this workflow works.\n-    uses: slsa-framework/slsa-github-generator/.github/workflows/generator_generic_slsa3.yml@v1.7.0\n+    uses: slsa-framework/slsa-github-generator/.github/workflows/generator_generic_slsa3.yml@v1.9.0\n     with:\n       base64-subjects: ${{ needs.build.outputs.hash }}\n   create-release:",
        "sim_diff_0": "diff --git a/.github/workflows/tag-actions.yml b/.github/workflows/tag-actions.yml @@ -10,6 +10,9 @@ jobs:\nname: Github Release\nruns-on: ubuntu-latest\n+ outputs:\n+ upload_url: ${{ steps.create_release.outputs.upload_url }}\n+\nsteps:\n- name: Create Release\nid: create_release\n@@ -125,7 +128,7 @@ jobs:\nenv:\nGITHUB_TOKEN: ${{ secrets.RELEASE_TOKEN }}\nwith:\n- upload_url: ${{ steps.create_release.outputs.upload_url }}\n+ upload_url: ${{ needs.github-release.outputs.upload_url }}\nasset_path: ./rpm/dist/beer-garden-${GITHUB_REF#refs/tags/}-1.el7.x86_64.rpm\nasset_name: beer-garden-${GITHUB_REF#refs/tags/}-1.el7.x86_64.rpm\nasset_content_type: application/octet-stream\n",
        "sim_msg_0": "Need to mark job output",
        "sim_diff_1": "diff --git a/.github/workflows/publish.yml b/.github/workflows/publish.yml @@ -2,7 +2,7 @@ name: publish\non:\npush:\n- branch:\n+ branches:\n- master\njobs:\n@@ -34,4 +34,4 @@ jobs:\nenv:\nPUBLISH_TARGET: ${{ secrets.PUBLISH_TARGET }}\nrun: |\n- rsync -azve \"ssh -o StrictHostKeyChecking=accept-new\" --delete build/anthology/ $PUBLISH_TARGET\n+ rsync -aze \"ssh -o StrictHostKeyChecking=accept-new\" --delete build/anthology/ $PUBLISH_TARGET\n",
        "sim_msg_1": "GH publish action: no verbose logging, only run on master\nSee PR",
        "sim_diff_2": "diff --git a/.github/workflows/release-drafter.yml b/.github/workflows/release-drafter.yml @@ -16,7 +16,7 @@ jobs:\nruns-on: ubuntu-latest\nsteps:\n- uses: release-drafter/release-drafter@v5\n- # with:\n- # disable-autolabeler: true\n+ with:\n+ disable-autolabeler: true\nenv:\nGITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n",
        "sim_msg_2": "explictly disable autolabeler for good measure",
        "sim_diff_3": "diff --git a/.github/workflows/release-drafter.yml b/.github/workflows/release-drafter.yml @@ -15,8 +15,20 @@ jobs:\ncontents: write\nruns-on: ubuntu-latest\nsteps:\n- - uses: release-drafter/release-drafter@v5\n+ - name: Run release-drafter action\n+ id: release-drafter\n+ uses: release-drafter/release-drafter@v5\nwith:\ndisable-autolabeler: true\nenv:\nGITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n+\n+ - name: Adding markdown\n+ run: |\n+ cat <<MKDOWN\n+ ### Release Drafter :rocket:\n+\n+ * **Draft Release URL**:\n+ [${{ steps.release-drafter.outputs.name }} (${{ steps.release-drafter.outputs.id }})](${{ steps.release-drafter.outputs.html_url }})\n+ * **Tag Name**: ${{ steps.release-drafter.outputs.tag_name }}\n+ MKDOWN >> $GITHUB_STEP_SUMMARY\n",
        "sim_msg_3": "Output release-drafter workflow summary"
    },
    {
        "org_diff": "diff --git a/.github/workflows/publish.yaml b/a/.github/workflows/publish.yaml @@ -63,10 +63,10 @@ jobs:\n     steps:\n       - uses: actions/download-artifact@9bc31d5ccc31df68ecc42ccf4149144866c47d8a\n       # Try uploading to Test PyPI first, in case something fails.\n-      - uses: pypa/gh-action-pypi-publish@f8c70e705ffc13c3b4d1221169b84f12a75d6ca8\n+      - uses: pypa/gh-action-pypi-publish@b7f401de30cb6434a1e19f805ff006643653240e\n         with:\n           repository-url: https://test.pypi.org/legacy/\n           packages-dir: artifact/\n-      - uses: pypa/gh-action-pypi-publish@f8c70e705ffc13c3b4d1221169b84f12a75d6ca8\n+      - uses: pypa/gh-action-pypi-publish@b7f401de30cb6434a1e19f805ff006643653240e\n         with:\n           packages-dir: artifact/",
        "sim_diff_0": "diff --git a/.github/workflows/full-build.yml b/.github/workflows/full-build.yml @@ -397,7 +397,7 @@ jobs:\nname: Publish to PyPI (release only)\nneeds: [ linux-gtk4, linux-flatpak-devel, macos-gtk4, check-linux-appimage, check-macos-app, check-windows-installer ]\nruns-on: ubuntu-22.04\n- # if: github.event_name == 'release'\n+ if: github.event_name == 'release'\nsteps:\n- uses: actions/download-artifact@v3\nwith:\n@@ -410,4 +410,3 @@ jobs:\n- uses: pypa/gh-action-pypi-publish@release/v1\nwith:\npassword: ${{ secrets.PYPI_TOKEN }}\n- repository_url: https://test.pypi.org/legacy/\n",
        "sim_msg_0": "Change publish target for production",
        "sim_diff_1": "diff --git a/.github/workflows/pypi_upload.yml b/.github/workflows/pypi_upload.yml @@ -47,7 +47,7 @@ jobs:\n# to upload to test pypi, pass repository_url: https://test.pypi.org/legacy/ and use secrets.TEST_PYPI_TOKEN\n- name: Publish a Python distribution to PyPI\n- uses: pypa/gh-action-pypi-publish@master\n+ uses: pypa/gh-action-pypi-publish@release/v1\nwith:\nuser: __token__\npassword: ${{ secrets.PYPI_TOKEN }}\n",
        "sim_msg_1": "Update pypi release action.",
        "sim_diff_2": "diff --git a/.github/workflows/pypi_upload.yml b/.github/workflows/pypi_upload.yml @@ -54,8 +54,8 @@ jobs:\nuses: pypa/gh-action-pypi-publish@master\nwith:\nuser: __token__\n- password: ${{ secrets.TEST_PYPI_TOKEN }}\n- repository_url: https://test.pypi.org/legacy/\n+ password: ${{ secrets.PYPI_TOKEN }}\n+ # repository_url: https://test.pypi.org/legacy/\npackages_dir: dist/\n# git push https://${{ github.actor }}:${{ secrets.GITHUB_TOKEN }}@github.com/${{ github.repository }}.git HEAD:master\n",
        "sim_msg_2": "Switch automated release action to point at production pypi",
        "sim_diff_3": "diff --git a/.github/workflows/build.yml b/.github/workflows/build.yml @@ -73,8 +73,7 @@ jobs:\npath: dist/gaphor-${{ steps.meta.outputs.version }}-py3-none-any.whl\n- name: Publish to PyPI\nif: github.event_name == 'release'\n- run: |\n- poetry publish -u __token__ -p ${{ secrets.PYPI_TOKEN }}\n+ run: poetry publish -u __token__ -p ${{ secrets.PYPI_TOKEN }}\nwindows:\nneeds: lint\n@@ -104,16 +103,14 @@ jobs:\nkey: ${{ runner.os }}-poetry-${{ hashFiles('**/poetry.lock') }}\nrestore-keys: ${{ runner.os }}-poetry-\n- name: Install Dependencies\n- run: |\n- ./win-installer/msys2-install.sh\n+ run: ./win-installer/msys2-install.sh\n- name: Install Poetry\nrun: |\npip install poetry==$POETRY_VERSION\npoetry config virtualenvs.create false\n- name: Collect Metadata\nid: meta\n- run: |\n- .github/scripts/metadata.sh\n+ run: .github/scripts/metadata.sh\n- name: Install Python Dependencies\nrun: mingw32-make install\n- name: Run Tests\n@@ -168,9 +165,7 @@ jobs:\n- name: Set up Python\nuses: actions/setup-python@v2.1.3\n- name: Install macOS Dependencies\n- run: |\n- brew list\n- brew install gobject-introspection gtk+3 adwaita-icon-theme gtk-mac-integration create-dmg\n+ run: brew install gobject-introspection gtk+3 adwaita-icon-theme gtk-mac-integration create-dmg\n- name: Install Poetry\nrun: pip install poetry==$POETRY_VERSION\n- name: Collect Metadata\n@@ -183,8 +178,7 @@ jobs:\nkey: ${{ runner.os }}-poetry-${{ hashFiles('**/poetry.lock') }}\nrestore-keys: ${{ runner.os }}-poetry-\n- name: Install Python Dependencies\n- run: |\n- poetry install\n+ run: poetry install\n- name: Test with Pytest\nrun: make test-all\n- name: Create macOS Application\n",
        "sim_msg_3": "Put single line build statements on one line"
    },
    {
        "org_diff": "diff --git a/.github/workflows/publish.yaml b/a/.github/workflows/publish.yaml @@ -33,7 +33,7 @@ jobs:\n       id-token: write\n       contents: write\n     # Can't pin with hash due to how this workflow works.\n-    uses: slsa-framework/slsa-github-generator/.github/workflows/generator_generic_slsa3.yml@v1.7.0\n+    uses: slsa-framework/slsa-github-generator/.github/workflows/generator_generic_slsa3.yml@v1.9.0\n     with:\n       base64-subjects: ${{ needs.build.outputs.hash }}\n   create-release:",
        "sim_diff_0": "diff --git a/.github/workflows/tag-actions.yml b/.github/workflows/tag-actions.yml @@ -10,6 +10,9 @@ jobs:\nname: Github Release\nruns-on: ubuntu-latest\n+ outputs:\n+ upload_url: ${{ steps.create_release.outputs.upload_url }}\n+\nsteps:\n- name: Create Release\nid: create_release\n@@ -125,7 +128,7 @@ jobs:\nenv:\nGITHUB_TOKEN: ${{ secrets.RELEASE_TOKEN }}\nwith:\n- upload_url: ${{ steps.create_release.outputs.upload_url }}\n+ upload_url: ${{ needs.github-release.outputs.upload_url }}\nasset_path: ./rpm/dist/beer-garden-${GITHUB_REF#refs/tags/}-1.el7.x86_64.rpm\nasset_name: beer-garden-${GITHUB_REF#refs/tags/}-1.el7.x86_64.rpm\nasset_content_type: application/octet-stream\n",
        "sim_msg_0": "Need to mark job output",
        "sim_diff_1": "diff --git a/.github/workflows/publish.yml b/.github/workflows/publish.yml @@ -2,7 +2,7 @@ name: publish\non:\npush:\n- branch:\n+ branches:\n- master\njobs:\n@@ -34,4 +34,4 @@ jobs:\nenv:\nPUBLISH_TARGET: ${{ secrets.PUBLISH_TARGET }}\nrun: |\n- rsync -azve \"ssh -o StrictHostKeyChecking=accept-new\" --delete build/anthology/ $PUBLISH_TARGET\n+ rsync -aze \"ssh -o StrictHostKeyChecking=accept-new\" --delete build/anthology/ $PUBLISH_TARGET\n",
        "sim_msg_1": "GH publish action: no verbose logging, only run on master\nSee PR",
        "sim_diff_2": "diff --git a/.github/workflows/release-drafter.yml b/.github/workflows/release-drafter.yml @@ -16,7 +16,7 @@ jobs:\nruns-on: ubuntu-latest\nsteps:\n- uses: release-drafter/release-drafter@v5\n- # with:\n- # disable-autolabeler: true\n+ with:\n+ disable-autolabeler: true\nenv:\nGITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n",
        "sim_msg_2": "explictly disable autolabeler for good measure",
        "sim_diff_3": "diff --git a/.github/workflows/release-drafter.yml b/.github/workflows/release-drafter.yml @@ -15,8 +15,20 @@ jobs:\ncontents: write\nruns-on: ubuntu-latest\nsteps:\n- - uses: release-drafter/release-drafter@v5\n+ - name: Run release-drafter action\n+ id: release-drafter\n+ uses: release-drafter/release-drafter@v5\nwith:\ndisable-autolabeler: true\nenv:\nGITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n+\n+ - name: Adding markdown\n+ run: |\n+ cat <<MKDOWN\n+ ### Release Drafter :rocket:\n+\n+ * **Draft Release URL**:\n+ [${{ steps.release-drafter.outputs.name }} (${{ steps.release-drafter.outputs.id }})](${{ steps.release-drafter.outputs.html_url }})\n+ * **Tag Name**: ${{ steps.release-drafter.outputs.tag_name }}\n+ MKDOWN >> $GITHUB_STEP_SUMMARY\n",
        "sim_msg_3": "Output release-drafter workflow summary"
    },
    {
        "org_diff": "diff --git a/CHANGES.rst b/a/CHANGES.rst @@ -11,7 +11,7 @@ Unreleased\n Version 2.3.3\n -------------\n \n-Unreleased\n+Released 2023-08-21\n \n -   Python 3.12 compatibility.\n -   Require Werkzeug >= 2.3.7.",
        "sim_diff_0": "diff --git a/CHANGES.rst b/CHANGES.rst Changes\n=======\n-v2.0 (in development)\n----------------------\n+v2.0 (2019-03-06)\n+-----------------\n-This is a major new release with some backwards-incompatible changes.\n-Please review them and adjust your scripts if necessary.\n+This is a major new release with lots of bug fixes and new features, but\n+also some backwards-incompatible changes. These should hopefully\n+not affect too many users, but please make sure to review them and\n+possibly update your scripts!\nBackwards-incompatible changes\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
        "sim_msg_0": "Cutadapt 2.0",
        "sim_diff_1": "diff --git a/docs/releases.rst b/docs/releases.rst @@ -21,6 +21,9 @@ unreleased\n`git master <https://github.com/meejah/txtorcon>`_ *will likely become v19.2.0*\n* Use real GeoIP database or nothing (`#250 <https://github.com/meejah/txtorcon/issues/250>`_)\n* Change abstract base classes import in preperation for Python 3.8 (thanks `@glowatsk <https://github.com/glowatsk>`_\n+ * Python 3.4 is no longer supported\n+ * Python 2 is deprecated; all new code should be Python 3. Support\n+ for Python 2 will be removed in a future release.\nv19.1.0\n",
        "sim_msg_1": "deprecate python2",
        "sim_diff_2": "diff --git a/docs/about/whats_new.rst b/docs/about/whats_new.rst @@ -14,6 +14,7 @@ v1.8rc (???)\n- Remove old Search Expressions and replace with a simpler implementation based on Lark Parser. (:pull:`840`)\n- Remove no longer required PyPEG2 dependency. (:pull:`840`)\n- Remove S3AIO driver. (:pull:`865`)\n+- Change development version numbers generation. Use ``setuptools_scm`` instead of ``versioneer``. (:issue:`871`)\nv1.7.0 (16 May 2019)\n",
        "sim_msg_2": "Update Whats New Page",
        "sim_diff_3": "diff --git a/CHANGES.rst b/CHANGES.rst @@ -7,7 +7,7 @@ New Features\nOther Changes and Additions\n^^^^^^^^^^^^^^^^^^^^^^^^^^^\n-- Improved handling of large flags in the `bitfield` module. [#610]\n+- Improved handling of large flags in the ``bitfield`` module. [#610]\nBug Fixes\n^^^^^^^^^\n",
        "sim_msg_3": "Fix docstrings in changelog related to updates to bitfield"
    },
    {
        "org_diff": "diff --git a/src/flask/app.py b/a/src/flask/app.py @@ -409,7 +409,6 @@ def create_url_adapter(self, request: Request | None) -> MapAdapter | None:\n             else:\n                 subdomain = None\n \n-            print(self.config[\"SERVER_NAME\"], subdomain)\n             return self.url_map.bind_to_environ(\n                 request.environ,\n                 server_name=self.config[\"SERVER_NAME\"],",
        "sim_diff_0": "diff --git a/flask/testing.py b/flask/testing.py @@ -40,10 +40,10 @@ def make_test_environ_builder(\nif subdomain:\nhttp_host = '{0}.{1}'.format(subdomain, http_host)\n+ url = url_parse(path)\nif url_scheme is None:\n- url_scheme = app.config['PREFERRED_URL_SCHEME']\n+ url_scheme = url.scheme or app.config['PREFERRED_URL_SCHEME']\n- url = url_parse(path)\nbase_url = '{0}://{1}/{2}'.format(\nurl_scheme, url.netloc or http_host, app_root.lstrip('/')\n)\n",
        "sim_msg_0": "make_test_environ_builder: use url_scheme from path if provided\nWhen providing https url in path (\"https://example.com/\")\nwe hope that we will get https scheme in environment",
        "sim_diff_1": "diff --git a/flask/ctx.py b/flask/ctx.py @@ -282,7 +282,11 @@ class RequestContext(object):\nif request is None:\nrequest = app.request_class(environ)\nself.request = request\n+ self.url_adapter = None\n+ try:\nself.url_adapter = app.create_url_adapter(self.request)\n+ except HTTPException as e:\n+ self.request.routing_exception = e\nself.flashes = None\nself.session = session\n@@ -305,6 +309,7 @@ class RequestContext(object):\n# functions.\nself._after_request_functions = []\n+ if self.url_adapter is not None:\nself.match_request()\ndef _get_g(self):\n",
        "sim_msg_1": "Handle errors during create_url_adapter\nIf create_url_adapter raises (which it can if werkzeug cannot bind\nenvironment, for example on non-ASCII Host header), we handle it as\nother routing exceptions rather than raising through.\nref",
        "sim_diff_2": "diff --git a/src/flask/app.py b/src/flask/app.py @@ -960,17 +960,24 @@ class Flask(_PackageBoundObject):\nif debug is not None:\nself.debug = bool(debug)\n- _host = \"127.0.0.1\"\n- _port = 5000\nserver_name = self.config.get(\"SERVER_NAME\")\n- sn_host, sn_port = None, None\n+ sn_host = sn_port = None\nif server_name:\nsn_host, _, sn_port = server_name.partition(\":\")\n- host = host or sn_host or _host\n- # pick the first value that's not None (0 is allowed)\n- port = int(next((p for p in (port, sn_port) if p is not None), _port))\n+ if not host:\n+ if sn_host:\n+ host = sn_host\n+ else:\n+ host = \"127.0.0.1\"\n+\n+ if port or port == 0:\n+ port = int(port)\n+ elif sn_port:\n+ port = int(sn_port)\n+ else:\n+ port = 5000\noptions.setdefault(\"use_reloader\", self.debug)\noptions.setdefault(\"use_debugger\", self.debug)\n@@ -2146,11 +2153,11 @@ class Flask(_PackageBoundObject):\n# If subdomain matching is disabled (the default), use the\n# default subdomain in all cases. This should be the default\n# in Werkzeug but it currently does not have that feature.\n- subdomain = (\n- (self.url_map.default_subdomain or None)\n- if not self.subdomain_matching\n- else None\n- )\n+ if not self.subdomain_matching:\n+ subdomain = self.url_map.default_subdomain or None\n+ else:\n+ subdomain = None\n+\nreturn self.url_map.bind_to_environ(\nrequest.environ,\nserver_name=self.config[\"SERVER_NAME\"],\n",
        "sim_msg_2": "refactor variable choices into if blocks",
        "sim_diff_3": "diff --git a/ghdata/server.py b/ghdata/server.py @@ -53,6 +53,8 @@ def flaskify(flaskapp, func):\nreturn generated_function\n+def run():\n+\napp = Flask(__name__, static_url_path=os.path.abspath('static/'))\nCORS(app)\n# Flags and Initialization\n@@ -431,7 +433,6 @@ if (DEBUG):\napp.debug = True\n-def run():\napp.run(host=host, port=int(port), debug=DEBUG)\nif __name__ == '__main__':\n",
        "sim_msg_3": "Refactor server to prevent execution on import"
    },
    {
        "org_diff": "diff --git a/CHANGES.rst b/a/CHANGES.rst @@ -4,6 +4,8 @@ Version 3.0.0\n Unreleased\n \n -   Remove previously deprecated code. :pr:`5223`\n+-   Restructure the code such that the Flask (app) and Blueprint\n+    classes have Sans-IO bases. :pr:`5127`\n \n \n Version 2.3.3",
        "sim_diff_0": "diff --git a/tests/test_blueprints.py b/tests/test_blueprints.py @@ -679,3 +679,65 @@ def test_template_global():\nwith app.app_context():\nrv = flask.render_template_string('{{ get_answer() }}')\nassert rv == '42'\n+\n+def test_request_processing():\n+ app = flask.Flask(__name__)\n+ bp = flask.Blueprint('bp', __name__)\n+ evts = []\n+ @bp.before_request\n+ def before_bp():\n+ evts.append('before')\n+ @bp.after_request\n+ def after_bp(response):\n+ response.data += b'|after'\n+ evts.append('after')\n+ return response\n+\n+ # Setup routes for testing\n+ @bp.route('/bp')\n+ def bp_endpoint():\n+ return 'request'\n+\n+ app.register_blueprint(bp)\n+\n+ assert evts == []\n+ rv = app.test_client().get('/bp')\n+ assert rv.data == b'request|after'\n+ assert evts == ['before', 'after']\n+\n+def test_app_request_processing():\n+ app = flask.Flask(__name__)\n+ bp = flask.Blueprint('bp', __name__)\n+ evts = []\n+\n+ @bp.before_app_first_request\n+ def before_first_request():\n+ evts.append('first')\n+ @bp.before_app_request\n+ def before_app():\n+ evts.append('before')\n+ @bp.after_app_request\n+ def after_app(response):\n+ response.data += b'|after'\n+ evts.append('after')\n+ return response\n+\n+ app.register_blueprint(bp)\n+\n+ # Setup routes for testing\n+ @app.route('/')\n+ def bp_endpoint():\n+ return 'request'\n+\n+ # before first request\n+ assert evts == []\n+\n+ # first request\n+ resp = app.test_client().get('/').data\n+ assert resp == b'request|after'\n+ assert evts == ['first', 'before', 'after']\n+\n+ # second request\n+ resp = app.test_client().get('/').data\n+ assert resp == b'request|after'\n+ assert evts == ['first', 'before', 'after', 'before', 'after']\n",
        "sim_msg_0": "Add coverage for Blueprint request process methods\nAdd test to cover following methodss to the Blueprint object:\nbefore_request, after_request, before_app_request,\nbefore_app_first_request, after_app_request.\nThis PR increases the coverage of flask.blueprints by 6%.",
        "sim_diff_1": "diff --git a/tests/test_blueprints.py b/tests/test_blueprints.py @@ -660,3 +660,22 @@ def test_context_processing():\nassert b'42' in answer_page_bytes\nassert b'43' in answer_page_bytes\n+\n+def test_template_global():\n+ app = flask.Flask(__name__)\n+ bp = flask.Blueprint('bp', __name__)\n+ @bp.app_template_global()\n+ def get_answer():\n+ return 42\n+ # Make sure the function is not in the jinja_env already\n+ assert 'get_answer' not in app.jinja_env.globals.keys()\n+ app.register_blueprint(bp)\n+\n+ # Tests\n+ assert 'get_answer' in app.jinja_env.globals.keys()\n+ assert app.jinja_env.globals['get_answer'] is get_answer\n+ assert app.jinja_env.globals['get_answer']() == 42\n+\n+ with app.app_context():\n+ rv = flask.render_template_string('{{ get_answer() }}')\n+ assert rv == '42'\n",
        "sim_msg_1": "Add coverage for Blueprint.add_app_template_global\nThis tests the Blueprint.add_app_template_global mothod, which internally\ncalls the Blueprint.app_template_global method. The methods are used to\nregistering a function to the jinja template environment.\nThis PR increases the test coverage for module flask.blueprint by 4%.",
        "sim_diff_2": "diff --git a/tests/test_blueprints.py b/tests/test_blueprints.py @@ -91,6 +91,33 @@ def test_blueprint_specific_user_error_handling():\nassert c.get('/decorator').data == b'boom'\nassert c.get('/function').data == b'bam'\n+def test_blueprint_app_error_handling():\n+ errors = flask.Blueprint('errors', __name__)\n+\n+ @errors.app_errorhandler(403)\n+ def forbidden_handler(e):\n+ return 'you shall not pass', 403\n+\n+ app = flask.Flask(__name__)\n+\n+ @app.route('/forbidden')\n+ def app_forbidden():\n+ flask.abort(403)\n+\n+ forbidden_bp = flask.Blueprint('forbidden_bp', __name__)\n+\n+ @forbidden_bp.route('/nope')\n+ def bp_forbidden():\n+ flask.abort(403)\n+\n+ app.register_blueprint(errors)\n+ app.register_blueprint(forbidden_bp)\n+\n+ c = app.test_client()\n+\n+ assert c.get('/forbidden').data == b'you shall not pass'\n+ assert c.get('/nope').data == b'you shall not pass'\n+\ndef test_blueprint_url_definitions():\nbp = flask.Blueprint('test', __name__)\n",
        "sim_msg_2": "Add coverage for Blueprint.app_errorhandler\nThis test case registers an application-wise error handler from\na Blueprint. Verifies the error handler by aborting the flask app\nfrom the application itself as well as from another registered\nBlueprint.",
        "sim_diff_3": "diff --git a/blueprints/apiv1.py b/blueprints/apiv1.py @@ -2,29 +2,9 @@ import sys\nfrom os import path, remove\nsys.path.append(path.dirname(path.dirname(path.abspath(__file__))))\n-from flask import Blueprint, request, url_for\n+from flask import Blueprint, url_for\nfrom flask_restplus import Api, Resource, reqparse\n-import shutil\n-import uuid\n-import datetime\n-import socket\n-\n-from classes import Sec\n-from classes import Channel\n-from classes import Stream\n-from classes import RecordedVideo\n-from classes import topics\n-from classes import upvotes\n-from classes import apikey\n-from classes import views\n-from classes import settings\n-from classes.shared import db\n-\n-from functions import rtmpFunc\n-from functions import system\n-\n-from globals import globalvars\nfrom .apis.server_ns import api as serverNS\nfrom .apis.channel_ns import api as channelNS\n@@ -37,19 +17,6 @@ from .apis.xmpp_ns import api as xmppNS\nfrom .apis.rtmp_ns import api as rtmpNS\n-def isValidAdminKey(apikey):\n- validKey = False\n- apiKeyQuery = apikey.apikey.query.filter_by(type=2, key=apikey).first()\n- if apiKeyQuery is not None:\n- if apiKeyQuery.isValid() is True:\n- userID = apiKeyQuery.userID\n- userQuery = Sec.User.query.filter_by(id=userID).first()\n- if userQuery is not None:\n- if userQuery.has_role(\"Admin\"):\n- validKey = True\n- return validKey\n-\n-\nclass fixedAPI(Api):\n# Monkeyfixed API IAW https://github.com/noirbizarre/flask-restplus/issues/223\n@property\n",
        "sim_msg_3": "Cleaned up unneeded imports"
    },
    {
        "org_diff": "diff --git a/src/flask/typing.py b/a/src/flask/typing.py @@ -77,7 +77,10 @@\n # https://github.com/pallets/flask/issues/4095\n # https://github.com/pallets/flask/issues/4295\n # https://github.com/pallets/flask/issues/4297\n-ErrorHandlerCallable = t.Callable[[t.Any], ResponseReturnValue]\n+ErrorHandlerCallable = t.Union[\n+    t.Callable[[t.Any], ResponseReturnValue],\n+    t.Callable[[t.Any], t.Awaitable[ResponseReturnValue]],\n+]\n \n RouteCallable = t.Union[\n     t.Callable[..., ResponseReturnValue],",
        "sim_diff_0": "diff --git a/src/flask/app.py b/src/flask/app.py @@ -23,7 +23,6 @@ from werkzeug.exceptions import BadRequestKeyError\nfrom werkzeug.exceptions import default_exceptions\nfrom werkzeug.exceptions import HTTPException\nfrom werkzeug.exceptions import InternalServerError\n-from werkzeug.exceptions import MethodNotAllowed\nfrom werkzeug.routing import BuildError\nfrom werkzeug.routing import Map\nfrom werkzeug.routing import RequestRedirect\n@@ -2000,17 +1999,7 @@ class Flask(_PackageBoundObject):\n.. versionadded:: 0.7\n\"\"\"\nadapter = _request_ctx_stack.top.url_adapter\n- if hasattr(adapter, \"allowed_methods\"):\nmethods = adapter.allowed_methods()\n- else:\n- # fallback for Werkzeug < 0.7\n- methods = []\n- try:\n- adapter.match(method=\"--\")\n- except MethodNotAllowed as e:\n- methods = e.valid_methods\n- except HTTPException:\n- pass\nrv = self.response_class()\nrv.allow.update(methods)\nreturn rv\n",
        "sim_msg_0": "clean up outdated code",
        "sim_diff_1": "diff --git a/flask/app.py b/flask/app.py @@ -1728,9 +1728,7 @@ class Flask(_PackageBoundObject):\n.. versionadded:: 0.3\n\"\"\"\nexc_type, exc_value, tb = sys.exc_info()\n-\ngot_request_exception.send(self, exception=e)\n- handler = self._find_error_handler(InternalServerError())\nif self.propagate_exceptions:\n# if we want to repropagate the exception, we can attempt to\n@@ -1743,6 +1741,7 @@ class Flask(_PackageBoundObject):\nraise e\nself.log_exception((exc_type, exc_value, tb))\n+ handler = self._find_error_handler(InternalServerError())\nif handler is None:\nreturn InternalServerError()\nreturn self.finalize_request(handler(e), from_error_handler=True)\n",
        "sim_msg_1": "Reduce unnecessary function calls.\nWhen propagate exceptions, the function call of \"_find_error_handler\"\nmakes no sense.",
        "sim_diff_2": "diff --git a/src/flask/cli.py b/src/flask/cli.py @@ -9,6 +9,8 @@ from functools import update_wrapper\nfrom operator import attrgetter\nfrom threading import Lock\nfrom threading import Thread\n+from typing import Any\n+from typing import TYPE_CHECKING\nimport click\nfrom werkzeug.utils import import_string\n@@ -36,7 +38,12 @@ else:\n# We technically have importlib.metadata on 3.8+,\n# but the API changed in 3.10, so use the backport\n# for consistency.\n- import importlib_metadata as metadata # type: ignore\n+ if TYPE_CHECKING:\n+ metadata: Any\n+ else:\n+ # we do this to avoid a version dependent mypy error\n+ # because importlib_metadata is not installed in python3.10+\n+ import importlib_metadata as metadata\nclass NoAppException(click.UsageError):\n",
        "sim_msg_2": "Fix linting error.\nSuppress mypy.\nSuppress mypy error.\nSuppress mypy error.",
        "sim_diff_3": "diff --git a/flask/app.py b/flask/app.py @@ -1270,7 +1270,11 @@ class Flask(_PackageBoundObject):\n@staticmethod\ndef _get_exc_class_and_code(exc_class_or_code):\n- \"\"\"Ensure that we register only exceptions as handler keys\"\"\"\n+ \"\"\"Ensure that we register only exceptions as handler keys\n+\n+ :param exc_class_or_code: the class for the exception, or\n+ exception code as integer\n+ \"\"\"\nif isinstance(exc_class_or_code, integer_types):\nexc_class = default_exceptions[exc_class_or_code]\nelse:\n",
        "sim_msg_3": "document _get_exc_class_and_code params"
    },
    {
        "org_diff": "diff --git a/src/flask/typing.py b/a/src/flask/typing.py @@ -5,7 +5,7 @@\n if t.TYPE_CHECKING:  # pragma: no cover\n     from _typeshed.wsgi import WSGIApplication  # noqa: F401\n     from werkzeug.datastructures import Headers  # noqa: F401\n-    from werkzeug.wrappers import Response  # noqa: F401\n+    from werkzeug.sansio.response import Response  # noqa: F401\n \n # The possible types that are directly convertible or are a Response object.\n ResponseValue = t.Union[",
        "sim_diff_0": "diff --git a/flask/helpers.py b/flask/helpers.py @@ -23,7 +23,7 @@ from werkzeug.routing import BuildError\nfrom functools import update_wrapper\nfrom werkzeug.urls import url_quote\n-from werkzeug.datastructures import Headers, Range\n+from werkzeug.datastructures import Headers\nfrom werkzeug.exceptions import BadRequest, NotFound, RequestedRangeNotSatisfiable\nfrom werkzeug.wsgi import wrap_file\n",
        "sim_msg_0": "Issue Remove unused werkzeug datastructure import",
        "sim_diff_1": "diff --git a/src/flask/app.py b/src/flask/app.py @@ -23,7 +23,6 @@ from werkzeug.exceptions import BadRequestKeyError\nfrom werkzeug.exceptions import default_exceptions\nfrom werkzeug.exceptions import HTTPException\nfrom werkzeug.exceptions import InternalServerError\n-from werkzeug.exceptions import MethodNotAllowed\nfrom werkzeug.routing import BuildError\nfrom werkzeug.routing import Map\nfrom werkzeug.routing import RequestRedirect\n@@ -2000,17 +1999,7 @@ class Flask(_PackageBoundObject):\n.. versionadded:: 0.7\n\"\"\"\nadapter = _request_ctx_stack.top.url_adapter\n- if hasattr(adapter, \"allowed_methods\"):\nmethods = adapter.allowed_methods()\n- else:\n- # fallback for Werkzeug < 0.7\n- methods = []\n- try:\n- adapter.match(method=\"--\")\n- except MethodNotAllowed as e:\n- methods = e.valid_methods\n- except HTTPException:\n- pass\nrv = self.response_class()\nrv.allow.update(methods)\nreturn rv\n",
        "sim_msg_1": "clean up outdated code",
        "sim_diff_2": "diff --git a/flask/app.py b/flask/app.py @@ -1923,7 +1923,7 @@ class Flask(_PackageBoundObject):\nstatus = headers = None\n# unpack tuple returns\n- if isinstance(rv, (tuple, list)):\n+ if isinstance(rv, tuple):\nlen_rv = len(rv)\n# a 3-tuple is unpacked directly\n",
        "sim_msg_2": "fix - allow lists to be passed through to response_class init",
        "sim_diff_3": "diff --git a/src/flask/cli.py b/src/flask/cli.py @@ -9,6 +9,8 @@ from functools import update_wrapper\nfrom operator import attrgetter\nfrom threading import Lock\nfrom threading import Thread\n+from typing import Any\n+from typing import TYPE_CHECKING\nimport click\nfrom werkzeug.utils import import_string\n@@ -36,7 +38,12 @@ else:\n# We technically have importlib.metadata on 3.8+,\n# but the API changed in 3.10, so use the backport\n# for consistency.\n- import importlib_metadata as metadata # type: ignore\n+ if TYPE_CHECKING:\n+ metadata: Any\n+ else:\n+ # we do this to avoid a version dependent mypy error\n+ # because importlib_metadata is not installed in python3.10+\n+ import importlib_metadata as metadata\nclass NoAppException(click.UsageError):\n",
        "sim_msg_3": "Fix linting error.\nSuppress mypy.\nSuppress mypy error.\nSuppress mypy error."
    },
    {
        "org_diff": "diff --git a/docs/patterns/appdispatch.rst b/a/docs/patterns/appdispatch.rst @@ -146,7 +146,7 @@ the ``Host`` header to figure out the subdomain one simply looks at the\n request path up to the first slash::\n \n     from threading import Lock\n-    from werkzeug.wsgi import pop_path_info, peek_path_info\n+    from wsgiref.util import shift_path_info\n \n     class PathDispatcher:\n \n@@ -166,13 +166,20 @@ request path up to the first slash::\n                 return app\n \n         def __call__(self, environ, start_response):\n-            app = self.get_application(peek_path_info(environ))\n+            app = self.get_application(self._peek_path_info(environ))\n             if app is not None:\n-                pop_path_info(environ)\n+                shift_path_info(environ)\n             else:\n                 app = self.default_app\n             return app(environ, start_response)\n \n+    def _peek_path_info(environ):\n+        segments = environ.get(\"PATH_INFO\", \"\").lstrip(\"/\").split(\"/\", 1)\n+        if segments:\n+            return segments[0]\n+\n+        return None\n+\n The big difference between this and the subdomain one is that this one\n falls back to another application if the creator function returns ``None``::\n ",
        "sim_diff_0": "diff --git a/globus_sdk/base.py b/globus_sdk/base.py @@ -54,7 +54,7 @@ class BaseClient(object):\nBASE_USER_AGENT = 'globus-sdk-py-{0}'.format(__version__)\n- def __init__(self, service, environment=None,\n+ def __init__(self, service, environment=None, base_url=None,\nbase_path=None, authorizer=None, app_name=None):\n# get the fully qualified name of the client class, so that it's a\n# child of globus_sdk\n@@ -85,7 +85,10 @@ class BaseClient(object):\nself.environment = environment\nself.authorizer = authorizer\n+ if base_url is None:\nself.base_url = config.get_service_url(environment, service)\n+ else:\n+ self.base_url = base_url\nif base_path is not None:\nself.base_url = slash_join(self.base_url, base_path)\n",
        "sim_msg_0": "Allow passing a base_url to BaseClient objects",
        "sim_diff_1": "diff --git a/pycket/prims/input_output.py b/pycket/prims/input_output.py @@ -752,6 +752,25 @@ def complete_path(v):\n# FIXME: stub\nreturn values.w_true\n+@expose(\"expand-user-path\", [values.W_Object])\n+def expand_user_path(p):\n+ if isinstance(p, values.W_Path):\n+ path_str = p.path\n+ elif isinstance(p, values_string.W_String):\n+ path_str = p.tostring()\n+ else:\n+ raise SchemeException(\"expand_user_path expects a string or a path\")\n+\n+ if \"~\" in path_str:\n+ if os.environ.get('HOME') is None:\n+ raise Exception(\"HOME is not found among the os environment variables\")\n+\n+ home_dir = os.environ.get('HOME')\n+ # assumes a) there's exactly one ~ and b) nothing is there behind the ~\n+ path_str = home_dir.join(path_str.split(\"~\"))\n+\n+ return values.W_Path(path_str)\n+\n@expose(\"path->string\", [values.W_Path])\ndef path2string(p):\nreturn values_string.W_String.fromstr_utf8(p.path)\n",
        "sim_msg_1": "adding primitive expand-user-path",
        "sim_diff_2": "diff --git a/pipenv/utils.py b/pipenv/utils.py @@ -973,6 +973,7 @@ def resolve_deps(\n\"\"\"Given a list of dependencies, return a resolved list of dependencies,\nusing pip-tools -- and their hashes, using the warehouse API / pip.\n\"\"\"\n+\nindex_lookup = {}\nmarkers_lookup = {}\npython_path = which(\"python\", allow_global=allow_global)\n@@ -982,7 +983,7 @@ def resolve_deps(\nresults = []\nresolver = None\nif not deps:\n- return results, None\n+ return results, resolver\n# First (proper) attempt:\nreq_dir = req_dir if req_dir else os.environ.get(\"req_dir\", None)\nif not req_dir:\n",
        "sim_msg_2": "Update utils to work with patch",
        "sim_diff_3": "diff --git a/home.admin/config.scripts/blitz.subscriptions.letsencrypt.py b/home.admin/config.scripts/blitz.subscriptions.letsencrypt.py @@ -83,8 +83,10 @@ def handleException(e):\ndef get_subdomain(fulldomain_str):\n+ try:\nreturn fulldomain_str.split('.')[0]\n-\n+ except Exception as e:\n+ return fulldomain_str\n############################\n# API Calls to DNS Services\n",
        "sim_msg_3": "try fix slit error"
    },
    {
        "org_diff": "diff --git a/tests/test_basic.py b/a/tests/test_basic.py @@ -431,9 +431,9 @@ def dump_session_contents():\n         client.get(\"/\")\n         s = flask.session\n         assert s[\"t\"] == (1, 2, 3)\n-        assert type(s[\"b\"]) == bytes\n+        assert type(s[\"b\"]) is bytes\n         assert s[\"b\"] == b\"\\xff\"\n-        assert type(s[\"m\"]) == Markup\n+        assert type(s[\"m\"]) is Markup\n         assert s[\"m\"] == Markup(\"<html>\")\n         assert s[\"u\"] == the_uuid\n         assert s[\"d\"] == now\n@@ -760,7 +760,7 @@ def test_teardown_request_handler_error(app, client):\n \n     @app.teardown_request\n     def teardown_request1(exc):\n-        assert type(exc) == ZeroDivisionError\n+        assert type(exc) is ZeroDivisionError\n         called.append(True)\n         # This raises a new error and blows away sys.exc_info(), so we can\n         # test that all teardown_requests get passed the same original\n@@ -772,7 +772,7 @@ def teardown_request1(exc):\n \n     @app.teardown_request\n     def teardown_request2(exc):\n-        assert type(exc) == ZeroDivisionError\n+        assert type(exc) is ZeroDivisionError\n         called.append(True)\n         # This raises a new error and blows away sys.exc_info(), so we can\n         # test that all teardown_requests get passed the same original",
        "sim_diff_0": "diff --git a/tests/test_helpers.py b/tests/test_helpers.py \"\"\"\nimport datetime\n+import io\nimport os\nimport uuid\n@@ -608,6 +609,23 @@ class TestSendfile(object):\nassert rv.status_code == 200\nrv.close()\n+ @pytest.mark.skipif(\n+ not callable(getattr(Range, 'to_content_range_header', None)),\n+ reason=\"not implemented within werkzeug\"\n+ )\n+ def test_send_file_range_request_bytesio(self, app, client):\n+ @app.route('/')\n+ def index():\n+ file = io.BytesIO(b'somethingsomething')\n+ return flask.send_file(\n+ file, attachment_filename='filename', conditional=True\n+ )\n+\n+ rv = client.get('/', headers={'Range': 'bytes=4-15'})\n+ assert rv.status_code == 206\n+ assert rv.data == b'somethingsomething'[4:16]\n+ rv.close()\n+\n@pytest.mark.skipif(\nnot callable(getattr(Range, 'to_content_range_header', None)),\nreason=\"not implemented within werkzeug\"\n",
        "sim_msg_0": "Allow partial content on bytesio",
        "sim_diff_1": "diff --git a/tests/test_blueprints.py b/tests/test_blueprints.py @@ -679,3 +679,65 @@ def test_template_global():\nwith app.app_context():\nrv = flask.render_template_string('{{ get_answer() }}')\nassert rv == '42'\n+\n+def test_request_processing():\n+ app = flask.Flask(__name__)\n+ bp = flask.Blueprint('bp', __name__)\n+ evts = []\n+ @bp.before_request\n+ def before_bp():\n+ evts.append('before')\n+ @bp.after_request\n+ def after_bp(response):\n+ response.data += b'|after'\n+ evts.append('after')\n+ return response\n+\n+ # Setup routes for testing\n+ @bp.route('/bp')\n+ def bp_endpoint():\n+ return 'request'\n+\n+ app.register_blueprint(bp)\n+\n+ assert evts == []\n+ rv = app.test_client().get('/bp')\n+ assert rv.data == b'request|after'\n+ assert evts == ['before', 'after']\n+\n+def test_app_request_processing():\n+ app = flask.Flask(__name__)\n+ bp = flask.Blueprint('bp', __name__)\n+ evts = []\n+\n+ @bp.before_app_first_request\n+ def before_first_request():\n+ evts.append('first')\n+ @bp.before_app_request\n+ def before_app():\n+ evts.append('before')\n+ @bp.after_app_request\n+ def after_app(response):\n+ response.data += b'|after'\n+ evts.append('after')\n+ return response\n+\n+ app.register_blueprint(bp)\n+\n+ # Setup routes for testing\n+ @app.route('/')\n+ def bp_endpoint():\n+ return 'request'\n+\n+ # before first request\n+ assert evts == []\n+\n+ # first request\n+ resp = app.test_client().get('/').data\n+ assert resp == b'request|after'\n+ assert evts == ['first', 'before', 'after']\n+\n+ # second request\n+ resp = app.test_client().get('/').data\n+ assert resp == b'request|after'\n+ assert evts == ['first', 'before', 'after', 'before', 'after']\n",
        "sim_msg_1": "Add coverage for Blueprint request process methods\nAdd test to cover following methodss to the Blueprint object:\nbefore_request, after_request, before_app_request,\nbefore_app_first_request, after_app_request.\nThis PR increases the coverage of flask.blueprints by 6%.",
        "sim_diff_2": "diff --git a/test/test_integration.py b/test/test_integration.py @@ -6,6 +6,8 @@ import os\nimport sys\nimport time\nimport json\n+\n+import flask\nimport pandas as pd\nimport dash\n@@ -1399,3 +1401,47 @@ class Tests(IntegrationTests):\nself.wait_for_element_by_css_selector('.test-input-css')\nself.snapshot('styled input - width: 100%, border-color: hotpink')\n+\n+ def test_logout_btn(self):\n+ app = dash.Dash(__name__)\n+\n+ @app.server.route('/_logout', methods=['POST'])\n+ def on_logout():\n+ rep = flask.redirect('/logged-out')\n+ rep.set_cookie('logout-cookie', '', 0)\n+ return rep\n+\n+ app.layout = html.Div([\n+ html.H2('Logout test'),\n+ dcc.Location(id='location'),\n+ html.Div(id='content'),\n+ ])\n+\n+ @app.callback(Output('content', 'children'),\n+ [Input('location', 'pathname')])\n+ def on_location(location_path):\n+ if location_path is None:\n+ raise PreventUpdate\n+\n+ if 'logged-out' in location_path:\n+ return 'Logged out'\n+ else:\n+\n+ @flask.after_this_request\n+ def _insert_cookie(rep):\n+ rep.set_cookie('logout-cookie', 'logged-in')\n+ return rep\n+\n+ return dcc.LogoutButton(id='logout-btn', logout_url='/_logout')\n+\n+ self.startServer(app)\n+ time.sleep(1)\n+\n+ self.assertEqual(\n+ 'logged-in',\n+ self.driver.get_cookie('logout-cookie')['value'])\n+ logout_button = self.wait_for_element_by_css_selector('#logout-btn')\n+ logout_button.click()\n+ self.wait_for_text_to_equal('#content', 'Logged out')\n+\n+ self.assertFalse(self.driver.get_cookie('logout-cookie'))\n",
        "sim_msg_2": "Add logout button test.",
        "sim_diff_3": "diff --git a/tests/test_misc.py b/tests/test_misc.py @@ -29,6 +29,7 @@ from flask_security.forms import (\nemail_validator,\nvalid_user_email,\n)\n+from flask_security import auth_required\nfrom flask_security.utils import (\ncapture_reset_password_requests,\nencode_string,\n@@ -498,3 +499,29 @@ def test_json_error_response_typeerror():\nerror_msg = (\"tuple\",)\nwith pytest.raises(TypeError):\njson_error_response(errors=error_msg)\n+\n+\n+def test_method_view(app, client):\n+ # auth_required with flask method view\n+ from flask.views import MethodView\n+ from flask import render_template_string\n+\n+ class MyView(MethodView):\n+ decorators = [auth_required(\"token\", \"session\")]\n+\n+ def get(self):\n+ return render_template_string(\"Hi view\")\n+\n+ myview = MyView.as_view(\"myview\")\n+\n+ app.add_url_rule(\"/myview\", view_func=myview, methods=[\"GET\"])\n+\n+ response = client.get(\"/myview\", follow_redirects=False)\n+ # should require login\n+ assert response.status_code == 302\n+ assert \"/login\" in response.location\n+\n+ authenticate(client)\n+ response = client.get(\"/myview\")\n+ assert response.status_code == 200\n+ assert b\"Hi view\" in response.data\n",
        "sim_msg_3": "Quick unit test using flask's method view view creation.\nMake sure easy to use"
    },
    {
        "org_diff": "diff --git a/tests/test_basic.py b/a/tests/test_basic.py @@ -431,9 +431,9 @@ def dump_session_contents():\n         client.get(\"/\")\n         s = flask.session\n         assert s[\"t\"] == (1, 2, 3)\n-        assert type(s[\"b\"]) == bytes\n+        assert type(s[\"b\"]) is bytes\n         assert s[\"b\"] == b\"\\xff\"\n-        assert type(s[\"m\"]) == Markup\n+        assert type(s[\"m\"]) is Markup\n         assert s[\"m\"] == Markup(\"<html>\")\n         assert s[\"u\"] == the_uuid\n         assert s[\"d\"] == now\n@@ -760,7 +760,7 @@ def test_teardown_request_handler_error(app, client):\n \n     @app.teardown_request\n     def teardown_request1(exc):\n-        assert type(exc) == ZeroDivisionError\n+        assert type(exc) is ZeroDivisionError\n         called.append(True)\n         # This raises a new error and blows away sys.exc_info(), so we can\n         # test that all teardown_requests get passed the same original\n@@ -772,7 +772,7 @@ def teardown_request1(exc):\n \n     @app.teardown_request\n     def teardown_request2(exc):\n-        assert type(exc) == ZeroDivisionError\n+        assert type(exc) is ZeroDivisionError\n         called.append(True)\n         # This raises a new error and blows away sys.exc_info(), so we can\n         # test that all teardown_requests get passed the same original",
        "sim_diff_0": "diff --git a/tests/test_helpers.py b/tests/test_helpers.py \"\"\"\nimport datetime\n+import io\nimport os\nimport uuid\n@@ -608,6 +609,23 @@ class TestSendfile(object):\nassert rv.status_code == 200\nrv.close()\n+ @pytest.mark.skipif(\n+ not callable(getattr(Range, 'to_content_range_header', None)),\n+ reason=\"not implemented within werkzeug\"\n+ )\n+ def test_send_file_range_request_bytesio(self, app, client):\n+ @app.route('/')\n+ def index():\n+ file = io.BytesIO(b'somethingsomething')\n+ return flask.send_file(\n+ file, attachment_filename='filename', conditional=True\n+ )\n+\n+ rv = client.get('/', headers={'Range': 'bytes=4-15'})\n+ assert rv.status_code == 206\n+ assert rv.data == b'somethingsomething'[4:16]\n+ rv.close()\n+\n@pytest.mark.skipif(\nnot callable(getattr(Range, 'to_content_range_header', None)),\nreason=\"not implemented within werkzeug\"\n",
        "sim_msg_0": "Allow partial content on bytesio",
        "sim_diff_1": "diff --git a/tests/test_blueprints.py b/tests/test_blueprints.py @@ -679,3 +679,65 @@ def test_template_global():\nwith app.app_context():\nrv = flask.render_template_string('{{ get_answer() }}')\nassert rv == '42'\n+\n+def test_request_processing():\n+ app = flask.Flask(__name__)\n+ bp = flask.Blueprint('bp', __name__)\n+ evts = []\n+ @bp.before_request\n+ def before_bp():\n+ evts.append('before')\n+ @bp.after_request\n+ def after_bp(response):\n+ response.data += b'|after'\n+ evts.append('after')\n+ return response\n+\n+ # Setup routes for testing\n+ @bp.route('/bp')\n+ def bp_endpoint():\n+ return 'request'\n+\n+ app.register_blueprint(bp)\n+\n+ assert evts == []\n+ rv = app.test_client().get('/bp')\n+ assert rv.data == b'request|after'\n+ assert evts == ['before', 'after']\n+\n+def test_app_request_processing():\n+ app = flask.Flask(__name__)\n+ bp = flask.Blueprint('bp', __name__)\n+ evts = []\n+\n+ @bp.before_app_first_request\n+ def before_first_request():\n+ evts.append('first')\n+ @bp.before_app_request\n+ def before_app():\n+ evts.append('before')\n+ @bp.after_app_request\n+ def after_app(response):\n+ response.data += b'|after'\n+ evts.append('after')\n+ return response\n+\n+ app.register_blueprint(bp)\n+\n+ # Setup routes for testing\n+ @app.route('/')\n+ def bp_endpoint():\n+ return 'request'\n+\n+ # before first request\n+ assert evts == []\n+\n+ # first request\n+ resp = app.test_client().get('/').data\n+ assert resp == b'request|after'\n+ assert evts == ['first', 'before', 'after']\n+\n+ # second request\n+ resp = app.test_client().get('/').data\n+ assert resp == b'request|after'\n+ assert evts == ['first', 'before', 'after', 'before', 'after']\n",
        "sim_msg_1": "Add coverage for Blueprint request process methods\nAdd test to cover following methodss to the Blueprint object:\nbefore_request, after_request, before_app_request,\nbefore_app_first_request, after_app_request.\nThis PR increases the coverage of flask.blueprints by 6%.",
        "sim_diff_2": "diff --git a/test/test_integration.py b/test/test_integration.py @@ -6,6 +6,8 @@ import os\nimport sys\nimport time\nimport json\n+\n+import flask\nimport pandas as pd\nimport dash\n@@ -1399,3 +1401,47 @@ class Tests(IntegrationTests):\nself.wait_for_element_by_css_selector('.test-input-css')\nself.snapshot('styled input - width: 100%, border-color: hotpink')\n+\n+ def test_logout_btn(self):\n+ app = dash.Dash(__name__)\n+\n+ @app.server.route('/_logout', methods=['POST'])\n+ def on_logout():\n+ rep = flask.redirect('/logged-out')\n+ rep.set_cookie('logout-cookie', '', 0)\n+ return rep\n+\n+ app.layout = html.Div([\n+ html.H2('Logout test'),\n+ dcc.Location(id='location'),\n+ html.Div(id='content'),\n+ ])\n+\n+ @app.callback(Output('content', 'children'),\n+ [Input('location', 'pathname')])\n+ def on_location(location_path):\n+ if location_path is None:\n+ raise PreventUpdate\n+\n+ if 'logged-out' in location_path:\n+ return 'Logged out'\n+ else:\n+\n+ @flask.after_this_request\n+ def _insert_cookie(rep):\n+ rep.set_cookie('logout-cookie', 'logged-in')\n+ return rep\n+\n+ return dcc.LogoutButton(id='logout-btn', logout_url='/_logout')\n+\n+ self.startServer(app)\n+ time.sleep(1)\n+\n+ self.assertEqual(\n+ 'logged-in',\n+ self.driver.get_cookie('logout-cookie')['value'])\n+ logout_button = self.wait_for_element_by_css_selector('#logout-btn')\n+ logout_button.click()\n+ self.wait_for_text_to_equal('#content', 'Logged out')\n+\n+ self.assertFalse(self.driver.get_cookie('logout-cookie'))\n",
        "sim_msg_2": "Add logout button test.",
        "sim_diff_3": "diff --git a/tests/test_misc.py b/tests/test_misc.py @@ -29,6 +29,7 @@ from flask_security.forms import (\nemail_validator,\nvalid_user_email,\n)\n+from flask_security import auth_required\nfrom flask_security.utils import (\ncapture_reset_password_requests,\nencode_string,\n@@ -498,3 +499,29 @@ def test_json_error_response_typeerror():\nerror_msg = (\"tuple\",)\nwith pytest.raises(TypeError):\njson_error_response(errors=error_msg)\n+\n+\n+def test_method_view(app, client):\n+ # auth_required with flask method view\n+ from flask.views import MethodView\n+ from flask import render_template_string\n+\n+ class MyView(MethodView):\n+ decorators = [auth_required(\"token\", \"session\")]\n+\n+ def get(self):\n+ return render_template_string(\"Hi view\")\n+\n+ myview = MyView.as_view(\"myview\")\n+\n+ app.add_url_rule(\"/myview\", view_func=myview, methods=[\"GET\"])\n+\n+ response = client.get(\"/myview\", follow_redirects=False)\n+ # should require login\n+ assert response.status_code == 302\n+ assert \"/login\" in response.location\n+\n+ authenticate(client)\n+ response = client.get(\"/myview\")\n+ assert response.status_code == 200\n+ assert b\"Hi view\" in response.data\n",
        "sim_msg_3": "Quick unit test using flask's method view view creation.\nMake sure easy to use"
    },
    {
        "org_diff": "diff --git a/src/flask/cli.py b/a/src/flask/cli.py @@ -302,7 +302,7 @@ def load_app(self) -> Flask:\n         else:\n             if self.app_import_path:\n                 path, name = (\n-                    re.split(r\":(?![\\\\/])\", self.app_import_path, 1) + [None]\n+                    re.split(r\":(?![\\\\/])\", self.app_import_path, maxsplit=1) + [None]\n                 )[:2]\n                 import_name = prepare_import(path)\n                 app = locate_app(import_name, name)",
        "sim_diff_0": "diff --git a/flask/cli.py b/flask/cli.py @@ -206,8 +206,9 @@ def prepare_import(path):\n\"\"\"\npath = os.path.realpath(path)\n- if os.path.splitext(path)[1] == '.py':\n- path = os.path.splitext(path)[0]\n+ fname, ext = os.path.splitext(path)\n+ if ext == '.py':\n+ path = fname\nif os.path.basename(path) == '__init__':\npath = os.path.dirname(path)\n",
        "sim_msg_0": "Cache return values to avoid repeated function calls.",
        "sim_diff_1": "diff --git a/flask/cli.py b/flask/cli.py @@ -26,7 +26,7 @@ import click\nfrom werkzeug.utils import import_string\nfrom . import __version__\n-from ._compat import getargspec, iteritems, reraise, text_type\n+from ._compat import getargspec, itervalues, reraise, text_type\nfrom .globals import current_app\nfrom .helpers import get_debug_flag, get_env, get_load_dotenv\n@@ -55,7 +55,7 @@ def find_best_app(script_info, module):\n# Otherwise find the only object that is a Flask instance.\nmatches = [\n- v for k, v in iteritems(module.__dict__) if isinstance(v, Flask)\n+ v for v in itervalues(module.__dict__) if isinstance(v, Flask)\n]\nif len(matches) == 1:\n",
        "sim_msg_1": "art: Use itervalues instead of iteritems",
        "sim_diff_2": "diff --git a/flask/cli.py b/flask/cli.py @@ -21,6 +21,7 @@ import traceback\nfrom functools import update_wrapper\nfrom operator import attrgetter\nfrom threading import Lock, Thread\n+import werkzeug\nimport click\nfrom werkzeug.utils import import_string\n@@ -259,10 +260,11 @@ def locate_app(script_info, module_name, app_name, raise_if_not_found=True):\ndef get_version(ctx, param, value):\nif not value or ctx.resilient_parsing:\nreturn\n- message = 'Flask %(version)s\\nPython %(python_version)s'\n+ message = 'Python %(python_version)s\\nFlask %(version)s\\nWerkzeug %(werkzeug_version)s'\nclick.echo(message % {\n'version': __version__,\n'python_version': sys.version,\n+ 'werkzeug_version': werkzeug.__version__,\n}, color=ctx.color)\nctx.exit()\n",
        "sim_msg_2": "add werkzeug to flask --version",
        "sim_diff_3": "diff --git a/flask_app.py b/flask_app.py @@ -6,6 +6,10 @@ app = Flask(__name__)\nCORS(app)\nimport os\n+\n+THIS_FOLDER = os.path.dirname(os.path.abspath(__file__)) + \"/..\"\n+sys.path.insert(1, THIS_FOLDER)\n+\nos.system(\"rm -rf sessions\")\nos.system(\"md sessions\")\n",
        "sim_msg_3": "I forgot that pythonanywhere gets fussy about file locations"
    },
    {
        "org_diff": "diff --git a/src/flask/cli.py b/a/src/flask/cli.py @@ -302,7 +302,7 @@ def load_app(self) -> Flask:\n         else:\n             if self.app_import_path:\n                 path, name = (\n-                    re.split(r\":(?![\\\\/])\", self.app_import_path, 1) + [None]\n+                    re.split(r\":(?![\\\\/])\", self.app_import_path, maxsplit=1) + [None]\n                 )[:2]\n                 import_name = prepare_import(path)\n                 app = locate_app(import_name, name)",
        "sim_diff_0": "diff --git a/flask/cli.py b/flask/cli.py @@ -206,8 +206,9 @@ def prepare_import(path):\n\"\"\"\npath = os.path.realpath(path)\n- if os.path.splitext(path)[1] == '.py':\n- path = os.path.splitext(path)[0]\n+ fname, ext = os.path.splitext(path)\n+ if ext == '.py':\n+ path = fname\nif os.path.basename(path) == '__init__':\npath = os.path.dirname(path)\n",
        "sim_msg_0": "Cache return values to avoid repeated function calls.",
        "sim_diff_1": "diff --git a/flask/cli.py b/flask/cli.py @@ -26,7 +26,7 @@ import click\nfrom werkzeug.utils import import_string\nfrom . import __version__\n-from ._compat import getargspec, iteritems, reraise, text_type\n+from ._compat import getargspec, itervalues, reraise, text_type\nfrom .globals import current_app\nfrom .helpers import get_debug_flag, get_env, get_load_dotenv\n@@ -55,7 +55,7 @@ def find_best_app(script_info, module):\n# Otherwise find the only object that is a Flask instance.\nmatches = [\n- v for k, v in iteritems(module.__dict__) if isinstance(v, Flask)\n+ v for v in itervalues(module.__dict__) if isinstance(v, Flask)\n]\nif len(matches) == 1:\n",
        "sim_msg_1": "art: Use itervalues instead of iteritems",
        "sim_diff_2": "diff --git a/flask/cli.py b/flask/cli.py @@ -21,6 +21,7 @@ import traceback\nfrom functools import update_wrapper\nfrom operator import attrgetter\nfrom threading import Lock, Thread\n+import werkzeug\nimport click\nfrom werkzeug.utils import import_string\n@@ -259,10 +260,11 @@ def locate_app(script_info, module_name, app_name, raise_if_not_found=True):\ndef get_version(ctx, param, value):\nif not value or ctx.resilient_parsing:\nreturn\n- message = 'Flask %(version)s\\nPython %(python_version)s'\n+ message = 'Python %(python_version)s\\nFlask %(version)s\\nWerkzeug %(werkzeug_version)s'\nclick.echo(message % {\n'version': __version__,\n'python_version': sys.version,\n+ 'werkzeug_version': werkzeug.__version__,\n}, color=ctx.color)\nctx.exit()\n",
        "sim_msg_2": "add werkzeug to flask --version",
        "sim_diff_3": "diff --git a/flask_app.py b/flask_app.py @@ -6,6 +6,10 @@ app = Flask(__name__)\nCORS(app)\nimport os\n+\n+THIS_FOLDER = os.path.dirname(os.path.abspath(__file__)) + \"/..\"\n+sys.path.insert(1, THIS_FOLDER)\n+\nos.system(\"rm -rf sessions\")\nos.system(\"md sessions\")\n",
        "sim_msg_3": "I forgot that pythonanywhere gets fussy about file locations"
    },
    {
        "org_diff": "diff --git a/src/flask/cli.py b/a/src/flask/cli.py @@ -302,7 +302,7 @@ def load_app(self) -> Flask:\n         else:\n             if self.app_import_path:\n                 path, name = (\n-                    re.split(r\":(?![\\\\/])\", self.app_import_path, 1) + [None]\n+                    re.split(r\":(?![\\\\/])\", self.app_import_path, maxsplit=1) + [None]\n                 )[:2]\n                 import_name = prepare_import(path)\n                 app = locate_app(import_name, name)",
        "sim_diff_0": "diff --git a/flask/cli.py b/flask/cli.py @@ -206,8 +206,9 @@ def prepare_import(path):\n\"\"\"\npath = os.path.realpath(path)\n- if os.path.splitext(path)[1] == '.py':\n- path = os.path.splitext(path)[0]\n+ fname, ext = os.path.splitext(path)\n+ if ext == '.py':\n+ path = fname\nif os.path.basename(path) == '__init__':\npath = os.path.dirname(path)\n",
        "sim_msg_0": "Cache return values to avoid repeated function calls.",
        "sim_diff_1": "diff --git a/flask/cli.py b/flask/cli.py @@ -26,7 +26,7 @@ import click\nfrom werkzeug.utils import import_string\nfrom . import __version__\n-from ._compat import getargspec, iteritems, reraise, text_type\n+from ._compat import getargspec, itervalues, reraise, text_type\nfrom .globals import current_app\nfrom .helpers import get_debug_flag, get_env, get_load_dotenv\n@@ -55,7 +55,7 @@ def find_best_app(script_info, module):\n# Otherwise find the only object that is a Flask instance.\nmatches = [\n- v for k, v in iteritems(module.__dict__) if isinstance(v, Flask)\n+ v for v in itervalues(module.__dict__) if isinstance(v, Flask)\n]\nif len(matches) == 1:\n",
        "sim_msg_1": "art: Use itervalues instead of iteritems",
        "sim_diff_2": "diff --git a/flask/cli.py b/flask/cli.py @@ -21,6 +21,7 @@ import traceback\nfrom functools import update_wrapper\nfrom operator import attrgetter\nfrom threading import Lock, Thread\n+import werkzeug\nimport click\nfrom werkzeug.utils import import_string\n@@ -259,10 +260,11 @@ def locate_app(script_info, module_name, app_name, raise_if_not_found=True):\ndef get_version(ctx, param, value):\nif not value or ctx.resilient_parsing:\nreturn\n- message = 'Flask %(version)s\\nPython %(python_version)s'\n+ message = 'Python %(python_version)s\\nFlask %(version)s\\nWerkzeug %(werkzeug_version)s'\nclick.echo(message % {\n'version': __version__,\n'python_version': sys.version,\n+ 'werkzeug_version': werkzeug.__version__,\n}, color=ctx.color)\nctx.exit()\n",
        "sim_msg_2": "add werkzeug to flask --version",
        "sim_diff_3": "diff --git a/flask_app.py b/flask_app.py @@ -6,6 +6,10 @@ app = Flask(__name__)\nCORS(app)\nimport os\n+\n+THIS_FOLDER = os.path.dirname(os.path.abspath(__file__)) + \"/..\"\n+sys.path.insert(1, THIS_FOLDER)\n+\nos.system(\"rm -rf sessions\")\nos.system(\"md sessions\")\n",
        "sim_msg_3": "I forgot that pythonanywhere gets fussy about file locations"
    },
    {
        "org_diff": "diff --git a/.github/workflows/publish.yaml b/a/.github/workflows/publish.yaml @@ -63,10 +63,10 @@ jobs:\n     steps:\n       - uses: actions/download-artifact@9bc31d5ccc31df68ecc42ccf4149144866c47d8a\n       # Try uploading to Test PyPI first, in case something fails.\n-      - uses: pypa/gh-action-pypi-publish@f5622bde02b04381239da3573277701ceca8f6a0\n+      - uses: pypa/gh-action-pypi-publish@f8c70e705ffc13c3b4d1221169b84f12a75d6ca8\n         with:\n           repository-url: https://test.pypi.org/legacy/\n           packages-dir: artifact/\n-      - uses: pypa/gh-action-pypi-publish@f5622bde02b04381239da3573277701ceca8f6a0\n+      - uses: pypa/gh-action-pypi-publish@f8c70e705ffc13c3b4d1221169b84f12a75d6ca8\n         with:\n           packages-dir: artifact/",
        "sim_diff_0": "diff --git a/.github/workflows/full-build.yml b/.github/workflows/full-build.yml @@ -397,7 +397,7 @@ jobs:\nname: Publish to PyPI (release only)\nneeds: [ linux-gtk4, linux-flatpak-devel, macos-gtk4, check-linux-appimage, check-macos-app, check-windows-installer ]\nruns-on: ubuntu-22.04\n- # if: github.event_name == 'release'\n+ if: github.event_name == 'release'\nsteps:\n- uses: actions/download-artifact@v3\nwith:\n@@ -410,4 +410,3 @@ jobs:\n- uses: pypa/gh-action-pypi-publish@release/v1\nwith:\npassword: ${{ secrets.PYPI_TOKEN }}\n- repository_url: https://test.pypi.org/legacy/\n",
        "sim_msg_0": "Change publish target for production",
        "sim_diff_1": "diff --git a/.github/workflows/pypi_upload.yml b/.github/workflows/pypi_upload.yml @@ -47,7 +47,7 @@ jobs:\n# to upload to test pypi, pass repository_url: https://test.pypi.org/legacy/ and use secrets.TEST_PYPI_TOKEN\n- name: Publish a Python distribution to PyPI\n- uses: pypa/gh-action-pypi-publish@master\n+ uses: pypa/gh-action-pypi-publish@release/v1\nwith:\nuser: __token__\npassword: ${{ secrets.PYPI_TOKEN }}\n",
        "sim_msg_1": "Update pypi release action.",
        "sim_diff_2": "diff --git a/.github/workflows/pypi_upload.yml b/.github/workflows/pypi_upload.yml @@ -54,8 +54,8 @@ jobs:\nuses: pypa/gh-action-pypi-publish@master\nwith:\nuser: __token__\n- password: ${{ secrets.TEST_PYPI_TOKEN }}\n- repository_url: https://test.pypi.org/legacy/\n+ password: ${{ secrets.PYPI_TOKEN }}\n+ # repository_url: https://test.pypi.org/legacy/\npackages_dir: dist/\n# git push https://${{ github.actor }}:${{ secrets.GITHUB_TOKEN }}@github.com/${{ github.repository }}.git HEAD:master\n",
        "sim_msg_2": "Switch automated release action to point at production pypi",
        "sim_diff_3": "diff --git a/.github/workflows/pypi_upload.yml b/.github/workflows/pypi_upload.yml -name: Create Release & Upload To PyPI\n+name: Upload Python Package\non:\npush:\n# Sequence of patterns matched against refs/tags\ntags:\n- - v?[0-9]+.[0-9]+.[0-9]+.?(a|b|rc|dev)?[0-9]+ # add .* to allow dev releases\n+ - v[0-9]+.[0-9]+.* # add .* to allow dev releases\njobs:\n- build:\n+ deploy:\nname: pipenv PyPI Upload\nruns-on: ubuntu-latest\nenv:\n@@ -15,7 +15,7 @@ jobs:\nsteps:\n- name: Checkout code\n- uses: actions/checkout@v1\n+ uses: actions/checkout@v2\n- uses: webfactory/ssh-agent@v0.1.1\nwith:\n@@ -37,14 +37,18 @@ jobs:\nwith:\npython-version: 3.7\n- - name: Install latest tools for build\n+ - name: Install dependencies\nrun: |\n- python -m pip install --upgrade --upgrade-strategy=eager pip setuptools wheel invoke\n+ python -m pip install --upgrade --upgrade-strategy=eager pip setuptools wheel twine\npython -m pip install .\npython -m pipenv install --dev\n+ env:\n+ PIPENV_PYTHON: \"3.7\"\n+\n- name: Build wheels\nrun: |\npython -m pipenv run python setup.py sdist bdist_wheel\n+\n# to upload to test pypi, pass repository_url: https://test.pypi.org/legacy/ and use secrets.TEST_PYPI_TOKEN\n- name: Publish a Python distribution to PyPI\nuses: pypa/gh-action-pypi-publish@master\n@@ -53,6 +57,7 @@ jobs:\npassword: ${{ secrets.TEST_PYPI_TOKEN }}\nrepository_url: https://test.pypi.org/legacy/\npackages_dir: dist/\n+\n# git push https://${{ github.actor }}:${{ secrets.GITHUB_TOKEN }}@github.com/${{ github.repository }}.git HEAD:master\n# we need to use a deploy key for this to get around branch protection as the default token fails\n- name: Pre-bump\n@@ -61,3 +66,4 @@ jobs:\ngit config --local user.email action@github.com\npython -m pipenv run inv release.bump-version --dev --commit\ngit push git@github.com:${{ github.repository }}.git HEAD:master\n+\n",
        "sim_msg_3": "Fix tag syntax in workflow yaml"
    },
    {
        "org_diff": "diff --git a/.github/workflows/publish.yaml b/a/.github/workflows/publish.yaml @@ -63,10 +63,10 @@ jobs:\n     steps:\n       - uses: actions/download-artifact@9bc31d5ccc31df68ecc42ccf4149144866c47d8a\n       # Try uploading to Test PyPI first, in case something fails.\n-      - uses: pypa/gh-action-pypi-publish@f5622bde02b04381239da3573277701ceca8f6a0\n+      - uses: pypa/gh-action-pypi-publish@f8c70e705ffc13c3b4d1221169b84f12a75d6ca8\n         with:\n           repository-url: https://test.pypi.org/legacy/\n           packages-dir: artifact/\n-      - uses: pypa/gh-action-pypi-publish@f5622bde02b04381239da3573277701ceca8f6a0\n+      - uses: pypa/gh-action-pypi-publish@f8c70e705ffc13c3b4d1221169b84f12a75d6ca8\n         with:\n           packages-dir: artifact/",
        "sim_diff_0": "diff --git a/.github/workflows/full-build.yml b/.github/workflows/full-build.yml @@ -397,7 +397,7 @@ jobs:\nname: Publish to PyPI (release only)\nneeds: [ linux-gtk4, linux-flatpak-devel, macos-gtk4, check-linux-appimage, check-macos-app, check-windows-installer ]\nruns-on: ubuntu-22.04\n- # if: github.event_name == 'release'\n+ if: github.event_name == 'release'\nsteps:\n- uses: actions/download-artifact@v3\nwith:\n@@ -410,4 +410,3 @@ jobs:\n- uses: pypa/gh-action-pypi-publish@release/v1\nwith:\npassword: ${{ secrets.PYPI_TOKEN }}\n- repository_url: https://test.pypi.org/legacy/\n",
        "sim_msg_0": "Change publish target for production",
        "sim_diff_1": "diff --git a/.github/workflows/pypi_upload.yml b/.github/workflows/pypi_upload.yml @@ -47,7 +47,7 @@ jobs:\n# to upload to test pypi, pass repository_url: https://test.pypi.org/legacy/ and use secrets.TEST_PYPI_TOKEN\n- name: Publish a Python distribution to PyPI\n- uses: pypa/gh-action-pypi-publish@master\n+ uses: pypa/gh-action-pypi-publish@release/v1\nwith:\nuser: __token__\npassword: ${{ secrets.PYPI_TOKEN }}\n",
        "sim_msg_1": "Update pypi release action.",
        "sim_diff_2": "diff --git a/.github/workflows/pypi_upload.yml b/.github/workflows/pypi_upload.yml @@ -54,8 +54,8 @@ jobs:\nuses: pypa/gh-action-pypi-publish@master\nwith:\nuser: __token__\n- password: ${{ secrets.TEST_PYPI_TOKEN }}\n- repository_url: https://test.pypi.org/legacy/\n+ password: ${{ secrets.PYPI_TOKEN }}\n+ # repository_url: https://test.pypi.org/legacy/\npackages_dir: dist/\n# git push https://${{ github.actor }}:${{ secrets.GITHUB_TOKEN }}@github.com/${{ github.repository }}.git HEAD:master\n",
        "sim_msg_2": "Switch automated release action to point at production pypi",
        "sim_diff_3": "diff --git a/.github/workflows/pypi_upload.yml b/.github/workflows/pypi_upload.yml -name: Create Release & Upload To PyPI\n+name: Upload Python Package\non:\npush:\n# Sequence of patterns matched against refs/tags\ntags:\n- - v?[0-9]+.[0-9]+.[0-9]+.?(a|b|rc|dev)?[0-9]+ # add .* to allow dev releases\n+ - v[0-9]+.[0-9]+.* # add .* to allow dev releases\njobs:\n- build:\n+ deploy:\nname: pipenv PyPI Upload\nruns-on: ubuntu-latest\nenv:\n@@ -15,7 +15,7 @@ jobs:\nsteps:\n- name: Checkout code\n- uses: actions/checkout@v1\n+ uses: actions/checkout@v2\n- uses: webfactory/ssh-agent@v0.1.1\nwith:\n@@ -37,14 +37,18 @@ jobs:\nwith:\npython-version: 3.7\n- - name: Install latest tools for build\n+ - name: Install dependencies\nrun: |\n- python -m pip install --upgrade --upgrade-strategy=eager pip setuptools wheel invoke\n+ python -m pip install --upgrade --upgrade-strategy=eager pip setuptools wheel twine\npython -m pip install .\npython -m pipenv install --dev\n+ env:\n+ PIPENV_PYTHON: \"3.7\"\n+\n- name: Build wheels\nrun: |\npython -m pipenv run python setup.py sdist bdist_wheel\n+\n# to upload to test pypi, pass repository_url: https://test.pypi.org/legacy/ and use secrets.TEST_PYPI_TOKEN\n- name: Publish a Python distribution to PyPI\nuses: pypa/gh-action-pypi-publish@master\n@@ -53,6 +57,7 @@ jobs:\npassword: ${{ secrets.TEST_PYPI_TOKEN }}\nrepository_url: https://test.pypi.org/legacy/\npackages_dir: dist/\n+\n# git push https://${{ github.actor }}:${{ secrets.GITHUB_TOKEN }}@github.com/${{ github.repository }}.git HEAD:master\n# we need to use a deploy key for this to get around branch protection as the default token fails\n- name: Pre-bump\n@@ -61,3 +66,4 @@ jobs:\ngit config --local user.email action@github.com\npython -m pipenv run inv release.bump-version --dev --commit\ngit push git@github.com:${{ github.repository }}.git HEAD:master\n+\n",
        "sim_msg_3": "Fix tag syntax in workflow yaml"
    },
    {
        "org_diff": "diff --git a/.pre-commit-config.yaml b/a/.pre-commit-config.yaml @@ -3,7 +3,7 @@ ci:\n   autoupdate_schedule: monthly\n repos:\n   - repo: https://github.com/asottile/pyupgrade\n-    rev: v3.8.0\n+    rev: v3.10.1\n     hooks:\n       - id: pyupgrade\n         args: [\"--py38-plus\"]\n@@ -15,11 +15,11 @@ repos:\n         files: \"^(?!examples/)\"\n         args: [\"--application-directories\", \"src\"]\n   - repo: https://github.com/psf/black\n-    rev: 23.3.0\n+    rev: 23.7.0\n     hooks:\n       - id: black\n   - repo: https://github.com/PyCQA/flake8\n-    rev: 6.0.0\n+    rev: 6.1.0\n     hooks:\n       - id: flake8\n         additional_dependencies:",
        "sim_diff_0": "diff --git a/.pre-commit-config.yaml b/.pre-commit-config.yaml @@ -22,7 +22,7 @@ repos:\nhooks:\n- id: isort\n- repo: https://github.com/asottile/pyupgrade\n- rev: v3.0.0\n+ rev: v3.2.0\nhooks:\n- id: pyupgrade\nargs: [--py36-plus]\n@@ -38,7 +38,7 @@ repos:\n- id: rst-inline-touching-normal\n- id: text-unicode-replacement-char\n- repo: https://github.com/psf/black\n- rev: 22.8.0\n+ rev: 22.10.0\nhooks:\n- id: black\nargs: [--safe, --quiet, --target-version=py36]\n",
        "sim_msg_0": "Upgrade pre-commit hook versions",
        "sim_diff_1": "diff --git a/.pre-commit-config.yaml b/.pre-commit-config.yaml @@ -5,7 +5,7 @@ repos:\n- id: black\nlanguage_version: python3\n- repo: https://github.com/pre-commit/mirrors-mypy\n- rev: v0.931\n+ rev: v0.941\nhooks:\n- id: mypy\nadditional_dependencies:\n@@ -36,6 +36,6 @@ repos:\n- id: shellcheck\nargs: [--exclude, SC1017]\n- repo: https://github.com/asottile/pyupgrade\n- rev: v2.31.0\n+ rev: v2.31.1\nhooks:\n- id: pyupgrade\n",
        "sim_msg_1": "Update pre-commit config: mypy, pyupgrade",
        "sim_diff_2": "diff --git a/.pre-commit-config.yaml b/.pre-commit-config.yaml @@ -24,7 +24,7 @@ repos:\nhooks:\n- id: isort\n- repo: https://github.com/asottile/pyupgrade\n- rev: v1.22.1\n+ rev: v1.23.0\nhooks:\n- id: pyupgrade\n- repo: https://github.com/pre-commit/pygrep-hooks\n@@ -33,7 +33,7 @@ repos:\n- id: python-no-eval\n- id: python-check-blanket-noqa\n- id: rst-backticks\n- - repo: https://github.com/python/black\n+ - repo: https://github.com/psf/black\nrev: 19.3b0\nhooks:\n- id: black\n",
        "sim_msg_2": "Upgraded pre-commit packages",
        "sim_diff_3": "diff --git a/.pre-commit-config.yaml b/.pre-commit-config.yaml @@ -7,7 +7,7 @@ repos:\n- id: end-of-file-fixer\n- id: requirements-txt-fixer\n- repo: https://github.com/asottile/pyupgrade\n- rev: v2.23.3\n+ rev: v3.1.0\nhooks:\n- id: pyupgrade\nargs: [\"--py37-plus\"]\n",
        "sim_msg_3": "Update pyupgrade version to avoid ImportError for Python 3.10.8"
    },
    {
        "org_diff": "diff --git a/.pre-commit-config.yaml b/a/.pre-commit-config.yaml @@ -3,7 +3,7 @@ ci:\n   autoupdate_schedule: monthly\n repos:\n   - repo: https://github.com/asottile/pyupgrade\n-    rev: v3.8.0\n+    rev: v3.10.1\n     hooks:\n       - id: pyupgrade\n         args: [\"--py38-plus\"]\n@@ -15,11 +15,11 @@ repos:\n         files: \"^(?!examples/)\"\n         args: [\"--application-directories\", \"src\"]\n   - repo: https://github.com/psf/black\n-    rev: 23.3.0\n+    rev: 23.7.0\n     hooks:\n       - id: black\n   - repo: https://github.com/PyCQA/flake8\n-    rev: 6.0.0\n+    rev: 6.1.0\n     hooks:\n       - id: flake8\n         additional_dependencies:",
        "sim_diff_0": "diff --git a/.pre-commit-config.yaml b/.pre-commit-config.yaml @@ -22,7 +22,7 @@ repos:\nhooks:\n- id: isort\n- repo: https://github.com/asottile/pyupgrade\n- rev: v3.0.0\n+ rev: v3.2.0\nhooks:\n- id: pyupgrade\nargs: [--py36-plus]\n@@ -38,7 +38,7 @@ repos:\n- id: rst-inline-touching-normal\n- id: text-unicode-replacement-char\n- repo: https://github.com/psf/black\n- rev: 22.8.0\n+ rev: 22.10.0\nhooks:\n- id: black\nargs: [--safe, --quiet, --target-version=py36]\n",
        "sim_msg_0": "Upgrade pre-commit hook versions",
        "sim_diff_1": "diff --git a/.pre-commit-config.yaml b/.pre-commit-config.yaml @@ -5,7 +5,7 @@ repos:\n- id: black\nlanguage_version: python3\n- repo: https://github.com/pre-commit/mirrors-mypy\n- rev: v0.931\n+ rev: v0.941\nhooks:\n- id: mypy\nadditional_dependencies:\n@@ -36,6 +36,6 @@ repos:\n- id: shellcheck\nargs: [--exclude, SC1017]\n- repo: https://github.com/asottile/pyupgrade\n- rev: v2.31.0\n+ rev: v2.31.1\nhooks:\n- id: pyupgrade\n",
        "sim_msg_1": "Update pre-commit config: mypy, pyupgrade",
        "sim_diff_2": "diff --git a/.pre-commit-config.yaml b/.pre-commit-config.yaml @@ -24,7 +24,7 @@ repos:\nhooks:\n- id: isort\n- repo: https://github.com/asottile/pyupgrade\n- rev: v1.22.1\n+ rev: v1.23.0\nhooks:\n- id: pyupgrade\n- repo: https://github.com/pre-commit/pygrep-hooks\n@@ -33,7 +33,7 @@ repos:\n- id: python-no-eval\n- id: python-check-blanket-noqa\n- id: rst-backticks\n- - repo: https://github.com/python/black\n+ - repo: https://github.com/psf/black\nrev: 19.3b0\nhooks:\n- id: black\n",
        "sim_msg_2": "Upgraded pre-commit packages",
        "sim_diff_3": "diff --git a/.pre-commit-config.yaml b/.pre-commit-config.yaml @@ -7,7 +7,7 @@ repos:\n- id: end-of-file-fixer\n- id: requirements-txt-fixer\n- repo: https://github.com/asottile/pyupgrade\n- rev: v2.23.3\n+ rev: v3.1.0\nhooks:\n- id: pyupgrade\nargs: [\"--py37-plus\"]\n",
        "sim_msg_3": "Update pyupgrade version to avoid ImportError for Python 3.10.8"
    },
    {
        "org_diff": "diff --git a/.pre-commit-config.yaml b/a/.pre-commit-config.yaml @@ -3,7 +3,7 @@ ci:\n   autoupdate_schedule: monthly\n repos:\n   - repo: https://github.com/asottile/pyupgrade\n-    rev: v3.7.0\n+    rev: v3.8.0\n     hooks:\n       - id: pyupgrade\n         args: [\"--py38-plus\"]",
        "sim_diff_0": "diff --git a/.pre-commit-config.yaml b/.pre-commit-config.yaml @@ -5,7 +5,7 @@ repos:\n- id: black\nlanguage_version: python3\n- repo: https://github.com/pre-commit/mirrors-mypy\n- rev: v0.931\n+ rev: v0.941\nhooks:\n- id: mypy\nadditional_dependencies:\n@@ -36,6 +36,6 @@ repos:\n- id: shellcheck\nargs: [--exclude, SC1017]\n- repo: https://github.com/asottile/pyupgrade\n- rev: v2.31.0\n+ rev: v2.31.1\nhooks:\n- id: pyupgrade\n",
        "sim_msg_0": "Update pre-commit config: mypy, pyupgrade",
        "sim_diff_1": "diff --git a/.pre-commit-config.yaml b/.pre-commit-config.yaml @@ -7,7 +7,7 @@ repos:\n- id: end-of-file-fixer\n- id: requirements-txt-fixer\n- repo: https://github.com/asottile/pyupgrade\n- rev: v2.23.3\n+ rev: v3.1.0\nhooks:\n- id: pyupgrade\nargs: [\"--py37-plus\"]\n",
        "sim_msg_1": "Update pyupgrade version to avoid ImportError for Python 3.10.8",
        "sim_diff_2": "diff --git a/.pre-commit-config.yaml b/.pre-commit-config.yaml @@ -22,7 +22,7 @@ repos:\nhooks:\n- id: isort\n- repo: https://github.com/asottile/pyupgrade\n- rev: v3.0.0\n+ rev: v3.2.0\nhooks:\n- id: pyupgrade\nargs: [--py36-plus]\n@@ -38,7 +38,7 @@ repos:\n- id: rst-inline-touching-normal\n- id: text-unicode-replacement-char\n- repo: https://github.com/psf/black\n- rev: 22.8.0\n+ rev: 22.10.0\nhooks:\n- id: black\nargs: [--safe, --quiet, --target-version=py36]\n",
        "sim_msg_2": "Upgrade pre-commit hook versions",
        "sim_diff_3": "diff --git a/.pre-commit-config.yaml b/.pre-commit-config.yaml @@ -24,7 +24,7 @@ repos:\nhooks:\n- id: isort\n- repo: https://github.com/asottile/pyupgrade\n- rev: v1.22.1\n+ rev: v1.23.0\nhooks:\n- id: pyupgrade\n- repo: https://github.com/pre-commit/pygrep-hooks\n@@ -33,7 +33,7 @@ repos:\n- id: python-no-eval\n- id: python-check-blanket-noqa\n- id: rst-backticks\n- - repo: https://github.com/python/black\n+ - repo: https://github.com/psf/black\nrev: 19.3b0\nhooks:\n- id: black\n",
        "sim_msg_3": "Upgraded pre-commit packages"
    },
    {
        "org_diff": "diff --git a/.pre-commit-config.yaml b/a/.pre-commit-config.yaml @@ -3,7 +3,7 @@ ci:\n   autoupdate_schedule: monthly\n repos:\n   - repo: https://github.com/asottile/pyupgrade\n-    rev: v3.7.0\n+    rev: v3.8.0\n     hooks:\n       - id: pyupgrade\n         args: [\"--py38-plus\"]",
        "sim_diff_0": "diff --git a/.pre-commit-config.yaml b/.pre-commit-config.yaml @@ -5,7 +5,7 @@ repos:\n- id: black\nlanguage_version: python3\n- repo: https://github.com/pre-commit/mirrors-mypy\n- rev: v0.931\n+ rev: v0.941\nhooks:\n- id: mypy\nadditional_dependencies:\n@@ -36,6 +36,6 @@ repos:\n- id: shellcheck\nargs: [--exclude, SC1017]\n- repo: https://github.com/asottile/pyupgrade\n- rev: v2.31.0\n+ rev: v2.31.1\nhooks:\n- id: pyupgrade\n",
        "sim_msg_0": "Update pre-commit config: mypy, pyupgrade",
        "sim_diff_1": "diff --git a/.pre-commit-config.yaml b/.pre-commit-config.yaml @@ -7,7 +7,7 @@ repos:\n- id: end-of-file-fixer\n- id: requirements-txt-fixer\n- repo: https://github.com/asottile/pyupgrade\n- rev: v2.23.3\n+ rev: v3.1.0\nhooks:\n- id: pyupgrade\nargs: [\"--py37-plus\"]\n",
        "sim_msg_1": "Update pyupgrade version to avoid ImportError for Python 3.10.8",
        "sim_diff_2": "diff --git a/.pre-commit-config.yaml b/.pre-commit-config.yaml @@ -22,7 +22,7 @@ repos:\nhooks:\n- id: isort\n- repo: https://github.com/asottile/pyupgrade\n- rev: v3.0.0\n+ rev: v3.2.0\nhooks:\n- id: pyupgrade\nargs: [--py36-plus]\n@@ -38,7 +38,7 @@ repos:\n- id: rst-inline-touching-normal\n- id: text-unicode-replacement-char\n- repo: https://github.com/psf/black\n- rev: 22.8.0\n+ rev: 22.10.0\nhooks:\n- id: black\nargs: [--safe, --quiet, --target-version=py36]\n",
        "sim_msg_2": "Upgrade pre-commit hook versions",
        "sim_diff_3": "diff --git a/.pre-commit-config.yaml b/.pre-commit-config.yaml @@ -24,7 +24,7 @@ repos:\nhooks:\n- id: isort\n- repo: https://github.com/asottile/pyupgrade\n- rev: v1.22.1\n+ rev: v1.23.0\nhooks:\n- id: pyupgrade\n- repo: https://github.com/pre-commit/pygrep-hooks\n@@ -33,7 +33,7 @@ repos:\n- id: python-no-eval\n- id: python-check-blanket-noqa\n- id: rst-backticks\n- - repo: https://github.com/python/black\n+ - repo: https://github.com/psf/black\nrev: 19.3b0\nhooks:\n- id: black\n",
        "sim_msg_3": "Upgraded pre-commit packages"
    },
    {
        "org_diff": "diff --git a/docs/tutorial/install.rst b/a/docs/tutorial/install.rst @@ -35,6 +35,7 @@ The ``pyproject.toml`` file describes your project and how to build it.\n     [project]\n     name = \"flaskr\"\n     version = \"1.0.0\"\n+    description = \"The basic blog app built in the Flask tutorial.\"\n     dependencies = [\n         \"flask\",\n     ]",
        "sim_diff_0": "diff --git a/pyproject.toml b/pyproject.toml [build-system]\nrequires = [\n- \"setuptools\",\n+ \"setuptools==59.5.0\",\n\"wheel\",\n]\n[tool.black]\n# https://github.com/psf/black\nline-length = 120\n-target-version = [\"py36\"]\n+target-version = [\"py37\"]\n[tool.isort]\nknown_first_party = [\n@@ -19,7 +19,7 @@ known_first_party = [\nknown_third_party = [\n\"matplotlib\",\n\"numpy\",\n- \"setuptools\",\n+ \"setuptools==59.5.0\",\n\"sphinx_rtd_theme\",\n\"torch\",\n]\n",
        "sim_msg_0": "setuptools version",
        "sim_diff_1": "diff --git a/pyproject.toml b/pyproject.toml requires = [\n\"setuptools\",\n+ \"setuptools_scm\",\n\"wheel\",\n- \"extension-helpers\"\n+ \"extension-helpers\",\n+ \"oldest-supported-numpy\",\n+ \"cython==0.29.14\"\n]\nbuild-backend = 'setuptools.build_meta'\n",
        "sim_msg_1": "flesh out pyproject.toml",
        "sim_diff_2": "diff --git a/docs/requirements.txt b/docs/requirements.txt # Keep until RTD fully support pyproject.toml\n-docutils==0.17.1\n-Pygments==2.10.0\nmyst-parser==0.15.2\nSphinx==4.3.0\nsphinx-rtd-theme==1.0.0\n-sphinxcontrib-websupport==1.2.4\nsphinxcontrib-images==0.9.4\ntomli==1.2.2\ngeneric==1.0.1\n",
        "sim_msg_2": "Remove unneeded dependencies from docs requirements",
        "sim_diff_3": "diff --git a/pyproject.toml b/pyproject.toml @@ -14,7 +14,9 @@ classifiers = [\n\"Programming Language :: Python :: 3.7\",\n]\npackages = [\n- { include = \"astral\", from = \"src\"}\n+ { include = \"astral\", from = \"src\"},\n+ { include = \"doc\", from = \"src\", format = \"sdist\"},\n+ { include = \"test\", from = \"src\", format = \"sdist\"},\n]\n[tool.poetry.dependencies]\n",
        "sim_msg_3": "Added doc and test source to sdist"
    },
    {
        "org_diff": "diff --git a/docs/tutorial/install.rst b/a/docs/tutorial/install.rst @@ -35,6 +35,7 @@ The ``pyproject.toml`` file describes your project and how to build it.\n     [project]\n     name = \"flaskr\"\n     version = \"1.0.0\"\n+    description = \"The basic blog app built in the Flask tutorial.\"\n     dependencies = [\n         \"flask\",\n     ]",
        "sim_diff_0": "diff --git a/pyproject.toml b/pyproject.toml [build-system]\nrequires = [\n- \"setuptools\",\n+ \"setuptools==59.5.0\",\n\"wheel\",\n]\n[tool.black]\n# https://github.com/psf/black\nline-length = 120\n-target-version = [\"py36\"]\n+target-version = [\"py37\"]\n[tool.isort]\nknown_first_party = [\n@@ -19,7 +19,7 @@ known_first_party = [\nknown_third_party = [\n\"matplotlib\",\n\"numpy\",\n- \"setuptools\",\n+ \"setuptools==59.5.0\",\n\"sphinx_rtd_theme\",\n\"torch\",\n]\n",
        "sim_msg_0": "setuptools version",
        "sim_diff_1": "diff --git a/pyproject.toml b/pyproject.toml requires = [\n\"setuptools\",\n+ \"setuptools_scm\",\n\"wheel\",\n- \"extension-helpers\"\n+ \"extension-helpers\",\n+ \"oldest-supported-numpy\",\n+ \"cython==0.29.14\"\n]\nbuild-backend = 'setuptools.build_meta'\n",
        "sim_msg_1": "flesh out pyproject.toml",
        "sim_diff_2": "diff --git a/docs/requirements.txt b/docs/requirements.txt # Keep until RTD fully support pyproject.toml\n-docutils==0.17.1\n-Pygments==2.10.0\nmyst-parser==0.15.2\nSphinx==4.3.0\nsphinx-rtd-theme==1.0.0\n-sphinxcontrib-websupport==1.2.4\nsphinxcontrib-images==0.9.4\ntomli==1.2.2\ngeneric==1.0.1\n",
        "sim_msg_2": "Remove unneeded dependencies from docs requirements",
        "sim_diff_3": "diff --git a/pyproject.toml b/pyproject.toml @@ -14,7 +14,9 @@ classifiers = [\n\"Programming Language :: Python :: 3.7\",\n]\npackages = [\n- { include = \"astral\", from = \"src\"}\n+ { include = \"astral\", from = \"src\"},\n+ { include = \"doc\", from = \"src\", format = \"sdist\"},\n+ { include = \"test\", from = \"src\", format = \"sdist\"},\n]\n[tool.poetry.dependencies]\n",
        "sim_msg_3": "Added doc and test source to sdist"
    },
    {
        "org_diff": "diff --git a/.github/workflows/publish.yaml b/a/.github/workflows/publish.yaml @@ -33,7 +33,7 @@ jobs:\n       id-token: write\n       contents: write\n     # Can't pin with hash due to how this workflow works.\n-    uses: slsa-framework/slsa-github-generator/.github/workflows/generator_generic_slsa3.yml@v1.6.0\n+    uses: slsa-framework/slsa-github-generator/.github/workflows/generator_generic_slsa3.yml@v1.7.0\n     with:\n       base64-subjects: ${{ needs.build.outputs.hash }}\n   create-release:",
        "sim_diff_0": "diff --git a/.github/workflows/tag-actions.yml b/.github/workflows/tag-actions.yml @@ -10,6 +10,9 @@ jobs:\nname: Github Release\nruns-on: ubuntu-latest\n+ outputs:\n+ upload_url: ${{ steps.create_release.outputs.upload_url }}\n+\nsteps:\n- name: Create Release\nid: create_release\n@@ -125,7 +128,7 @@ jobs:\nenv:\nGITHUB_TOKEN: ${{ secrets.RELEASE_TOKEN }}\nwith:\n- upload_url: ${{ steps.create_release.outputs.upload_url }}\n+ upload_url: ${{ needs.github-release.outputs.upload_url }}\nasset_path: ./rpm/dist/beer-garden-${GITHUB_REF#refs/tags/}-1.el7.x86_64.rpm\nasset_name: beer-garden-${GITHUB_REF#refs/tags/}-1.el7.x86_64.rpm\nasset_content_type: application/octet-stream\n",
        "sim_msg_0": "Need to mark job output",
        "sim_diff_1": "diff --git a/.github/workflows/publish.yml b/.github/workflows/publish.yml @@ -2,7 +2,7 @@ name: publish\non:\npush:\n- branch:\n+ branches:\n- master\njobs:\n@@ -34,4 +34,4 @@ jobs:\nenv:\nPUBLISH_TARGET: ${{ secrets.PUBLISH_TARGET }}\nrun: |\n- rsync -azve \"ssh -o StrictHostKeyChecking=accept-new\" --delete build/anthology/ $PUBLISH_TARGET\n+ rsync -aze \"ssh -o StrictHostKeyChecking=accept-new\" --delete build/anthology/ $PUBLISH_TARGET\n",
        "sim_msg_1": "GH publish action: no verbose logging, only run on master\nSee PR",
        "sim_diff_2": "diff --git a/.github/workflows/release-drafter.yml b/.github/workflows/release-drafter.yml @@ -16,7 +16,7 @@ jobs:\nruns-on: ubuntu-latest\nsteps:\n- uses: release-drafter/release-drafter@v5\n- # with:\n- # disable-autolabeler: true\n+ with:\n+ disable-autolabeler: true\nenv:\nGITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n",
        "sim_msg_2": "explictly disable autolabeler for good measure",
        "sim_diff_3": "diff --git a/.github/workflows/publish.yaml b/.github/workflows/publish.yaml @@ -4,6 +4,7 @@ on:\npush:\nbranches:\n- develop\n+ - main\njobs:\npublish:\n@@ -21,6 +22,13 @@ jobs:\nproject_id: ${{ secrets.GCLOUD_FETCH_AI_SANDBOX_PROJECT }}\nservice_account_key: ${{ secrets.GCLOUD_FETCH_AI_SANDBOX_KEY }}\n+ - name: Setup GCloud - production\n+ uses: GoogleCloudPlatform/github-actions/setup-gcloud@master\n+ if: github.ref == 'refs/heads/main'\n+ with:\n+ project_id: ${{ secrets.GCLOUD_FETCH_AI_PROD_PROJECT }}\n+ service_account_key: ${{ secrets.GCLOUD_FETCH_AI_PROD_KEY }}\n+\n- name: Configure Docker\nrun: |\ngcloud auth configure-docker\n@@ -39,6 +47,11 @@ jobs:\n./scripts/acn/build_upload_img.sh\nfi\n+ if [ ${{ github.ref }} == 'refs/heads/main' ]\n+ then\n+ ./scripts/acn/build_upload_img.sh prod\n+ fi\n+\n- name: Repository Dispatch\nenv:\nIMAGE_TAG: ${{ steps.vars.outputs.sha_short }}\n@@ -51,3 +64,12 @@ jobs:\n--data '{\"event_type\": \"agents-dht-testnet\", \"client_payload\": {\"image\": \"gcr.io/fetch-ai-sandbox/acn_node\", \"tag\": \"'\"$IMAGE_TAG\"'\"}}' \\\nhttps://api.github.com/repos/fetchai/infra-sandbox-london-b-deployment/dispatches\nfi\n+\n+ if [ ${{ github.ref }} == 'refs/heads/main' ]\n+ then\n+ curl -H \"Accept: application/vnd.github.everest-preview+json\" \\\n+ -H \"Authorization: token ${{ secrets.GH_PAT }}\" \\\n+ --request POST \\\n+ --data '{\"event_type\": \"agents-dht\", \"client_payload\": {\"image\": \"gcr.io/fetch-ai-images/acn_node\", \"tag\": \"'\"$IMAGE_TAG\"'\"}}' \\\n+ https://api.github.com/repos/fetchai/infra-mainnet-v2-deployment/dispatches\n+ fi\n",
        "sim_msg_3": "Added steps for prod deployment"
    },
    {
        "org_diff": "diff --git a/.github/workflows/lock.yaml b/a/.github/workflows/lock.yaml @@ -19,7 +19,7 @@ jobs:\n   lock:\n     runs-on: ubuntu-latest\n     steps:\n-      - uses: dessant/lock-threads@c1b35aecc5cdb1a34539d14196df55838bb2f836\n+      - uses: dessant/lock-threads@be8aa5be94131386884a6da4189effda9b14aa21\n         with:\n           issue-inactive-days: 14\n           pr-inactive-days: 14",
        "sim_diff_0": "diff --git a/.github/workflows/stale.yml b/.github/workflows/stale.yml @@ -12,7 +12,7 @@ jobs:\nstale:\nruns-on: ubuntu-latest\nsteps:\n- uses: actions/stale@v4\n+ - uses: actions/stale@v4\nwith:\nexempt-all-milestones: true\nany-of-labels: 'need info'\n",
        "sim_msg_0": ".github/workflows/stale.yml: Missing dash",
        "sim_diff_1": "diff --git a/.github/workflows/stale.yml b/.github/workflows/stale.yml @@ -12,7 +12,7 @@ jobs:\nstale:\nruns-on: ubuntu-latest\nsteps:\n- uses: actions@stale@v4\n+ uses: actions/stale@v4\nwith:\nexempt-all-milestones: true\nany-of-labels: 'need info'\n",
        "sim_msg_1": ".github/workflows/stale.yml: Fix typo",
        "sim_diff_2": "diff --git a/.github/workflows/workflow.yml b/.github/workflows/workflow.yml @@ -53,7 +53,6 @@ jobs:\nrun: |\ntox -e black-check\ntox -e flake8\n- tox -e pylint\n- name: Static type check\nrun: tox -e mypy\n- name: Golang code style check\n@@ -63,6 +62,25 @@ jobs:\nworking-directory: packages/fetchai/connections/p2p_libp2p/\ncommon_checks_3:\n+ continue-on-error: False\n+ runs-on: ubuntu-latest\n+ timeout-minutes: 10\n+ steps:\n+ - uses: actions/checkout@master\n+ - uses: actions/setup-python@master\n+ with:\n+ python-version: 3.6\n+ - name: Install dependencies (ubuntu-latest)\n+ run: |\n+ sudo apt-get update --fix-missing\n+ sudo apt-get autoremove\n+ sudo apt-get autoclean\n+ pip install tox\n+ - name: Pylint check\n+ run: |\n+ tox -e pylint\n+\n+ common_checks_4:\ncontinue-on-error: False\nruns-on: ubuntu-latest\ntimeout-minutes: 10\n@@ -102,6 +120,7 @@ jobs:\n- common_checks_1\n- common_checks_2\n- common_checks_3\n+ - common_checks_4\nruns-on: ubuntu-latest\ntimeout-minutes: 50\nsteps:\n@@ -131,6 +150,7 @@ jobs:\n- common_checks_1\n- common_checks_2\n- common_checks_3\n+ - common_checks_4\nruns-on: ubuntu-latest\ntimeout-minutes: 30\nsteps:\n@@ -156,6 +176,7 @@ jobs:\n- common_checks_1\n- common_checks_2\n- common_checks_3\n+ - common_checks_4\nruns-on: ${{ matrix.os }}\nstrategy:\nmatrix:\n@@ -202,6 +223,7 @@ jobs:\n- common_checks_1\n- common_checks_2\n- common_checks_3\n+ - common_checks_4\nruns-on: ubuntu-latest\ntimeout-minutes: 30\nsteps:\n@@ -229,6 +251,7 @@ jobs:\n- common_checks_1\n- common_checks_2\n- common_checks_3\n+ - common_checks_4\nruns-on: ${{ matrix.os }}\nstrategy:\nmatrix:\n",
        "sim_msg_2": "split pylint out in separate common check",
        "sim_diff_3": "diff --git a/.github/workflows/workflow.yml b/.github/workflows/workflow.yml @@ -8,7 +8,44 @@ on:\npull_request:\njobs:\n- run:\n+ common_checks:\n+ runs-on: ubuntu-latest\n+\n+ timeout-minutes: 30\n+\n+ steps:\n+ - uses: actions/checkout@master\n+ - uses: actions/setup-python@master\n+ with:\n+ python-version: 3.6\n+ - name: Install dependencies (ubuntu-latest)\n+ run: |\n+ sudo apt-get update --fix-missing\n+ sudo apt-get autoremove\n+ sudo apt-get autoclean\n+ pip install pipenv\n+ pip install tox\n+ sudo apt-get install -y protobuf-compiler\n+ - name: Security Check - Main\n+ run: tox -e bandit-main\n+ - name: Security Check - Tests\n+ run: tox -e bandit-tests\n+ - name: Safety Check\n+ run: tox -e safety\n+ - name: License Check\n+ run: tox -e liccheck\n+ - name: Copyright Check\n+ run: tox -e copyright_check\n+ - name: Code style check\n+ run: |\n+ tox -e black-check\n+ tox -e flake8\n+ - name: Static type check\n+ run: tox -e mypy\n+ - name: Generate Documentation\n+ run: tox -e docs\n+\n+ platform_checks:\nruns-on: ${{ matrix.os }}\nstrategy:\n@@ -40,22 +77,6 @@ jobs:\npip install pipenv\npip install tox\nbrew install protobuf\n- - name: Security Check - Main\n- run: tox -e bandit-main\n- - name: Security Check - Tests\n- run: tox -e bandit-tests\n- - name: Safety Check\n- run: tox -e safety\n- - name: License Check\n- run: tox -e liccheck\n- - name: Copyright Check\n- run: tox -e copyright_check\n- - name: Code style check\n- run: |\n- tox -e black-check\n- tox -e flake8\n- - name: Static type check\n- run: tox -e mypy\n- name: Unit tests and coverage\nrun: |\ntox -e py${{ matrix.python-version }} -- --no-integration-tests --ci\n@@ -69,6 +90,3 @@ jobs:\nname: codecov-umbrella\nyml: ./codecov.yml\nfail_ci_if_error: true\n- - name: Generate Documentation\n- run: tox -e docs\n-\n",
        "sim_msg_3": "git workflow checks optimized"
    },
    {
        "org_diff": "diff --git a/.github/workflows/publish.yaml b/a/.github/workflows/publish.yaml @@ -63,10 +63,10 @@ jobs:\n     steps:\n       - uses: actions/download-artifact@9bc31d5ccc31df68ecc42ccf4149144866c47d8a\n       # Try uploading to Test PyPI first, in case something fails.\n-      - uses: pypa/gh-action-pypi-publish@a56da0b891b3dc519c7ee3284aff1fad93cc8598\n+      - uses: pypa/gh-action-pypi-publish@f5622bde02b04381239da3573277701ceca8f6a0\n         with:\n           repository-url: https://test.pypi.org/legacy/\n           packages-dir: artifact/\n-      - uses: pypa/gh-action-pypi-publish@a56da0b891b3dc519c7ee3284aff1fad93cc8598\n+      - uses: pypa/gh-action-pypi-publish@f5622bde02b04381239da3573277701ceca8f6a0\n         with:\n           packages-dir: artifact/",
        "sim_diff_0": "diff --git a/.github/workflows/full-build.yml b/.github/workflows/full-build.yml @@ -397,7 +397,7 @@ jobs:\nname: Publish to PyPI (release only)\nneeds: [ linux-gtk4, linux-flatpak-devel, macos-gtk4, check-linux-appimage, check-macos-app, check-windows-installer ]\nruns-on: ubuntu-22.04\n- # if: github.event_name == 'release'\n+ if: github.event_name == 'release'\nsteps:\n- uses: actions/download-artifact@v3\nwith:\n@@ -410,4 +410,3 @@ jobs:\n- uses: pypa/gh-action-pypi-publish@release/v1\nwith:\npassword: ${{ secrets.PYPI_TOKEN }}\n- repository_url: https://test.pypi.org/legacy/\n",
        "sim_msg_0": "Change publish target for production",
        "sim_diff_1": "diff --git a/.github/workflows/pypi_upload.yml b/.github/workflows/pypi_upload.yml @@ -47,7 +47,7 @@ jobs:\n# to upload to test pypi, pass repository_url: https://test.pypi.org/legacy/ and use secrets.TEST_PYPI_TOKEN\n- name: Publish a Python distribution to PyPI\n- uses: pypa/gh-action-pypi-publish@master\n+ uses: pypa/gh-action-pypi-publish@release/v1\nwith:\nuser: __token__\npassword: ${{ secrets.PYPI_TOKEN }}\n",
        "sim_msg_1": "Update pypi release action.",
        "sim_diff_2": "diff --git a/.github/workflows/pypi_upload.yml b/.github/workflows/pypi_upload.yml @@ -54,8 +54,8 @@ jobs:\nuses: pypa/gh-action-pypi-publish@master\nwith:\nuser: __token__\n- password: ${{ secrets.TEST_PYPI_TOKEN }}\n- repository_url: https://test.pypi.org/legacy/\n+ password: ${{ secrets.PYPI_TOKEN }}\n+ # repository_url: https://test.pypi.org/legacy/\npackages_dir: dist/\n# git push https://${{ github.actor }}:${{ secrets.GITHUB_TOKEN }}@github.com/${{ github.repository }}.git HEAD:master\n",
        "sim_msg_2": "Switch automated release action to point at production pypi",
        "sim_diff_3": "diff --git a/.github/workflows/pypi_upload.yml b/.github/workflows/pypi_upload.yml -name: Create Release & Upload To PyPI\n+name: Upload Python Package\non:\npush:\n# Sequence of patterns matched against refs/tags\ntags:\n- - v?[0-9]+.[0-9]+.[0-9]+.?(a|b|rc|dev)?[0-9]+ # add .* to allow dev releases\n+ - v[0-9]+.[0-9]+.* # add .* to allow dev releases\njobs:\n- build:\n+ deploy:\nname: pipenv PyPI Upload\nruns-on: ubuntu-latest\nenv:\n@@ -15,7 +15,7 @@ jobs:\nsteps:\n- name: Checkout code\n- uses: actions/checkout@v1\n+ uses: actions/checkout@v2\n- uses: webfactory/ssh-agent@v0.1.1\nwith:\n@@ -37,14 +37,18 @@ jobs:\nwith:\npython-version: 3.7\n- - name: Install latest tools for build\n+ - name: Install dependencies\nrun: |\n- python -m pip install --upgrade --upgrade-strategy=eager pip setuptools wheel invoke\n+ python -m pip install --upgrade --upgrade-strategy=eager pip setuptools wheel twine\npython -m pip install .\npython -m pipenv install --dev\n+ env:\n+ PIPENV_PYTHON: \"3.7\"\n+\n- name: Build wheels\nrun: |\npython -m pipenv run python setup.py sdist bdist_wheel\n+\n# to upload to test pypi, pass repository_url: https://test.pypi.org/legacy/ and use secrets.TEST_PYPI_TOKEN\n- name: Publish a Python distribution to PyPI\nuses: pypa/gh-action-pypi-publish@master\n@@ -53,6 +57,7 @@ jobs:\npassword: ${{ secrets.TEST_PYPI_TOKEN }}\nrepository_url: https://test.pypi.org/legacy/\npackages_dir: dist/\n+\n# git push https://${{ github.actor }}:${{ secrets.GITHUB_TOKEN }}@github.com/${{ github.repository }}.git HEAD:master\n# we need to use a deploy key for this to get around branch protection as the default token fails\n- name: Pre-bump\n@@ -61,3 +66,4 @@ jobs:\ngit config --local user.email action@github.com\npython -m pipenv run inv release.bump-version --dev --commit\ngit push git@github.com:${{ github.repository }}.git HEAD:master\n+\n",
        "sim_msg_3": "Fix tag syntax in workflow yaml"
    },
    {
        "org_diff": "diff --git a/.github/workflows/publish.yaml b/a/.github/workflows/publish.yaml @@ -33,7 +33,7 @@ jobs:\n       id-token: write\n       contents: write\n     # Can't pin with hash due to how this workflow works.\n-    uses: slsa-framework/slsa-github-generator/.github/workflows/generator_generic_slsa3.yml@v1.6.0\n+    uses: slsa-framework/slsa-github-generator/.github/workflows/generator_generic_slsa3.yml@v1.7.0\n     with:\n       base64-subjects: ${{ needs.build.outputs.hash }}\n   create-release:",
        "sim_diff_0": "diff --git a/.github/workflows/tag-actions.yml b/.github/workflows/tag-actions.yml @@ -10,6 +10,9 @@ jobs:\nname: Github Release\nruns-on: ubuntu-latest\n+ outputs:\n+ upload_url: ${{ steps.create_release.outputs.upload_url }}\n+\nsteps:\n- name: Create Release\nid: create_release\n@@ -125,7 +128,7 @@ jobs:\nenv:\nGITHUB_TOKEN: ${{ secrets.RELEASE_TOKEN }}\nwith:\n- upload_url: ${{ steps.create_release.outputs.upload_url }}\n+ upload_url: ${{ needs.github-release.outputs.upload_url }}\nasset_path: ./rpm/dist/beer-garden-${GITHUB_REF#refs/tags/}-1.el7.x86_64.rpm\nasset_name: beer-garden-${GITHUB_REF#refs/tags/}-1.el7.x86_64.rpm\nasset_content_type: application/octet-stream\n",
        "sim_msg_0": "Need to mark job output",
        "sim_diff_1": "diff --git a/.github/workflows/publish.yml b/.github/workflows/publish.yml @@ -2,7 +2,7 @@ name: publish\non:\npush:\n- branch:\n+ branches:\n- master\njobs:\n@@ -34,4 +34,4 @@ jobs:\nenv:\nPUBLISH_TARGET: ${{ secrets.PUBLISH_TARGET }}\nrun: |\n- rsync -azve \"ssh -o StrictHostKeyChecking=accept-new\" --delete build/anthology/ $PUBLISH_TARGET\n+ rsync -aze \"ssh -o StrictHostKeyChecking=accept-new\" --delete build/anthology/ $PUBLISH_TARGET\n",
        "sim_msg_1": "GH publish action: no verbose logging, only run on master\nSee PR",
        "sim_diff_2": "diff --git a/.github/workflows/release-drafter.yml b/.github/workflows/release-drafter.yml @@ -16,7 +16,7 @@ jobs:\nruns-on: ubuntu-latest\nsteps:\n- uses: release-drafter/release-drafter@v5\n- # with:\n- # disable-autolabeler: true\n+ with:\n+ disable-autolabeler: true\nenv:\nGITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n",
        "sim_msg_2": "explictly disable autolabeler for good measure",
        "sim_diff_3": "diff --git a/.github/workflows/publish.yaml b/.github/workflows/publish.yaml @@ -4,6 +4,7 @@ on:\npush:\nbranches:\n- develop\n+ - main\njobs:\npublish:\n@@ -21,6 +22,13 @@ jobs:\nproject_id: ${{ secrets.GCLOUD_FETCH_AI_SANDBOX_PROJECT }}\nservice_account_key: ${{ secrets.GCLOUD_FETCH_AI_SANDBOX_KEY }}\n+ - name: Setup GCloud - production\n+ uses: GoogleCloudPlatform/github-actions/setup-gcloud@master\n+ if: github.ref == 'refs/heads/main'\n+ with:\n+ project_id: ${{ secrets.GCLOUD_FETCH_AI_PROD_PROJECT }}\n+ service_account_key: ${{ secrets.GCLOUD_FETCH_AI_PROD_KEY }}\n+\n- name: Configure Docker\nrun: |\ngcloud auth configure-docker\n@@ -39,6 +47,11 @@ jobs:\n./scripts/acn/build_upload_img.sh\nfi\n+ if [ ${{ github.ref }} == 'refs/heads/main' ]\n+ then\n+ ./scripts/acn/build_upload_img.sh prod\n+ fi\n+\n- name: Repository Dispatch\nenv:\nIMAGE_TAG: ${{ steps.vars.outputs.sha_short }}\n@@ -51,3 +64,12 @@ jobs:\n--data '{\"event_type\": \"agents-dht-testnet\", \"client_payload\": {\"image\": \"gcr.io/fetch-ai-sandbox/acn_node\", \"tag\": \"'\"$IMAGE_TAG\"'\"}}' \\\nhttps://api.github.com/repos/fetchai/infra-sandbox-london-b-deployment/dispatches\nfi\n+\n+ if [ ${{ github.ref }} == 'refs/heads/main' ]\n+ then\n+ curl -H \"Accept: application/vnd.github.everest-preview+json\" \\\n+ -H \"Authorization: token ${{ secrets.GH_PAT }}\" \\\n+ --request POST \\\n+ --data '{\"event_type\": \"agents-dht\", \"client_payload\": {\"image\": \"gcr.io/fetch-ai-images/acn_node\", \"tag\": \"'\"$IMAGE_TAG\"'\"}}' \\\n+ https://api.github.com/repos/fetchai/infra-mainnet-v2-deployment/dispatches\n+ fi\n",
        "sim_msg_3": "Added steps for prod deployment"
    },
    {
        "org_diff": "diff --git a/.github/workflows/lock.yaml b/a/.github/workflows/lock.yaml @@ -19,7 +19,7 @@ jobs:\n   lock:\n     runs-on: ubuntu-latest\n     steps:\n-      - uses: dessant/lock-threads@c1b35aecc5cdb1a34539d14196df55838bb2f836\n+      - uses: dessant/lock-threads@be8aa5be94131386884a6da4189effda9b14aa21\n         with:\n           issue-inactive-days: 14\n           pr-inactive-days: 14",
        "sim_diff_0": "diff --git a/.github/workflows/stale.yml b/.github/workflows/stale.yml @@ -12,7 +12,7 @@ jobs:\nstale:\nruns-on: ubuntu-latest\nsteps:\n- uses: actions/stale@v4\n+ - uses: actions/stale@v4\nwith:\nexempt-all-milestones: true\nany-of-labels: 'need info'\n",
        "sim_msg_0": ".github/workflows/stale.yml: Missing dash",
        "sim_diff_1": "diff --git a/.github/workflows/stale.yml b/.github/workflows/stale.yml @@ -12,7 +12,7 @@ jobs:\nstale:\nruns-on: ubuntu-latest\nsteps:\n- uses: actions@stale@v4\n+ uses: actions/stale@v4\nwith:\nexempt-all-milestones: true\nany-of-labels: 'need info'\n",
        "sim_msg_1": ".github/workflows/stale.yml: Fix typo",
        "sim_diff_2": "diff --git a/.github/workflows/workflow.yml b/.github/workflows/workflow.yml @@ -53,7 +53,6 @@ jobs:\nrun: |\ntox -e black-check\ntox -e flake8\n- tox -e pylint\n- name: Static type check\nrun: tox -e mypy\n- name: Golang code style check\n@@ -63,6 +62,25 @@ jobs:\nworking-directory: packages/fetchai/connections/p2p_libp2p/\ncommon_checks_3:\n+ continue-on-error: False\n+ runs-on: ubuntu-latest\n+ timeout-minutes: 10\n+ steps:\n+ - uses: actions/checkout@master\n+ - uses: actions/setup-python@master\n+ with:\n+ python-version: 3.6\n+ - name: Install dependencies (ubuntu-latest)\n+ run: |\n+ sudo apt-get update --fix-missing\n+ sudo apt-get autoremove\n+ sudo apt-get autoclean\n+ pip install tox\n+ - name: Pylint check\n+ run: |\n+ tox -e pylint\n+\n+ common_checks_4:\ncontinue-on-error: False\nruns-on: ubuntu-latest\ntimeout-minutes: 10\n@@ -102,6 +120,7 @@ jobs:\n- common_checks_1\n- common_checks_2\n- common_checks_3\n+ - common_checks_4\nruns-on: ubuntu-latest\ntimeout-minutes: 50\nsteps:\n@@ -131,6 +150,7 @@ jobs:\n- common_checks_1\n- common_checks_2\n- common_checks_3\n+ - common_checks_4\nruns-on: ubuntu-latest\ntimeout-minutes: 30\nsteps:\n@@ -156,6 +176,7 @@ jobs:\n- common_checks_1\n- common_checks_2\n- common_checks_3\n+ - common_checks_4\nruns-on: ${{ matrix.os }}\nstrategy:\nmatrix:\n@@ -202,6 +223,7 @@ jobs:\n- common_checks_1\n- common_checks_2\n- common_checks_3\n+ - common_checks_4\nruns-on: ubuntu-latest\ntimeout-minutes: 30\nsteps:\n@@ -229,6 +251,7 @@ jobs:\n- common_checks_1\n- common_checks_2\n- common_checks_3\n+ - common_checks_4\nruns-on: ${{ matrix.os }}\nstrategy:\nmatrix:\n",
        "sim_msg_2": "split pylint out in separate common check",
        "sim_diff_3": "diff --git a/.github/workflows/workflow.yml b/.github/workflows/workflow.yml @@ -8,7 +8,44 @@ on:\npull_request:\njobs:\n- run:\n+ common_checks:\n+ runs-on: ubuntu-latest\n+\n+ timeout-minutes: 30\n+\n+ steps:\n+ - uses: actions/checkout@master\n+ - uses: actions/setup-python@master\n+ with:\n+ python-version: 3.6\n+ - name: Install dependencies (ubuntu-latest)\n+ run: |\n+ sudo apt-get update --fix-missing\n+ sudo apt-get autoremove\n+ sudo apt-get autoclean\n+ pip install pipenv\n+ pip install tox\n+ sudo apt-get install -y protobuf-compiler\n+ - name: Security Check - Main\n+ run: tox -e bandit-main\n+ - name: Security Check - Tests\n+ run: tox -e bandit-tests\n+ - name: Safety Check\n+ run: tox -e safety\n+ - name: License Check\n+ run: tox -e liccheck\n+ - name: Copyright Check\n+ run: tox -e copyright_check\n+ - name: Code style check\n+ run: |\n+ tox -e black-check\n+ tox -e flake8\n+ - name: Static type check\n+ run: tox -e mypy\n+ - name: Generate Documentation\n+ run: tox -e docs\n+\n+ platform_checks:\nruns-on: ${{ matrix.os }}\nstrategy:\n@@ -40,22 +77,6 @@ jobs:\npip install pipenv\npip install tox\nbrew install protobuf\n- - name: Security Check - Main\n- run: tox -e bandit-main\n- - name: Security Check - Tests\n- run: tox -e bandit-tests\n- - name: Safety Check\n- run: tox -e safety\n- - name: License Check\n- run: tox -e liccheck\n- - name: Copyright Check\n- run: tox -e copyright_check\n- - name: Code style check\n- run: |\n- tox -e black-check\n- tox -e flake8\n- - name: Static type check\n- run: tox -e mypy\n- name: Unit tests and coverage\nrun: |\ntox -e py${{ matrix.python-version }} -- --no-integration-tests --ci\n@@ -69,6 +90,3 @@ jobs:\nname: codecov-umbrella\nyml: ./codecov.yml\nfail_ci_if_error: true\n- - name: Generate Documentation\n- run: tox -e docs\n-\n",
        "sim_msg_3": "git workflow checks optimized"
    },
    {
        "org_diff": "diff --git a/.github/workflows/publish.yaml b/a/.github/workflows/publish.yaml @@ -63,10 +63,10 @@ jobs:\n     steps:\n       - uses: actions/download-artifact@9bc31d5ccc31df68ecc42ccf4149144866c47d8a\n       # Try uploading to Test PyPI first, in case something fails.\n-      - uses: pypa/gh-action-pypi-publish@a56da0b891b3dc519c7ee3284aff1fad93cc8598\n+      - uses: pypa/gh-action-pypi-publish@f5622bde02b04381239da3573277701ceca8f6a0\n         with:\n           repository-url: https://test.pypi.org/legacy/\n           packages-dir: artifact/\n-      - uses: pypa/gh-action-pypi-publish@a56da0b891b3dc519c7ee3284aff1fad93cc8598\n+      - uses: pypa/gh-action-pypi-publish@f5622bde02b04381239da3573277701ceca8f6a0\n         with:\n           packages-dir: artifact/",
        "sim_diff_0": "diff --git a/.github/workflows/full-build.yml b/.github/workflows/full-build.yml @@ -397,7 +397,7 @@ jobs:\nname: Publish to PyPI (release only)\nneeds: [ linux-gtk4, linux-flatpak-devel, macos-gtk4, check-linux-appimage, check-macos-app, check-windows-installer ]\nruns-on: ubuntu-22.04\n- # if: github.event_name == 'release'\n+ if: github.event_name == 'release'\nsteps:\n- uses: actions/download-artifact@v3\nwith:\n@@ -410,4 +410,3 @@ jobs:\n- uses: pypa/gh-action-pypi-publish@release/v1\nwith:\npassword: ${{ secrets.PYPI_TOKEN }}\n- repository_url: https://test.pypi.org/legacy/\n",
        "sim_msg_0": "Change publish target for production",
        "sim_diff_1": "diff --git a/.github/workflows/pypi_upload.yml b/.github/workflows/pypi_upload.yml @@ -47,7 +47,7 @@ jobs:\n# to upload to test pypi, pass repository_url: https://test.pypi.org/legacy/ and use secrets.TEST_PYPI_TOKEN\n- name: Publish a Python distribution to PyPI\n- uses: pypa/gh-action-pypi-publish@master\n+ uses: pypa/gh-action-pypi-publish@release/v1\nwith:\nuser: __token__\npassword: ${{ secrets.PYPI_TOKEN }}\n",
        "sim_msg_1": "Update pypi release action.",
        "sim_diff_2": "diff --git a/.github/workflows/pypi_upload.yml b/.github/workflows/pypi_upload.yml @@ -54,8 +54,8 @@ jobs:\nuses: pypa/gh-action-pypi-publish@master\nwith:\nuser: __token__\n- password: ${{ secrets.TEST_PYPI_TOKEN }}\n- repository_url: https://test.pypi.org/legacy/\n+ password: ${{ secrets.PYPI_TOKEN }}\n+ # repository_url: https://test.pypi.org/legacy/\npackages_dir: dist/\n# git push https://${{ github.actor }}:${{ secrets.GITHUB_TOKEN }}@github.com/${{ github.repository }}.git HEAD:master\n",
        "sim_msg_2": "Switch automated release action to point at production pypi",
        "sim_diff_3": "diff --git a/.github/workflows/pypi_upload.yml b/.github/workflows/pypi_upload.yml -name: Create Release & Upload To PyPI\n+name: Upload Python Package\non:\npush:\n# Sequence of patterns matched against refs/tags\ntags:\n- - v?[0-9]+.[0-9]+.[0-9]+.?(a|b|rc|dev)?[0-9]+ # add .* to allow dev releases\n+ - v[0-9]+.[0-9]+.* # add .* to allow dev releases\njobs:\n- build:\n+ deploy:\nname: pipenv PyPI Upload\nruns-on: ubuntu-latest\nenv:\n@@ -15,7 +15,7 @@ jobs:\nsteps:\n- name: Checkout code\n- uses: actions/checkout@v1\n+ uses: actions/checkout@v2\n- uses: webfactory/ssh-agent@v0.1.1\nwith:\n@@ -37,14 +37,18 @@ jobs:\nwith:\npython-version: 3.7\n- - name: Install latest tools for build\n+ - name: Install dependencies\nrun: |\n- python -m pip install --upgrade --upgrade-strategy=eager pip setuptools wheel invoke\n+ python -m pip install --upgrade --upgrade-strategy=eager pip setuptools wheel twine\npython -m pip install .\npython -m pipenv install --dev\n+ env:\n+ PIPENV_PYTHON: \"3.7\"\n+\n- name: Build wheels\nrun: |\npython -m pipenv run python setup.py sdist bdist_wheel\n+\n# to upload to test pypi, pass repository_url: https://test.pypi.org/legacy/ and use secrets.TEST_PYPI_TOKEN\n- name: Publish a Python distribution to PyPI\nuses: pypa/gh-action-pypi-publish@master\n@@ -53,6 +57,7 @@ jobs:\npassword: ${{ secrets.TEST_PYPI_TOKEN }}\nrepository_url: https://test.pypi.org/legacy/\npackages_dir: dist/\n+\n# git push https://${{ github.actor }}:${{ secrets.GITHUB_TOKEN }}@github.com/${{ github.repository }}.git HEAD:master\n# we need to use a deploy key for this to get around branch protection as the default token fails\n- name: Pre-bump\n@@ -61,3 +66,4 @@ jobs:\ngit config --local user.email action@github.com\npython -m pipenv run inv release.bump-version --dev --commit\ngit push git@github.com:${{ github.repository }}.git HEAD:master\n+\n",
        "sim_msg_3": "Fix tag syntax in workflow yaml"
    },
    {
        "org_diff": "diff --git a/docs/errorhandling.rst b/a/docs/errorhandling.rst @@ -231,7 +231,7 @@ responses, you could also pass them through directly.\n Error handlers still respect the exception class hierarchy. If you\n register handlers for both ``HTTPException`` and ``Exception``, the\n ``Exception`` handler will not handle ``HTTPException`` subclasses\n-because it the ``HTTPException`` handler is more specific.\n+because the ``HTTPException`` handler is more specific.\n \n \n Unhandled Exceptions",
        "sim_diff_0": "diff --git a/docs/errorhandling.rst b/docs/errorhandling.rst @@ -76,9 +76,9 @@ Error handlers\nYou might want to show custom error pages to the user when an error occurs.\nThis can be done by registering error handlers.\n-An error handler is a normal view function that return a response, but instead\n+An error handler is a normal view function that returns a response, but instead\nof being registered for a route, it is registered for an exception or HTTP\n-status code that would is raised while trying to handle a request.\n+status code that would be raised while trying to handle a request.\nRegistering\n```````````\n@@ -184,7 +184,7 @@ options in order to use your favorite debugger:\n* ``debug`` - whether to enable debug mode and catch exceptions\n* ``use_debugger`` - whether to use the internal Flask debugger\n-* ``use_reloader`` - whether to reload and fork the process on exception\n+* ``use_reloader`` - whether to reload and fork the process if modules were changed\n``debug`` must be True (i.e., exceptions must be caught) in order for the other\ntwo options to have any value.\n@@ -205,11 +205,6 @@ Then in your application's entry-point (main.py), you could have something like:\n# To allow aptana to receive errors, set use_debugger=False\napp = create_app(config=\"config.yaml\")\n- if app.debug: use_debugger = True\n- try:\n- # Disable Flask's debugger if external debugger is requested\n- use_debugger = not(app.config.get('DEBUG_WITH_APTANA'))\n- except:\n- pass\n+ use_debugger = app.debug and not(app.config.get('DEBUG_WITH_APTANA'))\napp.run(use_debugger=use_debugger, debug=app.debug,\nuse_reloader=use_debugger, host='0.0.0.0')\n",
        "sim_msg_0": "Fix docs errors\n1.Grammar error: 'return' should be 'returns'; 'would is' should be\n'would be'.\n2.Reloader is used to reload and fork process if modules were changed\nrather than when an exception occurred.\n3.The sample code is not concise enough.",
        "sim_diff_1": "diff --git a/docs/patterns/errorpages.rst b/docs/patterns/errorpages.rst @@ -54,9 +54,11 @@ can be a different error: a handler for internal server errors will be\npassed other exception instances as well if they are uncaught.\nAn error handler is registered with the :meth:`~flask.Flask.errorhandler`\n-decorator and the error code of the exception. Keep in mind that Flask\n-will *not* set the error code for you, so make sure to also provide the\n-HTTP status code when returning a response.\n+decorator and the error code of the exception (alternatively, you can use the\n+:meth:`~flask.Flask.register_error_handler` function, e.g., when you're\n+registering error handlers as part of your Application Factory). Keep in mind\n+that Flask will *not* set the error code for you, so make sure to also provide\n+the HTTP status code when returning a response.delete_cookie.\nPlease note that if you add an error handler for \"500 Internal Server\nError\", Flask will not trigger it if it's running in Debug mode.\n@@ -69,6 +71,18 @@ Here an example implementation for a \"404 Page Not Found\" exception::\ndef page_not_found(e):\nreturn render_template('404.html'), 404\n+And, using an application factory pattern (see :ref:`app-factories`)::\n+\n+ from flask import Flask, render_template\n+\n+ def page_not_found(e):\n+ return render_template('404.html'), 404\n+\n+ def create_app(config_filename):\n+ app = Flask(__name__)\n+ # ...\n+ app.register_error_handler(404, page_not_found)\n+\nAn example template might be this:\n.. sourcecode:: html+jinja\n",
        "sim_msg_1": "Mention existence of register_error_handler in errorpages.rst\nSee for context.",
        "sim_diff_2": "diff --git a/lnbits/app.py b/lnbits/app.py @@ -174,6 +174,8 @@ def register_exception_handlers(app: FastAPI):\netype, _, tb = sys.exc_info()\ntraceback.print_exception(etype, exc, tb)\nlogger.error(f\"Exception: {str(exc)}\")\n+ # Only the browser sends \"text/html\" request\n+ # not fail proof, but everything else get's a JSON response\nif (\nrequest.headers\nand \"accept\" in request.headers\n@@ -215,8 +217,6 @@ def register_exception_handlers(app: FastAPI):\n@app.exception_handler(HTTPException)\nasync def http_exception_handler(request: Request, exc: HTTPException):\n- etype, _, tb = sys.exc_info()\n- traceback.print_exception(etype, exc, tb)\nlogger.error(f\"HTTPException {exc.status_code}: {exc.detail}\")\n# Only the browser sends \"text/html\" request\n# not fail proof, but everything else get's a JSON response\n",
        "sim_msg_2": "fix: no stack trace for http errors",
        "sim_diff_3": "diff --git a/docs/reqcontext.rst b/docs/reqcontext.rst @@ -119,8 +119,8 @@ understand what is actually happening. The new behavior is quite simple:\nnot executed yet or at all (for example in test environments sometimes\nyou might want to not execute before-request callbacks).\n-Now what happens on errors? In production mode if an exception is not\n-caught, the 500 internal server handler is called. In development mode\n+Now what happens on errors? If you are not in debug mode if an exception is not\n+caught, the 500 internal server handler is called. In debug mode\nhowever the exception is not further processed and bubbles up to the WSGI\nserver. That way things like the interactive debugger can provide helpful\ndebug information.\n@@ -214,10 +214,11 @@ provide you with important information.\nStarting with Flask 0.7 you have finer control over that behavior by\nsetting the ``PRESERVE_CONTEXT_ON_EXCEPTION`` configuration variable. By\ndefault it's linked to the setting of ``DEBUG``. If the application is in\n-debug mode the context is preserved, in production mode it's not.\n+debug mode the context is preserved. If debug mode is set to off, the context\n+is not preserved.\n-Do not force activate ``PRESERVE_CONTEXT_ON_EXCEPTION`` in production mode\n-as it will cause your application to leak memory on exceptions. However\n+Do not force activate ``PRESERVE_CONTEXT_ON_EXCEPTION`` if debug mode is set to off\n+as it will cause your application to leak memory on exceptions. However,\nit can be useful during development to get the same error preserving\n-behavior as in development mode when attempting to debug an error that\n+behavior as debug mode when attempting to debug an error that\nonly occurs under production settings.\n",
        "sim_msg_3": "Updated documentation. Replaced term development mode with debug mode."
    },
    {
        "org_diff": "diff --git a/docs/errorhandling.rst b/a/docs/errorhandling.rst @@ -231,7 +231,7 @@ responses, you could also pass them through directly.\n Error handlers still respect the exception class hierarchy. If you\n register handlers for both ``HTTPException`` and ``Exception``, the\n ``Exception`` handler will not handle ``HTTPException`` subclasses\n-because it the ``HTTPException`` handler is more specific.\n+because the ``HTTPException`` handler is more specific.\n \n \n Unhandled Exceptions",
        "sim_diff_0": "diff --git a/docs/errorhandling.rst b/docs/errorhandling.rst @@ -76,9 +76,9 @@ Error handlers\nYou might want to show custom error pages to the user when an error occurs.\nThis can be done by registering error handlers.\n-An error handler is a normal view function that return a response, but instead\n+An error handler is a normal view function that returns a response, but instead\nof being registered for a route, it is registered for an exception or HTTP\n-status code that would is raised while trying to handle a request.\n+status code that would be raised while trying to handle a request.\nRegistering\n```````````\n@@ -184,7 +184,7 @@ options in order to use your favorite debugger:\n* ``debug`` - whether to enable debug mode and catch exceptions\n* ``use_debugger`` - whether to use the internal Flask debugger\n-* ``use_reloader`` - whether to reload and fork the process on exception\n+* ``use_reloader`` - whether to reload and fork the process if modules were changed\n``debug`` must be True (i.e., exceptions must be caught) in order for the other\ntwo options to have any value.\n@@ -205,11 +205,6 @@ Then in your application's entry-point (main.py), you could have something like:\n# To allow aptana to receive errors, set use_debugger=False\napp = create_app(config=\"config.yaml\")\n- if app.debug: use_debugger = True\n- try:\n- # Disable Flask's debugger if external debugger is requested\n- use_debugger = not(app.config.get('DEBUG_WITH_APTANA'))\n- except:\n- pass\n+ use_debugger = app.debug and not(app.config.get('DEBUG_WITH_APTANA'))\napp.run(use_debugger=use_debugger, debug=app.debug,\nuse_reloader=use_debugger, host='0.0.0.0')\n",
        "sim_msg_0": "Fix docs errors\n1.Grammar error: 'return' should be 'returns'; 'would is' should be\n'would be'.\n2.Reloader is used to reload and fork process if modules were changed\nrather than when an exception occurred.\n3.The sample code is not concise enough.",
        "sim_diff_1": "diff --git a/docs/patterns/errorpages.rst b/docs/patterns/errorpages.rst @@ -54,9 +54,11 @@ can be a different error: a handler for internal server errors will be\npassed other exception instances as well if they are uncaught.\nAn error handler is registered with the :meth:`~flask.Flask.errorhandler`\n-decorator and the error code of the exception. Keep in mind that Flask\n-will *not* set the error code for you, so make sure to also provide the\n-HTTP status code when returning a response.\n+decorator and the error code of the exception (alternatively, you can use the\n+:meth:`~flask.Flask.register_error_handler` function, e.g., when you're\n+registering error handlers as part of your Application Factory). Keep in mind\n+that Flask will *not* set the error code for you, so make sure to also provide\n+the HTTP status code when returning a response.delete_cookie.\nPlease note that if you add an error handler for \"500 Internal Server\nError\", Flask will not trigger it if it's running in Debug mode.\n@@ -69,6 +71,18 @@ Here an example implementation for a \"404 Page Not Found\" exception::\ndef page_not_found(e):\nreturn render_template('404.html'), 404\n+And, using an application factory pattern (see :ref:`app-factories`)::\n+\n+ from flask import Flask, render_template\n+\n+ def page_not_found(e):\n+ return render_template('404.html'), 404\n+\n+ def create_app(config_filename):\n+ app = Flask(__name__)\n+ # ...\n+ app.register_error_handler(404, page_not_found)\n+\nAn example template might be this:\n.. sourcecode:: html+jinja\n",
        "sim_msg_1": "Mention existence of register_error_handler in errorpages.rst\nSee for context.",
        "sim_diff_2": "diff --git a/lnbits/app.py b/lnbits/app.py @@ -174,6 +174,8 @@ def register_exception_handlers(app: FastAPI):\netype, _, tb = sys.exc_info()\ntraceback.print_exception(etype, exc, tb)\nlogger.error(f\"Exception: {str(exc)}\")\n+ # Only the browser sends \"text/html\" request\n+ # not fail proof, but everything else get's a JSON response\nif (\nrequest.headers\nand \"accept\" in request.headers\n@@ -215,8 +217,6 @@ def register_exception_handlers(app: FastAPI):\n@app.exception_handler(HTTPException)\nasync def http_exception_handler(request: Request, exc: HTTPException):\n- etype, _, tb = sys.exc_info()\n- traceback.print_exception(etype, exc, tb)\nlogger.error(f\"HTTPException {exc.status_code}: {exc.detail}\")\n# Only the browser sends \"text/html\" request\n# not fail proof, but everything else get's a JSON response\n",
        "sim_msg_2": "fix: no stack trace for http errors",
        "sim_diff_3": "diff --git a/docs/reqcontext.rst b/docs/reqcontext.rst @@ -119,8 +119,8 @@ understand what is actually happening. The new behavior is quite simple:\nnot executed yet or at all (for example in test environments sometimes\nyou might want to not execute before-request callbacks).\n-Now what happens on errors? In production mode if an exception is not\n-caught, the 500 internal server handler is called. In development mode\n+Now what happens on errors? If you are not in debug mode if an exception is not\n+caught, the 500 internal server handler is called. In debug mode\nhowever the exception is not further processed and bubbles up to the WSGI\nserver. That way things like the interactive debugger can provide helpful\ndebug information.\n@@ -214,10 +214,11 @@ provide you with important information.\nStarting with Flask 0.7 you have finer control over that behavior by\nsetting the ``PRESERVE_CONTEXT_ON_EXCEPTION`` configuration variable. By\ndefault it's linked to the setting of ``DEBUG``. If the application is in\n-debug mode the context is preserved, in production mode it's not.\n+debug mode the context is preserved. If debug mode is set to off, the context\n+is not preserved.\n-Do not force activate ``PRESERVE_CONTEXT_ON_EXCEPTION`` in production mode\n-as it will cause your application to leak memory on exceptions. However\n+Do not force activate ``PRESERVE_CONTEXT_ON_EXCEPTION`` if debug mode is set to off\n+as it will cause your application to leak memory on exceptions. However,\nit can be useful during development to get the same error preserving\n-behavior as in development mode when attempting to debug an error that\n+behavior as debug mode when attempting to debug an error that\nonly occurs under production settings.\n",
        "sim_msg_3": "Updated documentation. Replaced term development mode with debug mode."
    },
    {
        "org_diff": "diff --git a/tox.ini b/a/tox.ini @@ -34,17 +34,9 @@ skip_install = true\n commands = pre-commit run --all-files\n \n [testenv:typing]\n-package = wheel\n-wheel_build_env = .pkg\n-constrain_package_deps = true\n-use_frozen_constraints = true\n deps = -r requirements/typing.txt\n commands = mypy\n \n [testenv:docs]\n-package = wheel\n-wheel_build_env = .pkg\n-constrain_package_deps = true\n-use_frozen_constraints = true\n deps = -r requirements/docs.txt\n commands = sphinx-build -W -b html -d {envtmpdir}/doctrees docs {envtmpdir}/html",
        "sim_diff_0": "diff --git a/tox.ini b/tox.ini [tox]\n-envlist = flake8,py35,py36,py37,py38,docs\n+envlist = flake8,py35,py36,py37,py38,mypy,docs\nrequires = Cython>=0.29.13\n[testenv]\n@@ -26,9 +26,14 @@ basepython = python3.6\ndeps = flake8\ncommands = flake8 src/ tests/\n+[testenv:mypy]\n+basepython = python3.6\n+deps = mypy\n+commands = mypy src/\n+\n[travis]\npython =\n- 3.6: py36, docs\n+ 3.6: py36, docs, mypy\n[coverage:run]\nparallel = True\n",
        "sim_msg_0": "Run mypy as part of CI",
        "sim_diff_1": "diff --git a/tox.ini b/tox.ini @@ -69,7 +69,14 @@ basepython =\ncommands =\npy.test {env:TESTPATH} {posargs} --max-slave-restart=4\n+[testenv:pypy]\n+commands:\n+ pypy: py.test {env:TESTPATH} {posargs} -n0\n+\n# Linters\n+\n+\n+\n[testenv:flake8]\nbasepython = python3.5\nskip_install = true\n",
        "sim_msg_1": "No luck, just removing xdist from pypy env",
        "sim_diff_2": "diff --git a/tox.ini b/tox.ini [tox]\n-envlist = py27, py36\n+envlist = py27, py36, {py27,py36}-flake8\n+\n+[flake8]\n+max-line-length = 160\n+exclude: .git,.venv,.tox\n[testenv]\ncommands = nosetests -s --with-coverage --cover-package=hvac --cover-html {posargs}\ndeps = -rrequirements.txt\n-rrequirements-dev.txt\n+\n+[testenv:py27-flake8]\n+basepython = python2.7\n+deps = flake8\n+commands = flake8 {posargs}\n+\n+[testenv:py36-flake8]\n+basepython = python3.6\n+deps = flake8\n+commands = flake8 {posargs}\n",
        "sim_msg_2": "Add flake8 linting to tox jobs",
        "sim_diff_3": "diff --git a/tox.ini b/tox.ini @@ -6,9 +6,7 @@ skipsdist = True\n[testenv]\nusedevelop = True\nwhitelist_externals = find\n-install_command =\n- pip install -U --force-reinstall -c{env:UPPER_CONSTRAINTS_FILE:https://git.openstack.org/cgit/openstack/requirements/plain/upper-constraints.txt} {opts} {packages}\n-\n+install_command = pip install -c{env:UPPER_CONSTRAINTS_FILE:https://git.openstack.org/cgit/openstack/requirements/plain/upper-constraints.txt} {opts} {packages}\nsetenv =\nVIRTUAL_ENV={envdir}\ndeps = -r{toxinidir}/test-requirements.txt\n",
        "sim_msg_3": "Fix broken gates because of wrong pip command"
    },
    {
        "org_diff": "diff --git a/tox.ini b/a/tox.ini @@ -34,17 +34,9 @@ skip_install = true\n commands = pre-commit run --all-files\n \n [testenv:typing]\n-package = wheel\n-wheel_build_env = .pkg\n-constrain_package_deps = true\n-use_frozen_constraints = true\n deps = -r requirements/typing.txt\n commands = mypy\n \n [testenv:docs]\n-package = wheel\n-wheel_build_env = .pkg\n-constrain_package_deps = true\n-use_frozen_constraints = true\n deps = -r requirements/docs.txt\n commands = sphinx-build -W -b html -d {envtmpdir}/doctrees docs {envtmpdir}/html",
        "sim_diff_0": "diff --git a/tox.ini b/tox.ini [tox]\n-envlist = flake8,py35,py36,py37,py38,docs\n+envlist = flake8,py35,py36,py37,py38,mypy,docs\nrequires = Cython>=0.29.13\n[testenv]\n@@ -26,9 +26,14 @@ basepython = python3.6\ndeps = flake8\ncommands = flake8 src/ tests/\n+[testenv:mypy]\n+basepython = python3.6\n+deps = mypy\n+commands = mypy src/\n+\n[travis]\npython =\n- 3.6: py36, docs\n+ 3.6: py36, docs, mypy\n[coverage:run]\nparallel = True\n",
        "sim_msg_0": "Run mypy as part of CI",
        "sim_diff_1": "diff --git a/tox.ini b/tox.ini @@ -69,7 +69,14 @@ basepython =\ncommands =\npy.test {env:TESTPATH} {posargs} --max-slave-restart=4\n+[testenv:pypy]\n+commands:\n+ pypy: py.test {env:TESTPATH} {posargs} -n0\n+\n# Linters\n+\n+\n+\n[testenv:flake8]\nbasepython = python3.5\nskip_install = true\n",
        "sim_msg_1": "No luck, just removing xdist from pypy env",
        "sim_diff_2": "diff --git a/tox.ini b/tox.ini [tox]\n-envlist = py27, py36\n+envlist = py27, py36, {py27,py36}-flake8\n+\n+[flake8]\n+max-line-length = 160\n+exclude: .git,.venv,.tox\n[testenv]\ncommands = nosetests -s --with-coverage --cover-package=hvac --cover-html {posargs}\ndeps = -rrequirements.txt\n-rrequirements-dev.txt\n+\n+[testenv:py27-flake8]\n+basepython = python2.7\n+deps = flake8\n+commands = flake8 {posargs}\n+\n+[testenv:py36-flake8]\n+basepython = python3.6\n+deps = flake8\n+commands = flake8 {posargs}\n",
        "sim_msg_2": "Add flake8 linting to tox jobs",
        "sim_diff_3": "diff --git a/tox.ini b/tox.ini @@ -6,9 +6,7 @@ skipsdist = True\n[testenv]\nusedevelop = True\nwhitelist_externals = find\n-install_command =\n- pip install -U --force-reinstall -c{env:UPPER_CONSTRAINTS_FILE:https://git.openstack.org/cgit/openstack/requirements/plain/upper-constraints.txt} {opts} {packages}\n-\n+install_command = pip install -c{env:UPPER_CONSTRAINTS_FILE:https://git.openstack.org/cgit/openstack/requirements/plain/upper-constraints.txt} {opts} {packages}\nsetenv =\nVIRTUAL_ENV={envdir}\ndeps = -r{toxinidir}/test-requirements.txt\n",
        "sim_msg_3": "Fix broken gates because of wrong pip command"
    },
    {
        "org_diff": "diff --git a/docs/patterns/sqlalchemy.rst b/a/docs/patterns/sqlalchemy.rst @@ -34,8 +34,7 @@ official documentation on the `declarative`_ extension.\n Here's the example :file:`database.py` module for your application::\n \n     from sqlalchemy import create_engine\n-    from sqlalchemy.orm import scoped_session, sessionmaker\n-    from sqlalchemy.ext.declarative import declarative_base\n+    from sqlalchemy.orm import scoped_session, sessionmaker, declarative_base\n \n     engine = create_engine('sqlite:////tmp/test.db')\n     db_session = scoped_session(sessionmaker(autocommit=False,",
        "sim_diff_0": "diff --git a/packages/syft/src/syft/core/node/common/node.py b/packages/syft/src/syft/core/node/common/node.py @@ -110,7 +110,7 @@ class Node(AbstractNode):\nverify_key: Optional[VerifyKey] = None,\ndb_path: Optional[str] = None,\nTableBase: Any = None,\n- engine: Any = None,\n+ db_engine: Any = None,\ndb: Any = None,\n):\n@@ -132,14 +132,14 @@ class Node(AbstractNode):\nif db is None:\n# If a DB engine isn't provided then\n- if engine is None:\n+ if db_engine is None:\nengine = create_engine(\"sqlite://\", echo=False)\n- db = sessionmaker(bind=engine)()\n+ db = sessionmaker(bind=db_engine)()\n# cache these variables on self\nself.TableBase = TableBase\n- self.engine = engine\n+ self.db_engine = db_engine\nself.db = db\n# launch the tables in the database\n@@ -153,8 +153,9 @@ class Node(AbstractNode):\n# become quite numerous (or otherwise fill up RAM).\n# self.store is the elastic memory.\n+\nself.store = BinObjectManager(\n- db=self.db\n+ db=self.db_engine\n)\n# We need to register all the services once a node is created\n",
        "sim_msg_0": "RENAME engine -> db_engine",
        "sim_diff_1": "diff --git a/pajbot/managers/db.py b/pajbot/managers/db.py @@ -2,16 +2,38 @@ import logging\nfrom contextlib import contextmanager\nfrom sqlalchemy import create_engine\n+from sqlalchemy import event\n+from sqlalchemy import exc\nfrom sqlalchemy import inspect\nfrom sqlalchemy.ext.declarative import declarative_base\nfrom sqlalchemy.orm import scoped_session\nfrom sqlalchemy.orm import sessionmaker\n+from sqlalchemy.pool import Pool\nBase = declarative_base()\nlog = logging.getLogger('pajbot')\n+@event.listens_for(Pool, 'checkout')\n+def check_connection(dbapi_con, con_record, con_proxy):\n+ '''Listener for Pool checkout events that pings every connection before using.\n+ Implements pessimistic disconnect handling strategy. See also:\n+ http://docs.sqlalchemy.org/en/rel_0_8/core/pooling.html#disconnect-handling-pessimistic'''\n+\n+ cursor = dbapi_con.cursor()\n+ try:\n+ cursor.execute('SELECT 1')\n+ except exc.OperationalError as ex:\n+ if ex.args[0] in (2006, # MySQL server has gone away\n+ 2013, # Lost connection to MySQL server during query\n+ 2055): # Lost connection to MySQL server at '%s', system error: %d\n+ # caught by pool, which will retry with a new connection\n+ raise exc.DisconnectionError()\n+ else:\n+ raise\n+\n+\nclass DBManager:\ndef init(url):\nDBManager.engine = create_engine(url)\n",
        "sim_msg_1": "Add potential fix to database connections timing out",
        "sim_diff_2": "diff --git a/haystack/document_stores/sql.py b/haystack/document_stores/sql.py @@ -24,7 +24,7 @@ try:\nTypeDecorator,\n)\nfrom sqlalchemy.ext.declarative import declarative_base\n- from sqlalchemy.orm import relationship, sessionmaker\n+ from sqlalchemy.orm import relationship, sessionmaker, aliased\nfrom sqlalchemy.sql import case, null\nexcept (ImportError, ModuleNotFoundError) as ie:\nfrom haystack.utils.import_utils import _optional_component_not_installed\n@@ -688,7 +688,8 @@ class SQLDocumentStore(BaseDocumentStore):\nif ids:\ndocument_ids_to_delete = document_ids_to_delete.filter(DocumentORM.id.in_(ids))\n- self.session.query(DocumentORM).filter(DocumentORM.id.in_(document_ids_to_delete)).delete(\n+ inner_query = document_ids_to_delete.subquery()\n+ self.session.query(DocumentORM).filter(DocumentORM.id.in_(aliased(inner_query))).delete(\nsynchronize_session=False\n)\n@@ -736,7 +737,8 @@ class SQLDocumentStore(BaseDocumentStore):\nif ids:\nlabel_ids_to_delete = label_ids_to_delete.filter(LabelORM.id.in_(ids))\n- self.session.query(LabelORM).filter(LabelORM.id.in_(label_ids_to_delete)).delete(synchronize_session=False)\n+ inner_query = label_ids_to_delete.subquery()\n+ self.session.query(LabelORM).filter(LabelORM.id.in_(aliased(inner_query))).delete(synchronize_session=False)\nself.session.commit()\n",
        "sim_msg_2": "fix: add inner query for mysql compatibility",
        "sim_diff_3": "diff --git a/haystack/document_store/sql.py b/haystack/document_store/sql.py from typing import Any, Dict, Union, List, Optional\nfrom uuid import uuid4\n-from sqlalchemy import create_engine, Column, Integer, String, DateTime, func, ForeignKey, Boolean\n+from sqlalchemy import create_engine, Column, Integer, String, DateTime, func, ForeignKey, Boolean, Text\nfrom sqlalchemy.ext.declarative import declarative_base\nfrom sqlalchemy.orm import relationship, sessionmaker\nfrom sqlalchemy.sql import case\n@@ -16,7 +16,7 @@ Base = declarative_base() # type: Any\nclass ORMBase(Base):\n__abstract__ = True\n- id = Column(String, default=lambda: str(uuid4()), primary_key=True)\n+ id = Column(String(100), default=lambda: str(uuid4()), primary_key=True)\ncreated = Column(DateTime, server_default=func.now())\nupdated = Column(DateTime, server_default=func.now(), server_onupdate=func.now())\n@@ -24,19 +24,20 @@ class ORMBase(Base):\nclass DocumentORM(ORMBase):\n__tablename__ = \"document\"\n- text = Column(String, nullable=False)\n- index = Column(String, nullable=False)\n- vector_id = Column(String, unique=True, nullable=True)\n+ text = Column(Text, nullable=False)\n+ index = Column(String(100), nullable=False)\n+ vector_id = Column(String(100), unique=True, nullable=True)\n# speeds up queries for get_documents_by_vector_ids() by having a single query that returns joined metadata\nmeta = relationship(\"MetaORM\", backref=\"Document\", lazy=\"joined\")\n+\nclass MetaORM(ORMBase):\n__tablename__ = \"meta\"\n- name = Column(String, index=True)\n- value = Column(String, index=True)\n- document_id = Column(String, ForeignKey(\"document.id\", ondelete=\"CASCADE\"), nullable=False)\n+ name = Column(String(100), index=True)\n+ value = Column(String(1000), index=True)\n+ document_id = Column(String(100), ForeignKey(\"document.id\", ondelete=\"CASCADE\"), nullable=False)\ndocuments = relationship(DocumentORM, backref=\"Meta\")\n@@ -44,14 +45,14 @@ class MetaORM(ORMBase):\nclass LabelORM(ORMBase):\n__tablename__ = \"label\"\n- document_id = Column(String, ForeignKey(\"document.id\", ondelete=\"CASCADE\"), nullable=False)\n- index = Column(String, nullable=False)\n+ document_id = Column(String(100), ForeignKey(\"document.id\", ondelete=\"CASCADE\"), nullable=False)\n+ index = Column(String(100), nullable=False)\nno_answer = Column(Boolean, nullable=False)\n- origin = Column(String, nullable=False)\n- question = Column(String, nullable=False)\n+ origin = Column(String(100), nullable=False)\n+ question = Column(Text, nullable=False)\nis_correct_answer = Column(Boolean, nullable=False)\nis_correct_document = Column(Boolean, nullable=False)\n- answer = Column(String, nullable=False)\n+ answer = Column(Text, nullable=False)\noffset_start_in_doc = Column(Integer, nullable=False)\nmodel_id = Column(Integer, nullable=True)\n",
        "sim_msg_3": "Add support for MySQL database"
    },
    {
        "org_diff": "diff --git a/docs/patterns/sqlalchemy.rst b/a/docs/patterns/sqlalchemy.rst @@ -34,8 +34,7 @@ official documentation on the `declarative`_ extension.\n Here's the example :file:`database.py` module for your application::\n \n     from sqlalchemy import create_engine\n-    from sqlalchemy.orm import scoped_session, sessionmaker\n-    from sqlalchemy.ext.declarative import declarative_base\n+    from sqlalchemy.orm import scoped_session, sessionmaker, declarative_base\n \n     engine = create_engine('sqlite:////tmp/test.db')\n     db_session = scoped_session(sessionmaker(autocommit=False,",
        "sim_diff_0": "diff --git a/packages/syft/src/syft/core/node/common/node.py b/packages/syft/src/syft/core/node/common/node.py @@ -110,7 +110,7 @@ class Node(AbstractNode):\nverify_key: Optional[VerifyKey] = None,\ndb_path: Optional[str] = None,\nTableBase: Any = None,\n- engine: Any = None,\n+ db_engine: Any = None,\ndb: Any = None,\n):\n@@ -132,14 +132,14 @@ class Node(AbstractNode):\nif db is None:\n# If a DB engine isn't provided then\n- if engine is None:\n+ if db_engine is None:\nengine = create_engine(\"sqlite://\", echo=False)\n- db = sessionmaker(bind=engine)()\n+ db = sessionmaker(bind=db_engine)()\n# cache these variables on self\nself.TableBase = TableBase\n- self.engine = engine\n+ self.db_engine = db_engine\nself.db = db\n# launch the tables in the database\n@@ -153,8 +153,9 @@ class Node(AbstractNode):\n# become quite numerous (or otherwise fill up RAM).\n# self.store is the elastic memory.\n+\nself.store = BinObjectManager(\n- db=self.db\n+ db=self.db_engine\n)\n# We need to register all the services once a node is created\n",
        "sim_msg_0": "RENAME engine -> db_engine",
        "sim_diff_1": "diff --git a/pajbot/managers/db.py b/pajbot/managers/db.py @@ -2,16 +2,38 @@ import logging\nfrom contextlib import contextmanager\nfrom sqlalchemy import create_engine\n+from sqlalchemy import event\n+from sqlalchemy import exc\nfrom sqlalchemy import inspect\nfrom sqlalchemy.ext.declarative import declarative_base\nfrom sqlalchemy.orm import scoped_session\nfrom sqlalchemy.orm import sessionmaker\n+from sqlalchemy.pool import Pool\nBase = declarative_base()\nlog = logging.getLogger('pajbot')\n+@event.listens_for(Pool, 'checkout')\n+def check_connection(dbapi_con, con_record, con_proxy):\n+ '''Listener for Pool checkout events that pings every connection before using.\n+ Implements pessimistic disconnect handling strategy. See also:\n+ http://docs.sqlalchemy.org/en/rel_0_8/core/pooling.html#disconnect-handling-pessimistic'''\n+\n+ cursor = dbapi_con.cursor()\n+ try:\n+ cursor.execute('SELECT 1')\n+ except exc.OperationalError as ex:\n+ if ex.args[0] in (2006, # MySQL server has gone away\n+ 2013, # Lost connection to MySQL server during query\n+ 2055): # Lost connection to MySQL server at '%s', system error: %d\n+ # caught by pool, which will retry with a new connection\n+ raise exc.DisconnectionError()\n+ else:\n+ raise\n+\n+\nclass DBManager:\ndef init(url):\nDBManager.engine = create_engine(url)\n",
        "sim_msg_1": "Add potential fix to database connections timing out",
        "sim_diff_2": "diff --git a/haystack/document_stores/sql.py b/haystack/document_stores/sql.py @@ -24,7 +24,7 @@ try:\nTypeDecorator,\n)\nfrom sqlalchemy.ext.declarative import declarative_base\n- from sqlalchemy.orm import relationship, sessionmaker\n+ from sqlalchemy.orm import relationship, sessionmaker, aliased\nfrom sqlalchemy.sql import case, null\nexcept (ImportError, ModuleNotFoundError) as ie:\nfrom haystack.utils.import_utils import _optional_component_not_installed\n@@ -688,7 +688,8 @@ class SQLDocumentStore(BaseDocumentStore):\nif ids:\ndocument_ids_to_delete = document_ids_to_delete.filter(DocumentORM.id.in_(ids))\n- self.session.query(DocumentORM).filter(DocumentORM.id.in_(document_ids_to_delete)).delete(\n+ inner_query = document_ids_to_delete.subquery()\n+ self.session.query(DocumentORM).filter(DocumentORM.id.in_(aliased(inner_query))).delete(\nsynchronize_session=False\n)\n@@ -736,7 +737,8 @@ class SQLDocumentStore(BaseDocumentStore):\nif ids:\nlabel_ids_to_delete = label_ids_to_delete.filter(LabelORM.id.in_(ids))\n- self.session.query(LabelORM).filter(LabelORM.id.in_(label_ids_to_delete)).delete(synchronize_session=False)\n+ inner_query = label_ids_to_delete.subquery()\n+ self.session.query(LabelORM).filter(LabelORM.id.in_(aliased(inner_query))).delete(synchronize_session=False)\nself.session.commit()\n",
        "sim_msg_2": "fix: add inner query for mysql compatibility",
        "sim_diff_3": "diff --git a/haystack/document_store/sql.py b/haystack/document_store/sql.py from typing import Any, Dict, Union, List, Optional\nfrom uuid import uuid4\n-from sqlalchemy import create_engine, Column, Integer, String, DateTime, func, ForeignKey, Boolean\n+from sqlalchemy import create_engine, Column, Integer, String, DateTime, func, ForeignKey, Boolean, Text\nfrom sqlalchemy.ext.declarative import declarative_base\nfrom sqlalchemy.orm import relationship, sessionmaker\nfrom sqlalchemy.sql import case\n@@ -16,7 +16,7 @@ Base = declarative_base() # type: Any\nclass ORMBase(Base):\n__abstract__ = True\n- id = Column(String, default=lambda: str(uuid4()), primary_key=True)\n+ id = Column(String(100), default=lambda: str(uuid4()), primary_key=True)\ncreated = Column(DateTime, server_default=func.now())\nupdated = Column(DateTime, server_default=func.now(), server_onupdate=func.now())\n@@ -24,19 +24,20 @@ class ORMBase(Base):\nclass DocumentORM(ORMBase):\n__tablename__ = \"document\"\n- text = Column(String, nullable=False)\n- index = Column(String, nullable=False)\n- vector_id = Column(String, unique=True, nullable=True)\n+ text = Column(Text, nullable=False)\n+ index = Column(String(100), nullable=False)\n+ vector_id = Column(String(100), unique=True, nullable=True)\n# speeds up queries for get_documents_by_vector_ids() by having a single query that returns joined metadata\nmeta = relationship(\"MetaORM\", backref=\"Document\", lazy=\"joined\")\n+\nclass MetaORM(ORMBase):\n__tablename__ = \"meta\"\n- name = Column(String, index=True)\n- value = Column(String, index=True)\n- document_id = Column(String, ForeignKey(\"document.id\", ondelete=\"CASCADE\"), nullable=False)\n+ name = Column(String(100), index=True)\n+ value = Column(String(1000), index=True)\n+ document_id = Column(String(100), ForeignKey(\"document.id\", ondelete=\"CASCADE\"), nullable=False)\ndocuments = relationship(DocumentORM, backref=\"Meta\")\n@@ -44,14 +45,14 @@ class MetaORM(ORMBase):\nclass LabelORM(ORMBase):\n__tablename__ = \"label\"\n- document_id = Column(String, ForeignKey(\"document.id\", ondelete=\"CASCADE\"), nullable=False)\n- index = Column(String, nullable=False)\n+ document_id = Column(String(100), ForeignKey(\"document.id\", ondelete=\"CASCADE\"), nullable=False)\n+ index = Column(String(100), nullable=False)\nno_answer = Column(Boolean, nullable=False)\n- origin = Column(String, nullable=False)\n- question = Column(String, nullable=False)\n+ origin = Column(String(100), nullable=False)\n+ question = Column(Text, nullable=False)\nis_correct_answer = Column(Boolean, nullable=False)\nis_correct_document = Column(Boolean, nullable=False)\n- answer = Column(String, nullable=False)\n+ answer = Column(Text, nullable=False)\noffset_start_in_doc = Column(Integer, nullable=False)\nmodel_id = Column(Integer, nullable=True)\n",
        "sim_msg_3": "Add support for MySQL database"
    },
    {
        "org_diff": "diff --git a/pyproject.toml b/a/pyproject.toml @@ -54,8 +54,8 @@ version = {attr = \"flask.__version__\"}\n testpaths = [\"tests\"]\n filterwarnings = [\n     \"error\",\n-    # change in Python 3.12 alpha causes warning from inside pytest\n-    \"ignore:onerror argument:DeprecationWarning\",\n+    # change in Python 3.12 causes warning from inside pytest\n+    \"ignore:ast:DeprecationWarning\",\n ]\n \n [tool.coverage.run]",
        "sim_diff_0": "diff --git a/pyproject.toml b/pyproject.toml @@ -59,7 +59,7 @@ float_to_top=true\npython_version = \"3.9\"\nfollow_imports = \"silent\"\nfiles = [\"reactivex\"]\n-exclude = [\"reactivex/core/operators\"]\n+exclude = [\"reactivex/operators/_\\\\w.*\\\\.py$\"]\n[tool.pytest.ini_options]\ntestpaths = [\"tests\"]\n",
        "sim_msg_0": "Exclude operators for mypy",
        "sim_diff_1": "diff --git a/pyproject.toml b/pyproject.toml @@ -46,18 +46,11 @@ pytest-cov = \"^2.5\"\npytest-runner = \"^4.2\"\nblack = { version = \"^18.3-alpha.0\", python = \"^3.6\" }\npre-commit = \"^1.12\"\n-tox = \"^3.5\"\n[build-system]\nrequires = [\"poetry>=0.12\"]\nbuild-backend = \"poetry.masonry.api\"\n-[tool.tox]\n-legacy_tox_ini = \"\"\"\n-[tox]\n-skipsdist = True\n-envlist = py356, py36, py37\n-\n[testenv]\nwhitelist_externals =\npoetry\n",
        "sim_msg_1": "Remove tox as a dependency",
        "sim_diff_2": "diff --git a/pyproject.toml b/pyproject.toml @@ -67,6 +67,8 @@ pytest-github-actions-annotate-failures = {version = \"*\", optional = true}\n[tool.poetry.dev-dependencies]\n# checks and make tools\n+pre-commit = \"^2.15.0\"\n+\ninvoke = \"*\"\nflake8 = \"*\"\nmypy = \"*\"\n@@ -91,7 +93,6 @@ pydata-sphinx-theme = \"*\"\nnbsphinx = \"*\"\npandoc = \"*\"\nrecommonmark = \"*\"\n-pre-commit = \"^2.15.0\"\n[tool.poetry.extras] # extras\n",
        "sim_msg_2": "random commit to trigger CI",
        "sim_diff_3": "diff --git a/pyproject.toml b/pyproject.toml @@ -58,17 +58,8 @@ float_to_top=true\n[tool.mypy]\npython_version = \"3.9\"\nfollow_imports = \"silent\"\n-files = [\n- \"rx/__init__.py\",\n- \"rx/core/abc\",\n- \"rx/core/observer\",\n- \"rx/core/observable\",\n- \"rx/disposable\",\n- \"rx/internal\",\n- \"rx/operators\",\n- \"rx/subject\",\n- \"rx/scheduler\"\n-]\n+files = [\"rx\"]\n+exclude = [\"rx/core/operators\"]\n[tool.pytest.ini_options]\ntestpaths = [\"tests\"]\n",
        "sim_msg_3": "Run mypy on all code except operators"
    },
    {
        "org_diff": "diff --git a/.pre-commit-config.yaml b/a/.pre-commit-config.yaml @@ -7,7 +7,7 @@ repos:\n     hooks:\n       - id: pyupgrade\n         args: [\"--py38-plus\"]\n-  - repo: https://github.com/asottile/reorder_python_imports\n+  - repo: https://github.com/asottile/reorder-python-imports\n     rev: v3.9.0\n     hooks:\n       - id: reorder-python-imports",
        "sim_diff_0": "diff --git a/.pre-commit-config.yaml b/.pre-commit-config.yaml @@ -20,7 +20,7 @@ repos:\nrev: v2.7.1\nhooks:\n- id: reorder-python-imports\n- args: [--add-import, 'from __future__ import annotations']\n+ args: [--py37-plus, --add-import, 'from __future__ import annotations']\n- repo: https://github.com/asottile/add-trailing-comma\nrev: v2.2.1\nhooks:\n",
        "sim_msg_0": "run reorder-python-imports with `--py37-plus`",
        "sim_diff_1": "diff --git a/.pre-commit-config.yaml b/.pre-commit-config.yaml @@ -5,7 +5,7 @@ repos:\n- id: black\nlanguage_version: python3\n- repo: https://github.com/pre-commit/mirrors-mypy\n- rev: v0.931\n+ rev: v0.941\nhooks:\n- id: mypy\nadditional_dependencies:\n@@ -36,6 +36,6 @@ repos:\n- id: shellcheck\nargs: [--exclude, SC1017]\n- repo: https://github.com/asottile/pyupgrade\n- rev: v2.31.0\n+ rev: v2.31.1\nhooks:\n- id: pyupgrade\n",
        "sim_msg_1": "Update pre-commit config: mypy, pyupgrade",
        "sim_diff_2": "diff --git a/.pre-commit-config.yaml b/.pre-commit-config.yaml @@ -6,6 +6,7 @@ repos:\n- id: debug-statements\n- id: mixed-line-ending\n- id: check-case-conflict\n+ - id: check-yaml\n- repo: https://github.com/asottile/reorder_python_imports\nrev: v2.1.0\nhooks:\n",
        "sim_msg_2": "Add pre-commit for check-yaml",
        "sim_diff_3": "diff --git a/.pre-commit-config.yaml b/.pre-commit-config.yaml @@ -22,7 +22,7 @@ repos:\nhooks:\n- id: isort\n- repo: https://github.com/asottile/pyupgrade\n- rev: v3.0.0\n+ rev: v3.2.0\nhooks:\n- id: pyupgrade\nargs: [--py36-plus]\n@@ -38,7 +38,7 @@ repos:\n- id: rst-inline-touching-normal\n- id: text-unicode-replacement-char\n- repo: https://github.com/psf/black\n- rev: 22.8.0\n+ rev: 22.10.0\nhooks:\n- id: black\nargs: [--safe, --quiet, --target-version=py36]\n",
        "sim_msg_3": "Upgrade pre-commit hook versions"
    },
    {
        "org_diff": "diff --git a/.pre-commit-config.yaml b/a/.pre-commit-config.yaml @@ -1,5 +1,5 @@\n ci:\n-  autoupdate_branch: \"2.2.x\"\n+  autoupdate_branch: \"2.3.x\"\n   autoupdate_schedule: monthly\n repos:\n   - repo: https://github.com/asottile/pyupgrade",
        "sim_diff_0": "diff --git a/.pre-commit-config.yaml b/.pre-commit-config.yaml @@ -5,7 +5,7 @@ default_language_version:\nrepos:\n- repo: https://github.com/psf/black\n- rev: 21.12b0\n+ rev: 22.1.0\nhooks:\n- id: black\n@@ -39,6 +39,6 @@ repos:\n- --ignore-init-module-imports\n- repo: https://github.com/pre-commit/mirrors-mypy\n- rev: v0.930\n+ rev: v0.931\nhooks:\n- id: mypy\n",
        "sim_msg_0": "Update black and mypy versions in pre-commit yaml",
        "sim_diff_1": "diff --git a/.pre-commit-config.yaml b/.pre-commit-config.yaml @@ -5,7 +5,7 @@ repos:\n- id: black\nlanguage_version: python3\n- repo: https://github.com/pre-commit/mirrors-mypy\n- rev: v0.931\n+ rev: v0.941\nhooks:\n- id: mypy\nadditional_dependencies:\n@@ -36,6 +36,6 @@ repos:\n- id: shellcheck\nargs: [--exclude, SC1017]\n- repo: https://github.com/asottile/pyupgrade\n- rev: v2.31.0\n+ rev: v2.31.1\nhooks:\n- id: pyupgrade\n",
        "sim_msg_1": "Update pre-commit config: mypy, pyupgrade",
        "sim_diff_2": "diff --git a/.pre-commit-config.yaml b/.pre-commit-config.yaml @@ -13,7 +13,7 @@ repos:\n- id: requirements-txt-fixer\n- id: trailing-whitespace\n- repo: https://github.com/psf/black\n- rev: 22.1.0\n+ rev: 22.3.0\nhooks:\n- id: black\n- repo: https://github.com/asottile/pyupgrade\n",
        "sim_msg_2": "fix black in pre-commit",
        "sim_diff_3": "diff --git a/.pre-commit-config.yaml b/.pre-commit-config.yaml @@ -17,7 +17,7 @@ repos:\nadditional_dependencies: [-e, 'git+git://github.com/pycqa/pyflakes.git@1911c20#egg=pyflakes']\n- repo: https://github.com/pre-commit/mirrors-mypy\n- rev: v0.790\n+ rev: v0.931\nhooks:\n- id: mypy\nargs: [--strict]\n",
        "sim_msg_3": ".pre-commit-config.yaml: bump mypy v0.790 -> v0.931"
    },
    {
        "org_diff": "diff --git a/.pre-commit-config.yaml b/a/.pre-commit-config.yaml @@ -1,5 +1,5 @@\n ci:\n-  autoupdate_branch: \"2.2.x\"\n+  autoupdate_branch: \"2.3.x\"\n   autoupdate_schedule: monthly\n repos:\n   - repo: https://github.com/asottile/pyupgrade",
        "sim_diff_0": "diff --git a/.pre-commit-config.yaml b/.pre-commit-config.yaml @@ -5,7 +5,7 @@ default_language_version:\nrepos:\n- repo: https://github.com/psf/black\n- rev: 21.12b0\n+ rev: 22.1.0\nhooks:\n- id: black\n@@ -39,6 +39,6 @@ repos:\n- --ignore-init-module-imports\n- repo: https://github.com/pre-commit/mirrors-mypy\n- rev: v0.930\n+ rev: v0.931\nhooks:\n- id: mypy\n",
        "sim_msg_0": "Update black and mypy versions in pre-commit yaml",
        "sim_diff_1": "diff --git a/.pre-commit-config.yaml b/.pre-commit-config.yaml @@ -5,7 +5,7 @@ repos:\n- id: black\nlanguage_version: python3\n- repo: https://github.com/pre-commit/mirrors-mypy\n- rev: v0.931\n+ rev: v0.941\nhooks:\n- id: mypy\nadditional_dependencies:\n@@ -36,6 +36,6 @@ repos:\n- id: shellcheck\nargs: [--exclude, SC1017]\n- repo: https://github.com/asottile/pyupgrade\n- rev: v2.31.0\n+ rev: v2.31.1\nhooks:\n- id: pyupgrade\n",
        "sim_msg_1": "Update pre-commit config: mypy, pyupgrade",
        "sim_diff_2": "diff --git a/.pre-commit-config.yaml b/.pre-commit-config.yaml @@ -13,7 +13,7 @@ repos:\n- id: requirements-txt-fixer\n- id: trailing-whitespace\n- repo: https://github.com/psf/black\n- rev: 22.1.0\n+ rev: 22.3.0\nhooks:\n- id: black\n- repo: https://github.com/asottile/pyupgrade\n",
        "sim_msg_2": "fix black in pre-commit",
        "sim_diff_3": "diff --git a/.pre-commit-config.yaml b/.pre-commit-config.yaml @@ -17,7 +17,7 @@ repos:\nadditional_dependencies: [-e, 'git+git://github.com/pycqa/pyflakes.git@1911c20#egg=pyflakes']\n- repo: https://github.com/pre-commit/mirrors-mypy\n- rev: v0.790\n+ rev: v0.931\nhooks:\n- id: mypy\nargs: [--strict]\n",
        "sim_msg_3": ".pre-commit-config.yaml: bump mypy v0.790 -> v0.931"
    },
    {
        "org_diff": "diff --git a/.github/workflows/publish.yaml b/a/.github/workflows/publish.yaml @@ -63,10 +63,10 @@ jobs:\n     steps:\n       - uses: actions/download-artifact@9bc31d5ccc31df68ecc42ccf4149144866c47d8a\n       # Try uploading to Test PyPI first, in case something fails.\n-      - uses: pypa/gh-action-pypi-publish@0bf742be3ebe032c25dd15117957dc15d0cfc38d\n+      - uses: pypa/gh-action-pypi-publish@a56da0b891b3dc519c7ee3284aff1fad93cc8598\n         with:\n           repository-url: https://test.pypi.org/legacy/\n           packages-dir: artifact/\n-      - uses: pypa/gh-action-pypi-publish@0bf742be3ebe032c25dd15117957dc15d0cfc38d\n+      - uses: pypa/gh-action-pypi-publish@a56da0b891b3dc519c7ee3284aff1fad93cc8598\n         with:\n           packages-dir: artifact/",
        "sim_diff_0": "diff --git a/.github/workflows/full-build.yml b/.github/workflows/full-build.yml @@ -397,7 +397,7 @@ jobs:\nname: Publish to PyPI (release only)\nneeds: [ linux-gtk4, linux-flatpak-devel, macos-gtk4, check-linux-appimage, check-macos-app, check-windows-installer ]\nruns-on: ubuntu-22.04\n- # if: github.event_name == 'release'\n+ if: github.event_name == 'release'\nsteps:\n- uses: actions/download-artifact@v3\nwith:\n@@ -410,4 +410,3 @@ jobs:\n- uses: pypa/gh-action-pypi-publish@release/v1\nwith:\npassword: ${{ secrets.PYPI_TOKEN }}\n- repository_url: https://test.pypi.org/legacy/\n",
        "sim_msg_0": "Change publish target for production",
        "sim_diff_1": "diff --git a/.github/workflows/pypi_upload.yml b/.github/workflows/pypi_upload.yml @@ -47,7 +47,7 @@ jobs:\n# to upload to test pypi, pass repository_url: https://test.pypi.org/legacy/ and use secrets.TEST_PYPI_TOKEN\n- name: Publish a Python distribution to PyPI\n- uses: pypa/gh-action-pypi-publish@master\n+ uses: pypa/gh-action-pypi-publish@release/v1\nwith:\nuser: __token__\npassword: ${{ secrets.PYPI_TOKEN }}\n",
        "sim_msg_1": "Update pypi release action.",
        "sim_diff_2": "diff --git a/.github/workflows/pypi_upload.yml b/.github/workflows/pypi_upload.yml @@ -54,8 +54,8 @@ jobs:\nuses: pypa/gh-action-pypi-publish@master\nwith:\nuser: __token__\n- password: ${{ secrets.TEST_PYPI_TOKEN }}\n- repository_url: https://test.pypi.org/legacy/\n+ password: ${{ secrets.PYPI_TOKEN }}\n+ # repository_url: https://test.pypi.org/legacy/\npackages_dir: dist/\n# git push https://${{ github.actor }}:${{ secrets.GITHUB_TOKEN }}@github.com/${{ github.repository }}.git HEAD:master\n",
        "sim_msg_2": "Switch automated release action to point at production pypi",
        "sim_diff_3": "diff --git a/.github/workflows/pypi_deploy.yml b/.github/workflows/pypi_deploy.yml name: Build and upload to PyPI\n-# Build on every branch push, tag push, and pull request change:\n-on: [push, pull_request]\n-# Alternatively, to publish when a (published) GitHub Release is created, use the following:\n-# on:\n-# push:\n-# pull_request:\n-# release:\n-# types:\n-# - published\n+on:\n+ release:\n+ types: [published]\njobs:\nbuild_wheels:\n@@ -65,10 +59,6 @@ jobs:\nupload_pypi:\nneeds: [build_wheels, build_sdist]\nruns-on: ubuntu-latest\n- # upload to PyPI on every tag starting with 'v'\n- # if: github.event_name == 'push' && startsWith(github.event.ref, 'refs/tags/v')\n- # alternatively, to publish when a GitHub Release is created, use the following rule:\n- # if: github.event_name == 'release' && github.event.action == 'published'\nsteps:\n- uses: actions/download-artifact@v2\nwith:\n",
        "sim_msg_3": "Run PyPI deploy workflow when releases are created."
    },
    {
        "org_diff": "diff --git a/.github/workflows/publish.yaml b/a/.github/workflows/publish.yaml @@ -33,7 +33,7 @@ jobs:\n       id-token: write\n       contents: write\n     # Can't pin with hash due to how this workflow works.\n-    uses: slsa-framework/slsa-github-generator/.github/workflows/generator_generic_slsa3.yml@v1.5.0\n+    uses: slsa-framework/slsa-github-generator/.github/workflows/generator_generic_slsa3.yml@v1.6.0\n     with:\n       base64-subjects: ${{ needs.build.outputs.hash }}\n   create-release:",
        "sim_diff_0": "diff --git a/.github/workflows/tag-actions.yml b/.github/workflows/tag-actions.yml @@ -10,6 +10,9 @@ jobs:\nname: Github Release\nruns-on: ubuntu-latest\n+ outputs:\n+ upload_url: ${{ steps.create_release.outputs.upload_url }}\n+\nsteps:\n- name: Create Release\nid: create_release\n@@ -125,7 +128,7 @@ jobs:\nenv:\nGITHUB_TOKEN: ${{ secrets.RELEASE_TOKEN }}\nwith:\n- upload_url: ${{ steps.create_release.outputs.upload_url }}\n+ upload_url: ${{ needs.github-release.outputs.upload_url }}\nasset_path: ./rpm/dist/beer-garden-${GITHUB_REF#refs/tags/}-1.el7.x86_64.rpm\nasset_name: beer-garden-${GITHUB_REF#refs/tags/}-1.el7.x86_64.rpm\nasset_content_type: application/octet-stream\n",
        "sim_msg_0": "Need to mark job output",
        "sim_diff_1": "diff --git a/.github/workflows/publish.yml b/.github/workflows/publish.yml @@ -2,7 +2,7 @@ name: publish\non:\npush:\n- branch:\n+ branches:\n- master\njobs:\n@@ -34,4 +34,4 @@ jobs:\nenv:\nPUBLISH_TARGET: ${{ secrets.PUBLISH_TARGET }}\nrun: |\n- rsync -azve \"ssh -o StrictHostKeyChecking=accept-new\" --delete build/anthology/ $PUBLISH_TARGET\n+ rsync -aze \"ssh -o StrictHostKeyChecking=accept-new\" --delete build/anthology/ $PUBLISH_TARGET\n",
        "sim_msg_1": "GH publish action: no verbose logging, only run on master\nSee PR",
        "sim_diff_2": "diff --git a/.github/workflows/release-drafter.yml b/.github/workflows/release-drafter.yml @@ -16,7 +16,7 @@ jobs:\nruns-on: ubuntu-latest\nsteps:\n- uses: release-drafter/release-drafter@v5\n- # with:\n- # disable-autolabeler: true\n+ with:\n+ disable-autolabeler: true\nenv:\nGITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n",
        "sim_msg_2": "explictly disable autolabeler for good measure",
        "sim_diff_3": "diff --git a/.github/workflows/release-drafter.yml b/.github/workflows/release-drafter.yml @@ -15,8 +15,20 @@ jobs:\ncontents: write\nruns-on: ubuntu-latest\nsteps:\n- - uses: release-drafter/release-drafter@v5\n+ - name: Run release-drafter action\n+ id: release-drafter\n+ uses: release-drafter/release-drafter@v5\nwith:\ndisable-autolabeler: true\nenv:\nGITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n+\n+ - name: Adding markdown\n+ run: |\n+ cat <<MKDOWN\n+ ### Release Drafter :rocket:\n+\n+ * **Draft Release URL**:\n+ [${{ steps.release-drafter.outputs.name }} (${{ steps.release-drafter.outputs.id }})](${{ steps.release-drafter.outputs.html_url }})\n+ * **Tag Name**: ${{ steps.release-drafter.outputs.tag_name }}\n+ MKDOWN >> $GITHUB_STEP_SUMMARY\n",
        "sim_msg_3": "Output release-drafter workflow summary"
    },
    {
        "org_diff": "diff --git a/.github/workflows/publish.yaml b/a/.github/workflows/publish.yaml @@ -63,10 +63,10 @@ jobs:\n     steps:\n       - uses: actions/download-artifact@9bc31d5ccc31df68ecc42ccf4149144866c47d8a\n       # Try uploading to Test PyPI first, in case something fails.\n-      - uses: pypa/gh-action-pypi-publish@0bf742be3ebe032c25dd15117957dc15d0cfc38d\n+      - uses: pypa/gh-action-pypi-publish@a56da0b891b3dc519c7ee3284aff1fad93cc8598\n         with:\n           repository-url: https://test.pypi.org/legacy/\n           packages-dir: artifact/\n-      - uses: pypa/gh-action-pypi-publish@0bf742be3ebe032c25dd15117957dc15d0cfc38d\n+      - uses: pypa/gh-action-pypi-publish@a56da0b891b3dc519c7ee3284aff1fad93cc8598\n         with:\n           packages-dir: artifact/",
        "sim_diff_0": "diff --git a/.github/workflows/full-build.yml b/.github/workflows/full-build.yml @@ -397,7 +397,7 @@ jobs:\nname: Publish to PyPI (release only)\nneeds: [ linux-gtk4, linux-flatpak-devel, macos-gtk4, check-linux-appimage, check-macos-app, check-windows-installer ]\nruns-on: ubuntu-22.04\n- # if: github.event_name == 'release'\n+ if: github.event_name == 'release'\nsteps:\n- uses: actions/download-artifact@v3\nwith:\n@@ -410,4 +410,3 @@ jobs:\n- uses: pypa/gh-action-pypi-publish@release/v1\nwith:\npassword: ${{ secrets.PYPI_TOKEN }}\n- repository_url: https://test.pypi.org/legacy/\n",
        "sim_msg_0": "Change publish target for production",
        "sim_diff_1": "diff --git a/.github/workflows/pypi_upload.yml b/.github/workflows/pypi_upload.yml @@ -47,7 +47,7 @@ jobs:\n# to upload to test pypi, pass repository_url: https://test.pypi.org/legacy/ and use secrets.TEST_PYPI_TOKEN\n- name: Publish a Python distribution to PyPI\n- uses: pypa/gh-action-pypi-publish@master\n+ uses: pypa/gh-action-pypi-publish@release/v1\nwith:\nuser: __token__\npassword: ${{ secrets.PYPI_TOKEN }}\n",
        "sim_msg_1": "Update pypi release action.",
        "sim_diff_2": "diff --git a/.github/workflows/pypi_upload.yml b/.github/workflows/pypi_upload.yml @@ -54,8 +54,8 @@ jobs:\nuses: pypa/gh-action-pypi-publish@master\nwith:\nuser: __token__\n- password: ${{ secrets.TEST_PYPI_TOKEN }}\n- repository_url: https://test.pypi.org/legacy/\n+ password: ${{ secrets.PYPI_TOKEN }}\n+ # repository_url: https://test.pypi.org/legacy/\npackages_dir: dist/\n# git push https://${{ github.actor }}:${{ secrets.GITHUB_TOKEN }}@github.com/${{ github.repository }}.git HEAD:master\n",
        "sim_msg_2": "Switch automated release action to point at production pypi",
        "sim_diff_3": "diff --git a/.github/workflows/pypi_deploy.yml b/.github/workflows/pypi_deploy.yml name: Build and upload to PyPI\n-# Build on every branch push, tag push, and pull request change:\n-on: [push, pull_request]\n-# Alternatively, to publish when a (published) GitHub Release is created, use the following:\n-# on:\n-# push:\n-# pull_request:\n-# release:\n-# types:\n-# - published\n+on:\n+ release:\n+ types: [published]\njobs:\nbuild_wheels:\n@@ -65,10 +59,6 @@ jobs:\nupload_pypi:\nneeds: [build_wheels, build_sdist]\nruns-on: ubuntu-latest\n- # upload to PyPI on every tag starting with 'v'\n- # if: github.event_name == 'push' && startsWith(github.event.ref, 'refs/tags/v')\n- # alternatively, to publish when a GitHub Release is created, use the following rule:\n- # if: github.event_name == 'release' && github.event.action == 'published'\nsteps:\n- uses: actions/download-artifact@v2\nwith:\n",
        "sim_msg_3": "Run PyPI deploy workflow when releases are created."
    },
    {
        "org_diff": "diff --git a/.github/workflows/publish.yaml b/a/.github/workflows/publish.yaml @@ -33,7 +33,7 @@ jobs:\n       id-token: write\n       contents: write\n     # Can't pin with hash due to how this workflow works.\n-    uses: slsa-framework/slsa-github-generator/.github/workflows/generator_generic_slsa3.yml@v1.5.0\n+    uses: slsa-framework/slsa-github-generator/.github/workflows/generator_generic_slsa3.yml@v1.6.0\n     with:\n       base64-subjects: ${{ needs.build.outputs.hash }}\n   create-release:",
        "sim_diff_0": "diff --git a/.github/workflows/tag-actions.yml b/.github/workflows/tag-actions.yml @@ -10,6 +10,9 @@ jobs:\nname: Github Release\nruns-on: ubuntu-latest\n+ outputs:\n+ upload_url: ${{ steps.create_release.outputs.upload_url }}\n+\nsteps:\n- name: Create Release\nid: create_release\n@@ -125,7 +128,7 @@ jobs:\nenv:\nGITHUB_TOKEN: ${{ secrets.RELEASE_TOKEN }}\nwith:\n- upload_url: ${{ steps.create_release.outputs.upload_url }}\n+ upload_url: ${{ needs.github-release.outputs.upload_url }}\nasset_path: ./rpm/dist/beer-garden-${GITHUB_REF#refs/tags/}-1.el7.x86_64.rpm\nasset_name: beer-garden-${GITHUB_REF#refs/tags/}-1.el7.x86_64.rpm\nasset_content_type: application/octet-stream\n",
        "sim_msg_0": "Need to mark job output",
        "sim_diff_1": "diff --git a/.github/workflows/publish.yml b/.github/workflows/publish.yml @@ -2,7 +2,7 @@ name: publish\non:\npush:\n- branch:\n+ branches:\n- master\njobs:\n@@ -34,4 +34,4 @@ jobs:\nenv:\nPUBLISH_TARGET: ${{ secrets.PUBLISH_TARGET }}\nrun: |\n- rsync -azve \"ssh -o StrictHostKeyChecking=accept-new\" --delete build/anthology/ $PUBLISH_TARGET\n+ rsync -aze \"ssh -o StrictHostKeyChecking=accept-new\" --delete build/anthology/ $PUBLISH_TARGET\n",
        "sim_msg_1": "GH publish action: no verbose logging, only run on master\nSee PR",
        "sim_diff_2": "diff --git a/.github/workflows/release-drafter.yml b/.github/workflows/release-drafter.yml @@ -16,7 +16,7 @@ jobs:\nruns-on: ubuntu-latest\nsteps:\n- uses: release-drafter/release-drafter@v5\n- # with:\n- # disable-autolabeler: true\n+ with:\n+ disable-autolabeler: true\nenv:\nGITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n",
        "sim_msg_2": "explictly disable autolabeler for good measure",
        "sim_diff_3": "diff --git a/.github/workflows/release-drafter.yml b/.github/workflows/release-drafter.yml @@ -15,8 +15,20 @@ jobs:\ncontents: write\nruns-on: ubuntu-latest\nsteps:\n- - uses: release-drafter/release-drafter@v5\n+ - name: Run release-drafter action\n+ id: release-drafter\n+ uses: release-drafter/release-drafter@v5\nwith:\ndisable-autolabeler: true\nenv:\nGITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n+\n+ - name: Adding markdown\n+ run: |\n+ cat <<MKDOWN\n+ ### Release Drafter :rocket:\n+\n+ * **Draft Release URL**:\n+ [${{ steps.release-drafter.outputs.name }} (${{ steps.release-drafter.outputs.id }})](${{ steps.release-drafter.outputs.html_url }})\n+ * **Tag Name**: ${{ steps.release-drafter.outputs.tag_name }}\n+ MKDOWN >> $GITHUB_STEP_SUMMARY\n",
        "sim_msg_3": "Output release-drafter workflow summary"
    },
    {
        "org_diff": "diff --git a/pyproject.toml b/a/pyproject.toml @@ -4,7 +4,6 @@ description = \"A simple framework for building complex web applications.\"\n readme = \"README.rst\"\n license = {text = \"BSD-3-Clause\"}\n maintainers = [{name = \"Pallets\", email = \"contact@palletsprojects.com\"}]\n-authors = [{name = \"Armin Ronacher\", email = \"armin.ronacher@active-4.com\"}]\n classifiers = [\n     \"Development Status :: 5 - Production/Stable\",\n     \"Environment :: Web Environment\",",
        "sim_diff_0": "diff --git a/pyproject.toml b/pyproject.toml @@ -14,7 +14,9 @@ classifiers = [\n\"Programming Language :: Python :: 3.7\",\n]\npackages = [\n- { include = \"astral\", from = \"src\"}\n+ { include = \"astral\", from = \"src\"},\n+ { include = \"doc\", from = \"src\", format = \"sdist\"},\n+ { include = \"test\", from = \"src\", format = \"sdist\"},\n]\n[tool.poetry.dependencies]\n",
        "sim_msg_0": "Added doc and test source to sdist",
        "sim_diff_1": "diff --git a/pyproject.toml b/pyproject.toml @@ -21,6 +21,7 @@ classifiers = [\n\"Intended Audience :: Developers\",\n\"Intended Audience :: End Users/Desktop\",\n\"Intended Audience :: Information Technology\",\n+ \"License :: OSI Approved :: Apache Software License\",\n\"Operating System :: MacOS :: MacOS X\",\n\"Operating System :: Microsoft :: Windows\",\n\"Operating System :: POSIX\",\n@@ -28,7 +29,6 @@ classifiers = [\n\"Programming Language :: Python\",\n\"Topic :: Multimedia :: Graphics :: Editors :: Vector-Based\",\n\"Topic :: Software Development :: Documentation\",\n- \"License :: OSI Approved :: Apache Software License\",\n]\n[tool.poetry.dependencies]\n",
        "sim_msg_1": "Undo change to pyproject.toml",
        "sim_diff_2": "diff --git a/pyproject.toml b/pyproject.toml @@ -14,6 +14,8 @@ classifiers = [\n\"Programming Language :: Python :: 3.6\",\n\"Programming Language :: Python :: 3.7\",\n\"Programming Language :: Python :: 3.8\",\n+ \"Programming Language :: Python :: 3.9\",\n+ \"Programming Language :: Python :: 3.10\",\n]\npackages = [\n{ include = \"astral\", from = \"src\"},\n",
        "sim_msg_2": "Also supports Python 3.9 and 3.10",
        "sim_diff_3": "diff --git a/pyproject.toml b/pyproject.toml @@ -9,7 +9,7 @@ authors = [\nreadme = \"README.md\"\n-homepage = \"https://gaphor.readthedocs.io/\"\n+homepage = \"https://gaphor.org/\"\nrepository = \"https://github.com/gaphor/gaphor\"\ndocumentation = \"https://gaphor.readthedocs.io/\"\n",
        "sim_msg_3": "Update homepage to gaphor.org"
    },
    {
        "org_diff": "diff --git a/docs/config.rst b/a/docs/config.rst @@ -410,8 +410,8 @@ from a TOML file:\n \n .. code-block:: python\n \n-    import toml\n-    app.config.from_file(\"config.toml\", load=toml.load)\n+    import tomllib\n+    app.config.from_file(\"config.toml\", load=tomllib.load, text=False)\n \n Or from a JSON file:\n ",
        "sim_diff_0": "diff --git a/docs/conf.py b/docs/conf.py # import os\n# import sys\n# sys.path.insert(0, os.path.abspath('.'))\n+from pathlib import Path\n+\nfrom tomlkit import parse\n# -- Project information -----------------------------------------------------\n@@ -25,10 +27,9 @@ author = \"Arjan J. Molenaar\"\n# The short X.Y version\nversion = \"\"\n-with open(\"../pyproject.toml\", \"r\") as f:\n- parsed_toml = parse(f.read())\n- # The full version, including alpha/beta/rc tags.\n- release = parsed_toml[\"tool\"][\"poetry\"][\"version\"]\n+project_dir = Path(__file__).resolve().parent.parent\n+f = project_dir.joinpath(\"pyproject.toml\")\n+release = parse(f.read_text())[\"tool\"][\"poetry\"][\"version\"]\n# -- General configuration ---------------------------------------------------\n",
        "sim_msg_0": "Fix relative path to pyproject.toml is not found",
        "sim_diff_1": "diff --git a/docs/conf.py b/docs/conf.py @@ -151,10 +151,11 @@ def metadata_to_rst(app):\ndef static_dfs_to_rst(app):\n\"\"\"Export static code labeling dataframes to RST for inclusion in the documentation.\"\"\"\n- csv_dir = DOCS_DIR / \"data_dictionaries/code_csvs\"\n- csv_dir.mkdir(parents=True, exist_ok=True)\n+ abs_csv_dir = DOCS_DIR / \"data_dictionaries/code_csvs\"\n+ abs_csv_dir.mkdir(parents=True, exist_ok=True)\n+ rel_csv_dir = Path(\"code_csvs\")\ncodemetadata = CodeMetadata.from_code_ids(sorted(CODE_METADATA.keys()))\n- codemetadata.to_rst(csv_dir=csv_dir, path=DOCS_DIR / \"data_dictionaries/codes_and_labels.rst\")\n+ codemetadata.to_rst(csv_dir=rel_csv_dir, path=DOCS_DIR / \"data_dictionaries/codes_and_labels.rst\")\ndef cleanup_rsts(app, exception):\n",
        "sim_msg_1": "changed absolute csv path to relative path",
        "sim_diff_2": "diff --git a/docs/conf.py b/docs/conf.py @@ -151,11 +151,10 @@ def metadata_to_rst(app):\ndef static_dfs_to_rst(app):\n\"\"\"Export static code labeling dataframes to RST for inclusion in the documentation.\"\"\"\n- abs_csv_dir = DOCS_DIR / \"data_dictionaries/code_csvs\"\n- abs_csv_dir.mkdir(parents=True, exist_ok=True)\n- rel_csv_dir = Path(\"code_csvs\")\n+ csv_dir = DOCS_DIR / \"data_dictionaries/code_csvs\"\n+ csv_dir.mkdir(parents=True, exist_ok=True)\ncodemetadata = CodeMetadata.from_code_ids(sorted(CODE_METADATA.keys()))\n- codemetadata.to_rst(csv_dir=rel_csv_dir, path=DOCS_DIR / \"data_dictionaries/codes_and_labels.rst\")\n+ codemetadata.to_rst(csv_dir=csv_dir, path=DOCS_DIR / \"data_dictionaries/codes_and_labels.rst\")\ndef cleanup_rsts(app, exception):\n@@ -177,4 +176,4 @@ def setup(app):\napp.connect(\"builder-inited\", metadata_to_rst)\napp.connect(\"builder-inited\", static_dfs_to_rst)\napp.connect(\"build-finished\", cleanup_rsts)\n- app.connect(\"build-finished\", cleanup_csv_dir)\n+ # app.connect(\"build-finished\", cleanup_csv_dir)\n",
        "sim_msg_2": "relative path didnt work, trying removing the cleanup step",
        "sim_diff_3": "diff --git a/pyproject.toml b/pyproject.toml @@ -100,6 +100,7 @@ types-aiofiles = \"^0.1.9\"\ntypes-pkg-resources = \"^0.1.3\"\ntypes-requests = \"^2.25.9\"\ntypes-toml = \"^0.10.0\"\n+types-dataclasses = { version = \"^0.1.7\", markers = \"python_version < '3.7'\" }\n# Documantation\nmkdocs = \"^1.2.2\"\n",
        "sim_msg_3": "add types-dataclasses for python 3.6"
    },
    {
        "org_diff": "diff --git a/docs/config.rst b/a/docs/config.rst @@ -410,8 +410,8 @@ from a TOML file:\n \n .. code-block:: python\n \n-    import toml\n-    app.config.from_file(\"config.toml\", load=toml.load)\n+    import tomllib\n+    app.config.from_file(\"config.toml\", load=tomllib.load, text=False)\n \n Or from a JSON file:\n ",
        "sim_diff_0": "diff --git a/docs/conf.py b/docs/conf.py # import os\n# import sys\n# sys.path.insert(0, os.path.abspath('.'))\n+from pathlib import Path\n+\nfrom tomlkit import parse\n# -- Project information -----------------------------------------------------\n@@ -25,10 +27,9 @@ author = \"Arjan J. Molenaar\"\n# The short X.Y version\nversion = \"\"\n-with open(\"../pyproject.toml\", \"r\") as f:\n- parsed_toml = parse(f.read())\n- # The full version, including alpha/beta/rc tags.\n- release = parsed_toml[\"tool\"][\"poetry\"][\"version\"]\n+project_dir = Path(__file__).resolve().parent.parent\n+f = project_dir.joinpath(\"pyproject.toml\")\n+release = parse(f.read_text())[\"tool\"][\"poetry\"][\"version\"]\n# -- General configuration ---------------------------------------------------\n",
        "sim_msg_0": "Fix relative path to pyproject.toml is not found",
        "sim_diff_1": "diff --git a/docs/conf.py b/docs/conf.py @@ -151,10 +151,11 @@ def metadata_to_rst(app):\ndef static_dfs_to_rst(app):\n\"\"\"Export static code labeling dataframes to RST for inclusion in the documentation.\"\"\"\n- csv_dir = DOCS_DIR / \"data_dictionaries/code_csvs\"\n- csv_dir.mkdir(parents=True, exist_ok=True)\n+ abs_csv_dir = DOCS_DIR / \"data_dictionaries/code_csvs\"\n+ abs_csv_dir.mkdir(parents=True, exist_ok=True)\n+ rel_csv_dir = Path(\"code_csvs\")\ncodemetadata = CodeMetadata.from_code_ids(sorted(CODE_METADATA.keys()))\n- codemetadata.to_rst(csv_dir=csv_dir, path=DOCS_DIR / \"data_dictionaries/codes_and_labels.rst\")\n+ codemetadata.to_rst(csv_dir=rel_csv_dir, path=DOCS_DIR / \"data_dictionaries/codes_and_labels.rst\")\ndef cleanup_rsts(app, exception):\n",
        "sim_msg_1": "changed absolute csv path to relative path",
        "sim_diff_2": "diff --git a/docs/conf.py b/docs/conf.py @@ -151,11 +151,10 @@ def metadata_to_rst(app):\ndef static_dfs_to_rst(app):\n\"\"\"Export static code labeling dataframes to RST for inclusion in the documentation.\"\"\"\n- abs_csv_dir = DOCS_DIR / \"data_dictionaries/code_csvs\"\n- abs_csv_dir.mkdir(parents=True, exist_ok=True)\n- rel_csv_dir = Path(\"code_csvs\")\n+ csv_dir = DOCS_DIR / \"data_dictionaries/code_csvs\"\n+ csv_dir.mkdir(parents=True, exist_ok=True)\ncodemetadata = CodeMetadata.from_code_ids(sorted(CODE_METADATA.keys()))\n- codemetadata.to_rst(csv_dir=rel_csv_dir, path=DOCS_DIR / \"data_dictionaries/codes_and_labels.rst\")\n+ codemetadata.to_rst(csv_dir=csv_dir, path=DOCS_DIR / \"data_dictionaries/codes_and_labels.rst\")\ndef cleanup_rsts(app, exception):\n@@ -177,4 +176,4 @@ def setup(app):\napp.connect(\"builder-inited\", metadata_to_rst)\napp.connect(\"builder-inited\", static_dfs_to_rst)\napp.connect(\"build-finished\", cleanup_rsts)\n- app.connect(\"build-finished\", cleanup_csv_dir)\n+ # app.connect(\"build-finished\", cleanup_csv_dir)\n",
        "sim_msg_2": "relative path didnt work, trying removing the cleanup step",
        "sim_diff_3": "diff --git a/pyproject.toml b/pyproject.toml @@ -100,6 +100,7 @@ types-aiofiles = \"^0.1.9\"\ntypes-pkg-resources = \"^0.1.3\"\ntypes-requests = \"^2.25.9\"\ntypes-toml = \"^0.10.0\"\n+types-dataclasses = { version = \"^0.1.7\", markers = \"python_version < '3.7'\" }\n# Documantation\nmkdocs = \"^1.2.2\"\n",
        "sim_msg_3": "add types-dataclasses for python 3.6"
    },
    {
        "org_diff": "diff --git a/docs/patterns/javascript.rst b/a/docs/patterns/javascript.rst @@ -125,8 +125,8 @@ in a Flask view.\n .. code-block:: javascript\n \n     let data = new FormData()\n-    data.append(\"name\": \"Flask Room\")\n-    data.append(\"description\": \"Talk about Flask here.\")\n+    data.append(\"name\", \"Flask Room\")\n+    data.append(\"description\", \"Talk about Flask here.\")\n     fetch(room_url, {\n         \"method\": \"POST\",\n         \"body\": data,",
        "sim_diff_0": "diff --git a/app/views/api.py b/app/views/api.py @@ -6,7 +6,7 @@ Some rules we should follow:\n\"\"\"\nfrom datetime import datetime, timedelta\n-from flask import Blueprint, jsonify, request, render_template, g\n+from flask import Blueprint, jsonify, request, render_template, g, send_file\nfrom flask_login import login_required, current_user\nfrom flask_oauthlib.provider import OAuth2Provider\nfrom .. import misc, sorting\n@@ -435,7 +435,7 @@ def whoamiv2():\n@api.route('/api/paint/canvas')\ndef getCanvas():\npixels = db.query('SELECT * FROM `pixel`').fetchall()\n- final = ''\n+ final = b''\nfor pixel in pixels:\nfinal += bytes([pixel['posy'],\n@@ -443,4 +443,4 @@ def getCanvas():\npixel['color'],\npixel['value'], 0])\n- return final\n+ return send_file(final, mimetype='application/octet-stream')\n",
        "sim_msg_0": "Prettily returning thingy with mime type and stuff",
        "sim_diff_1": "diff --git a/docs/patterns/errorpages.rst b/docs/patterns/errorpages.rst @@ -97,3 +97,30 @@ An example template might be this:\n<p>What you were looking for is just not there.\n<p><a href=\"{{ url_for('index') }}\">go somewhere nice</a>\n{% endblock %}\n+\n+\n+Handling API Errors with Abort\n+------------------------------\n+\n+When using Flask for web APIs, handling errors is as simple as the previous examples but with minor changes.\n+\n+Register the error handler::\n+\n+ from flask import jsonify\n+\n+ @app.errorhandler(404)\n+ def resource_not_found(e):\n+ # if passing in an Exception object directly, you may need to convert it to a string\n+ return jsonify(error=str(e)), 404\n+\n+To use this error handler::\n+\n+ @app.route('/cheese', methods=['GET'])\n+ def get_one_cheese():\n+ # logic to find your resource\n+ if (resource is None):\n+ abort(404, 'Resource not found')\n+ else:\n+ return jsonify(resource=resource)\n+\n+In the above example, the error handler is invoked with the second argument passed to it. It returns the json message with the response.\n\\ No newline at end of file\n",
        "sim_msg_1": "adds api error handling documentation",
        "sim_diff_2": "diff --git a/app/views/api.py b/app/views/api.py @@ -6,7 +6,8 @@ Some rules we should follow:\n\"\"\"\nfrom datetime import datetime, timedelta\n-from flask import Blueprint, jsonify, request, render_template, g\n+from flask import Blueprint, jsonify, request, render_template, g, current_app\n+from flask.sessions import SecureCookieSessionInterface\nfrom flask_login import login_required, current_user\nfrom flask_oauthlib.provider import OAuth2Provider\nfrom .. import misc\n@@ -181,6 +182,16 @@ def me():\nreturn jsonify(email=user['email'], username=user['name'], uid=user['uid'])\n+@api.route('/api/getToken')\n+@oauth.require_oauth('interact')\n+def get_socket_session():\n+ \"\"\" Returns basic user info \"\"\"\n+ user = request.oauth.user\n+ session_serializer = SecureCookieSessionInterface().get_signing_serializer(current_app)\n+\n+ return jsonify(token=session_serializer.dumps({'uid': user['uid']}))\n+\n+\n@api.route('/oauth/token', methods=['GET', 'POST'])\n@oauth.token_handler\ndef token_thingy():\n",
        "sim_msg_2": "Adding an oauth endpoint to request a session cookie",
        "sim_diff_3": "diff --git a/app/views/do.py b/app/views/do.py @@ -8,6 +8,7 @@ import uuid\nimport bcrypt\nimport requests\nfrom bs4 import BeautifulSoup\n+from urllib.parse import urlparse\nfrom flask import Blueprint, redirect, url_for, session, abort, jsonify\nfrom flask import render_template, request\nfrom flask_login import login_user, login_required, logout_user, current_user\n@@ -576,7 +577,7 @@ def grab_title():\n@login_required\n@misc.ratelimit(1, per=30, key_func=lambda: 'post')\ndef create_lnkpost():\n- \"\"\" Sub text post creation endpoint \"\"\"\n+ \"\"\" Sub link post creation endpoint \"\"\"\nif misc.get_user_level(current_user.uid)[0] <= 5:\nform = CaptchaForm()\nif not form.validate():\n@@ -601,6 +602,15 @@ def create_lnkpost():\nif l:\nreturn jsonify(status='error', error=['This link was recently '\n'posted on this sub.'])\n+ bans = db.uquery('SELECT `value` FROM `site_metadata` WHERE `key`=%s',\n+ ('banned_domain',)).fetchall()\n+ ben = []\n+ for i in bans:\n+ ben.append(i['value'])\n+ url = urlparse(form.link.data)\n+ if url.netloc in ben:\n+ return jsonify(status='error', error=['This domain is banned'])\n+\nimg = misc.get_thumbnail(form)\npost = db.create_post(sid=sub['sid'],\nuid=current_user.uid,\n",
        "sim_msg_3": "apply domain filter to submitted links"
    },
    {
        "org_diff": "diff --git a/src/flask/config.py b/a/src/flask/config.py @@ -72,7 +72,9 @@ class Config(dict):\n     :param defaults: an optional dictionary of default values\n     \"\"\"\n \n-    def __init__(self, root_path: str, defaults: dict | None = None) -> None:\n+    def __init__(\n+        self, root_path: str | os.PathLike, defaults: dict | None = None\n+    ) -> None:\n         super().__init__(defaults or {})\n         self.root_path = root_path\n \n@@ -164,7 +166,7 @@ def from_prefixed_env(\n \n         return True\n \n-    def from_pyfile(self, filename: str, silent: bool = False) -> bool:\n+    def from_pyfile(self, filename: str | os.PathLike, silent: bool = False) -> bool:\n         \"\"\"Updates the values in the config from a Python file.  This function\n         behaves as if the file was imported as module with the\n         :meth:`from_object` function.\n@@ -233,7 +235,7 @@ class and has ``@property`` attributes, it needs to be\n \n     def from_file(\n         self,\n-        filename: str,\n+        filename: str | os.PathLike,\n         load: t.Callable[[t.IO[t.Any]], t.Mapping],\n         silent: bool = False,\n         text: bool = True,",
        "sim_diff_0": "diff --git a/src/flask/config.py b/src/flask/config.py @@ -275,8 +275,9 @@ class Config(dict):\ndef from_mapping(\nself, mapping: t.Optional[t.Mapping[str, t.Any]] = None, **kwargs: t.Any\n) -> bool:\n- \"\"\"Updates the config like :meth:`update` ignoring items with non-upper\n- keys.\n+ \"\"\"Updates the config like :meth:`update` ignoring items with\n+ non-upper keys.\n+\n:return: Always returns ``True``.\n.. versionadded:: 0.11\n",
        "sim_msg_0": "Fix misrendered docstring\nThe API reference for `flask.Config.from_mapping` needs a newline to separate\nthe summary from the return description.  I also wrapped the docstring at 72\ncharacters as suggested in CONTRIBUTING.rst.",
        "sim_diff_1": "diff --git a/src/flask/app.py b/src/flask/app.py @@ -960,17 +960,24 @@ class Flask(_PackageBoundObject):\nif debug is not None:\nself.debug = bool(debug)\n- _host = \"127.0.0.1\"\n- _port = 5000\nserver_name = self.config.get(\"SERVER_NAME\")\n- sn_host, sn_port = None, None\n+ sn_host = sn_port = None\nif server_name:\nsn_host, _, sn_port = server_name.partition(\":\")\n- host = host or sn_host or _host\n- # pick the first value that's not None (0 is allowed)\n- port = int(next((p for p in (port, sn_port) if p is not None), _port))\n+ if not host:\n+ if sn_host:\n+ host = sn_host\n+ else:\n+ host = \"127.0.0.1\"\n+\n+ if port or port == 0:\n+ port = int(port)\n+ elif sn_port:\n+ port = int(sn_port)\n+ else:\n+ port = 5000\noptions.setdefault(\"use_reloader\", self.debug)\noptions.setdefault(\"use_debugger\", self.debug)\n@@ -2146,11 +2153,11 @@ class Flask(_PackageBoundObject):\n# If subdomain matching is disabled (the default), use the\n# default subdomain in all cases. This should be the default\n# in Werkzeug but it currently does not have that feature.\n- subdomain = (\n- (self.url_map.default_subdomain or None)\n- if not self.subdomain_matching\n- else None\n- )\n+ if not self.subdomain_matching:\n+ subdomain = self.url_map.default_subdomain or None\n+ else:\n+ subdomain = None\n+\nreturn self.url_map.bind_to_environ(\nrequest.environ,\nserver_name=self.config[\"SERVER_NAME\"],\n",
        "sim_msg_1": "refactor variable choices into if blocks",
        "sim_diff_2": "diff --git a/src/flask/config.py b/src/flask/config.py @@ -218,7 +218,7 @@ class Config(dict):\nabsolute path or relative to the config root path.\n:param silent: Ignore the file if it doesn't exist.\n- .. deprecated:: 1.2\n+ .. deprecated:: 2.0\nUse :meth:`from_file` with :meth:`json.load` instead.\n.. versionadded:: 0.11\n",
        "sim_msg_2": "Update deprecated for config.from_json",
        "sim_diff_3": "diff --git a/app/config.py b/app/config.py @@ -57,7 +57,7 @@ cfg_defaults = { # key => default value\n\"trusted_proxy_count\": 0,\n\"custom_hot_sort\": False,\n\"recent_activity\": {\n- \"enabled\": True,\n+ \"enabled\": False, # TODO: Address performance issues\n\"defaults_only\": False,\n\"comments_only\": False,\n\"max_entries\": 10,\n",
        "sim_msg_3": "Disabling recent activity in the sidebar by default until we address the performance issues"
    },
    {
        "org_diff": "diff --git a/src/flask/config.py b/a/src/flask/config.py @@ -72,7 +72,9 @@ class Config(dict):\n     :param defaults: an optional dictionary of default values\n     \"\"\"\n \n-    def __init__(self, root_path: str, defaults: dict | None = None) -> None:\n+    def __init__(\n+        self, root_path: str | os.PathLike, defaults: dict | None = None\n+    ) -> None:\n         super().__init__(defaults or {})\n         self.root_path = root_path\n \n@@ -164,7 +166,7 @@ def from_prefixed_env(\n \n         return True\n \n-    def from_pyfile(self, filename: str, silent: bool = False) -> bool:\n+    def from_pyfile(self, filename: str | os.PathLike, silent: bool = False) -> bool:\n         \"\"\"Updates the values in the config from a Python file.  This function\n         behaves as if the file was imported as module with the\n         :meth:`from_object` function.\n@@ -233,7 +235,7 @@ class and has ``@property`` attributes, it needs to be\n \n     def from_file(\n         self,\n-        filename: str,\n+        filename: str | os.PathLike,\n         load: t.Callable[[t.IO[t.Any]], t.Mapping],\n         silent: bool = False,\n         text: bool = True,",
        "sim_diff_0": "diff --git a/src/flask/config.py b/src/flask/config.py @@ -275,8 +275,9 @@ class Config(dict):\ndef from_mapping(\nself, mapping: t.Optional[t.Mapping[str, t.Any]] = None, **kwargs: t.Any\n) -> bool:\n- \"\"\"Updates the config like :meth:`update` ignoring items with non-upper\n- keys.\n+ \"\"\"Updates the config like :meth:`update` ignoring items with\n+ non-upper keys.\n+\n:return: Always returns ``True``.\n.. versionadded:: 0.11\n",
        "sim_msg_0": "Fix misrendered docstring\nThe API reference for `flask.Config.from_mapping` needs a newline to separate\nthe summary from the return description.  I also wrapped the docstring at 72\ncharacters as suggested in CONTRIBUTING.rst.",
        "sim_diff_1": "diff --git a/src/flask/app.py b/src/flask/app.py @@ -960,17 +960,24 @@ class Flask(_PackageBoundObject):\nif debug is not None:\nself.debug = bool(debug)\n- _host = \"127.0.0.1\"\n- _port = 5000\nserver_name = self.config.get(\"SERVER_NAME\")\n- sn_host, sn_port = None, None\n+ sn_host = sn_port = None\nif server_name:\nsn_host, _, sn_port = server_name.partition(\":\")\n- host = host or sn_host or _host\n- # pick the first value that's not None (0 is allowed)\n- port = int(next((p for p in (port, sn_port) if p is not None), _port))\n+ if not host:\n+ if sn_host:\n+ host = sn_host\n+ else:\n+ host = \"127.0.0.1\"\n+\n+ if port or port == 0:\n+ port = int(port)\n+ elif sn_port:\n+ port = int(sn_port)\n+ else:\n+ port = 5000\noptions.setdefault(\"use_reloader\", self.debug)\noptions.setdefault(\"use_debugger\", self.debug)\n@@ -2146,11 +2153,11 @@ class Flask(_PackageBoundObject):\n# If subdomain matching is disabled (the default), use the\n# default subdomain in all cases. This should be the default\n# in Werkzeug but it currently does not have that feature.\n- subdomain = (\n- (self.url_map.default_subdomain or None)\n- if not self.subdomain_matching\n- else None\n- )\n+ if not self.subdomain_matching:\n+ subdomain = self.url_map.default_subdomain or None\n+ else:\n+ subdomain = None\n+\nreturn self.url_map.bind_to_environ(\nrequest.environ,\nserver_name=self.config[\"SERVER_NAME\"],\n",
        "sim_msg_1": "refactor variable choices into if blocks",
        "sim_diff_2": "diff --git a/src/flask/config.py b/src/flask/config.py @@ -218,7 +218,7 @@ class Config(dict):\nabsolute path or relative to the config root path.\n:param silent: Ignore the file if it doesn't exist.\n- .. deprecated:: 1.2\n+ .. deprecated:: 2.0\nUse :meth:`from_file` with :meth:`json.load` instead.\n.. versionadded:: 0.11\n",
        "sim_msg_2": "Update deprecated for config.from_json",
        "sim_diff_3": "diff --git a/app/config.py b/app/config.py @@ -57,7 +57,7 @@ cfg_defaults = { # key => default value\n\"trusted_proxy_count\": 0,\n\"custom_hot_sort\": False,\n\"recent_activity\": {\n- \"enabled\": True,\n+ \"enabled\": False, # TODO: Address performance issues\n\"defaults_only\": False,\n\"comments_only\": False,\n\"max_entries\": 10,\n",
        "sim_msg_3": "Disabling recent activity in the sidebar by default until we address the performance issues"
    },
    {
        "org_diff": "diff --git a/CHANGES.rst b/a/CHANGES.rst @@ -69,6 +69,15 @@ Released 2023-04-25\n -   Use postponed evaluation of annotations. :pr:`5071`\n \n \n+Version 2.2.5\n+-------------\n+\n+Released 2023-05-02\n+\n+-   Update for compatibility with Werkzeug 2.3.3.\n+-   Set ``Vary: Cookie`` header when the session is accessed, modified, or refreshed.\n+\n+\n Version 2.2.4\n -------------\n ",
        "sim_diff_0": "diff --git a/CHANGELOG.rst b/CHANGELOG.rst @@ -9,6 +9,7 @@ This project adheres to `Semantic Versioning <https://semver.org/>`_.\n`2.4.0-dev`_ (unreleased)\n-------------------------\n+* Added support for ``--session`` cookie expiration based on ``Set-Cookie: max-age=<n>``. (`#1029`_)\n* Show a ``--check-status`` warning with ``--quiet`` as well, not only when the output si redirected. (`#1026`_)\n* Fixed upload with ``--session`` (`#1020`_).\n* Fixed a missing blank line between request and response (`#1006`_).\n@@ -489,3 +490,4 @@ This project adheres to `Semantic Versioning <https://semver.org/>`_.\n.. _#1006: https://github.com/httpie/httpie/issues/1006\n.. _#1020: https://github.com/httpie/httpie/issues/1020\n.. _#1026: https://github.com/httpie/httpie/issues/1026\n+.. _#1029: https://github.com/httpie/httpie/issues/1029\n",
        "sim_msg_0": "Changelog entry for cookie expiration based on `Set-Cookie: max-age=<n>`",
        "sim_diff_1": "diff --git a/CHANGES.rst b/CHANGES.rst @@ -26,11 +26,9 @@ Changes - General:\n* Part user from rooms on account deactivate (PR #3201)\n* Make 'unexpected logging context' into warnings (PR #3007)\n* Set Server header in SynapseRequest (PR #3208)\n-* Use deferred.addTimeout instead of time_bound_deferred (PR #3127, #3178)\n* remove duplicates from groups tables (PR #3129)\n* Improve exception handling for background processes (PR #3138)\n* Add missing consumeErrors to improve exception handling (PR #3139)\n-* Use run_in_background in preference to preserve_fn (PR #3140)\n* reraise exceptions more carefully (PR #3142)\n* Remove redundant call to preserve_fn (PR #3143)\n* Trap exceptions thrown within run_in_background (PR #3144)\n@@ -46,6 +44,9 @@ Changes - Refactors:\n* Refactor request handling wrappers (PR #3203)\n* transaction_id, destination defined twice (PR #3209) Thanks to @damir-manapov!\n* Refactor event storage to prepare for changes in state calculations (PR #3141)\n+* Set Server header in SynapseRequest (PR #3208)\n+* Use deferred.addTimeout instead of time_bound_deferred (PR #3127, #3178)\n+* Use run_in_background in preference to preserve_fn (PR #3140)\nChanges - Python 3 migration:\n",
        "sim_msg_1": "further musical chairs",
        "sim_diff_2": "diff --git a/CHANGES.rst b/CHANGES.rst Changes\n=======\n-v2.0 (in development)\n----------------------\n+v2.0 (2019-03-06)\n+-----------------\n-This is a major new release with some backwards-incompatible changes.\n-Please review them and adjust your scripts if necessary.\n+This is a major new release with lots of bug fixes and new features, but\n+also some backwards-incompatible changes. These should hopefully\n+not affect too many users, but please make sure to review them and\n+possibly update your scripts!\nBackwards-incompatible changes\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
        "sim_msg_2": "Cutadapt 2.0",
        "sim_diff_3": "diff --git a/CHANGES.rst b/CHANGES.rst @@ -5,7 +5,7 @@ Version 2.0.2\nUnreleased\n-- Fix type annotation for ``teardown_request``. :issue:`4093`\n+- Fix type annotation for ``teardown_*`` methods. :issue:`4093`\n- Fix type annotation for ``before_request`` and ``before_app_request``\ndecorators. :issue:`4104`\n- Fixed the issue where typing requires template global\n",
        "sim_msg_3": "Improve the changelog entry\nThe fix to the teardown_request also applies to all teardown_*\nmethods."
    },
    {
        "org_diff": "diff --git a/.github/workflows/publish.yaml b/a/.github/workflows/publish.yaml @@ -63,10 +63,10 @@ jobs:\n     steps:\n       - uses: actions/download-artifact@9bc31d5ccc31df68ecc42ccf4149144866c47d8a\n       # Try uploading to Test PyPI first, in case something fails.\n-      - uses: pypa/gh-action-pypi-publish@29930c9cf57955dc1b98162d0d8bc3ec80d9e75c\n+      - uses: pypa/gh-action-pypi-publish@0bf742be3ebe032c25dd15117957dc15d0cfc38d\n         with:\n           repository_url: https://test.pypi.org/legacy/\n           packages_dir: artifact/\n-      - uses: pypa/gh-action-pypi-publish@29930c9cf57955dc1b98162d0d8bc3ec80d9e75c\n+      - uses: pypa/gh-action-pypi-publish@0bf742be3ebe032c25dd15117957dc15d0cfc38d\n         with:\n           packages_dir: artifact/",
        "sim_diff_0": "diff --git a/.github/workflows/full-build.yml b/.github/workflows/full-build.yml @@ -397,7 +397,7 @@ jobs:\nname: Publish to PyPI (release only)\nneeds: [ linux-gtk4, linux-flatpak-devel, macos-gtk4, check-linux-appimage, check-macos-app, check-windows-installer ]\nruns-on: ubuntu-22.04\n- # if: github.event_name == 'release'\n+ if: github.event_name == 'release'\nsteps:\n- uses: actions/download-artifact@v3\nwith:\n@@ -410,4 +410,3 @@ jobs:\n- uses: pypa/gh-action-pypi-publish@release/v1\nwith:\npassword: ${{ secrets.PYPI_TOKEN }}\n- repository_url: https://test.pypi.org/legacy/\n",
        "sim_msg_0": "Change publish target for production",
        "sim_diff_1": "diff --git a/.github/workflows/pypi_upload.yml b/.github/workflows/pypi_upload.yml @@ -47,7 +47,7 @@ jobs:\n# to upload to test pypi, pass repository_url: https://test.pypi.org/legacy/ and use secrets.TEST_PYPI_TOKEN\n- name: Publish a Python distribution to PyPI\n- uses: pypa/gh-action-pypi-publish@master\n+ uses: pypa/gh-action-pypi-publish@release/v1\nwith:\nuser: __token__\npassword: ${{ secrets.PYPI_TOKEN }}\n",
        "sim_msg_1": "Update pypi release action.",
        "sim_diff_2": "diff --git a/.github/workflows/pypi_upload.yml b/.github/workflows/pypi_upload.yml @@ -54,8 +54,8 @@ jobs:\nuses: pypa/gh-action-pypi-publish@master\nwith:\nuser: __token__\n- password: ${{ secrets.TEST_PYPI_TOKEN }}\n- repository_url: https://test.pypi.org/legacy/\n+ password: ${{ secrets.PYPI_TOKEN }}\n+ # repository_url: https://test.pypi.org/legacy/\npackages_dir: dist/\n# git push https://${{ github.actor }}:${{ secrets.GITHUB_TOKEN }}@github.com/${{ github.repository }}.git HEAD:master\n",
        "sim_msg_2": "Switch automated release action to point at production pypi",
        "sim_diff_3": "diff --git a/.github/workflows/build.yml b/.github/workflows/build.yml @@ -73,8 +73,7 @@ jobs:\npath: dist/gaphor-${{ steps.meta.outputs.version }}-py3-none-any.whl\n- name: Publish to PyPI\nif: github.event_name == 'release'\n- run: |\n- poetry publish -u __token__ -p ${{ secrets.PYPI_TOKEN }}\n+ run: poetry publish -u __token__ -p ${{ secrets.PYPI_TOKEN }}\nwindows:\nneeds: lint\n@@ -104,16 +103,14 @@ jobs:\nkey: ${{ runner.os }}-poetry-${{ hashFiles('**/poetry.lock') }}\nrestore-keys: ${{ runner.os }}-poetry-\n- name: Install Dependencies\n- run: |\n- ./win-installer/msys2-install.sh\n+ run: ./win-installer/msys2-install.sh\n- name: Install Poetry\nrun: |\npip install poetry==$POETRY_VERSION\npoetry config virtualenvs.create false\n- name: Collect Metadata\nid: meta\n- run: |\n- .github/scripts/metadata.sh\n+ run: .github/scripts/metadata.sh\n- name: Install Python Dependencies\nrun: mingw32-make install\n- name: Run Tests\n@@ -168,9 +165,7 @@ jobs:\n- name: Set up Python\nuses: actions/setup-python@v2.1.3\n- name: Install macOS Dependencies\n- run: |\n- brew list\n- brew install gobject-introspection gtk+3 adwaita-icon-theme gtk-mac-integration create-dmg\n+ run: brew install gobject-introspection gtk+3 adwaita-icon-theme gtk-mac-integration create-dmg\n- name: Install Poetry\nrun: pip install poetry==$POETRY_VERSION\n- name: Collect Metadata\n@@ -183,8 +178,7 @@ jobs:\nkey: ${{ runner.os }}-poetry-${{ hashFiles('**/poetry.lock') }}\nrestore-keys: ${{ runner.os }}-poetry-\n- name: Install Python Dependencies\n- run: |\n- poetry install\n+ run: poetry install\n- name: Test with Pytest\nrun: make test-all\n- name: Create macOS Application\n",
        "sim_msg_3": "Put single line build statements on one line"
    },
    {
        "org_diff": "diff --git a/.github/workflows/publish.yaml b/a/.github/workflows/publish.yaml @@ -63,10 +63,10 @@ jobs:\n     steps:\n       - uses: actions/download-artifact@9bc31d5ccc31df68ecc42ccf4149144866c47d8a\n       # Try uploading to Test PyPI first, in case something fails.\n-      - uses: pypa/gh-action-pypi-publish@29930c9cf57955dc1b98162d0d8bc3ec80d9e75c\n+      - uses: pypa/gh-action-pypi-publish@0bf742be3ebe032c25dd15117957dc15d0cfc38d\n         with:\n           repository_url: https://test.pypi.org/legacy/\n           packages_dir: artifact/\n-      - uses: pypa/gh-action-pypi-publish@29930c9cf57955dc1b98162d0d8bc3ec80d9e75c\n+      - uses: pypa/gh-action-pypi-publish@0bf742be3ebe032c25dd15117957dc15d0cfc38d\n         with:\n           packages_dir: artifact/",
        "sim_diff_0": "diff --git a/.github/workflows/full-build.yml b/.github/workflows/full-build.yml @@ -397,7 +397,7 @@ jobs:\nname: Publish to PyPI (release only)\nneeds: [ linux-gtk4, linux-flatpak-devel, macos-gtk4, check-linux-appimage, check-macos-app, check-windows-installer ]\nruns-on: ubuntu-22.04\n- # if: github.event_name == 'release'\n+ if: github.event_name == 'release'\nsteps:\n- uses: actions/download-artifact@v3\nwith:\n@@ -410,4 +410,3 @@ jobs:\n- uses: pypa/gh-action-pypi-publish@release/v1\nwith:\npassword: ${{ secrets.PYPI_TOKEN }}\n- repository_url: https://test.pypi.org/legacy/\n",
        "sim_msg_0": "Change publish target for production",
        "sim_diff_1": "diff --git a/.github/workflows/pypi_upload.yml b/.github/workflows/pypi_upload.yml @@ -47,7 +47,7 @@ jobs:\n# to upload to test pypi, pass repository_url: https://test.pypi.org/legacy/ and use secrets.TEST_PYPI_TOKEN\n- name: Publish a Python distribution to PyPI\n- uses: pypa/gh-action-pypi-publish@master\n+ uses: pypa/gh-action-pypi-publish@release/v1\nwith:\nuser: __token__\npassword: ${{ secrets.PYPI_TOKEN }}\n",
        "sim_msg_1": "Update pypi release action.",
        "sim_diff_2": "diff --git a/.github/workflows/pypi_upload.yml b/.github/workflows/pypi_upload.yml @@ -54,8 +54,8 @@ jobs:\nuses: pypa/gh-action-pypi-publish@master\nwith:\nuser: __token__\n- password: ${{ secrets.TEST_PYPI_TOKEN }}\n- repository_url: https://test.pypi.org/legacy/\n+ password: ${{ secrets.PYPI_TOKEN }}\n+ # repository_url: https://test.pypi.org/legacy/\npackages_dir: dist/\n# git push https://${{ github.actor }}:${{ secrets.GITHUB_TOKEN }}@github.com/${{ github.repository }}.git HEAD:master\n",
        "sim_msg_2": "Switch automated release action to point at production pypi",
        "sim_diff_3": "diff --git a/.github/workflows/build.yml b/.github/workflows/build.yml @@ -73,8 +73,7 @@ jobs:\npath: dist/gaphor-${{ steps.meta.outputs.version }}-py3-none-any.whl\n- name: Publish to PyPI\nif: github.event_name == 'release'\n- run: |\n- poetry publish -u __token__ -p ${{ secrets.PYPI_TOKEN }}\n+ run: poetry publish -u __token__ -p ${{ secrets.PYPI_TOKEN }}\nwindows:\nneeds: lint\n@@ -104,16 +103,14 @@ jobs:\nkey: ${{ runner.os }}-poetry-${{ hashFiles('**/poetry.lock') }}\nrestore-keys: ${{ runner.os }}-poetry-\n- name: Install Dependencies\n- run: |\n- ./win-installer/msys2-install.sh\n+ run: ./win-installer/msys2-install.sh\n- name: Install Poetry\nrun: |\npip install poetry==$POETRY_VERSION\npoetry config virtualenvs.create false\n- name: Collect Metadata\nid: meta\n- run: |\n- .github/scripts/metadata.sh\n+ run: .github/scripts/metadata.sh\n- name: Install Python Dependencies\nrun: mingw32-make install\n- name: Run Tests\n@@ -168,9 +165,7 @@ jobs:\n- name: Set up Python\nuses: actions/setup-python@v2.1.3\n- name: Install macOS Dependencies\n- run: |\n- brew list\n- brew install gobject-introspection gtk+3 adwaita-icon-theme gtk-mac-integration create-dmg\n+ run: brew install gobject-introspection gtk+3 adwaita-icon-theme gtk-mac-integration create-dmg\n- name: Install Poetry\nrun: pip install poetry==$POETRY_VERSION\n- name: Collect Metadata\n@@ -183,8 +178,7 @@ jobs:\nkey: ${{ runner.os }}-poetry-${{ hashFiles('**/poetry.lock') }}\nrestore-keys: ${{ runner.os }}-poetry-\n- name: Install Python Dependencies\n- run: |\n- poetry install\n+ run: poetry install\n- name: Test with Pytest\nrun: make test-all\n- name: Create macOS Application\n",
        "sim_msg_3": "Put single line build statements on one line"
    },
    {
        "org_diff": "diff --git a/CHANGES.rst b/a/CHANGES.rst @@ -1,7 +1,7 @@\n Version 2.3.2\n -------------\n \n-Released 2022-05-01\n+Released 2023-05-01\n \n -   Set ``Vary: Cookie`` header when the session is accessed, modified, or refreshed.\n -   Update Werkzeug requirement to >=2.3.3 to apply recent bug fixes.",
        "sim_diff_0": "diff --git a/CHANGELOG.rst b/CHANGELOG.rst @@ -9,6 +9,7 @@ This project adheres to `Semantic Versioning <https://semver.org/>`_.\n`2.4.0-dev`_ (unreleased)\n-------------------------\n+* Added support for ``--session`` cookie expiration based on ``Set-Cookie: max-age=<n>``. (`#1029`_)\n* Show a ``--check-status`` warning with ``--quiet`` as well, not only when the output si redirected. (`#1026`_)\n* Fixed upload with ``--session`` (`#1020`_).\n* Fixed a missing blank line between request and response (`#1006`_).\n@@ -489,3 +490,4 @@ This project adheres to `Semantic Versioning <https://semver.org/>`_.\n.. _#1006: https://github.com/httpie/httpie/issues/1006\n.. _#1020: https://github.com/httpie/httpie/issues/1020\n.. _#1026: https://github.com/httpie/httpie/issues/1026\n+.. _#1029: https://github.com/httpie/httpie/issues/1029\n",
        "sim_msg_0": "Changelog entry for cookie expiration based on `Set-Cookie: max-age=<n>`",
        "sim_diff_1": "diff --git a/CHANGES.rst b/CHANGES.rst Changes\n=======\n-v2.0 (in development)\n----------------------\n+v2.0 (2019-03-06)\n+-----------------\n-This is a major new release with some backwards-incompatible changes.\n-Please review them and adjust your scripts if necessary.\n+This is a major new release with lots of bug fixes and new features, but\n+also some backwards-incompatible changes. These should hopefully\n+not affect too many users, but please make sure to review them and\n+possibly update your scripts!\nBackwards-incompatible changes\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
        "sim_msg_1": "Cutadapt 2.0",
        "sim_diff_2": "diff --git a/CHANGES.rst b/CHANGES.rst @@ -26,11 +26,9 @@ Changes - General:\n* Part user from rooms on account deactivate (PR #3201)\n* Make 'unexpected logging context' into warnings (PR #3007)\n* Set Server header in SynapseRequest (PR #3208)\n-* Use deferred.addTimeout instead of time_bound_deferred (PR #3127, #3178)\n* remove duplicates from groups tables (PR #3129)\n* Improve exception handling for background processes (PR #3138)\n* Add missing consumeErrors to improve exception handling (PR #3139)\n-* Use run_in_background in preference to preserve_fn (PR #3140)\n* reraise exceptions more carefully (PR #3142)\n* Remove redundant call to preserve_fn (PR #3143)\n* Trap exceptions thrown within run_in_background (PR #3144)\n@@ -46,6 +44,9 @@ Changes - Refactors:\n* Refactor request handling wrappers (PR #3203)\n* transaction_id, destination defined twice (PR #3209) Thanks to @damir-manapov!\n* Refactor event storage to prepare for changes in state calculations (PR #3141)\n+* Set Server header in SynapseRequest (PR #3208)\n+* Use deferred.addTimeout instead of time_bound_deferred (PR #3127, #3178)\n+* Use run_in_background in preference to preserve_fn (PR #3140)\nChanges - Python 3 migration:\n",
        "sim_msg_2": "further musical chairs",
        "sim_diff_3": "diff --git a/CHANGELOG.rst b/CHANGELOG.rst @@ -9,16 +9,19 @@ This project adheres to `Semantic Versioning <https://semver.org/>`_.\n`2.2.0-dev`_ (unreleased)\n-------------------------\n+* Added support ``$XDG_CONFIG_HOME`` (`#920`_).\n+\n+\n`2.1.0`_ (2020-04-18)\n---------------------\n* Added ``--path-as-is`` to bypass dot segment (``/../`` or ``/./``)\n- URL squashing (#895).\n+ URL squashing (`#895`_).\n* Changed the default ``Accept`` header value for JSON requests from\n``application/json, */*`` to ``application/json, */*;q=0.5``\n- to clearly indicate preference (#488).\n+ to clearly indicate preference (`#488`_).\n* Fixed ``--form`` file upload mixed with redirected ``stdin`` error handling\n- (#840).\n+ (`#840`_).\n`2.0.0`_ (2020-01-12)\n@@ -431,3 +434,4 @@ This project adheres to `Semantic Versioning <https://semver.org/>`_.\n.. _#488:https://github.com/jakubroztocil/httpie/issues/488\n.. _#840:https://github.com/jakubroztocil/httpie/issues/840\n.. _#895:https://github.com/jakubroztocil/httpie/issues/895\n+.. _#920:https://github.com/jakubroztocil/httpie/issues/920\n",
        "sim_msg_3": "Added changelog entry for $XDG_CONFIG_HOME support"
    },
    {
        "org_diff": "diff --git a/CHANGES.rst b/a/CHANGES.rst @@ -3,6 +3,9 @@ Version 2.3.2\n \n Unreleased\n \n+-   Session cookie sets ``Vary: Cookie`` header when it is accessed, modified, cleared,\n+    or refreshed.\n+\n \n Version 2.3.1\n -------------",
        "sim_diff_0": "diff --git a/docs/index.rst b/docs/index.rst @@ -133,19 +133,19 @@ Or reuse cookie file:\njira = Jira(\nurl='http://localhost:8080',\n- cookie=cookie_dict)\n+ cookies=cookie_dict)\nconfluence = Confluence(\nurl='http://localhost:8090',\n- cookie=cookie_dict)\n+ cookies=cookie_dict)\nbitbucket = Bitbucket(\nurl='http://localhost:7990',\n- cookie=cookie_dict)\n+ cookies=cookie_dict)\nservice_desk = ServiceDesk(\nurl='http://localhost:8080',\n- cookie=cookie_dict)\n+ cookies=cookie_dict)\nTo authenticate to the Atlassian Cloud APIs:\n",
        "sim_msg_0": "Fix cookie auth parameter in docs\nCookie authentication uses the \"cookies\" parameter, not \"cookie\".\nSee atlassian/rest_client.py",
        "sim_diff_1": "diff --git a/static/htk/js/toolbar/emulate_user.js b/static/htk/js/toolbar/emulate_user.js @@ -60,7 +60,7 @@ $(function() {\nshowError();\n} else {\nemulateUserMessage.hide();\n- $.cookie(cookieName, cookieVal, { expires: getExpireDate() });\n+ $.cookie(cookieName, cookieVal, { expires: getExpireDate(), path: '/' });\nlocation.reload();\n}\n}\n",
        "sim_msg_1": "Set cookie path to /",
        "sim_diff_2": "diff --git a/docs/patterns/deferredcallbacks.rst b/docs/patterns/deferredcallbacks.rst @@ -41,5 +41,6 @@ user in a cookie in a :meth:`~flask.Flask.before_request` callback::\n@after_this_request\ndef remember_language(response):\nresponse.set_cookie('user_lang', language)\n+ return response\ng.language = language\n",
        "sim_msg_2": "Fix deferred callback doc",
        "sim_diff_3": "diff --git a/app/html/shared/layout.html b/app/html/shared/layout.html <body class=\"@{(conf.get('ENABLE_TOTP', False) and current_user.admin) and 'body_admin' or ''} @{(request.cookies.get( \"dayNight\")==\"dank\" and not current_user.is_anonymous) and 'dark dank' or ''} @{(request.cookies.get( \"dayNight\")==\"dark\" and not current_user.is_anonymous) and 'dark' or ''}\">\n@if conf.get('ENABLE_TOTP', False) and current_user.admin:\n- <div class=\"admin_alert\">Admin mode is currently enabled. <a href=\"/admin/logout\">Disable</a></div>\n+ <div class=\"admin_alert\">Admin mode is currently enabled.\n+ <form method=\"POST\" action=\"/admin/logout\" id=\"adminlogout\">\n+ @{ form.LogOutForm().csrf_token() }\n+ <button type=\"submit\" class=\"btn_link\">Disable</button>\n+ </form>\n+ </div>\n+</div>\n@end\n<div class=\"th-subbar pure-u-1\">\n<ul>\n",
        "sim_msg_3": "Fixing disable admin mode on new style templates"
    },
    {
        "org_diff": "diff --git a/src/flask/app.py b/a/src/flask/app.py @@ -1852,7 +1852,7 @@ def make_response(self, rv: ft.ResponseReturnValue) -> Response:\n \n         # extend existing headers with provided headers\n         if headers:\n-            rv.headers.update(headers)\n+            rv.headers.update(headers)  # type: ignore[arg-type]\n \n         return rv\n ",
        "sim_diff_0": "diff --git a/flask_app.py b/flask_app.py @@ -107,6 +107,18 @@ def oeis():\nreturn render_template(\"oeis.html\")\n+@app.route(\"/update\", methods=(\"GET\", ))\n+def update():\n+ # Updates the server after a commit\n+\n+ if request.method == 'POST':\n+ repo = git.Repo('/home/Lyxal/mysite')\n+ origin = repo.remotes.origin\n+ origin.pull()\n+ return 'Updated PythonAnywhere successfully', 200\n+ else:\n+ return 'Wrong event type', 400\n+\ndef parse_file():\nimport os\n",
        "sim_msg_0": "added time.sleep as a digraph\nand maybe done something cool",
        "sim_diff_1": "diff --git a/flask/app.py b/flask/app.py @@ -1923,7 +1923,7 @@ class Flask(_PackageBoundObject):\nstatus = headers = None\n# unpack tuple returns\n- if isinstance(rv, (tuple, list)):\n+ if isinstance(rv, tuple):\nlen_rv = len(rv)\n# a 3-tuple is unpacked directly\n",
        "sim_msg_1": "fix - allow lists to be passed through to response_class init",
        "sim_diff_2": "diff --git a/src/flask/app.py b/src/flask/app.py @@ -960,17 +960,24 @@ class Flask(_PackageBoundObject):\nif debug is not None:\nself.debug = bool(debug)\n- _host = \"127.0.0.1\"\n- _port = 5000\nserver_name = self.config.get(\"SERVER_NAME\")\n- sn_host, sn_port = None, None\n+ sn_host = sn_port = None\nif server_name:\nsn_host, _, sn_port = server_name.partition(\":\")\n- host = host or sn_host or _host\n- # pick the first value that's not None (0 is allowed)\n- port = int(next((p for p in (port, sn_port) if p is not None), _port))\n+ if not host:\n+ if sn_host:\n+ host = sn_host\n+ else:\n+ host = \"127.0.0.1\"\n+\n+ if port or port == 0:\n+ port = int(port)\n+ elif sn_port:\n+ port = int(sn_port)\n+ else:\n+ port = 5000\noptions.setdefault(\"use_reloader\", self.debug)\noptions.setdefault(\"use_debugger\", self.debug)\n@@ -2146,11 +2153,11 @@ class Flask(_PackageBoundObject):\n# If subdomain matching is disabled (the default), use the\n# default subdomain in all cases. This should be the default\n# in Werkzeug but it currently does not have that feature.\n- subdomain = (\n- (self.url_map.default_subdomain or None)\n- if not self.subdomain_matching\n- else None\n- )\n+ if not self.subdomain_matching:\n+ subdomain = self.url_map.default_subdomain or None\n+ else:\n+ subdomain = None\n+\nreturn self.url_map.bind_to_environ(\nrequest.environ,\nserver_name=self.config[\"SERVER_NAME\"],\n",
        "sim_msg_2": "refactor variable choices into if blocks",
        "sim_diff_3": "diff --git a/ghdata/server.py b/ghdata/server.py @@ -53,6 +53,8 @@ def flaskify(flaskapp, func):\nreturn generated_function\n+def run():\n+\napp = Flask(__name__, static_url_path=os.path.abspath('static/'))\nCORS(app)\n# Flags and Initialization\n@@ -431,7 +433,6 @@ if (DEBUG):\napp.debug = True\n-def run():\napp.run(host=host, port=int(port), debug=DEBUG)\nif __name__ == '__main__':\n",
        "sim_msg_3": "Refactor server to prevent execution on import"
    },
    {
        "org_diff": "diff --git a/CHANGES.rst b/a/CHANGES.rst @@ -53,7 +53,7 @@ Unreleased\n Version 2.2.4\n -------------\n \n-Unreleased\n+Released 2023-04-25\n \n -   Update for compatibility with Werkzeug 2.3.\n ",
        "sim_diff_0": "diff --git a/CHANGES.rst b/CHANGES.rst Changes\n=======\n-v2.0 (in development)\n----------------------\n+v2.0 (2019-03-06)\n+-----------------\n-This is a major new release with some backwards-incompatible changes.\n-Please review them and adjust your scripts if necessary.\n+This is a major new release with lots of bug fixes and new features, but\n+also some backwards-incompatible changes. These should hopefully\n+not affect too many users, but please make sure to review them and\n+possibly update your scripts!\nBackwards-incompatible changes\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
        "sim_msg_0": "Cutadapt 2.0",
        "sim_diff_1": "diff --git a/docs/releases.rst b/docs/releases.rst @@ -21,6 +21,13 @@ unreleased\n`git master <https://github.com/meejah/txtorcon>`_ *will likely become v0.18.0*\n+\n+v0.18.0\n+-------\n+\n+January 11, 2017\n+\n+ * `txtorcon-0.18.0.tar.gz <http://timaq4ygg2iegci7.onion/txtorcon-0.18.0.tar.gz>`_ (`PyPI <https://pypi.python.org/pypi/txtorcon/0.18.0>`_ (:download:`local-sig </../signatues/txtorcon-0.18.0.tar.gz.asc>` or `github-sig <https://github.com/meejah/txtorcon/blob/master/signatues/txtorcon-0.18.0.tar.gz.asc?raw=true>`_) (`source <https://github.com/meejah/txtorcon/archive/v0.18.0.tar.gz>`_)\n* `issue 200 <https://github.com/meejah/txtorcon/issues/200>`_: better feedback if the cookie data can't be read\n",
        "sim_msg_1": "links for 0.18.0",
        "sim_diff_2": "diff --git a/docs/releases.rst b/docs/releases.rst @@ -18,6 +18,14 @@ unreleased\n`git master <https://github.com/meejah/txtorcon>`_ *will likely become v17.0.0*\n+\n+v0.19.2\n+----------\n+\n+May 11, 2017\n+\n+ * `txtorcon-0.19.2.tar.gz <http://timaq4ygg2iegci7.onion/txtorcon-0.19.2.tar.gz>`_ (`PyPI <https://pypi.python.org/pypi/txtorcon/0.19.2>`_ (:download:`local-sig </../signatues/txtorcon-0.19.2.tar.gz.asc>` or `github-sig <https://github.com/meejah/txtorcon/blob/master/signatues/txtorcon-0.19.2.tar.gz.asc?raw=true>`_) (`source <https://github.com/meejah/txtorcon/archive/v0.19.2.tar.gz>`_)\n+\n* Work around a bug in `incremental` (see `Issue 233 <https://github.com/meejah/txtorcon/issues/233>`_)\n* Fix for `Issue 190 <https://github.com/meejah/txtorcon/issues/190>`_ from Felipe Dau.\n* add :meth:`txtorcon.Circuit.when_built`.\n",
        "sim_msg_2": "release notes for 0.19.2",
        "sim_diff_3": "diff --git a/docs/releases.rst b/docs/releases.rst @@ -19,6 +19,16 @@ unreleased\n`git master <https://github.com/meejah/txtorcon>`_ *will likely become v17.0.0*\n+v0.19.1\n+-------\n+\n+April 26, 2017\n+\n+ * `txtorcon-0.19.1.tar.gz <http://timaq4ygg2iegci7.onion/txtorcon-0.19.1.tar.gz>`_ (`PyPI <https://pypi.python.org/pypi/txtorcon/0.19.1>`_ (:download:`local-sig </../signatues/txtorcon-0.19.1.tar.gz.asc>` or `github-sig <https://github.com/meejah/txtorcon/blob/master/signatues/txtorcon-0.19.1.tar.gz.asc?raw=true>`_) (`source <https://github.com/meejah/txtorcon/archive/v0.19.1.tar.gz>`_)\n+\n+ * Fix a regression in ``launch_tor``, see `Issue 227 <https://github.com/meejah/txtorcon/issues/227>`_\n+\n+\nv0.19.0\n-------\n",
        "sim_msg_3": "release-notes for 0.19.1"
    },
    {
        "org_diff": "diff --git a/.github/workflows/tests.yaml b/a/.github/workflows/tests.yaml @@ -34,7 +34,7 @@ jobs:\n           - {name: '3.7', python: '3.7', os: ubuntu-latest, tox: py37}\n           - {name: 'PyPy', python: 'pypy-3.9', os: ubuntu-latest, tox: pypy39}\n           - {name: 'Pallets Minimum Versions', python: '3.11', os: ubuntu-latest, tox: py311-min}\n-          - {name: 'Pallets Development Versions', python: '3.7', os: ubuntu-latest, tox: py37-dev}\n+          - {name: 'Pallets Development Versions', python: '3.8', os: ubuntu-latest, tox: py38-dev}\n           - {name: Typing, python: '3.11', os: ubuntu-latest, tox: typing}\n     steps:\n       - uses: actions/checkout@ac593985615ec2ede58e132d2e21d2b1cbd6127c",
        "sim_diff_0": "diff --git a/.github/workflows/test.yml b/.github/workflows/test.yml @@ -30,7 +30,7 @@ jobs:\n- run: pip install types-pytz types-requests types-termcolor types-tabulate types-PyYAML types-python-dateutil\n- run: bandit -r . || true\n- run: black --check .\n- - run: codespell --ignore-words-list=\"mape,ba,hist,Pres,COO,Navagation,Ser,Buil,Operatio\" --quiet-level=2 --skip=\".git\" --skip=\"*.yaml\" --skip=\"*.json\" --skip=\"*.html\"\n+ - run: codespell --ignore-words-list=\"mape\",\"ba\",\"hist\",\"Press\",\"COUP\",\"Navigation\",\"Set\",\"Build\",\"built\",\"Operation\" --quiet-level=2 --skip=\".git\" --skip=\"*.yaml\" --skip=\"*.json\" --skip=\"*.html\"\n- run: flake8 . --count --ignore=E203,W503 --max-line-length=122 --show-source --statistics\n- run: mypy --ignore-missing-imports .\n- run: shopt -s globstar && pyupgrade --py36-plus **/*.py\n",
        "sim_msg_0": "ignore dictionary suggestions codespell",
        "sim_diff_1": "diff --git a/.github/workflows/test.yml b/.github/workflows/test.yml @@ -30,7 +30,7 @@ jobs:\n- run: pip install types-pytz types-requests types-termcolor types-tabulate types-PyYAML types-python-dateutil\n- run: bandit -r . || true\n- run: black --check .\n- - run: codespell --ignore-words-list=\"mape\",\"ba\",\"hist\",\"Pres\",\"COO\",\"Navagation\",\"Ser\",\"Buil\",\"Operatio\" --quiet-level=2 --skip=\".git\" --skip=\"*.yaml\" --skip=\"*.json\" --skip=\"*.html\"\n+ - run: codespell --ignore-words-list=\"Pres\",\"COO\",\"Navagation\",\"Ser\",\"Buil\",\"Operatio\",\"mape\",\"ba\",\"hist\" --quiet-level=2 --skip=\".git\" --skip=\"*.yaml\" --skip=\"*.json\" --skip=\"*.html\" --skip=\"*.ini\"\n- run: flake8 . --count --ignore=E203,W503 --max-line-length=122 --show-source --statistics\n- run: mypy --ignore-missing-imports .\n- run: shopt -s globstar && pyupgrade --py36-plus **/*.py\n",
        "sim_msg_1": "codespell skip .ini",
        "sim_diff_2": "diff --git a/.github/workflows/test.yml b/.github/workflows/test.yml @@ -30,7 +30,7 @@ jobs:\n- run: pip install types-pytz types-requests types-termcolor types-tabulate types-PyYAML types-python-dateutil\n- run: bandit -r . || true\n- run: black --check .\n- - run: codespell --ignore-words-list=\"mape\",\"ba\",\"hist\",\"Pres\",\"COO\",\"Navagation\",\"Ser\",\"Buil\",\"Operatio\" --quiet-level=2 --skip=\".git\" --skip=\"*.yaml\" --skip=\"*.json\" --skip=\"*.html\"\n+ - run: codespell --ignore-words-list mape,ba,hist,Pres,COO,Navagation,Ser,Buil,Operatio --quiet-level=2 --skip=\".git\" --skip=\"*.yaml\" --skip=\"*.json\" --skip=\"*.html\"\n- run: flake8 . --count --ignore=E203,W503 --max-line-length=122 --show-source --statistics\n- run: mypy --ignore-missing-imports .\n- run: shopt -s globstar && pyupgrade --py36-plus **/*.py\n",
        "sim_msg_2": "another try at ignore-words-list codespell",
        "sim_diff_3": "diff --git a/.github/workflows/test.yml b/.github/workflows/test.yml @@ -30,7 +30,7 @@ jobs:\n- run: pip install types-pytz types-requests types-termcolor types-tabulate types-PyYAML types-python-dateutil\n- run: bandit -r . || true\n- run: black --check .\n- - run: codespell --ignore-words-list=\"mape\",\"ba\",\"hist\" --quiet-level=2 --skip=\".git\" --skip=\"*.yaml\" --skip=\"*.json\" --skip=\"*.html\"\n+ - run: codespell --ignore-words-list=\"mape\",\"ba\",\"hist\",\"Pres\",\"COO\",\"Navagation\",\"Ser\",\"Buil\",\"Operatio\" --quiet-level=2 --skip=\".git\" --skip=\"*.yaml\" --skip=\"*.json\" --skip=\"*.html\"\n- run: flake8 . --count --ignore=E203,W503 --max-line-length=122 --show-source --statistics\n- run: mypy --ignore-missing-imports .\n- run: shopt -s globstar && pyupgrade --py36-plus **/*.py\n",
        "sim_msg_3": "Update ignore words test\nThis should allow to run"
    }
]