[
    {
        "sim_msg": "Change Rendeder ' s access level modifiers for extra draw methods",
        "sim_diff": "diff --git a/MPChartLib/src/com/github/mikephil/charting/renderer/LineChartRenderer.java \nppp b/MPChartLib/src/com/github/mikephil/charting/renderer/LineChartRenderer.java \npublic void drawExtras(Canvas c){ \ndrawCircles(c);}- private void drawCircles(Canvas c){+protected void drawCircles(Canvas c){ \nmRenderPaint.setStyle(Paint.Style.FILL); \nArrayList<LineDataSet>dataSets=mChart.getLineData().getDataSets();diff --git a/MPChartLib/src/com/github/mikephil/charting/renderer/PieChartRenderer.java \nppp b/MPChartLib/src/com/github/mikephil/charting/renderer/PieChartRenderer.java \npublic void drawExtras(Canvas c){*draws the hole in the center of the chart and the transparent circle/* hole*/-private void drawHole(Canvas c){+protected void drawHole(Canvas c){ \nif(mChart.isDrawHoleEnabled()){ \nprivate void drawHole(Canvas c){*draws the description text in the center of the pie chart makes most*sense when center-hole is enabled*/-private void drawCenterText(Canvas c){+protected void drawCenterText(Canvas c){ \nString centerText=mChart.getCenterText();diff --git a/MPChartLib/src/com/github/mikephil/charting/renderer/RadarChartRenderer.java \nppp b/MPChartLib/src/com/github/mikephil/charting/renderer/RadarChartRenderer.java \npublic void drawExtras(Canvas c){ \ndrawWeb(c);}- private void drawWeb(Canvas c){+protected void drawWeb(Canvas c){ \nfloat sliceangle=mChart.getSliceAngle() ; \n",
        "org_diff": "diff --git a/MPChartLib/src/com/github/mikephil/charting/renderer/PieChartRenderer.java  b/MPChartLib/src/com/github/mikephil/charting/renderer/PieChartRenderer.java \npublic void drawValues(Canvas c){ \npublic void drawExtras(Canvas c){// drawCircles(c); \ndrawHole(c);-c.drawBitmap(mDrawBitmap,0,0,mRenderPaint);+c.drawBitmap(mDrawBitmap,0,0,null); \ndrawCenterText(c); \n} \n"
    },
    {
        "sim_msg": "add loadMasterSlaveRuleConfiguration",
        "sim_diff": "diff --git a/sharding-jdbc-orchestration/src/main/java/io/shardingsphere/jdbc/orchestration/internal/config/ConfigurationService.java \nppp b/sharding-jdbc-orchestration/src/main/java/io/shardingsphere/jdbc/orchestration/internal/config/ConfigurationService.java \nprivate boolean hasShardingProperties(){*@param dataSourceMap data source map*@ param masterSlaveRuleConfig master-slave rule configuration*@ param configMap config map+*@param props props*@ param isOverwrite is overwrite registry center's configuration*/ \npublic void persistMasterSlaveConfiguration(- final Map<String,DataSource>dataSourceMap,final MasterSlaveRuleConfiguration masterSlaveRuleConfig,final Map<String,Object>configMap,final boolean isOverwrite){+final Map<String,DataSource>dataSourceMap,final MasterSlaveRuleConfiguration masterSlaveRuleConfig,final Map<String,Object>configMap,+ final Properties props,final boolean isOverwrite){ \npersistDataSourceConfiguration(dataSourceMap,isOverwrite); \npersistMasterSlaveRuleConfiguration(masterSlaveRuleConfig,isOverwrite); \npersistMasterSlaveConfigMap(configMap,isOverwrite);+persistMasterSlaveProperties(props,isOverwrite);}private void persistMasterSlaveRuleConfiguration(final MasterSlaveRuleConfiguration masterSlaveRuleConfig,final boolean isOverwrite){ \nprivate boolean hasMasterSlaveConfigMap(){return regCenter.isExisted(configNode.getFullPath(ConfigurationNode.MASTER_SLAVE_CONFIG_MAP_NODE_PATH));}+private void persistMasterSlaveProperties(final Properties props,final boolean isOverwrite){+if(isOverwrite||!hasMasterSlaveProperties()){+regCenter.persist(configNode.getFullPath(ConfigurationNode.MASTER_SLAVE_PROPS_NODE_PATH), MasterSlaveConfigurationConverter.propertiesToYaml(props));+}+}++private boolean hasMasterSlaveProperties(){+ return regCenter.isExisted(configNode.getFullPath(ConfigurationNode.MASTER_SLAVE_PROPS_NODE_PATH));+}+/*** Persist proxy configuration.* \npublic MasterSlaveRuleConfiguration loadMasterSlaveRuleConfiguration(){return MasterSlaveConfigurationConverter.configMapFromYaml(regCenter.getDirectly(configNode.getFullPath(ConfigurationNode.MASTER_SLAVE_CONFIG_MAP_NODE_PATH)));}+/**+*Load sharding properties configuration.+*+*@ return sharding properties+*/+ public Properties loadMasterSlaveProperties(){+ String data=regCenter.getDirectly(configNode.getFullPath(ConfigurationNode.MASTER_SLAVE_CONFIG_MAP_NODE_PATH));+ return Strings.isNullOrEmpty(data)? new Properties():MasterSlaveConfigurationConverter.propertiesFromYaml(data);+}+/***Load proxy configuration.* \n",
        "org_diff": "diff --git a/sharding-jdbc-orchestration/src/main/java/io/shardingjdbc/orchestration/yaml/YamlOrchestrationConfiguration.java  b/sharding-jdbc-orchestration/src/main/java/io/shardingjdbc/orchestration/yaml/YamlOrchestrationConfiguration.java*@ return orchestration master-slave rule configuration from yaml*/ \npublic OrchestrationConfiguration getOrchestrationConfiguration(){+ if(null!= etcd&& null!= zookeeper){+throw new RuntimeException(\" Can't config both zookeeper and etcd as registry center!\");+} \nreturn new OrchestrationConfiguration(getName(),null!= etcd?etcd:zookeeper,overwrite);}} \n"
    },
    {
        "sim_msg": "Only include name for UserDefinedFunctionProfiling",
        "sim_diff": "diff --git a/src/main/java/com/google/devtools/build/lib/syntax/UserDefinedFunction.java \nppp b/src/main/java/com/google/devtools/build/lib/syntax/UserDefinedFunction.java \npublic Object call(Object[] arguments,FuncallExpression ast,Environment env)}}- Profiler.instance().startTask(ProfilerTask.SKYLARK_USER_FN,- getLocationPathAndLine()+\"#\"+getName());+Profiler.instance().startTask(ProfilerTask.SKYLARK_USER_FN,getName()); \ntry{env.enterScope(this,ast,definitionGlobals); \nImmutableList<String>names=signature.getSignature().getNames() ; \n",
        "org_diff": "diff --git a/Ghidra/Features/GhidraServer/src/main/java/ghidra/server/ServerAdmin.java  b/Ghidra/Features/GhidraServer/src/main/java/ghidra/server/ServerAdmin.java \nprivate void displayUsage(String msg){ \nSystem.err.println(\"\\nSupported commands:\"); \nSystem.err.println(\"-add<sid>[-- p]\"); \nSystem.err.println(-\"Add a new user to the server identified by their sid identifier[- p prompt for password]\");+\" Add a new user to the server identified by their sid identifier[--p prompt for password]\"); \nSystem.err.println(\"-remove<sid>\"); \nSystem.err.println(\" Remove the specified user from the server's user list\");System.err.println(\"-reset<sid>[-- p]\"); \nSystem.err.println(-\"Reset the specified user's server login password[- p prompt for password]\");+\" Reset the specified user's server login password[--p prompt for password]\"); \nSystem.err.println(\"-dn<sid>\\\"< dname>\\\"\"); \nSystem.err.println(\" When PKI authentication is used,add the specified X500 Distinguished Name for a user\") ; \n"
    },
    {
        "sim_msg": "Add Documenting Rules link to skydoc . bazel . io .",
        "sim_diff": "diff --git a/site/_layouts/documentation.html \nppp b/site/_layouts/documentation.html<h3>Extensions</ h3></li>< li>< a href=\"{{ page.version_prefix}}/docs/skylark/cookbook.html\"> Examples</ a></li>< li>< a href=\"{{ page.version_prefix}}/docs/skylark/deploying.html\"> Packaging rules</ a></li>+<li>< a href=\" https://skydoc.bazel.io\"target=\" _blank\"> Documenting rules</ a></li></ul></nav></div > \n",
        "org_diff": "diff --git a/site/_layouts/documentation.html  b/site/_layouts/documentation.html<h3>Extensions</ h3>< li>< a href=\"{{ page.version_prefix}}/docs/skylark/cookbook.html\"> Examples</ a></li>< li>< a href=\"{{ page.version_prefix}}/docs/skylark/deploying.html\"> Packaging rules</ a></li>< li>< a href=\" https://skydoc.bazel.build\"target=\" _blank\"> Documenting rules</ a></li>+<li>< a href=\"{{ page.version_prefix}}/docs/skylark/build-style.html\"> Style guide for BUILD files</ a></li>+<li>< a href=\"{{ page.version_prefix}}/docs/skylark/bzl-style.html\"> Style guide for bzl files</ a></li></ul></nav></div > \n"
    },
    {
        "sim_msg": "Translated using Weblate ( Bulgarian )",
        "sim_diff": "diff --git a/app/src/main/res/values-bg/strings.xml \nppp b/app/src/main/res/values-bg/strings.xml<string name=\" show_search_suggestions_summary\"> Показвай предложения за търсене</ string>< string name=\" enable_search_history_title\"> История на търсенията</ string>< string name=\" enable_search_history_summary\"> Съхранявай заявките за търсене локално</ string>-<string name=\" enable_watch_history_title\"> История и кеш-памет</ string>+<string name=\" enable_watch_history_title\"> История на гледане</ string>< string name=\" enable_watch_history_summary\"> Запаметявай кои видеота са гледани</ string>< string name=\" resume_on_audio_focus_gain_title\"> Възобнови при връщане на фокус</ string>< string name=\" resume_on_audio_focus_gain_summary\"> Продължавай възпроизвеждането след прекъсване(например телефонно обаждане)</string>< string name=\" no_player_found_toast\"> Липсва стрийм плейър(можете да изтеглите VLC,за да пуснете стрийма).</ string>< string name=\" download_thumbnail_summary\"> Изключете,за да спрете зареждането на всички миниатюри,спестявайки трафик и памет.При промяна на тази настройка,текущата кеш-памет на изображенията ще бъде изтрита.</string>< string name=\" show_hold_to_append_summary\"> Показвай подсказка,когато е избран фонов режим или режим в прозорец на страницата с детайли на съответния клип</ string>-<string name=\" clear_views_history_summary\"> Изтрива историята на възпроизвежданите стриймове</ string>+<string name=\" clear_views_history_summary\"> Изтрива историята на възпроизвежданите стриймове и позицията на възпроизвеждането</ string>< string name=\" video_streams_empty\"> Не са намерени видео стриймове</ string>< string name=\" audio_streams_empty\"> Не са намерени аудио стриймове</ string>< string name=\" info_labels\"> Какво:\\\\nЗаявка:\\\\nЕзик на съдържанието:\\\\nУслуга:\\\\nВреме по GMT:\\\\nПакет:\\\\nВерсия:\\\\nОС версия:</string>< string name=\" autoplay_title\"> Автоматично пускане</ string>< plurals name=\" comments\"><item quantity=\" one\"> Коментари</ item>-<item quantity=\" other\"></ item>+<item quantity=\" other\"/></plurals>+<string name=\" tab_new\"> Нов раздел</ string>+<string name=\" tab_choose\"> Избери раздел</ string>+<string name=\" settings_category_updates_title\"> Промени</ string>+<string name=\" enable_playback_resume_title\"> Продължи възпроизвеждане</ string>+<string name=\" settings_category_clear_data_title\"> Изтрии данни</ string></resources>\\ No newline at end of file \n",
        "org_diff": "diff --git a/app/src/main/res/values-ru/strings.xml  b/app/src/main/res/values-ru/strings.xml<string name=\" fragment_whats_new\"> Что нового</ string>< string name=\" enable_search_history_title\"> История поиска</ string>-<string name=\" enable_search_history_summary\"> Хранить поисковые запросы локально</ string>+<string name=\" enable_search_history_summary\"> Хранить запросы поиска локально</ string>< string name=\" enable_watch_history_title\"> История и кэш</ string>-<string name=\" enable_watch_history_summary\"> Запоминать просмотренные видео</ string>+<string name=\" enable_watch_history_summary\"> Запоминать воспроизведённые потоки</ string>< string name=\" resume_on_audio_focus_gain_title\"> Возобновить при фокусе</ string>< string name=\" resume_on_audio_focus_gain_summary\"> Возобновлять воспроизведение после перерывов(например,телефонных звонков)</string>< string name=\" delete_view_history_alert\"> Вся история просмотров будет удалена.</string>< string name=\" view_history_deleted\"> История просмотров удалена</ string>< string name=\" clear_search_history_title\"> Очистить историю поиска</ string>-<string name=\" clear_search_history_summary\"> Удалить историю поисковых запросов</ string>+<string name=\" clear_search_history_summary\"> Удалить историю запросов поиска</ string>< string name=\" clear_views_history_summary\"> Удалить историю воспроизведённых потоков</ string>< string name=\" delete_search_history_alert\"> Вся история поиска будет удалена.</string>< string name=\" search_history_deleted\"> История поиска удалена</ string > \n"
    },
    {
        "sim_msg": "Back - link added",
        "sim_diff": "diff --git a/persistence-modules/java-jpa-2/README.md \nppp b/persistence-modules/java-jpa-2/README.md-[ JPA Query Parameters Usage]( http://www.baeldung.com/jpa-query-parameters-usage)=======>>>>>>>refs/heads/master+-[Mapping Entitiy Class Names to SQL Table Names with JPA]( https://www.baeldung.com/jpa-entity-table-names ) \n",
        "org_diff": "diff --git a/persistence-modules/java-jpa-2/README.md  b/persistence-modules/java-jpa-2/README.md \nThis module contains articles about the Java Persistence API(JPA)in Java.-[JPA Annotation for the PostgreSQL TEXT Type]( https://www.baeldung.com/jpa-annotation-postgresql-text-type)-[Mapping a Single Entity to Multiple Tables in JPA]( https://www.baeldung.com/jpa-mapping-single-entity-to-multiple-tables)-[Constructing a JPA Query Between Unrelated Entities]( https://www.baeldung.com/jpa-query-unrelated-entities)+-[ When Does JPA Set the Primary Key]( https://www.baeldung.com/jpa-strategies-when-set-primary-key)- More articles:[[<-- prev]](/ java-jpa ) \n"
    },
    {
        "sim_msg": "TESTS : Make score Float # NaN when there is no max score ( )",
        "sim_diff": "diff --git a/server/src/test/java/org/elasticsearch/search/aggregations/metrics/InternalTopHitsTests.java \nppp b/server/src/test/java/org/elasticsearch/search/aggregations/metrics/InternalTopHitsTests.java \nprotected InternalTopHits createTestInstance(String name,List<PipelineAggregato \nint requestedSize=between(1,40); \nint actualSize=between(0,requestedSize);-float maxScore=Float.MIN_VALUE;+ float maxScore=Float.NEGATIVE_INFINITY;ScoreDoc[] scoreDocs=new ScoreDoc[actualSize]; \nSearchHit[] hits=new SearchHit[actualSize]; \nSet<Integer>usedDocIds=new HashSet<>();protected InternalTopHits createTestInstance(String name,List<PipelineAggregato}else{topDocs=new TopDocs(new TotalHits(totalHits,TotalHits.Relation.EQUAL_TO), scoreDocs);}- TopDocsAndMaxScore topDocsAndMaxScore=new TopDocsAndMaxScore(topDocs,maxScore);+//Lucene's TopDocs initializes the maxScore to Float.NaN,if there is no maxScore+TopDocsAndMaxScore topDocsAndMaxScore=new TopDocsAndMaxScore(topDocs,maxScore== Float.NEGATIVE_INFINITY?Float.NaN:maxScore); \nreturn new InternalTopHits(name,from,requestedSize,topDocsAndMaxScore,searchHits,pipelineAggregators,metaData);}private Object randomOfType(SortField.Type type){ \nprotected void assertReduced(InternalTopHits reduced,List<InternalTopHits>inputs){ \nSearchHits actualHits=reduced.getHits();List<Tuple<ScoreDoc,SearchHit>> allHits=new ArrayList<>();- float maxScore=Float.MIN_VALUE;+ float maxScore=Float.NEGATIVE_INFINITY;long totalHits=0;for(int input=0;input<inputs.size();input++){ \nSearchHits internalHits=inputs.get(input). getHits();protected void assertReduced(InternalTopHits reduced,List<InternalTopHits>inpu \nexpectedHitsHits[i]= allHits.get(i). v2();}// Lucene's TopDocs initializes the maxScore to Float.NaN,if there is no maxScore-SearchHits expectedHits=new SearchHits(expectedHitsHits,totalHits,maxScore== Float.MIN_VALUE?Float.NaN:maxScore);+SearchHits expectedHits=new SearchHits(expectedHitsHits,totalHits,maxScore== Float.NEGATIVE_INFINITY?Float.NaN:maxScore); \nassertEqualsWithErrorMessageFromXContent(expectedHits,actualHits); \n} \n",
        "org_diff": "diff --git a/modules/rank-eval/src/test/java/org/elasticsearch/index/rankeval/ExpectedReciprocalRankTests.java  b/modules/rank-eval/src/test/java/org/elasticsearch/index/rankeval/ExpectedReciprocalRankTests.java \npublic void testProbabilityOfRelevance(){* 4|1|0.03125|0.078125|0.00244140625|*}</pre>*-* err=> sum of last column+* err=sum of last column*/ \npublic void testERRAt(){List<RatedDocument>rated=new ArrayList<>();public void testERRAt(){* 4|1|0.03125|0.125|0.00390625|*}</pre>*-* err=> sum of last column+* err=sum of last column*/ \npublic void testERRMissingRatings(){List<RatedDocument>rated=new ArrayList<>();diff --git a/x-pack/plugin/sql/src/main/java/org/elasticsearch/xpack/sql/expression/function/scalar/string/StringFunctionUtils.java  b/x-pack/plugin/sql/src/main/java/org/elasticsearch/xpack/sql/expression/function/scalar/string/StringFunctionUtils.java \npackage org.elasticsearch.xpack.sql.expression.function.scalar.string;abstract class StringFunctionUtils{-+/**-* Trims the trailing whitespace characters from the given String.Uses{@ link java.lang.Character.isWhitespace(char)}+* Trims the trailing whitespace characters from the given String.Uses@link java.lang.Character.isWhitespace(char)* to determine if a character is whitespace or not.**@ param s the original String \nstatic String trimTrailingWhitespaces(String s){ \nif(! hasLength(s)){return s;}-+ \nStringBuilder sb=new StringBuilder(s); \nwhile(sb.length()>0&& Character.isWhitespace(sb.charAt(sb.length()-1))){ \nsb.deleteCharAt(sb.length()-1);}return sb.toString();}-+/**-*Trims the leading whitespace characters from the given String.Uses{@ link java.lang.Character.isWhitespace(char)}+* Trims the leading whitespace characters from the given String.Uses@link java.lang.Character.isWhitespace(char)* to determine if a character is whitespace or not.**@ param s the original String \nstatic String trimLeadingWhitespaces(String s){ \nif(! hasLength(s)){return s;}-+ \nStringBuilder sb=new StringBuilder(s); \nwhile(sb.length()>0&& Character.isWhitespace(sb.charAt(0))){ \nsb.deleteCharAt(0); \n"
    },
    {
        "sim_msg": "Break cycle caused by JndiDataSourceAutoConfiguration",
        "sim_diff": "diff --git a/spring-boot-autoconfigure/src/main/java/org/springframework/boot/autoconfigure/jdbc/JndiDataSourceAutoConfiguration.java \nppp b/spring-boot-autoconfigure/src/main/java/org/springframework/boot/autoconfigure/jdbc/JndiDataSourceAutoConfiguration.java \nimport javax.sql.DataSource;+ import org.springframework.beans.factory.NoSuchBeanDefinitionException;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.boot.autoconfigure.AutoConfigureBefore;import org.springframework.boot.autoconfigure.EnableAutoConfiguration;import org.springframework.boot.autoconfigure.condition.ConditionalOnMissingBean;import org.springframework.boot.autoconfigure.condition.ConditionalOnProperty;import org.springframework.boot.context.properties.EnableConfigurationProperties;+ import org.springframework.context.ApplicationContext;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.jdbc.datasource.embedded.EmbeddedDatabaseType;@ EnableConfigurationProperties(DataSourceProperties.class)public class JndiDataSourceAutoConfiguration{-@Autowired(required=false)- private MBeanExporter mbeanExporter;+@Autowired+private ApplicationContext context;@ Bean(destroyMethod=\"\")@ConditionalOnMissingBean \npublic DataSource dataSource(DataSourceProperties properties){}private void excludeMBeanIfNecessary(Object candidate,String beanName){-if(this.mbeanExporter!= null&& JmxUtils.isMBean(candidate.getClass())){- this.mbeanExporter.addExcludedBean(beanName);+try{+ MBeanExporter mbeanExporter=this.context.getBean(MBeanExporter.class);+if(JmxUtils.isMBean(candidate.getClass())){+ mbeanExporter.addExcludedBean(beanName);+}+}+catch(NoSuchBeanDefinitionException ex){+//No exporter.Exclusion is unnecessary}} \n",
        "org_diff": "diff --git a/spring-boot-autoconfigure/src/main/java/org/springframework/boot/autoconfigure/jdbc/BasicDataSourceConfiguration.java  b/spring-boot-autoconfigure/src/main/java/org/springframework/boot/autoconfigure/jdbc/BasicDataSourceConfiguration.java \npublic DataSource dataSource(){this.pool.setMaxIdle(getMaxIdle()); \nthis.pool.setMinIdle(getMinIdle()); \nthis.pool.setTestOnBorrow(isTestOnBorrow());-this.pool.setTestOnReturn(isTestOnBorrow());+this.pool.setTestOnReturn(isTestOnReturn()); \nthis.pool.setValidationQuery(getValidationQuery()); \nreturn this.pool;} \ndiff --git a/spring-boot-autoconfigure/src/main/java/org/springframework/boot/autoconfigure/jdbc/TomcatDataSourceConfiguration.java  b/spring-boot-autoconfigure/src/main/java/org/springframework/boot/autoconfigure/jdbc/TomcatDataSourceConfiguration.java \npublic DataSource dataSource(){this.pool.setMaxIdle(getMaxIdle()); \nthis.pool.setMinIdle(getMinIdle()); \nthis.pool.setTestOnBorrow(isTestOnBorrow());-this.pool.setTestOnReturn(isTestOnBorrow());+this.pool.setTestOnReturn(isTestOnReturn()); \nthis.pool.setValidationQuery(getValidationQuery()); \nreturn this.pool;} \n"
    },
    {
        "sim_msg": "Replace deprecated Concourse resource for pull requests",
        "sim_diff": "diff --git a/ci/pipeline.yml \nppp b/ci/pipeline.yml \nresource_types:- name:pull-request \ntype:docker-image \nsource:- repository:jtarchie/pr+repository:teliaoss/github-pr-resource-name:github-status-resource \ntype:docker-image \nsource:resources:icon:source-pull \nsource:access_token:((github-ci-pull-request-token))-repo:((github-repo-name))-base:((branch))+repository:((github-repo-name))+base_branch:((branch)) \nignore_paths:[\"ci/*\"]-name:github-pre-release \ntype:github-release \n",
        "org_diff": "diff --git a/ci/pipeline.yml  b/ci/pipeline.yml \nresource_types:- name:pull-request \ntype:docker-image \nsource:- repository:jtarchie/pr+repository:teliaoss/github-pr-resource-name:github-status-resource \ntype:docker-image \nsource:resources:icon:source-pull \nsource:access_token:((github-ci-pull-request-token))-repo:((github-repo-name))-base:((branch))+repository:((github-repo-name))+base_branch:((branch)) \nignore_paths:[\"ci/*\"]-name:github-pre-release \ntype:github-release \n"
    },
    {
        "sim_msg": "fixed IllegalArgumentException in submitting configuration of the maven2 job ( )",
        "sim_diff": "diff --git a/core/src/main/java/hudson/matrix/MatrixProject.java \nppp b/core/src/main/java/hudson/matrix/MatrixProject.java \nimport hudson.tasks.BuildWrappers;import hudson.tasks.Builder;import hudson.tasks.Publisher;+ import hudson.tasks.BuildStepDescriptor;import hudson.util.CopyOnWriteMap;import org.kohsuke.stapler.StaplerRequest;import org.kohsuke.stapler.StaplerResponse;protected void submit(StaplerRequest req,StaplerResponse rsp)throws IOExceptio \nnewAxes.add(Axis.parsePrefixed(req,\" label\")); \nthis.axes=newAxes;- buildWrappers=buildDescribable(req,BuildWrappers.WRAPPERS,\" wrapper\");- builders=buildDescribable(req,BuildStep.BUILDERS,\" builder\");- publishers=buildDescribable(req,BuildStep.PUBLISHERS,\" publisher\");+ buildWrappers=buildDescribable(req,BuildWrappers.getFor(this),\"wrapper\");+ builders=buildDescribable(req,BuildStepDescriptor.filter(BuildStep.BUILDERS,getClass()),\"builder\");+ publishers=buildDescribable(req,BuildStepDescriptor.filter(BuildStep.PUBLISHERS,getClass()),\"publisher\");updateTransientActions();//to pick up transient actions from builder,publisher,etc.rebuildConfigurations() ; \n",
        "org_diff": "diff --git a/core/src/main/java/hudson/matrix/MatrixProject.java  b/core/src/main/java/hudson/matrix/MatrixProject.java \nprotected void submit(StaplerRequest req,StaplerResponse rsp)throws IOExceptio \nbuildWrappers=buildDescribable(req,BuildWrappers.getFor(this),\"wrapper\");builders=Descriptor.newInstancesFromHeteroList(req,StructuredForm.get(req),\"builder\", BuildStep.BUILDERS);-publishers=buildDescribable(req,BuildStepDescriptor.filter(BuildStep.PUBLISHERS,getClass()),\"publisher\");++publishers=buildDescribable(req,BuildStepDescriptor.filter(BuildStep.PUBLISHERS,this.getClass()),\"publisher\");updateTransientActions();//to pick up transient actions from builder,publisher,etc.rebuildConfigurations();diff --git a/core/src/main/java/hudson/maven/MavenModuleSet.java  b/core/src/main/java/hudson/maven/MavenModuleSet.java \nprotected void submit(StaplerRequest req,StaplerResponse rsp)throws IOExceptio \nJSONObject json=StructuredForm.get(req); \nreporters.rebuild(req,json,MavenReporters.getConfigurableList(),\" reporter\");- publishers.rebuild(req,json,BuildStepDescriptor.filter(BuildStep.PUBLISHERS,getClass()),\"publisher\");+ publishers.rebuild(req,json,BuildStepDescriptor.filter(BuildStep.PUBLISHERS,this.getClass()),\"publisher\");updateTransientActions();//to pick up transient actions from builder,publisher,etc.} \ndiff --git a/core/src/main/java/hudson/model/Project.java  b/core/src/main/java/hudson/model/Project.java \nprotected void submit(StaplerRequest req,StaplerResponse rsp)throws IOExcept \nbuildWrappers=buildDescribable(req,BuildWrappers.getFor(this),\"wrapper\");builders=Descriptor.newInstancesFromHeteroList(req,StructuredForm.get(req),\"builder\", BuildStep.BUILDERS);-publishers=buildDescribable(req,BuildStepDescriptor.filter(BuildStep.PUBLISHERS,getClass()),\"publisher\");+ publishers=buildDescribable(req,BuildStepDescriptor.filter(BuildStep.PUBLISHERS,this.getClass()),\"publisher\");updateTransientActions();//to pick up transient actions from builder,publisher,etc.} \n"
    },
    {
        "sim_msg": "Implement the w3c timeouts command",
        "sim_diff": "diff --git a/java/client/src/org/openqa/selenium/remote/RemoteWebDriver.java \nppp b/java/client/src/org/openqa/selenium/remote/RemoteWebDriver.java \npublic void activateEngine(String engine){ \npublic Timeouts implicitlyWait(long time,TimeUnit unit){ \nexecute(DriverCommand.SET_TIMEOUT,ImmutableMap.of(-\"type\",\"implicit\",-\" ms\", TimeUnit.MILLISECONDS.convert(time,unit)));+\" implicit\", TimeUnit.MILLISECONDS.convert(time,unit))); \nreturn this;} \npublic Timeouts setScriptTimeout(long time,TimeUnit unit){ \nexecute(DriverCommand.SET_TIMEOUT,ImmutableMap.of(-\"type\",\"script\",-\" ms\", TimeUnit.MILLISECONDS.convert(time,unit)));+\" script\", TimeUnit.MILLISECONDS.convert(time,unit))); \nreturn this;} \npublic Timeouts pageLoadTimeout(long time,TimeUnit unit){ \nexecute(DriverCommand.SET_TIMEOUT,ImmutableMap.of(-\"type\",\"page load\",-\" ms\", TimeUnit.MILLISECONDS.convert(time,unit)));+\" page load\", TimeUnit.MILLISECONDS.convert(time,unit))); \nreturn this;}}//timeouts class.diff --git a/java/client/src/org/openqa/selenium/remote/http/JsonHttpCommandCodec.java \nppp b/java/client/src/org/openqa/selenium/remote/http/JsonHttpCommandCodec.java \nimport com.google.common.collect.ImmutableMap;+ import org.openqa.selenium.InvalidArgumentException;import org.openqa.selenium.remote.DriverCommand;import java.util.Map;public JsonHttpCommandCodec(){. put(\" handle\",\"current\").build();+ case DriverCommand.SET_TIMEOUT:+ if(parameters.size()!= 1){+throw new InvalidArgumentException(+\"The JSON wire protocol only supports setting one time out at a time\");+}+ Map.Entry<String,?>entry=parameters.entrySet().iterator().next();+ String type=entry.getKey();+ if(\" pageLoad\". equals(type)){+ type=\" page load\";+}+return ImmutableMap.of(\" type\", type,\" ms\", entry.getValue());+case DriverCommand.SWITCH_TO_WINDOW:return ImmutableMap.< String,Object>builder().put(\" name\", parameters.get(\" handle\"))diff --git a/java/client/test/org/openqa/selenium/PageLoadingTest.java \nppp b/java/client/test/org/openqa/selenium/PageLoadingTest.java \npublic void testShouldNotHangIfDocumentOpenCallIsNeverFollowedByDocumentCloseCal@Ignore(value={ HTMLUNIT,SAFARI,PHANTOMJS,FIREFOX}, \nreason=\" Safari:see issue 687,comment 41;PHANTOMJS:not tested\", issues={ 687})@NeedsLocalEnvironment+@ NotYetImplemented(MARIONETTE)@ NoDriverAfterTest@Test \npublic void testPageLoadTimeoutCanBeChanged(){private void testPageLoadTimeoutIsEnforced(long webDriverPageLoadTimeout){ \nlong start=System.currentTimeMillis();try{- driver-. get(appServer.whereIs(\" sleep?time=\"+( webDriverPageLoadTimeout+pageLoadTimeBuffer)));+driver.get(appServer.whereIs(+\"sleep?time=\"+( webDriverPageLoadTimeout+pageLoadTimeBuffer))); \nfail(\" I should have timed out after\"+ webDriverPageLoadTimeout+\" seconds\");} catch(RuntimeException e){ \nlong end=System.currentTimeMillis() ; \n",
        "org_diff": "diff --git a/java/client/src/org/openqa/selenium/support/events/EventFiringWebDriver.java  b/java/client/src/org/openqa/selenium/support/events/EventFiringWebDriver.java \npublic Timeouts timeouts(){} \npublic ImeHandler ime(){- throw new UnsupportedOperationException(\" Driver does not support IME interactions\");+ return options.ime();}@Beta \n"
    },
    {
        "sim_msg": "Be careful with MultiGuardNodes in GraphUtil . killCFGInner",
        "sim_diff": "diff --git a/compiler/src/org.graalvm.compiler.nodes/src/org/graalvm/compiler/nodes/util/GraphUtil.java \nppp b/compiler/src/org.graalvm.compiler.nodes/src/org/graalvm/compiler/nodes/util/GraphUtil.java \nimport org.graalvm.compiler.nodes.ValuePhiNode;import org.graalvm.compiler.nodes.ValueProxyNode;import org.graalvm.compiler.nodes.WithExceptionNode;+ import org.graalvm.compiler.nodes.extended.MultiGuardNode;import org.graalvm.compiler.nodes.java.LoadIndexedNode;import org.graalvm.compiler.nodes.java.MethodCallTargetNode;import org.graalvm.compiler.nodes.java.MonitorIdNode;private static void killCFGInner(FixedNode node){ \ndebug.dump(DebugContext.DETAILED_LEVEL,node.graph(),\" After fixing merges(killCFG%s)\",node);// Mark non-fixed nodes-markUsages(markedNodes);+markUsagesForKill(markedNodes);// Detach marked nodes from non-marked nodes \nfor(Node marked:markedNodes){ \nprivate static void fixSurvivingAffectedMerges(EconomicSet<Node>markedNodes,Ec}}-private static void markUsages(EconomicSet<Node>markedNodes){+private static void markUsagesForKill(EconomicSet<Node>markedNodes){ \nNodeStack workStack=new NodeStack(markedNodes.size()+4); \nfor(Node marked:markedNodes){ \nworkStack.push(marked);}+ EconomicSet<MultiGuardNode>unmarkedMultiGuards=EconomicSet.create();while(! workStack.isEmpty()){ \nNode marked=workStack.pop();for(Node usage:marked.usages()){-if(! markedNodes.contains(usage)){+ boolean doMark=true;+ if(usage instanceof MultiGuardNode){+//Only mark a MultiGuardNode for deletion if all of its guards are marked for+//deletion.Otherwise,we would kill nodes outside the path to be killed.+ MultiGuardNode multiGuard=( MultiGuardNode)usage;+ for(Node guard:multiGuard.inputs()){+if(! markedNodes.contains(guard)){+ doMark=false;+ unmarkedMultiGuards.add(multiGuard);+break;+}+}+}+ if(doMark&&!markedNodes.contains(usage)){workStack.push(usage); \nmarkedNodes.add(usage);}}+//Detach unmarked multi guards from the marked node+for(MultiGuardNode multiGuard:unmarkedMultiGuards){+multiGuard.replaceFirstInput(marked,null);+}+unmarkedMultiGuards.clear();} \n} \n",
        "org_diff": "diff --git a/compiler/src/org.graalvm.compiler.nodes/src/org/graalvm/compiler/nodes/util/GraphUtil.java  b/compiler/src/org.graalvm.compiler.nodes/src/org/graalvm/compiler/nodes/util/GraphUtil.java \nprivate static void markUsagesForKill(EconomicSet<Node>markedNodes){ \nfor(Node marked:markedNodes){ \nworkStack.push(marked);}- EconomicSet<MultiGuardNode>unmarkedMultiGuards=EconomicSet.create();+ ArrayList<MultiGuardNode>unmarkedMultiGuards=new ArrayList<>();while(! workStack.isEmpty()){ \nNode marked=workStack.pop();for(Node usage:marked.usages()){ \nprivate static void markUsagesForKill(EconomicSet<Node>markedNodes){ \nif(! markedNodes.contains(guard)){doMark=false;unmarkedMultiGuards.add(multiGuard);-break;}}} \n"
    },
    {
        "sim_msg": "ProGuard config for @ Subscribe annotation",
        "sim_diff": "diff --git a/HOWTO.md \nppp b/HOWTO.md \nProGuard obfuscates method names.However,the onEvent methods must not renamed \npublic void onEvent*(**);}+#EventBus 3.0 annotation+- keepclassmembers class*{+@ de.greenrobot.event.Subscribe<methods>;+}+- keep enum de.greenrobot.event.ThreadMode{*;}+# Only required if you use AsyncExecutor-keepclassmembers class*extends de.greenrobot.event.util.ThrowableFailureEvent{< init>( java.lang.Throwable); \n",
        "org_diff": "diff --git a/HOWTO.md  b/HOWTO.md \nIt's also possible to remove previously posted sticky events using one of the re \nProGuard configuration \ndiff --gitdiff --gitdiff --gitdiff --gitdiff --gitdiff --gitdiff --git-ProGuard obfuscates method names.However,the onEvent methods must not renamed because they are accessed using reflection.Use the following snip in your ProGuard configuration file(proguard.cfg):-< pre>< code>- keepclassmembers class**{++```+- keepclassmembers class**{public void onEvent*(**);}ProGuard obfuscates method names.However,the onEvent methods must not renamed-keepclassmembers class*extends de.greenrobot.event.util.ThrowableFailureEvent{< init>( java.lang.Throwable);}-</ code></pre>+```AsyncExecutor \n"
    },
    {
        "sim_msg": "Refactor + RN 0 . 56",
        "sim_diff": "diff --git a/src/android/build.gradle \nppp b/src/android/build.gradle+def safeExtGet(prop,fallback){+rootProject.ext.has(prop)? rootProject.ext.get(prop): fallback+}+apply plugin:' com.android.library'apply from:' gradle-maven-push.gradle'- def DEFAULT_COMPILE_SDK_VERSION=26-def DEFAULT_BUILD_TOOLS_VERSION=\" 26.0.1\"- def DEFAULT_TARGET_SDK_VERSION=26-def DEFAULT_MIN_SDK_VERSION=16-android{- compileSdkVersion rootProject.hasProperty(' compileSdkVersion')?rootProject.compileSdkVersion:DEFAULT_COMPILE_SDK_VERSION-buildToolsVersion rootProject.hasProperty(' buildToolsVersion')?rootProject.buildToolsVersion:DEFAULT_BUILD_TOOLS_VERSION+compileSdkVersion safeExtGet(' compileSdkVersion', 26)+ buildToolsVersion safeExtGet(' buildToolsVersion','26.0.3') \npublishNonDefault true \ndefaultConfig{- minSdkVersion rootProject.hasProperty(' minSdkVersion')?rootProject.minSdkVersion:DEFAULT_MIN_SDK_VERSION-targetSdkVersion rootProject.hasProperty(' targetSdkVersion')?rootProject.targetSdkVersion:DEFAULT_TARGET_SDK_VERSION+minSdkVersion safeExtGet(' minSdkVersion', 16)+ targetSdkVersion safeExtGet(' targetSdkVersion', 26)} \nlintOptions { \n",
        "org_diff": "diff --git a/src/android/build.gradle  b/src/android/build.gradle \napply plugin:' com.android.library'apply from:' gradle-maven-push.gradle'+ def DEFAULT_COMPILE_SDK_VERSION=26+def DEFAULT_BUILD_TOOLS_VERSION=\" 26.0.1\"+ def DEFAULT_TARGET_SDK_VERSION=26+def DEFAULT_MIN_SDK_VERSION=16+android{- compileSdkVersion 26-buildToolsVersion\"26.0.1\"+ compileSdkVersion rootProject.hasProperty(' compileSdkVersion')?rootProject.compileSdkVersion:DEFAULT_COMPILE_SDK_VERSION+buildToolsVersion rootProject.hasProperty(' buildToolsVersion')?rootProject.buildToolsVersion:DEFAULT_BUILD_TOOLS_VERSION \npublishNonDefault true \ndefaultConfig{- minSdkVersion 16-targetSdkVersion 26+minSdkVersion rootProject.hasProperty(' minSdkVersion')?rootProject.minSdkVersion:DEFAULT_MIN_SDK_VERSION+targetSdkVersion rootProject.hasProperty(' targetSdkVersion')?rootProject.targetSdkVersion:DEFAULT_TARGET_SDK_VERSION}lintOptions{android{} \ndependencies{- provided\"com.facebook.react:react-native:+\"- compile'com.airbnb.android:lottie:2.5.+'+ compileOnly\"com.facebook.react:react-native:+\"+ implementation'com.airbnb.android:lottie:2.5.+'} \n"
    },
    {
        "sim_msg": "Only load term statistics if required",
        "sim_diff": "diff --git a/core/src/main/java/org/elasticsearch/action/termvectors/TermVectorsWriter.java \nppp b/core/src/main/java/org/elasticsearch/action/termvectors/TermVectorsWriter.java \nvoid setFields(Fields termVectorsByField,Set<String>selectedFields,EnumSet<Fl \nfinal boolean useDocsAndPos=positions|| offsets|| payloads;while(iterator.next()!= null){// iterate all terms of the current field \nBytesRef termBytesRef=iterator.term();- boolean foundTerm=topLevelIterator.seekExact(termBytesRef); \nTerm term=new Term(field,termBytesRef);// with filtering we only keep the best terms \nvoid setFields(Fields termVectorsByField,Set<String>selectedFields,EnumSet<Fl \nfinal TermStatistics statistics=dfs.termStatistics().get(term); \nwriteTermStatistics(statistics== null?new TermStatistics(termBytesRef,0,0): statistics);}else{+ boolean foundTerm=topLevelIterator.seekExact(termBytesRef); \nif(foundTerm){ \nwriteTermStatistics(topLevelIterator);}else { \n",
        "org_diff": "diff --git a/elasticsearch/src/main/java/org/elasticsearch/xpack/prelert/job/persistence/ElasticsearchMappings.java  b/elasticsearch/src/main/java/org/elasticsearch/xpack/prelert/job/persistence/ElasticsearchMappings.java \nprivate ElasticsearchMappings(){*<li>AnomalyCause.by_field_value</ li>*<li>AnomalyCause.partition_field_value</ li>*<li>AnomalyCause.over_field_value</ li>-*< li>Influencer.influencer_field_values</ li>+*< li>AnomalyRecord.Influencers.influencer_field_values</ li>+*< li>Influencer.influencer_field_value</ li>*</ ul>**@ param termFieldNames All the term fields(by,over,partition)and influencers \nprivate static XContentBuilder addInfluencerFieldsToMapping(XContentBuilder buil.endObject().startObject(Influencer.INFLUENCER_FIELD_VALUE.getPreferredName()). field(TYPE,KEYWORD)+.field(COPY_TO,ALL_FIELD_VALUES). endObject();return builder ; \n"
    },
    {
        "sim_msg": "add 0 . 18 . 5 version",
        "sim_diff": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/Version.java \nppp b/modules/elasticsearch/src/main/java/org/elasticsearch/Version.java \npublic static final Version V_0_18_3=new Version(V_0_18_3_ID,false); \npublic static final int V_0_18_4_ID=/*00*/ 180499;public static final Version V_0_18_4=new Version(V_0_18_4_ID,false);+public static final int V_0_18_5_ID=/*00*/ 180599;+ public static final Version V_0_18_5=new Version(V_0_18_5_ID,false); \npublic static final int V_0_19_0_ID=/*00*/ 190099;public static final Version V_0_19_0=new Version(V_0_19_0_ID,true); \nprivate static Version fromId(int id){ \nreturn V_0_18_3;case V_0_18_4_ID:return V_0_18_4;+ case V_0_18_5_ID:+ return V_0_18_5;case V_0_19_0_ID:return V_0_19_0;default : \n",
        "org_diff": "diff --git a/modules/elasticsearch/src/main/java/org/elasticsearch/Version.java  b/modules/elasticsearch/src/main/java/org/elasticsearch/Version.java \npublic static final Version V_0_18_4=new Version(V_0_18_4_ID,false); \npublic static final int V_0_18_5_ID=/*00*/ 180599;public static final Version V_0_18_5=new Version(V_0_18_5_ID,false);+public static final int V_0_18_6_ID=/*00*/ 180699;+ public static final Version V_0_18_6=new Version(V_0_18_6_ID,false); \npublic static final int V_0_19_0_ID=/*00*/ 190099;public static final Version V_0_19_0=new Version(V_0_19_0_ID,true); \nprivate static Version fromId(int id){ \nreturn V_0_18_4;case V_0_18_5_ID:return V_0_18_5;+ case V_0_18_6_ID:+ return V_0_18_6;case V_0_19_0_ID:return V_0_19_0;default : \n"
    },
    {
        "sim_msg": "Permit cc_test to run on darwin .",
        "sim_diff": "diff --git a/src/main/java/com/google/devtools/build/lib/rules/cpp/CcBinary.java \nppp b/src/main/java/com/google/devtools/build/lib/rules/cpp/CcBinary.java \nimport com.google.devtools.build.lib.collect.nestedset.Order;import com.google.devtools.build.lib.packages.TargetUtils;import com.google.devtools.build.lib.rules.RuleConfiguredTargetFactory;+ import com.google.devtools.build.lib.rules.apple.Platform;import com.google.devtools.build.lib.rules.cpp.CcToolchainFeatures.FeatureConfiguration;import com.google.devtools.build.lib.rules.cpp.CppConfiguration.DynamicMode;import com.google.devtools.build.lib.rules.cpp.Link.LinkStaticness;import com.google.devtools.build.lib.rules.cpp.Link.LinkTargetType;import com.google.devtools.build.lib.rules.cpp.LinkerInputs.LibraryToLink;+ import com.google.devtools.build.lib.rules.test.ExecutionInfoProvider;import com.google.devtools.build.lib.rules.test.InstrumentedFilesProvider;import com.google.devtools.build.lib.syntax.Type;import com.google.devtools.build.lib.util.FileTypeSet;public static ConfiguredTarget init(CppSemantics semantics,RuleContext ruleCont \nsourceFileMap.put(source.getExecPath(),source);}}-++//Support test execution on darwin.+ if(Platform.isApplePlatform(cppConfiguration.getTargetCpu())+&& TargetUtils.isTestRule(ruleContext.getRule())){+ ruleBuilder.add(+ ExecutionInfoProvider.class,+ new ExecutionInfoProvider(ImmutableMap.of(\" requires-darwin\",\"\")));+}+return ruleBuilder.add(RunfilesProvider.class,RunfilesProvider.simple(runfiles)).add ( \n",
        "org_diff": "diff --git a/src/main/java/com/google/devtools/build/lib/rules/objc/ExperimentalObjcLibrary.java  b/src/main/java/com/google/devtools/build/lib/rules/objc/ExperimentalObjcLibrary.java \npackage com.google.devtools.build.lib.rules.objc;+ import static com.google.devtools.build.lib.rules.objc.ObjcProvider.DEFINE;import static com.google.devtools.build.lib.rules.objc.XcodeProductType.LIBRARY_STATIC;import com.google.common.collect.ImmutableList;import com.google.devtools.build.lib.rules.cpp.CppRuleClasses;import com.google.devtools.build.lib.rules.cpp.Link.LinkTargetType;import com.google.devtools.build.lib.rules.cpp.PrecompiledFiles;+ import com.google.devtools.build.lib.rules.objc.ObjcCommon.ResourceAttributes;import java.util.Collection;/** Implementation for experimental_objc_library.*/public ConfiguredTarget create(RuleContext ruleContext). addSources(arcSources,ImmutableMap.of(\" objc_arc\",\"\")).addSources(nonArcSources,ImmutableMap.of(\" no_objc_arc\",\"\")).addSources(privateHdrs)+.addDefines(common.getObjcProvider().get(DEFINE)).enableCompileProviders().addPublicHeaders(publicHdrs). addPrecompiledFiles(precompiledFiles)public ConfiguredTarget create(RuleContext ruleContext). registerActions(xcodeProviderBuilder.build()); \nreturn ObjcRuleClasses.ruleConfiguredTarget(ruleContext,filesToBuild.build())+.addProvider(ObjcProvider.class,common.getObjcProvider()). addProviders(info.getProviders()). addProvider(XcodeProvider.class,xcodeProviderBuilder.build()). build();private void validateAttributes(RuleContext ruleContext){}}-private static ObjcCommon common(+/**+*Constructs an{@ link ObjcCommon}instance based on the attributes of the given rule context.+*/+private ObjcCommon common(RuleContext ruleContext,CompilationAttributes compilationAttributes,CompilationArtifacts compilationArtifacts){ \nreturn new ObjcCommon.Builder(ruleContext). setCompilationAttributes(compilationAttributes)+.setResourceAttributes(new ResourceAttributes(ruleContext))+. addDefines(ruleContext.getTokenizedStringListAttr(\" defines\")). setCompilationArtifacts(compilationArtifacts)-.addDepObjcProviders(ruleContext.getPrerequisites(\" deps\", Mode.TARGET,ObjcProvider.class))+. addDeps(ruleContext.getPrerequisites(\" deps\", Mode.TARGET))+. addRuntimeDeps(ruleContext.getPrerequisites(\" runtime_deps\", Mode.TARGET))+. setIntermediateArtifacts(ObjcRuleClasses.intermediateArtifacts(ruleContext)).build();} \n"
    },
    {
        "sim_msg": "Update logstash mappings to use pipeline . id + correct metric types ( elastic / x - pack - elasticsearch )",
        "sim_diff": "diff --git a/plugin/src/main/resources/monitoring-logstash.json \nppp b/plugin/src/main/resources/monitoring-logstash.json\"pipelines\":{\" type\":\"nested\",\"properties\":{-\"name\":{+\"id\":{\" type\":\"keyword\"},\" hash\":{\" events_out\":{\" type\":\"long\"},\" duration_in_millis\":{\" type\":\"long\"},\" queue_push_duration_in_millis\":{\" type\":\"long\"},-\"counters\":{+\"long_counters\":{\" type\":\"nested\",\"properties\":{\" name\":{\" type\":\"double\"}}-},-\" text_gauges\":{-\"type\":\"nested\",-\" properties\":{-\"name\":{-\"type\":\"keyword\"-},-\" value\":{-\"type\":\"keyword\"-}-}-},-\" boolean_gauges\":{-\"type\":\"nested\",-\" properties\":{-\"name\":{-\"type\":\"keyword\"-},-\" value\":{-\"type\":\"boolean\"-}-}}}},},\" pipeline\":{\" properties\":{-\"name\":{+\"id\":{\" type\":\"keyword\"},\" hash\": { \n",
        "org_diff": "diff --git a/plugin/src/main/resources/monitoring-logstash.json  b/plugin/src/main/resources/monitoring-logstash.json\"name\":{\" type\":\"keyword\"},+\"ephemeral_id\":{+\"type\":\"keyword\"+},\"host\":{\" type\":\"keyword\"},\" hash\":{\" type\":\"keyword\"},+\"ephemeral_id\":{+\"type\":\"keyword\"+},\"events\":{\" properties\":{-\"input\":{+\"in\":{\" type\":\"long\"},-\"filter\":{+\"filtered\":{\" type\":\"long\"},-\"output\":{+\"out\":{\" type\":\"long\"} \n} \n"
    },
    {
        "sim_msg": "Add user - configurable number of simultaneously playing audio sources",
        "sim_diff": "diff --git a/backends/gdx-backend-lwjgl/src/com/badlogic/gdx/backends/lwjgl/LwjglApplication.java \nppp b/backends/gdx-backend-lwjgl/src/com/badlogic/gdx/backends/lwjgl/LwjglApplication.java \npackage com.badlogic.gdx.backends.lwjgl;+ import java.awt.Canvas;+ import java.util.HashMap;+ import java.util.Map;++import org.lwjgl.LWJGLException;+ import org.lwjgl.opengl.Display;+ \nimport com.badlogic.gdx.Application;import com.badlogic.gdx.ApplicationListener;import com.badlogic.gdx.Audio;import com.badlogic.gdx.utils.Clipboard;import com.badlogic.gdx.utils.GdxRuntimeException;- import java.awt.Canvas;- import java.util.HashMap;- import java.util.Map;--import org.lwjgl.LWJGLException;- import org.lwjgl.opengl.Display;-/**An OpenGL surface fullscreen or in a lightweight window.*/public class LwjglApplication implements Application{protected final LwjglGraphics graphics;public LwjglApplication(ApplicationListener listener,LwjglApplicationConfigura \nthis.graphics=graphics;if(! LwjglApplicationConfiguration.disableAudio)- audio=new OpenALAudio(16,config.audioDeviceBufferCount,config.audioDeviceBufferSize);+audio=new OpenALAudio(config.audioDeviceSimultaneousSources,config.audioDeviceBufferCount,+ config.audioDeviceBufferSize); \nfiles=new LwjglFiles();input=new LwjglInput();net=new LwjglNet();private static LwjglApplicationConfiguration createConfig(String title,int wid \nprivate void initialize(){mainLoopThread=new Thread(\" LWJGL Application\"){+@Override \npublic void run(){graphics.setVSync(graphics.config.vSyncEnabled); \ntry{public void debug(String tag,String message,Throwable exception){}}+@ Override \npublic void log(String tag,String message){ \nif(logLevel>= LOG_INFO){ \nSystem.out.println(tag+\":\"+message); \ndiff --git a/backends/gdx-backend-lwjgl/src/com/badlogic/gdx/backends/lwjgl/LwjglApplicationConfiguration.java \nppp b/backends/gdx-backend-lwjgl/src/com/badlogic/gdx/backends/lwjgl/LwjglApplicationConfiguration.java \npackage com.badlogic.gdx.backends.lwjgl;+ import java.awt.GraphicsDevice;+ import java.awt.GraphicsEnvironment;+ import java.util.ArrayList;+ \nimport com.badlogic.gdx.Application;import com.badlogic.gdx.Files.FileType;import com.badlogic.gdx.Graphics;import com.badlogic.gdx.graphics.Color;import com.badlogic.gdx.utils.Array;- import java.awt.GraphicsDevice;- import java.awt.GraphicsEnvironment;- import java.util.ArrayList;- \npublic class LwjglApplicationConfiguration{/** If true,OpenAL will not be used.This means{@ link Application#getAudio()}returns null and the gdx-openal.jar and OpenAL*natives are not needed.*/public boolean forceExit=true;/** whether the window is resizable**/public boolean resizable=true;+/**the maximum number of sources that can be played simultaneously*/+public int audioDeviceSimultaneousSources=16;/** the audio device buffer size in samples**/public int audioDeviceBufferSize=512;/** the audio device buffer count** / \n",
        "org_diff": "diff --git a/backends/gdx-backend-lwjgl/src/com/badlogic/gdx/backends/lwjgl/LwjglApplication.java  b/backends/gdx-backend-lwjgl/src/com/badlogic/gdx/backends/lwjgl/LwjglApplication.java \npackage com.badlogic.gdx.backends.lwjgl;+ import java.awt.Canvas;+ import java.util.HashMap;+ import java.util.Map;++import org.lwjgl.LWJGLException;+ import org.lwjgl.opengl.Display;+ \nimport com.badlogic.gdx.Application;import com.badlogic.gdx.ApplicationListener;import com.badlogic.gdx.Audio;import com.badlogic.gdx.utils.Clipboard;import com.badlogic.gdx.utils.GdxRuntimeException;- import java.awt.Canvas;- import java.util.HashMap;- import java.util.Map;--import org.lwjgl.LWJGLException;- import org.lwjgl.opengl.Display;-/**An OpenGL surface fullscreen or in a lightweight window.*/public class LwjglApplication implements Application{protected final LwjglGraphics graphics;public LwjglApplication(ApplicationListener listener,LwjglApplicationConfigura \nthis.graphics=graphics;if(! LwjglApplicationConfiguration.disableAudio)- audio=new OpenALAudio(16,config.audioDeviceBufferCount,config.audioDeviceBufferSize);+audio=new OpenALAudio(config.audioDeviceSimultaneousSources,config.audioDeviceBufferCount,+ config.audioDeviceBufferSize); \nfiles=new LwjglFiles();input=new LwjglInput();net=new LwjglNet();private static LwjglApplicationConfiguration createConfig(String title,int wid \nprivate void initialize(){mainLoopThread=new Thread(\" LWJGL Application\"){+@Override \npublic void run(){graphics.setVSync(graphics.config.vSyncEnabled); \ntry{public void debug(String tag,String message,Throwable exception){}}+@ Override \npublic void log(String tag,String message){ \nif(logLevel>= LOG_INFO){ \nSystem.out.println(tag+\":\"+message); \ndiff --git a/backends/gdx-backend-lwjgl/src/com/badlogic/gdx/backends/lwjgl/LwjglApplicationConfiguration.java  b/backends/gdx-backend-lwjgl/src/com/badlogic/gdx/backends/lwjgl/LwjglApplicationConfiguration.java \npackage com.badlogic.gdx.backends.lwjgl;+ import java.awt.GraphicsDevice;+ import java.awt.GraphicsEnvironment;+ import java.util.ArrayList;+ \nimport com.badlogic.gdx.Application;import com.badlogic.gdx.Files.FileType;import com.badlogic.gdx.Graphics;import com.badlogic.gdx.graphics.Color;import com.badlogic.gdx.utils.Array;- import java.awt.GraphicsDevice;- import java.awt.GraphicsEnvironment;- import java.util.ArrayList;- \npublic class LwjglApplicationConfiguration{/** If true,OpenAL will not be used.This means{@ link Application#getAudio()}returns null and the gdx-openal.jar and OpenAL*natives are not needed.*/public boolean forceExit=true;/** whether the window is resizable**/public boolean resizable=true;+/**the maximum number of sources that can be played simultaneously*/+public int audioDeviceSimultaneousSources=16;/** the audio device buffer size in samples**/public int audioDeviceBufferSize=512;/** the audio device buffer count** / \n"
    },
    {
        "sim_msg": "Have initMonitorStack use a given MonitorStack .",
        "sim_diff": "diff --git a/src/com.oracle.truffle.espresso/src/com/oracle/truffle/espresso/nodes/EspressoRootNode.java \nppp b/src/com.oracle.truffle.espresso/src/com/oracle/truffle/espresso/nodes/EspressoRootNode.java \npublic boolean usesMonitors(){return monitorSlot!= null;}-final void initMonitorStack(VirtualFrame frame){-frame.setObject(monitorSlot,new MonitorStack());+final void initMonitorStack(VirtualFrame frame,MonitorStack monitorStack){+frame.setObject(monitorSlot,monitorStack);}final void monitorExit(VirtualFrame frame,StaticObject monitor){ \nprivate void enterSynchronized(VirtualFrame frame,StaticObject monitor){ \nInterpreterToVM.monitorEnter(monitor,getMeta()); \nMonitorStack monitorStack=new MonitorStack();monitorStack.synchronizedMethodMonitor=monitor;- frame.setObject(super.monitorSlot,monitorStack);-+ initMonitorStack(frame,monitorStack);}private void exitSynchronized(@ SuppressWarnings(\" unused\") VirtualFrame frame,StaticObject monitor){ \npublic EspressoRootNode split(){@ Override \npublic Object execute(VirtualFrame frame){ \nif(usesMonitors()){-initMonitorStack(frame);+initMonitorStack(frame,new MonitorStack());}return methodNode.execute(frame);}}-private static class MonitorStack{+ private static final class MonitorStack{private static final int DEFAULT_CAPACITY=4;private StaticObject synchronizedMethodMonitor;private void abort(Meta meta){}}-StaticObject[] getMonitors(){+ private StaticObject[] getMonitors(){if(synchronizedMethodMonitor== null){ \nreturn monitors;} else { \n",
        "org_diff": "diff --git a/src/com.oracle.truffle.espresso/src/com/oracle/truffle/espresso/nodes/EspressoRootNode.java  b/src/com.oracle.truffle.espresso/src/com/oracle/truffle/espresso/nodes/EspressoRootNode.java \npublic Object execute(VirtualFrame frame){ \nBytecodeNode bytecodeNode=getBytecodeNode();bytecodeNode.methodMonitorEnter(frame,monitor);}else{+// TODO(Gregersen)- register monitors on frames for non-bytecode methods \nInterpreterToVM.monitorEnter(monitor);}Object result;public Object execute(VirtualFrame frame){ \ngetBytecodeNode().monitorExit(frame,monitor);}} else{+// TODO(Gregersen)- exit monitors on frames for non-bytecode methods \nInterpreterToVM.monitorExit(monitor);}} \n"
    },
    {
        "sim_msg": "Decouple XContentGenerator and JsonXContentGenerator from BytesReference ( elastic / x - pack - elasticsearch )",
        "sim_diff": "diff --git a/plugin/core/src/main/java/org/elasticsearch/xpack/core/ml/action/PreviewDatafeedAction.java \nppp b/plugin/core/src/main/java/org/elasticsearch/xpack/core/ml/action/PreviewDatafeedAction.java \npublic void writeTo(StreamOutput out)throws IOException{@ Override \npublic XContentBuilder toXContent(XContentBuilder builder,Params params)throws IOException{- builder.rawValue(preview,XContentType.JSON);+builder.rawValue(preview.streamInput(),XContentType.JSON); \nreturn builder;} \n",
        "org_diff": "diff --git a/x-pack/plugin/core/src/main/java/org/elasticsearch/xpack/core/dataframe/action/PreviewDataFrameTransformAction.java  b/x-pack/plugin/core/src/main/java/org/elasticsearch/xpack/core/dataframe/action/PreviewDataFrameTransformAction.java \npublic static Request fromXContent(final XContentParser parser)throws IOExcepti.createParser(parser.getXContentRegistry(),LoggingDeprecationHandler.INSTANCE,BytesReference.bytes(xContentBuilder). streamInput())){- return new Request(DataFrameTransformConfig.fromXContent(newParser,\" transform-preview\", true));+ return new Request(DataFrameTransformConfig.fromXContent(newParser,\" transform-preview\", false));}}diff --git a/x-pack/plugin/src/test/resources/rest-api-spec/test/data_frame/preview_transforms.yml  b/x-pack/plugin/src/test/resources/rest-api-spec/test/data_frame/preview_transforms.yml \nsetup:- match:{ preview.2.airline:foo}- match:{ preview.2.by-hour:\" 2017-02-49 01\"}-match:{ preview.2.avg_response:42.0}++diff --git+\" Test preview transform with invalid config\":+- do:+ catch:/\\[ data_frame_terms_group\\] unknown field\\[ not_a_terms_param\\]/+ data_frame.preview_data_frame_transform:+ body:>+{+\" source\":\"airline-data\",+\" pivot\":{+\"group_by\":{\" airline\":{\" terms\":{\" not_a_terms_param\":\"airline\"}}},+\"aggs\":{\" avg_response\":{\" avg\":{\" field\":\"responsetime\"}}}+}+} \n"
    },
    {
        "sim_msg": "Added version 2 . 4 . 0 to Version",
        "sim_diff": "diff --git a/core/src/main/java/org/elasticsearch/Version.java \nppp b/core/src/main/java/org/elasticsearch/Version.java \npublic static final Version V_2_2_1=new Version(V_2_2_1_ID,org.apache.lucene.util.Version.LUCENE_5_4_1); \npublic static final int V_2_3_0_ID=2030099;public static final Version V_2_3_0=new Version(V_2_3_0_ID,org.apache.lucene.util.Version.LUCENE_5_5_0);+public static final int V_2_4_0_ID=2040099;+ public static final Version V_2_4_0=new Version(V_2_4_0_ID,org.apache.lucene.util.Version.LUCENE_5_5_0); \npublic static final int V_5_0_0_ID=5000099;public static final Version V_5_0_0=new Version(V_5_0_0_ID,org.apache.lucene.util.Version.LUCENE_6_0_0); \npublic static final Version CURRENT=V_5_0_0;public static Version fromId(int id){ \nswitch(id){ \ncase V_5_0_0_ID:return V_5_0_0;+ case V_2_4_0_ID:+ return V_2_4_0;case V_2_3_0_ID:return V_2_3_0;case V_2_2_1_ID : \n",
        "org_diff": "diff --git a/core/src/main/java/org/elasticsearch/Version.java  b/core/src/main/java/org/elasticsearch/Version.java \npublic static final Version V_2_2_1=new Version(V_2_2_1_ID,org.apache.lucene.util.Version.LUCENE_5_4_1); \npublic static final int V_2_3_0_ID=2030099;public static final Version V_2_3_0=new Version(V_2_3_0_ID,org.apache.lucene.util.Version.LUCENE_5_5_0);-public static final int V_2_4_0_ID=2040099;- public static final Version V_2_4_0=new Version(V_2_4_0_ID,org.apache.lucene.util.Version.LUCENE_5_5_0); \npublic static final int V_5_0_0_ID=5000099;public static final Version V_5_0_0=new Version(V_5_0_0_ID,org.apache.lucene.util.Version.LUCENE_6_0_0); \npublic static final Version CURRENT=V_5_0_0;public static Version fromId(int id){ \nswitch(id){ \ncase V_5_0_0_ID:return V_5_0_0;- case V_2_4_0_ID:- return V_2_4_0;case V_2_3_0_ID:return V_2_3_0;case V_2_2_1_ID : \n"
    },
    {
        "sim_msg": "PG permission management",
        "sim_diff": "diff --git a/plugins/org.jkiss.dbeaver.ext.postgresql.ui/src/org/jkiss/dbeaver/ext/postgresql/ui/editors/PostgresRolePrivilegesEditor.java \nppp b/plugins/org.jkiss.dbeaver.ext.postgresql.ui/src/org/jkiss/dbeaver/ext/postgresql/ui/editors/PostgresRolePrivilegesEditor.java \nprivate void updateCurrentPrivileges(boolean grant,PostgrePrivilegeType privile \nreturn;}+PostgrePrivilegeOwner databaseObject=getDatabaseObject();+ \nfor(int i=0;i<currentObjects.length;i++){ \nDBSObject currentObject=currentObjects[i]; \nPostgrePrivilege permission=currentPermissions[i]; \nprivate void updateCurrentPrivileges(boolean grant,PostgrePrivilegeType privile \nobjectName=permissionsOwner.getName();} \npermission=new PostgreRolePrivilege(- getDatabaseObject(),+ databaseObject,kind,permissionsOwner.getSchema().getName(),objectName,Collections.emptyList());}else{+ String currentUser=databaseObject.getDataSource().getContainer().getActualConnectionConfiguration().getUserName();+ PostgrePrivilegeGrant privGrant=new PostgrePrivilegeGrant(+ currentUser,+ currentObject.getName(),+ databaseObject.getDatabase().getName(),+ databaseObject.getSchema().getName(),+ databaseObject.getName(),+ privilegeType,+ false,+ false); \npermission=new PostgreObjectPrivilege(- getDatabaseObject(),+ databaseObject,currentObject.getName(),- Collections.emptyList());+Collections.singletonList(privGrant));}// Add to map \npermissionMap.put(permission.getName(),permission); \nprivate void updateCurrentPrivileges(boolean grant,PostgrePrivilegeType privile \nboolean hasPriv=permission.getPermission(privilegeType)!=PostgrePrivilege.NONE;if(grant== hasPriv){ \ncontinue;+}else if(! grant){+permissionMap.remove(permission.getName());}}// Add command \naddChangeCommand(new PostgreCommandGrantPrivilege(- getDatabaseObject(),+ databaseObject,grant,permission,privilegeType== null?null:new PostgrePrivilegeType[]{privilegeType}),diff --git a/plugins/org.jkiss.dbeaver.ext.postgresql/src/org/jkiss/dbeaver/ext/postgresql/model/PostgrePrivilege.java \nppp b/plugins/org.jkiss.dbeaver.ext.postgresql/src/org/jkiss/dbeaver/ext/postgresql/model/PostgrePrivilege.java \npublic PostgrePrivilegeOwner getOwner(){} \npublic short getPermission(PostgrePrivilegeType privilegeType){-for(int i=0;i<permissions.length;i++){-if(permissions[i]. privilegeType== privilegeType){-return permissions[i]. permissions;+ for(ObjectPermission permission:permissions){+if(permission.privilegeType== privilegeType|| permission.privilegeType== PostgrePrivilegeType.ALL){+return permission.permissions;}}return NONE;} \npublic void setPermission(PostgrePrivilegeType privilegeType,boolean permit){-for(int i=0;i<permissions.length;i++){-if(permissions[i]. privilegeType== privilegeType){+for(ObjectPermission permission:permissions){+if(permission.privilegeType== privilegeType){ \nif(permit){-permissions[i]. permissions|= GRANTED;+ permission.permissions|= GRANTED;} else{- permissions[i]. permissions=0;+ permission.permissions=0;}}} \n",
        "org_diff": "diff --git a/plugins/org.jkiss.dbeaver.ext.postgresql/src/org/jkiss/dbeaver/ext/postgresql/edit/PostgreCommandGrantPrivilege.java  b/plugins/org.jkiss.dbeaver.ext.postgresql/src/org/jkiss/dbeaver/ext/postgresql/edit/PostgreCommandGrantPrivilege.java \npublic void updateModel() \nif(object instanceof PostgreRole){ \nroleName=DBUtils.getQuotedIdentifier(object); \nif(privilegeOwner instanceof PostgreProcedure){-objectName=((PostgreProcedure)privilegeOwner). getFullyQualifiedName(DBPEvaluationContext.DDL);+objectName=((PostgreProcedure)privilegeOwner). getFullQualifiedSignature();} else{objectName=((PostgreRolePrivilege)permission). getFullObjectName();} \n"
    },
    {
        "sim_msg": "sulong : create LLVM Runtime Core and LLVM Runtime Native componentes",
        "sim_diff": "diff --git a/sulong/mx.sulong/mx_sulong.py \nppp b/sulong/mx.sulong/mx_sulong.py \ndef getBuildTask(self,args): \nmx_sdk_vm.register_graalvm_component(mx_sdk_vm.GraalVmLanguage(suite=_suite,- name=' Sulong',-short_name=' slg',+name=' LLVM Runtime Core',+short_name=' llic', \ndir_name=' llvm', \nlicense_files=[], \nthird_party_license_files=[],-dependencies=['Truffle','Truffle NFI'],- truffle_jars=['sulong:SULONG_CORE','sulong:SULONG_NATIVE','sulong:SULONG_API'],+ dependencies=['Truffle'],+ truffle_jars=['sulong:SULONG_CORE','sulong:SULONG_API'],support_distributions=['sulong:SULONG_HOME','sulong:SULONG_GRAALVM_DOCS',], \nlauncher_configs=[-mx_sdk_vm.LanguageLauncherConfig(- destination=' bin/< exe:lli>',- jar_distributions=['sulong:SULONG_LAUNCHER'],- main_class=' com.oracle.truffle.llvm.launcher.LLVMLauncher',-build_args=[],-language=' llvm',-),-]+ _suite.toolchain.get_launcher_configs(),+ mx_sdk_vm.LanguageLauncherConfig(+ destination=' bin/< exe:lli>',+ jar_distributions=['sulong:SULONG_LAUNCHER'],+ main_class=' com.oracle.truffle.llvm.launcher.LLVMLauncher',+build_args=[],+language=' llvm',+),+],+installable=False,+))++ mx_sdk_vm.register_graalvm_component(mx_sdk_vm.GraalVmLanguage(+ suite=_suite,+ name=' LLVM Runtime Native',+short_name=' llin',+dir_name=' llvm',+license_files=[],+third_party_license_files=[],+dependencies=['LLVM Runtime Core'],+ truffle_jars=['sulong:SULONG_NATIVE'],+ support_distributions=[],+launcher_configs=_suite.toolchain.get_launcher_configs(),+ installable=False,+))++ mx_sdk_vm.register_graalvm_component(mx_sdk_vm.GraalVmLanguage(+ suite=_suite,+ name=' Sulong',+short_name=' slg',+dir_name=' llvm',+license_files=[],+third_party_license_files=[],+dependencies=['LLVM Runtime Core','LLVM Runtime Native'],+ truffle_jars=[],+support_distributions=[], \ninstallable=False,) ) \n",
        "org_diff": "diff --git a/sulong/mx.sulong/native-image.properties  b/sulong/mx.sulong/native-image.properties \nImageName=lli-Requires=tool:truffle+Requires=tool:nfi \nJavaArgs=- Xmx3G \ndiff --git a/truffle/mx.truffle/mx_truffle.py  b/truffle/mx.truffle/mx_truffle.py \ndef clean(self,forBuild=False): \nmx_sdk.register_graalvm_component(mx_sdk.GraalVmTool(suite=_suite,- name=' Truffle NFI',+name=' Truffle', \nshort_name=' tfl', \ndir_name=' truffle', \nlicense_files=[], \ndef clean(self,forBuild=False): \nsupport_distributions=['truffle:TRUFFLE_GRAALVM_SUPPORT']))++ mx_sdk.register_graalvm_component(mx_sdk.GraalVmTool(+ suite=_suite,+ name=' Truffle NFI',+short_name=' nfi',+dir_name=' nfi',+license_files=[],+third_party_license_files=[],+truffle_jars=[],+support_distributions=['truffle:TRUFFLE_NFI_GRAALVM_SUPPORT']+))++mx.update_commands(_suite,{'check-filename-length':[check_filename_length,\"\"],' create-dsl-parser':[create_dsl_parser,\" create the DSL expression parser using antlr\"],diff --git a/truffle/mx.truffle/suite.py  b/truffle/mx.truffle/suite.py\"native-image.properties\":\"file:mx.truffle/tools-truffle.properties\",},},++\"TRUFFLE_NFI_GRAALVM_SUPPORT\":{+\"native\": True,+\"description\":\"Truffle NFI support distribution for the GraalVM\",+\" layout\":{+\"native-image.properties\":\"file:mx.truffle/tools-nfi.properties\",+},+},},}new file mode 100644 \nindex 000000000000.. fd109752eadb \ndiff --git/dev/null  b/truffle/mx.truffle/tools-nfi.properties@@-0,0+1@@+Requires=tool:truffle \n"
    },
    {
        "sim_msg": "mx : readd - - vmprefix ( and - - gdb , - - lldb ) argument previously provided by mx . jvmci",
        "sim_diff": "diff --git a/mx.graal-core/mx_graal_core.py \nppp b/mx.graal-core/mx_graal_core.py \n_suite=mx.suite(' graal-core')+\"\"\" Prefix for running the VM.\"\"\"+_vm_prefix=None++ def get_vm_prefix(asList=True):+\"\"\"+Get the prefix for running the VM(e.g.\" gdb-- args\").+\"\"\"+ if asList:+ return _vm_prefix.split() if _vm_prefix is not None else[]+return _vm_prefix+#:The JDK used to build and run Graal.jdk=mx.get_jdk(tag=' default') \ndef _check_bootstrap_config(args): \ndef run_java(args,nonZeroIsFatal=True,out=None,err=None,cwd=None,timeout=None,env=None,addDefaultArgs=True): \nargs=['- XX:+ UnlockExperimentalVMOptions','- XX:+ EnableJVMCI']+_parseVmArgs(args,addDefaultArgs=addDefaultArgs)_check_bootstrap_config(args)- cmd=[ jdk.java]+['-server']+args+cmd=get_vm_prefix()+[ jdk.java]+['-server']+args \nreturn mx.run(cmd,nonZeroIsFatal=nonZeroIsFatal,out=out,err=err,cwd=cwd)_JVMCI_JDK_TAG=' jvmci'def __addsrc__(self,arcname,contents): \ndef __closing__(self): \npass+mx.add_argument('-- vmprefix', action=' store', dest=' vm_prefix', help=' prefix for running the VM(e.g.\" gdb-- args\")', metavar='<prefix>')+ mx.add_argument('-- gdb', action=' store_const', const=' gdb-- args', dest=' vm_prefix', help=' alias for-- vmprefix\"gdb-- args\"')+ mx.add_argument('-- lldb', action=' store_const', const=' lldb--', dest=' vm_prefix', help=' alias for-- vmprefix\"lldb--\"')+ \nmx.update_commands(_suite,{'vm':[run_vm,'[- options]class[args...]'],' ctw':[ctw,'[- vmoptions|noinline|nocomplex|full]'], \ndef mx_post_parse_cmd_line(opts): \nfor dist in _suite.dists:dist.set_archiveparticipant(GraalArchiveParticipant(dist,isTest=dist.name.endswith(' _TEST'))) \nadd_bootclasspath_append(mx.distribution(' truffle:TRUFFLE_API'))+ global _vm_prefix+_vm_prefix=opts.vm_prefix \n",
        "org_diff": "diff --git a/mx.graal-core/mx_graal_core.py  b/mx.graal-core/mx_graal_core.py \n_suite=mx.suite(' graal-core')+\"\"\" Prefix for running the VM.\"\"\"+_vm_prefix=None++ def get_vm_prefix(asList=True):+\"\"\"+Get the prefix for running the VM(e.g.\" gdb-- args\").+\"\"\"+ if asList:+ return _vm_prefix.split() if _vm_prefix is not None else[]+return _vm_prefix+#:The JDK used to build and run Graal.jdk=mx.get_jdk(tag=' default') \ndef _check_bootstrap_config(args): \ndef run_java(args,nonZeroIsFatal=True,out=None,err=None,cwd=None,timeout=None,env=None,addDefaultArgs=True): \nargs=['- XX:+ UnlockExperimentalVMOptions','- XX:+ EnableJVMCI']+_parseVmArgs(args,addDefaultArgs=addDefaultArgs)_check_bootstrap_config(args)- cmd=[ jdk.java]+['-server']+args+cmd=get_vm_prefix()+[ jdk.java]+['-server']+args \nreturn mx.run(cmd,nonZeroIsFatal=nonZeroIsFatal,out=out,err=err,cwd=cwd)_JVMCI_JDK_TAG=' jvmci'def __addsrc__(self,arcname,contents): \ndef __closing__(self): \npass+mx.add_argument('-- vmprefix', action=' store', dest=' vm_prefix', help=' prefix for running the VM(e.g.\" gdb-- args\")', metavar='<prefix>')+ mx.add_argument('-- gdb', action=' store_const', const=' gdb-- args', dest=' vm_prefix', help=' alias for-- vmprefix\"gdb-- args\"')+ mx.add_argument('-- lldb', action=' store_const', const=' lldb--', dest=' vm_prefix', help=' alias for-- vmprefix\"lldb--\"')+ \nmx.update_commands(_suite,{'vm':[run_vm,'[- options]class[args...]'],' ctw':[ctw,'[- vmoptions|noinline|nocomplex|full]'], \ndef mx_post_parse_cmd_line(opts): \nfor dist in _suite.dists:dist.set_archiveparticipant(GraalArchiveParticipant(dist,isTest=dist.name.endswith(' _TEST'))) \nadd_bootclasspath_append(mx.distribution(' truffle:TRUFFLE_API'))+ global _vm_prefix+_vm_prefix=opts.vm_prefix \n"
    },
    {
        "sim_msg": "[ TEST ] fix lucene query comparison in RangeQueryBuilderTest",
        "sim_diff": "diff --git a/core/src/test/java/org/elasticsearch/index/query/RangeQueryBuilderTest.java \nppp b/core/src/test/java/org/elasticsearch/index/query/RangeQueryBuilderTest.java \nprotected Query doCreateExpectedQuery(RangeQueryBuilder queryBuilder,QueryParse \ndateTimeZone=DateTimeZone.forID(queryBuilder.timeZone());}MappedFieldType mapper=context.fieldMapper(queryBuilder.fieldName());-expectedQuery=((DateFieldMapper.DateFieldType)mapper). rangeQuery(queryBuilder.from(),queryBuilder.to(),+ expectedQuery=((DateFieldMapper.DateFieldType)mapper). rangeQuery(BytesRefs.toBytesRef(queryBuilder.from()), BytesRefs.toBytesRef(queryBuilder.to()), \nqueryBuilder.includeLower(),queryBuilder.includeUpper(),dateTimeZone,forcedDateParser,context);}else if(queryBuilder.fieldName().equals(INT_FIELD_NAME)){expectedQuery=NumericRangeQuery.newIntRange(INT_FIELD_NAME,( Integer)queryBuilder.from(),( Integer)queryBuilder.to() , \n",
        "org_diff": "diff --git a/core/src/test/java/org/elasticsearch/index/query/RangeQueryBuilderTest.java  b/core/src/test/java/org/elasticsearch/index/query/RangeQueryBuilderTest.java \nprotected RangeQueryBuilder createTestQueryBuilder(){} else{//use mapped date field,using date string representation \nquery=new RangeQueryBuilder(DATE_FIELD_NAME);-query.from(new DateTime(System.currentTimeMillis()-randomIntBetween(0,1000000)).toString());-query.to(new DateTime(System.currentTimeMillis()+randomIntBetween(0,1000000)).toString());+query.from(new DateTime(System.currentTimeMillis()-randomIntBetween(0,1000000), DateTimeZone.UTC). toString());+query.to(new DateTime(System.currentTimeMillis()+randomIntBetween(0,1000000), DateTimeZone.UTC). toString());// Create timestamp option only then we have a date mapper,otherwise we could trigger exception.if(createContext().mapperService().smartNameFieldType(DATE_FIELD_NAME)!=null){ \nif(randomBoolean()){ \n"
    },
    {
        "sim_msg": "Fix pkg_tar docs .",
        "sim_diff": "diff --git a/tools/build_defs/pkg/README.md \nppp b/tools/build_defs/pkg/README.md \npkg_tar(pkg_tar(name=\" debian-data\", \nextension=\" tar.gz\",-tars=[+deps=[\": bazel-bin\",\": bazel-tools\",], \nHere,the Debian package is built from three`pkg_tar`targets:##pkg_tar```python-pkg_tar(name,extension,data_path,directory,files,mode,modes,tars,debs,symlinks)+ pkg_tar(name,extension,data_path,directory,files,mode,modes,deps,symlinks)``` \nCreates a tar file from a list of inputs.Creates a tar file from a list of inputs.</td></tr>< tr>-<td>< code>tars</ code></td>+<td>< code>deps</ code></td>< td>-<code>List of files,optional</ code>-<p>Tar file to extract in the layer.</p>+<code>List of labels,optional</ code>+<p>Tar files to extract and include in this tar package.</p>< p>- A list of tar files to merge into the output tarball.+ A list of tarball labels to merge into the output tarball.</p></td></tr > \n",
        "org_diff": "diff --git a/tools/build_defs/pkg/make_deb.py  b/tools/build_defs/pkg/make_deb.py \ndef CreateDebControl(extrafiles=None,**kwargs): \nfor name in extrafiles:tarinfo=tarfile.TarInfo(name)tarinfo.size=len(extrafiles[name])+tarinfo.mode=0755 \nf.addfile(tarinfo,fileobj=StringIO(extrafiles[name]))control=tar.getvalue() \ntar.close() \n"
    },
    {
        "sim_msg": "Read configuration file with . yaml suffix",
        "sim_diff": "diff --git a/src/main/java/org/elasticsearch/node/internal/InternalSettingsPreparer.java \nppp b/src/main/java/org/elasticsearch/node/internal/InternalSettingsPreparer.java \npackage org.elasticsearch.node.internal;+ import com.google.common.collect.ImmutableList;import org.elasticsearch.cluster.ClusterName;import org.elasticsearch.common.Names;import org.elasticsearch.common.Strings;import org.elasticsearch.env.Environment;import org.elasticsearch.env.FailedToResolveConfigException;+ import java.util.List;import java.util.Map;import static org.elasticsearch.common.Strings.cleanPath;*/public class InternalSettingsPreparer{+ static final List<String>ALLOWED_SUFFIXES=ImmutableList.of(\".yml\",\". yaml\",\". json\",\". properties\");+ \npublic static Tuple<Settings,Environment>prepareSettings(Settings pSettings,boolean loadConfigSettings){// ignore this prefixes when getting properties from es.and elasticsearch.String[] ignorePrefixes=new String[]{\" es.default.\",\" elasticsearch.default.\"};}} \nif(loadFromEnv){-try{- settingsBuilder.loadFromUrl(environment.resolveConfig(\" elasticsearch.yml\"));-} catch(FailedToResolveConfigException e){-//ignore-} catch(NoClassDefFoundError e){-//ignore,no yaml-}-try{- settingsBuilder.loadFromUrl(environment.resolveConfig(\" elasticsearch.json\"));-} catch(FailedToResolveConfigException e){-//ignore-}-try{- settingsBuilder.loadFromUrl(environment.resolveConfig(\" elasticsearch.properties\"));-} catch(FailedToResolveConfigException e){-//ignore+for(String allowedSuffix:ALLOWED_SUFFIXES){+try{+ settingsBuilder.loadFromUrl(environment.resolveConfig(\" elasticsearch\"+ allowedSuffix));+}catch(FailedToResolveConfigException e){+//ignore+}}} \n} \n",
        "org_diff": "diff --git a/src/main/java/org/elasticsearch/node/internal/InternalSettingsPreparer.java  b/src/main/java/org/elasticsearch/node/internal/InternalSettingsPreparer.java \npackage org.elasticsearch.node.internal;+ import com.google.common.collect.ImmutableList;import org.elasticsearch.cluster.ClusterName;import org.elasticsearch.common.Names;import org.elasticsearch.common.Strings;import org.elasticsearch.env.Environment;import org.elasticsearch.env.FailedToResolveConfigException;+ import java.util.List;import java.util.Map;import static org.elasticsearch.common.Strings.cleanPath;*/public class InternalSettingsPreparer{+ static final List<String>ALLOWED_SUFFIXES=ImmutableList.of(\".yml\",\". yaml\",\". json\",\". properties\");+ \npublic static Tuple<Settings,Environment>prepareSettings(Settings pSettings,boolean loadConfigSettings){// ignore this prefixes when getting properties from es.and elasticsearch.String[] ignorePrefixes=new String[]{\" es.default.\",\" elasticsearch.default.\"};}} \nif(loadFromEnv){-try{- settingsBuilder.loadFromUrl(environment.resolveConfig(\" elasticsearch.yml\"));-} catch(FailedToResolveConfigException e){-//ignore-} catch(NoClassDefFoundError e){-//ignore,no yaml-}-try{- settingsBuilder.loadFromUrl(environment.resolveConfig(\" elasticsearch.json\"));-} catch(FailedToResolveConfigException e){-//ignore-}-try{- settingsBuilder.loadFromUrl(environment.resolveConfig(\" elasticsearch.properties\"));-} catch(FailedToResolveConfigException e){-//ignore+for(String allowedSuffix:ALLOWED_SUFFIXES){+try{+ settingsBuilder.loadFromUrl(environment.resolveConfig(\" elasticsearch\"+ allowedSuffix));+}catch(FailedToResolveConfigException e){+//ignore+}}}}diff --git a/src/test/java/org/elasticsearch/node/internal/InternalSettingsPreparerTests.java  b/src/test/java/org/elasticsearch/node/internal/InternalSettingsPreparerTests.java \npublic void testIgnoreSystemProperties(){//Should use setting from the system property \nassertThat(tuple.v1().get(\" node.zone\"),equalTo(\" bar\"));}++@ Test+public void testAlternateConfigFileSuffixes(){+// test that we can read config files with.yaml,. json,and.properties suffixes+Tuple<Settings,Environment>tuple=InternalSettingsPreparer.prepareSettings(settingsBuilder()+. put(\" config.ignore_system_properties\", true)+.build(),true);++ assertThat(tuple.v1().get(\" yaml.config.exists\"),equalTo(\" true\"));+assertThat(tuple.v1().get(\" json.config.exists\"),equalTo(\" true\"));+assertThat(tuple.v1().get(\" properties.config.exists\"),equalTo(\" true\"));+}}new file mode 100644 \nindex 0000000000000.. 16433a2c88d2c \ndiff --git/dev/null  b/src/test/resources/config/elasticsearch.json+{+\" json.config.exists\":\"true\"+}new file mode 100644 \nindex 0000000000000.. d3f822cafb555 \ndiff --git/dev/null  b/src/test/resources/config/elasticsearch.properties++ properties.config.exists:true \nnew file mode 100644 \nindex 0000000000000.. b6ebc6bd10576 \ndiff --git/dev/null  b/src/test/resources/config/elasticsearch.yaml++ yaml.config.exists:true \n+ \n"
    },
    {
        "sim_msg": "Update cs locale",
        "sim_diff": "new file mode 100644 \nindex 00000000000.. e28db5b8bf6 \ndiff --git/dev/null \nppp b/l10n/cs/chrome.properties+# Copyright 2012 Mozilla Foundation+#+# Licensed under the Apache License,Version 2.0(the\"License\");+#you may not use this file except in compliance with the License.+#You may obtain a copy of the License at+#+# http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing,software+# distributed under the License is distributed on an\"AS IS\"BASIS,+#WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND,either express or implied.+#See the License for the specific language governing permissions and+# limitations under the License.++# Chrome notification bar messages and buttons+unsupported_feature=Tento dokument PDF se nemusel zobrazit správně.+ unsupported_feature_forms=Tento dokument PDF obsahuje formuláře.Vyplňění formulářových polích není podporováno.+ open_with_different_viewer=Otevřít v jiném prohlížeči+open_with_different_viewer.accessKey=o \n",
        "org_diff": "new file mode 100644 \nindex 0000000000.. 94973fde8a \ndiff --git/dev/null  b/okhttp/src/main/resources/okhttp3/internal/publicsuffix/NOTICE+Note that publicsuffixes.gz is compiled from The Public Suffix List:+ https://publicsuffix.org/list/public_suffix_list.dat++ It is subject to the terms of the Mozilla Public License,v.2.0:+ https://mozilla.org/MPL/2.0 / \n"
    },
    {
        "sim_msg": "Muting XContentParserTests # testSubParserArray",
        "sim_diff": "diff --git a/libs/x-content/src/test/java/org/elasticsearch/common/xcontent/XContentParserTests.java \nppp b/libs/x-content/src/test/java/org/elasticsearch/common/xcontent/XContentParserTests.java \npackage org.elasticsearch.common.xcontent;import com.fasterxml.jackson.core.JsonParseException;+ \nimport org.elasticsearch.common.CheckedSupplier;import org.elasticsearch.common.Strings;import org.elasticsearch.common.bytes.BytesReference;public void testSubParserObject() throws IOException{}}+@AwaitsFix(bugUrl=\" https://github.com/elastic/elasticsearch/issues/40617\") \npublic void testSubParserArray() throws IOException{XContentBuilder builder=XContentFactory.jsonBuilder();int numberOfArrayElements=randomInt(10); \n",
        "org_diff": "diff --git a/core/src/main/java/org/elasticsearch/common/xcontent/json/JsonXContentGenerator.java  b/core/src/main/java/org/elasticsearch/common/xcontent/json/JsonXContentGenerator.java \npackage org.elasticsearch.common.xcontent.json;import com.fasterxml.jackson.core.io.SerializedString;+ import com.fasterxml.jackson.core.util.DefaultIndenter;+ import com.fasterxml.jackson.core.util.DefaultPrettyPrinter;import org.elasticsearch.common.bytes.BytesReference;import org.elasticsearch.common.xcontent.*;protected final BaseJsonGenerator generator;private boolean writeLineFeedAtEnd;+ private static final SerializedString LF=new SerializedString(\"\\n\");+ private static final DefaultPrettyPrinter.Indenter INDENTER=new DefaultIndenter(\"\", LF.getValue()); \npublic JsonXContentGenerator(BaseJsonGenerator generator){ \nthis.generator=generator;public XContentType contentType(){}@Override-public void usePrettyPrint(){- generator.useDefaultPrettyPrinter();+ public final void usePrettyPrint(){+ generator.setPrettyPrinter(new DefaultPrettyPrinter().withObjectIndenter(INDENTER));}@Override \npublic void close() throws IOException{} \ngenerator.close();}-- private static final SerializedString LF=new SerializedString(\"\\n\");} \ndiff --git a/core/src/test/java/org/elasticsearch/common/xcontent/builder/XContentBuilderTests.java  b/core/src/test/java/org/elasticsearch/common/xcontent/builder/XContentBuilderTests.java \npublic void testHandlingOfCollectionOfPaths() throws IOException{assertThat(pathBuilder.string(),equalTo(stringBuilder.string()));}+public void testIndentIsPlatformIndependent() throws IOException{+ XContentBuilder builder=XContentFactory.contentBuilder(XContentType.JSON). prettyPrint();+ builder.startObject().field(\" test\",\"foo\").startObject(\" foo\").field(\" foobar\",\"boom\").endObject().endObject();+ String string=builder.string();+ assertEquals(\"{\\ n\"++\"\\\" test\\\":\\\"foo\\\",\\ n\"++\"\\\" foo\\\":{\\n\"++\"\\\" foobar\\\":\\\"boom\\\"\\n\"++\"}\\ n\"++\"}\",string);++ builder=XContentFactory.contentBuilder(XContentType.YAML). prettyPrint();+ builder.startObject().field(\" test\",\"foo\").startObject(\" foo\").field(\" foobar\",\"boom\").endObject().endObject();+ string=builder.string();+ assertEquals(\" diff --git\\n\"++\" test:\\\"foo\\\"\\n\"++\" foo:\\ n\"++\" foobar:\\\"boom\\\"\\n\", string);+}+} \ndiff --git a/core/src/test/java/org/elasticsearch/index/query/HasChildQueryBuilderTests.java  b/core/src/test/java/org/elasticsearch/index/query/HasChildQueryBuilderTests.java \npublic void testParseFromJSON() throws IOException{//now assert that we actually generate the same JSON \nXContentBuilder builder=XContentFactory.jsonBuilder().prettyPrint();queryBuilder.toXContent(builder,ToXContent.EMPTY_PARAMS);-assertEquals(query,builder.string().replaceAll(\"\\\\ r\\\\ n\",\"\\ n\"));// jackson uses system linefeed-will fail on windows otherwise+assertEquals(query,builder.string());}} \n"
    },
    {
        "sim_msg": "Add value type for encapsuating dependency info",
        "sim_diff": "diff --git a/src/tools/android/java/com/google/devtools/build/android/BUILD \nppp b/src/tools/android/java/com/google/devtools/build/android/BUILD \njava_binary(java_library(name=\" android_builder_lib\",-srcs=glob([-\"*. java\",-\" xml/*.java\",-\" aapt2/*.java\",-]),+srcs=glob(+[+\"*.java\",+\" xml/*.java\",+\" aapt2/*.java\",+],+ exclude=[\"DependencyInfo.java\"],+), \ndeps=[+\":dependency_info\",\"//src/java_tools/singlejar/java/com/google/devtools/build/singlejar:libSingleJar\",\"//src/java_tools/singlejar/java/com/google/devtools/build/zip\",\"//src/main/java/com/google/devtools/common/options\", \njava_library(],)+java_library(+ name=\" dependency_info\",+srcs=[\"DependencyInfo.java\"],+ visibility=[\": __subpackages__\"],+ deps=[+\"// third_party:auto_value\",+],+)+ \nfilegroup(name=\" srcs\", \nsrcs=glob([\"**\"])+[ \nnew file mode 100644 \nindex 000000000000.. 32a196eaf990 \ndiff --git/dev/null \nppp b/src/tools/android/java/com/google/devtools/build/android/DependencyInfo.java+//Copyright 2019 The Bazel Authors.All rights reserved.+//+//Licensed under the Apache License,Version 2.0(the\"License\");+// you may not use this file except in compliance with the License.+// You may obtain a copy of the License at+//+// http://www.apache.org/licenses/LICENSE-2.0+//+// Unless required by applicable law or agreed to in writing,software+//distributed under the License is distributed on an\"AS IS\"BASIS,+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND,either express or implied.+// See the License for the specific language governing permissions and+//limitations under the License.+ package com.google.devtools.build.android;++import com.google.auto.value.AutoValue;++/** Encapsulates information about a Bazel dependency with respect to the current target.*/+@AutoValue+public abstract class DependencyInfo{+ public abstract String label();++public abstract DependencyType dependencyType();++static DependencyInfo create(String label,DependencyType dependencyType){+return new AutoValue_DependencyInfo(label,dependencyType);+}++/**The type of dependency relationship,in terms of its distance from the current target.*/+ public static enum DependencyType{+/**+*The current target.This corresponds to the\"--primaryData\"option of+* ResourceProcessorBusyBox.+*/+PRIMARY,+/**Direct dependency.*/+ DIRECT,+/**Transitive dependency.*/+ TRANSITIVE+}+} \n",
        "org_diff": "diff --git a/third_party/BUILD  b/third_party/BUILD \njava_import(\" android_common/com.android.tools_sdk-common_25.0.0.jar\",\"android_common/com.android.tools_sdklib_25.0.0.jar\",],-deps=[-\"// third_party/jaxb\",-],runtime_deps=[\": asm\",\": asm-analysis\",\": asm-tree\",],+deps=[+\"// third_party/jaxb\",+],) \njava_import(filegroup(],)-pkg_tar(- name=\" java_tools_pkg\",-srcs=[-\"// third_party/java/java_tools:java_tools\",-\"// third_party/java/jdk/langtools:javac_jar\",-\"// third_party/java/jdk/langtools:jdk_compiler_jar\",-\"// third_party/java/jdk/langtools:java_compiler_jar\"-],-)-pkg_tar(name=\" java_tools_pkg-gz\", \nsrcs=[-\"// third_party/java/java_tools:java_tools\",+\"// third_party/java/java_tools\",+\"// third_party/java/jdk/langtools:java_compiler_jar\",\"//third_party/java/jdk/langtools:javac_jar\",\"//third_party/java/jdk/langtools:jdk_compiler_jar\",-\"// third_party/java/jdk/langtools:java_compiler_jar\"],- extension=\" tar.gz\"+ extension=\" tar.gz\",+# Permissions-rwxr-xr-x+mode=\" 755\",)- \nload(\":compiler_config_setting.bzl\",\"create_compiler_config_setting\") \ncreate_compiler_config_setting ( \n"
    },
    {
        "sim_msg": "RunListener now supports automatic registration",
        "sim_diff": "diff --git a/core/src/main/java/hudson/model/listeners/RunListener.java \nppp b/core/src/main/java/hudson/model/listeners/RunListener.java \npackage hudson.model.listeners;import hudson.ExtensionPoint;+ import hudson.ExtensionListView;+ import hudson.Extension;+ import hudson.DescriptorExtensionList;+ import hudson.ExtensionList;+ import hudson.scm.RepositoryBrowser;import hudson.model.Run;import hudson.model.TaskListener;+ import hudson.model.Descriptor;+ import hudson.model.Hudson;import hudson.util.CopyOnWriteList;/** \npublic void onStarted(R r,TaskListener listener){}/***Registers this object as an active listener so that it can start getting*callbacks invoked.+*+*@ deprecated+* Put{@ link Extension}on your class to get it auto-registered.*/public void register(){LISTENERS.add(this); \npublic void unregister(){/***List of registered listeners.+*@ deprecated as of 1.281+* Use{@ link#all()}for read access,and use{@ link Extension}for registration.*/- public static final CopyOnWriteList<RunListener>LISTENERS=new CopyOnWriteList<RunListener>();+public static final CopyOnWriteList<RunListener>LISTENERS=ExtensionListView.createCopyOnWriteList(RunListener.class);/*** Fires the{@ link#onCompleted}event.*/public static void fireCompleted(Run r,TaskListener listener){-for(RunListener l:LISTENERS){+for(RunListener l:all()){ \nif(l.targetType.isInstance(r)) \nl.onCompleted(r,listener);}public static void fireCompleted(Run r,TaskListener listener){*Fires the{@ link#onStarted}event.*/public static void fireStarted(Run r,TaskListener listener){-for(RunListener l:LISTENERS){+for(RunListener l:all()){ \nif(l.targetType.isInstance(r)) \nl.onStarted(r,listener);}public static void fireStarted(Run r,TaskListener listener){*Fires the{@ link#onFinalized(Run)} event.*/public static void fireFinalized(Run r){-for(RunListener l:LISTENERS){+for(RunListener l:all()){ \nif(l.targetType.isInstance(r)) \nl.onFinalized(r);}}++/**+*Returns all the registered{@ link RunListener}descriptors.+*/+public static ExtensionList<RunListener>all(){+ return Hudson.getInstance().getExtensionList(RunListener.class);+}}diff --git a/core/src/main/java/hudson/tasks/test/AggregatedTestResultPublisher.java \nppp b/core/src/main/java/hudson/tasks/test/AggregatedTestResultPublisher.java \npublic String getUrlName(){return\"aggregatedTestReport\";}- static{- new RunListener<Run>( Run.class){-public void onCompleted(Run run,TaskListener listener){-lastChanged=System.currentTimeMillis();-}-}. register();+@Extension+public static class RunListenerImpl extends RunListener<Run>{+public RunListenerImpl(){+ super(Run.class);+}++ public void onCompleted(Run run,TaskListener listener){+lastChanged=System.currentTimeMillis();+}} \n} \n",
        "org_diff": "diff --git a/core/src/main/java/hudson/model/listeners/RunListener.java  b/core/src/main/java/hudson/model/listeners/RunListener.java \nimport hudson.Extension;import hudson.ExtensionList;import hudson.FilePath;+ import hudson.Functions;import hudson.Launcher;import hudson.model.AbstractBuild;import hudson.model.BuildListener;import hudson.model.Run;import hudson.model.Run.RunnerAbortedException;import hudson.model.TaskListener;- import jenkins.model.Jenkins;import hudson.scm.SCM;import hudson.tasks.BuildWrapper;import hudson.util.CopyOnWriteList;public static void fireStarted(Run r,TaskListener listener){*Fires the{@ link#onFinalized(Run)} event.*/public static void fireFinalized(Run r){-if(Jenkins.getInstanceOrNull()== null){// TODO use!Functions.isExtensionsAvailable() once JENKINS-33377+if(! Functions.isExtensionsAvailable()){ \nreturn;} \nfor(RunListener l:all()){ \n"
    },
    {
        "sim_msg": "Sometimes String is more efficient than StringBuilder",
        "sim_diff": "diff --git a/core/src/main/java/hudson/model/Computer.java \nppp b/core/src/main/java/hudson/model/Computer.java \npublic Executor getExecutor(){@ Override \npublic String toString(){- final StringBuilder sb=new StringBuilder(\" DisplayExecutor{\");-sb.append(\" displayName='\").append(displayName). append('\\'');- sb.append(\",url='\").append(url). append('\\'');- sb.append(\",executor=\"). append(executor);-sb.append('}');-return sb.toString();+ String sb=\" DisplayExecutor{\"+\" displayName='\"+ displayName+'\\''++\",url='\"+ url+'\\''++\",executor=\"+executor++'}';+return sb;}@Override \ndiff --git a/core/src/main/java/hudson/slaves/NodeProvisioner.java \nppp b/core/src/main/java/hudson/slaves/NodeProvisioner.java \npublic void recordPendingLaunches(Collection<PlannedNode>plannedNodes){*/@Override \npublic String toString(){- final StringBuilder sb=new StringBuilder(\" StrategyState{\");-sb.append(\" label=\"). append(label);-sb.append(\",snapshot=\"). append(snapshot);-sb.append(\",plannedCapacitySnapshot=\"). append(plannedCapacitySnapshot);-sb.append(\",additionalPlannedCapacity=\"). append(additionalPlannedCapacity);-sb.append('}');-return sb.toString();+ String sb=\" StrategyState{\"+\" label=\"+label++\", snapshot=\"+snapshot++\", plannedCapacitySnapshot=\"+plannedCapacitySnapshot++\", additionalPlannedCapacity=\"+additionalPlannedCapacity++'}';+return sb;} \n} \n",
        "org_diff": "diff --git a/core/src/main/java/hudson/Launcher.java  b/core/src/main/java/hudson/Launcher.java \nprotected final void printCommandLine(String[] cmd,FilePath workDir){ \nStringBuffer buf=new StringBuffer();if(workDir!= null){ \nbuf.append('[');-buf.append(workDir.getRemote().replaceFirst(\"^.+[/\\\\\\\\]\",\"\"));+ if(showFullPath)+ buf.append(workDir.getRemote());+else+buf.append(workDir.getRemote().replaceFirst(\"^.+[/\\\\\\\\]\",\"\"));buf.append(\"]\");}buf.append('$'); \npublic Proc launch(String[] cmd,String[] env,InputStream in,OutputStream out,Fi \nreturn m;}}++/**+* Debug option to display full current path instead of just the last token.+*/+public static boolean showFullPath=false;} \n"
    },
    {
        "sim_msg": "Fix bean name for reactive Cassandra health indicator",
        "sim_diff": "diff --git a/spring-boot-project/spring-boot-actuator-autoconfigure/src/main/java/org/springframework/boot/actuate/autoconfigure/cassandra/CassandraReactiveHealthIndicatorAutoConfiguration.java \nppp b/spring-boot-project/spring-boot-actuator-autoconfigure/src/main/java/org/springframework/boot/actuate/autoconfigure/cassandra/CassandraReactiveHealthIndicatorAutoConfiguration.java \npublic CassandraReactiveHealthIndicatorAutoConfiguration(}@Bean-@ ConditionalOnMissingBean(name=\" cassandraReactiveHealthIndicator\")+@ ConditionalOnMissingBean(name=\" cassandraHealthIndicator\") \npublic ReactiveHealthIndicator cassandraHealthIndicator(){return createHealthIndicator(this.reactiveCassandraOperations); \n} \n",
        "org_diff": "diff --git a/spring-boot-project/spring-boot-actuator/src/main/java/org/springframework/boot/actuate/cassandra/CassandraDriverReactiveHealthIndicator.java  b/spring-boot-project/spring-boot-actuator/src/main/java/org/springframework/boot/actuate/cassandra/CassandraDriverReactiveHealthIndicator.java \nprivate final CqlSession session;/**-* Create a new{@ link CassandraHealthIndicator}instance.+*Create a new{@ link CassandraDriverReactiveHealthIndicator}instance.*@param session the{@ link CqlSession}.*/ \npublic CassandraDriverReactiveHealthIndicator(CqlSession session){ \ndiff --git a/spring-boot-project/spring-boot-autoconfigure/src/main/java/org/springframework/boot/autoconfigure/web/ConditionalOnEnabledResourceChain.java  b/spring-boot-project/spring-boot-autoconfigure/src/main/java/org/springframework/boot/autoconfigure/web/ConditionalOnEnabledResourceChain.java/***{@ link Conditional@Conditional}that checks whether or not the Spring resource-* handling chain is enabled.Matches if{@ link ResourceProperties.Chain#getEnabled()}is-*{@ code true}or if{@ code webjars-locator-core}is on the classpath.+*handling chain is enabled.Matches if+*{@ link WebProperties.Resources.Chain#getEnabled()}is{@ code true}or if+*{@ code webjars-locator-core}is on the classpath.**@ author Stephane Nicoll*@ since 1.3.0 \n"
    },
    {
        "sim_msg": "Add @ since tags",
        "sim_diff": "diff --git a/spring-test/src/main/java/org/springframework/mock/http/server/reactive/MockServerHttpRequest.java \nppp b/spring-test/src/main/java/org/springframework/mock/http/server/reactive/MockServerHttpRequest.java/*** Mock implementation of{@ link ServerHttpRequest}.*@ author Rossen Stoyanchev+*@since 5.0*/ \npublic class MockServerHttpRequest implements ServerHttpRequest{diff --git a/spring-test/src/main/java/org/springframework/mock/http/server/reactive/MockServerHttpResponse.java \nppp b/spring-test/src/main/java/org/springframework/mock/http/server/reactive/MockServerHttpResponse.java/*** Mock implementation of{@ link ServerHttpResponse}.*@ author Rossen Stoyanchev+*@since 5.0*/ \npublic class MockServerHttpResponse implements ServerHttpResponse { \n",
        "org_diff": "diff --git a/spring-test/src/main/java/org/springframework/mock/web/MockHttpServletRequest.java  b/spring-test/src/main/java/org/springframework/mock/web/MockHttpServletRequest.java \nimport org.springframework.util.Assert;import org.springframework.util.LinkedCaseInsensitiveMap;+ import org.springframework.util.StringUtils;/***Mock implementation of the{@ link javax.servlet.http.HttpServletRequest}interface.public MockHttpServletRequest(ServletContext servletContext){*/ \npublic MockHttpServletRequest(ServletContext servletContext,String method,String requestURI){ \nthis.servletContext=( servletContext!= null?servletContext:new MockServletContext());-this.method=( method== null?\"\": method);-this.requestURI=( requestURI== null?\"\": requestURI);+this.method=method;+ this.requestURI=requestURI;this.locales.add(Locale.ENGLISH);}else if(value!= null){}public void setMethod(String method){-this.method=( method== null?\"\": method);+this.method=method;}@Override \npublic String getRequestedSessionId(){} \npublic void setRequestURI(String requestURI){-this.requestURI=( requestURI== null?\"\": requestURI);+this.requestURI=requestURI;}@Override \npublic StringBuffer getRequestURL(){url.append(':'). append(this.serverPort);}- url.append(getRequestURI());+if(StringUtils.hasText(getRequestURI())){+ url.append(getRequestURI());+}+return url;} \ndiff --git a/spring-test/src/test/java/org/springframework/mock/web/MockHttpServletRequestTests.java  b/spring-test/src/test/java/org/springframework/mock/web/MockHttpServletRequestTests.java \npublic void getRequestURLWithDefaults(){assertEquals(\" http://localhost\", requestURL.toString());}+@Test+public void getRequestURLWithNullRequestUri(){+ request.setRequestURI(null);+StringBuffer requestURL=request.getRequestURL();+ assertEquals(\" http://localhost\", requestURL.toString());+}+@ Test \npublic void getRequestURLWithDefaultsAndHttps(){request.setScheme(\" https\") ; \n"
    },
    {
        "sim_msg": "XXE Vulnerability",
        "sim_diff": "diff --git a/java/client/src/org/openqa/selenium/firefox/internal/FileExtension.java \nppp b/java/client/src/org/openqa/selenium/firefox/internal/FileExtension.java \nprivate String readIdFromInstallRdf(File root){ \nDocumentBuilderFactory factory=DocumentBuilderFactory.newInstance();factory.setNamespaceAware(true);+factory.setExpandEntityReferences(false); \nDocumentBuilder builder=factory.newDocumentBuilder();Document doc=builder.parse(installRdf); \n",
        "org_diff": "diff --git a/java/client/src/org/openqa/selenium/firefox/internal/FileExtension.java  b/java/client/src/org/openqa/selenium/firefox/internal/FileExtension.java \npublic String getPrefix(String uri){ \nthrow new UnsupportedOperationException(\" getPrefix\");}-public Iterator<?>getPrefixes(String uri){+public Iterator<String>getPrefixes(String uri){ \nthrow new UnsupportedOperationException(\" getPrefixes\");}}) ; \n"
    },
    {
        "sim_msg": "Fixes for ' force - bash - launchers ' and ' needsBuild ' .",
        "sim_diff": "diff --git a/vm/mx.vm/mx_vm.py \nppp b/vm/mx.vm/mx_vm.py \ndef needsBuild(self,newestInput): \nsup=super(GraalVmLayoutDistributionTask,self). needsBuild(newestInput)if sup[0]: \nreturn sup-for link_path,link_target in[( self._root_link_path,self._root_link_target()),(self._home_link_path,self._home_link_target())]:- if not os.path.lexists(link_path):-return True,'{} does not exist'. format(link_path)- link_file=mx.TimeStampFile(link_path,False)- if link_file.isOlderThan(self.subject.output):-return True,'{} is older than{}'. format(link_file,newestInput)- if self.subject== get_final_graalvm_distribution():- if link_target!= os.readlink(link_path):-return True,'{} is pointing to the wrong directory'. format(link_file)+ if mx.get_os()!='windows':+for link_path,link_target in[( self._root_link_path,self._root_link_target()),(self._home_link_path,self._home_link_target())]:+ if not os.path.lexists(link_path):+return True,'{} does not exist'. format(link_path)+ link_file=mx.TimeStampFile(link_path,False)+ if link_file.isOlderThan(self.subject.output):+return True,'{} is older than{}'. format(link_file,newestInput)+ if self.subject== get_final_graalvm_distribution():+ if link_target!= os.readlink(link_path):+return True,'{} is pointing to the wrong directory'. format(link_file)return False,None \ndef build(self): \ndef build(self): \nproperties={'ImageName': basename(launcher_config.destination)[:- len(mx.exe_suffix(\"\"))],' LauncherClass': basename(launcher_config.main_class),-' LauncherClassPath': graalvm_home_relative_classpath(launcher_config.jar_distributions,_get_graalvm_archive_path(' jre')). replace(os.pathsep,':'),+' LauncherClassPath': graalvm_home_relative_classpath(launcher_config.jar_distributions,_get_graalvm_archive_path(' jre')). replace(os.pathsep,':'). replace(os.sep,'/'),'Args':''.join(launcher_config.build_args),}for p in(' ImageName','LauncherClass'):def _force_bash_launchers(launcher,forced=None): \nforced=forced.split(',')if isinstance(launcher,mx_sdk.AbstractNativeImageConfig): \nlauncher=launcher.destination+assert launcher.endswith(mx.exe_suffix(''))+ launcher=launcher[:-len(mx.exe_suffix(''))] \nlauncher_name=basename(launcher)return launcher_name in forced \n",
        "org_diff": "diff --git a/vm/mx.vm/mx_vm.py  b/vm/mx.vm/mx_vm.py \ndef __init__(self,args,dist,root_link_name,home_link_name): \nsuper(GraalVmLayoutDistributionTask,self). __init__(args,dist)def _add_link(self):+if mx.get_os()=='windows':+mx.log(' Skip adding symlink'+ self._root_link_path+'(Windows)')+ return \nself._rm_link() \nos.symlink(self._root_link_target(),self._root_link_path)os.symlink(self._home_link_target(),self._home_link_path)def _home_link_target(self): \nreturn relpath(join(self.subject.output,self.subject.jdk_base), _suite.dir)def _rm_link(self):+if mx.get_os()=='windows':+return \nfor l in[self._root_link_path,self._home_link_path]: \nif os.path.lexists(l): \nos.unlink(l ) \n"
    },
    {
        "sim_msg": "truffle : introduce the ShowInternalStackFrames option",
        "sim_diff": "diff --git a/truffle/CHANGELOG.md \nppp b/truffle/CHANGELOG.md \nThis changelog summarizes major changes between Truffle versions relevant to languages implementors building upon the Truffle framework.The main focus is on APIs exported by Truffle.##Version 20.2.0+* Added new internal engine option`ShowInternalStackFrames`to show internal frames specific to the language implementation in stack traces.* Added new identity APIs to`InteropLibrary`:*` hasIdentity(Object receiver)` to find out whether an object specifies identity*` isIdentical(Object receiver,Object other,InteropLibrary otherLib)` to compare the identity of two object \ndiff --git a/truffle/src/com.oracle.truffle.polyglot/src/com/oracle/truffle/polyglot/PolyglotEngineOptions.java \nppp b/truffle/src/com.oracle.truffle.polyglot/src/com/oracle/truffle/polyglot/PolyglotEngineOptions.java@Option(name=INSTRUMENT_EXCEPTIONS_ARE_THROWN_NAME,category=OptionCategory.INTERNAL,help=\" Propagates exceptions thrown by instruments.\")//static final OptionKey<Boolean>InstrumentExceptionsAreThrown=new OptionKey<>(false);+@ Option(category=OptionCategory.INTERNAL,stability=OptionStability.EXPERIMENTAL,help=\" Show internal frames specific to the language implementation in stack traces.\")//+ static final OptionKey<Boolean>ShowInternalStackFrames=new OptionKey<>(false);+@ Option(category=OptionCategory.INTERNAL,stability=OptionStability.EXPERIMENTAL,help=\" Enables conservative context references.\"+\" This allows invalid sharing between contexts.\"+\" For testing purposes only.\")//diff --git a/truffle/src/com.oracle.truffle.polyglot/src/com/oracle/truffle/polyglot/PolyglotExceptionFrame.java \nppp b/truffle/src/com.oracle.truffle.polyglot/src/com/oracle/truffle/polyglot/PolyglotExceptionFrame.java \nstatic PolyglotExceptionFrame createGuest(PolyglotExceptionImpl exception,Truff \nreturn null;} \nRootNode targetRoot=frame.getTarget().getRootNode();- if(targetRoot.isInternal()){+if(targetRoot.isInternal()&&!exception.showInternalStackFrames){ \nreturn null;} \ndiff --git a/truffle/src/com.oracle.truffle.polyglot/src/com/oracle/truffle/polyglot/PolyglotExceptionImpl.java \nppp b/truffle/src/com.oracle.truffle.polyglot/src/com/oracle/truffle/polyglot/PolyglotExceptionImpl.java \nfinal PolyglotEngineImpl engine;final PolyglotContextImpl context;final Throwable exception;+ final boolean showInternalStackFrames;private final List<TruffleStackTraceElement>guestFrames;private StackTraceElement[] javaStackTrace;private PolyglotExceptionImpl(PolyglotImpl polyglot,PolyglotEngineImpl engine,this.context=( languageContext!= null)? languageContext.context:null;this.exception=original;this.guestFrames=TruffleStackTrace.getStackTrace(original);+this.showInternalStackFrames=engine== null?false:engine.engineOptionValues.get(PolyglotEngineOptions.ShowInternalStackFrames); \nif(exception instanceof TruffleException){ \nTruffleException truffleException=( TruffleException)exception ; \n",
        "org_diff": "diff --git a/truffle/CHANGELOG.md  b/truffle/CHANGELOG.md \nThis changelog summarizes major changes between Truffle versions relevant to languages implementors building upon the Truffle framework.The main focus is on APIs exported by Truffle.##Version 20.2.0+* Added new internal engine option`ShowInternalStackFrames`to show internal frames specific to the language implementation in stack traces.* Added new identity APIs to`InteropLibrary`:*` hasIdentity(Object receiver)` to find out whether an object specifies identity*` isIdentical(Object receiver,Object other,InteropLibrary otherLib)` to compare the identity of two object \ndiff --git a/truffle/src/com.oracle.truffle.polyglot/src/com/oracle/truffle/polyglot/PolyglotEngineOptions.java  b/truffle/src/com.oracle.truffle.polyglot/src/com/oracle/truffle/polyglot/PolyglotEngineOptions.java@Option(name=INSTRUMENT_EXCEPTIONS_ARE_THROWN_NAME,category=OptionCategory.INTERNAL,help=\" Propagates exceptions thrown by instruments.\")//static final OptionKey<Boolean>InstrumentExceptionsAreThrown=new OptionKey<>(false);+@ Option(category=OptionCategory.INTERNAL,stability=OptionStability.EXPERIMENTAL,help=\" Show internal frames specific to the language implementation in stack traces.\")//+ static final OptionKey<Boolean>ShowInternalStackFrames=new OptionKey<>(false);+@ Option(category=OptionCategory.INTERNAL,stability=OptionStability.EXPERIMENTAL,help=\" Enables conservative context references.\"+\" This allows invalid sharing between contexts.\"+\" For testing purposes only.\")//diff --git a/truffle/src/com.oracle.truffle.polyglot/src/com/oracle/truffle/polyglot/PolyglotExceptionFrame.java  b/truffle/src/com.oracle.truffle.polyglot/src/com/oracle/truffle/polyglot/PolyglotExceptionFrame.java \nstatic PolyglotExceptionFrame createGuest(PolyglotExceptionImpl exception,Truff \nreturn null;} \nRootNode targetRoot=frame.getTarget().getRootNode();- if(targetRoot.isInternal()){+if(targetRoot.isInternal()&&!exception.showInternalStackFrames){ \nreturn null;} \ndiff --git a/truffle/src/com.oracle.truffle.polyglot/src/com/oracle/truffle/polyglot/PolyglotExceptionImpl.java  b/truffle/src/com.oracle.truffle.polyglot/src/com/oracle/truffle/polyglot/PolyglotExceptionImpl.java \nfinal PolyglotEngineImpl engine;final PolyglotContextImpl context;final Throwable exception;+ final boolean showInternalStackFrames;private final List<TruffleStackTraceElement>guestFrames;private StackTraceElement[] javaStackTrace;private PolyglotExceptionImpl(PolyglotImpl polyglot,PolyglotEngineImpl engine,this.context=( languageContext!= null)? languageContext.context:null;this.exception=original;this.guestFrames=TruffleStackTrace.getStackTrace(original);+this.showInternalStackFrames=engine== null?false:engine.engineOptionValues.get(PolyglotEngineOptions.ShowInternalStackFrames); \nif(exception instanceof TruffleException){ \nTruffleException truffleException=( TruffleException)exception ; \n"
    },
    {
        "sim_msg": "Fix duplicate section ID in the docs",
        "sim_diff": "diff --git a/spring-boot-project/spring-boot-docs/src/main/asciidoc/spring-boot-features.adoc \nppp b/spring-boot-project/spring-boot-docs/src/main/asciidoc/spring-boot-features.adoc \nYou can take full control over the session creation by adding a==== Using the Embedded Mode \nIf you add`org.neo4j:neo4j-ogm-embedded-driver`to the dependencies of your application,Spring Boot automatically configures an in-process embedded instance of Neo4j that does-not persist any data when your application shuts down.+ not persist any data when your application shuts down.[ NOTE]====- As the embedded Neo4j OGM driver does not provide the Neo4j kernel itself,you have-to declare`org.neo4j:neo4j`as dependency yourself.Refer to+As the embedded Neo4j OGM driver does not provide the Neo4j kernel itself,you have+to declare`org.neo4j:neo4j`as dependency yourself.Refer to \nhttps://neo4j.com/docs/ogm-manual/current/reference/# reference:getting-started[the \nNeo4j OGM documentation]for a list of compatible versions.====The embedded driver takes precedence over the other drivers when there are multiple-drivers on the classpath.You can explicitly disable the embedded mode by setting-` spring.data.neo4j.embedded.enabled=false`.+drivers on the classpath.You can explicitly disable the embedded mode by setting+` spring.data.neo4j.embedded.enabled=false`.<< boot-features-testing-spring-boot-applications-testing-autoconfigured-neo4j-test,Data Neo4j Tests>> \nautomatically make use of an embedded Neo4j instance if the embedded driver and Neo4j \nkernel are on the classpath as described above.[ NOTE]====- You can enable persistence for the embedded mode by providing a path to a database file+You can enable persistence for the embedded mode by providing a path to a database file \nin your configuration,e.g.` spring.data.neo4j.uri=file://var/tmp/graph.db`.==== \nabstraction works in the same way,as shown in the following example:} \ndiff --git-- The`spring-boot-starter-data-neo4j`\"`Starter`\" enables the repository support as well+The`spring-boot-starter-data-neo4j`\"`Starter`\" enables the repository support as well \nas transaction management.You can customize the locations to look for repositories and-entities by using`@ EnableNeo4jRepositories`and`@ EntityScan`respectively on a+entities by using`@ EnableNeo4jRepositories`and`@ EntityScan`respectively on a`@ Configuration`- bean.TIP:For complete details of Spring Data Neo4j,including its object mapping \nIf you prefer your test to run against a real database,you can use the-[[boot-features-testing-spring-boot-applications-testing-autoconfigured-jdbc-test]]+[[boot-features-testing-spring-boot-applications-testing-autoconfigured-data-jdbc-test]]==== Auto-configured Data JDBC Tests`@ DataJdbcTest`is similar to`@ JdbcTest`but is for tests that use Spring Data JDBC \nrepositories.By default,it configures an in-memory embedded database,a`JdbcTemplate`, \n",
        "org_diff": "diff --git a/spring-boot-docs/src/main/asciidoc/spring-boot-features.adoc  b/spring-boot-docs/src/main/asciidoc/spring-boot-features.adoc \nproperties:[[boot-features-connecting-to-neo4j-embedded]]==== Using the embedded mode-NOTE:Neo4j's embedded mode is subject to a different licensing,make sure to review it-before integrating the dependency in your application.- \nIf you add`org.neo4j:neo4j-ogm-embedded-driver`to the dependencies of your application,Spring Boot will automatically configure an in-process embedded instance of Neo4j that \nwill not persist any data when your application shuts down.You can explicitly disable \n"
    },
    {
        "sim_msg": "Upgrade to Spring Integration 5 . 1 . 3",
        "sim_diff": "diff --git a/spring-boot-project/spring-boot-dependencies/pom.xml \nppp b/spring-boot-project/spring-boot-dependencies/pom.xml<spring-data-releasetrain.version>Lovelace-SR5</ spring-data-releasetrain.version>< spring-framework.version>${spring.version}</spring-framework.version>< spring-hateoas.version>0.25.1.RELEASE</ spring-hateoas.version>-<spring-integration.version>5.1.3.BUILD-SNAPSHOT</ spring-integration.version>+<spring-integration.version>5.1.3.RELEASE</ spring-integration.version>< spring-kafka.version>2.2.4.RELEASE</ spring-kafka.version>< spring-ldap.version>2.3.2.RELEASE</ spring-ldap.version>< spring-plugin.version>1.2.0.RELEASE</ spring-plugin.version > \n",
        "org_diff": "diff --git a/spring-boot-project/spring-boot-dependencies/pom.xml  b/spring-boot-project/spring-boot-dependencies/pom.xml<spring-data-releasetrain.version>Lovelace-SR19</ spring-data-releasetrain.version>< spring-framework.version>${spring.version}</spring-framework.version>< spring-hateoas.version>0.25.2.RELEASE</ spring-hateoas.version>-<spring-integration.version>5.1.11.RELEASE</ spring-integration.version>+<spring-integration.version>5.1.12.RELEASE</ spring-integration.version>< spring-kafka.version>2.2.14.RELEASE</ spring-kafka.version>< spring-ldap.version>2.3.3.RELEASE</ spring-ldap.version>< spring-plugin.version>1.2.0.RELEASE</ spring-plugin.version > \n"
    },
    {
        "sim_msg": "Adding legacy constructor",
        "sim_diff": "diff --git a/core/src/main/java/hudson/tasks/Maven.java \nppp b/core/src/main/java/hudson/tasks/Maven.java \npublic Maven(String targets,String name){ \nthis(targets,name,null,null,null,false);}+ public Maven(String targets,String name,String pom,String properties,String jvmOptions){+this(targets,name,pom,properties,jvmOptions,false);+}+@ DataBoundConstructor \npublic Maven(String targets,String name,String pom,String properties,String jvmOptions,boolean usePrivateRepository){ \nthis.targets=targets ; \n",
        "org_diff": "diff --git a/core/src/main/java/hudson/tasks/Maven.java  b/core/src/main/java/hudson/tasks/Maven.java \npublic MavenInstallation(String name,String home){@DataBoundConstructor \npublic MavenInstallation(String name,String home,List<? extends ToolProperty<?>> properties){-super(name,home,properties);+super(Util.fixEmptyAndTrim(name), Util.fixEmptyAndTrim(home), properties);}/** \n"
    },
    {
        "sim_msg": "Fix test was making wrong assertions .",
        "sim_diff": "diff --git a/truffle/src/com.oracle.truffle.tck.tests/src/com/oracle/truffle/tck/tests/ValueAssert.java \nppp b/truffle/src/com.oracle.truffle.tck.tests/src/com/oracle/truffle/tck/tests/ValueAssert.java \nprivate static void assertValueImpl(Value value,int depth,boolean hasHostAcces \nassertTrue(stringMap.equals(stringMap));assertFalse(value.as(STRING_OBJECT_MAP). equals(expectedValues));assertTrue(value.as(STRING_OBJECT_MAP). equals(value.as(STRING_OBJECT_MAP)));-assertNotEquals(0,value.as(STRING_OBJECT_MAP). hashCode());+assertNotNull(value.as(STRING_OBJECT_MAP). hashCode()); \nassertNotNull(value.as(STRING_OBJECT_MAP). toString()); \nSet<String>keySet=value.as(Map.class). keySet() ; \n",
        "org_diff": "diff --git a/truffle/src/com.oracle.truffle.tck.tests/src/com/oracle/truffle/tck/tests/ValueAssert.java  b/truffle/src/com.oracle.truffle.tck.tests/src/com/oracle/truffle/tck/tests/ValueAssert.java \nprivate static void assertValueArrayElements(Value value,int depth,boolean has \nassertFails(()->value.as(FLOAT_OBJECT_MAP), ClassCastException.class); \nassertFails(()->value.as(DOUBLE_OBJECT_MAP), ClassCastException.class);-try{- assertEquals(receivedObjectsLongMap,objectMap2);-} catch(AssertionError e){-throw e;-}- assertEquals(receivedObjectsIntMap,objectMap3);-assertEquals(receivedObjectsLongMap,objectMap4);+assertCollectionEqualValues(receivedObjectsLongMap.values(),objectMap2.values());+assertCollectionEqualValues(receivedObjectsIntMap.values(),objectMap3.values());+assertCollectionEqualValues(receivedObjectsLongMap.values(),objectMap4.values());}private static void assertCollectionEqualValues(Collection<? extends Object>expected,Collection<? extends Object>actual){ \n"
    },
    {
        "sim_msg": "Merge pull request from square / jakew / keep - retrofit - interfaces / 2019 - 01 - 22",
        "sim_diff": "diff --git a/retrofit/src/main/resources/META-INF/proguard/retrofit2.pro \nppp b/retrofit/src/main/resources/META-INF/proguard/retrofit2.pro#Top-level functions that can only be used by Kotlin.- dontwarn retrofit2.- KotlinExtensions++#With R8 full mode,it sees no subtypes of Retrofit interfaces since they are created with a Proxy+# and replaces all potential values with null.Explicitly keeping the interfaces prevents this.+-if interface*{@retrofit2.http.*<methods>;}+-keep,allowobfuscation interface<1 > \n",
        "org_diff": "diff --git a/retrofit/src/main/resources/META-INF/proguard/retrofit2.pro  b/retrofit/src/main/resources/META-INF/proguard/retrofit2.pro#Top-level functions that can only be used by Kotlin.- dontwarn retrofit2.KotlinExtensions+- dontwarn retrofit2.KotlinExtensions$*#With R8 full mode,it sees no subtypes of Retrofit interfaces since they are created with a Proxy#and replaces all potential values with null.Explicitly keeping the interfaces prevents this . \n"
    },
    {
        "sim_msg": "[ GR - 18848 ] [ GR - 15901 ] Fix ( de ) - serialization of lambdas .",
        "sim_diff": "diff --git a/src/com.oracle.truffle.espresso/src/com/oracle/truffle/espresso/impl/Klass.java \nppp b/src/com.oracle.truffle.espresso/src/com/oracle/truffle/espresso/impl/Klass.java \npublic Klass getHostClass(){return null;}+/**+* Returns{@ code true}if the type is an anonymous class.+*/+public final boolean isAnonymous(){+ return getHostClass()!= null;+}+/*** Returns true if this type is exactly the type{@ link java.lang.Object}.*/ \ndiff --git a/src/com.oracle.truffle.espresso/src/com/oracle/truffle/espresso/substitutions/Target_java_lang_Class.java \nppp b/src/com.oracle.truffle.espresso/src/com/oracle/truffle/espresso/substitutions/Target_java_lang_Class.java \npublic static boolean desiredAssertionStatus0(@ Host(Class.class)StaticObject cl@Substitution(hasReceiver=true)public static@Host(String.class)StaticObject getName0(@ Host(Class.class)StaticObject self){-String name=self.getMirrorKlass().getType().toString();+ Klass klass=self.getMirrorKlass();+ String name=klass.getType().toString();//Conversion from internal form.- return self.getKlass().getMeta().toGuestString(MetaUtil.internalNameToJava(name,true,true));+ String externalName=MetaUtil.internalNameToJava(name,true,true);++// Reflection relies on anonymous classes including a'/'on the name,to avoid generating+//( invalid)fast method accessors.See+//sun.reflect.misc.ReflectUtil#isVMAnonymousClass(Class<?>).+ if(klass.isAnonymous()){+//A small improvement over HotSpot here,which uses the class identity hash code.+ externalName+=\"/\"+ klass.getID();//VM.JVM_IHashCode(self);+}++// Class names must be interned.+ Meta meta=klass.getMeta();+ return meta.getStrings().intern(meta.toGuestString(externalName));}@Substitution(hasReceiver=true ) \n",
        "org_diff": "diff --git a/src/com.oracle.truffle.espresso/src/com/oracle/truffle/espresso/verifier/Operand.java  b/src/com.oracle.truffle.espresso/src/com/oracle/truffle/espresso/verifier/Operand.java \nboolean compliesWith(Operand other){ \nif(other.getType()== null){ \nreturn false;}+if(other.getType()== type){+/*+*If the two operand have the same type,we can shortcut a few cases:+*+*- Both are not loaded-> would load using same CL.+*+*- Only one of the two is loaded and in same CL as thisKlass.+*/+Klass otherKlass=((ReferenceOperand)other). klass;+ if(otherKlass== null|| klass== null){+Klass k=klass== null?otherKlass:klass;+ if(k== null|| k.getDefiningClassLoader()== thisKlass.getDefiningClassLoader()){+return true;+}+}++} \nKlass otherKlass=other.getKlass();if(otherKlass.isInterface()){-/**+/** 4.10.1.2.For assignments,interfaces are treated like Object.*/return true;boolean compliesWith(Operand other){ \nreturn otherKlass.isAssignableFrom(getKlass());}return other== Invalid;+}@ Override \n"
    },
    {
        "sim_msg": "improved error diagnosis . the logic that looks into the chained exceptions were wrong .",
        "sim_diff": "diff --git a/core/src/main/java/hudson/Util.java \nppp b/core/src/main/java/hudson/Util.java \npublic static String getWin32ErrorMessage(IOException e){*/ \npublic static String getWin32ErrorMessage(Throwable e){ \nString msg=e.getMessage();- if(msg== null){-if(e.getCause()!= null)- return getWin32ErrorMessage(e.getCause());-return null;//no message+if(msg!= null){+Matcher m=errorCodeParser.matcher(msg);+if(m.matches()){+try{+ ResourceBundle rb=ResourceBundle.getBundle(\"/hudson/win32errors\");+ return rb.getString(\" error\"+ m.group(1));+}catch(Exception _){+//silently recover from resource related failures+}+}}- Matcher m=errorCodeParser.matcher(msg);-if(! m.matches())- return null;//failed to parse-try{- ResourceBundle rb=ResourceBundle.getBundle(\"/hudson/win32errors\");- return rb.getString(\" error\"+ m.group(1));-}catch(Exception _){-//silently recover from resource related failures-return null;-}+ if(e.getCause()!= null)+ return getWin32ErrorMessage(e.getCause());+return null;//no message}/** \n",
        "org_diff": "diff --git a/core/src/main/resources/hudson/model/Messages_ru.properties  b/core/src/main/resources/hudson/model/Messages_ru.properties \nBallColor.Failed=\\ u041f\\u0440\\u043e\\u0432\\u0430\\u043b\\u0438\\u043b\\u043e\\u0441\\u0 \nBallColor.InProgress=\\ u0412\\u043f\\u0440\\u043e\\u0446\\u0435\\u0441\\u0441\\u0435 \nBallColor.Pending=\\ u041e\\u0436\\u0438\\u0434\\u0430\\u0435\\u0442 \nBallColor.Success=\\ u0423\\u0441\\u043f\\u0435\\u0448\\u043d\\u043e-BallColor.Unstable=\\ u041d\\u0435\\u0441\\u0442\\u0430\\u0431\\u0438\\u043b\\u044c\\u043d\\u043e+BallColor.Unstable=\\ u041D\\u0435\\u0441\\u0442\\u0430\\u0431\\u0438\\u043B\\u044C\\u043D\\u044B\\u0439 \nComputer.Caption=\\ u041f\\u043e\\u0434\\u0447\\u0438\\u043d\\u0435\\u043d\\u043d\\u044b\\u0439\\u0443\\u0437\\u0435\\u043b{0 } \n"
    },
    {
        "sim_msg": "Add updated submodules",
        "sim_diff": "diff --git a/Extensions/ILSpy.Decompiler/ICSharpCode.Decompiler \nppp b/Extensions/ILSpy.Decompiler/ICSharpCode.Decompiler@@-1+1@@-Subproject commit 2d17234e16d7be5894d9e51a88380dedb72b9b6a+Subproject commit 0c496e07ff210ad00215d5678e1b5610d54e036e \ndiff --git a/Libraries/dnlib \nppp b/Libraries/dnlib@@-1+1@@-Subproject commit 389438b5bd545c4a2d387f5c7b6f367890882ec6+Subproject commit af4aaeac823ae53b790c92c033e764fdde90dfdd \n",
        "org_diff": "diff --git a/codec-http/src/main/java/io/netty/handler/codec/spdy/SpdyFrameCodec.java  b/codec-http/src/main/java/io/netty/handler/codec/spdy/SpdyFrameCodec.java/*** A{@ link ChannelHandler}that encodes and decodes SPDY Frames.*/- public final class SpdyFrameCodec extends ByteToMessageDecoder+public class SpdyFrameCodec extends ByteToMessageDecoder \nimplements SpdyFrameDecoderDelegate,ChannelOutboundHandler{private static final SpdyProtocolException INVALID_FRAME = \n"
    },
    {
        "sim_msg": "Add changelog entry for 14 . 3 . 3",
        "sim_diff": "diff --git a/CHANGELOG.md \nppp b/CHANGELOG.md \nand this project adheres to[Semantic Versioning]( https://semver.org/spec/v2.0.0##[Unreleased][ unreleased]+##[14.3.3]- 2020-03-15++-Skip running on versions of Node.js older than 8.10.0.[#1496]( https://github.com/standard/standard/pull/1496)+##[14.3.2]- 2020-03-14-Update`eslint`to`~ 6.8.0`In`package.json`, use the\"standard\"property:[ view diff]( https://github.com/standard/standard/compare/v3.9.0...v4.0.0)-[unreleased]: https://github.com/standard/standard/compare/v14.3.1...HEAD+[ unreleased]: https://github.com/standard/standard/compare/v14.3.3...HEAD++[14.3.3]: https://github.com/standard/standard/compare/v14.3.2...v14.3.3[14.3.2]: https://github.com/standard/standard/compare/v14.3.1...v14.3.2 \n",
        "org_diff": "diff --git a/rest-api-spec/test/watch_info/10_basic.yaml  b/rest-api-spec/test/watch_info/10_basic.yaml-do:{ watcher.info:{}}-is_true:version.build_hash-is_true:version.build_timestamp-- is_true:version.build_snapshot \n"
    },
    {
        "sim_msg": "move common code to org . jkiss . dbeaver . debug . ui",
        "sim_diff": "diff --git a/plugins/org.jkiss.dbeaver.debug.ui/META-INF/MANIFEST.MF \nppp b/plugins/org.jkiss.dbeaver.debug.ui/META-INF/MANIFEST.MF \nBundle-Version:1.0.0 \nBundle-Vendor:% Bundle-Vendor \nBundle-RequiredExecutionEnvironment:JavaSE-1.8 \nRequire-Bundle:org.eclipse.core.runtime,+ org.eclipse.core.expressions,+ org.eclipse.jface.text,org.eclipse.ui,org.eclipse.debug.ui,org.jkiss.dbeaver.core,similarity index 100%rename from plugins/org.jkiss.dbeaver.ext.postgresql/src/org/jkiss/dbeaver/debug/internal/ui/DebugContributionFactory.java \nrename to plugins/org.jkiss.dbeaver.debug.ui/src/org/jkiss/dbeaver/debug/internal/ui/DebugContributionFactory.java \nsimilarity index 100%rename from plugins/org.jkiss.dbeaver.ext.postgresql/src/org/jkiss/dbeaver/debug/internal/ui/DebugContributionItem.java \nrename to plugins/org.jkiss.dbeaver.debug.ui/src/org/jkiss/dbeaver/debug/internal/ui/DebugContributionItem.java \nsimilarity index 100%rename from plugins/org.jkiss.dbeaver.ext.postgresql/src/org/jkiss/dbeaver/debug/internal/ui/DebugUiInternals.java \nrename to plugins/org.jkiss.dbeaver.debug.ui/src/org/jkiss/dbeaver/debug/internal/ui/DebugUiInternals.java \nsimilarity index 100%rename from plugins/org.jkiss.dbeaver.ext.postgresql/src/org/jkiss/dbeaver/debug/internal/ui/DebugUiMessages.java \nrename to plugins/org.jkiss.dbeaver.debug.ui/src/org/jkiss/dbeaver/debug/internal/ui/DebugUiMessages.java \nsimilarity index 100%rename from plugins/org.jkiss.dbeaver.ext.postgresql/src/org/jkiss/dbeaver/debug/internal/ui/DebugUiMessages.properties \nrename to plugins/org.jkiss.dbeaver.debug.ui/src/org/jkiss/dbeaver/debug/internal/ui/DebugUiMessages.properties \nsimilarity index 100%rename from plugins/org.jkiss.dbeaver.ext.postgresql/src/org/jkiss/dbeaver/debug/ui/DatabaseTab.java \nrename to plugins/org.jkiss.dbeaver.debug.ui/src/org/jkiss/dbeaver/debug/ui/DatabaseTab.java \nsimilarity index 100%rename from plugins/org.jkiss.dbeaver.ext.postgresql/src/org/jkiss/dbeaver/debug/ui/LaunchContributionFactory.java \nrename to plugins/org.jkiss.dbeaver.debug.ui/src/org/jkiss/dbeaver/debug/ui/LaunchContributionFactory.java \nsimilarity index 100%rename from plugins/org.jkiss.dbeaver.ext.postgresql/src/org/jkiss/dbeaver/debug/ui/LaunchContributionItem.java \nrename to plugins/org.jkiss.dbeaver.debug.ui/src/org/jkiss/dbeaver/debug/ui/LaunchContributionItem.java \nsimilarity index 100%rename from plugins/org.jkiss.dbeaver.ext.postgresql/src/org/jkiss/dbeaver/debug/ui/LaunchShortcut.java \nrename to plugins/org.jkiss.dbeaver.debug.ui/src/org/jkiss/dbeaver/debug/ui/LaunchShortcut.java \n",
        "org_diff": "diff --git a/plugins/org.jkiss.dbeaver.debug.core/META-INF/MANIFEST.MF  b/plugins/org.jkiss.dbeaver.debug.core/META-INF/MANIFEST.MF \nBundle-SymbolicName:org.jkiss.dbeaver.debug.core \nBundle-Version:1.0.0 \nBundle-Vendor:% Bundle-Vendor \nBundle-RequiredExecutionEnvironment:JavaSE-1.8+Require-Bundle:org.eclipse.core.runtime,+ org.eclipse.debug.core,+ org.jkiss.dbeaver.model+Export-Package:org.jkiss.dbeaver.debug.core \nsimilarity index 100%rename from plugins/org.jkiss.dbeaver.ext.postgresql/src/org/jkiss/dbeaver/debug/core/DebugCore.java \nrename to plugins/org.jkiss.dbeaver.debug.core/src/org/jkiss/dbeaver/debug/core/DebugCore.java \nsimilarity index 100%rename from plugins/org.jkiss.dbeaver.ext.postgresql/src/org/jkiss/dbeaver/debug/internal/core/DebugCoreMessages.java \nrename to plugins/org.jkiss.dbeaver.debug.core/src/org/jkiss/dbeaver/debug/internal/core/DebugCoreMessages.java \nsimilarity index 100%rename from plugins/org.jkiss.dbeaver.ext.postgresql/src/org/jkiss/dbeaver/debug/internal/core/DebugCoreMessages.properties \nrename to plugins/org.jkiss.dbeaver.debug.core/src/org/jkiss/dbeaver/debug/internal/core/DebugCoreMessages.properties \ndiff --git a/plugins/org.jkiss.dbeaver.ext.postgresql/META-INF/MANIFEST.MF  b/plugins/org.jkiss.dbeaver.ext.postgresql/META-INF/MANIFEST.MF \nRequire-Bundle:org.eclipse.ui,org.eclipse.ui.editors,org.eclipse.debug.core,org.eclipse.debug.ui,+ org.jkiss.dbeaver.debug.core,org.jkiss.dbeaver.ext.generic,org.jkiss.dbeaver.ext.ui.locks,net.sf.opencsv , \n"
    },
    {
        "sim_msg": "Fixes 5 . 3 . 0 - SNAPSHOT typo",
        "sim_diff": "diff --git a/qa/backwards-5.0/build.gradle \nppp b/qa/backwards-5.0/build.gradle \nintegTest{cluster{numNodes=4 \nnumBwcNodes=2-bwcVersion=\" 5.3g.0-SNAPSHOT\"+ bwcVersion=\" 5.3.0-SNAPSHOT\"setting'logger.org.elasticsearch','DEBUG'} \n} \n",
        "org_diff": "diff --git a/qa/backwards-5.0/build.gradle  b/qa/backwards-5.0/build.gradle \nintegTest{cluster{numNodes=4 \nnumBwcNodes=2-bwcVersion=\" 5.2.0-SNAPSHOT\"+ bwcVersion=\" 5.3g.0-SNAPSHOT\"setting'logger.org.elasticsearch','DEBUG'} \n} \n"
    },
    {
        "sim_msg": "doc : transport sniff only adds data nodes",
        "sim_diff": "diff --git a/docs/java-api/client.asciidoc \nppp b/docs/java-api/client.asciidoc \nClient client=new TransportClient(settings); \nOr using`elasticsearch.yml`file as shown in<< node-client>>-The client allows to sniff the rest of the cluster,and add those into-its list of machines to use.In this case,note that the IP addresses+The client allows sniffing the rest of the cluster,which adds data nodes+into its list of machines to use.In this case,note that the IP addresses \nused will be the ones that the other nodes were started with(the\"publish\"address). In order to enable it,set the`client.transport.sniff`to`true`: \n",
        "org_diff": "diff --git a/docs/java-api/client.asciidoc  b/docs/java-api/client.asciidoc \nTransportClient client=new PreBuiltTransportClient(settings); \nThe Transport client comes with a cluster sniffing feature which \nallows it to dynamically add new hosts and remove old ones.- When sniffing is enabled the the transport client will connect to the nodes in its-internal node list,which is built via calls to addTransportAddress.+ When sniffing is enabled,the transport client will connect to the nodes in its+internal node list,which is built via calls to`addTransportAddress`. \nAfter this,the client will call the internal cluster state API on those nodes \nto discover available data nodes.The internal node list of the client will \nbe replaced with those data nodes only.This list is refreshed every five seconds by default.Note that the IP addresses the sniffer connects to are the ones declared as the'publish'address in those node's elasticsearch config.- Keep in mind that list might possibly not include the original node it connected to+Keep in mind that the list might possibly not include the original node it connected to \nif that node is not a data node.If,for instance,you initially connect to a-master node,after sniffing no further requests will go to that master node,- but rather to any data nodes instead.The reason the transport excludes non-data+master node,after sniffing,no further requests will go to that master node,+ but rather to any data nodes instead.The reason the transport client excludes non-data \nnodes is to avoid sending search traffic to master only nodes.In order to enable sniffing,set`client.transport.sniff`to`true`: \n"
    },
    {
        "sim_msg": "Return a \" JsonNull \" object for empty whitespace input into the JsonParser .",
        "sim_diff": "diff --git a/gson/src/main/java/com/google/gson/JsonParser.java \nppp b/gson/src/main/java/com/google/gson/JsonParser.java \npublic JsonElement parse(Reader json)throws JsonParseException{throw new JsonParseException(\" Failed parsing JSON source:\"+json+\" to Json\", e);}catch(JsonParseException e){ \nif(e.getCause() instanceof EOFException){-return null;+ return JsonNull.createJsonNull();} else{throw e;} \ndiff --git a/gson/src/test/java/com/google/gson/JsonParserTest.java \nppp b/gson/src/test/java/com/google/gson/JsonParserTest.java \npublic void testParseString(){assertEquals(10,e.getAsJsonObject().get(\" a\").getAsInt()); \nassertEquals(\" c\", e.getAsJsonObject().get(\" b\").getAsString());}++public void testParseEmptyString(){+ JsonElement e=parser.parse(\"\\\"\\\"\");+ assertTrue(e.isJsonPrimitive());+assertEquals(\"\", e.getAsString());+}++ public void testParseEmptyWhitespaceInput(){+ JsonElement e=parser.parse(\"\");+ assertTrue(e.isJsonNull());+} \npublic void testParseReader(){StringReader reader=new StringReader(\"{a:10,b:' c'}\") ; \n",
        "org_diff": "diff --git a/gson/src/main/java/com/google/gson/internal/bind/JsonElementWriter.java  b/gson/src/main/java/com/google/gson/internal/bind/JsonElementWriter.java \nprivate JsonElement peek(){private void put(JsonElement value){ \nif(pendingName!= null){-JsonObject object=( JsonObject)peek();- object.add(pendingName,value);+if(! value.isJsonNull()|| getSerializeNulls()){+JsonObject object=( JsonObject)peek();+ object.add(pendingName,value);+} \npendingName=null;} else if(stack.isEmpty()){ \nproduct=value;diff --git a/gson/src/test/java/com/google/gson/internal/bind/JsonElementWriterTest.java  b/gson/src/test/java/com/google/gson/internal/bind/JsonElementWriterTest.java// TODO:more tests// TODO:figure out what should be returned by an empty writer-//TODO:test when serialize nulls is false \npublic void testArray() throws IOException{JsonElementWriter writer=new JsonElementWriter();public void testPrematureClose() throws Exception{} catch(IOException expected){}}++ public void testSerializeNullsFalse() throws IOException{+ JsonElementWriter writer=new JsonElementWriter();+ writer.setSerializeNulls(false);+writer.beginObject();+ writer.name(\" A\");+ writer.nullValue();+ writer.endObject();+ assertEquals(\"{}\", writer.get().toString());+}++ public void testSerializeNullsTrue() throws IOException{+ JsonElementWriter writer=new JsonElementWriter();+ writer.setSerializeNulls(true);+writer.beginObject();+ writer.name(\" A\");+ writer.nullValue();+ writer.endObject();+ assertEquals(\"{\\\"A\\\":null}\",writer.get().toString());+} \n} \n"
    },
    {
        "sim_msg": "remove package rx . lang . scala . util since all its contents were removed",
        "sim_diff": "deleted file mode 100644 \nindex 45afef4a4d.. 0000000000 \ndiff --git a/language-adaptors/rxjava-scala/src/main/scala/rx/lang/scala/util/package.scala \nppp/dev/null-/**-* Copyright 2013 Netflix,Inc.-*-*Licensed under the Apache License,Version 2.0(the\"License\");-*you may not use this file except in compliance with the License.-*You may obtain a copy of the License at-*-* http://www.apache.org/licenses/LICENSE-2.0-*-* Unless required by applicable law or agreed to in writing,software-* distributed under the License is distributed on an\"AS IS\"BASIS,-*WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND,either express or implied.-*See the License for the specific language governing permissions and-* limitations under the License.-*/-package rx.lang.scala--/**-*Provides[[ Opening]] s,[[Closing]] s,and[[ Timestamped]].-*/-package object util{--//rx.util.Range not needed because there's a standard Scala Range-- } \n",
        "org_diff": "new file mode 100644 \nindex 0000000000.. 7566d5fad8 \ndiff --git/dev/null  b/language-adaptors/rxjava-scala/src/main/scala/rx/lang/scala/subjects/package.scala+/**+* Copyright 2013 Netflix,Inc.+*+*Licensed under the Apache License,Version 2.0(the\"License\");+*you may not use this file except in compliance with the License.+*You may obtain a copy of the License at+*+* http://www.apache.org/licenses/LICENSE-2.0+*+* Unless required by applicable law or agreed to in writing,software+* distributed under the License is distributed on an\"AS IS\"BASIS,+*WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND,either express or implied.+*See the License for the specific language governing permissions and+* limitations under the License.+*/+package rx.lang.scala++/**+*Subjects are Observers and Observables at the same time.+*/+package object subjects{} \n"
    },
    {
        "sim_msg": "Merge pull request in G / graal - core from ~ JOSEF . E . EISL_ORACLE . COM / graal - core : ci - fix - tracera to master",
        "sim_diff": "diff --git a/ci_common/x52-tracera.hocon \nppp b/ci_common/x52-tracera.hocon \nx52.tracera:${x52.default}{}builds+=[-${ x52.default}${bench-dacapo}{ name:\" bench-dacapo-linux-x52-tracera\"}-${x52.default}${bench-dacapo-timing}{ name:\" bench-dacapo-timing-linux-x52-tracera\"}-${x52.default}${bench-scala-dacapo}{ name:\" bench-scala-dacapo-linux-x52-tracera\"}-${x52.default}${bench-scala-dacapo-timing}{ name:\" bench-scala-dacapo-timing-linux-x52-tracera\"}-${x52.default}${bench-specjvm2008}{ name:\" bench-specjvm2008-linux-x52-tracera\"}-${x52.default}${bench-specjbb2015}{ name:\" bench-specjbb2015-linux-x52-tracera\"}-${x52.default}${bench-micros-graal}{ name:\" bench-jmh-micros-graal-linux-x52-tracera\"}+${x52.tracera}${bench-dacapo}{ name:\" bench-dacapo-linux-x52-tracera\"}+${x52.tracera}${bench-dacapo-timing}{ name:\" bench-dacapo-timing-linux-x52-tracera\"}+${x52.tracera}${bench-scala-dacapo}{ name:\" bench-scala-dacapo-linux-x52-tracera\"}+${x52.tracera}${bench-scala-dacapo-timing}{ name:\" bench-scala-dacapo-timing-linux-x52-tracera\"}+${x52.tracera}${bench-specjvm2008}{ name:\" bench-specjvm2008-linux-x52-tracera\"}+${x52.tracera}${bench-specjbb2015}{ name:\" bench-specjbb2015-linux-x52-tracera\"}+${x52.tracera}${bench-micros-graal}{ name:\" bench-jmh-micros-graal-linux-x52-tracera\"} \n] \n",
        "org_diff": "diff --git a/ci_common/x52-tracera.hocon  b/ci_common/x52-tracera.hocon \nx52.tracera:${x52.default}{}builds+=[-${ x52.default}${bench-dacapo}{ name:\" bench-dacapo-linux-x52-tracera\"}-${x52.default}${bench-dacapo-timing}{ name:\" bench-dacapo-timing-linux-x52-tracera\"}-${x52.default}${bench-scala-dacapo}{ name:\" bench-scala-dacapo-linux-x52-tracera\"}-${x52.default}${bench-scala-dacapo-timing}{ name:\" bench-scala-dacapo-timing-linux-x52-tracera\"}-${x52.default}${bench-specjvm2008}{ name:\" bench-specjvm2008-linux-x52-tracera\"}-${x52.default}${bench-specjbb2015}{ name:\" bench-specjbb2015-linux-x52-tracera\"}-${x52.default}${bench-micros-graal}{ name:\" bench-jmh-micros-graal-linux-x52-tracera\"}+${x52.tracera}${bench-dacapo}{ name:\" bench-dacapo-linux-x52-tracera\"}+${x52.tracera}${bench-dacapo-timing}{ name:\" bench-dacapo-timing-linux-x52-tracera\"}+${x52.tracera}${bench-scala-dacapo}{ name:\" bench-scala-dacapo-linux-x52-tracera\"}+${x52.tracera}${bench-scala-dacapo-timing}{ name:\" bench-scala-dacapo-timing-linux-x52-tracera\"}+${x52.tracera}${bench-specjvm2008}{ name:\" bench-specjvm2008-linux-x52-tracera\"}+${x52.tracera}${bench-specjbb2015}{ name:\" bench-specjbb2015-linux-x52-tracera\"}+${x52.tracera}${bench-micros-graal}{ name:\" bench-jmh-micros-graal-linux-x52-tracera\"} \n] \n"
    },
    {
        "sim_msg": "Excluding this test that keeps failing and blocking my release .",
        "sim_diff": "diff --git a/test/src/test/java/hudson/UDPBroadcastThreadTest.java \nppp b/test/src/test/java/hudson/UDPBroadcastThreadTest.java \nprivate static void updatePort(int newValue)throws Exception{/***Multicast based clients should be able to receive multiple replies.*/-@Test public void multicast() throws Exception{+//@Test:keeps failing-excluding for now+public void multicast() throws Exception{UDPBroadcastThread second=new UDPBroadcastThread(j.jenkins); \nsecond.start() ; \n",
        "org_diff": "diff --git a/test/src/test/java/hudson/UDPBroadcastThreadTest.java  b/test/src/test/java/hudson/UDPBroadcastThreadTest.java \npublic void testLegacy() throws Exception{* Multicast based clients should be able to receive multiple replies.*/public void testMulticast() throws Exception{- UDPBroadcastThread second=new UDPBroadcastThread(hudson);+UDPBroadcastThread second=new UDPBroadcastThread(jenkins); \nsecond.start();++UDPBroadcastThread third=new UDPBroadcastThread(jenkins);+third.start();+ \nsecond.ready.block();+ third.ready.block();try{DatagramSocket s=new DatagramSocket();public void testMulticast() throws Exception{receiveAndVerify(s); \nreceiveAndVerify(s);}finally{+ third.interrupt();second.interrupt();} \n} \n"
    },
    {
        "sim_msg": "JariBakken : Remove code generation",
        "sim_diff": "diff --git a/selenium/src/rb/Rakefile \nppp b/selenium/src/rb/Rakefile \nrequire'spec/rake/spectask'require'selenium/rake/tasks'CLEAN.include(\" COMMENTS\")-CLEAN.include(' lib/selenium/client/generated_driver.rb','**/*. log',\"target\",\"pkg\",\"test/integration/reporting/dummy_project/target\")+CLEAN.include('**/*.log',\"target\",\"pkg\",\"test/integration/reporting/dummy_project/target\") \nif ENV[\" SELENIUM_RC_JAR\"]#User override \nfile\"target/iedoc.xml\"do \nend \nend-desc\"Generate driver from iedoc.xml\"- file\"lib/selenium/client/generated_driver.rb\"=>[\"target/iedoc.xml\"] do-sh\"ant generate-sources\"- end-desc\"Run unit tests\"Rake:: TestTask.new(:'test:unit') do|t|t.test_files=FileList[' test/unit/**/*_tests.rb'] \nt.warning=true \nend-task:\" test:unit\"=>\" lib/selenium/client/generated_driver.rb\"+ task:\" test:unit\"Selenium:: Rake:: RemoteControlStartTask.new do|rc|rc.port=4444 \nSpec:: Rake:: SpecTask.new(\" test:integration\") do|t|t.spec_opts<<\"--format=Selenium:: RSpec:: SeleniumTestReportFormatter:./target/integration_tests_report.html\"t.spec_opts<<\"--format=progress\"end-task:\" test:integration\"=>[\"lib/selenium/client/generated_driver.rb\"]+task:\" test:integration\"begin \ngem\"deep_test\",\">=1.2.1\"Rake:: GemPackageTask.new(specification)do|package|end \ndesc\"Build the RubyGem\"- task:gem=>\"lib/selenium/client/generated_driver.rb\"+ task:gem \ndesc\"Generate documentation\"Rake:: RDocTask.new(\" rdoc\") do|rdoc|diff --git a/selenium/src/rb/pom.xml \nppp b/selenium/src/rb/pom.xml</ execution></executions></plugin>-<plugin>+<!--<plugin>< artifactId>maven-clean-plugin</ artifactId>< configuration>< filesets></fileset></filesets></configuration>-</ plugin>+</ plugin>--></ plugins></build></project > \n",
        "org_diff": "diff --git a/clients/ruby/ChangeLog  b/clients/ruby/ChangeLog======-Include examples in RubyGem+- Added visible?method \n1.2.10=======diff --git a/clients/ruby/Rakefile  b/clients/ruby/Rakefile \ntask:' ci:integration'=>[:clean,:'test:unit'] do \nend \nfile\"target/iedoc.xml\"do-sh\"unzip-uj'#{SELENIUM_RC_JAR}' core/iedoc.xml-d target\"+ has_unzip=system\"unzipx-v\"+ if has_unzip+sh\"unzip-uj'#{SELENIUM_RC_JAR}' core/iedoc.xml-d target\"+ else#Windows support assumes Java is installed+sh\"jar xvf\\\"#{ SELENIUM_RC_JAR}\\\"core/iedoc.xml\"+ FileUtils.mkdir_p\"target\"+ FileUtils.mv\"core/iedoc.xml\",\"target/iedoc.xml\"+ FileUtils.rmdir\"core\"+ end \nend \ndesc\"Generate driver from iedoc.xml \" \n"
    },
    {
        "sim_msg": "fix the issue that an immediate login after logout will be redirected to signin page ( )",
        "sim_diff": "diff --git a/apollo-portal/src/main/java/com/ctrip/framework/apollo/portal/spi/configuration/AuthConfiguration.java \nppp b/apollo-portal/src/main/java/com/ctrip/framework/apollo/portal/spi/configuration/AuthConfiguration.java \nprotected void configure(HttpSecurity http)throws Exception{http.authorizeRequests().antMatchers(\"/prometheus/**\",\"/metrics/**\",\"/openapi/**\",\"/vendor/**\",\"/styles/**\",\"/scripts/**\",\"/views/**\",\"/img/**\"). permitAll().antMatchers(\"/**\"). hasAnyRole(USER_ROLE);-http.formLogin().loginPage(\"/signin\").permitAll().failureUrl(\"/signin?#/error\").and().httpBasic();- SimpleUrlLogoutSuccessHandler urlLogoutHandler=new SimpleUrlLogoutSuccessHandler();- urlLogoutHandler.setDefaultTargetUrl(\"/signin?#/logout\");+ http.formLogin().loginPage(\"/signin\").defaultSuccessUrl(\"/\",true). permitAll().failureUrl(\"/signin?#/error\").and()+. httpBasic();http.logout().logoutUrl(\"/user/logout\").invalidateHttpSession(true). clearAuthentication(true)-.logoutSuccessHandler(urlLogoutHandler);+. logoutSuccessUrl(\"/signin?#/logout\");http.exceptionHandling().authenticationEntryPoint(new LoginUrlAuthenticationEntryPoint(\"/signin\")); \n} \n",
        "org_diff": "diff --git a/apollo-portal/src/main/java/com/ctrip/framework/apollo/portal/controller/PrefixPathController.java  b/apollo-portal/src/main/java/com/ctrip/framework/apollo/portal/controller/PrefixPathController.java@Value(\"${ prefixPath:}\") \nprivate String prefixPath;-@GetMapping(\"/prefixPath\")+@ GetMapping(\"/prefix-path\") \npublic String getPrefixPath(){return prefixPath;} \ndiff --git a/apollo-portal/src/main/java/com/ctrip/framework/apollo/portal/spi/configuration/AuthConfiguration.java  b/apollo-portal/src/main/java/com/ctrip/framework/apollo/portal/spi/configuration/AuthConfiguration.java \nprotected void configure(HttpSecurity http)throws Exception{http.csrf().disable();http.headers().frameOptions().sameOrigin();http.authorizeRequests()-. antMatchers(\"/prometheus/**\",\"/metrics/**\",\"/openapi/**\",\"/vendor/**\",\"/styles/**\",\"/scripts/**\",\"/views/**\",\"/img/**\",\"/i18n/**\",\"/prefixPath\").permitAll()+. antMatchers(\"/prometheus/**\",\"/metrics/**\",\"/openapi/**\",\"/vendor/**\",\"/styles/**\",\"/scripts/**\",\"/views/**\",\"/img/**\",\"/i18n/**\",\"/prefix-path\").permitAll().antMatchers(\"/**\"). hasAnyRole(USER_ROLE); \nhttp.formLogin().loginPage(\"/signin\").defaultSuccessUrl(\"/\",true). permitAll().failureUrl(\"/signin?#/error\").and().httpBasic();protected void configure(HttpSecurity http)throws Exception{http.csrf().disable();http.headers().frameOptions().sameOrigin();http.authorizeRequests()-. antMatchers(\"/prometheus/**\",\"/metrics/**\",\"/openapi/**\",\"/vendor/**\",\"/styles/**\",\"/scripts/**\",\"/views/**\",\"/img/**\",\"/i18n/**\",\"/prefixPath\").permitAll()+. antMatchers(\"/prometheus/**\",\"/metrics/**\",\"/openapi/**\",\"/vendor/**\",\"/styles/**\",\"/scripts/**\",\"/views/**\",\"/img/**\",\"/i18n/**\",\"/prefix-path\").permitAll().antMatchers(\"/**\"). authenticated();http.formLogin().loginPage(\"/signin\").defaultSuccessUrl(\"/\",true). permitAll().failureUrl(\"/signin?#/error\").and().httpBasic();diff --git a/apollo-portal/src/main/resources/static/login.html  b/apollo-portal/src/main/resources/static/login.html \ne.preventDefault();});-$.get(\" prefixPath\", function(result){+$.get(\" prefix-path\", function(result){ \nwindow.localStorage.setItem(\" prefixPath\", result);}) ; \n"
    },
    {
        "sim_msg": "[ ENGINE ] Add current translog ID to commit meta before closing",
        "sim_diff": "diff --git a/src/main/java/org/elasticsearch/index/engine/internal/InternalEngine.java \nppp b/src/main/java/org/elasticsearch/index/engine/internal/InternalEngine.java \npublic void flush(Flush flush)throws EngineException{//disable refreshing,not dirty \ndirty=false;try{-// that's ok if the index writer failed and is in inconsistent state-//we will get an exception on a dirty operation,and will cause the shard-//to be allocated to a different node-currentIndexWriter().close(false);+{// commit and close the current writer-we write the current tanslog ID just in case+final long translogId=translog.currentId();+ indexWriter.setCommitData(MapBuilder.< String,String>newMapBuilder().put(Translog.TRANSLOG_ID_KEY,Long.toString(translogId)).map());+indexWriter.commit();+ indexWriter.rollback();+}indexWriter=createWriter();mergeScheduler.removeListener(this.throttle); \n",
        "org_diff": "diff --git a/src/main/java/org/elasticsearch/index/engine/robin/RobinEngine.java  b/src/main/java/org/elasticsearch/index/engine/robin/RobinEngine.java \npublic void flush(Flush flush)throws EngineException{translog.newTransientTranslog(translogId); \nindexWriter.setCommitData(MapBuilder.< String,String>newMapBuilder().put(Translog.TRANSLOG_ID_KEY,Long.toString(translogId)).map()); \nindexWriter.commit();- if(flush.force()){-//if we force,we might not have committed,we need to check that its the same id-Map<String,String>commitUserData=Lucene.readSegmentInfos(store.directory()). getUserData();- long committedTranslogId=Long.parseLong(commitUserData.get(Translog.TRANSLOG_ID_KEY));- if(committedTranslogId!= translogId){-//we did not commit anything,revert to the old translog-translog.revertTransient();-}else{- makeTransientCurrent=true;-}-}else{- makeTransientCurrent=true;-}- if(makeTransientCurrent){-refreshVersioningTable(threadPool.estimatedTimeInMillis());-//we need to move transient to current only after we refresh-//so items added to current will still be around for realtime get-//when tans overrides it-translog.makeTransientCurrent();-}+ refreshVersioningTable(threadPool.estimatedTimeInMillis());+//we need to move transient to current only after we refresh+//so items added to current will still be around for realtime get+//when tans overrides it+translog.makeTransientCurrent();} catch(OutOfMemoryError e){ \ntranslog.revertTransient();failEngine(e); \n"
    },
    {
        "sim_msg": "Merge pull request from kwoyke / JAVA - 2974",
        "sim_diff": "diff --git a/persistence-modules/spring-data-jpa-enterprise/pom.xml \nppp b/persistence-modules/spring-data-jpa-enterprise/pom.xml</ build>< properties>-<spring-boot-version>2.1.9.RELEASE</ spring-boot-version>-<start-class>com.baeldung.springdatageode.app.ClientCacheApp</ start-class>-<spring-geode-starter-version>1.1.1.RELEASE</ spring-geode-starter-version>-<spring.boot.starter.version>2.1.9.RELEASE</ spring.boot.starter.version>< mapstruct.version>1.3.1.Final</ mapstruct.version>< guava.version>21.0</ guava.version>< testcontainers.version>1.12.2</ testcontainers.version > \n",
        "org_diff": "diff --git a/persistence-modules/spring-jpa-2/pom.xml  b/persistence-modules/spring-jpa-2/pom.xml<artifactId>guava</ artifactId>< version>${guava.version}</version></dependency>+<dependency>+<groupId>net.bytebuddy</ groupId>+<artifactId>byte-buddy</ artifactId>+<version>${byte-buddy.version}</version>+</ dependency><!--test scoped-->< dependency>< properties><!--Spring-->< org.springframework.version>5.1.5.RELEASE</ org.springframework.version>+<spring-boot.version>2.2.6.RELEASE</ spring-boot.version><!--persistence-->< tomcat-dbcp.version>9.0.0.M26</ tomcat-dbcp.version><!--utilities-->< guava.version>21.0</ guava.version>-<spring-boot.version>2.2.6.RELEASE</ spring-boot.version>+<byte-buddy.version>1.10.16</ byte-buddy.version></properties></project>\\ No newline at end of file \n"
    },
    {
        "sim_msg": "Mute TimeSeriesLifecycleActionsIT ( )",
        "sim_diff": "diff --git a/x-pack/plugin/ilm/qa/multi-node/src/test/java/org/elasticsearch/xpack/ilm/TimeSeriesLifecycleActionsIT.java \nppp b/x-pack/plugin/ilm/qa/multi-node/src/test/java/org/elasticsearch/xpack/ilm/TimeSeriesLifecycleActionsIT.java \nimport org.apache.http.entity.StringEntity;import org.apache.logging.log4j.LogManager;import org.apache.logging.log4j.Logger;+ import org.apache.lucene.util.LuceneTestCase;import org.elasticsearch.client.Request;import org.elasticsearch.client.Response;import org.elasticsearch.client.ResponseException;import static org.hamcrest.Matchers.not;import static org.hamcrest.Matchers.nullValue;+@LuceneTestCase.AwaitsFix(bugUrl=\" https://github.com/elastic/elasticsearch/issues/53738\") \npublic class TimeSeriesLifecycleActionsIT extends ESRestTestCase{private static final Logger logger=LogManager.getLogger(TimeSeriesLifecycleActionsIT.class); \nprivate static final String FAILED_STEP_RETRY_COUNT_FIELD=\" failed_step_retry_count\"; \npublic void refreshIndex(){public static void updatePolicy(String indexName,String policy)throws IOException{Request changePolicyRequest=new Request(\" PUT\",\"/\"+ indexName+\"/_settings\");final StringEntity changePolicyEntity=new StringEntity(\"{\\\"index.lifecycle.name\\\":\\\"\"+policy+\"\\\"}\",- ContentType.APPLICATION_JSON);+ContentType.APPLICATION_JSON); \nchangePolicyRequest.setEntity(changePolicyEntity); \nassertOK(client().performRequest(changePolicyRequest));} \npublic void testSetSingleNodeAllocationRetriesUntilItSucceeds() throws Exception \ncreateIndexWithSettings(index,Settings.builder().put(IndexMetaData.SETTING_NUMBER_OF_SHARDS,numShards). put(IndexMetaData.SETTING_NUMBER_OF_REPLICAS,0));- ensureGreen(index);+ensureGreen(index);-//unallocate all index shards+//unallocate all index shards \nRequest setAllocationToMissingAttribute=new Request(\" PUT\",\"/\"+ index+\"/_settings\");setAllocationToMissingAttribute.setJsonEntity(\"{\\ n\"+\"\\\"settings\\\":{\\n\"+ \npublic void testWaitForActiveShardsStep() throws Exception{String originalIndex=index+\"-000001\"; \nString secondIndex=index+\"-000002\"; \ncreateIndexWithSettings(originalIndex,Settings.builder().put(IndexMetaData.SETTING_NUMBER_OF_SHARDS,1)-.put(IndexMetaData.SETTING_NUMBER_OF_REPLICAS,0)-.put(RolloverAction.LIFECYCLE_ROLLOVER_ALIAS,alias),+. put(IndexMetaData.SETTING_NUMBER_OF_REPLICAS,0)+.put(RolloverAction.LIFECYCLE_ROLLOVER_ALIAS,alias), \ntrue);// create policy \nprivate void createSlmPolicy(String smlPolicy,String repo)throws IOException{. field(\" repository\", repo). field(\" name\",\"snap\"+ randomAlphaOfLengthBetween(5,10). toLowerCase(Locale.ROOT)).startObject(\" config\")-. field(\" include_global_state\", false)+.field(\" include_global_state\", false). endObject().endObject())) ; \n",
        "org_diff": "diff --git a/x-pack/plugin/ilm/qa/multi-cluster/src/test/java/org/elasticsearch/xpack/ilm/CCRIndexLifecycleIT.java  b/x-pack/plugin/ilm/qa/multi-cluster/src/test/java/org/elasticsearch/xpack/ilm/CCRIndexLifecycleIT.java \nimport org.apache.http.entity.ContentType;import org.apache.http.entity.StringEntity;+ import org.apache.http.util.EntityUtils;import org.apache.logging.log4j.LogManager;import org.apache.logging.log4j.Logger;- import org.apache.lucene.util.LuceneTestCase;import org.elasticsearch.client.Request;import org.elasticsearch.client.Response;+ import org.elasticsearch.client.ResponseException;import org.elasticsearch.client.RestClient;import org.elasticsearch.common.Strings;import org.elasticsearch.common.settings.Settings;public void testBasicCCRAndILMIntegration() throws Exception{}}-@LuceneTestCase.AwaitsFix(bugUrl=\" https://github.com/elastic/elasticsearch/issues/48461\") \npublic void testCCRUnfollowDuringSnapshot() throws Exception{String indexName=\" unfollow-test-index\"; \nif(\" leader\". equals(targetCluster)){private static Object getIndexSetting(RestClient client,String index,String se \nreturn settings.get(setting);}- private static void assertDocumentExists(RestClient client,String index,String id)throws IOException{- Request request=new Request(\" HEAD\",\"/\"+ index+\"/_doc/\"+id);-Response response=client.performRequest(request);-assertThat(response.getStatusLine().getStatusCode(),equalTo(200));+ private void assertDocumentExists(RestClient client,String index,String id)throws IOException{+ Request request=new Request(\" GET\",\"/\"+ index+\"/_doc/\"+id);+Response response;+ try{+ response=client.performRequest(request);+if(response.getStatusLine().getStatusCode()!= 200){+if(response.getEntity()!= null){+logger.error(EntityUtils.toString(response.getEntity()));+}else{+ logger.error(\" response body was null\");+}+ fail(\" HTTP response code expected to be[200]but was[\"+response.getStatusLine().getStatusCode()+\"]\");+}+} catch(ResponseException ex){+if(ex.getResponse().getEntity()!= null){+logger.error(EntityUtils.toString(ex.getResponse().getEntity()), ex);+} else{+ logger.error(\" response body was null\");+}+ fail(\" HTTP response code expected to be[200]but was[\"+ex.getResponse().getStatusLine().getStatusCode()+\"]\");+}}private void createNewSingletonPolicy(String policyName,String phaseName,LifecycleAction action,TimeValue after)throws IOException { \n"
    },
    {
        "sim_msg": "AlexeiBarantsev : Implementing testSendingKeyboardEventsShouldAppendTextinTextAreas for HtmlUnitDriver",
        "sim_diff": "diff --git a/java/client/src/org/openqa/selenium/htmlunit/HtmlUnitKeyboard.java \nppp b/java/client/src/org/openqa/selenium/htmlunit/HtmlUnitKeyboard.java \npublic void sendKeys(HtmlElement element,String currentValue,InputKeysContaine \nkeysToSend.setCapitalization(modifiersState.isShiftPressed()); \nif(parent.isJavascriptEnabled()&&!( element instanceof HtmlFileInput)){+ if(element instanceof HtmlTextArea){+String text=((HtmlTextArea)element). getText();+(( HtmlTextArea)element). setSelectionStart(text.length());+((HtmlTextArea)element). setSelectionEnd(text.length());+} \ntry{element.type(keysToSend.toString());}catch(IOException e){ \ndiff --git a/java/client/test/org/openqa/selenium/FormHandlingTest.java \nppp b/java/client/test/org/openqa/selenium/FormHandlingTest.java \nimport static org.junit.Assert.fail;import static org.openqa.selenium.testing.Ignore.Driver.ANDROID;import static org.openqa.selenium.testing.Ignore.Driver.CHROME;- import static org.openqa.selenium.testing.Ignore.Driver.HTMLUNIT;import static org.openqa.selenium.testing.Ignore.Driver.IPHONE;import static org.openqa.selenium.testing.Ignore.Driver.OPERA;import static org.openqa.selenium.testing.Ignore.Driver.SELENESE;public void testSendingKeyboardEventsShouldAppendTextInInputsWithExistingValue() \nassertThat(value,is(\" Example text.Some text\"));}-@Ignore(value={ HTMLUNIT,SELENESE,IPHONE,ANDROID},+@ Ignore(value={ SELENESE,IPHONE,ANDROID}, \nreason=\" Not implemented going to the end of the line first;\\ n\"+\"iPhone:sendKeys not implemented correctly\")@Test \n",
        "org_diff": "diff --git a/java/client/src/org/openqa/selenium/htmlunit/HtmlUnitAlert.java  b/java/client/src/org/openqa/selenium/htmlunit/HtmlUnitAlert.java \npublic void sendKeys(String keysToSend){ \npublic void authenticateUsing(Credentials credentials){}+@Override+public void setCredentials(Credentials credentials){+}++@Override \npublic void handleAlert(Page page,String message){ \nQueue<String>queue=queues.get(page); \n"
    },
    {
        "sim_msg": "Automated rollback of commit 56ef727987c05df2953a4a53935b4f9b899f9d81 .",
        "sim_diff": "diff --git a/src/main/java/com/google/devtools/build/lib/rules/java/JvmConfigurationLoader.java \nppp b/src/main/java/com/google/devtools/build/lib/rules/java/JvmConfigurationLoader.java \nprivate static Jvm createFromJavaRuntimeSuite(} \nTarget javaHomeTarget=lookup.getTarget(javaBase); \nif(javaHomeTarget instanceof Rule){-switch(((Rule)javaHomeTarget). getRuleClass()){-case\"java_runtime_suite\":-return createFromRuntimeSuite(lookup,( Rule)javaHomeTarget,cpu);-case\"java_runtime\":-return createFromRuntime(lookup,javaHomeTarget.getLabel());-default:- throw new InvalidConfigurationException(-\"Unexpected javabase rule kind'\"-+(( Rule)javaHomeTarget). getRuleClass()-+\"'.Expected java_runtime_suite\");+ if(!(( Rule)javaHomeTarget). getRuleClass().equals(\" java_runtime_suite\")){+throw new InvalidConfigurationException(+\"Unexpected javabase rule kind'\"++(( Rule)javaHomeTarget). getRuleClass()++\"'.Expected java_runtime_suite\");}+return createFromRuntimeSuite(lookup,( Rule)javaHomeTarget,cpu);}throw new InvalidConfigurationException(\" No JVM target found under\"+ javaBase+\" that would work for\"+ cpu); \nprivate static Jvm createFromJavaRuntimeSuite(//TODO(b/34175492): eventually the Jvm fragement will containg only the label of a java_runtime// rule,and all of the configuration will be accessed using JavaRuntimeInfo.--private static Jvm createFromRuntimeSuite(- ConfigurationEnvironment lookup,Rule javaRuntimeSuite,String cpu)+ private static Jvm createFromRuntimeSuite(ConfigurationEnvironment lookup,Rule javaRuntimeSuite,+ String cpu)throws InvalidConfigurationException,InterruptedException,NoSuchTargetException,NoSuchPackageException{Label javaRuntimeLabel=selectRuntime(javaRuntimeSuite,cpu);-PathFragment javaHome=getJavaHome(lookup,javaRuntimeLabel);-return new Jvm(javaHome,javaRuntimeSuite.getLabel());-}-- private static Jvm createFromRuntime(ConfigurationEnvironment lookup,Label javaRuntimeLabel)- throws InvalidConfigurationException,InterruptedException,NoSuchTargetException,- NoSuchPackageException{- return new Jvm(getJavaHome(lookup,javaRuntimeLabel), javaRuntimeLabel);-}-- private static PathFragment getJavaHome(ConfigurationEnvironment lookup,Label javaRuntimeLabel)- throws NoSuchPackageException,NoSuchTargetException,InterruptedException,- InvalidConfigurationException{Target javaRuntimeTarget=lookup.getTarget(javaRuntimeLabel); \nif(javaRuntimeTarget== null){ \nreturn null;private static PathFragment getJavaHome(ConfigurationEnvironment lookup,Label j \njavaHomePath,srcs.toString()));}}- return javaHomePath;+ return new Jvm(javaHomePath,javaRuntimeSuite.getLabel());}private static Label selectRuntime(Rule javaRuntimeSuite,String cpu ) \n",
        "org_diff": "diff --git a/src/main/java/com/google/devtools/build/lib/rules/java/JvmConfigurationLoader.java  b/src/main/java/com/google/devtools/build/lib/rules/java/JvmConfigurationLoader.java \nprivate static Jvm createDefault(ConfigurationEnvironment lookup,String javaHom \nreturn null;} \nTarget javaHomeTarget=lookup.getTarget(label);-if(javaHomeTarget== null){-return null;-}if(( javaHomeTarget instanceof Rule)&&\" filegroup\". equals(((Rule)javaHomeTarget). getRuleClass())){RawAttributeMapper javaHomeAttributes=RawAttributeMapper.of(( Rule)javaHomeTarget); \n"
    },
    {
        "sim_msg": "Fix typo in GraphBuilder . nodeOrder ( ) javadoc .",
        "sim_diff": "diff --git a/guava/src/com/google/common/graph/GraphBuilder.java \nppp b/guava/src/com/google/common/graph/GraphBuilder.java \nprivate GraphBuilder(boolean directed){}/**-* Specifies the order of iteration for the elements of{@ link Network#nodes()}.+* Specifies the order of iteration for the elements of{@ link Graph#nodes()}.*/ \npublic<N1 extends N>GraphBuilder<N1>nodeOrder(ElementOrder<N1>nodeOrder){ \ncheckNotNull(nodeOrder); \n",
        "org_diff": "diff --git a/guava/src/com/google/common/graph/NetworkBuilder.java  b/guava/src/com/google/common/graph/NetworkBuilder.java*@ author Joshua O'Madadhain*@ since 20.0*/-//TODO(user): try creating an abstract superclass that this and GraphBuilder could derive from.@ Beta \npublic final class NetworkBuilder<N,E>{ \nfinal boolean directed ; \n"
    },
    {
        "sim_msg": "Always update animatable when updating resource in ImageViewTarget .",
        "sim_diff": "diff --git a/library/src/main/java/com/bumptech/glide/request/target/ImageViewTarget.java \nppp b/library/src/main/java/com/bumptech/glide/request/target/ImageViewTarget.java \npublic void setDrawable(Drawable drawable){@Override \npublic void onLoadStarted(@ Nullable Drawable placeholder){ \nsuper.onLoadStarted(placeholder);-setResource(null);+setResourceInternal(null); \nsetDrawable(placeholder);}public void onLoadStarted(@ Nullable Drawable placeholder){@Override \npublic void onLoadFailed(@ Nullable Drawable errorDrawable){ \nsuper.onLoadFailed(errorDrawable);-setResource(null);+setResourceInternal(null); \nsetDrawable(errorDrawable);}public void onLoadFailed(@ Nullable Drawable errorDrawable){@Override \npublic void onLoadCleared(@ Nullable Drawable placeholder){ \nsuper.onLoadCleared(placeholder);-setResource(null);+setResourceInternal(null); \nsetDrawable(placeholder);}@ Override \npublic void onResourceReady(Z resource,@ Nullable Transition<? super Z>transition){ \nif(transition== null||!transition.transition(resource,this)){- setResource(resource);-}-- if(resource instanceof Animatable){-animatable=( Animatable)resource;- animatable.start();+ setResourceInternal(resource);}else{- animatable=null;+ maybeUpdateAnimatable(resource);}} \npublic void onStop(){}}+ private void setResourceInternal(@ Nullable Z resource){+maybeUpdateAnimatable(resource);+setResource(resource);+}++ private void maybeUpdateAnimatable(@ Nullable Z resource){+if(resource instanceof Animatable){+animatable=( Animatable)resource;+ animatable.start();+}else{+ animatable=null;+}+}+ \nprotected abstract void setResource(@ Nullable Z resource); \n} \n",
        "org_diff": "diff --git a/library/src/main/java/com/bumptech/glide/request/target/BaseTarget.java  b/library/src/main/java/com/bumptech/glide/request/target/BaseTarget.java \npackage com.bumptech.glide.request.target;import android.graphics.drawable.Drawable;+ import android.support.annotation.Nullable;import com.bumptech.glide.request.Request;/** \nprivate Request request;@ Override-public void setRequest(Request request){+public void setRequest(@ Nullable Request request){ \nthis.request=request;}@Override+@ Nullable \npublic Request getRequest(){return request;}@Override-public void onLoadCleared(Drawable placeholder){+public void onLoadCleared(@ Nullable Drawable placeholder){// Do nothing.}@Override-public void onLoadStarted(Drawable placeholder){+public void onLoadStarted(@ Nullable Drawable placeholder){// Do nothing.}@Override-public void onLoadFailed(Drawable errorDrawable){+public void onLoadFailed(@ Nullable Drawable errorDrawable){// Do nothing.} \n"
    },
    {
        "sim_msg": "Internal : prevent injection of unannotated dynamic settings",
        "sim_diff": "diff --git a/src/main/java/org/elasticsearch/cluster/settings/ClusterDynamicSettingsModule.java \nppp b/src/main/java/org/elasticsearch/cluster/settings/ClusterDynamicSettingsModule.java \nimport org.elasticsearch.cluster.routing.allocation.decider.*;import org.elasticsearch.cluster.service.InternalClusterService;import org.elasticsearch.common.inject.AbstractModule;+ import org.elasticsearch.common.inject.util.Providers;import org.elasticsearch.discovery.DiscoverySettings;import org.elasticsearch.discovery.zen.ZenDiscovery;import org.elasticsearch.indices.breaker.HierarchyCircuitBreakerService;public void addDynamicSetting(String setting,Validator validator){ \nclusterDynamicSettings.addDynamicSetting(setting,validator);}-@Override \nprotected void configure(){bind(DynamicSettings.class). annotatedWith(ClusterDynamicSettings.class). toInstance(clusterDynamicSettings);++// Bind to null provider just in case somebody will forget to supply@ClusterDynamicSetting or@IndexDynamicSetting annotations+//This will cause any attempt to inject a unannotated DynamicSettings to fail with Guice error,instead of silently+//injecting an empty copy of dynamic settings+bind(DynamicSettings.class). toProvider(Providers.< DynamicSettings>of(null));} \n} \n",
        "org_diff": "diff --git a/core/src/main/java/org/elasticsearch/common/settings/ClusterSettings.java  b/core/src/main/java/org/elasticsearch/common/settings/ClusterSettings.java \nimport org.elasticsearch.common.network.NetworkModule;import org.elasticsearch.common.network.NetworkService;import org.elasticsearch.common.util.concurrent.EsExecutors;+ import org.elasticsearch.common.util.concurrent.ThreadContext;import org.elasticsearch.discovery.DiscoveryModule;import org.elasticsearch.discovery.DiscoveryService;import org.elasticsearch.discovery.DiscoverySettings;public boolean isLoggerSetting(String key){ \nClient.CLIENT_TYPE_SETTING_S,InternalSettingsPreparer.IGNORE_SYSTEM_PROPERTIES_SETTING,ClusterModule.SHARDS_ALLOCATOR_TYPE_SETTING,- EsExecutors.PROCESSORS_SETTING)));+EsExecutors.PROCESSORS_SETTING,+ ThreadContext.DEFAULT_HEADERS_SETTING)));}diff --git a/core/src/main/java/org/elasticsearch/common/util/concurrent/ThreadContext.java  b/core/src/main/java/org/elasticsearch/common/util/concurrent/ThreadContext.java \nimport org.elasticsearch.common.io.stream.StreamInput;import org.elasticsearch.common.io.stream.StreamOutput;import org.elasticsearch.common.io.stream.Writeable;+ import org.elasticsearch.common.settings.Setting;import org.elasticsearch.common.settings.Settings;import java.io.Closeable;public final class ThreadContext implements Closeable,Writeable<ThreadContext.ThreadContextStruct>{ \npublic static final String PREFIX=\" request.headers\";+public static final Setting<Settings>DEFAULT_HEADERS_SETTING=Setting.groupSetting(PREFIX+\".\",false,Setting.Scope.CLUSTER); \nprivate final Map<String,String>defaultHeader;private static final ThreadContextStruct DEFAULT_CONTEXT=new ThreadContextStruct(Collections.emptyMap()); \nprivate final ContextThreadLocal threadLocal;*@param settings the settings to read the default request headers from*/ \npublic ThreadContext(Settings settings){-Settings headers=settings.getAsSettings(PREFIX);+Settings headers=DEFAULT_HEADERS_SETTING.get(settings); \nif(headers== null){ \nthis.defaultHeader=Collections.emptyMap();} else { \n"
    },
    {
        "sim_msg": "KAFKA - 10138 : Prefer - - bootstrap - server for reassign_partitions command in ducktape tests ( )",
        "sim_diff": "diff --git a/tests/kafkatest/services/kafka/kafka.py \nppp b/tests/kafkatest/services/kafka/kafka.py \ndef parse_describe_topic(self,topic_description):\"replicas\": map(int,fields[3]. split(','))}) \nreturn{\" partitions\": partitions}++def _connect_setting_reassign_partitions(self,node):+if node.version.reassign_partitions_command_supports_bootstrap_server():+ return\"--bootstrap-server%s\"% self.bootstrap_servers(self.security_protocol)+ else:+ return\"--zookeeper%s\"% self.zk_connect_setting()+def verify_reassign_partitions(self,reassignment,node=None):\"\"\"Run the reassign partitions admin tool in\"verify\"mode\"\"\"def verify_reassign_partitions(self,reassignment,node=None): \ncmd=fix_opts_for_new_jvm(node)cmd+=\"echo%s>% s&&\"%(json_str,json_file)cmd+=\"% s\"% self.path.script(\" kafka-reassign-partitions.sh\", node)- cmd+=\"--zookeeper%s\"% self.zk_connect_setting()+cmd+= self._connect_setting_reassign_partitions(node)cmd+=\"--reassignment-json-file%s\"% json_file \ncmd+=\"--verify\"cmd+=\"&&sleep 1&& rm-f%s\"% json_file \ndef execute_reassign_partitions(self,reassignment,node=None,cmd=fix_opts_for_new_jvm(node)cmd+=\"echo%s>% s&&\"%(json_str,json_file)cmd+=\"% s\"% self.path.script(\" kafka-reassign-partitions.sh\", node)- cmd+=\"--zookeeper%s\"% self.zk_connect_setting()+cmd+= self._connect_setting_reassign_partitions(node)cmd+=\"--reassignment-json-file%s\"% json_file \ncmd+=\"--execute\"if throttle is not None:diff --git a/tests/kafkatest/version.py \nppp b/tests/kafkatest/version.py \ndef supports_tls_to_zookeeper(self):#indicate if KIP-515 is available \nreturn self>LATEST_2_4+def reassign_partitions_command_supports_bootstrap_server(self):+return self>= V_2_5_0+def get_version(node=None):\"\"\"Return the version attached to the given node.Default to DEV_BRANCH if node or node.version is undefined(aka None)def get_version(node=None):#2.5.x versions \nV_2_5_0=KafkaVersion(\" 2.5.0\") \nLATEST_2_5=V_2_5_0++#2.6.x versions+V_2_6_0=KafkaVersion(\" 2.6.0\")+LATEST_2_6=V_2_6_0 \n",
        "org_diff": "diff --git a/docs/ops.html  b/docs/ops.html<h5>< a id=\" basic_ops_partitionassignment\"href=\"#basic_ops_partitionassignment\">}</pre>< p>- The-- verify option can be used with the tool to check the status of the partition reassignment.Note that the same expand-cluster-reassignment.json(used with the-- execute option)should be used with the-- verify option:+ The-- verify option can be used with the tool to check the status of the partition reassignment.Note that the same custom-reassignment.json(used with the-- execute option)should be used with the-- verify option:< pre class=\" brush:bash;\">> bin/kafka-reassign-partitions.sh-- zookeeper localhost:2181-- reassignment-json-file custom-reassignment.json-- verify \nStatus of partition reassignment : \n"
    },
    {
        "sim_msg": "PiperOrigin - RevId : 168854156",
        "sim_diff": "diff --git a/src/test/java/com/google/devtools/build/lib/packages/util/MockProtoSupport.java \nppp b/src/test/java/com/google/devtools/build/lib/packages/util/MockProtoSupport.java*/ \npublic static void setup(MockToolsConfig config)throws IOException{createNetProto2(config);-//TODO(ulfjack): Consider moving these elsewhere;it's not needed for most proto_library tests.- createJsPbPlugin(config); \ncreateJavascriptClosureProto2(config);}private static void createNetProto2(MockToolsConfig config)throws IOException{\" srcs=['context.go'])\");}-/**-*Create a dummy\"java/com/google/apps/jspb\"package.-*/-private static void createJsPbPlugin(MockToolsConfig config)throws IOException{- config.create(\" java/com/google/apps/jspb/BUILD\",-\" package(default_visibility=['//visibility:public'])\",-\"java_binary(name=' JsPbCodeGeneratorPlugin',\",-\" srcs=['jspb.java'])\");-config.create(-\"javascript/apps/jspb/BUILD\",-\" package(default_visibility=['//visibility:public'])\",-\"js_library(name=' message',\",-\" srcs=['message.js'],\",-\"deps_mgmt=' legacy')\");-}-/*** Create a dummy\"javascript/closure/proto2\"package.* / \n",
        "org_diff": "diff --git a/src/test/java/com/google/devtools/build/lib/packages/util/MockProtoSupport.java  b/src/test/java/com/google/devtools/build/lib/packages/util/MockProtoSupport.java*/ \npublic static void setup(MockToolsConfig config)throws IOException{createNetProto2(config);-createJavascriptClosureProto2(config);+createJavascriptJspb(config);}/** \nprivate static void createNetProto2(MockToolsConfig config)throws IOException{\" srcs=['metadata.go'])\");}-/**-*Create a dummy\"javascript/closure/proto2\"package.-*/-private static void createJavascriptClosureProto2(MockToolsConfig config)throws IOException{+/**Create a dummy jspb support package.*/+ private static void createJavascriptJspb(MockToolsConfig config)throws IOException{+ config.create(+\"net/proto2/compiler/js/internal/BUILD\",+\" package(default_visibility=['//visibility:public'])\",+\"cc_binary(name=' protoc-gen-js',\",+\" srcs=['plugin.cc'])\"); \nconfig.create(-\"javascript/closure/proto2/BUILD\",+\" javascript/apps/jspb/BUILD\",\"package(default_visibility=['//visibility:public'])\",\" js_library(name=' message',\",-\" srcs=['message.js'],\",-\"deps_mgmt=' legacy')\");+\"srcs=['message.js'],\",+\"deps_mgmt=' legacy')\");+ config.create(+\"javascript/closure/array/BUILD\",+\" package(default_visibility=['//visibility:public'])\",+\"js_library(name=' array',\",+\" srcs=['array.js'],\",+\"deps_mgmt=' legacy')\");+ config.create(+\"javascript/apps/xid/BUILD\",+\" package(default_visibility=['//visibility:public'])\",+\"js_library(name=' xid',\",+\" srcs=['xid.js'],\",+\"deps_mgmt=' legacy')\");} \n} \n"
    },
    {
        "sim_msg": "Merge pull request from benjchristensen / increase - timeout - for - unit - tests",
        "sim_diff": "diff --git a/hystrix-core/src/main/java/com/netflix/hystrix/HystrixCommand.java \nppp b/hystrix-core/src/main/java/com/netflix/hystrix/HystrixCommand.java \nprivate TestCommandWithTimeout(long timeout,int fallbackBehavior){ \nprotected Boolean run(){System.out.println(\"*****running\");try{- Thread.sleep(timeout*2);+Thread.sleep(timeout*10);}catch(InterruptedException e){ \ne.printStackTrace();} \n",
        "org_diff": "diff --git a/hystrix-core/src/main/java/com/netflix/hystrix/HystrixCommand.java  b/hystrix-core/src/main/java/com/netflix/hystrix/HystrixCommand.java \nprivate TestCommandWithTimeout(long timeout,int fallbackBehavior){ \nprotected Boolean run(){System.out.println(\"*****running\");try{- Thread.sleep(timeout*2);+Thread.sleep(timeout*10);}catch(InterruptedException e){ \ne.printStackTrace();} \n"
    },
    {
        "sim_msg": "Add unit test for HttpObjectDecoder with message split on buffer boundaries",
        "sim_diff": "diff --git a/codec-http/src/test/java/io/netty/handler/codec/http/HttpRequestDecoderTest.java \nppp b/codec-http/src/test/java/io/netty/handler/codec/http/HttpRequestDecoderTest.java \nimport io.netty.buffer.Unpooled;import io.netty.channel.embedded.EmbeddedChannel;+ import io.netty.util.AsciiString;import io.netty.util.CharsetUtil;import org.junit.Test;import java.util.List;+ import static io.netty.handler.codec.http.HttpHeaderNames.*;import static io.netty.handler.codec.http.HttpHeadersTestUtils.of;import static org.hamcrest.CoreMatchers.instanceOf;import static org.hamcrest.CoreMatchers.is;public void test100ContinueWithBadClient(){assertThat(channel.finish(),is(false));}++@Test+public void testMessagesSplitBetweenMultipleBuffers(){+ EmbeddedChannel channel=new EmbeddedChannel(new HttpRequestDecoder());+String crlf=\"\\r\\n\";+String str1=\" GET/some/path HTTP/1.1\"+ crlf++\"Host:localhost1\"+ crlf+crlf++\"GET/some/other/path HTTP/1.0\"+ crlf++\"Hos\";+String str2=\" t:localhost2\"+ crlf++\"content-length:0\"+ crlf+crlf;+ channel.writeInbound(Unpooled.copiedBuffer(str1,CharsetUtil.US_ASCII));+ HttpRequest req=channel.readInbound();+ assertEquals(HttpVersion.HTTP_1_1,req.protocolVersion());+assertEquals(\"/some/path\", req.uri());+assertEquals(1,req.headers().size());+assertTrue(AsciiString.contentEqualsIgnoreCase(\" localhost1\", req.headers().get(HOST)));+LastHttpContent cnt=channel.readInbound();+ cnt.release();++channel.writeInbound(Unpooled.copiedBuffer(str2,CharsetUtil.US_ASCII));+ req=channel.readInbound();+ assertEquals(HttpVersion.HTTP_1_0,req.protocolVersion());+assertEquals(\"/some/other/path\", req.uri());+assertEquals(2,req.headers().size());+assertTrue(AsciiString.contentEqualsIgnoreCase(\" localhost2\", req.headers().get(HOST)));+assertTrue(AsciiString.contentEqualsIgnoreCase(\" 0\", req.headers().get(HttpHeaderNames.CONTENT_LENGTH)));+cnt=channel.readInbound();+ cnt.release();+ assertFalse(channel.finishAndReleaseAll());+} \n} \n",
        "org_diff": "diff --git a/codec-smtp/src/test/java/io/netty/handler/codec/smtp/SmtpRequestEncoderTest.java  b/codec-smtp/src/test/java/io/netty/handler/codec/smtp/SmtpRequestEncoderTest.java \nimport io.netty.util.CharsetUtil;import org.junit.Test;- import static org.junit.Assert.*;+ import static org.junit.Assert.assertEquals;+ import static org.junit.Assert.assertNull;+ import static org.junit.Assert.assertTrue;public class SmtpRequestEncoderTest{public void testEncodeDataAndContent(){@ Test(expected=EncoderException.class)public void testThrowsIfContentExpected(){EmbeddedChannel channel=new EmbeddedChannel(new SmtpRequestEncoder());-assertTrue(channel.writeOutbound(SmtpRequests.data()));- channel.writeOutbound(SmtpRequests.noop());+try{+ assertTrue(channel.writeOutbound(SmtpRequests.data()));+ channel.writeOutbound(SmtpRequests.noop());+} finally{+ channel.finishAndReleaseAll();+}}@Test \n"
    },
    {
        "sim_msg": "Object shouldn ' t be tested for equality with itself . This was identified using Error Prone check .",
        "sim_diff": "diff --git a/guava-tests/test/com/google/common/net/HostAndPortTest.java \nppp b/guava-tests/test/com/google/common/net/HostAndPortTest.java \npackage com.google.common.net;import com.google.common.annotations.GwtCompatible;+ import com.google.common.testing.EqualsTester;import com.google.common.testing.SerializableTester;- \nimport junit.framework.TestCase;/** \npublic void testHashCodeAndEquals(){HostAndPort hp3=HostAndPort.fromString(\"[foo:: 123]\"); \nHostAndPort hp4=HostAndPort.fromParts(\"[foo:: 123]\",80); \nHostAndPort hp5=HostAndPort.fromString(\"[foo:: 123]: 80\");- assertEquals(hp1.hashCode(),hp1.hashCode());-assertEquals(hp1.hashCode(),hp2.hashCode());-assertFalse(hp1.hashCode()== hp3.hashCode());-assertFalse(hp3.hashCode()== hp4.hashCode());-assertEquals(hp4.hashCode(),hp5.hashCode());-- assertTrue(hp1.equals(hp1));- assertTrue(hp1.equals(hp2));- assertFalse(hp1.equals(hp3));- assertFalse(hp3.equals(hp4));- assertTrue(hp4.equals(hp5));- assertFalse(hp1.equals(null));+ new EqualsTester()+. addEqualityGroup(hp1,hp2)+.addEqualityGroup(hp3)+.addEqualityGroup(hp4,hp5)+.testEquals();} \npublic void testRequireBracketsForIPv6() { \n",
        "org_diff": "diff --git a/guava-tests/test/com/google/common/net/HostSpecifierTest.java  b/guava-tests/test/com/google/common/net/HostSpecifierTest.java \npackage com.google.common.net;import com.google.common.collect.ImmutableList;+ import com.google.common.testing.EqualsTester;import com.google.common.testing.NullPointerTester;import junit.framework.TestCase;public void testBadDomains(){}}+ public void testEquality(){+ new EqualsTester()+. addEqualityGroup(spec(\" 1.2.3.4\"),spec(\" 1.2.3.4\"))+.addEqualityGroup(+ spec(\" 2001:db8:: 1\"),spec(\" 2001:db8:: 1\"),spec(\"[2001:db8:: 1]\"))+. addEqualityGroup(spec(\" 2001:db8:: 2\"))+.addEqualityGroup(spec(\" google.com\"),spec(\" google.com\"))+.addEqualityGroup(spec(\" www.google.com\"))+.testEquals();+}++private static HostSpecifier spec(String specifier){+return HostSpecifier.fromValid(specifier);+}+public void testNulls() throws Exception{final NullPointerTester tester=new NullPointerTester();diff --git a/guava-tests/test/com/google/common/net/InternetDomainNameTest.java  b/guava-tests/test/com/google/common/net/InternetDomainNameTest.java \nimport com.google.common.base.Strings;import com.google.common.collect.ImmutableList;import com.google.common.collect.Iterables;+ import com.google.common.testing.EqualsTester;import com.google.common.testing.NullPointerTester;import junit.framework.TestCase;*/@ GwtCompatible(emulated=true)public final class InternetDomainNameTest extends TestCase{+ private static final InternetDomainName UNICODE_EXAMPLE=+ InternetDomainName.from(\" j\\u00f8rpeland.no\");+ private static final InternetDomainName PUNYCODE_EXAMPLE=+ InternetDomainName.from(\" xn-- jrpeland-54a.no\");/***The Greek letter delta,used in unicode testing.public void testExclusion(){assertFalse(domain.publicSuffix().isPublicSuffix());}+ public void testEquality(){+ new EqualsTester()+. addEqualityGroup(+ idn(\" google.com\"),idn(\" google.com\"),idn(\" GOOGLE.COM\"))+.addEqualityGroup(idn(\" www.google.com\"))+.addEqualityGroup(UNICODE_EXAMPLE)+.addEqualityGroup(PUNYCODE_EXAMPLE)+.testEquals();+}++private static InternetDomainName idn(String domain){+return InternetDomainName.from(domain);+}+@ GwtIncompatible(\" NullPointerTester\") \npublic void testNulls() throws Exception{final NullPointerTester tester=new NullPointerTester();diff --git a/guava/src/com/google/common/net/HostSpecifier.java  b/guava/src/com/google/common/net/HostSpecifier.java \nprivate HostSpecifier(String canonicalForm){*< li>A IPv4 address string,like{@ code 127.0.0.1}*<li>An IPv6 address string with or without brackets,like*{@code[2001:db8:: 1]} or{@ code 2001:db8:: 1}-*< li>An IPv6 address string enclosed in square brackets,like-*{[ 2001:db8:: 1]}*</ul>**@ throws IllegalArgumentException if the specifier is not valid . \n"
    },
    {
        "sim_msg": "Add GOOGLE_PRODUCT_SEARCH_COUNTRY_TLD",
        "sim_diff": "diff --git a/android/src/com/google/zxing/client/android/LocaleManager.java \nppp b/android/src/com/google/zxing/client/android/LocaleManager.java \nGOOGLE_COUNTRY_TLD.put(\" CH\",\"ch\");//SWITZERLAND \nGOOGLE_COUNTRY_TLD.put(Locale.TAIWAN.getCountry(),\" tw\");GOOGLE_COUNTRY_TLD.put(\" TR\",\"com.tr\");//TURKEY+GOOGLE_COUNTRY_TLD.put(\" UA\",\"com.ua\");//UKRAINE \nGOOGLE_COUNTRY_TLD.put(Locale.UK.getCountry(),\" co.uk\");GOOGLE_COUNTRY_TLD.put(Locale.US.getCountry(),\" com\");} \n",
        "org_diff": "diff --git a/android/src/com/google/zxing/client/android/LocaleManager.java  b/android/src/com/google/zxing/client/android/LocaleManager.java \nprivate static final String DEFAULT_TLD=\" com\"; \nprivate static final Map<Locale,String>GOOGLE_COUNTRY_TLD;static{- GOOGLE_COUNTRY_TLD=new HashMap<Locale,String>( 13);+GOOGLE_COUNTRY_TLD=new HashMap<Locale,String>(); \nGOOGLE_COUNTRY_TLD.put(Locale.CANADA,\" ca\");GOOGLE_COUNTRY_TLD.put(Locale.CHINA,\" cn\");GOOGLE_COUNTRY_TLD.put(Locale.FRANCE,\" fr\");//Google Product Search for mobile is available in fewer countries than web search.private static final Map<Locale,String>GOOGLE_PRODUCT_SEARCH_COUNTRY_TLD;static{- GOOGLE_PRODUCT_SEARCH_COUNTRY_TLD=new HashMap<Locale,String>( 3);+GOOGLE_PRODUCT_SEARCH_COUNTRY_TLD=new HashMap<Locale,String>(); \nGOOGLE_PRODUCT_SEARCH_COUNTRY_TLD.put(Locale.UK,\" co.uk\");+ GOOGLE_PRODUCT_SEARCH_COUNTRY_TLD.put(Locale.GERMANY,\" de\");} \nprivate static final Map<Locale,String>GOOGLE_BOOK_SEARCH_COUNTRY_TLD;static{- GOOGLE_BOOK_SEARCH_COUNTRY_TLD=new HashMap<Locale,String>( 13);+GOOGLE_BOOK_SEARCH_COUNTRY_TLD=new HashMap<Locale,String>(); \nGOOGLE_BOOK_SEARCH_COUNTRY_TLD.putAll(GOOGLE_COUNTRY_TLD); \nGOOGLE_BOOK_SEARCH_COUNTRY_TLD.remove(Locale.CHINA); \n} \n"
    },
    {
        "sim_msg": "Make MultiValueMapAdapter public ( as base class for LinkedMultiValueMap )",
        "sim_diff": "diff --git a/spring-core/src/main/java/org/springframework/util/CollectionUtils.java \nppp b/spring-core/src/main/java/org/springframework/util/CollectionUtils.java \nelse if(candidate!= val.getClass()){*@ since 3.1*/ \npublic static<K,V>MultiValueMap<K,V>toMultiValueMap(Map<K,List<V>> targetMap){-Assert.notNull(targetMap,\"'targetMap'must not be null\");return new MultiValueMapAdapter<>(targetMap);}diff --git a/spring-core/src/main/java/org/springframework/util/LinkedMultiValueMap.java \nppp b/spring-core/src/main/java/org/springframework/util/LinkedMultiValueMap.java*@ param<K>the key type*@ param<V>the value element type*/-public class LinkedMultiValueMap<K,V>extends MultiValueMapAdapter<K,V>implements Serializable,Cloneable{+ public class LinkedMultiValueMap<K,V>extends MultiValueMapAdapter<K,V>//new public base class in 5.3+implements Serializable,Cloneable{private static final long serialVersionUID=3801124242820219131L;diff --git a/spring-core/src/main/java/org/springframework/util/MultiValueMapAdapter.java \nppp b/spring-core/src/main/java/org/springframework/util/MultiValueMapAdapter.java**@author Arjen Poutsma*@ author Juergen Hoeller-*@since 3.1+*@since 5.3*@ param<K>the key type*@ param<V>the value element type*@ see CollectionUtils#toMultiValueMap*@ see LinkedMultiValueMap*/@SuppressWarnings(\" serial\")-class MultiValueMapAdapter<K,V>implements MultiValueMap<K,V>, Serializable{+ public class MultiValueMapAdapter<K,V>implements MultiValueMap<K,V>, Serializable{private final Map<K,List<V>> targetMap;- MultiValueMapAdapter(Map<K,List<V>> targetMap){+/**+* Wrap the given target{@ link Map}as a{@ link MultiValueMap}adapter.+*@ param targetMap the plain target{@ code Map}+*/+public MultiValueMapAdapter(Map<K,List<V>> targetMap){+Assert.notNull(targetMap,\"'targetMap'must not be null\");this.targetMap=targetMap;}+//MultiValueMap implementation+@ Override@Nullable \npublic V getFirst(K key){ \npublic void setAll(Map<K,V>values){ \nreturn singleValueMap;}++// Map implementation+@ Override \npublic int size(){return this.targetMap.size() ; \n",
        "org_diff": "diff --git a/spring-core/src/main/java/org/springframework/util/MultiValueMap.java  b/spring-core/src/main/java/org/springframework/util/MultiValueMap.java/*-* Copyright 2002-2018 the original author or authors.+*Copyright 2002-2019 the original author or authors.**Licensed under the Apache License,Version 2.0(the\"License\");* you may not use this file except in compliance with the License.*/void addAll(MultiValueMap<K,V>values);+/**+*{@ link#add(Object,Object)Add}the given value,only when the map does not+*{@ link#containsKey(Object)contain}the given key.+*@ param key the key+*@param value the value to be added+*@since 5.2+*/+ default void addIfAbsent(K key,@ Nullable V value){+if(! containsKey(key)){+ add(key,value);+}+}+/***Set the given single value under the given key.*@param key the key \ndiff --git a/spring-core/src/test/java/org/springframework/util/LinkedMultiValueMapTests.java  b/spring-core/src/test/java/org/springframework/util/LinkedMultiValueMapTests.java \npublic void add(){assertThat(map.get(\" key\")). isEqualTo(expected);}+@Test+public void addIfAbsentWhenAbsent(){+ map.addIfAbsent(\" key\",\"value1\");+ assertThat(map.get(\" key\")). containsExactly(\" value1\");+}++@ Test+public void addIfAbsentWhenPresent(){+ map.add(\" key\",\"value1\");+ map.addIfAbsent(\" key\",\"value2\");+ assertThat(map.get(\" key\")). containsExactly(\" value1\");+}+@Test \npublic void set(){map.set(\" key\",\"value1\") ; \n"
    },
    {
        "sim_msg": "[ hotfix ] [ tests ] Make S3 Recoverable Writer tests ITCases",
        "sim_diff": "similarity index 98%rename from flink-filesystems/flink-s3-fs-hadoop/src/test/java/org/apache/flink/fs/s3hadoop/HadoopS3RecoverableWriterExceptionTest.java \nrename to flink-filesystems/flink-s3-fs-hadoop/src/test/java/org/apache/flink/fs/s3hadoop/HadoopS3RecoverableWriterExceptionITCase.java \ndiff --git a/flink-filesystems/flink-s3-fs-hadoop/src/test/java/org/apache/flink/fs/s3hadoop/HadoopS3RecoverableWriterExceptionTest.java \nppp b/flink-filesystems/flink-s3-fs-hadoop/src/test/java/org/apache/flink/fs/s3hadoop/HadoopS3RecoverableWriterExceptionITCase.java*Tests for exception throwing in the*{@link org.apache.flink.fs.s3.common.writer.S3RecoverableWriter S3RecoverableWriter}.*/-public class HadoopS3RecoverableWriterExceptionTest extends TestLogger{+ public class HadoopS3RecoverableWriterExceptionITCase extends TestLogger{//diff --gitdiff --gitdiff --gitdiff --gitdiff --gitdiff --gitdiff --git-- S3 general configuration diff --gitdiff --gitdiff --gitdiff --gitdiff --gitdiff --gitdiff --git-- \nsimilarity index 99%rename from flink-filesystems/flink-s3-fs-hadoop/src/test/java/org/apache/flink/fs/s3hadoop/HadoopS3RecoverableWriterTest.java \nrename to flink-filesystems/flink-s3-fs-hadoop/src/test/java/org/apache/flink/fs/s3hadoop/HadoopS3RecoverableWriterITCase.java \ndiff --git a/flink-filesystems/flink-s3-fs-hadoop/src/test/java/org/apache/flink/fs/s3hadoop/HadoopS3RecoverableWriterTest.java \nppp b/flink-filesystems/flink-s3-fs-hadoop/src/test/java/org/apache/flink/fs/s3hadoop/HadoopS3RecoverableWriterITCase.java/*** Tests for the{@ link org.apache.flink.fs.s3.common.writer.S3RecoverableWriter S3RecoverableWriter}.*/-public class HadoopS3RecoverableWriterTest extends TestLogger{+ public class HadoopS3RecoverableWriterITCase extends TestLogger{//diff --gitdiff --gitdiff --gitdiff --gitdiff --gitdiff --gitdiff --git-- S3 general configuration diff --gitdiff --gitdiff --gitdiff --gitdiff --gitdiff --gitdiff --git-- \n",
        "org_diff": "similarity index 100%rename from flink-filesystems/flink-oss-fs-hadoop/src/main/resources/licenses/LICENSE.jdom \nrename to flink-filesystems/flink-oss-fs-hadoop/src/main/resources/META-INF/licenses/LICENSE.jdom \n"
    },
    {
        "sim_msg": "Update api . md",
        "sim_diff": "diff --git a/docs/api.md \nppp b/docs/api.md \ntype AnimationProps={ \nsource:string|AnimationJson|{ uri:string},// A number between 0 and 1,or an`Animated`number between 0 and 1.This number-//represents the normalized pregress of the animation.If you update this prop,the+//represents the normalized progress of the animation.If you update this prop,the// animation will correspondingly update to the frame at that progress value.This// prop is not required if you are using the imperative API.progress:number|Animated=0,-// The speed the animation will pregress.This only affects the imperative API.The+//The speed the animation will progress.This only affects the imperative API.The// default value is 1.speed:number=1 , \n",
        "org_diff": "diff --git a/docs/api.md  b/docs/api.md|diff --git|diff --git|diff --git||**`source`**|** Mandatory**-The source of animation.Can be referenced as a local asset by a string,or remotely with an object with a`uri`property,or it can be an actual JS object of an animation,obtained(for example)with something like`require('../path/to/animation.json')`|*None*||**` progress`**| A number between 0 and 1,or an`Animated`number between 0 and 1.This number represents the normalized progress of the animation.If you update this prop,the animation will correspondingly update to the frame at that progress value.This prop is not required if you are using the imperative API.|`0`|-|**`speed`**| The speed the animation will progress.This only affects the imperative API.|`1`|+|**`speed`**| The speed the animation will progress.This only affects the imperative API.Sending a negative value will reverse the animation|` 1`||**` loop`**| A boolean flag indicating whether or not the animation should loop.|`false`||**` style`**| Style attributes for the view,as expected in a standard[` View`](http://facebook.github.io/react-native/releases/0.46/docs/layout-props.html), aside from border styling|* None*||**` imageAssetsFolder`**| Needed for** Android** to work properly with assets,iOS will ignore it.|*None*| \ndiff --git a/lib/android/src/main/java/com/airbnb/android/react/lottie/LottieAnimationViewManager.java  b/lib/android/src/main/java/com/airbnb/android/react/lottie/LottieAnimationViewManager.java \npublic void setProgress(LottieAnimationView view,float progress){@ReactProp(name=\" speed\") \npublic void setSpeed(LottieAnimationView view,double speed){-//TODO?+ view.setSpeed(( float)speed);}@ ReactProp(name=\" loop\") \n"
    },
    {
        "sim_msg": "sulong : make resolveRenamedSymbols look at transitive dependencies",
        "sim_diff": "diff --git a/sulong/projects/com.oracle.truffle.llvm/src/com/oracle/truffle/llvm/Runner.java \nppp b/sulong/projects/com.oracle.truffle.llvm/src/com/oracle/truffle/llvm/Runner.java \nimport java.io.IOException;import java.nio.file.Path;+ import java.util.ArrayDeque;import java.util.ArrayList;import java.util.Arrays;import java.util.Base64;private static void resolveRenamedSymbols(LLVMParserResult parserResult,ParseCo \nEconomicMap<String,ExternalLibrary>libs=EconomicMap.create();//TODO(je)we should probably do this in symbol resolution order-let's fix that when we// fix symbol resolution[GR-21400]- for(ExternalLibrary dep:parserResult.getDependencies()){+ArrayDeque<ExternalLibrary>dependencyQueue=new ArrayDeque<>(parserResult.getDependencies());+EconomicSet<ExternalLibrary>visited=EconomicSet.create(Equivalence.IDENTITY);+visited.addAll(parserResult.getDependencies());+while(! dependencyQueue.isEmpty()){+ExternalLibrary dep=dependencyQueue.removeFirst();LLVMParserResult depResult=libToRes.get(dep); \nif(depResult!= null){-scopes.put(getSimpleLibraryName(dep.getName()), depResult.getRuntime().getFileScope());-libs.put(getSimpleLibraryName(dep.getName()), dep);+String libraryName=getSimpleLibraryName(dep.getName());+scopes.put(libraryName,depResult.getRuntime().getFileScope());+libs.put(libraryName,dep);+//add transitive dependencies+for(ExternalLibrary transDep:depResult.getDependencies()){+if(! visited.contains(transDep)){+ dependencyQueue.addLast(transDep);+visited.add(transDep);+}+}}} \nListIterator<FunctionSymbol>it=parserResult.getExternalFunctions().listIterator() ; \n",
        "org_diff": "diff --git a/sulong/projects/com.oracle.truffle.llvm/src/com/oracle/truffle/llvm/Runner.java  b/sulong/projects/com.oracle.truffle.llvm/src/com/oracle/truffle/llvm/Runner.java \nprivate static void resolveRenamedSymbols(LLVMParserResult parserResult,ParseCo \nlibToRes.put(res.getRuntime().getLibrary(),res);}EconomicMap<String,LLVMScope>scopes=EconomicMap.create();+ EconomicMap<String,ExternalLibrary>libs=EconomicMap.create();//TODO(je)we should probably do this in symbol resolution order-let's fix that when we// fix symbol resolution[GR-21400]for(ExternalLibrary dep:parserResult.getDependencies()){ \nLLVMParserResult depResult=libToRes.get(dep); \nif(depResult!= null){ \nscopes.put(getSimpleLibraryName(dep.getName()), depResult.getRuntime().getFileScope());+libs.put(getSimpleLibraryName(dep.getName()), dep);}} \nListIterator<FunctionSymbol>it=parserResult.getExternalFunctions().listIterator();private static void resolveRenamedSymbols(LLVMParserResult parserResult,ParseCo \nString originalName=name.substring(idx+1); \nLLVMFunction originalSymbol=scope.getFunction(originalName); \nif(originalSymbol== null){-throw new LLVMLinkerException(String.format(\" The%s could not be imported because the symbol%s was not found in library%s\", external.getName(),originalName,lib));+ throw new LLVMLinkerException(+ String.format(\" The%s could not be imported because the symbol%s was not found in library%s\", external.getName(),originalName,libs.get(lib)));}LLVMAlias alias=new LLVMAlias(parserResult.getRuntime().getLibrary(),name,originalSymbol); \nparserResult.getRuntime().getFileScope().register(alias); \nit.remove();} else{- throw new LLVMLinkerException(String.format(\" The%s could not be imported because library%s was not found\", external.getName(),lib));+ throw new LLVMLinkerException(String.format(\" The%s could not be imported because library%s was not found\", external.getName(),libs.get(lib)));}} \n} \n"
    },
    {
        "sim_msg": "Adapt CHANGELOG to reflect new signature of CallTarget # call .",
        "sim_diff": "diff --git a/CHANGELOG.md \nppp b/CHANGELOG.md*Explicit types for inputs(InputType enum).*Added graal.version system property to Graal enabled VM builds.* Transitioned to JDK 8 as minimum JDK level for Graal.-*Added support for stack introspection+* Added support for stack introspection.*...### Truffle-* Support for collecting stack traces and for accessing the current frame in slow paths+* The method CallTarget#call takes now a variable number of Object arguments.+*Support for collecting stack traces and for accessing the current frame in slow paths.* Renamed CallNode to DirectCallNode.* Renamed TruffleRuntime#createCallNode to TruffleRuntime#createDirectCallNode.* Added IndirectCallNode for calls with a changing CallTarget . \n",
        "org_diff": "diff --git a/CHANGELOG.md  b/CHANGELOG.md*Explicit types for inputs(InputType enum).*Added graal.version system property to Graal enabled VM builds.* Transitioned to JDK 8 as minimum JDK level for Graal.-*Added support for stack introspection+* Added support for stack introspection.*...### Truffle-* Support for collecting stack traces and for accessing the current frame in slow paths+* The method CallTarget#call takes now a variable number of Object arguments.+*Support for collecting stack traces and for accessing the current frame in slow paths.* Renamed CallNode to DirectCallNode.* Renamed TruffleRuntime#createCallNode to TruffleRuntime#createDirectCallNode.* Added IndirectCallNode for calls with a changing CallTarget . \n"
    },
    {
        "sim_msg": "[ FIXED JENKINS - 28093 ] Reverting getDownloadableId from . Not compatible .",
        "sim_diff": "diff --git a/core/src/main/java/hudson/tools/DownloadFromUrlInstaller.java \nppp b/core/src/main/java/hudson/tools/DownloadFromUrlInstaller.java \nprotected DescriptorImpl(){} \nprotected Downloadable createDownloadable(){- return new Downloadable(getDownloadableId());+return new Downloadable(getId());}/***This ID needs to be unique,and needs to match the ID token in the JSON update file.*<p>* By default we use the fully-qualified class name of the{@ link DownloadFromUrlInstaller}subtype.-*@ since 1.610*/-public String getDownloadableId(){+ public String getId(){return clazz.getName().replace('$','.');}public String getDownloadableId(){*@return never null.*/public List<? extends Installable>getInstallables() throws IOException{- JSONObject d=Downloadable.get(getDownloadableId()). getData();+ JSONObject d=Downloadable.get(getId()). getData();if(d== null)return Collections.emptyList();return Arrays.asList(((InstallableList)JSONObject.toBean(d,InstallableList.class)).list); \n} \n",
        "org_diff": "diff --git a/core/src/main/java/hudson/tools/DownloadFromUrlInstaller.java  b/core/src/main/java/hudson/tools/DownloadFromUrlInstaller.java \npublic Downloadable createDownloadable(){final DownloadFromUrlInstaller.DescriptorImpl delegate=( DownloadFromUrlInstaller.DescriptorImpl)this;return new Downloadable(getId()){ \npublic JSONObject reduce(List<JSONObject>jsonList){-if(isDefualtSchema(jsonList)){+ if(isDefaultSchema(jsonList)){return delegate.reduce(jsonList);}else{//if it's not default schema fall back to the super class implementation \npublic JSONObject reduce(List<JSONObject>jsonList){*@ param jsonList the list of Update centers json files*@ return true if the schema is the default one(id,name,url), false otherwise*/-private boolean isDefualtSchema(List<JSONObject>jsonList){+private boolean isDefaultSchema(List<JSONObject>jsonList){ \nJSONObject jsonToolInstallerList=jsonList.get(0); \nToolInstallerList toolInstallerList=( ToolInstallerList)JSONObject.toBean(jsonToolInstallerList,ToolInstallerList.class); \n"
    },
    {
        "sim_msg": "Don ' t use null EvaluationProgressReceiver in MemoizingEvaluator ( it was only null in AbstractPackageLoader and tests ) .",
        "sim_diff": "diff --git a/src/main/java/com/google/devtools/build/lib/skyframe/packages/AbstractPackageLoader.java \nppp b/src/main/java/com/google/devtools/build/lib/skyframe/packages/AbstractPackageLoader.java \nimport com.google.devtools.build.skyframe.BuildDriver;import com.google.devtools.build.skyframe.Differencer;import com.google.devtools.build.skyframe.ErrorInfo;+ import com.google.devtools.build.skyframe.EvaluationProgressReceiver;import com.google.devtools.build.skyframe.EvaluationResult;import com.google.devtools.build.skyframe.ImmutableDiff;import com.google.devtools.build.skyframe.InMemoryMemoizingEvaluator;private BuildDriver makeFreshDriver(){InMemoryMemoizingEvaluator.SUPPLIER.create(makeFreshSkyFunctions(),preinjectedDifferencer,-/* progressReceiver=*/null,+ new EvaluationProgressReceiver.NullEvaluationProgressReceiver(),new MemoizingEvaluator.EmittedEventState(),/*keepEdges=*/false));} \ndiff --git a/src/main/java/com/google/devtools/build/skyframe/InMemoryMemoizingEvaluator.java \nppp b/src/main/java/com/google/devtools/build/skyframe/InMemoryMemoizingEvaluator.java \npublic boolean storeEvents(){}};-public static final EvaluatorSupplier SUPPLIER=- new EvaluatorSupplier(){-@Override-public MemoizingEvaluator create(- ImmutableMap<SkyFunctionName,? extends SkyFunction>skyFunctions,- Differencer differencer,-@Nullable EvaluationProgressReceiver progressReceiver,- EmittedEventState emittedEventState,- boolean keepEdges){-return new InMemoryMemoizingEvaluator(- skyFunctions,differencer,progressReceiver,emittedEventState,keepEdges);-}-};+ public static final EvaluatorSupplier SUPPLIER=InMemoryMemoizingEvaluator:: new;} \ndiff --git a/src/main/java/com/google/devtools/build/skyframe/MemoizingEvaluator.java \nppp b/src/main/java/com/google/devtools/build/skyframe/MemoizingEvaluator.java \nMemoizingEvaluator create(ImmutableMap<SkyFunctionName,? extends SkyFunction>skyFunctions,Differencer differencer,-@Nullable EvaluationProgressReceiver progressReceiver,+ EvaluationProgressReceiver progressReceiver,EmittedEventState emittedEventState,boolean keepEdges); \n} \n",
        "org_diff": "diff --git a/src/main/java/com/google/devtools/build/lib/skyframe/PackageFunction.java  b/src/main/java/com/google/devtools/build/lib/skyframe/PackageFunction.java \nprivate final Cache<PackageIdentifier,CacheEntryWithGlobDeps<AstAfterPreprocessing>> astCache;private final AtomicBoolean showLoadingProgress;private final AtomicInteger numPackagesLoaded;- private final PackageProgressReceiver packageProgress;+@Nullable private final PackageProgressReceiver packageProgress;private final Profiler profiler=Profiler.instance();private final Label preludeLabel ; \n"
    },
    {
        "sim_msg": "Revert to redcarpet for Bazel ' s markdown engine .",
        "sim_diff": "diff --git a/site/_config.yml \nppp b/site/_config.yml \ndestination:production-markdown:kramdown-kramdown:- syntax_highlighter:rouge-- highlighter:rouge-+ markdown:redcarpet+redcarpet:+ extensions:[\"tables\"] \npaginate:10+highlighter:pygments \nsass:sass_dir:_sass \ngems:[ jekyll-paginate ] \n",
        "org_diff": "diff --git a/site/_config.yml  b/site/_config.yml \ndestination:production-markdown:redcarpet-redcarpet:- extensions:[\"tables\"]+markdown:kramdown+kramdown:+ syntax_highlighter:rouge+highlighter:rouge+paginate:10-highlighter:pygments \nsass:sass_dir:_sass \ngems:[ jekyll-paginate ] \n"
    },
    {
        "sim_msg": "[ hotfix ] Update RocksDB version to 5 . 7 . 5",
        "sim_diff": "diff --git a/flink-state-backends/flink-statebackend-rocksdb/pom.xml \nppp b/flink-state-backends/flink-statebackend-rocksdb/pom.xml \nunder the License.< dependency>< groupId>org.rocksdb</ groupId>< artifactId>rocksdbjni</ artifactId>-<version>5.6.1</ version>+<version>5.7.5</ version></dependency><!--test dependencies-- > \n",
        "org_diff": "diff --git a/flink-contrib/flink-statebackend-rocksdb/pom.xml  b/flink-contrib/flink-statebackend-rocksdb/pom.xml \nunder the License.< dependency>< groupId>org.rocksdb</ groupId>< artifactId>rocksdbjni</ artifactId>-<version>5.5.5</ version>+<version>5.6.1</ version></dependency><!--test dependencies-- > \n"
    },
    {
        "sim_msg": "[ regression ] Close player in onPlaybackShutdown ( )",
        "sim_diff": "diff --git a/app/src/main/java/org/schabi/newpipe/player/BasePlayer.java \nppp b/app/src/main/java/org/schabi/newpipe/player/BasePlayer.java \nprotected void onMetadataChanged(@ NonNull final MediaSourceTag tag){ \nregisterView();}-@ Override-public void onPlaybackShutdown(){- if(DEBUG){-Log.d(TAG,\" Shutting down...\");-}-destroy();-}-/*//////////////////////////////////////////////////////////////////////////// General Player//////////////////////////////////////////////////////////////////////////*/ \ndiff --git a/app/src/main/java/org/schabi/newpipe/player/VideoPlayerImpl.java \nppp b/app/src/main/java/org/schabi/newpipe/player/VideoPlayerImpl.java \npublic void onPlaybackShutdown(){if(DEBUG){ \nLog.d(TAG,\" onPlaybackShutdown() called\");}-//Override it because we don't want playerImpl destroyed+service.onDestroy();}@Override \n",
        "org_diff": "diff --git a/app/src/main/java/org/schabi/newpipe/player/BasePlayer.java  b/app/src/main/java/org/schabi/newpipe/player/BasePlayer.java \npublic void onShuffleClicked(){if(simpleExoPlayer== null)return;simpleExoPlayer.setShuffleModeEnabled(! simpleExoPlayer.getShuffleModeEnabled());}+/*//////////////////////////////////////////////////////////////////////////+//Mute/Unmute+//////////////////////////////////////////////////////////////////////////*/++public void onMuteUnmuteButtonClicled(){+ if(DEBUG)Log.d(TAG,\" onMuteUnmuteButtonClicled() called\");++if(simpleExoPlayer.getVolume()!= 0){+simpleExoPlayer.setVolume(0);+}+else{+ simpleExoPlayer.setVolume(1);+}+}/*//////////////////////////////////////////////////////////////////////////// Progress Updates \ndiff --git a/app/src/main/java/org/schabi/newpipe/player/MainVideoPlayer.java  b/app/src/main/java/org/schabi/newpipe/player/MainVideoPlayer.java \nimport androidx.core.app.ActivityCompat;import androidx.appcompat.app.AppCompatActivity;import androidx.appcompat.content.res.AppCompatResources;+ import androidx.core.content.ContextCompat;import androidx.recyclerview.widget.RecyclerView;import androidx.recyclerview.widget.ItemTouchHelper;import android.util.DisplayMetrics;public void onPlaybackParameterChanged(float playbackTempo,float playbackPitch,private ImageButton toggleOrientationButton;private ImageButton switchPopupButton;private ImageButton switchBackgroundButton;+ private ImageButton muteButton;private RelativeLayout windowRootLayout;private View secondaryControls;public void initViews(View rootView){ \nthis.shareButton=rootView.findViewById(R.id.share); \nthis.toggleOrientationButton=rootView.findViewById(R.id.toggleOrientation); \nthis.switchBackgroundButton=rootView.findViewById(R.id.switchBackground);+this.muteButton=rootView.findViewById(R.id.switchMute); \nthis.switchPopupButton=rootView.findViewById(R.id.switchPopup); \nthis.queueLayout=findViewById(R.id.playQueuePanel); \npublic void initListeners(){shareButton.setOnClickListener(this); \ntoggleOrientationButton.setOnClickListener(this); \nswitchBackgroundButton.setOnClickListener(this);+muteButton.setOnClickListener(this); \nswitchPopupButton.setOnClickListener(this); \ngetRootView().addOnLayoutChangeListener(( view,l,t,r,b,ol,ot,or,ob)->{ \npublic void onPlayBackgroundButtonClicked(){destroy();finish();}+@ Override+public void onMuteUnmuteButtonClicled(){+ super.onMuteUnmuteButtonClicled();+ setMuteIcon();+}++public void setMuteIcon(){+ if(simpleExoPlayer.getVolume()== 0){+muteButton.setColorFilter(ContextCompat.getColor(context,R.color.white));+}++else{+ muteButton.setColorFilter(ContextCompat.getColor(context,R.color.gray));+}+}@ Override \npublic void onClick(View v){}else if(v.getId()== switchBackgroundButton.getId()){ \nonPlayBackgroundButtonClicked();+}else if(v.getId()== muteButton.getId()){+onMuteUnmuteButtonClicled();+}else if(v.getId()== closeButton.getId()){ \nonPlaybackShutdown();return ; \n"
    },
    {
        "sim_msg": "made verification of @ Fold methods configurable",
        "sim_diff": "diff --git a/compiler/src/org.graalvm.compiler.core.test/src/org/graalvm/compiler/core/test/CheckGraalInvariants.java \nppp b/compiler/src/org.graalvm.compiler.core.test/src/org/graalvm/compiler/core/test/CheckGraalInvariants.java \nprotected void handleClassLoadingException(Throwable t){ \nprotected void handleParsingException(Throwable t){ \nGraalError.shouldNotReachHere(t);}++public boolean shouldVerifyFoldableMethods(){+ return true;+}}@Test \npublic static void runTest(InvariantsTool tool){ \nverifiers.add(new VerifyGetOptionsUsage()); \nVerifyFoldableMethods foldableMethodsVerifier=new VerifyFoldableMethods();- verifiers.add(foldableMethodsVerifier);+if(tool.shouldVerifyFoldableMethods()){+verifiers.add(foldableMethodsVerifier);+} \nfor(Method m:BadUsageWithEquals.class.getDeclaredMethods()){ \nResolvedJavaMethod method=metaAccess.lookupJavaMethod(m); \npublic static void runTest(InvariantsTool tool){ \nthrow new RuntimeException(e1);}- try{- foldableMethodsVerifier.finish();-}catch(Throwable e){-errors.add(e.getMessage());+if(tool.shouldVerifyFoldableMethods()){+try{+ foldableMethodsVerifier.finish();+}catch(Throwable e){+errors.add(e.getMessage());+}}} \nif(! errors.isEmpty()){ \n",
        "org_diff": "diff --git a/compiler/src/org.graalvm.compiler.debug/src/org/graalvm/compiler/debug/DebugContext.java  b/compiler/src/org.graalvm.compiler.debug/src/org/graalvm/compiler/debug/DebugContext.java \npublic String getCurrentScopeName(){private final Invariants invariants=Assertions.ENABLED?new Invariants():null;+ static StackTraceElement[] getStackTrace(Thread thread){+return thread.getStackTrace();+}+/*** Utility for enforcing{@ link DebugContext}invariants via assertions.*/public String getCurrentScopeName(){Invariants(){thread=Thread.currentThread();- origin=thread.getStackTrace();+ origin=getStackTrace(thread);}boolean checkNoConcurrentAccess() { \n"
    },
    {
        "sim_msg": "Complete listTags api",
        "sim_diff": "diff --git a/src/main/java/cc/ryanc/halo/service/TagService.java \nppp b/src/main/java/cc/ryanc/halo/service/TagService.java \npackage cc.ryanc.halo.service;+ import cc.ryanc.halo.model.dto.TagOutputDTO;import cc.ryanc.halo.model.entity.Tag;import cc.ryanc.halo.service.base.CrudService;+ import java.util.List;+/*** Tag service.*@param id id*/ \nvoid remove(Integer id);+} \ndiff --git a/src/main/java/cc/ryanc/halo/web/controller/admin/api/TagController.java \nppp b/src/main/java/cc/ryanc/halo/web/controller/admin/api/TagController.java \npackage cc.ryanc.halo.web.controller.admin.api;import cc.ryanc.halo.model.dto.TagOutputDTO;+ import cc.ryanc.halo.model.dto.TagWithCountOutputDTO;import cc.ryanc.halo.model.entity.Tag;import cc.ryanc.halo.model.params.TagParam;+ import cc.ryanc.halo.service.PostTagService;import cc.ryanc.halo.service.TagService;import lombok.extern.slf4j.Slf4j;import org.springframework.data.domain.Sort;private final TagService tagService;- public TagController(TagService tagService){+private final PostTagService postTagService;++public TagController(TagService tagService,+ PostTagService postTagService){ \nthis.tagService=tagService;+ this.postTagService=postTagService;}@GetMapping-public List<TagOutputDTO>listTags(@ SortDefault(sort=\" updateTime\", direction=Sort.Direction.DESC)Sort sort){-- return null;+ public List<TagWithCountOutputDTO>listTags(@ SortDefault(sort=\" updateTime\", direction=Sort.Direction.DESC)Sort sort){+return postTagService.listTagWithCountDtos(sort);}@ PostMapping \n",
        "org_diff": "diff --git a/src/main/java/run/halo/app/service/TagService.java  b/src/main/java/run/halo/app/service/TagService.java*@ param name name*@ return Tag*/+@ Nullable \nTag getByName(@ NonNull String name);/**diff --git a/src/main/java/run/halo/app/service/impl/CategoryServiceImpl.java  b/src/main/java/run/halo/app/service/impl/CategoryServiceImpl.java \nimport run.halo.app.service.CategoryService;import run.halo.app.service.PostCategoryService;import run.halo.app.service.base.AbstractCrudService;+ import run.halo.app.utils.ServiceUtils;import java.util.Collections;import java.util.LinkedList;public Category create(Category category){}//Check parent id-if(category.getParentId()>0){+if(! ServiceUtils.isEmptyId(category.getParentId())){count=categoryRepository.countById(category.getParentId()); \nif(count== 0){ \n"
    },
    {
        "sim_msg": "Add an integration test of android_binary - > aar_import .",
        "sim_diff": "diff --git a/src/test/shell/bazel/android/BUILD \nppp b/src/test/shell/bazel/android/BUILD \nsh_test(size=\" large\", \nsrcs=[\"android_integration_test.sh\"],data=[+\" sample.aar\",\"//external:android_sdk_for_testing\",\"//src/test/shell/bazel:test-deps\",], \ndiff --git a/src/test/shell/bazel/android/android_integration_test.sh \nppp b/src/test/shell/bazel/android/android_integration_test.sh \nsource\"${CURRENT_DIR}/../../ integration_test_setup.sh\"\\ \nfunction create_android_binary(){mkdir-p java/bazel \ncat>java/bazel/BUILD<< EOF+aar_import(+ name=\" aar\",+aar=\" sample.aar\",+) \nandroid_library(name=\" lib\", \nsrcs=[\"Lib.java\"],+ deps=[\": aar\"],) \nandroid_binary(name=\" bin\", \nandroid_binary() \nEOF+cp\"${TEST_SRCDIR}/ io_bazel/src/test/shell/bazel/android/sample.aar\"\\+java/bazel/sample.aar \ncat>java/bazel/AndroidManifest.xml<< EOF<manifest package=\" bazel.android\"/>EOF \ncat>java/bazel/Lib.java<< EOF \npackage bazel;-+import com.sample.aar.Sample;public class Lib{public static String message(){- return\"Hello Lib\";+return\"Hello Lib\"+ Sample.getZero();}}EOF \nnew file mode 100644 \nindex 000000000000.. 66fc37c9e02d \nBinary files/dev/null and b/src/test/shell/bazel/android/sample.aar differ \n",
        "org_diff": "diff --git a/src/test/shell/bazel/android/aapt_integration_test.sh  b/src/test/shell/bazel/android/aapt_integration_test.sh \nfunction test_build_with_aapt2(){setup_android_sdk_support \ncreate_android_binary-assert_build// java/bazel:bin-- android_aapt=aapt2+assert_build// java/bazel:bin}run_suite\"aapt2 integration test \" \n"
    },
    {
        "sim_msg": "Fix RouterFunction . andRoute ( )",
        "sim_diff": "diff --git a/spring-web-reactive/src/main/java/org/springframework/web/reactive/function/RouterFunction.java \nppp b/spring-web-reactive/src/main/java/org/springframework/web/reactive/function/RouterFunction.java*{@link RouterFunctions#route(RequestPredicate,HandlerFunction)}.*@param predicate the predicate to test*@ param handlerFunction the handler function to route to+*@param<S>the handler function type*@ return a composed function that first routes with this function and then the function*created from{@ code predicate}and{@ code handlerFunction}if this*function has no result*/-default RouterFunction<?>andRoute(RequestPredicate predicate,- HandlerFunction<?>handlerFunction){+default<S>RouterFunction<?>andRoute(RequestPredicate predicate,+ HandlerFunction<S>handlerFunction){ \nreturn and(RouterFunctions.route(predicate,handlerFunction));} \ndiff --git a/spring-web-reactive/src/test/java/org/springframework/web/reactive/function/RouterFunctionTests.java \nppp b/spring-web-reactive/src/test/java/org/springframework/web/reactive/function/RouterFunctionTests.java \npublic void and() throws Exception{assertEquals(handlerFunction,resultHandlerFunction.get());}+@Test+public void andRoute() throws Exception{+ RouterFunction<Integer>routerFunction1=request-> Optional.empty();+ RequestPredicate requestPredicate=request-> true;++RouterFunction<?>result=routerFunction1.andRoute(requestPredicate,this:: handlerMethod);+assertNotNull(result);++ MockServerRequest request=MockServerRequest.builder().build();+ Optional<? extends HandlerFunction<?>> resultHandlerFunction=result.route(request);+assertTrue(resultHandlerFunction.isPresent());+}++ private ServerResponse<String>handlerMethod(ServerRequest request){+return ServerResponse.ok().body(fromObject(\" 42\"));+}+@ Test \npublic void filter() throws Exception{HandlerFunction<String>handlerFunction=request-> ServerResponse.ok().body(fromObject(\" 42\")); \n",
        "org_diff": "diff --git a/spring-web-reactive/src/main/java/org/springframework/web/reactive/function/RouterFunctions.java  b/spring-web-reactive/src/main/java/org/springframework/web/reactive/function/RouterFunctions.java \nimport org.springframework.util.Assert;import org.springframework.web.reactive.HandlerMapping;import org.springframework.web.server.ServerWebExchange;+ import org.springframework.web.server.WebHandler;import org.springframework.web.server.adapter.HttpWebHandlerAdapter;+ import org.springframework.web.server.adapter.WebHttpHandlerBuilder;/***< strong>Central entry point to Spring's functional web framework.</strong>/***Convert the given{@ linkplain RouterFunction router function}into a{@ link HttpHandler}.*This conversion uses{@ linkplain HandlerStrategies#builder() default strategies}.-*<p>The returned{@ code HttpHandler}can be adapted to run in+*<p>The returned handler can be adapted to run in*< ul>*<li>Servlet 3.1+using the*{@link org.springframework.http.server.reactive.ServletHttpHandlerAdapter},</ li>*<li>Undertow using the*{@link org.springframework.http.server.reactive.UndertowHttpHandlerAdapter}.</ li>*</ ul>+*< p>Note that{@ code HttpWebHandlerAdapter}also implements{@ link WebHandler}, allowing+* for additional filter and exception handler registration through+*{@ link WebHttpHandlerBuilder}.*@ param routerFunction the router function to convert*@ return an http handler that handles HTTP request using the given router function*/-public static HttpHandler toHttpHandler(RouterFunction<?>routerFunction){+public static HttpWebHandlerAdapter toHttpHandler(RouterFunction<?>routerFunction){ \nreturn toHttpHandler(routerFunction,HandlerStrategies.withDefaults());}public static HttpHandler toHttpHandler(RouterFunction<?>routerFunction){*< li>Undertow using the*{@link org.springframework.http.server.reactive.UndertowHttpHandlerAdapter}.</ li>*</ ul>+*< p>Note that{@ code HttpWebHandlerAdapter}also implements{@ link WebHandler}, allowing+* for additional filter and exception handler registration through*@ param routerFunction the router function to convert*@ param strategies the strategies to use*@ return an http handler that handles HTTP request using the given router function*/-public static HttpHandler toHttpHandler(RouterFunction<?>routerFunction,HandlerStrategies strategies){+public static HttpWebHandlerAdapter toHttpHandler(RouterFunction<?>routerFunction,HandlerStrategies strategies){ \nAssert.notNull(routerFunction,\" RouterFunction must not be null\");Assert.notNull(strategies,\" HandlerStrategies must not be null\") ; \n"
    },
    {
        "sim_msg": "Set external nodes to default to 512m of heap",
        "sim_diff": "diff --git a/buildSrc/src/main/groovy/org/elasticsearch/gradle/test/ClusterConfiguration.groovy \nppp b/buildSrc/src/main/groovy/org/elasticsearch/gradle/test/ClusterConfiguration.groovy \nclass ClusterConfiguration{boolean debug=false@Input-String jvmArgs=System.getProperty(' tests.jvm.argline','')+ String jvmArgs=\"-Xms\"+ System.getProperty(' tests.heap.size','512m')++\"\"+\"-Xmx\"+ System.getProperty(' tests.heap.size','512m')++\"\"+System.getProperty(' tests.jvm.argline','')/***The seed nodes port file.In the case the cluster has more than one node we use a seed node \n",
        "org_diff": "diff --git a/buildSrc/src/main/groovy/org/elasticsearch/gradle/test/ClusterConfiguration.groovy  b/buildSrc/src/main/groovy/org/elasticsearch/gradle/test/ClusterConfiguration.groovy \nclass ClusterConfiguration{@ Input \nboolean debug=false+/**+* if<code>true</ code>each node will be configured with<tt>discovery.zen.minimum_master_nodes</ tt>set+* to the total number of nodes in the cluster.This will also cause that each node has`0s`state recovery+* timeout which can lead to issues if for instance an existing clusterstate is expected to be recovered+* before any tests start+*/+@Input+boolean useMinimumMasterNodes=true+@ Input \nString jvmArgs=\"-Xms\"+ System.getProperty(' tests.heap.size','512m')+\"\"+\"- Xmx\"+ System.getProperty(' tests.heap.size','512m')+class ClusterConfiguration{@ Input \nClosure waitCondition={ NodeInfo node,AntBuilder ant-> \nFile tmpFile=new File(node.cwd,' wait.success')-ant.echo(\"==>[${ new Date()}] checking health:http://${node.httpUri()}/ _cluster/health?wait_for_nodes=>=${numNodes}\")+ ant.echo(\"==>[${ new Date()}] checking health:http://${node.httpUri()}/ _cluster/health?wait_for_nodes=>=${numNodes}& wait_for_status=yellow\")// checking here for wait_for_nodes to be>= the number of nodes because its possible// this cluster is attempting to connect to nodes created by another task(same cluster name),// so there will be more nodes in that case in the cluster state-ant.get(src:\" http://${node.httpUri()}/ _cluster/health?wait_for_nodes=>=${numNodes}\",+ ant.get(src:\" http://${node.httpUri()}/ _cluster/health?wait_for_nodes=>=${numNodes}& wait_for_status=yellow\", \ndest:tmpFile.toString(),ignoreerrors:true,//do not fail on error,so logging buffers can be flushed by the wait task \nretries:10)diff --git a/buildSrc/src/main/groovy/org/elasticsearch/gradle/test/ClusterFormationTasks.groovy  b/buildSrc/src/main/groovy/org/elasticsearch/gradle/test/ClusterFormationTasks.groovy \nclass ClusterFormationTasks{//basically skip initial state recovery to allow the cluster to form using a realistic master election// this means all nodes must be up,join the seed node and do a master election.This will also allow new and// old nodes in the BWC case to become the master-if(node.config.numNodes>1){+if(node.config.useMinimumMasterNodes&& node.config.numNodes>1){ \nesConfig[' discovery.zen.minimum_master_nodes']=node.config.numNodes \nesConfig[' discovery.initial_state_timeout']=' 0s'//don't wait for state.. just start up quickly \n} \n"
    },
    {
        "sim_msg": "Fix java_toolchain . jvm_opts label expansion if javac is an alias",
        "sim_diff": "diff --git a/src/main/java/com/google/devtools/build/lib/rules/java/JavaToolchain.java \nppp b/src/main/java/com/google/devtools/build/lib/rules/java/JavaToolchain.java \nimport com.google.devtools.build.lib.collect.nestedset.NestedSet;import com.google.devtools.build.lib.collect.nestedset.NestedSetBuilder;import com.google.devtools.build.lib.collect.nestedset.Order;+ import com.google.devtools.build.lib.rules.AliasProvider;import com.google.devtools.build.lib.rules.RuleConfiguredTargetFactory;import com.google.devtools.build.lib.rules.java.JavaToolchainData.SupportsWorkers;import com.google.devtools.build.lib.syntax.Type;public ConfiguredTarget create(RuleContext ruleContext)throws RuleErrorExceptio \nNestedSet<Artifact>tools=PrerequisiteArtifacts.nestedSet(ruleContext,\" tools\", Mode.HOST); \nTransitiveInfoCollection javacDep=ruleContext.getPrerequisite(\" javac\", Mode.HOST);-List<String>jvmOpts=getJvmOpts(- ruleContext,- ImmutableMap.< Label,ImmutableCollection<Artifact>> of(- javacDep.getLabel(),ImmutableList.of(javac)));+List<String>jvmOpts=+ getJvmOpts(+ ruleContext,+ ImmutableMap.< Label,ImmutableCollection<Artifact>> of(+ AliasProvider.getDependencyLabel(javacDep), ImmutableList.of(javac))); \nJavaToolchainData toolchainData=new JavaToolchainData ( \n",
        "org_diff": "diff --git a/src/test/java/com/google/devtools/build/lib/collect/nestedset/NestedSetImplTest.java  b/src/test/java/com/google/devtools/build/lib/collect/nestedset/NestedSetImplTest.java \npublic void correctOrder(){return builder.build();}+@ Test+public void hoistingKeepsSetSmall(){+ NestedSet<String>first=NestedSetBuilder.< String>stableOrder().add(\" a\").build();+ NestedSet<String>second=NestedSetBuilder.< String>stableOrder().add(\" a\").build();+ NestedSet<String>singleton=+ NestedSetBuilder.< String>stableOrder().addTransitive(first). addTransitive(second). build();+ assertThat(singleton.toList()). containsExactly(\" a\");+ assertThat(singleton.isSingleton()). isTrue();+}+@Test \npublic void addTransitiveAndBlockIfFuture_propagatesInterrupt() throws Exception{SettableFuture<Object[]>deserializationFuture=SettableFuture.create() ; \n"
    },
    {
        "sim_msg": "use SneakyThrows",
        "sim_diff": "diff --git a/sharding-jdbc/sharding-jdbc-orchestration/src/main/java/io/shardingsphere/shardingjdbc/orchestration/internal/datasource/OrchestrationMasterSlaveDataSource.java \nppp b/sharding-jdbc/sharding-jdbc-orchestration/src/main/java/io/shardingsphere/shardingjdbc/orchestration/internal/datasource/OrchestrationMasterSlaveDataSource.java \nimport io.shardingsphere.orchestration.internal.OrchestrationFacade;import io.shardingsphere.orchestration.internal.config.ConfigurationService;import io.shardingsphere.orchestration.internal.event.config.MasterSlaveConfigurationChangedEvent;+ import io.shardingsphere.orchestration.internal.event.config.PropertiesChangedEvent;import io.shardingsphere.orchestration.internal.rule.OrchestrationMasterSlaveRule;import io.shardingsphere.shardingjdbc.jdbc.core.datasource.MasterSlaveDataSource;import io.shardingsphere.shardingjdbc.orchestration.internal.circuit.datasource.CircuitBreakerDataSource;import io.shardingsphere.shardingjdbc.orchestration.internal.util.DataSourceConverter;+ import lombok.SneakyThrows;import java.sql.Connection;import java.sql.SQLException;public final void renew(final MasterSlaveConfigurationChangedEvent masterSlaveEv \ndataSource=new MasterSlaveDataSource(DataSourceConverter.getDataSourceMap(masterSlaveEvent.getDataSourceConfigurations()), \nmasterSlaveEvent.getMasterSlaveRuleConfig(),ConfigMapContext.getInstance().getConfigMap(),masterSlaveEvent.getProps());}++/**+* Renew properties.+*+*@ param propertiesEvent properties event+*/+@SneakyThrows+@ Subscribe+public void renew(final PropertiesChangedEvent propertiesEvent){+dataSource=new MasterSlaveDataSource(dataSource.getDataSourceMap(),+ dataSource.getMasterSlaveRule(),ConfigMapContext.getInstance().getConfigMap(),new ShardingProperties(propertiesEvent.getProps()));+}} \n",
        "org_diff": "diff --git a/sharding-jdbc/sharding-jdbc-orchestration/src/main/java/io/shardingsphere/shardingjdbc/orchestration/internal/datasource/OrchestrationMasterSlaveDataSource.java  b/sharding-jdbc/sharding-jdbc-orchestration/src/main/java/io/shardingsphere/shardingjdbc/orchestration/internal/datasource/OrchestrationMasterSlaveDataSource.java \nimport io.shardingsphere.core.constant.properties.ShardingProperties;import io.shardingsphere.core.rule.MasterSlaveRule;import io.shardingsphere.orchestration.config.OrchestrationConfiguration;+ import io.shardingsphere.orchestration.config.OrchestrationType;import io.shardingsphere.orchestration.internal.OrchestrationFacade;import io.shardingsphere.orchestration.internal.config.ConfigurationService;import io.shardingsphere.orchestration.internal.event.config.MasterSlaveConfigurationEventBusEvent;public OrchestrationMasterSlaveDataSource(final OrchestrationConfiguration orche \nPreconditions.checkState(null!= masterSlaveRuleConfig&&!Strings.isNullOrEmpty(masterSlaveRuleConfig.getMasterDataSourceName()),\"No available master slave rule configuration to load.\"); \ndataSource=new MasterSlaveDataSource(configService.loadDataSourceMap(),new OrchestrationMasterSlaveRule(masterSlaveRuleConfig), configService.loadMasterSlaveConfigMap(),new ShardingProperties(configService.loadMasterSlaveProperties()));- initOrchestrationFacade(dataSource);+getOrchestrationFacade().init(OrchestrationType.MASTER_SLAVE);}private void initOrchestrationFacade(final MasterSlaveDataSource masterSlaveDataSource){ \n"
    },
    {
        "sim_msg": "Update paint flags and remove anti alias .",
        "sim_diff": "diff --git a/library/src/main/java/com/bumptech/glide/load/resource/bitmap/Downsampler.java \nppp b/library/src/main/java/com/bumptech/glide/load/resource/bitmap/Downsampler.java \nprivate Bitmap downsampleWithSize(MarkEnforcingInputStream is,RecyclableBuffere \nBitmap.Config config=getConfig(is,decodeFormat); \noptions.inSampleSize=sampleSize;options.inPreferredConfig=config;+ if(options.inPreferredConfig!= Bitmap.Config.ARGB_8888){+options.inDither=true;+}if(( options.inSampleSize== 1|| Build.VERSION_CODES.KITKAT<= Build.VERSION.SDK_INT)&&shouldUsePool(is)){int targetWidth=( int)Math.ceil(inWidth/( double)sampleSize); \nint targetHeight=( int)Math.ceil(inHeight/( double)sampleSize); \ndiff --git a/library/src/main/java/com/bumptech/glide/load/resource/bitmap/TransformationUtils.java \nppp b/library/src/main/java/com/bumptech/glide/load/resource/bitmap/TransformationUtils.java*/ \npublic final class TransformationUtils{private static final String TAG=\" TransformationUtils\";-public static final int PAINT_FLAGS=Paint.ANTI_ALIAS_FLAG|Paint.DITHER_FLAG|Paint.FILTER_BITMAP_FLAG;+ public static final int PAINT_FLAGS=Paint.DITHER_FLAG|Paint.FILTER_BITMAP_FLAG;private TransformationUtils(){//Utility class . \n",
        "org_diff": "diff --git a/library/src/main/java/com/bumptech/glide/load/resource/bitmap/Downsampler.java  b/library/src/main/java/com/bumptech/glide/load/resource/bitmap/Downsampler.java \nprivate static IOException newIoExceptionForInBitmapAssertion(IllegalArgumentExc+\",inBitmap:\"+getInBitmapString(options), e);}-// Avoid short circuiting SDK checks.@ SuppressWarnings(\" PMD.CollapsibleIfStatements\")@TargetApi(Build.VERSION_CODES.O)private static void setInBitmap(BitmapFactory.Options options,BitmapPool bitmapPool,int width,int height){-if(Build.VERSION.SDK_INT>= Build.VERSION_CODES.O-&&options.inPreferredConfig== Config.HARDWARE){-return;+// Avoid short circuiting,it appears to break on some devices.+ if(Build.VERSION.SDK_INT>= Build.VERSION_CODES.O){+if(options.inPreferredConfig== Config.HARDWARE){+return;+}}// BitmapFactory will clear out the Bitmap before writing to it,so getDirty is safe.options.inBitmap=bitmapPool.getDirty(width,height,options.inPreferredConfig); \n"
    },
    {
        "sim_msg": "Upgrade to Jboss Transaction Spi 7 . 6 . 0 . Final",
        "sim_diff": "diff --git a/spring-boot-dependencies/pom.xml \nppp b/spring-boot-dependencies/pom.xml<jaxen.version>1.1.6</ jaxen.version>< jaybird.version>2.2.13</ jaybird.version>< jboss-logging.version>3.3.1.Final</ jboss-logging.version>-<jboss-transaction-spi.version>7.5.2.Final</ jboss-transaction-spi.version>+<jboss-transaction-spi.version>7.6.0.Final</ jboss-transaction-spi.version>< jdom2.version>2.0.6</ jdom2.version>< jedis.version>2.9.0</ jedis.version>< jersey.version>2.25.1</ jersey.version > \n",
        "org_diff": "diff --git a/spring-boot-dependencies/pom.xml  b/spring-boot-dependencies/pom.xml<jaxen.version>1.1.6</ jaxen.version>< jaybird.version>2.2.11</ jaybird.version>< jboss-logging.version>3.3.0.Final</ jboss-logging.version>-<jboss-transaction-spi.version>7.3.2.Final</ jboss-transaction-spi.version>+<jboss-transaction-spi.version>7.3.4.Final</ jboss-transaction-spi.version>< jdom2.version>2.0.6</ jdom2.version>< jedis.version>2.8.1</ jedis.version>< jersey.version>2.23.2</ jersey.version > \n"
    },
    {
        "sim_msg": "detect JRE ( vs JDK ) and invalid JAVA_HOME",
        "sim_diff": "diff --git a/bin/service.bat \nppp b/bin/service.bat \nset SCRIPT_DIR=%~dp0 \nfor%% I in(\"%SCRIPT_DIR%..\")do set ES_HOME=%%~ dpfI \nrem Detect JVM version to figure out appropriate executable to use+if not exist\"% JAVA_HOME%\\ bin\\java.exe\"(+echo JAVA_HOME points to an invalid Java installation(no java.exe found in\"% JAVA_HOME%\"^).Existing...+ goto finally+)\"% JAVA_HOME%\\ bin\\java\"- version 2>& 1|find\"64-Bit\"> nul:if errorlevel 1(echo The service'% SERVICE_ID%' has been removed \ngoto finally:doInstall-echo Installing service:'%SERVICE_ID%'-echo Using JAVA_HOME(% ARCH%):% JAVA_HOME%+ echo Installing service:\"%SERVICE_ID%\"+echo Using JAVA_HOME(% ARCH%):\"%JAVA_HOME%\"+rem Check JVM server dll first \nset JVM_DLL=% JAVA_HOME%\\ jre\\bin\\server\\jvm.dll+if exist%JVM_DLL%goto foundJVM++ set JVM_DLL=% JAVA_HOME%\\ bin\\client\\jvm.dll++ if exist%JVM_DLL%(+echo Warning:JAVA_HOME points to a JRE and not JDK installation;a client(not a server^) JVM will be used...+)else(+ echo JAVA_HOME points to an invalid Java installation(no jvm.dll found in\"% JAVA_HOME%\"^).Existing...+ goto finally+)++:foundJVM \nif\"% ES_MIN_MEM%\"==\"\"(set ES_MIN_MEM=256m \n) \n",
        "org_diff": "diff --git a/bin/as.bat  b/bin/as.bat \necho NB:JAVA_HOME should point to a JDK not a JRE.goto exit_bat:okJava-set JAVACMD=\"%JAVA_HOME%\"\\bin\\java-% JAVACMD%- Dfile.encoding=UTF-8%BOOT_CLASSPATH%- jar\"% CORE_JAR%\"-pid\"% PID%\"-target-ip 127.0.0.1-telnet-port%TELNET_PORT%- http-port%HTTP_PORT%- core\"% CORE_JAR%\"-agent\"% AGENT_JAR%\" \nif%ERRORLEVEL%NEQ 0 goto exit_bat \nif%exitProcess%==1 goto exit_bat \n"
    },
    {
        "sim_msg": "updated changelog as a part of the release",
        "sim_diff": "diff --git a/debian/debian/changelog \nppp b/debian/debian/changelog+hudson(1.391)unstable;urgency=low++*See http://hudson.dev.java.net/changelog.html for more details.++--Kohsuke Kawaguchi<kk@kohsuke.org>Sun,26 Dec 2010 10:24:25-0800+hudson(1.390)unstable;urgency=low*See http://hudson.dev.java.net/changelog.html for more details . \n",
        "org_diff": "diff --git a/debian/debian/changelog  b/debian/debian/changelog+hudson(1.392)unstable;urgency=low++*See http://hudson.dev.java.net/changelog.html for more details.++--Kohsuke Kawaguchi<kk@kohsuke.org>Fri,31 Dec 2010 21:41:33-0800+hudson(1.391)unstable;urgency=low*See http://hudson.dev.java.net/changelog.html for more details . \n"
    },
    {
        "sim_msg": "Add some developer utils .",
        "sim_diff": "diff --git a/app/src/main/java/org/thoughtcrime/securesms/RecipientPreferenceActivity.java \nppp b/app/src/main/java/org/thoughtcrime/securesms/RecipientPreferenceActivity.java \nimport org.thoughtcrime.securesms.util.DynamicTheme;import org.thoughtcrime.securesms.util.FeatureFlags;import org.thoughtcrime.securesms.util.IdentityUtil;+ import org.thoughtcrime.securesms.util.ServiceUtil;import org.thoughtcrime.securesms.util.TextSecurePreferences;import org.thoughtcrime.securesms.util.ThemeUtil;+ import org.thoughtcrime.securesms.util.Util;import org.thoughtcrime.securesms.util.ViewUtil;import org.thoughtcrime.securesms.util.concurrent.ListenableFuture;import org.thoughtcrime.securesms.util.concurrent.SignalExecutors;private void setHeader(@ NonNull Recipient recipient){ \nthis.avatar.setBackgroundColor(recipient.getColor().toActionBarColor(this));this.toolbarLayout.setTitle(recipient.toShortString(this));this.toolbarLayout.setContentScrimColor(recipient.getColor().toActionBarColor(this));+ if(recipient.getUuid().isPresent()){+toolbarLayout.setOnLongClickListener(v->{+ Util.copyToClipboard(this,recipient.getUuid().get().toString());+ServiceUtil.getVibrator(this). vibrate(200);+return true;+});+}}@Override \ndiff --git a/app/src/main/java/org/thoughtcrime/securesms/util/ServiceUtil.java \nppp b/app/src/main/java/org/thoughtcrime/securesms/util/ServiceUtil.java \nimport android.app.AlarmManager;import android.app.NotificationManager;import android.app.job.JobScheduler;+ import android.content.ClipData;+ import android.content.ClipboardManager;import android.content.Context;import android.hardware.display.DisplayManager;import android.location.LocationManager;public static AccessibilityManager getAccessibilityManager(@ NonNull Context cont \nreturn(AccessibilityManager)context.getSystemService(Context.ACCESSIBILITY_SERVICE);}+ public static ClipboardManager getClipboardManager(@ NonNull Context context){+return(ClipboardManager)context.getSystemService(Context.CLIPBOARD_SERVICE);+}+@ RequiresApi(26)public static JobScheduler getJobScheduler(Context context){ \nreturn(JobScheduler)context.getSystemService(JobScheduler.class); \ndiff --git a/app/src/main/java/org/thoughtcrime/securesms/util/Util.java \nppp b/app/src/main/java/org/thoughtcrime/securesms/util/Util.java \npublic static void sleep(long millis){}}+public static void copyToClipboard(@ NonNull Context context,@ NonNull String text){+ServiceUtil.getClipboardManager(context). setPrimaryClip(ClipData.newPlainText(\" text\", text));+}+ \nprivate static Handler getHandler(){if(handler== null){ \nsynchronized(Util.class){ \n",
        "org_diff": "diff --git a/app/src/main/java/org/thoughtcrime/securesms/jobs/SendViewedReceiptJob.java  b/app/src/main/java/org/thoughtcrime/securesms/jobs/SendViewedReceiptJob.java \nimport org.thoughtcrime.securesms.recipients.Recipient;import org.thoughtcrime.securesms.recipients.RecipientId;import org.thoughtcrime.securesms.recipients.RecipientUtil;+ import org.thoughtcrime.securesms.util.FeatureFlags;import org.thoughtcrime.securesms.util.TextSecurePreferences;import org.whispersystems.signalservice.api.SignalServiceMessageSender;import org.whispersystems.signalservice.api.crypto.UntrustedIdentityException;private SendViewedReceiptJob(@ NonNull Parameters parameters,@ Override \npublic void onRun() throws IOException,UntrustedIdentityException{- if(! TextSecurePreferences.isReadReceiptsEnabled(context)||syncTimestamps.isEmpty())return;+ if(! TextSecurePreferences.isReadReceiptsEnabled(context)||syncTimestamps.isEmpty()||!FeatureFlags.sendViewedReceipts())return;if(! RecipientUtil.isMessageRequestAccepted(context,threadId)){Log.w(TAG,\" Refusing to send receipts to untrusted recipient\");diff --git a/app/src/main/java/org/thoughtcrime/securesms/util/FeatureFlags.java  b/app/src/main/java/org/thoughtcrime/securesms/util/FeatureFlags.java \nprivate static final String GV1_AUTO_MIGRATE=\" android.groupsV1Migration.auto.3\"; \nprivate static final String GV1_MANUAL_MIGRATE=\" android.groupsV1Migration.manual\"; \nprivate static final String GV1_FORCED_MIGRATE=\" android.groupsV1Migration.forced\";+private static final String SEND_VIEWED_RECEIPTS=\" android.sendViewedReceipts\";/*** We will only store remote values for flags in this set.If you want a flag to be controllable \nGV1_AUTO_MIGRATE,GV1_MANUAL_MIGRATE,GV1_FORCED_MIGRATE,- GROUP_CALLING+GROUP_CALLING,+ SEND_VIEWED_RECEIPTS);/**public static boolean groupsV1ForcedMigration(){return getBoolean(GV1_FORCED_MIGRATE,false)&&groupsV1ManualMigration()&& groupsV1AutoMigration();}+/** Whether or not to send viewed receipts.*/+ public static boolean sendViewedReceipts(){+ return getBoolean(SEND_VIEWED_RECEIPTS,false);+}+/** Only for rendering debug info.*/public static synchronized@NonNull Map<String,Object>getMemoryValues(){return new TreeMap<>(REMOTE_VALUES); \n"
    },
    {
        "sim_msg": "Add call to oneOffExecutors . remove in Computer . removeExecutor",
        "sim_diff": "diff --git a/core/src/main/java/hudson/model/Computer.java \nppp b/core/src/main/java/hudson/model/Computer.java \nprotected void removeExecutor(final Executor e){ \npublic void run(){synchronized(Computer.this){ \nexecutors.remove(e);+oneOffExecutors.remove(e); \naddNewExecutorIfNecessary();if(! isAlive()){ \nAbstractCIBase ciBase=Jenkins.getInstanceOrNull() ; \n",
        "org_diff": "diff --git a/core/src/main/java/hudson/model/Computer.java  b/core/src/main/java/hudson/model/Computer.java \npublic int getNumExecutors(){*/@ CheckForNull \npublic Node getNode(){- Jenkins j=Jenkins.getInstanceOrNull();+ Jenkins j=Jenkins.getInstanceOrNull();//TODO confirm safe to assume non-null and use getInstance() \nif(j== null){ \nreturn null;} \npublic void run(){addNewExecutorIfNecessary();if(! isAlive()){ \nAbstractCIBase ciBase=Jenkins.getInstanceOrNull();- if(ciBase!= null){+if(ciBase!= null){// TODO confirm safe to assume non-null and use getInstance() \nciBase.removeComputer(Computer.this);}} \n"
    },
    {
        "sim_msg": "Set original encoded image metadata in DecodeProducer",
        "sim_diff": "diff --git a/imagepipeline/src/main/java/com/facebook/imagepipeline/producers/DecodeProducer.java \nppp b/imagepipeline/src/main/java/com/facebook/imagepipeline/producers/DecodeProducer.java \nimport com.facebook.imagepipeline.image.CloseableStaticBitmap;import com.facebook.imagepipeline.image.EncodedImage;import com.facebook.imagepipeline.image.ImmutableQualityInfo;+ import com.facebook.imagepipeline.image.OriginalEncodedImageInfo;import com.facebook.imagepipeline.image.QualityInfo;import com.facebook.imagepipeline.request.ImageRequest;import com.facebook.imagepipeline.systrace.FrescoSystrace;private void doDecode(EncodedImage encodedImage,@ Status int status){ \nrequestedSizeStr,sampleSize); \nmProducerListener.onProducerFinishWithSuccess(mProducerContext,PRODUCER_NAME,extraMap);++ if(image!= null){+image.setOriginalEncodedImageInfo(+ new OriginalEncodedImageInfo(+ encodedImage.getWidth(),encodedImage.getHeight(),encodedImage.getSize()));+}+ \nhandleResult(image,status);}finally{EncodedImage.closeSafely(encodedImage); \n",
        "org_diff": "diff --git a/imagepipeline/src/main/java/com/facebook/imagepipeline/platform/ArtDecoder.java  b/imagepipeline/src/main/java/com/facebook/imagepipeline/platform/ArtDecoder.java \nimport com.facebook.common.references.CloseableReference;import com.facebook.common.streams.LimitedInputStream;import com.facebook.common.streams.TailAppendingInputStream;+ import com.facebook.imagepipeline.bitmaps.SimpleBitmapReleaser;import com.facebook.imagepipeline.image.EncodedImage;import com.facebook.imagepipeline.memory.BitmapPool;import com.facebook.imageutils.BitmapUtil;public ArtDecoder(BitmapPool bitmapPool,int maxNumThreads,SynchronizedPool dec \nif(decodedBitmap== null){ \ndecodedBitmap=BitmapFactory.decodeStream(inputStream,null,options);}+}catch(IllegalArgumentException e){+mBitmapPool.release(bitmapToReuse);+//This is thrown if the Bitmap options are invalid,so let's just try to decode the bitmap+//as-is,which might be inefficient-but it works.+ try{+// We need to reset the stream first+inputStream.reset();++Bitmap naiveDecodedBitmap=BitmapFactory.decodeStream(inputStream);+if(naiveDecodedBitmap== null){+throw e;+}+ return CloseableReference.of(naiveDecodedBitmap,SimpleBitmapReleaser.getInstance());+} catch(IOException re){+//We throw the original exception instead since it's the one causing this workaround in the+//first place.+ throw e;+}} catch(RuntimeException re){ \nmBitmapPool.release(bitmapToReuse); \nthrow re ; \n"
    },
    {
        "sim_msg": "Add LLVM Cauldron presentation to publications list",
        "sim_diff": "diff --git a/docs/PUBLICATIONS.md \nppp b/docs/PUBLICATIONS.md \nand[Graal and Truffle papers]( https://wiki.openjdk.java.net/display/Graal/Publi## Presentations+*[Using LLVM and Sulong for Language C Extensions]( http://chrisseaton.com/rubytruffle/llvm-cauldron-16/llvm-cauldron-sulong.pdf)< br>LLVM Cauldron 2016,September 8,2016,Hebden Bridge,The United Kingdom<br>+[Download slides]( http://chrisseaton.com/rubytruffle/llvm-cauldron-16/llvm-cauldron-sulong.pdf)< br>+[Watch video]( https://www.youtube.com/watch?v=bJzMfYX6n9A)*[Sulong:Fast LLVM IR Execution on the JVM with Truffle and Graal]( https://fosdem.org/2016/schedule/event/llvm_sulong/)<br>FOSDEM'16(LLVM Toolchain devroom), January 31,2016,Brussels,Belgium<br>[ Download slides]( https://fosdem.org/2016/schedule/event/llvm_sulong/attachments/slides/1205/export/events/attachments/llvm_sulong/slides/1205/Sulong.pdf ) \n",
        "org_diff": "diff --git a/docs/PUBLICATIONS.md  b/docs/PUBLICATIONS.md \nand[Graal and Truffle papers]( https://wiki.openjdk.java.net/display/Graal/Publi## Presentations-*[Using LLVM and Sulong for Language C Extensions]( http://chrisseaton.com/rubytruffle/llvm-cauldron-16/llvm-cauldron-sulong.pdf)< br>LLVM Cauldron 2016,September 8,2016,Hebden Bridge,The United Kingdom<br>+*[ Using LLVM and Sulong for Language C Extensions]( http://chrisseaton.com/rubytruffle/llvm-cauldron-16/llvm-cauldron-sulong.pdf)< br>+ LLVM Cauldron 2016,September 8,2016,Hebden Bridge,The United Kingdom<br>[ Download slides]( http://chrisseaton.com/rubytruffle/llvm-cauldron-16/llvm-cauldron-sulong.pdf)< br>[ Watch video]( https://www.youtube.com/watch?v=bJzMfYX6n9A)*[Sulong:Fast LLVM IR Execution on the JVM with Truffle and Graal]( https://fosdem.org/2016/schedule/event/llvm_sulong/)<br > \n"
    },
    {
        "sim_msg": "Improvements for Multiton JavaDoc",
        "sim_diff": "diff --git a/multiton/src/main/java/com/iluwatar/multiton/App.java \nppp b/multiton/src/main/java/com/iluwatar/multiton/App.java*accessible object the Multiton pattern defines many globally*accessible objects.The client asks for the correct instance*from the Multiton by passing an enumeration as parameter.-*-*In this example Nazgul is the Multiton and we can ask single-* Nazgul from it using NazgulName.The Nazguls are statically+*<p>+*In this example{@ link Nazgul}is the Multiton and we can ask single+*{@ link Nazgul}from it using{@ link NazgulName}. The{@ link Nazgul}s are statically*initialized and stored in concurrent hash map.**/ \npublic class App{+/**+*Program entry point+*@param args command line args+*/public static void main(String[] args){ \nSystem.out.println(\" KHAMUL=\"+Nazgul.getInstance(NazgulName.KHAMUL));System.out.println(\" MURAZOR=\"+Nazgul.getInstance(NazgulName.MURAZOR));diff --git a/multiton/src/main/java/com/iluwatar/multiton/Nazgul.java \nppp b/multiton/src/main/java/com/iluwatar/multiton/Nazgul.java/****Nazgul is a Multiton class.Nazgul instances can be queried-* using getInstance() method.+*using{@ link#getInstance}method.**/ \npublic class Nazgul{diff --git a/multiton/src/main/java/com/iluwatar/multiton/NazgulName.java \nppp b/multiton/src/main/java/com/iluwatar/multiton/NazgulName.java/***-* Each Nazgul has different NazgulName.+*Each Nazgul has different{@ link NazgulName}.**/public enum NazgulName{diff --git a/multiton/src/test/java/com/iluwatar/multiton/AppTest.java \nppp b/multiton/src/test/java/com/iluwatar/multiton/AppTest.java \nimport com.iluwatar.multiton.App;+/**+*+*Application test+*+*/public class AppTest{@ Test \n",
        "org_diff": "diff --git a/multiton/src/main/java/com/iluwatar/App.java  b/multiton/src/main/java/com/iluwatar/App.java \npackage com.iluwatar;+/**+*+*Whereas Singleton design pattern introduces single globally+* accessible object the Multiton pattern defines many globally+* accessible objects.The client asks for the correct instance+* from the Multiton by passing an enumeration as parameter.+*+*In this example Nazgul is the Multiton and we can ask single+* Nazgul from it using NazgulName.The Nazguls are statically+* initialized and stored in concurrent hash map.+*+*/ \npublic class App{public static void main(String[] args){ \ndiff --git a/multiton/src/main/java/com/iluwatar/Nazgul.java  b/multiton/src/main/java/com/iluwatar/Nazgul.java \nimport java.util.Map;import java.util.concurrent.ConcurrentHashMap;+/**+*+*Nazgul is a Multiton class.Nazgul instances can be queried+* using getInstance() method.+*+*/ \npublic class Nazgul{private static Map<NazgulName,Nazgul>nazguls;diff --git a/multiton/src/main/java/com/iluwatar/NazgulName.java  b/multiton/src/main/java/com/iluwatar/NazgulName.java \npackage com.iluwatar;+/**+*+*Each Nazgul has different NazgulName.+*+*/ \npublic enum NazgulName{KHAMUL,MURAZOR,DWAR,JI_INDUR,AKHORAHIL,HOARMURATH,ADUNAPHEL,REN,UVATHA ; \n"
    },
    {
        "sim_msg": "xml error location",
        "sim_diff": "diff --git a/src/test/java/org/apache/ibatis/builder/XmlMapperBuilderTest.java \nppp b/src/test/java/org/apache/ibatis/builder/XmlMapperBuilderTest.java \npublic void erorrResultMapLocation() throws Exception{try(InputStream inputStream=Resources.getResourceAsStream(resource)){XMLMapperBuilder builder=new XMLMapperBuilder(inputStream,configuration,resource,configuration.getSqlFragments()); \nbuilder.parse();- MappedStatement mappedStatement=configuration.getMappedStatement(\" findProblemTypeTest\");+ String resultMapName=\" java.lang.String\";+//namespace+\".\"+id+String statementId=\" org.mybatis.spring.ErrorProblemMapper\"+\".\"+\"findProblemResultMapTest\";+//same as MapperBuilderAssistant.getStatementResultMaps Exception message+String message=\" Could not find result map'\"+resultMapName+\"'referenced from'\"+statementId+\"'\";+ IncompleteElementException exception=Assertions.assertThrows(IncompleteElementException.class,+()-> configuration.getMappedStatement(\" findProblemTypeTest\"));+assertThat(exception.getMessage()). isEqualTo(message);}} \n} \n",
        "org_diff": "diff --git a/src/main/java/org/apache/ibatis/builder/xml/XMLMapperBuilder.java  b/src/main/java/org/apache/ibatis/builder/xml/XMLMapperBuilder.java \nprivate void bindMapperForNamespace(){} catch(ClassNotFoundException e){// ignore,bound type is not required}- if(boundType!= null){-if(! configuration.hasMapper(boundType)){-// Spring may not know the real resource name so we set a flag-//to prevent loading again this resource from the mapper interface-//look at MapperAnnotationBuilder#loadXmlResource-configuration.addLoadedResource(\" namespace:\"+namespace);-configuration.addMapper(boundType);-}+if(boundType!= null&&!configuration.hasMapper(boundType)){+// Spring may not know the real resource name so we set a flag+//to prevent loading again this resource from the mapper interface+//look at MapperAnnotationBuilder#loadXmlResource+configuration.addLoadedResource(\" namespace:\"+namespace);+configuration.addMapper(boundType);}} \n} \n"
    },
    {
        "sim_msg": "Translated using Weblate ( Russian )",
        "sim_diff": "diff --git a/app/src/main/res/values-ru/strings.xml \nppp b/app/src/main/res/values-ru/strings.xml<string name=\" download_path_audio_summary\"> Папка для хранения загруженных аудио</ string>< string name=\" download_path_audio_dialog_title\"> Введите путь к папке для загрузки аудио</ string>-<string name=\" main_bg_subtitle\"> Нажмите поиск,чтобы начать</ string>+<string name=\" main_bg_subtitle\"> Начните с поиска</ string>< string name=\" msg_wait\"> Подождите…</string>< string name=\" msg_exists\"> Файл уже существует</ string>< string name=\" msg_threads\"> Потоки</ string > \n",
        "org_diff": "diff --git a/app/src/main/res/values-ru/strings.xml  b/app/src/main/res/values-ru/strings.xml<string name=\" download_path_audio_dialog_title\"> Введите путь к папке для загрузки аудио.</string>< string name=\" main_bg_subtitle\"> Нажмите поиск,чтобы начать</ string>-<string name=\" msg_wait\"> Пожалуйста подождите…</string>+<string name=\" msg_wait\"> Подождите…</string>< string name=\" msg_exists\"> Файл уже существует</ string>< string name=\" msg_threads\"> Потоки</ string>< string name=\" finish\"> Окей</ string > \n"
    },
    {
        "sim_msg": "Add an initial Ruby downstream test",
        "sim_diff": "diff --git a/ci.hocon \nppp b/ci.hocon \ndeploy-binaries-linux:${deploy-binaries}${linux-amd64}${requireGCC}{ \ndeploy-binaries-darwin:${deploy-binaries}${darwin-amd64}${darwin-llvm}{}+ ruby-downstream-test:{+packages:{+ruby:\"== 2.1.0\"+}+ run:[+[ mx,testdownstream,--repo,\" https://github.com/graalvm/truffleruby.git\",+--mx-command,\"-- dynamicimports sulong ruby_testdownstream_sulong\"]+]+}+builds=[${ gateStyle}{ name:gate-style,run:[[mx,check,--verbose,checkstyle,mdl,canonicalizeprojects,httpcheck,checkoverlap,clangformatcheck,pylint,eclipseformat]]}${gateTest32}${requireJDT}{ name:gate-full-build,run:[[mx,check,--verbose,ecj,findbugs]]}builds=[${ gateTest38-darwin}${sulongSuite}{ name:gate-sulong-v38-darwin}${gateTest38-linux}{ name:gate-gcc-v38,run:[[mx,build,--dependencies,SULONG_TEST],[mx,test,gcc38]]}${gateTest38-linux}{ name:gate-var-v38,run:[[mx,build,--dependencies,SULONG_TEST],[mx,test,interop],[mx,test,assembly],[mx,test,args],[mx,test,callback],[mx,test,vaargs]]}+${ gateTest38-linux}${ruby-downstream-test}{ name:gate-ruby-downstream}${deploy-binaries-linux}{ name:postmerge-deploy-binaries-linux-amd64}${deploy-binaries-darwin}{ name:postmerge-deploy-binaries-darwin-amd64 } \n",
        "org_diff": "diff --git a/ci.hocon  b/ci.hocon \nruby-downstream-test:{]}+python-downstream-test:{+packages:{+python:\"== 3.4.1\"+ gcc:\"== 4.9.1\"+ llvm:\">= 4.0\"+}+ run:[+[ mx,testdownstream,--repo,\" https://github.com/graalvm/graalpython.git\",+--mx-command,\"-- dynamicimports sulong gate-- tags build,python-cpyext\"]+]+}+svm-downstream-test:${requireGCC}{ \nenvironment:{ \nSVM_REPO:\" https://github.com/graalvm/graal.git\", \nbuilds=[${ gateTest40-darwin}{ name:gate-basic_mac,run:[[mx,gate,--tags,\" build,nwcc,llvm,sulong,interop\"]]}${ gateTest38-linux}${ruby-downstream-test}{ name:gate-ruby-downstream}+${ gateTest38-linux}${python-downstream-test}{ name:gate-python-downstream}${gateTest38-linux}${svm-downstream-test}{ name:gate-substratevm-downstream}${deploy-binaries-linux}{ name:postmerge-deploy-binaries-linux-amd64 } \n"
    },
    {
        "sim_msg": "reapplying a fix for ' \\ ' in SVN user name issue .",
        "sim_diff": "diff --git a/core/src/main/java/hudson/model/User.java \nppp b/core/src/main/java/hudson/model/User.java \npublic synchronized void doSubmitDescription(StaplerRequest req,StaplerRespons \npublic static User get(String name){ \nif(name== null)return null;+ name=name.replace('\\\\','_').replace('/',' _');+ \nsynchronized(byName){ \nUser u=byName.get(name); \nif(u== null){ \npublic String toString(){* The file we save our configuration.*/protected final XmlFile getConfigFile(){- String safeId=id.replace('\\\\','_').replace('/',' _');return new XmlFile(XSTREAM,new File(Hudson.getInstance().getRootDir(),\" users/\"+safeId+\"/config.xml\")); \n} \n",
        "org_diff": "diff --git a/core/src/main/java/hudson/model/Hudson.java  b/core/src/main/java/hudson/model/Hudson.java \npublic synchronized void doReload(StaplerRequest req,StaplerResponse rsp)thr \nreturn;load();+ User.reload();rsp.sendRedirect2(req.getContextPath()+\"/\");}diff --git a/core/src/main/java/hudson/model/User.java  b/core/src/main/java/hudson/model/User.java \npublic static User get(String id){}}+/**+* Reloads the configuration from disk.+*/+public static void reload(){+// iterate over an array to be concurrency-safe+for(User u:byName.values().toArray(new User[0]))+ u.load();+}+/*** Returns the user name.* / \n"
    }
]