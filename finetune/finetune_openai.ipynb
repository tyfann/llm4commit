{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Data analysis",
   "id": "6fc3e20171d58fc5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T21:05:19.163811Z",
     "start_time": "2024-06-07T21:05:18.862109Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "import tiktoken # for token counting\n",
    "import numpy as np\n",
    "from collections import defaultdict"
   ],
   "id": "b0a4731c58d080ac",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T21:05:19.270083Z",
     "start_time": "2024-06-07T21:05:19.182711Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data_path = \"../data/final_preprocessed_data/discriminator/finetune_train_data_gpt35.jsonl\"\n",
    "\n",
    "# Load the dataset\n",
    "with open(data_path, 'r', encoding='utf-8') as f:\n",
    "    dataset = [json.loads(line) for line in f]\n",
    "\n",
    "# Initial dataset stats\n",
    "print(\"Num examples:\", len(dataset))\n",
    "print(\"First example:\")\n",
    "for message in dataset[0][\"messages\"]:\n",
    "    print(message)"
   ],
   "id": "9a863229ed49541f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num examples: 11884\n",
      "First example:\n",
      "{'role': 'user', 'content': 'The following is a diff which describes the code changes in a commit, Your task is to write a short commit message accordingly.\\ndiff --git a/vulnerabilities/api.py b/vulnerabilities/api.py @@ -146,7 +146,7 @@ class PackageViewSet(viewsets.ReadOnlyModelViewSet):\\n\"Error\": \"A non-empty \\'purls\\' list of package URLs is required.\"\\n},\\n)\\n- for purl in request.data.get(\"purls\"):\\n+ for purl in request.data[\"purls\"]:\\ntry:\\npurl = PackageURL.from_string(purl).to_dict()\\nexcept ValueError as ve:\\n\\nAccording to the diff, the commit message should be:'}\n",
      "{'role': 'assistant', 'content': 'Remove redundant \"get\" in bulk api code'}\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T21:06:10.875992Z",
     "start_time": "2024-06-07T21:06:10.831764Z"
    }
   },
   "cell_type": "code",
   "source": [
    "## write to jsonl file for previous 3000 examples\n",
    "with open(\"../data/final_preprocessed_data/discriminator/finetune_train_data_gpt35_3000.jsonl\", \"w\") as f:\n",
    "    for item in dataset[:3000]:\n",
    "        f.write(json.dumps(item) + \"\\n\")"
   ],
   "id": "615c215994f00f8f",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-06T09:51:45.536310Z",
     "start_time": "2024-06-06T09:51:45.492594Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Format error checks\n",
    "format_errors = defaultdict(int)\n",
    "\n",
    "for ex in dataset:\n",
    "    if not isinstance(ex, dict):\n",
    "        format_errors[\"data_type\"] += 1\n",
    "        continue\n",
    "        \n",
    "    messages = ex.get(\"messages\", None)\n",
    "    if not messages:\n",
    "        format_errors[\"missing_messages_list\"] += 1\n",
    "        continue\n",
    "        \n",
    "    for message in messages:\n",
    "        if \"role\" not in message or \"content\" not in message:\n",
    "            format_errors[\"message_missing_key\"] += 1\n",
    "        \n",
    "        if any(k not in (\"role\", \"content\", \"name\", \"function_call\", \"weight\") for k in message):\n",
    "            format_errors[\"message_unrecognized_key\"] += 1\n",
    "        \n",
    "        if message.get(\"role\", None) not in (\"system\", \"user\", \"assistant\", \"function\"):\n",
    "            format_errors[\"unrecognized_role\"] += 1\n",
    "            \n",
    "        content = message.get(\"content\", None)\n",
    "        function_call = message.get(\"function_call\", None)\n",
    "        \n",
    "        if (not content and not function_call) or not isinstance(content, str):\n",
    "            format_errors[\"missing_content\"] += 1\n",
    "    \n",
    "    if not any(message.get(\"role\", None) == \"assistant\" for message in messages):\n",
    "        format_errors[\"example_missing_assistant_message\"] += 1\n",
    "\n",
    "if format_errors:\n",
    "    print(\"Found errors:\")\n",
    "    for k, v in format_errors.items():\n",
    "        print(f\"{k}: {v}\")\n",
    "else:\n",
    "    print(\"No errors found\")"
   ],
   "id": "4d8620e5b9393163",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No errors found\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-06T09:52:00.820227Z",
     "start_time": "2024-06-06T09:52:00.547421Z"
    }
   },
   "cell_type": "code",
   "source": [
    "encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "# not exact!\n",
    "# simplified from https://github.com/openai/openai-cookbook/blob/main/examples/How_to_count_tokens_with_tiktoken.ipynb\n",
    "def num_tokens_from_messages(messages, tokens_per_message=3, tokens_per_name=1):\n",
    "    num_tokens = 0\n",
    "    for message in messages:\n",
    "        num_tokens += tokens_per_message\n",
    "        for key, value in message.items():\n",
    "            num_tokens += len(encoding.encode(value))\n",
    "            if key == \"name\":\n",
    "                num_tokens += tokens_per_name\n",
    "    num_tokens += 3\n",
    "    return num_tokens\n",
    "\n",
    "def num_assistant_tokens_from_messages(messages):\n",
    "    num_tokens = 0\n",
    "    for message in messages:\n",
    "        if message[\"role\"] == \"assistant\":\n",
    "            num_tokens += len(encoding.encode(message[\"content\"]))\n",
    "    return num_tokens\n",
    "\n",
    "def print_distribution(values, name):\n",
    "    print(f\"\\n#### Distribution of {name}:\")\n",
    "    print(f\"min / max: {min(values)}, {max(values)}\")\n",
    "    print(f\"mean / median: {np.mean(values)}, {np.median(values)}\")\n",
    "    print(f\"p5 / p95: {np.quantile(values, 0.1)}, {np.quantile(values, 0.9)}\")"
   ],
   "id": "54ed6c69bd925757",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-06T09:53:09.436493Z",
     "start_time": "2024-06-06T09:53:08.278270Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Warnings and tokens counts\n",
    "n_missing_system = 0\n",
    "n_missing_user = 0\n",
    "n_messages = []\n",
    "convo_lens = []\n",
    "assistant_message_lens = []\n",
    "\n",
    "for ex in dataset:\n",
    "    messages = ex[\"messages\"]\n",
    "    if not any(message[\"role\"] == \"system\" for message in messages):\n",
    "        n_missing_system += 1\n",
    "    if not any(message[\"role\"] == \"user\" for message in messages):\n",
    "        n_missing_user += 1\n",
    "    n_messages.append(len(messages))\n",
    "    convo_lens.append(num_tokens_from_messages(messages))\n",
    "    assistant_message_lens.append(num_assistant_tokens_from_messages(messages))\n",
    "    \n",
    "print(\"Num examples missing system message:\", n_missing_system)\n",
    "print(\"Num examples missing user message:\", n_missing_user)\n",
    "print_distribution(n_messages, \"num_messages_per_example\")\n",
    "print_distribution(convo_lens, \"num_total_tokens_per_example\")\n",
    "print_distribution(assistant_message_lens, \"num_assistant_tokens_per_example\")\n",
    "n_too_long = sum(l > 512 for l in convo_lens)\n",
    "print(f\"\\n{n_too_long} examples may be over the 512 token limit, they will be truncated during fine-tuning\")"
   ],
   "id": "6dafe94b716ea6d5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num examples missing system message: 11884\n",
      "Num examples missing user message: 0\n",
      "\n",
      "#### Distribution of num_messages_per_example:\n",
      "min / max: 2, 2\n",
      "mean / median: 2.0, 2.0\n",
      "p5 / p95: 2.0, 2.0\n",
      "\n",
      "#### Distribution of num_total_tokens_per_example:\n",
      "min / max: 83, 366\n",
      "mean / median: 163.01624032312353, 161.0\n",
      "p5 / p95: 135.0, 191.0\n",
      "\n",
      "#### Distribution of num_assistant_tokens_per_example:\n",
      "min / max: 2, 22\n",
      "mean / median: 6.749326825984517, 7.0\n",
      "p5 / p95: 3.0, 10.0\n",
      "\n",
      "0 examples may be over the 512 token limit, they will be truncated during fine-tuning\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-06T09:53:28.724844Z",
     "start_time": "2024-06-06T09:53:28.712350Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Pricing and default n_epochs estimate\n",
    "MAX_TOKENS_PER_EXAMPLE = 512\n",
    "\n",
    "TARGET_EPOCHS = 3\n",
    "MIN_TARGET_EXAMPLES = 100\n",
    "MAX_TARGET_EXAMPLES = 25000\n",
    "MIN_DEFAULT_EPOCHS = 1\n",
    "MAX_DEFAULT_EPOCHS = 25\n",
    "\n",
    "n_epochs = TARGET_EPOCHS\n",
    "n_train_examples = len(dataset)\n",
    "if n_train_examples * TARGET_EPOCHS < MIN_TARGET_EXAMPLES:\n",
    "    n_epochs = min(MAX_DEFAULT_EPOCHS, MIN_TARGET_EXAMPLES // n_train_examples)\n",
    "elif n_train_examples * TARGET_EPOCHS > MAX_TARGET_EXAMPLES:\n",
    "    n_epochs = max(MIN_DEFAULT_EPOCHS, MAX_TARGET_EXAMPLES // n_train_examples)\n",
    "\n",
    "n_billing_tokens_in_dataset = sum(min(MAX_TOKENS_PER_EXAMPLE, length) for length in convo_lens)\n",
    "print(f\"Dataset has ~{n_billing_tokens_in_dataset} tokens that will be charged for during training\")\n",
    "print(f\"By default, you'll train for {n_epochs} epochs on this dataset\")\n",
    "print(f\"By default, you'll be charged for ~{n_epochs * n_billing_tokens_in_dataset} tokens\")"
   ],
   "id": "e99e401efaadd2b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset has ~1937285 tokens that will be charged for during training\n",
      "By default, you'll train for 2 epochs on this dataset\n",
      "By default, you'll be charged for ~3874570 tokens\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Finetune",
   "id": "c936709084d5f9c5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T21:13:10.481871Z",
     "start_time": "2024-06-07T21:13:10.248072Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI(\n",
    "    api_key=\"sk-proj-c5dK0p6JtZQTzVdJJxuXT3BlbkFJ9bYsPPvOUbtNqcKJ5R7y\",\n",
    ")"
   ],
   "id": "417eb4af5713bfb0",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "f1346c27b16cf85d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T21:07:40.147260Z",
     "start_time": "2024-06-07T21:07:38.350638Z"
    }
   },
   "cell_type": "code",
   "source": [
    "client.files.create(\n",
    "  file=open(\"../data/final_preprocessed_data/discriminator/finetune_train_data_gpt35_3000.jsonl\", \"rb\"),\n",
    "  purpose=\"fine-tune\"\n",
    ")"
   ],
   "id": "ac234b62e90b43e3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FileObject(id='file-QdsYR7EoyvNIi6wtqm2qrjJZ', bytes=2091055, created_at=1717794459, filename='finetune_train_data_gpt35_3000.jsonl', object='file', purpose='fine-tune', status='processed', status_details=None)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T21:13:13.121940Z",
     "start_time": "2024-06-07T21:13:12.746910Z"
    }
   },
   "cell_type": "code",
   "source": "client.files.list()",
   "id": "f9f7d6b152600c1f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SyncPage[FileObject](data=[FileObject(id='file-QdsYR7EoyvNIi6wtqm2qrjJZ', bytes=2091055, created_at=1717794459, filename='finetune_train_data_gpt35_3000.jsonl', object='file', purpose='fine-tune', status='processed', status_details=None), FileObject(id='file-qkCoJIduAkUnAvGRoPJMBrjN', bytes=8280854, created_at=1717794139, filename='finetune_train_data_gpt35.jsonl', object='file', purpose='fine-tune', status='processed', status_details=None)], object='list', has_more=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T21:19:29.219096Z",
     "start_time": "2024-06-07T21:19:27.009204Z"
    }
   },
   "cell_type": "code",
   "source": [
    "client.fine_tuning.jobs.create(\n",
    "  training_file=\"file-QdsYR7EoyvNIi6wtqm2qrjJZ\", \n",
    "  model=\"gpt-3.5-turbo\"\n",
    ")"
   ],
   "id": "4b983740f9f5958c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FineTuningJob(id='ftjob-9Sepnav1KQbZ0mGQWKWz8ZWI', created_at=1717795169, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs='auto', batch_size='auto', learning_rate_multiplier='auto'), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-vNGdTdFPwXPkFJG0nWlHKFPf', result_files=[], status='validating_files', trained_tokens=None, training_file='file-QdsYR7EoyvNIi6wtqm2qrjJZ', validation_file=None, user_provided_suffix=None, seed=1338143889, estimated_finish=None, integrations=[])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T21:19:44.051032Z",
     "start_time": "2024-06-07T21:19:43.799051Z"
    }
   },
   "cell_type": "code",
   "source": "client.fine_tuning.jobs.list(limit=10)",
   "id": "c5c81860023ace32",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SyncCursorPage[FineTuningJob](data=[FineTuningJob(id='ftjob-9Sepnav1KQbZ0mGQWKWz8ZWI', created_at=1717795169, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs=3, batch_size=6, learning_rate_multiplier=2), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-vNGdTdFPwXPkFJG0nWlHKFPf', result_files=[], status='running', trained_tokens=None, training_file='file-QdsYR7EoyvNIi6wtqm2qrjJZ', validation_file=None, user_provided_suffix=None, seed=1338143889, estimated_finish=None, integrations=[]), FineTuningJob(id='ftjob-s9NJoTFCh36p9v9CA450r9Si', created_at=1717794826, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs=3, batch_size=6, learning_rate_multiplier=2), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-vNGdTdFPwXPkFJG0nWlHKFPf', result_files=[], status='cancelled', trained_tokens=None, training_file='file-QdsYR7EoyvNIi6wtqm2qrjJZ', validation_file=None, user_provided_suffix=None, seed=271616465, estimated_finish=None, integrations=[])], object='list', has_more=False)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T21:20:17.908740Z",
     "start_time": "2024-06-07T21:20:17.700445Z"
    }
   },
   "cell_type": "code",
   "source": "client.fine_tuning.jobs.retrieve(\"ftjob-9Sepnav1KQbZ0mGQWKWz8ZWI\")",
   "id": "5124390d1808fcba",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FineTuningJob(id='ftjob-9Sepnav1KQbZ0mGQWKWz8ZWI', created_at=1717795169, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs=3, batch_size=6, learning_rate_multiplier=2), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-vNGdTdFPwXPkFJG0nWlHKFPf', result_files=[], status='running', trained_tokens=None, training_file='file-QdsYR7EoyvNIi6wtqm2qrjJZ', validation_file=None, user_provided_suffix=None, seed=1338143889, estimated_finish=None, integrations=[])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T21:18:47.861379Z",
     "start_time": "2024-06-07T21:18:47.450340Z"
    }
   },
   "cell_type": "code",
   "source": "client.fine_tuning.jobs.cancel(\"ftjob-s9NJoTFCh36p9v9CA450r9Si\")",
   "id": "e1a87673fe05693e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FineTuningJob(id='ftjob-s9NJoTFCh36p9v9CA450r9Si', created_at=1717794826, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs=3, batch_size=6, learning_rate_multiplier=2), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-vNGdTdFPwXPkFJG0nWlHKFPf', result_files=[], status='cancelled', trained_tokens=None, training_file='file-QdsYR7EoyvNIi6wtqm2qrjJZ', validation_file=None, user_provided_suffix=None, seed=271616465, estimated_finish=None, integrations=[])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T22:10:03.832758Z",
     "start_time": "2024-06-07T22:10:03.636816Z"
    }
   },
   "cell_type": "code",
   "source": "client.fine_tuning.jobs.list(limit=10)",
   "id": "3fba61385f9be611",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SyncCursorPage[FineTuningJob](data=[FineTuningJob(id='ftjob-9Sepnav1KQbZ0mGQWKWz8ZWI', created_at=1717795169, error=Error(code=None, message=None, param=None), fine_tuned_model='ft:gpt-3.5-turbo-0125:personal::9Xc170ni', finished_at=1717797987, hyperparameters=Hyperparameters(n_epochs=3, batch_size=6, learning_rate_multiplier=2), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-vNGdTdFPwXPkFJG0nWlHKFPf', result_files=['file-Xo01iQv5JWJfDOeHeR6f0oMt'], status='succeeded', trained_tokens=1450593, training_file='file-QdsYR7EoyvNIi6wtqm2qrjJZ', validation_file=None, user_provided_suffix=None, seed=1338143889, estimated_finish=None, integrations=[]), FineTuningJob(id='ftjob-s9NJoTFCh36p9v9CA450r9Si', created_at=1717794826, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs=3, batch_size=6, learning_rate_multiplier=2), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-vNGdTdFPwXPkFJG0nWlHKFPf', result_files=[], status='cancelled', trained_tokens=None, training_file='file-QdsYR7EoyvNIi6wtqm2qrjJZ', validation_file=None, user_provided_suffix=None, seed=271616465, estimated_finish=None, integrations=[])], object='list', has_more=False)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T22:21:04.651619Z",
     "start_time": "2024-06-07T22:12:42.550356Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tqdm import tqdm\n",
    "def gpt_35_api(messages: list):\n",
    "\n",
    "    # completion = client.chat.completions.create(model=\"gpt-3.5-turbo-0125\", messages=messages, temperature=0.5)\n",
    "    completion = client.chat.completions.create(model=\"ft:gpt-3.5-turbo-0125:personal::9Xc170ni\", messages=messages, temperature=0)\n",
    "    return completion.choices[0].message.content\n",
    "from langchain import hub\n",
    "prompt = hub.pull(\"tyfann/llm4commit-zeroshot\")\n",
    "with open('../data/final_preprocessed_data/discriminator/dis_eval_data.json', 'r', encoding='UTF-8') as f:\n",
    "    org_data = json.load(f)\n",
    "\n",
    "org_data = org_data[:1000]\n",
    "\n",
    "gpt_msg = []\n",
    "for index, data in tqdm(enumerate(org_data), total=len(org_data), desc=\"Processing documents\"):\n",
    "    # merged_diff = '\\n'.join(diff['diff'] for diff in data['diff'])\n",
    "    messages = prompt.invoke(\n",
    "        {\"DIFF\": data['diff']}\n",
    "    ).to_messages()\n",
    "    example_prompt = [{'role': 'user','content': messages[0].content},]\n",
    "    try:\n",
    "        gpt_msg.append(gpt_35_api(example_prompt))\n",
    "    except:\n",
    "        print(index)\n",
    "        gpt_msg.append(\"\")"
   ],
   "id": "596644eaf55f518f",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing documents: 100%|██████████| 1000/1000 [08:20<00:00,  2.00it/s]\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T22:21:13.398478Z",
     "start_time": "2024-06-07T22:21:13.372483Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "for item, msg in zip(org_data, gpt_msg):\n",
    "    item['chatgpt_finetune'] = msg\n",
    "import os\n",
    "# output_file = '../data/chronicle/rag_baseline/zeroshot/rag_baseline_python_chatgpt.json'\n",
    "output_file = '../data/final_preprocessed_data/discriminator/dis_eval_data_chatgpt_finetune.json'\n",
    "os.makedirs(os.path.dirname(output_file), exist_ok=True)\n",
    "with open(output_file, 'w', encoding='UTF-8') as f:\n",
    "    json.dump(org_data, f, ensure_ascii=False, indent=4)"
   ],
   "id": "eb0a5f7f375c3af8",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Old version finetune",
   "id": "da7d73167c8a171a"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-06T09:40:32.524980Z",
     "start_time": "2024-06-06T09:40:32.513982Z"
    }
   },
   "source": [
    "import openai\n",
    "import json\n",
    "\n",
    "openai.api_key = \"sk-0rLvuRkMiD4Mw25QYygh6rUlZVjpQWNGNF4yez7z3PZ7yCOm\"\n",
    "openai.base_url = \"https://api.chatanywhere.tech/v1\"\n",
    "\n",
    "model_engine = \"gpt-3.5-turbo-ca\"\n",
    "n_epochs = 3\n",
    "batch_size = 4\n",
    "learning_rate = 1e-5\n",
    "max_tokens = 1024\n",
    "\n",
    "training_file = \"../data/final_preprocessed_data/discriminator/finetune_train_data.jsonl\"\n",
    "validation_file = \"../data/final_preprocessed_data/discriminator/finetune_eval_data.jsonl\""
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-06T09:40:35.128921Z",
     "start_time": "2024-06-06T09:40:35.095680Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "# Create the fine-tuning job\n",
    "fine_tuning_job = openai.FineTune.create(\n",
    "    model_engine=model_engine,\n",
    "    n_epochs=n_epochs,\n",
    "    batch_size=batch_size,\n",
    "    learning_rate=learning_rate,\n",
    "    max_tokens=max_tokens,\n",
    "    training_file=os.path.abspath(training_file),\n",
    "    validation_file=os.path.abspath(validation_file),\n",
    ")\n",
    "\n",
    "job_id = fine_tuning_job[\"id\"]\n",
    "print(f\"Fine-tuning job created with ID: {job_id}\")"
   ],
   "id": "a2fc46bfa2927a0d",
   "outputs": [
    {
     "ename": "APIRemovedInV1",
     "evalue": "\n\nYou tried to access openai.FineTune, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n\nYou can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n\nAlternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n\nA detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAPIRemovedInV1\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[12], line 4\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mos\u001B[39;00m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;66;03m# Create the fine-tuning job\u001B[39;00m\n\u001B[1;32m----> 4\u001B[0m fine_tuning_job \u001B[38;5;241m=\u001B[39m \u001B[43mopenai\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mFineTune\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcreate\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m      5\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmodel_engine\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel_engine\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      6\u001B[0m \u001B[43m    \u001B[49m\u001B[43mn_epochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mn_epochs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      7\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      8\u001B[0m \u001B[43m    \u001B[49m\u001B[43mlearning_rate\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlearning_rate\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      9\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmax_tokens\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmax_tokens\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     10\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtraining_file\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mos\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpath\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mabspath\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtraining_file\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     11\u001B[0m \u001B[43m    \u001B[49m\u001B[43mvalidation_file\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mos\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpath\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mabspath\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalidation_file\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     12\u001B[0m \u001B[43m)\u001B[49m\n\u001B[0;32m     14\u001B[0m job_id \u001B[38;5;241m=\u001B[39m fine_tuning_job[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mid\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[0;32m     15\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFine-tuning job created with ID: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mjob_id\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\llm4commit\\lib\\site-packages\\openai\\lib\\_old_api.py:39\u001B[0m, in \u001B[0;36mAPIRemovedInV1Proxy.__call__\u001B[1;34m(self, *_args, **_kwargs)\u001B[0m\n\u001B[0;32m     38\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39m_args: Any, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m_kwargs: Any) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Any:\n\u001B[1;32m---> 39\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m APIRemovedInV1(symbol\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_symbol)\n",
      "\u001B[1;31mAPIRemovedInV1\u001B[0m: \n\nYou tried to access openai.FineTune, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n\nYou can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n\nAlternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n\nA detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import time\n",
    "\n",
    "while True:\n",
    "    fine_tuning_status = openai.FineTune.get_status(job_id)\n",
    "    status = fine_tuning_status[\"status\"]\n",
    "    print(f\"Fine-tuning job status: {status}\")\n",
    "\n",
    "    if status in [\"completed\", \"failed\"]:\n",
    "        break\n",
    "\n",
    "    time.sleep(60)"
   ],
   "id": "16205e9acba87999"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "fine_tuned_model_id = fine_tuning_status[\"fine_tuned_model_id\"]\n",
    "\n",
    "# Use the fine-tuned model for text generation\n",
    "def generate_text(prompt, model_id, max_tokens=1024):\n",
    "    response = openai.Completion.create(\n",
    "        engine=model_id,\n",
    "        prompt=prompt,\n",
    "        max_tokens=max_tokens,\n",
    "        n=1,\n",
    "        stop=None,\n",
    "        temperature=0.5,\n",
    "    )\n",
    "    return response.choices[0].text.strip()"
   ],
   "id": "250b64c1443807f4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "test_file = \"../data/final_preprocessed_data/discriminator/finetune_test_data.jsonl\"\n",
    "test_data = []\n",
    "with open(test_file, 'r', encoding='UTF-8') as file:\n",
    "    for line in file:\n",
    "        test_data.append(json.loads(line.strip()))\n",
    "\n",
    "for test_item in test_data:\n",
    "    test_item['chatgpt_finetune'] = generate_text(test_item['prompt'], fine_tuned_model_id)\n",
    "\n",
    "output_file_path = '../data/final_preprocessed_data/discriminator/finetune_test_data_chatgpt.jsonl'\n",
    "# Open the output JSONL file for writing\n",
    "with open(output_file_path, 'w') as output_file:\n",
    "    for item in test_data:\n",
    "        output_file.write(json.dumps(item) + '\\n')"
   ],
   "id": "9e22df02c010194a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-06T09:48:57.074321Z",
     "start_time": "2024-06-06T09:48:57.043327Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "da244e8d19d53763",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "703a2b37dbd23a72"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
