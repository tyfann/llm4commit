{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-28T17:19:13.719892Z",
     "start_time": "2024-05-28T17:19:12.801012Z"
    }
   },
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    # defaults to os.environ.get(\"OPENAI_API_KEY\")\n",
    "    api_key=\"sk-0rLvuRkMiD4Mw25QYygh6rUlZVjpQWNGNF4yez7z3PZ7yCOm\",\n",
    "    # api_key=\"sk-tMbkq3K1iO5vf0FRMlrmzslGXJZwE0us3mve4QXuvpnZcumG\",\n",
    "    base_url=\"https://api.chatanywhere.tech/v1\"\n",
    "    # base_url=\"https://api.chatanywhere.cn/v1\"\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "source": [
    "def gpt_35_api(messages: list):\n",
    "\n",
    "    completion = client.chat.completions.create(model=\"gpt-3.5-turbo-ca\", messages=messages, temperature=0.5)\n",
    "    return completion.choices[0].message.content"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-28T17:19:13.734915Z",
     "start_time": "2024-05-28T17:19:13.722405Z"
    }
   },
   "id": "ec804f733bdb1890",
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "source": [
    "import json\n",
    "from tqdm import tqdm"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-28T17:19:13.766148Z",
     "start_time": "2024-05-28T17:19:13.737428Z"
    }
   },
   "id": "1929b998d5ce80de",
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "source": [
    "from langchain import hub\n",
    "\n",
    "prompt = hub.pull(\"tyfann/llm4commit-rag\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-28T17:19:15.459209Z",
     "start_time": "2024-05-28T17:19:13.768110Z"
    }
   },
   "id": "fdb997cde6ec8ef0",
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "source": [
    "with open('../data/final_preprocessed_data/python_baseline/python_baseline_rag_prompt.json', 'r', encoding='UTF-8') as f:\n",
    "    org_data = json.load(f)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-26T09:37:11.318798Z",
     "start_time": "2024-05-26T09:37:11.295456Z"
    }
   },
   "id": "787db25ca0cfda54",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T18:54:03.714790Z",
     "start_time": "2024-05-24T18:54:03.691751Z"
    }
   },
   "cell_type": "code",
   "source": [
    "output_file = '../data/final_preprocessed_data/python_baseline/python_baseline_rag.json'\n",
    "with open(output_file, 'w', encoding='UTF-8') as f:\n",
    "    json.dump(org_data, f, ensure_ascii=False, indent=4)"
   ],
   "id": "324a099208390050",
   "outputs": [],
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "source": [
    "gpt_msg = []\n",
    "for index, data in tqdm(enumerate(org_data), total=len(org_data), desc=\"Processing documents\"):\n",
    "    messages = prompt.invoke(\n",
    "        {\"context\": data['sim_diff'], \"msg\": data['sim_msg'], \"diff\": data['org_diff']}\n",
    "    ).to_messages()\n",
    "    example_prompt = [{'role': 'user','content': messages[0].content},]\n",
    "    try:\n",
    "        gpt_msg.append(gpt_35_api(example_prompt))\n",
    "    except:\n",
    "        print(index)\n",
    "        gpt_msg.append(\"\")\n",
    "\n",
    "with open('../data/final_preprocessed_data/python_baseline_test_data.json', 'r', encoding='UTF-8') as f:\n",
    "    chronicle_data = json.load(f)[:1000]\n",
    "\n",
    "for item, msg in zip(chronicle_data, gpt_msg):\n",
    "    item['chatgpt_rag'] = msg\n",
    "\n",
    "output_file = '../data/final_preprocessed_data/python_baseline/python_baseline_rag.json'\n",
    "with open(output_file, 'w', encoding='UTF-8') as f:\n",
    "    json.dump(chronicle_data, f, ensure_ascii=False, indent=4)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-24T12:53:25.842916Z",
     "start_time": "2024-05-24T11:52:29.047829Z"
    }
   },
   "id": "6104b8546eaddbf1",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing documents: 100%|██████████| 1000/1000 [1:00:56<00:00,  3.66s/it]\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T21:41:24.520069Z",
     "start_time": "2024-05-27T21:37:21.406399Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# TODO\n",
    "lang = 'js'\n",
    "with open(f'../data/final_preprocessed_data/{lang}_baseline/{lang}_baseline_weaviate_rag_300_prompt.json', 'r', encoding='UTF-8') as f:\n",
    "    org_data = json.load(f)\n",
    "\n",
    "org_data = org_data[:100]\n",
    "gpt_msg = []\n",
    "for index, data in tqdm(enumerate(org_data), total=len(org_data), desc=\"Processing documents\"):\n",
    "    messages = prompt.invoke(\n",
    "        {\"context\": data['sim_diff'], \"msg\": data['sim_msg'], \"diff\": data['org_diff']}\n",
    "    ).to_messages()\n",
    "    example_prompt = [{'role': 'user','content': messages[0].content},]\n",
    "    try:\n",
    "        msg = gpt_35_api(example_prompt)\n",
    "        while msg is None:\n",
    "            msg = gpt_35_api(example_prompt)\n",
    "        gpt_msg.append(msg)\n",
    "    except:\n",
    "        print(index)\n",
    "        gpt_msg.append(\"\")\n",
    "\n",
    "with open(f'../data/final_preprocessed_data/{lang}_baseline_test_data_300.json', 'r', encoding='UTF-8') as f:\n",
    "    chronicle_data = json.load(f)[:100]\n",
    "\n",
    "for item, msg in zip(chronicle_data, gpt_msg): \n",
    "    item['chatgpt_rag'] = msg\n",
    "\n",
    "output_file = f'../data/final_preprocessed_data/{lang}_baseline/{lang}_baseline_weaviate_rag_300_dev.json'\n",
    "with open(output_file, 'w', encoding='UTF-8') as f:\n",
    "    json.dump(chronicle_data, f, ensure_ascii=False, indent=4)"
   ],
   "id": "feafc4cb7dec62fc",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing documents: 100%|██████████| 100/100 [04:03<00:00,  2.43s/it]\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T18:11:17.249199Z",
     "start_time": "2024-05-28T17:21:25.679041Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# TODO\n",
    "prompt = hub.pull(\"tyfann/llm4commit-rag:b843ef0b\")\n",
    "lang = 'js'\n",
    "with open(f'../data/final_preprocessed_data/{lang}_baseline/{lang}_baseline_test_data_300_golden.json', 'r', encoding='UTF-8') as f:\n",
    "    org_data = json.load(f)\n",
    "\n",
    "# org_data = org_data[:100]\n",
    "gpt_msg = []\n",
    "for index, data in tqdm(enumerate(org_data), total=len(org_data), desc=\"Processing documents\"):\n",
    "    messages = prompt.invoke(\n",
    "        {\"context\": data['sim_diff'], \"msg\": data['sim_msg'], \"diff\": data['diff']}\n",
    "    ).to_messages()\n",
    "    example_prompt = [{'role': 'user','content': messages[0].content},]\n",
    "    try:\n",
    "        msg = gpt_35_api(example_prompt)\n",
    "        while msg is None:\n",
    "            msg = gpt_35_api(example_prompt)\n",
    "        gpt_msg.append(msg)\n",
    "    except:\n",
    "        print(index)\n",
    "        gpt_msg.append(\"\")\n",
    "\n",
    "with open(f'../data/final_preprocessed_data/{lang}_baseline_test_data_300.json', 'r', encoding='UTF-8') as f:\n",
    "    chronicle_data = json.load(f)\n",
    "\n",
    "for item, msg in zip(chronicle_data, gpt_msg): \n",
    "    item['chatgpt_rag'] = msg\n",
    "\n",
    "output_file = f'../data/final_preprocessed_data/{lang}_baseline/{lang}_baseline_rag_golden_300.json'\n",
    "with open(output_file, 'w', encoding='UTF-8') as f:\n",
    "    json.dump(chronicle_data, f, ensure_ascii=False, indent=4)"
   ],
   "id": "329fafc03726473b",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing documents: 100%|██████████| 1000/1000 [49:51<00:00,  2.99s/it] \n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T18:14:52.649414Z",
     "start_time": "2024-05-28T18:14:52.638559Z"
    }
   },
   "cell_type": "code",
   "source": "len(gpt_msg)",
   "id": "4b4ccebe22e984fc",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T13:19:06.250371Z",
     "start_time": "2024-05-27T13:13:41.895008Z"
    }
   },
   "cell_type": "code",
   "source": [
    "lang = 'js'\n",
    "with open(f'../data/final_preprocessed_data/{lang}_baseline/{lang}_baseline_rag_300_prompt.json', 'r', encoding='UTF-8') as f:\n",
    "    org_data = json.load(f)\n",
    "\n",
    "for data in org_data:\n",
    "    data['sim_diff'] = data['org_diff']\n",
    "    data['sim_msg'] = data['org_msg']\n",
    "\n",
    "org_data = org_data[:100]\n",
    "gpt_msg = []\n",
    "for index, data in tqdm(enumerate(org_data), total=len(org_data), desc=\"Processing documents\"):\n",
    "    messages = prompt.invoke(\n",
    "        {\"context\": data['sim_diff'], \"msg\": data['sim_msg'], \"diff\": data['org_diff']}\n",
    "    ).to_messages()\n",
    "    example_prompt = [{'role': 'user','content': messages[0].content},]\n",
    "    try:\n",
    "        msg = gpt_35_api(example_prompt)\n",
    "        while msg is None:\n",
    "            msg = gpt_35_api(example_prompt)\n",
    "        gpt_msg.append(msg)\n",
    "    except:\n",
    "        print(index)\n",
    "        gpt_msg.append(\"\")\n",
    "\n",
    "with open(f'../data/final_preprocessed_data/{lang}_baseline_test_data_300.json', 'r', encoding='UTF-8') as f:\n",
    "    chronicle_data = json.load(f)[:100]\n",
    "\n",
    "for item, msg in zip(chronicle_data, gpt_msg): \n",
    "    item['chatgpt_rag'] = msg\n",
    "\n",
    "output_file = f'../data/final_preprocessed_data/{lang}_baseline/{lang}_baseline_rag_300_dump_2.json'\n",
    "with open(output_file, 'w', encoding='UTF-8') as f:\n",
    "    json.dump(chronicle_data, f, ensure_ascii=False, indent=4)"
   ],
   "id": "31a07b5da0d230bb",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing documents: 100%|██████████| 100/100 [05:24<00:00,  3.24s/it]\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T13:30:38.109523Z",
     "start_time": "2024-05-27T13:30:38.095997Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# output_file = f'../data/final_preprocessed_data/{lang}_baseline/{lang}_baseline_zeroshot_300.json'\n",
    "# with open(output_file, 'r', encoding='UTF-8') as f:\n",
    "#     org_data = json.load(f)\n",
    "# \n",
    "# org_data = org_data[:100]\n",
    "# with open(f'../data/final_preprocessed_data/{lang}_baseline/{lang}_baseline_zeroshot_300_dump.json', 'w', encoding='UTF-8') as f:\n",
    "#     json.dump(org_data, f, ensure_ascii=False, indent=4)\n",
    "# \n",
    "# \n",
    "# output_file = f'../data/final_preprocessed_data/{lang}_baseline/{lang}_baseline_race_300.json'\n",
    "# with open(output_file, 'r', encoding='UTF-8') as f:\n",
    "#     org_data = json.load(f)\n",
    "# \n",
    "# org_data = org_data[:100]\n",
    "# with open(f'../data/final_preprocessed_data/{lang}_baseline/{lang}_baseline_race_300_dump.json', 'w', encoding='UTF-8') as f:\n",
    "#     json.dump(org_data, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "output_file = f'../data/final_preprocessed_data/{lang}_baseline/{lang}_baseline_rag_300.json'\n",
    "with open(output_file, 'r', encoding='UTF-8') as f:\n",
    "    org_data = json.load(f)\n",
    "\n",
    "org_data = org_data[:100]\n",
    "with open(f'../data/final_preprocessed_data/{lang}_baseline/{lang}_baseline_rag_300_v3.json', 'w', encoding='UTF-8') as f:\n",
    "    json.dump(org_data, f, ensure_ascii=False, indent=4)"
   ],
   "id": "17eda75e27b98239",
   "outputs": [],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T12:33:06.090985Z",
     "start_time": "2024-05-27T12:33:02.179330Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data = org_data[631]\n",
    "messages = prompt.invoke(\n",
    "    {\"context\": data['sim_diff'], \"msg\": data['sim_msg'], \"diff\": data['org_diff']}\n",
    ").to_messages()\n",
    "example_prompt = [{'role': 'user','content': messages[0].content},]\n",
    "print(gpt_35_api(example_prompt))"
   ],
   "id": "ccbb91b8ef17f468",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Destroy tooltip if disabled to prevent unnecessary rendering.\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T12:31:58.754186Z",
     "start_time": "2024-05-27T12:31:58.740087Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for index, data in enumerate(org_data):\n",
    "    if data['org_msg']==\"Tooltip: invoke 'doDestory' manually when disabled\":\n",
    "        print(index)"
   ],
   "id": "969a38cc6a3c8ddd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "631\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T12:34:30.817270Z",
     "start_time": "2024-05-27T12:34:30.802058Z"
    }
   },
   "cell_type": "code",
   "source": [
    "output_file = f'../data/final_preprocessed_data/{lang}_baseline/{lang}_baseline_rag_300.json'\n",
    "with open(output_file, 'w', encoding='UTF-8') as f:\n",
    "    json.dump(chronicle_data, f, ensure_ascii=False, indent=4)"
   ],
   "id": "7f8329270a4d0204",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T20:42:28.590215Z",
     "start_time": "2024-05-26T19:56:59.489553Z"
    }
   },
   "cell_type": "code",
   "source": [
    "lang = 'js'\n",
    "with open(f'../data/final_preprocessed_data/{lang}_baseline/{lang}_baseline_nochunk_rag_prompt.json', 'r', encoding='UTF-8') as f:\n",
    "    org_data = json.load(f)\n",
    "\n",
    "gpt_msg = []\n",
    "for index, data in tqdm(enumerate(org_data), total=len(org_data), desc=\"Processing documents\"):\n",
    "    messages = prompt.invoke(\n",
    "        {\"context\": data['sim_diff'], \"msg\": data['sim_msg'], \"diff\": data['org_diff']}\n",
    "    ).to_messages()\n",
    "    example_prompt = [{'role': 'user','content': messages[0].content},]\n",
    "    try:\n",
    "        gpt_msg.append(gpt_35_api(example_prompt))\n",
    "    except:\n",
    "        print(index)\n",
    "        gpt_msg.append(\"\")\n",
    "\n",
    "with open(f'../data/final_preprocessed_data/{lang}_baseline_test_data.json', 'r', encoding='UTF-8') as f:\n",
    "    chronicle_data = json.load(f)[:1000]\n",
    "\n",
    "for item, msg in zip(chronicle_data, gpt_msg):\n",
    "    item['chatgpt_rag'] = msg\n",
    "\n",
    "output_file = f'../data/final_preprocessed_data/{lang}_baseline/{lang}_baseline_nochunk_rag.json'\n",
    "with open(output_file, 'w', encoding='UTF-8') as f:\n",
    "    json.dump(chronicle_data, f, ensure_ascii=False, indent=4)"
   ],
   "id": "b3c41e118fe53773",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing documents: 100%|██████████| 1000/1000 [45:29<00:00,  2.73s/it]\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 4SIM",
   "id": "8cf448a8440113e2"
  },
  {
   "cell_type": "code",
   "source": [
    "prompt = hub.pull(\"tyfann/llm4commit-rag-4sim\")\n",
    "for lang in ['js']:\n",
    "    with open(f'../data/final_preprocessed_data/{lang}_baseline/{lang}_baseline_rag_top4_prompt.json', 'r', encoding='UTF-8') as f:\n",
    "        org_data = json.load(f)\n",
    "    \n",
    "    gpt_msg = []\n",
    "    for index, data in tqdm(enumerate(org_data), total=len(org_data), desc=\"Processing documents\"):\n",
    "        try:\n",
    "            messages = prompt.invoke(\n",
    "                {\"diff1\": data['sim_diff_0'],  \"msg1\": data['sim_msg_0'],\n",
    "                 \"diff2\": data['sim_diff_1'],  \"msg2\": data['sim_msg_1'],\n",
    "                 \"diff3\": data['sim_diff_2'],  \"msg3\": data['sim_msg_2'],\n",
    "                 \"diff4\": data['sim_diff_3'],  \"msg4\": data['sim_msg_3'],\n",
    "                 \"question\": data['org_diff']}\n",
    "            ).to_messages()\n",
    "            example_prompt = [{'role': 'user','content': messages[0].content},]\n",
    "            gpt_msg.append(gpt_35_api(example_prompt))\n",
    "        except:\n",
    "            print(index)\n",
    "            gpt_msg.append('')\n",
    "    \n",
    "    with open(f'../data/final_preprocessed_data/{lang}_baseline_test_data.json', 'r', encoding='UTF-8') as f:\n",
    "        chronicle_data = json.load(f)[:1000]\n",
    "    \n",
    "    for item, msg in zip(chronicle_data, gpt_msg):\n",
    "        item['chatgpt_rag'] = msg\n",
    "    \n",
    "    output_file = f'../data/final_preprocessed_data/{lang}_baseline/{lang}_baseline_rag_top4.json'\n",
    "    with open(output_file, 'w', encoding='UTF-8') as f:\n",
    "        json.dump(chronicle_data, f, ensure_ascii=False, indent=4)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-25T13:11:56.938143Z",
     "start_time": "2024-05-25T12:15:01.032137Z"
    }
   },
   "id": "fbcdda2ea61990d7",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing documents: 100%|██████████| 1000/1000 [56:55<00:00,  3.42s/it] \n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# SIM_MSG",
   "id": "487f1501f00b386b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T14:09:45.087533Z",
     "start_time": "2024-05-25T13:11:56.940269Z"
    }
   },
   "cell_type": "code",
   "source": [
    "prompt = hub.pull(\"tyfann/llm4commit-rag-msg\")\n",
    "for lang in [ 'js']:\n",
    "    with open(f'../data/final_preprocessed_data/{lang}_baseline/{lang}_baseline_rag_sim_msg_prompt.json', 'r', encoding='UTF-8') as f:\n",
    "        org_data = json.load(f)\n",
    "    \n",
    "    gpt_msg = []\n",
    "    for index, data in tqdm(enumerate(org_data), total=len(org_data), desc=\"Processing documents\"):\n",
    "        try:\n",
    "            messages = prompt.invoke(\n",
    "                {\"diff1\": data['sim_diff'],  \"msg1\": data['sim_msg'],\n",
    "                 \"question\": data['org_diff'], 'draft': data['org_msg']}\n",
    "            ).to_messages()\n",
    "            example_prompt = [{'role': 'user','content': messages[0].content},]\n",
    "            gpt_msg.append(gpt_35_api(example_prompt))\n",
    "        except:\n",
    "            print(index)\n",
    "            gpt_msg.append('')\n",
    "    \n",
    "    \n",
    "    with open(f'../data/final_preprocessed_data/{lang}_baseline_test_data.json', 'r', encoding='UTF-8') as f:\n",
    "        chronicle_data = json.load(f)[:1000]\n",
    "    \n",
    "    for item, msg in zip(chronicle_data, gpt_msg):\n",
    "        item['chatgpt_rag'] = msg\n",
    "    \n",
    "    output_file = f'../data/final_preprocessed_data/{lang}_baseline/{lang}_baseline_rag_sim_msg.json'\n",
    "    with open(output_file, 'w', encoding='UTF-8') as f:\n",
    "        json.dump(chronicle_data, f, ensure_ascii=False, indent=4)"
   ],
   "id": "3b7bf58e30e95b09",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing documents: 100%|██████████| 1000/1000 [57:47<00:00,  3.47s/it] \n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "ef76484886f1376"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
