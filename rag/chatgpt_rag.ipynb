{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-15T13:13:24.465243Z",
     "start_time": "2024-06-15T13:13:23.369709Z"
    }
   },
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    # defaults to os.environ.get(\"OPENAI_API_KEY\")\n",
    "    api_key=\"sk-0rLvuRkMiD4Mw25QYygh6rUlZVjpQWNGNF4yez7z3PZ7yCOm\",\n",
    "    # api_key=\"sk-tMbkq3K1iO5vf0FRMlrmzslGXJZwE0us3mve4QXuvpnZcumG\",\n",
    "    base_url=\"https://api.chatanywhere.cn/v1\"\n",
    "    # base_url=\"https://api.chatanywhere.cn/v1\"\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "source": [
    "def gpt_35_api(messages: list):\n",
    "\n",
    "    completion = client.chat.completions.create(model=\"gpt-3.5-turbo-0125\", messages=messages, temperature=0)\n",
    "    return completion.choices[0].message.content"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-15T13:13:24.481273Z",
     "start_time": "2024-06-15T13:13:24.468241Z"
    }
   },
   "id": "ec804f733bdb1890",
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "source": [
    "import json\n",
    "from tqdm import tqdm"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-15T13:13:24.512339Z",
     "start_time": "2024-06-15T13:13:24.484281Z"
    }
   },
   "id": "1929b998d5ce80de",
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "source": [
    "# from langchain import hub\n",
    "# \n",
    "# prompt = hub.pull(\"tyfann/llm4commit-rag:b843ef0b\")\n",
    "\n",
    "from langchain import hub\n",
    "prompt = hub.pull(\"tyfann/llm4commit-rag:b843ef0b\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-15T13:13:30.131505Z",
     "start_time": "2024-06-15T13:13:28.543533Z"
    }
   },
   "id": "fdb997cde6ec8ef0",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-15T13:23:00.574496Z",
     "start_time": "2024-06-15T13:15:22.433785Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# for model in ['mxbai', 'miniLM']:\n",
    "for model in ['e5']:\n",
    "    with open(f'../data/angular_filtered/subsets/generation/rag_prompt/dev_test_rag_{model}_prompt.json', 'r', encoding='UTF-8') as f:\n",
    "        org_data = json.load(f)\n",
    "    gpt_msg = []\n",
    "    for index, data in tqdm(enumerate(org_data), total=len(org_data), desc=\"Processing documents\"):\n",
    "        # merged_diff = '\\n'.join(diff['diff'] for diff in data['diff'])\n",
    "        messages = prompt.invoke(\n",
    "            {\"context\": data['sim_diff'], \"msg\": data['sim_msg'], \"diff\": data['diff']}\n",
    "        ).to_messages()\n",
    "        example_prompt = [{'role': 'user','content': messages[0].content},]\n",
    "        try:\n",
    "            gpt_msg.append(gpt_35_api(example_prompt))\n",
    "        except:\n",
    "            print(index)\n",
    "            gpt_msg.append(\"\")\n",
    "    \n",
    "    for item, msg in zip(org_data, gpt_msg):\n",
    "        item['chatgpt_rag'] = msg\n",
    "    \n",
    "    output_file = f'../data/angular_filtered/subsets/generation/dev_test_gpt35_rag_{model}.json'\n",
    "    with open(output_file, 'w', encoding='UTF-8') as f:\n",
    "        json.dump(org_data, f, ensure_ascii=False, indent=4)\n",
    "        \n",
    "    output_file = f'../data/angular_filtered/subsets/generation/dev_test_gpt35_rag_{model}.txt'\n",
    "    with open(output_file, 'w', encoding='UTF-8') as f:\n",
    "        for item in org_data:\n",
    "            f.write(item['chatgpt_rag'].replace('\\n', '\\\\n').replace('\\r', '\\\\r') + '\\n')"
   ],
   "id": "df5474355f8505dd",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing documents: 100%|██████████| 603/603 [07:38<00:00,  1.32it/s]\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T13:40:30.995226Z",
     "start_time": "2024-06-11T13:40:30.980784Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "d77cae463d707ec1",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T09:17:32.417890Z",
     "start_time": "2024-06-10T09:17:32.404507Z"
    }
   },
   "cell_type": "code",
   "source": [
    "output_file = '../data/angular_filtered/test_result/test_data_js_gpt35_hybrid_golden.txt'\n",
    "with open(output_file, 'w', encoding='UTF-8') as f:\n",
    "    for item in org_data:\n",
    "        f.write(item['chatgpt_hybrid'] + '\\n')"
   ],
   "id": "4a793b9f03163ac5",
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "source": [
    "gpt_msg = []\n",
    "for index, data in tqdm(enumerate(org_data), total=len(org_data), desc=\"Processing documents\"):\n",
    "    messages = prompt.invoke(\n",
    "        {\"context\": data['sim_diff'], \"msg\": data['sim_msg'], \"diff\": data['diff']}\n",
    "    ).to_messages()\n",
    "    example_prompt = [{'role': 'user','content': messages[0].content},]\n",
    "    try:\n",
    "        gpt_msg.append(gpt_35_api(example_prompt))\n",
    "    except:\n",
    "        print(index)\n",
    "        gpt_msg.append(\"\")\n",
    "\n",
    "for item, msg in zip(org_data, gpt_msg):\n",
    "    item['chatgpt_rag'] = msg\n",
    "\n",
    "output_file = '../data/angular_filtered/test_result/test_data_js_gpt35_rag_golden.json'\n",
    "with open(output_file, 'w', encoding='UTF-8') as f:\n",
    "    json.dump(org_data, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "output_file = '../data/angular_filtered/test_result/test_data_js_gpt35_rag_golden.txt'\n",
    "with open(output_file, 'w', encoding='UTF-8') as f:\n",
    "    for item in org_data:\n",
    "        f.write(item['chatgpt_rag'] + '\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-10T08:54:21.684512Z",
     "start_time": "2024-06-10T08:47:49.286180Z"
    }
   },
   "id": "6104b8546eaddbf1",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing documents: 100%|██████████| 505/505 [06:32<00:00,  1.29it/s]\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T21:22:57.101558Z",
     "start_time": "2024-06-09T21:22:57.086558Z"
    }
   },
   "cell_type": "code",
   "source": [
    "output_file = '../data/angular_filtered/test_result/test_data_js_gpt35_rag_mxbai.txt'\n",
    "with open(output_file, 'w', encoding='UTF-8') as f:\n",
    "    for item in org_data:\n",
    "        f.write(item['chatgpt_rag'] + '\\n')"
   ],
   "id": "fbb2c58fa6e2bd77",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T21:23:20.004980Z",
     "start_time": "2024-06-09T21:23:19.993585Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with open('../data/angular_filtered/test_result/test_data_js_gpt35_rag_miniLM.json', 'r', encoding='UTF-8') as f:\n",
    "    org_data = json.load(f)\n",
    "# save msg to txt\n",
    "output_file = '../data/angular_filtered/test_result/test_data_js_gpt35_rag_miniLM.txt'\n",
    "with open(output_file, 'w', encoding='UTF-8') as f:\n",
    "    for item in org_data:\n",
    "        f.write(item['chatgpt_rag'] + '\\n')"
   ],
   "id": "b42886e2dcbbba49",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T21:41:24.520069Z",
     "start_time": "2024-05-27T21:37:21.406399Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# TODO\n",
    "lang = 'js'\n",
    "with open(f'../data/final_preprocessed_data/{lang}_baseline/{lang}_baseline_weaviate_rag_300_prompt.json', 'r', encoding='UTF-8') as f:\n",
    "    org_data = json.load(f)\n",
    "\n",
    "org_data = org_data[:100]\n",
    "gpt_msg = []\n",
    "for index, data in tqdm(enumerate(org_data), total=len(org_data), desc=\"Processing documents\"):\n",
    "    messages = prompt.invoke(\n",
    "        {\"context\": data['sim_diff'], \"msg\": data['sim_msg'], \"diff\": data['org_diff']}\n",
    "    ).to_messages()\n",
    "    example_prompt = [{'role': 'user','content': messages[0].content},]\n",
    "    try:\n",
    "        msg = gpt_35_api(example_prompt)\n",
    "        while msg is None:\n",
    "            msg = gpt_35_api(example_prompt)\n",
    "        gpt_msg.append(msg)\n",
    "    except:\n",
    "        print(index)\n",
    "        gpt_msg.append(\"\")\n",
    "\n",
    "with open(f'../data/final_preprocessed_data/{lang}_baseline_test_data_300.json', 'r', encoding='UTF-8') as f:\n",
    "    chronicle_data = json.load(f)[:100]\n",
    "\n",
    "for item, msg in zip(chronicle_data, gpt_msg): \n",
    "    item['chatgpt_rag'] = msg\n",
    "\n",
    "output_file = f'../data/final_preprocessed_data/{lang}_baseline/{lang}_baseline_weaviate_rag_300_dev.json'\n",
    "with open(output_file, 'w', encoding='UTF-8') as f:\n",
    "    json.dump(chronicle_data, f, ensure_ascii=False, indent=4)"
   ],
   "id": "feafc4cb7dec62fc",
   "execution_count": 5,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-03T15:49:31.774065Z",
     "start_time": "2024-06-03T15:40:45.716369Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# TODO\n",
    "prompt = hub.pull(\"tyfann/llm4commit-rag:b843ef0b\")\n",
    "lang = 'js'\n",
    "with open(f'../data/final_preprocessed_data/{lang}_baseline/{lang}_baseline_test_data_300_e5.json', 'r', encoding='UTF-8') as f:\n",
    "    org_data = json.load(f)[:100]\n",
    "\n",
    "# org_data = org_data[:100]\n",
    "gpt_msg = []\n",
    "for index, data in tqdm(enumerate(org_data), total=len(org_data), desc=\"Processing documents\"):\n",
    "    messages = prompt.invoke(\n",
    "        {\"context\": data['sim_diff'], \"msg\": data['sim_msg'], \"diff\": data['org_diff']}\n",
    "    ).to_messages()\n",
    "    example_prompt = [{'role': 'user','content': messages[0].content},]\n",
    "    try:\n",
    "        msg = gpt_35_api(example_prompt)\n",
    "        while msg is None:\n",
    "            msg = gpt_35_api(example_prompt)\n",
    "        gpt_msg.append(msg)\n",
    "    except:\n",
    "        print(index)\n",
    "        gpt_msg.append(\"\")\n",
    "\n",
    "with open(f'../data/final_preprocessed_data/{lang}_baseline_test_data_300.json', 'r', encoding='UTF-8') as f:\n",
    "    chronicle_data = json.load(f)[:100]\n",
    "\n",
    "for item, msg in zip(chronicle_data, gpt_msg): \n",
    "    item['chatgpt_rag'] = msg\n",
    "\n",
    "output_file = f'../data/final_preprocessed_data/{lang}_baseline/{lang}_baseline_test_data_300_e5_chatgpt.json'\n",
    "with open(output_file, 'w', encoding='UTF-8') as f:\n",
    "    json.dump(chronicle_data, f, ensure_ascii=False, indent=4)"
   ],
   "id": "329fafc03726473b",
   "execution_count": 5,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-03T14:15:56.826985Z",
     "start_time": "2024-06-03T13:58:15.499179Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# TODO\n",
    "prompt = hub.pull(\"tyfann/llm4commit-rag:b843ef0b\")\n",
    "lang = 'js'\n",
    "with open(f'../data/final_preprocessed_data/{lang}_baseline/{lang}_baseline_test_data_300_e5_finetune_10w.json', 'r', encoding='UTF-8') as f:\n",
    "    org_data = json.load(f)[:100]\n",
    "\n",
    "# org_data = org_data[:100]\n",
    "gpt_msg = []\n",
    "for index, data in tqdm(enumerate(org_data), total=len(org_data), desc=\"Processing documents\"):\n",
    "    messages = prompt.invoke(\n",
    "        {\"context\": data['sim_diff'], \"msg\": data['sim_msg'], \"diff\": data['org_diff']}\n",
    "    ).to_messages()\n",
    "    example_prompt = [{'role': 'user','content': messages[0].content},]\n",
    "    try:\n",
    "        msg = gpt_35_api(example_prompt)\n",
    "        while msg is None:\n",
    "            msg = gpt_35_api(example_prompt)\n",
    "        gpt_msg.append(msg)\n",
    "    except:\n",
    "        print(index)\n",
    "        gpt_msg.append(\"\")\n",
    "\n",
    "with open(f'../data/final_preprocessed_data/{lang}_baseline_test_data_300.json', 'r', encoding='UTF-8') as f:\n",
    "    chronicle_data = json.load(f)[:100]\n",
    "\n",
    "for item, msg in zip(chronicle_data, gpt_msg): \n",
    "    item['chatgpt_rag'] = msg\n",
    "\n",
    "output_file = f'../data/final_preprocessed_data/{lang}_baseline/{lang}_baseline_test_data_300_e5_finetune_10w_chatgpt.json'\n",
    "with open(output_file, 'w', encoding='UTF-8') as f:\n",
    "    json.dump(chronicle_data, f, ensure_ascii=False, indent=4)"
   ],
   "id": "db1f06d465b8f268",
   "execution_count": 8,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T18:14:52.649414Z",
     "start_time": "2024-05-28T18:14:52.638559Z"
    }
   },
   "cell_type": "code",
   "source": "len(gpt_msg)",
   "id": "4b4ccebe22e984fc",
   "execution_count": 8,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T13:19:06.250371Z",
     "start_time": "2024-05-27T13:13:41.895008Z"
    }
   },
   "cell_type": "code",
   "source": [
    "lang = 'js'\n",
    "with open(f'../data/final_preprocessed_data/{lang}_baseline/{lang}_baseline_rag_300_prompt.json', 'r', encoding='UTF-8') as f:\n",
    "    org_data = json.load(f)\n",
    "\n",
    "for data in org_data:\n",
    "    data['sim_diff'] = data['org_diff']\n",
    "    data['sim_msg'] = data['org_msg']\n",
    "\n",
    "org_data = org_data[:100]\n",
    "gpt_msg = []\n",
    "for index, data in tqdm(enumerate(org_data), total=len(org_data), desc=\"Processing documents\"):\n",
    "    messages = prompt.invoke(\n",
    "        {\"context\": data['sim_diff'], \"msg\": data['sim_msg'], \"diff\": data['org_diff']}\n",
    "    ).to_messages()\n",
    "    example_prompt = [{'role': 'user','content': messages[0].content},]\n",
    "    try:\n",
    "        msg = gpt_35_api(example_prompt)\n",
    "        while msg is None:\n",
    "            msg = gpt_35_api(example_prompt)\n",
    "        gpt_msg.append(msg)\n",
    "    except:\n",
    "        print(index)\n",
    "        gpt_msg.append(\"\")\n",
    "\n",
    "with open(f'../data/final_preprocessed_data/{lang}_baseline_test_data_300.json', 'r', encoding='UTF-8') as f:\n",
    "    chronicle_data = json.load(f)[:100]\n",
    "\n",
    "for item, msg in zip(chronicle_data, gpt_msg): \n",
    "    item['chatgpt_rag'] = msg\n",
    "\n",
    "output_file = f'../data/final_preprocessed_data/{lang}_baseline/{lang}_baseline_rag_300_dump_2.json'\n",
    "with open(output_file, 'w', encoding='UTF-8') as f:\n",
    "    json.dump(chronicle_data, f, ensure_ascii=False, indent=4)"
   ],
   "id": "31a07b5da0d230bb",
   "execution_count": 35,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T13:30:38.109523Z",
     "start_time": "2024-05-27T13:30:38.095997Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# output_file = f'../data/final_preprocessed_data/{lang}_baseline/{lang}_baseline_zeroshot_300.json'\n",
    "# with open(output_file, 'r', encoding='UTF-8') as f:\n",
    "#     org_data = json.load(f)\n",
    "# \n",
    "# org_data = org_data[:100]\n",
    "# with open(f'../data/final_preprocessed_data/{lang}_baseline/{lang}_baseline_zeroshot_300_dump.json', 'w', encoding='UTF-8') as f:\n",
    "#     json.dump(org_data, f, ensure_ascii=False, indent=4)\n",
    "# \n",
    "# \n",
    "# output_file = f'../data/final_preprocessed_data/{lang}_baseline/{lang}_baseline_race_300.json'\n",
    "# with open(output_file, 'r', encoding='UTF-8') as f:\n",
    "#     org_data = json.load(f)\n",
    "# \n",
    "# org_data = org_data[:100]\n",
    "# with open(f'../data/final_preprocessed_data/{lang}_baseline/{lang}_baseline_race_300_dump.json', 'w', encoding='UTF-8') as f:\n",
    "#     json.dump(org_data, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "output_file = f'../data/final_preprocessed_data/{lang}_baseline/{lang}_baseline_rag_300.json'\n",
    "with open(output_file, 'r', encoding='UTF-8') as f:\n",
    "    org_data = json.load(f)\n",
    "\n",
    "org_data = org_data[:100]\n",
    "with open(f'../data/final_preprocessed_data/{lang}_baseline/{lang}_baseline_rag_300_v3.json', 'w', encoding='UTF-8') as f:\n",
    "    json.dump(org_data, f, ensure_ascii=False, indent=4)"
   ],
   "id": "17eda75e27b98239",
   "execution_count": 37,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T12:33:06.090985Z",
     "start_time": "2024-05-27T12:33:02.179330Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data = org_data[631]\n",
    "messages = prompt.invoke(\n",
    "    {\"context\": data['sim_diff'], \"msg\": data['sim_msg'], \"diff\": data['org_diff']}\n",
    ").to_messages()\n",
    "example_prompt = [{'role': 'user','content': messages[0].content},]\n",
    "print(gpt_35_api(example_prompt))"
   ],
   "id": "ccbb91b8ef17f468",
   "execution_count": 24,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T12:31:58.754186Z",
     "start_time": "2024-05-27T12:31:58.740087Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for index, data in enumerate(org_data):\n",
    "    if data['org_msg']==\"Tooltip: invoke 'doDestory' manually when disabled\":\n",
    "        print(index)"
   ],
   "id": "969a38cc6a3c8ddd",
   "execution_count": 22,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T12:34:30.817270Z",
     "start_time": "2024-05-27T12:34:30.802058Z"
    }
   },
   "cell_type": "code",
   "source": [
    "output_file = f'../data/final_preprocessed_data/{lang}_baseline/{lang}_baseline_rag_300.json'\n",
    "with open(output_file, 'w', encoding='UTF-8') as f:\n",
    "    json.dump(chronicle_data, f, ensure_ascii=False, indent=4)"
   ],
   "id": "7f8329270a4d0204",
   "execution_count": 26,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T20:42:28.590215Z",
     "start_time": "2024-05-26T19:56:59.489553Z"
    }
   },
   "cell_type": "code",
   "source": [
    "lang = 'js'\n",
    "with open(f'../data/final_preprocessed_data/{lang}_baseline/{lang}_baseline_nochunk_rag_prompt.json', 'r', encoding='UTF-8') as f:\n",
    "    org_data = json.load(f)\n",
    "\n",
    "gpt_msg = []\n",
    "for index, data in tqdm(enumerate(org_data), total=len(org_data), desc=\"Processing documents\"):\n",
    "    messages = prompt.invoke(\n",
    "        {\"context\": data['sim_diff'], \"msg\": data['sim_msg'], \"diff\": data['org_diff']}\n",
    "    ).to_messages()\n",
    "    example_prompt = [{'role': 'user','content': messages[0].content},]\n",
    "    try:\n",
    "        gpt_msg.append(gpt_35_api(example_prompt))\n",
    "    except:\n",
    "        print(index)\n",
    "        gpt_msg.append(\"\")\n",
    "\n",
    "with open(f'../data/final_preprocessed_data/{lang}_baseline_test_data.json', 'r', encoding='UTF-8') as f:\n",
    "    chronicle_data = json.load(f)[:1000]\n",
    "\n",
    "for item, msg in zip(chronicle_data, gpt_msg):\n",
    "    item['chatgpt_rag'] = msg\n",
    "\n",
    "output_file = f'../data/final_preprocessed_data/{lang}_baseline/{lang}_baseline_nochunk_rag.json'\n",
    "with open(output_file, 'w', encoding='UTF-8') as f:\n",
    "    json.dump(chronicle_data, f, ensure_ascii=False, indent=4)"
   ],
   "id": "b3c41e118fe53773",
   "execution_count": 6,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 4SIM",
   "id": "8cf448a8440113e2"
  },
  {
   "cell_type": "code",
   "source": [
    "prompt = hub.pull(\"tyfann/llm4commit-rag-4sim\")\n",
    "for lang in ['js']:\n",
    "    with open(f'../data/final_preprocessed_data/{lang}_baseline/{lang}_baseline_rag_top4_prompt.json', 'r', encoding='UTF-8') as f:\n",
    "        org_data = json.load(f)\n",
    "    \n",
    "    gpt_msg = []\n",
    "    for index, data in tqdm(enumerate(org_data), total=len(org_data), desc=\"Processing documents\"):\n",
    "        try:\n",
    "            messages = prompt.invoke(\n",
    "                {\"diff1\": data['sim_diff_0'],  \"msg1\": data['sim_msg_0'],\n",
    "                 \"diff2\": data['sim_diff_1'],  \"msg2\": data['sim_msg_1'],\n",
    "                 \"diff3\": data['sim_diff_2'],  \"msg3\": data['sim_msg_2'],\n",
    "                 \"diff4\": data['sim_diff_3'],  \"msg4\": data['sim_msg_3'],\n",
    "                 \"question\": data['org_diff']}\n",
    "            ).to_messages()\n",
    "            example_prompt = [{'role': 'user','content': messages[0].content},]\n",
    "            gpt_msg.append(gpt_35_api(example_prompt))\n",
    "        except:\n",
    "            print(index)\n",
    "            gpt_msg.append('')\n",
    "    \n",
    "    with open(f'../data/final_preprocessed_data/{lang}_baseline_test_data.json', 'r', encoding='UTF-8') as f:\n",
    "        chronicle_data = json.load(f)[:1000]\n",
    "    \n",
    "    for item, msg in zip(chronicle_data, gpt_msg):\n",
    "        item['chatgpt_rag'] = msg\n",
    "    \n",
    "    output_file = f'../data/final_preprocessed_data/{lang}_baseline/{lang}_baseline_rag_top4.json'\n",
    "    with open(output_file, 'w', encoding='UTF-8') as f:\n",
    "        json.dump(chronicle_data, f, ensure_ascii=False, indent=4)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-25T13:11:56.938143Z",
     "start_time": "2024-05-25T12:15:01.032137Z"
    }
   },
   "id": "fbcdda2ea61990d7",
   "execution_count": 7,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# SIM_MSG",
   "id": "487f1501f00b386b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T14:09:45.087533Z",
     "start_time": "2024-05-25T13:11:56.940269Z"
    }
   },
   "cell_type": "code",
   "source": [
    "prompt = hub.pull(\"tyfann/llm4commit-rag-msg\")\n",
    "for lang in [ 'js']:\n",
    "    with open(f'../data/final_preprocessed_data/{lang}_baseline/{lang}_baseline_rag_sim_msg_prompt.json', 'r', encoding='UTF-8') as f:\n",
    "        org_data = json.load(f)\n",
    "    \n",
    "    gpt_msg = []\n",
    "    for index, data in tqdm(enumerate(org_data), total=len(org_data), desc=\"Processing documents\"):\n",
    "        try:\n",
    "            messages = prompt.invoke(\n",
    "                {\"diff1\": data['sim_diff'],  \"msg1\": data['sim_msg'],\n",
    "                 \"question\": data['org_diff'], 'draft': data['org_msg']}\n",
    "            ).to_messages()\n",
    "            example_prompt = [{'role': 'user','content': messages[0].content},]\n",
    "            gpt_msg.append(gpt_35_api(example_prompt))\n",
    "        except:\n",
    "            print(index)\n",
    "            gpt_msg.append('')\n",
    "    \n",
    "    \n",
    "    with open(f'../data/final_preprocessed_data/{lang}_baseline_test_data.json', 'r', encoding='UTF-8') as f:\n",
    "        chronicle_data = json.load(f)[:1000]\n",
    "    \n",
    "    for item, msg in zip(chronicle_data, gpt_msg):\n",
    "        item['chatgpt_rag'] = msg\n",
    "    \n",
    "    output_file = f'../data/final_preprocessed_data/{lang}_baseline/{lang}_baseline_rag_sim_msg.json'\n",
    "    with open(output_file, 'w', encoding='UTF-8') as f:\n",
    "        json.dump(chronicle_data, f, ensure_ascii=False, indent=4)"
   ],
   "id": "3b7bf58e30e95b09",
   "execution_count": 8,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": "",
   "id": "ef76484886f1376",
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
