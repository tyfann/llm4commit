{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T16:57:24.515341Z",
     "start_time": "2024-05-03T16:57:22.780652Z"
    }
   },
   "source": [
    "from langchain import hub\n",
    "prompt = hub.pull(\"tyfann/llm4commit-zeroshot\")"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T16:57:25.279801Z",
     "start_time": "2024-05-03T16:57:24.518412Z"
    }
   },
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    # defaults to os.environ.get(\"OPENAI_API_KEY\")\n",
    "    api_key=\"sk-0rLvuRkMiD4Mw25QYygh6rUlZVjpQWNGNF4yez7z3PZ7yCOm\",\n",
    "    # api_key=\"sk-tMbkq3K1iO5vf0FRMlrmzslGXJZwE0us3mve4QXuvpnZcumG\",\n",
    "    base_url=\"https://api.chatanywhere.tech/v1\"\n",
    "    # base_url=\"https://api.chatanywhere.cn/v1\"\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T16:58:40.725201Z",
     "start_time": "2024-05-03T16:58:40.706604Z"
    }
   },
   "source": [
    "def gpt_35_api(messages: list):\n",
    "\n",
    "    # completion = client.chat.completions.create(model=\"gpt-3.5-turbo-0125\", messages=messages, temperature=0.5)\n",
    "    completion = client.chat.completions.create(model=\"gpt-3.5-turbo-ca\", messages=messages, temperature=0.5)\n",
    "    return completion.choices[0].message.content"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T16:58:42.533497Z",
     "start_time": "2024-05-03T16:58:42.506540Z"
    }
   },
   "source": [
    "import json\n",
    "from tqdm import tqdm"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Python part"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T16:59:00.485205Z",
     "start_time": "2024-05-03T16:59:00.456168Z"
    }
   },
   "source": [
    "with open('../data/chronicle/rag_baseline/rag_baseline_python.json', 'r', encoding='UTF-8') as f:\n",
    "    org_data = json.load(f)"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T19:30:06.608990Z",
     "start_time": "2024-05-03T16:59:31.338673Z"
    }
   },
   "source": [
    "gpt_msg = []\n",
    "for data in tqdm(org_data, total=len(org_data), desc=\"Processing documents\"):\n",
    "    messages = prompt.invoke(\n",
    "        {\"DIFF\": data['org_diff']}\n",
    "    ).to_messages()\n",
    "    example_prompt = [{'role': 'user','content': messages[0].content},]\n",
    "    gpt_msg.append(gpt_35_api(example_prompt))\n",
    "\n",
    "for item, msg in zip(org_data, gpt_msg):\n",
    "    item['chatgpt'] = msg"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing documents: 100%|██████████| 1000/1000 [2:30:35<00:00,  9.04s/it] \n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T19:30:06.654882Z",
     "start_time": "2024-05-03T19:30:06.616671Z"
    }
   },
   "source": [
    "import os\n",
    "output_file = '../data/chronicle/rag_baseline/zeroshot/rag_baseline_python_chatgpt.json'\n",
    "os.makedirs(os.path.dirname(output_file), exist_ok=True)\n",
    "with open(output_file, 'w', encoding='UTF-8') as f:\n",
    "    json.dump(org_data, f, ensure_ascii=False, indent=4)\n"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# JavaScript part"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T21:17:23.126948Z",
     "start_time": "2024-05-03T19:30:06.656882Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with open('../data/chronicle/rag_baseline/rag_baseline_js.json', 'r', encoding='UTF-8') as f:\n",
    "    org_data = json.load(f)\n",
    "\n",
    "gpt_msg = []\n",
    "for data in tqdm(org_data, total=len(org_data), desc=\"Processing documents\"):\n",
    "    messages = prompt.invoke(\n",
    "        {\"DIFF\": data['org_diff']}\n",
    "    ).to_messages()\n",
    "    example_prompt = [{'role': 'user','content': messages[0].content},]\n",
    "    gpt_msg.append(gpt_35_api(example_prompt))\n",
    "\n",
    "for item, msg in zip(org_data, gpt_msg):\n",
    "    item['chatgpt'] = msg"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing documents: 100%|██████████| 1000/1000 [1:47:16<00:00,  6.44s/it] \n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T21:17:23.172238Z",
     "start_time": "2024-05-03T21:17:23.133160Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "output_file = '../data/chronicle/rag_baseline/zeroshot/rag_baseline_js_chatgpt.json'\n",
    "os.makedirs(os.path.dirname(output_file), exist_ok=True)\n",
    "with open(output_file, 'w', encoding='UTF-8') as f:\n",
    "    json.dump(org_data, f, ensure_ascii=False, indent=4)"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing documents: 100%|██████████| 69/69 [01:47<00:00,  1.56s/it]\n"
     ]
    }
   ],
   "source": [
    "prompt = hub.pull(\"tyfann/llm4commit-cot\")\n",
    "gpt_cot_msg = []\n",
    "\n",
    "example_q = \"\"\"\"diff --git a/java/client/src/org/openqa/selenium/htmlunit/HtmlUnitAlert.java  b/java/client/src/org/openqa/selenium/htmlunit/HtmlUnitAlert.java \\npublic void sendKeys(String keysToSend){ \\npublic void authenticateUsing(Credentials credentials){}+@Override+public void setCredentials(Credentials credentials){+}++@Override \\npublic void handleAlert(Page page,String message){ \\nQueue<String>queue=queues.get(page); \\n\" What is the commit message of this code diff?\"\"\"\n",
    "example_a = \"\"\"First, the scope of code changes is to add a method, and second, according to the filename \"HtmlUnitAlert\", and the function of the file could be an alert, the modification \"@Overide\" is an annotation which can solve the compilation issue, so the modification can help solve the compilation problem to the alert file. So the commit message for the code diff is \"fix compilation issue because of new method in Alert\".\"\"\"\n",
    "for data in tqdm(org_data[31:100], total=len(org_data[31:100]), desc=\"Processing documents\"):\n",
    "    messages = prompt.invoke(\n",
    "        {\"Example_Question\": example_q, \"Example_Answer\": example_a, \"Question\": data['diff']}\n",
    "    ).to_messages()\n",
    "    example_prompt = [{'role': 'user','content': messages[0].content},]\n",
    "    gpt_cot_msg.append(gpt_35_api(example_prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 100)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(gpt_msg), len(gpt_cot_msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def preprocess(text):\n",
    "    if re.search(r'commit\\s*message', text, re.IGNORECASE):\n",
    "        pattern = r'\\\"([^\"]+)'\n",
    "        match = re.search(pattern, text)\n",
    "        if match:\n",
    "            return match.group(1)\n",
    "        else:\n",
    "            return text\n",
    "    else:\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item, msg, cot_msg in zip(org_data[:100], gpt_msg, gpt_cot_msg):\n",
    "    item['chatgpt_cot'] = preprocess(cot_msg)\n",
    "    item['chatgpt_v2'] = msg\n",
    "\n",
    "output_file = '../../bleu/all_result_cot.json'\n",
    "with open(output_file, 'w', encoding='UTF-8') as f:\n",
    "    json.dump(org_data[:100], f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item, msg in zip(org_data[:100], gpt_msg):\n",
    "    item['chatgpt_v3'] = msg\n",
    "\n",
    "output_file = '../../bleu/all_result_chatgpt.json'\n",
    "with open(output_file, 'w', encoding='UTF-8') as f:\n",
    "    json.dump(org_data[:100], f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cmg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
