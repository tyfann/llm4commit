{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T08:52:13.067237Z",
     "start_time": "2024-06-18T08:52:11.316040Z"
    }
   },
   "source": [
    "from langchain import hub\n",
    "prompt = hub.pull(\"tyfann/llm4commit-fewshot\")"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T08:54:01.884839Z",
     "start_time": "2024-06-18T08:54:00.908538Z"
    }
   },
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    # defaults to os.environ.get(\"OPENAI_API_KEY\")\n",
    "    api_key=\"sk-0rLvuRkMiD4Mw25QYygh6rUlZVjpQWNGNF4yez7z3PZ7yCOm\",\n",
    "    # api_key=\"sk-tMbkq3K1iO5vf0FRMlrmzslGXJZwE0us3mve4QXuvpnZcumG\",\n",
    "    base_url=\"https://api.chatanywhere.cn/v1\"\n",
    "    # base_url=\"https://api.chatanywhere.cn/v1\"\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T08:54:05.247191Z",
     "start_time": "2024-06-18T08:54:05.234675Z"
    }
   },
   "source": [
    "def gpt_35_api(messages: list):\n",
    "\n",
    "    completion = client.chat.completions.create(model=\"gpt-3.5-turbo-0125\", messages=messages, temperature=0)\n",
    "    # completion = client.chat.completions.create(model=\"gpt-3.5-turbo-ca\", messages=messages, temperature=0.5)\n",
    "    return completion.choices[0].message.content"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T08:54:07.769105Z",
     "start_time": "2024-06-18T08:54:07.741265Z"
    }
   },
   "source": [
    "import json\n",
    "from tqdm import tqdm"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Python part"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T08:54:37.799654Z",
     "start_time": "2024-06-18T08:54:37.786288Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with open('../data/angular_filtered/subsets/test_dev.json', 'r', encoding='UTF-8') as f:\n",
    "    org_data = json.load(f)"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T09:02:33.112358Z",
     "start_time": "2024-06-18T08:54:51.507466Z"
    }
   },
   "source": [
    "gpt_msg = []\n",
    "for index, data in tqdm(enumerate(org_data), total=len(org_data), desc=\"Processing documents\"):\n",
    "    # merged_diff = '\\n'.join(diff['diff'] for diff in data['diff'])\n",
    "    messages = prompt.invoke(\n",
    "        {\"DIFF\": data['diff']}\n",
    "    ).to_messages()\n",
    "    example_prompt = [{'role': 'user','content': messages[0].content},]\n",
    "    try:\n",
    "        gpt_msg.append(gpt_35_api(example_prompt))\n",
    "    except:\n",
    "        print(index)\n",
    "        gpt_msg.append(\"\")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing documents: 100%|██████████| 603/603 [07:41<00:00,  1.31it/s]\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T09:02:48.248859Z",
     "start_time": "2024-06-18T09:02:48.219980Z"
    }
   },
   "source": [
    "for item, msg in zip(org_data, gpt_msg):\n",
    "    item['chatgpt_fewshot'] = msg\n",
    "import os\n",
    "# output_file = '../data/chronicle/rag_baseline/zeroshot/rag_baseline_python_chatgpt.json'\n",
    "output_file = '../data/angular_filtered/subsets/generation/dev_test_gpt35_fewshot.json'\n",
    "os.makedirs(os.path.dirname(output_file), exist_ok=True)\n",
    "with open(output_file, 'w', encoding='UTF-8') as f:\n",
    "    json.dump(org_data, f, ensure_ascii=False, indent=4)"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T09:10:20.873941Z",
     "start_time": "2024-06-18T09:10:20.860430Z"
    }
   },
   "cell_type": "code",
   "source": [
    "output_file = '../data/angular_filtered/subsets/generation/dev_test_gpt35_fewshot.txt'\n",
    "with open(output_file, 'w', encoding='UTF-8') as f:\n",
    "    for item in org_data:\n",
    "        f.write(item['chatgpt_fewshot'].replace('\\n', '\\\\n').replace('\\r', '\\\\r') + '\\n')"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T09:41:25.550565Z",
     "start_time": "2024-05-24T09:41:25.536559Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def chatgpt_gen(org_data):\n",
    "    gpt_msg = []\n",
    "    for index, data in tqdm(enumerate(org_data), total=len(org_data), desc=\"Processing documents\"):\n",
    "        # merged_diff = '\\n'.join(diff['diff'] for diff in data['diff'])\n",
    "        messages = prompt.invoke(\n",
    "            {\"DIFF\": data['diff']}\n",
    "        ).to_messages()\n",
    "        example_prompt = [{'role': 'user','content': messages[0].content},]\n",
    "        try:\n",
    "            gpt_msg.append(gpt_35_api(example_prompt))\n",
    "        except:\n",
    "            print(index)\n",
    "            gpt_msg.append(\"\")"
   ],
   "execution_count": 9,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T10:36:19.323536Z",
     "start_time": "2024-05-24T09:41:28.858806Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with open('../data/final_preprocessed_data/js_baseline_test_data.json', 'r', encoding='UTF-8') as f:\n",
    "    org_data = json.load(f)\n",
    "\n",
    "org_data = org_data[:1000]\n",
    "chatgpt_gen(org_data)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T11:19:56.443062Z",
     "start_time": "2024-05-24T11:19:56.415063Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "for item, msg in zip(org_data, gpt_msg):\n",
    "    item['chatgpt'] = msg\n",
    "import os\n",
    "# output_file = '../data/chronicle/rag_baseline/zeroshot/rag_baseline_python_chatgpt.json'\n",
    "output_file = '../data/final_preprocessed_data/discriminator/dis_eval_data_chatgpt_finetune.json'\n",
    "os.makedirs(os.path.dirname(output_file), exist_ok=True)\n",
    "with open(output_file, 'w', encoding='UTF-8') as f:\n",
    "    json.dump(org_data, f, ensure_ascii=False, indent=4)"
   ],
   "execution_count": 11,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# JavaScript part"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T09:12:52.181166Z",
     "start_time": "2024-05-10T09:03:46.056053Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with open('../data/scenario/filtered_data/project_based_react_multi_diff_filtered.json', 'r', encoding='UTF-8') as f:\n",
    "    org_data = json.load(f)\n",
    "\n",
    "org_data = org_data[:1000]\n",
    "gpt_msg = []\n",
    "for data in tqdm(org_data, total=len(org_data), desc=\"Processing documents\"):\n",
    "    merged_diff = '\\n'.join(diff['diff'] for diff in data['diff'])\n",
    "    messages = prompt.invoke(\n",
    "        {\"DIFFS\": merged_diff}\n",
    "    ).to_messages()\n",
    "    example_prompt = [{'role': 'user','content': messages[0].content},]\n",
    "    gpt_msg.append(gpt_35_api(example_prompt))\n",
    "\n",
    "for item, msg in zip(org_data[:100], gpt_msg):\n",
    "    item['chatgpt'] = msg"
   ],
   "execution_count": 17,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T09:12:52.228845Z",
     "start_time": "2024-05-10T09:12:52.188682Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "# output_file = '../data/chronicle/rag_baseline/zeroshot/rag_baseline_js_chatgpt.json'\n",
    "output_file = '../data/scenario/zeroshot/scenario_react_multi_diff_chatgpt_zeroshot.json'\n",
    "os.makedirs(os.path.dirname(output_file), exist_ok=True)\n",
    "with open(output_file, 'w', encoding='UTF-8') as f:\n",
    "    json.dump(org_data[:100], f, ensure_ascii=False, indent=4)"
   ],
   "execution_count": 18,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COT"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-08T08:50:01.159299Z",
     "start_time": "2024-06-08T08:37:53.088435Z"
    }
   },
   "source": [
    "from langchain import hub\n",
    "\n",
    "prompt = hub.pull(\"tyfann/llm4commit-cot:7f1b7f53\")\n",
    "gpt_cot_msg = []\n",
    "\n",
    "example_q = \"\"\"\"diff --git a/resources/lib/kodi/library_utils.py b/resources/lib/kodi/library_utils.py @@ -25,7 +25,7 @@ from resources.lib.utils.logging import LOG, measure_exec_time_decorator\\nLIBRARY_HOME = 'library'\\nFOLDER_NAME_MOVIES = 'movies'\\nFOLDER_NAME_SHOWS = 'shows'\\n-ILLEGAL_CHARACTERS = '[<|>|\\\"|?|$|!|:|#|*]'\\n+ILLEGAL_CHARACTERS = '[<|>|\\\"|?|$|!|:|#|*|/|\\\\\\\\\\\\\\\\]'\\ndef get_library_path():\\n\"\"\"\n",
    "example_a = \"\"\"First, the scope of code changes is to add extra information to an existing field, and second, according to the filename \"library_utils.py\", it is a utils class, so there is no strong relationship between this file and the entire project. And for the modification it mainly adds the missing slash and backslash to ILLEGAL_CHARACTERS. So the commit message for the code diff is \"Add missing slash backslash to illegal chars\" \"\"\"\n",
    "for data in tqdm(org_data, total=len(org_data), desc=\"Processing documents\"):\n",
    "    messages = prompt.invoke(\n",
    "        {\"Example_Question\": example_q, \"Example_Answer\": example_a, \"Question\": data['diff']}\n",
    "    ).to_messages()\n",
    "    example_prompt = [{'role': 'user','content': messages[0].content},]\n",
    "    gpt_cot_msg.append(gpt_35_api(example_prompt))"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing documents: 100%|██████████| 1000/1000 [12:07<00:00,  1.38it/s]\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "source": [
    "len(gpt_msg), len(gpt_cot_msg)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "source": [
    "import re\n",
    "\n",
    "def preprocess(text):\n",
    "    if re.search(r'commit\\s*message', text, re.IGNORECASE):\n",
    "        pattern = r'\\\"([^\"]+)'\n",
    "        match = re.search(pattern, text)\n",
    "        if match:\n",
    "            return match.group(1)\n",
    "        else:\n",
    "            return text\n",
    "    else:\n",
    "        return text"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-08T09:01:55.880158Z",
     "start_time": "2024-06-08T09:01:55.851830Z"
    }
   },
   "source": [
    "for item, cot_msg in zip(org_data, gpt_cot_msg):\n",
    "    item['chatgpt_cot'] = cot_msg\n",
    "\n",
    "output_file = '../data/final_preprocessed_data/discriminator/dis_eval_data_chatgpt_cot.json'\n",
    "with open(output_file, 'w', encoding='UTF-8') as f:\n",
    "    json.dump(org_data, f, ensure_ascii=False, indent=4)"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "source": [
    "for item, msg in zip(org_data[:100], gpt_msg):\n",
    "    item['chatgpt_v3'] = msg\n",
    "\n",
    "output_file = '../../bleu/all_result_chatgpt.json'\n",
    "with open(output_file, 'w', encoding='UTF-8') as f:\n",
    "    json.dump(org_data[:100], f, ensure_ascii=False, indent=4)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cmg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
