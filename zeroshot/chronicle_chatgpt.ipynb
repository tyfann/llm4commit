{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T11:46:17.440456Z",
     "start_time": "2024-05-24T11:46:17.231575Z"
    }
   },
   "outputs": [],
   "source": [
    "import pyarrow.parquet as pq\n",
    "df = pq.read_table('../rag/datasets--JetBrains-Research--commit-chronicle/snapshots/5fd076e67b812a9f3d1999e5e40f71715f84bb51/subset_cmg/test-00000-of-00002-983a1050cd3c058c.parquet').to_pandas()\n",
    "df.iloc[0]['repo']\n",
    "df[(df['language'] == 'JavaScript') & (df['mods'].apply(lambda x: x[0]['diff'].count('.js')==2))].head()['mods'].iloc[0][0]\n",
    "for index, row in df.iterrows():\n",
    "    print(row['message'])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T14:51:36.767663Z",
     "start_time": "2024-04-23T14:51:36.755406Z"
    }
   },
   "outputs": [],
   "source": [
    "languages = ['Java', 'Python', 'C#', 'C++', 'JavaScript']\n",
    "language_dict = {language: 0 for language in languages}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "234899f962914523bca4d68fd01513ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "JavaScript:   0%|          | 0/100000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pyarrow.parquet as pq\n",
    "import glob\n",
    "import os\n",
    "from tqdm.auto import tqdm\n",
    "import re\n",
    "\n",
    "def check_angular_convention(msg, has_space=True, strict=True):\n",
    "    types = '((build)|(ci)|(docs)|(feat)|(fix)|(perf)|(refactor)|(style)|(test)|(chore))'\n",
    "    # types = '((perf))'\n",
    "    if has_space:\n",
    "        pattern = f'{types}\\\\s(\\\\((\\\\s|\\\\S)+\\\\)\\\\s)?:\\\\s(\\\\s|\\\\S)+'\n",
    "    else:\n",
    "        pattern = f'{types}(\\\\((\\\\s|\\\\S)+\\\\))?:\\\\s\\\\S+(\\\\s|\\\\S)+'\n",
    "    if not strict:\n",
    "        pattern = '^((build)|(ci)|(docs)|(feat)|(fix)|(perf)|(refactor)|(style)|(test)|(chore))'\n",
    "    return re.match(pattern, msg) is not None\n",
    "\n",
    "# Define the types for the angular convention\n",
    "angular_types = ['build', 'ci', 'docs', 'feat', 'fix', 'perf', 'refactor', 'style', 'test', 'chore']\n",
    "# angular_types = ['perf']\n",
    "\n",
    "# Create empty dictionaries for each language and type\n",
    "languages = ['JavaScript']\n",
    "dfs = {lang: {atype: [] for atype in angular_types} for lang in languages}\n",
    "\n",
    "# Create a tqdm progress bar for each language\n",
    "bars = {lang: tqdm(total=100000, desc=lang) for lang in languages}  # Total: 10 types * 10000 each\n",
    "\n",
    "folder_path = '../rag/datasets--JetBrains-Research--commit-chronicle/snapshots/5fd076e67b812a9f3d1999e5e40f71715f84bb51/data'  # 文件夹的路径\n",
    "\n",
    "files = glob.glob(os.path.join(folder_path, 'train*')) + glob.glob(os.path.join(folder_path, 'validation*')) + glob.glob(os.path.join(folder_path, 'test*')) \n",
    "\n",
    "for file in files:\n",
    "    df = pq.read_table(file).to_pandas()\n",
    "\n",
    "    # Iterate over each language\n",
    "    for lang in languages[:]:\n",
    "        lang_suffix = '.js'\n",
    "\n",
    "        # Filter rows where language column matches the current language and additional conditions\n",
    "        lang_df = df[(df['language'] == lang) & \n",
    "                     (df['mods'].apply(len) == 1) & \n",
    "                    #  (df['message'].apply(len) <= 150) & \n",
    "                     (df['mods'].apply(lambda x: x[0]['change_type']) == 'MODIFY') &\n",
    "                     (df['mods'].apply(lambda x: len(f\"diff --git a/{x[0]['old_path']} b/{x[0]['new_path']} {x[0]['diff']}\") <= 5000))] \n",
    "                    #  (df['mods'].apply(lambda x: ( (x[0]['old_path'].count(lang_suffix) if x[0]['old_path'] else 0) == 1 and (x[0]['new_path'].count(lang_suffix) if x[0]['new_path'] else 0) == 1 and (x[0]['old_path'].count('.json') if x[0]['old_path'] else 0) == 0 and (x[0]['new_path'].count('.json') if x[0]['new_path'] else 0) == 0 )))]\n",
    "\n",
    "        # Iterate over each row in the filtered DataFrame\n",
    "        for index, row in lang_df.iterrows():\n",
    "            msg = row['message']\n",
    "            if check_angular_convention(msg, has_space=True) or check_angular_convention(msg, has_space=False) or check_angular_convention(msg, strict=False):\n",
    "                diff = row['mods'][0]\n",
    "                old_path = 'a/' + diff['old_path']\n",
    "                new_path = 'b/' + diff['new_path']\n",
    "                diff_content = diff['diff']  # assume diff_content is an empty string\n",
    "                item = {\n",
    "                    'msg': row['message'],\n",
    "                    'diff': f\"diff --git {old_path} {new_path} {diff_content}\",\n",
    "                    'date': row['date'],\n",
    "                    'repo': row['repo']\n",
    "                }\n",
    "\n",
    "                # Find the type in the message\n",
    "                for atype in angular_types:\n",
    "                    if msg.startswith(atype):\n",
    "                        if len(dfs[lang][atype]) < 10000:\n",
    "                            dfs[lang][atype].append(item)\n",
    "                            bars[lang].update(1)\n",
    "                        break\n",
    "\n",
    "            # Check if all types have reached 1000 rows\n",
    "            if all(len(dfs[lang][atype]) >= 10000 for atype in angular_types):\n",
    "                print(f\"Reached 10000 rows for all types in {lang}\")\n",
    "                languages.remove(lang)  # Remove language from list to avoid further processing\n",
    "                break\n",
    "\n",
    "    # Break out of the loop if all languages have reached the required number of rows\n",
    "    if not languages:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T09:52:24.594597Z",
     "start_time": "2024-06-09T09:50:55.298655Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "719c8c8de4374836a421da00fb9c9bd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "JavaScript:   0%|          | 0/150000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pyarrow.parquet as pq\n",
    "import glob\n",
    "import os\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Create empty DataFrames for each language\n",
    "# languages = ['Java', 'Python', 'C++', 'C#', 'JavaScript']\n",
    "# languages = ['Python', 'JavaScript']\n",
    "languages = ['JavaScript']\n",
    "dfs = {lang: [] for lang in languages}\n",
    "\n",
    "# Create a tqdm progress bar for each language\n",
    "bars = {lang: tqdm(total=150000, desc=lang) for lang in languages}\n",
    "\n",
    "folder_path = '../rag/datasets--JetBrains-Research--commit-chronicle/snapshots/5fd076e67b812a9f3d1999e5e40f71715f84bb51/data'  # 文件夹的路径\n",
    "\n",
    "# files = glob.glob(os.path.join(folder_path, 'test*')) \n",
    "files = glob.glob(os.path.join(folder_path, 'train*')) + glob.glob(os.path.join(folder_path, 'validation*')) + glob.glob(os.path.join(folder_path, 'test*')) \n",
    "\n",
    "for file in files:\n",
    "    df = pq.read_table(file).to_pandas()\n",
    "\n",
    "    # Iterate over each language\n",
    "    for lang in languages[:]:\n",
    "        if lang =='Python':\n",
    "            lang_suffix = '.py'\n",
    "        elif lang == 'JavaScript':\n",
    "            lang_suffix = '.js'\n",
    "\n",
    "        # Filter rows where language column matches the current language\n",
    "        lang_df = df[(df['language'] == lang) & \n",
    "                     (df['mods'].apply(len) == 1) & \n",
    "                     (df['message'].apply(len) <= 100) & \n",
    "                     (df['mods'].apply(lambda x: x[0]['change_type']) == 'MODIFY') & \n",
    "                     (df['mods'].apply(lambda x: len(f\"diff --git a/{x[0]['old_path']} b/{x[0]['new_path']} {x[0]['diff']}\") <= 1000)) & \n",
    "                     (df['mods'].apply(lambda x: ( (x[0]['old_path'].count(lang_suffix) if x[0]['old_path'] else 0) == 1 and (x[0]['new_path'].count(lang_suffix) if x[0]['new_path'] else 0) == 1 and (x[0]['old_path'].count('.json') if x[0]['old_path'] else 0) == 0 and (x[0]['old_path'].count('.json') if x[0]['old_path'] else 0) == 0 )))]\n",
    "\n",
    "        # Iterate over each row in the filtered DataFrame\n",
    "        for index, row in lang_df.iterrows():\n",
    "            diff = row['mods'][0]\n",
    "            old_path = 'a/' + diff['old_path']\n",
    "            new_path = 'b/' + diff['new_path']\n",
    "            diff_content = diff['diff']  # assume diff_content is an empty string\n",
    "            item = {\n",
    "                'msg': row['message'],\n",
    "                'diff': f\"diff --git {old_path} {new_path} {diff_content}\",\n",
    "                'date': row['date'],\n",
    "                'repo': row['repo']\n",
    "            }\n",
    "            dfs[lang].append(item)\n",
    "            bars[lang].update(1)\n",
    "\n",
    "            # Check if the language has reached 100,000 rows\n",
    "            if len(dfs[lang]) >= 150000:\n",
    "                print(f\"Reached 150000 rows for {lang}\")\n",
    "                languages.remove(lang)  # Remove language from list to avoid further processing\n",
    "                break\n",
    "    # Break out of the loop if all languages have reached 100,000 rows\n",
    "    if not languages:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T09:53:16.908112Z",
     "start_time": "2024-06-09T09:53:15.881075Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Create a single list of all items\n",
    "all_items = [item for lang in dfs for item in dfs[lang]]\n",
    "# Dump the data to a JSON file\n",
    "with open('../data/final_preprocessed_data/discriminator/db_data_js.json', 'w', encoding='UTF-8') as f:\n",
    "    json.dump(all_items, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-05T11:40:35.094799Z",
     "start_time": "2024-06-05T11:40:33.891021Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_temp = train_test_split(all_items, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-05T11:41:20.487714Z",
     "start_time": "2024-06-05T11:41:20.474205Z"
    }
   },
   "outputs": [],
   "source": [
    "X_eval, X_test = train_test_split(X_temp, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-05T11:41:52.991737Z",
     "start_time": "2024-06-05T11:41:52.878345Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('../data/final_preprocessed_data/discriminator/dis_train_data.json', 'w') as f:\n",
    "    json.dump(X_train, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-05T11:42:03.815688Z",
     "start_time": "2024-06-05T11:42:03.791592Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('../data/final_preprocessed_data/discriminator/dis_eval_data.json', 'w') as f:\n",
    "    json.dump(X_eval, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-05T11:42:18.681537Z",
     "start_time": "2024-06-05T11:42:18.651954Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('../data/final_preprocessed_data/discriminator/dis_test_data.json', 'w') as f:\n",
    "    json.dump(X_test, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T17:56:48.205090Z",
     "start_time": "2024-04-25T17:56:47.184723Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "data = []\n",
    "while any(value < 1000 for value in language_dict.values()):\n",
    "    for index, row in df.iterrows():\n",
    "        language = row['language']\n",
    "        if language in languages:\n",
    "            \n",
    "            if language_dict[language] >= 1000 or len(row['mods']) != 1 or row['mods'][0]['change_type'] != 'MODIFY' or len(f\"diff --git a/{row['mods'][0]['old_path']} b/{row['mods'][0]['new_path']} {row['mods'][0]['diff']}\") > 3000:\n",
    "                continue\n",
    "            language_dict[language] += 1\n",
    "\n",
    "            item = {\n",
    "                'msg': row['message'],\n",
    "                'diff': f\"diff --git a/{row['mods'][0]['old_path']} b/{row['mods'][0]['new_path']} {row['mods'][0]['diff']}\",\n",
    "                'lang': language\n",
    "            }\n",
    "            data.append(item)\n",
    "\n",
    "import random\n",
    "random.seed(42)\n",
    "random.shuffle(data)\n",
    "\n",
    "with open('../data/chronicle_data_dev.json', 'w', encoding='UTF-8') as f:\n",
    "    json.dump(data, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T17:57:06.273064Z",
     "start_time": "2024-04-25T17:57:06.229410Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Create a single list of all items\n",
    "all_items = [item for lang in dfs for item in dfs[lang]]\n",
    "\n",
    "import random\n",
    "random.seed(42)\n",
    "random.shuffle(all_items)\n",
    "\n",
    "# Dump the data to a JSON file\n",
    "with open('../data/chronicle/chronicle_test_data_dev.json', 'w') as f:\n",
    "    json.dump(all_items, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T17:47:25.529028Z",
     "start_time": "2024-04-25T17:47:25.517026Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(all_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 遍历每个item\n",
    "for item in data:\n",
    "    diff = item['diff']\n",
    "    new_diff = f\"diff --git {diff}\"\n",
    "\n",
    "    item['diff'] = new_diff\n",
    "\n",
    "# 将更新后的数据写入新的JSON文件\n",
    "with open('../data/chronicle_data.json', 'w', encoding='UTF-8') as file:\n",
    "    json.dump(data, file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T11:07:14.364197Z",
     "start_time": "2024-05-11T11:07:11.887852Z"
    }
   },
   "outputs": [],
   "source": [
    "import pyarrow.parquet as pq\n",
    "import glob\n",
    "import os\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Create empty DataFrames for each language\n",
    "# languages = ['Java', 'Python', 'C++', 'C#', 'JavaScript']\n",
    "languages = ['Python', 'JavaScript']\n",
    "dfs = {lang: [] for lang in languages}\n",
    "\n",
    "# Create a tqdm progress bar for each language\n",
    "bars = {lang: tqdm(total=1000, desc=lang) for lang in languages}\n",
    "\n",
    "folder_path = '../rag/datasets--JetBrains-Research--commit-chronicle/snapshots/5fd076e67b812a9f3d1999e5e40f71715f84bb51/subset_cmg'  # 文件夹的路径\n",
    "\n",
    "files = glob.glob(os.path.join(folder_path, 'test*'))\n",
    "\n",
    "for file in files:\n",
    "    df = pq.read_table(file).to_pandas()\n",
    "\n",
    "    # Iterate over each language\n",
    "    for lang in languages[:]:\n",
    "        # Filter rows where language column matches the current language\n",
    "        condition = lambda x: all(len(f\"diff --git a/{item['old_path']} b/{item['new_path']} {item['diff']}\") <= 3000 for item in x)\n",
    "        type_condition = lambda x: all(item['change_type'] == 'MODIFY' for item in x)\n",
    "        lang_df = df[(df['language'] == lang) & (df['mods'].apply(len) > 1) & (df['mods'].apply(type_condition)) & (df['mods'].apply(condition))]\n",
    "\n",
    "        # Iterate over each row in the filtered DataFrame\n",
    "        for index, row in lang_df.iterrows():\n",
    "            diffs = {}\n",
    "            diffs['msg'] = row['message']\n",
    "            diffs['diffs'] = []\n",
    "            diffs['lang'] = lang\n",
    "            for diff in row['mods']:\n",
    "                old_path = 'a/' + diff['old_path']\n",
    "                new_path = 'b/' + diff['new_path']\n",
    "                diff_content = diff['diff']  # assume diff_content is an empty string\n",
    "                item = {\n",
    "                    'diff': f\"diff --git {old_path} {new_path} {diff_content}\",\n",
    "                }\n",
    "                diffs['diffs'].append(item)\n",
    "            merged_diff = '\\n'.join(diff['diff'] for diff in diffs['diffs'])\n",
    "            diffs['diffs'] = merged_diff\n",
    "            dfs[lang].append(diffs)\n",
    "            bars[lang].update(1)\n",
    "\n",
    "            # Check if the language has reached 100,000 rows\n",
    "            if len(dfs[lang]) >= 1000:\n",
    "                print(f\"Reached 1000 rows for {lang}\")\n",
    "                languages.remove(lang)  # Remove language from list to avoid further processing\n",
    "                break\n",
    "    # Break out of the loop if all languages have reached 100,000 rows\n",
    "    if not languages:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T11:43:56.747943Z",
     "start_time": "2024-05-10T11:43:56.735702Z"
    }
   },
   "outputs": [],
   "source": [
    "len(dfs['JavaScript'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T11:07:46.822743Z",
     "start_time": "2024-05-11T11:07:46.773745Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Create a single list of all items\n",
    "all_items = [item for lang in dfs for item in dfs[lang]]\n",
    "\n",
    "# Dump the data to a JSON file\n",
    "with open('../data/chronicle/chronicle_multi_diff_test_data.json', 'w', encoding='UTF-8') as f:\n",
    "    json.dump(all_items, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cmg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
