{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T11:46:17.440456Z",
     "start_time": "2024-05-24T11:46:17.231575Z"
    }
   },
   "source": [
    "import pyarrow.parquet as pq"
   ],
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T11:46:18.872585Z",
     "start_time": "2024-05-24T11:46:17.442571Z"
    }
   },
   "source": [
    "df = pq.read_table('../rag/datasets--JetBrains-Research--commit-chronicle/snapshots/5fd076e67b812a9f3d1999e5e40f71715f84bb51/subset_cmg/test-00000-of-00002-983a1050cd3c058c.parquet').to_pandas()"
   ],
   "execution_count": 2,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T11:46:25.416138Z",
     "start_time": "2024-05-24T11:46:25.262068Z"
    }
   },
   "cell_type": "code",
   "source": "df[(df['language'] == 'JavaScript') & (df['mods'].apply(lambda x: x[0]['diff'].count('.js')==2))].head()['mods'].iloc[0][0]",
   "execution_count": 3,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T13:48:48.073928Z",
     "start_time": "2024-05-23T13:48:48.055097Z"
    }
   },
   "cell_type": "code",
   "source": "df['mods'].head()[0][0]['diff'].count('.py')",
   "execution_count": 11,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T14:51:28.108497Z",
     "start_time": "2024-04-23T14:51:28.079811Z"
    }
   },
   "source": [
    "df.tail()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "source": [
    "df['mods'][0][0]['change_type']"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "source": [
    "for index, row in df.iterrows():\n",
    "    print(row['message'])\n",
    "    break"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T14:51:36.767663Z",
     "start_time": "2024-04-23T14:51:36.755406Z"
    }
   },
   "source": [
    "languages = ['Java', 'Python', 'C#', 'C++', 'JavaScript']\n",
    "language_dict = {language: 0 for language in languages}"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import pyarrow.parquet as pq\n",
    "import glob\n",
    "import os\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Create empty DataFrames for each language\n",
    "# languages = ['Java', 'Python', 'C++', 'C#', 'JavaScript']\n",
    "# languages = ['Python', 'JavaScript']\n",
    "languages = ['Python']\n",
    "dfs = {lang: [] for lang in languages}\n",
    "\n",
    "# Create a tqdm progress bar for each language\n",
    "bars = {lang: tqdm(total=1000, desc=lang) for lang in languages}\n",
    "\n",
    "folder_path = '../rag/datasets--JetBrains-Research--commit-chronicle/snapshots/5fd076e67b812a9f3d1999e5e40f71715f84bb51/data'  # 文件夹的路径\n",
    "\n",
    "# files = glob.glob(os.path.join(folder_path, 'train*')) + glob.glob(os.path.join(folder_path, 'validation*'))\n",
    "files = glob.glob(os.path.join(folder_path, 'test*'))\n",
    "\n",
    "for file in files:\n",
    "    df = pq.read_table(file).to_pandas()\n",
    "\n",
    "    # Iterate over each language\n",
    "    for lang in languages[:]:\n",
    "        if lang =='Python':\n",
    "            lang_suffix = '.py'\n",
    "        elif lang == 'JavaScript':\n",
    "            lang_suffix = '.js'\n",
    "\n",
    "        # Filter rows where language column matches the current language\n",
    "        lang_df = df[(df['language'] == lang) & (df['mods'].apply(len) == 1) & (df['message'].apply(len) <= 50) & (df['mods'].apply(lambda x: x[0]['change_type']) == 'MODIFY') & (df['mods'].apply(lambda x: len(f\"diff --git a/{x[0]['old_path']} b/{x[0]['new_path']} {x[0]['diff']}\") <= 500)) & (df['mods'].apply(lambda x: ( (x[0]['old_path'].count(lang_suffix) if x[0]['old_path'] else 0) == 1 and (x[0]['new_path'].count(lang_suffix) if x[0]['new_path'] else 0) == 1 and (x[0]['old_path'].count('.json') if x[0]['old_path'] else 0) == 0 and (x[0]['old_path'].count('.json') if x[0]['old_path'] else 0) == 0 )))]\n",
    "\n",
    "        # Iterate over each row in the filtered DataFrame\n",
    "        for index, row in lang_df.iterrows():\n",
    "            diff = row['mods'][0]\n",
    "            old_path = 'a/' + diff['old_path']\n",
    "            new_path = 'b/' + diff['new_path']\n",
    "            diff_content = diff['diff']  # assume diff_content is an empty string\n",
    "            item = {\n",
    "                'msg': row['message'],\n",
    "                'diff': f\"diff --git {old_path} {new_path} {diff_content}\",\n",
    "                'lang': lang\n",
    "            }\n",
    "            dfs[lang].append(item)\n",
    "            bars[lang].update(1)\n",
    "\n",
    "            # Check if the language has reached 100,000 rows\n",
    "            if len(dfs[lang]) >= 1000:\n",
    "                print(f\"Reached 1000 rows for {lang}\")\n",
    "                languages.remove(lang)  # Remove language from list to avoid further processing\n",
    "                break\n",
    "    # Break out of the loop if all languages have reached 100,000 rows\n",
    "    if not languages:\n",
    "        break\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-28T13:07:39.948570Z",
     "start_time": "2024-05-28T13:07:38.671186Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Python:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "070ce3a604394446b595e2e12fafd394"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reached 1000 rows for Python\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T13:07:54.722138Z",
     "start_time": "2024-05-28T13:07:54.677160Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "import json\n",
    "\n",
    "# Create a single list of all items\n",
    "all_items = [item for lang in dfs for item in dfs[lang]]\n",
    "# Dump the data to a JSON file\n",
    "with open('../data/final_preprocessed_data/python_baseline_test_data_500.json', 'w') as f:\n",
    "    json.dump(all_items, f, indent=4)"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T17:56:48.205090Z",
     "start_time": "2024-04-25T17:56:47.184723Z"
    }
   },
   "source": [
    "import json\n",
    "data = []\n",
    "while any(value < 1000 for value in language_dict.values()):\n",
    "    for index, row in df.iterrows():\n",
    "        language = row['language']\n",
    "        if language in languages:\n",
    "            \n",
    "            if language_dict[language] >= 1000 or len(row['mods']) != 1 or row['mods'][0]['change_type'] != 'MODIFY' or len(f\"diff --git a/{row['mods'][0]['old_path']} b/{row['mods'][0]['new_path']} {row['mods'][0]['diff']}\") > 3000:\n",
    "                continue\n",
    "            language_dict[language] += 1\n",
    "\n",
    "            item = {\n",
    "                'msg': row['message'],\n",
    "                'diff': f\"diff --git a/{row['mods'][0]['old_path']} b/{row['mods'][0]['new_path']} {row['mods'][0]['diff']}\",\n",
    "                'lang': language\n",
    "            }\n",
    "            data.append(item)\n",
    "\n",
    "import random\n",
    "random.seed(42)\n",
    "random.shuffle(data)\n",
    "\n",
    "with open('../data/chronicle_data_dev.json', 'w', encoding='UTF-8') as f:\n",
    "    json.dump(data, f, indent=4)\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import json\n",
    "\n",
    "# Create a single list of all items\n",
    "all_items = [item for lang in dfs for item in dfs[lang]]\n",
    "\n",
    "import random\n",
    "random.seed(42)\n",
    "random.shuffle(all_items)\n",
    "\n",
    "# Dump the data to a JSON file\n",
    "with open('../data/chronicle/chronicle_test_data_dev.json', 'w') as f:\n",
    "    json.dump(all_items, f, indent=4)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-25T17:57:06.273064Z",
     "start_time": "2024-04-25T17:57:06.229410Z"
    }
   },
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "len(all_items)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-25T17:47:25.529028Z",
     "start_time": "2024-04-25T17:47:25.517026Z"
    }
   },
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "source": [
    "# 遍历每个item\n",
    "for item in data:\n",
    "    diff = item['diff']\n",
    "    new_diff = f\"diff --git {diff}\"\n",
    "\n",
    "    item['diff'] = new_diff\n",
    "\n",
    "# 将更新后的数据写入新的JSON文件\n",
    "with open('../data/chronicle_data.json', 'w', encoding='UTF-8') as file:\n",
    "    json.dump(data, file, indent=4)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "source": [
    "len(df)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T11:07:14.364197Z",
     "start_time": "2024-05-11T11:07:11.887852Z"
    }
   },
   "source": [
    "import pyarrow.parquet as pq\n",
    "import glob\n",
    "import os\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Create empty DataFrames for each language\n",
    "# languages = ['Java', 'Python', 'C++', 'C#', 'JavaScript']\n",
    "languages = ['Python', 'JavaScript']\n",
    "dfs = {lang: [] for lang in languages}\n",
    "\n",
    "# Create a tqdm progress bar for each language\n",
    "bars = {lang: tqdm(total=1000, desc=lang) for lang in languages}\n",
    "\n",
    "folder_path = '../rag/datasets--JetBrains-Research--commit-chronicle/snapshots/5fd076e67b812a9f3d1999e5e40f71715f84bb51/subset_cmg'  # 文件夹的路径\n",
    "\n",
    "files = glob.glob(os.path.join(folder_path, 'test*'))\n",
    "\n",
    "for file in files:\n",
    "    df = pq.read_table(file).to_pandas()\n",
    "\n",
    "    # Iterate over each language\n",
    "    for lang in languages[:]:\n",
    "        # Filter rows where language column matches the current language\n",
    "        condition = lambda x: all(len(f\"diff --git a/{item['old_path']} b/{item['new_path']} {item['diff']}\") <= 3000 for item in x)\n",
    "        type_condition = lambda x: all(item['change_type'] == 'MODIFY' for item in x)\n",
    "        lang_df = df[(df['language'] == lang) & (df['mods'].apply(len) > 1) & (df['mods'].apply(type_condition)) & (df['mods'].apply(condition))]\n",
    "\n",
    "        # Iterate over each row in the filtered DataFrame\n",
    "        for index, row in lang_df.iterrows():\n",
    "            diffs = {}\n",
    "            diffs['msg'] = row['message']\n",
    "            diffs['diffs'] = []\n",
    "            diffs['lang'] = lang\n",
    "            for diff in row['mods']:\n",
    "                old_path = 'a/' + diff['old_path']\n",
    "                new_path = 'b/' + diff['new_path']\n",
    "                diff_content = diff['diff']  # assume diff_content is an empty string\n",
    "                item = {\n",
    "                    'diff': f\"diff --git {old_path} {new_path} {diff_content}\",\n",
    "                }\n",
    "                diffs['diffs'].append(item)\n",
    "            merged_diff = '\\n'.join(diff['diff'] for diff in diffs['diffs'])\n",
    "            diffs['diffs'] = merged_diff\n",
    "            dfs[lang].append(diffs)\n",
    "            bars[lang].update(1)\n",
    "\n",
    "            # Check if the language has reached 100,000 rows\n",
    "            if len(dfs[lang]) >= 1000:\n",
    "                print(f\"Reached 1000 rows for {lang}\")\n",
    "                languages.remove(lang)  # Remove language from list to avoid further processing\n",
    "                break\n",
    "    # Break out of the loop if all languages have reached 100,000 rows\n",
    "    if not languages:\n",
    "        break"
   ],
   "execution_count": 1,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T11:43:56.747943Z",
     "start_time": "2024-05-10T11:43:56.735702Z"
    }
   },
   "cell_type": "code",
   "source": "len(dfs['JavaScript'])",
   "execution_count": 3,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T11:07:46.822743Z",
     "start_time": "2024-05-11T11:07:46.773745Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "\n",
    "# Create a single list of all items\n",
    "all_items = [item for lang in dfs for item in dfs[lang]]\n",
    "\n",
    "# Dump the data to a JSON file\n",
    "with open('../data/chronicle/chronicle_multi_diff_test_data.json', 'w', encoding='UTF-8') as f:\n",
    "    json.dump(all_items, f, indent=4)"
   ],
   "execution_count": 2,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": "",
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cmg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
